{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRukHLbtNl5P",
        "colab_type": "code",
        "outputId": "90ee129c-fa31-4023-83ae-b2e175a449ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "##install pytorch in colab\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.4)\n",
            "Requirement already satisfied: torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4wBaaNRg682",
        "colab_type": "code",
        "outputId": "4dc0e388-dec8-4bb1-bbdb-19d43c102a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBAG6IknNt9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBKvPDiGfGn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset\n",
        "class load_dataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.samples = pd.read_csv(data_path).values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx,:-1] ,self.samples[idx,-1]\n",
        "      \n",
        "###Model\n",
        "\n",
        "class MultilayerPerceptron(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MultilayerPerceptron, self).__init__()\n",
        "        \n",
        "        self.hidden = torch.nn.ModuleList()\n",
        "        self.hidden.append(torch.nn.Linear(num_features, hidden_nodes_list[0]))\n",
        "        for k in range(num_hidden_layes-1):\n",
        "            self.hidden.append(torch.nn.Linear(hidden_nodes_list[k], hidden_nodes_list[k+1]))\n",
        "             \n",
        "        ### Output layer\n",
        "        self.hidden.append(torch.nn.Linear(hidden_nodes_list[num_hidden_layes-1], num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        for layer in self.hidden[:-1]:\n",
        "          out = layer(out)\n",
        "          out = F.relu(out)\n",
        "\n",
        "        logits = self.hidden[-1](out)\n",
        "        probas = F.log_softmax(logits, dim=1)\n",
        "        return logits, probas\n",
        "      \n",
        "#weight initialization function\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    if initialisation_method=='xavier':\n",
        "      init.xavier_uniform_(m.weight)\n",
        "    if initialisation_method=='he':\n",
        "      init.kaiming_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n",
        "    \n",
        "#compute accuracy function\n",
        "def compute_accuracy(net, data_loader):\n",
        "    net.eval()\n",
        "    cost, correct_pred, num_examples = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            features = features.float().to(device)\n",
        "            targets = targets.long().to(device)\n",
        "            logits, probas = net(features)\n",
        "            cost += F.cross_entropy(logits, targets) * targets.size(0)\n",
        "            _, predicted_labels = torch.max(probas, 1)\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "        return cost/num_examples , correct_pred.float()/num_examples * 100\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d22O4rJoDeZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#data\n",
        "points_dim = 32\n",
        "radius_of_sphere = 1\n",
        "radius_of_shell = 1.6\n",
        "thickness_of_shell = 1\n",
        "csv_path = '/content/drive/My Drive/DL_exp/data/train_sp'+ str(radius_of_sphere) + '_sh'+ str(radius_of_shell) + '_t' + str(thickness_of_shell)+ '_' + str(points_dim) + 'dim.csv'     \n",
        "\n",
        "dataset = load_dataset(csv_path)\n",
        "size = len(dataset)\n",
        "\n",
        "\n",
        "#architecture\n",
        "num_features  = next(iter(dataset))[0].shape[0]        # Input data dimention\n",
        "hidden_nodes_list   = [64]                              # List of number of nodes at each hidden layer\n",
        "num_hidden_layes = len(hidden_nodes_list)              # The number of hidden layers\n",
        "num_classes   = 2                                      # The number of output classes. In this case, 0 and 1\n",
        "\n",
        "# 'xavier' : Xavier Initialisation\n",
        "# 'he' : He Initialisation\n",
        "initialisation_method = 'xavier'\n",
        "\n",
        "# 'sgd' : SGD (lr) \n",
        "# 'sgdwm' : SGD with Momentum (lr, momentum)\n",
        "# 'adagrad' : AdaGrad\n",
        "# 'adam' : Adam\n",
        "# 'ngd' : Natural gradient descent\n",
        "# 'l1' : L1 Regularisation\n",
        "# 'l2' : L2 Regularisation\n",
        "# 'pathnorm' : PathNorm Regularisation\n",
        "# 'spectralnorm' : Spectral norm Regularisation\n",
        "optimisation_method = 'sgdwm'  \n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = 400\n",
        "learning_rate = 0.05\n",
        "num_epochs = 100\n",
        "batch_size = size\n",
        "\n",
        "##load dataset\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "model = MultilayerPerceptron()\n",
        "model.apply(init_weights)\n",
        "model = model.to(device)\n",
        "\n",
        "if optimisation_method=='sgd' or optimisation_method=='ngd':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "if optimisation_method=='sgdwm':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "if optimisation_method=='adagrad':\n",
        "  optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
        "if optimisation_method=='adam':\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08)\n",
        "\n",
        "epoch_loss = []\n",
        "### training of a model\n",
        "start_time = time.time()\n",
        "epoch = 0\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "  cost,best_acc = compute_accuracy(model, train_dataloader)\n",
        "  print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (epoch,best_acc,cost))\n",
        "epoch_loss.append([0,11])\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "count = 1\n",
        "prev_acc=best_acc\n",
        "best_epoch = epoch\n",
        "best_cost = cost\n",
        "\n",
        "while True:\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_dataloader):\n",
        "        features = features.float().to(device)\n",
        "        targets = targets.long().to(device)\n",
        "            \n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "    epoch+=1\n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "        cost,acc = compute_accuracy(model, train_dataloader)\n",
        "        print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (epoch,acc,cost))\n",
        "        \n",
        "    if prev_acc==acc:\n",
        "      count+=1\n",
        "    else:\n",
        "      prev_acc=acc\n",
        "      count=1\n",
        "    if (epoch>50 and best_acc-acc>=5) or count==20 or epoch==400:\n",
        "      break\n",
        "    if acc>best_acc:\n",
        "      best_acc=acc\n",
        "      best_epoch = epoch\n",
        "      best_cost = cost\n",
        "    \n",
        "#     print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoSuX_AQv3vk",
        "colab_type": "code",
        "outputId": "f9b1f42b-d7db-4c7c-f319-743ec9830520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### training of multiple models and save the result in JSON file\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "start_time = time.time()\n",
        "radius_of_sphere = 1\n",
        "radius_of_shell = 2\n",
        "thickness_of_shell = 1\n",
        "\n",
        "with open('/content/drive/My Drive/DL_exp/result/loss.json', mode='r') as readjson:\n",
        "  try: \n",
        "    loss = json.loads(readjson.read())\n",
        "  except ValueError: \n",
        "    loss = {}\n",
        "          \n",
        "dimentions = [2,4,8,16,32,64]          #list of dimention of data\n",
        "for dim in dimentions:\n",
        "  csv_path = '/content/drive/My Drive/DL_exp/uniform_data/train_sp'+ str(radius_of_sphere) + '_sh'+ str(radius_of_shell) + '_t' + str(thickness_of_shell)+ '_' + str(dim) + 'dim.csv'\n",
        "  dataset = load_dataset(csv_path)\n",
        "  size = len(dataset)\n",
        "  train_dataloader = DataLoader(dataset, batch_size=size, shuffle=True)\n",
        "\n",
        "\n",
        "  tmp_h = [2,4,6,8,12,16,24,32,48,64,128,256]             #list of number of nodes in hidden layer\n",
        "  tmp_i = [100,200,300,400,500,600,700,800,900,1000]      #list of random seed for weight initialization\n",
        "\n",
        "  for t_h in tmp_h:\n",
        "    for t_i in tmp_i:\n",
        "\n",
        "      #architecture\n",
        "      num_features  = next(iter(dataset))[0].shape[0]        # Input data dimention\n",
        "      hidden_nodes_list   = [t_h]                              # List of number of nodes at each hidden layer\n",
        "      num_hidden_layes = len(hidden_nodes_list)              # The number of hidden layers\n",
        "      num_classes   = 2                                      # The number of output classes. In this case, 0 and 1\n",
        "\n",
        "      initialisation_method = 'xavier'\n",
        "      optimisation_method = 'sgdwm'  \n",
        "\n",
        "      # Hyperparameters\n",
        "      random_seed = t_i\n",
        "      learning_rate = 0.05\n",
        "            \n",
        "      torch.manual_seed(random_seed)\n",
        "      model = MultilayerPerceptron()\n",
        "      model.apply(init_weights)\n",
        "      model = model.to(device)\n",
        "\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "      model_loss = []\n",
        "      epoch = 0\n",
        "\n",
        "      with torch.set_grad_enabled(False):\n",
        "        cost,best_acc = compute_accuracy(model, train_dataloader)\n",
        "      model_loss.append([epoch,cost.data.tolist()])\n",
        "      # for epoch in range(num_epochs):\n",
        "      count = 1\n",
        "      prev_acc=best_acc\n",
        "      best_epoch = epoch\n",
        "      best_cost = cost\n",
        "\n",
        "      while True:\n",
        "          model.train()\n",
        "          for batch_idx, (features, targets) in enumerate(train_dataloader):\n",
        "\n",
        "              features = features.float().to(device)\n",
        "              targets = targets.long().to(device)\n",
        "\n",
        "              ### FORWARD AND BACK PROP\n",
        "              logits, probas = model(features)\n",
        "              cost = F.cross_entropy(logits, targets)\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              cost.backward()\n",
        "\n",
        "              ### UPDATE MODEL PARAMETERS\n",
        "              optimizer.step()\n",
        "\n",
        "\n",
        "          with torch.set_grad_enabled(False):\n",
        "              cost,acc = compute_accuracy(model, train_dataloader)\n",
        "              \n",
        "          epoch+=1\n",
        "          model_loss.append([epoch,cost.data.tolist()])\n",
        "          if prev_acc==acc:\n",
        "            count+=1\n",
        "          else:\n",
        "            prev_acc=acc\n",
        "            count=1\n",
        "          if (epoch>50 and best_acc-acc>=5) or count==20 or epoch==400:\n",
        "            break\n",
        "          if acc>best_acc:\n",
        "            best_acc=acc\n",
        "            best_epoch = epoch\n",
        "            best_cost = cost\n",
        " \n",
        "      print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (best_epoch,best_acc,best_cost))\n",
        "  \n",
        "      if len(hidden_nodes_list)==1:\n",
        "        loss.update({'sh'+ str(radius_of_shell)+'dim'+str(dim)+'h'+str(t_h)+'i'+str(t_i):model_loss})\n",
        "      else:\n",
        "        loss.update({'sh'+ str(radius_of_shell)+'dim'+str(dim)+'h'+str(t_h)+'i'+str(t_i)+'l2':model_loss})\n",
        "    \n",
        "      with open('/content/drive/My Drive/DL_exp/result/uniform_result.json', mode='r') as readjson:\n",
        "        try: \n",
        "          result = json.loads(readjson.read())\n",
        "        except ValueError: \n",
        "          result = []  \n",
        "      \n",
        "        \n",
        "      with open('/content/drive/My Drive/DL_exp/result/uniform_result.json', mode='w') as feedjson:\n",
        "        entry = {'sphere_radius': 1, 'shell_radius': radius_of_shell, 'thickness' : 1, 'dimension':dim, 'n_nodes':hidden_nodes_list, 'random_seed':t_i, 'epoch':best_epoch, 'accuracy':best_acc.data.tolist(), 'cost':best_cost.data.tolist()}\n",
        "        result.append(entry)\n",
        "        json.dump(result, feedjson)\n",
        "\n",
        "with open('/content/drive/My Drive/DL_exp/result/loss.json', mode='w') as feedjson:\n",
        "  json.dump(loss, feedjson)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 078 | Accuracy: 86.20% | Cost: 0.3343\n",
            "Epoch: 090 | Accuracy: 89.60% | Cost: 0.2856\n",
            "Epoch: 045 | Accuracy: 63.20% | Cost: 0.6925\n",
            "Epoch: 039 | Accuracy: 64.80% | Cost: 0.6756\n",
            "Epoch: 195 | Accuracy: 89.60% | Cost: 0.2708\n",
            "Epoch: 069 | Accuracy: 84.80% | Cost: 0.3917\n",
            "Epoch: 206 | Accuracy: 90.00% | Cost: 0.2657\n",
            "Epoch: 097 | Accuracy: 69.80% | Cost: 0.5406\n",
            "Epoch: 143 | Accuracy: 89.40% | Cost: 0.3071\n",
            "Epoch: 181 | Accuracy: 86.20% | Cost: 0.3069\n",
            "Epoch: 122 | Accuracy: 100.00% | Cost: 0.0849\n",
            "Epoch: 074 | Accuracy: 100.00% | Cost: 0.1490\n",
            "Epoch: 092 | Accuracy: 99.80% | Cost: 0.0968\n",
            "Epoch: 070 | Accuracy: 100.00% | Cost: 0.1470\n",
            "Epoch: 051 | Accuracy: 100.00% | Cost: 0.1495\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.1453\n",
            "Epoch: 122 | Accuracy: 100.00% | Cost: 0.0696\n",
            "Epoch: 116 | Accuracy: 100.00% | Cost: 0.0749\n",
            "Epoch: 073 | Accuracy: 100.00% | Cost: 0.1150\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.1723\n",
            "Epoch: 055 | Accuracy: 100.00% | Cost: 0.1254\n",
            "Epoch: 034 | Accuracy: 100.00% | Cost: 0.2516\n",
            "Epoch: 050 | Accuracy: 100.00% | Cost: 0.1247\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.1469\n",
            "Epoch: 047 | Accuracy: 100.00% | Cost: 0.1388\n",
            "Epoch: 044 | Accuracy: 100.00% | Cost: 0.1649\n",
            "Epoch: 063 | Accuracy: 100.00% | Cost: 0.0975\n",
            "Epoch: 028 | Accuracy: 100.00% | Cost: 0.2396\n",
            "Epoch: 067 | Accuracy: 100.00% | Cost: 0.1221\n",
            "Epoch: 060 | Accuracy: 100.00% | Cost: 0.0880\n",
            "Epoch: 038 | Accuracy: 100.00% | Cost: 0.2038\n",
            "Epoch: 045 | Accuracy: 100.00% | Cost: 0.1320\n",
            "Epoch: 040 | Accuracy: 100.00% | Cost: 0.1404\n",
            "Epoch: 058 | Accuracy: 100.00% | Cost: 0.0939\n",
            "Epoch: 028 | Accuracy: 100.00% | Cost: 0.2402\n",
            "Epoch: 061 | Accuracy: 100.00% | Cost: 0.0905\n",
            "Epoch: 049 | Accuracy: 100.00% | Cost: 0.1465\n",
            "Epoch: 030 | Accuracy: 99.80% | Cost: 0.2452\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.1135\n",
            "Epoch: 029 | Accuracy: 100.00% | Cost: 0.2130\n",
            "Epoch: 028 | Accuracy: 100.00% | Cost: 0.2073\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.1955\n",
            "Epoch: 044 | Accuracy: 100.00% | Cost: 0.1441\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1532\n",
            "Epoch: 025 | Accuracy: 100.00% | Cost: 0.2939\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3240\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1356\n",
            "Epoch: 047 | Accuracy: 100.00% | Cost: 0.1218\n",
            "Epoch: 036 | Accuracy: 100.00% | Cost: 0.2033\n",
            "Epoch: 040 | Accuracy: 100.00% | Cost: 0.1867\n",
            "Epoch: 025 | Accuracy: 100.00% | Cost: 0.2206\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.2699\n",
            "Epoch: 038 | Accuracy: 100.00% | Cost: 0.1487\n",
            "Epoch: 024 | Accuracy: 100.00% | Cost: 0.2611\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.2498\n",
            "Epoch: 044 | Accuracy: 100.00% | Cost: 0.1435\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3179\n",
            "Epoch: 038 | Accuracy: 100.00% | Cost: 0.2246\n",
            "Epoch: 038 | Accuracy: 100.00% | Cost: 0.1470\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.2966\n",
            "Epoch: 024 | Accuracy: 100.00% | Cost: 0.2551\n",
            "Epoch: 040 | Accuracy: 100.00% | Cost: 0.1561\n",
            "Epoch: 022 | Accuracy: 100.00% | Cost: 0.3160\n",
            "Epoch: 024 | Accuracy: 100.00% | Cost: 0.2342\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.2521\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2888\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.2727\n",
            "Epoch: 024 | Accuracy: 100.00% | Cost: 0.2413\n",
            "Epoch: 025 | Accuracy: 100.00% | Cost: 0.2812\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.3134\n",
            "Epoch: 037 | Accuracy: 100.00% | Cost: 0.1388\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.2889\n",
            "Epoch: 020 | Accuracy: 100.00% | Cost: 0.3017\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2851\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.2912\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.2993\n",
            "Epoch: 024 | Accuracy: 100.00% | Cost: 0.2437\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2885\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3175\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3186\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.2908\n",
            "Epoch: 020 | Accuracy: 100.00% | Cost: 0.2746\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.2455\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2682\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.3018\n",
            "Epoch: 022 | Accuracy: 100.00% | Cost: 0.2798\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2821\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2763\n",
            "Epoch: 022 | Accuracy: 100.00% | Cost: 0.2732\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.2517\n",
            "Epoch: 018 | Accuracy: 100.00% | Cost: 0.3258\n",
            "Epoch: 018 | Accuracy: 100.00% | Cost: 0.2984\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.3164\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2643\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.2514\n",
            "Epoch: 020 | Accuracy: 100.00% | Cost: 0.3296\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.3140\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.2625\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.2502\n",
            "Epoch: 024 | Accuracy: 100.00% | Cost: 0.2684\n",
            "Epoch: 018 | Accuracy: 100.00% | Cost: 0.3226\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.3034\n",
            "Epoch: 020 | Accuracy: 100.00% | Cost: 0.3004\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2802\n",
            "Epoch: 020 | Accuracy: 100.00% | Cost: 0.2968\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2856\n",
            "Epoch: 018 | Accuracy: 100.00% | Cost: 0.3012\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.2945\n",
            "Epoch: 020 | Accuracy: 100.00% | Cost: 0.2977\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.2984\n",
            "Epoch: 018 | Accuracy: 100.00% | Cost: 0.3227\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.3011\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.2987\n",
            "Epoch: 018 | Accuracy: 100.00% | Cost: 0.3174\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.2946\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.2909\n",
            "Epoch: 018 | Accuracy: 100.00% | Cost: 0.3159\n",
            "Epoch: 019 | Accuracy: 100.00% | Cost: 0.3035\n",
            "Epoch: 018 | Accuracy: 100.00% | Cost: 0.3180\n",
            "Epoch: 017 | Accuracy: 100.00% | Cost: 0.3273\n",
            "Epoch: 101 | Accuracy: 82.40% | Cost: 0.4033\n",
            "Epoch: 189 | Accuracy: 84.00% | Cost: 0.3820\n",
            "Epoch: 202 | Accuracy: 85.80% | Cost: 0.3672\n",
            "Epoch: 217 | Accuracy: 85.60% | Cost: 0.3341\n",
            "Epoch: 171 | Accuracy: 81.40% | Cost: 0.4031\n",
            "Epoch: 139 | Accuracy: 81.60% | Cost: 0.4060\n",
            "Epoch: 119 | Accuracy: 67.20% | Cost: 0.5796\n",
            "Epoch: 151 | Accuracy: 82.60% | Cost: 0.3945\n",
            "Epoch: 137 | Accuracy: 83.60% | Cost: 0.4069\n",
            "Epoch: 114 | Accuracy: 81.20% | Cost: 0.4323\n",
            "Epoch: 236 | Accuracy: 96.00% | Cost: 0.1109\n",
            "Epoch: 098 | Accuracy: 96.40% | Cost: 0.1698\n",
            "Epoch: 197 | Accuracy: 92.00% | Cost: 0.1904\n",
            "Epoch: 162 | Accuracy: 96.60% | Cost: 0.1448\n",
            "Epoch: 189 | Accuracy: 96.20% | Cost: 0.1461\n",
            "Epoch: 273 | Accuracy: 95.20% | Cost: 0.1402\n",
            "Epoch: 206 | Accuracy: 92.40% | Cost: 0.1908\n",
            "Epoch: 080 | Accuracy: 98.20% | Cost: 0.1548\n",
            "Epoch: 210 | Accuracy: 98.20% | Cost: 0.1056\n",
            "Epoch: 137 | Accuracy: 91.80% | Cost: 0.2189\n",
            "Epoch: 162 | Accuracy: 99.80% | Cost: 0.0659\n",
            "Epoch: 119 | Accuracy: 97.00% | Cost: 0.1177\n",
            "Epoch: 116 | Accuracy: 97.80% | Cost: 0.1115\n",
            "Epoch: 129 | Accuracy: 98.60% | Cost: 0.0917\n",
            "Epoch: 151 | Accuracy: 99.00% | Cost: 0.0871\n",
            "Epoch: 112 | Accuracy: 100.00% | Cost: 0.0963\n",
            "Epoch: 217 | Accuracy: 99.20% | Cost: 0.0860\n",
            "Epoch: 170 | Accuracy: 99.40% | Cost: 0.0748\n",
            "Epoch: 092 | Accuracy: 97.00% | Cost: 0.1536\n",
            "Epoch: 103 | Accuracy: 100.00% | Cost: 0.0974\n",
            "Epoch: 062 | Accuracy: 99.60% | Cost: 0.1630\n",
            "Epoch: 081 | Accuracy: 100.00% | Cost: 0.1152\n",
            "Epoch: 088 | Accuracy: 100.00% | Cost: 0.1094\n",
            "Epoch: 096 | Accuracy: 100.00% | Cost: 0.0823\n",
            "Epoch: 076 | Accuracy: 96.40% | Cost: 0.1539\n",
            "Epoch: 091 | Accuracy: 100.00% | Cost: 0.0854\n",
            "Epoch: 064 | Accuracy: 100.00% | Cost: 0.1264\n",
            "Epoch: 094 | Accuracy: 100.00% | Cost: 0.0800\n",
            "Epoch: 132 | Accuracy: 99.80% | Cost: 0.0667\n",
            "Epoch: 163 | Accuracy: 99.80% | Cost: 0.0693\n",
            "Epoch: 077 | Accuracy: 100.00% | Cost: 0.1081\n",
            "Epoch: 057 | Accuracy: 100.00% | Cost: 0.1865\n",
            "Epoch: 087 | Accuracy: 99.80% | Cost: 0.1174\n",
            "Epoch: 093 | Accuracy: 100.00% | Cost: 0.0973\n",
            "Epoch: 096 | Accuracy: 100.00% | Cost: 0.0869\n",
            "Epoch: 052 | Accuracy: 100.00% | Cost: 0.1907\n",
            "Epoch: 075 | Accuracy: 100.00% | Cost: 0.0998\n",
            "Epoch: 132 | Accuracy: 100.00% | Cost: 0.0658\n",
            "Epoch: 061 | Accuracy: 100.00% | Cost: 0.1127\n",
            "Epoch: 100 | Accuracy: 100.00% | Cost: 0.0885\n",
            "Epoch: 078 | Accuracy: 100.00% | Cost: 0.0877\n",
            "Epoch: 079 | Accuracy: 100.00% | Cost: 0.1131\n",
            "Epoch: 061 | Accuracy: 100.00% | Cost: 0.1375\n",
            "Epoch: 073 | Accuracy: 100.00% | Cost: 0.0848\n",
            "Epoch: 083 | Accuracy: 100.00% | Cost: 0.0857\n",
            "Epoch: 064 | Accuracy: 100.00% | Cost: 0.1212\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.1701\n",
            "Epoch: 059 | Accuracy: 99.60% | Cost: 0.1235\n",
            "Epoch: 062 | Accuracy: 99.60% | Cost: 0.1417\n",
            "Epoch: 083 | Accuracy: 100.00% | Cost: 0.0941\n",
            "Epoch: 069 | Accuracy: 100.00% | Cost: 0.1046\n",
            "Epoch: 054 | Accuracy: 100.00% | Cost: 0.1224\n",
            "Epoch: 035 | Accuracy: 99.80% | Cost: 0.2237\n",
            "Epoch: 035 | Accuracy: 100.00% | Cost: 0.1921\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.3270\n",
            "Epoch: 069 | Accuracy: 100.00% | Cost: 0.1134\n",
            "Epoch: 056 | Accuracy: 100.00% | Cost: 0.1313\n",
            "Epoch: 068 | Accuracy: 100.00% | Cost: 0.0947\n",
            "Epoch: 072 | Accuracy: 100.00% | Cost: 0.1074\n",
            "Epoch: 054 | Accuracy: 100.00% | Cost: 0.1274\n",
            "Epoch: 031 | Accuracy: 100.00% | Cost: 0.2669\n",
            "Epoch: 033 | Accuracy: 100.00% | Cost: 0.1984\n",
            "Epoch: 054 | Accuracy: 100.00% | Cost: 0.1462\n",
            "Epoch: 032 | Accuracy: 100.00% | Cost: 0.2190\n",
            "Epoch: 048 | Accuracy: 100.00% | Cost: 0.1368\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.1648\n",
            "Epoch: 045 | Accuracy: 100.00% | Cost: 0.1595\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1804\n",
            "Epoch: 047 | Accuracy: 100.00% | Cost: 0.1413\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1605\n",
            "Epoch: 031 | Accuracy: 99.80% | Cost: 0.2375\n",
            "Epoch: 037 | Accuracy: 100.00% | Cost: 0.2135\n",
            "Epoch: 062 | Accuracy: 100.00% | Cost: 0.1099\n",
            "Epoch: 052 | Accuracy: 100.00% | Cost: 0.1170\n",
            "Epoch: 032 | Accuracy: 100.00% | Cost: 0.2403\n",
            "Epoch: 039 | Accuracy: 100.00% | Cost: 0.2011\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.3038\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.1780\n",
            "Epoch: 029 | Accuracy: 100.00% | Cost: 0.2343\n",
            "Epoch: 053 | Accuracy: 100.00% | Cost: 0.1207\n",
            "Epoch: 029 | Accuracy: 100.00% | Cost: 0.2411\n",
            "Epoch: 030 | Accuracy: 100.00% | Cost: 0.2284\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.1657\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3036\n",
            "Epoch: 055 | Accuracy: 100.00% | Cost: 0.1251\n",
            "Epoch: 033 | Accuracy: 99.80% | Cost: 0.2220\n",
            "Epoch: 039 | Accuracy: 100.00% | Cost: 0.1737\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.3149\n",
            "Epoch: 031 | Accuracy: 100.00% | Cost: 0.2423\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.2716\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.2602\n",
            "Epoch: 022 | Accuracy: 100.00% | Cost: 0.3021\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.3326\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.2714\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3091\n",
            "Epoch: 029 | Accuracy: 100.00% | Cost: 0.2558\n",
            "Epoch: 038 | Accuracy: 100.00% | Cost: 0.1822\n",
            "Epoch: 025 | Accuracy: 100.00% | Cost: 0.2812\n",
            "Epoch: 032 | Accuracy: 100.00% | Cost: 0.2203\n",
            "Epoch: 030 | Accuracy: 100.00% | Cost: 0.2498\n",
            "Epoch: 036 | Accuracy: 100.00% | Cost: 0.1974\n",
            "Epoch: 032 | Accuracy: 100.00% | Cost: 0.2164\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.2922\n",
            "Epoch: 022 | Accuracy: 100.00% | Cost: 0.3325\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3046\n",
            "Epoch: 031 | Accuracy: 100.00% | Cost: 0.2192\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.2860\n",
            "Epoch: 021 | Accuracy: 100.00% | Cost: 0.3328\n",
            "Epoch: 022 | Accuracy: 100.00% | Cost: 0.3212\n",
            "Epoch: 020 | Accuracy: 100.00% | Cost: 0.3418\n",
            "Epoch: 178 | Accuracy: 85.40% | Cost: 0.3528\n",
            "Epoch: 390 | Accuracy: 82.60% | Cost: 0.4121\n",
            "Epoch: 059 | Accuracy: 70.80% | Cost: 0.5764\n",
            "Epoch: 187 | Accuracy: 85.60% | Cost: 0.3725\n",
            "Epoch: 211 | Accuracy: 83.40% | Cost: 0.3921\n",
            "Epoch: 246 | Accuracy: 84.00% | Cost: 0.3931\n",
            "Epoch: 127 | Accuracy: 81.00% | Cost: 0.4602\n",
            "Epoch: 318 | Accuracy: 87.20% | Cost: 0.3415\n",
            "Epoch: 029 | Accuracy: 62.20% | Cost: 0.6810\n",
            "Epoch: 129 | Accuracy: 70.20% | Cost: 0.5638\n",
            "Epoch: 253 | Accuracy: 94.00% | Cost: 0.1480\n",
            "Epoch: 151 | Accuracy: 94.40% | Cost: 0.1596\n",
            "Epoch: 194 | Accuracy: 95.60% | Cost: 0.1540\n",
            "Epoch: 154 | Accuracy: 94.80% | Cost: 0.1609\n",
            "Epoch: 203 | Accuracy: 91.60% | Cost: 0.2271\n",
            "Epoch: 154 | Accuracy: 96.40% | Cost: 0.1576\n",
            "Epoch: 199 | Accuracy: 96.60% | Cost: 0.1400\n",
            "Epoch: 319 | Accuracy: 95.60% | Cost: 0.1431\n",
            "Epoch: 260 | Accuracy: 92.20% | Cost: 0.2228\n",
            "Epoch: 242 | Accuracy: 96.00% | Cost: 0.1239\n",
            "Epoch: 176 | Accuracy: 98.60% | Cost: 0.1066\n",
            "Epoch: 157 | Accuracy: 94.60% | Cost: 0.1552\n",
            "Epoch: 158 | Accuracy: 96.20% | Cost: 0.1408\n",
            "Epoch: 181 | Accuracy: 95.80% | Cost: 0.1463\n",
            "Epoch: 128 | Accuracy: 97.60% | Cost: 0.1532\n",
            "Epoch: 090 | Accuracy: 94.60% | Cost: 0.2356\n",
            "Epoch: 223 | Accuracy: 99.00% | Cost: 0.0956\n",
            "Epoch: 287 | Accuracy: 99.40% | Cost: 0.0751\n",
            "Epoch: 172 | Accuracy: 99.20% | Cost: 0.0939\n",
            "Epoch: 227 | Accuracy: 97.20% | Cost: 0.0900\n",
            "Epoch: 153 | Accuracy: 98.80% | Cost: 0.1047\n",
            "Epoch: 163 | Accuracy: 99.60% | Cost: 0.0768\n",
            "Epoch: 249 | Accuracy: 98.60% | Cost: 0.0938\n",
            "Epoch: 128 | Accuracy: 98.00% | Cost: 0.1310\n",
            "Epoch: 175 | Accuracy: 98.80% | Cost: 0.0961\n",
            "Epoch: 137 | Accuracy: 97.00% | Cost: 0.1233\n",
            "Epoch: 170 | Accuracy: 99.20% | Cost: 0.0936\n",
            "Epoch: 175 | Accuracy: 97.60% | Cost: 0.0985\n",
            "Epoch: 190 | Accuracy: 98.80% | Cost: 0.0880\n",
            "Epoch: 214 | Accuracy: 98.20% | Cost: 0.0948\n",
            "Epoch: 142 | Accuracy: 99.40% | Cost: 0.0801\n",
            "Epoch: 092 | Accuracy: 98.60% | Cost: 0.1485\n",
            "Epoch: 098 | Accuracy: 99.00% | Cost: 0.1142\n",
            "Epoch: 126 | Accuracy: 100.00% | Cost: 0.0928\n",
            "Epoch: 152 | Accuracy: 99.80% | Cost: 0.0699\n",
            "Epoch: 090 | Accuracy: 99.20% | Cost: 0.1406\n",
            "Epoch: 138 | Accuracy: 99.60% | Cost: 0.1006\n",
            "Epoch: 116 | Accuracy: 99.40% | Cost: 0.1090\n",
            "Epoch: 101 | Accuracy: 99.00% | Cost: 0.1105\n",
            "Epoch: 119 | Accuracy: 99.80% | Cost: 0.0950\n",
            "Epoch: 101 | Accuracy: 99.80% | Cost: 0.1123\n",
            "Epoch: 077 | Accuracy: 99.40% | Cost: 0.1535\n",
            "Epoch: 137 | Accuracy: 100.00% | Cost: 0.0805\n",
            "Epoch: 113 | Accuracy: 99.60% | Cost: 0.0808\n",
            "Epoch: 136 | Accuracy: 100.00% | Cost: 0.0765\n",
            "Epoch: 077 | Accuracy: 99.20% | Cost: 0.1487\n",
            "Epoch: 070 | Accuracy: 98.80% | Cost: 0.1560\n",
            "Epoch: 065 | Accuracy: 99.20% | Cost: 0.1618\n",
            "Epoch: 108 | Accuracy: 100.00% | Cost: 0.1115\n",
            "Epoch: 067 | Accuracy: 99.40% | Cost: 0.1675\n",
            "Epoch: 076 | Accuracy: 100.00% | Cost: 0.1393\n",
            "Epoch: 074 | Accuracy: 99.80% | Cost: 0.1272\n",
            "Epoch: 098 | Accuracy: 100.00% | Cost: 0.0915\n",
            "Epoch: 073 | Accuracy: 99.80% | Cost: 0.1322\n",
            "Epoch: 110 | Accuracy: 100.00% | Cost: 0.0757\n",
            "Epoch: 076 | Accuracy: 100.00% | Cost: 0.1475\n",
            "Epoch: 052 | Accuracy: 100.00% | Cost: 0.1784\n",
            "Epoch: 064 | Accuracy: 99.80% | Cost: 0.1740\n",
            "Epoch: 058 | Accuracy: 99.80% | Cost: 0.1561\n",
            "Epoch: 071 | Accuracy: 100.00% | Cost: 0.1175\n",
            "Epoch: 044 | Accuracy: 99.80% | Cost: 0.2188\n",
            "Epoch: 106 | Accuracy: 100.00% | Cost: 0.0926\n",
            "Epoch: 081 | Accuracy: 100.00% | Cost: 0.1110\n",
            "Epoch: 034 | Accuracy: 100.00% | Cost: 0.2428\n",
            "Epoch: 080 | Accuracy: 100.00% | Cost: 0.1122\n",
            "Epoch: 065 | Accuracy: 100.00% | Cost: 0.1408\n",
            "Epoch: 047 | Accuracy: 99.80% | Cost: 0.1830\n",
            "Epoch: 081 | Accuracy: 99.80% | Cost: 0.1198\n",
            "Epoch: 067 | Accuracy: 100.00% | Cost: 0.1306\n",
            "Epoch: 062 | Accuracy: 99.80% | Cost: 0.1409\n",
            "Epoch: 060 | Accuracy: 100.00% | Cost: 0.1481\n",
            "Epoch: 054 | Accuracy: 100.00% | Cost: 0.1602\n",
            "Epoch: 056 | Accuracy: 100.00% | Cost: 0.1559\n",
            "Epoch: 055 | Accuracy: 100.00% | Cost: 0.1494\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.2125\n",
            "Epoch: 066 | Accuracy: 100.00% | Cost: 0.1328\n",
            "Epoch: 048 | Accuracy: 100.00% | Cost: 0.1865\n",
            "Epoch: 089 | Accuracy: 100.00% | Cost: 0.0918\n",
            "Epoch: 064 | Accuracy: 100.00% | Cost: 0.1199\n",
            "Epoch: 045 | Accuracy: 100.00% | Cost: 0.1729\n",
            "Epoch: 067 | Accuracy: 100.00% | Cost: 0.1208\n",
            "Epoch: 047 | Accuracy: 99.80% | Cost: 0.1897\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.1377\n",
            "Epoch: 053 | Accuracy: 100.00% | Cost: 0.1499\n",
            "Epoch: 054 | Accuracy: 100.00% | Cost: 0.1480\n",
            "Epoch: 064 | Accuracy: 100.00% | Cost: 0.1263\n",
            "Epoch: 053 | Accuracy: 100.00% | Cost: 0.1566\n",
            "Epoch: 055 | Accuracy: 100.00% | Cost: 0.1608\n",
            "Epoch: 057 | Accuracy: 100.00% | Cost: 0.1426\n",
            "Epoch: 070 | Accuracy: 100.00% | Cost: 0.1052\n",
            "Epoch: 037 | Accuracy: 100.00% | Cost: 0.2196\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.3183\n",
            "Epoch: 058 | Accuracy: 100.00% | Cost: 0.1362\n",
            "Epoch: 047 | Accuracy: 100.00% | Cost: 0.1650\n",
            "Epoch: 029 | Accuracy: 100.00% | Cost: 0.2720\n",
            "Epoch: 048 | Accuracy: 100.00% | Cost: 0.1747\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1880\n",
            "Epoch: 052 | Accuracy: 100.00% | Cost: 0.1572\n",
            "Epoch: 048 | Accuracy: 100.00% | Cost: 0.1677\n",
            "Epoch: 051 | Accuracy: 100.00% | Cost: 0.1537\n",
            "Epoch: 038 | Accuracy: 100.00% | Cost: 0.2064\n",
            "Epoch: 034 | Accuracy: 100.00% | Cost: 0.2294\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.2925\n",
            "Epoch: 050 | Accuracy: 100.00% | Cost: 0.1502\n",
            "Epoch: 037 | Accuracy: 100.00% | Cost: 0.2222\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1929\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1986\n",
            "Epoch: 038 | Accuracy: 100.00% | Cost: 0.2145\n",
            "Epoch: 035 | Accuracy: 100.00% | Cost: 0.2257\n",
            "Epoch: 033 | Accuracy: 100.00% | Cost: 0.2259\n",
            "Epoch: 309 | Accuracy: 85.40% | Cost: 0.3590\n",
            "Epoch: 345 | Accuracy: 86.20% | Cost: 0.3662\n",
            "Epoch: 286 | Accuracy: 90.00% | Cost: 0.2887\n",
            "Epoch: 227 | Accuracy: 88.00% | Cost: 0.3391\n",
            "Epoch: 183 | Accuracy: 85.40% | Cost: 0.3805\n",
            "Epoch: 396 | Accuracy: 87.80% | Cost: 0.3488\n",
            "Epoch: 208 | Accuracy: 85.60% | Cost: 0.3726\n",
            "Epoch: 145 | Accuracy: 68.00% | Cost: 0.5732\n",
            "Epoch: 253 | Accuracy: 87.20% | Cost: 0.3619\n",
            "Epoch: 195 | Accuracy: 87.40% | Cost: 0.3533\n",
            "Epoch: 222 | Accuracy: 97.00% | Cost: 0.1292\n",
            "Epoch: 234 | Accuracy: 94.40% | Cost: 0.1946\n",
            "Epoch: 269 | Accuracy: 95.60% | Cost: 0.1630\n",
            "Epoch: 264 | Accuracy: 95.80% | Cost: 0.1391\n",
            "Epoch: 238 | Accuracy: 92.60% | Cost: 0.1994\n",
            "Epoch: 194 | Accuracy: 95.80% | Cost: 0.1572\n",
            "Epoch: 154 | Accuracy: 95.60% | Cost: 0.1748\n",
            "Epoch: 267 | Accuracy: 94.40% | Cost: 0.1969\n",
            "Epoch: 207 | Accuracy: 97.40% | Cost: 0.1408\n",
            "Epoch: 204 | Accuracy: 99.00% | Cost: 0.1047\n",
            "Epoch: 219 | Accuracy: 97.80% | Cost: 0.1033\n",
            "Epoch: 249 | Accuracy: 98.20% | Cost: 0.1044\n",
            "Epoch: 133 | Accuracy: 98.20% | Cost: 0.1548\n",
            "Epoch: 131 | Accuracy: 96.80% | Cost: 0.1610\n",
            "Epoch: 266 | Accuracy: 98.20% | Cost: 0.0949\n",
            "Epoch: 233 | Accuracy: 97.80% | Cost: 0.1255\n",
            "Epoch: 203 | Accuracy: 99.00% | Cost: 0.1036\n",
            "Epoch: 197 | Accuracy: 99.00% | Cost: 0.1134\n",
            "Epoch: 202 | Accuracy: 99.80% | Cost: 0.0869\n",
            "Epoch: 182 | Accuracy: 98.80% | Cost: 0.1297\n",
            "Epoch: 226 | Accuracy: 98.60% | Cost: 0.0894\n",
            "Epoch: 128 | Accuracy: 99.60% | Cost: 0.1165\n",
            "Epoch: 126 | Accuracy: 98.00% | Cost: 0.1205\n",
            "Epoch: 152 | Accuracy: 99.00% | Cost: 0.1144\n",
            "Epoch: 191 | Accuracy: 99.60% | Cost: 0.0794\n",
            "Epoch: 164 | Accuracy: 98.60% | Cost: 0.1235\n",
            "Epoch: 166 | Accuracy: 98.00% | Cost: 0.1298\n",
            "Epoch: 196 | Accuracy: 98.80% | Cost: 0.0927\n",
            "Epoch: 136 | Accuracy: 97.80% | Cost: 0.1363\n",
            "Epoch: 159 | Accuracy: 99.40% | Cost: 0.1012\n",
            "Epoch: 106 | Accuracy: 97.60% | Cost: 0.1669\n",
            "Epoch: 128 | Accuracy: 98.60% | Cost: 0.1117\n",
            "Epoch: 145 | Accuracy: 99.20% | Cost: 0.0969\n",
            "Epoch: 102 | Accuracy: 100.00% | Cost: 0.1112\n",
            "Epoch: 135 | Accuracy: 99.60% | Cost: 0.0969\n",
            "Epoch: 115 | Accuracy: 98.60% | Cost: 0.1106\n",
            "Epoch: 122 | Accuracy: 99.00% | Cost: 0.1252\n",
            "Epoch: 101 | Accuracy: 98.40% | Cost: 0.1550\n",
            "Epoch: 104 | Accuracy: 99.00% | Cost: 0.1586\n",
            "Epoch: 116 | Accuracy: 98.80% | Cost: 0.1171\n",
            "Epoch: 132 | Accuracy: 99.80% | Cost: 0.0937\n",
            "Epoch: 101 | Accuracy: 99.40% | Cost: 0.1252\n",
            "Epoch: 126 | Accuracy: 99.80% | Cost: 0.1052\n",
            "Epoch: 114 | Accuracy: 100.00% | Cost: 0.1175\n",
            "Epoch: 122 | Accuracy: 99.60% | Cost: 0.1054\n",
            "Epoch: 095 | Accuracy: 99.80% | Cost: 0.1217\n",
            "Epoch: 081 | Accuracy: 99.40% | Cost: 0.1560\n",
            "Epoch: 151 | Accuracy: 100.00% | Cost: 0.0847\n",
            "Epoch: 097 | Accuracy: 99.80% | Cost: 0.1274\n",
            "Epoch: 128 | Accuracy: 99.80% | Cost: 0.0938\n",
            "Epoch: 077 | Accuracy: 99.40% | Cost: 0.1511\n",
            "Epoch: 077 | Accuracy: 99.60% | Cost: 0.1619\n",
            "Epoch: 099 | Accuracy: 100.00% | Cost: 0.1048\n",
            "Epoch: 058 | Accuracy: 99.60% | Cost: 0.1869\n",
            "Epoch: 099 | Accuracy: 100.00% | Cost: 0.1061\n",
            "Epoch: 075 | Accuracy: 98.80% | Cost: 0.1732\n",
            "Epoch: 062 | Accuracy: 99.20% | Cost: 0.1961\n",
            "Epoch: 083 | Accuracy: 99.60% | Cost: 0.1467\n",
            "Epoch: 067 | Accuracy: 99.60% | Cost: 0.1672\n",
            "Epoch: 064 | Accuracy: 99.20% | Cost: 0.1812\n",
            "Epoch: 101 | Accuracy: 100.00% | Cost: 0.0965\n",
            "Epoch: 077 | Accuracy: 100.00% | Cost: 0.1210\n",
            "Epoch: 081 | Accuracy: 99.60% | Cost: 0.1202\n",
            "Epoch: 095 | Accuracy: 100.00% | Cost: 0.0992\n",
            "Epoch: 080 | Accuracy: 99.80% | Cost: 0.1179\n",
            "Epoch: 074 | Accuracy: 100.00% | Cost: 0.1389\n",
            "Epoch: 080 | Accuracy: 100.00% | Cost: 0.1187\n",
            "Epoch: 108 | Accuracy: 100.00% | Cost: 0.0875\n",
            "Epoch: 064 | Accuracy: 100.00% | Cost: 0.1724\n",
            "Epoch: 048 | Accuracy: 99.40% | Cost: 0.2133\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.2382\n",
            "Epoch: 048 | Accuracy: 100.00% | Cost: 0.1961\n",
            "Epoch: 073 | Accuracy: 100.00% | Cost: 0.1255\n",
            "Epoch: 060 | Accuracy: 99.80% | Cost: 0.1621\n",
            "Epoch: 049 | Accuracy: 99.80% | Cost: 0.2036\n",
            "Epoch: 063 | Accuracy: 100.00% | Cost: 0.1437\n",
            "Epoch: 061 | Accuracy: 99.80% | Cost: 0.1518\n",
            "Epoch: 075 | Accuracy: 100.00% | Cost: 0.1270\n",
            "Epoch: 051 | Accuracy: 100.00% | Cost: 0.1965\n",
            "Epoch: 068 | Accuracy: 100.00% | Cost: 0.1287\n",
            "Epoch: 040 | Accuracy: 99.80% | Cost: 0.2407\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.1485\n",
            "Epoch: 052 | Accuracy: 100.00% | Cost: 0.1705\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.1516\n",
            "Epoch: 053 | Accuracy: 100.00% | Cost: 0.1737\n",
            "Epoch: 051 | Accuracy: 100.00% | Cost: 0.1810\n",
            "Epoch: 065 | Accuracy: 100.00% | Cost: 0.1418\n",
            "Epoch: 056 | Accuracy: 99.80% | Cost: 0.1638\n",
            "Epoch: 057 | Accuracy: 100.00% | Cost: 0.1609\n",
            "Epoch: 061 | Accuracy: 100.00% | Cost: 0.1449\n",
            "Epoch: 037 | Accuracy: 100.00% | Cost: 0.2322\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.1958\n",
            "Epoch: 031 | Accuracy: 100.00% | Cost: 0.3006\n",
            "Epoch: 027 | Accuracy: 99.80% | Cost: 0.3124\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.1987\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.2050\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.3051\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1995\n",
            "Epoch: 041 | Accuracy: 100.00% | Cost: 0.2160\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.2061\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3692\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3414\n",
            "Epoch: 022 | Accuracy: 100.00% | Cost: 0.3482\n",
            "Epoch: 031 | Accuracy: 100.00% | Cost: 0.2654\n",
            "Epoch: 025 | Accuracy: 100.00% | Cost: 0.3196\n",
            "Epoch: 024 | Accuracy: 100.00% | Cost: 0.3301\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.2992\n",
            "Epoch: 025 | Accuracy: 100.00% | Cost: 0.3267\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.1929\n",
            "Epoch: 022 | Accuracy: 100.00% | Cost: 0.3483\n",
            "Epoch: 369 | Accuracy: 91.20% | Cost: 0.2733\n",
            "Epoch: 255 | Accuracy: 91.40% | Cost: 0.3027\n",
            "Epoch: 354 | Accuracy: 92.00% | Cost: 0.2632\n",
            "Epoch: 253 | Accuracy: 73.80% | Cost: 0.5183\n",
            "Epoch: 246 | Accuracy: 90.00% | Cost: 0.3199\n",
            "Epoch: 210 | Accuracy: 89.60% | Cost: 0.3378\n",
            "Epoch: 284 | Accuracy: 92.00% | Cost: 0.2850\n",
            "Epoch: 329 | Accuracy: 90.60% | Cost: 0.2856\n",
            "Epoch: 395 | Accuracy: 89.40% | Cost: 0.2962\n",
            "Epoch: 234 | Accuracy: 88.40% | Cost: 0.3171\n",
            "Epoch: 164 | Accuracy: 97.00% | Cost: 0.2003\n",
            "Epoch: 191 | Accuracy: 97.40% | Cost: 0.1570\n",
            "Epoch: 338 | Accuracy: 95.80% | Cost: 0.1622\n",
            "Epoch: 219 | Accuracy: 95.60% | Cost: 0.1695\n",
            "Epoch: 261 | Accuracy: 98.20% | Cost: 0.1333\n",
            "Epoch: 224 | Accuracy: 98.00% | Cost: 0.1395\n",
            "Epoch: 282 | Accuracy: 97.20% | Cost: 0.1303\n",
            "Epoch: 252 | Accuracy: 99.00% | Cost: 0.1376\n",
            "Epoch: 275 | Accuracy: 96.80% | Cost: 0.1379\n",
            "Epoch: 198 | Accuracy: 94.40% | Cost: 0.1857\n",
            "Epoch: 174 | Accuracy: 99.60% | Cost: 0.1199\n",
            "Epoch: 192 | Accuracy: 98.40% | Cost: 0.1274\n",
            "Epoch: 196 | Accuracy: 99.20% | Cost: 0.1301\n",
            "Epoch: 170 | Accuracy: 99.00% | Cost: 0.1299\n",
            "Epoch: 280 | Accuracy: 98.00% | Cost: 0.1291\n",
            "Epoch: 213 | Accuracy: 99.80% | Cost: 0.0866\n",
            "Epoch: 239 | Accuracy: 98.60% | Cost: 0.1361\n",
            "Epoch: 218 | Accuracy: 98.40% | Cost: 0.1166\n",
            "Epoch: 210 | Accuracy: 97.40% | Cost: 0.1514\n",
            "Epoch: 173 | Accuracy: 97.40% | Cost: 0.1846\n",
            "Epoch: 183 | Accuracy: 99.40% | Cost: 0.0992\n",
            "Epoch: 201 | Accuracy: 99.60% | Cost: 0.1022\n",
            "Epoch: 210 | Accuracy: 99.80% | Cost: 0.0772\n",
            "Epoch: 167 | Accuracy: 99.20% | Cost: 0.1240\n",
            "Epoch: 144 | Accuracy: 96.60% | Cost: 0.2013\n",
            "Epoch: 175 | Accuracy: 99.00% | Cost: 0.1187\n",
            "Epoch: 147 | Accuracy: 99.20% | Cost: 0.1360\n",
            "Epoch: 272 | Accuracy: 100.00% | Cost: 0.0749\n",
            "Epoch: 181 | Accuracy: 99.40% | Cost: 0.1058\n",
            "Epoch: 132 | Accuracy: 97.60% | Cost: 0.1974\n",
            "Epoch: 154 | Accuracy: 99.60% | Cost: 0.1083\n",
            "Epoch: 171 | Accuracy: 99.60% | Cost: 0.0993\n",
            "Epoch: 155 | Accuracy: 100.00% | Cost: 0.1075\n",
            "Epoch: 170 | Accuracy: 99.20% | Cost: 0.1157\n",
            "Epoch: 107 | Accuracy: 98.40% | Cost: 0.1819\n",
            "Epoch: 173 | Accuracy: 100.00% | Cost: 0.0926\n",
            "Epoch: 142 | Accuracy: 99.60% | Cost: 0.1229\n",
            "Epoch: 129 | Accuracy: 99.60% | Cost: 0.1217\n",
            "Epoch: 149 | Accuracy: 99.80% | Cost: 0.1134\n",
            "Epoch: 150 | Accuracy: 99.40% | Cost: 0.1468\n",
            "Epoch: 114 | Accuracy: 99.60% | Cost: 0.1480\n",
            "Epoch: 124 | Accuracy: 99.80% | Cost: 0.1169\n",
            "Epoch: 120 | Accuracy: 99.80% | Cost: 0.1221\n",
            "Epoch: 148 | Accuracy: 100.00% | Cost: 0.0929\n",
            "Epoch: 140 | Accuracy: 100.00% | Cost: 0.1193\n",
            "Epoch: 123 | Accuracy: 99.20% | Cost: 0.1449\n",
            "Epoch: 120 | Accuracy: 99.80% | Cost: 0.1330\n",
            "Epoch: 141 | Accuracy: 99.80% | Cost: 0.0995\n",
            "Epoch: 154 | Accuracy: 99.80% | Cost: 0.0921\n",
            "Epoch: 103 | Accuracy: 99.00% | Cost: 0.1636\n",
            "Epoch: 128 | Accuracy: 100.00% | Cost: 0.1085\n",
            "Epoch: 118 | Accuracy: 99.80% | Cost: 0.1104\n",
            "Epoch: 092 | Accuracy: 98.80% | Cost: 0.1963\n",
            "Epoch: 084 | Accuracy: 99.80% | Cost: 0.1795\n",
            "Epoch: 112 | Accuracy: 100.00% | Cost: 0.1278\n",
            "Epoch: 105 | Accuracy: 99.60% | Cost: 0.1279\n",
            "Epoch: 089 | Accuracy: 99.00% | Cost: 0.1673\n",
            "Epoch: 109 | Accuracy: 99.60% | Cost: 0.1409\n",
            "Epoch: 099 | Accuracy: 99.60% | Cost: 0.1440\n",
            "Epoch: 122 | Accuracy: 100.00% | Cost: 0.1123\n",
            "Epoch: 097 | Accuracy: 100.00% | Cost: 0.1370\n",
            "Epoch: 090 | Accuracy: 99.60% | Cost: 0.1631\n",
            "Epoch: 097 | Accuracy: 100.00% | Cost: 0.1244\n",
            "Epoch: 092 | Accuracy: 99.20% | Cost: 0.1536\n",
            "Epoch: 098 | Accuracy: 100.00% | Cost: 0.1311\n",
            "Epoch: 109 | Accuracy: 100.00% | Cost: 0.1180\n",
            "Epoch: 096 | Accuracy: 99.80% | Cost: 0.1372\n",
            "Epoch: 079 | Accuracy: 99.40% | Cost: 0.1923\n",
            "Epoch: 073 | Accuracy: 99.20% | Cost: 0.1800\n",
            "Epoch: 084 | Accuracy: 99.60% | Cost: 0.1630\n",
            "Epoch: 113 | Accuracy: 100.00% | Cost: 0.1084\n",
            "Epoch: 084 | Accuracy: 99.80% | Cost: 0.1458\n",
            "Epoch: 113 | Accuracy: 100.00% | Cost: 0.0952\n",
            "Epoch: 101 | Accuracy: 100.00% | Cost: 0.1122\n",
            "Epoch: 109 | Accuracy: 100.00% | Cost: 0.1024\n",
            "Epoch: 088 | Accuracy: 100.00% | Cost: 0.1259\n",
            "Epoch: 106 | Accuracy: 100.00% | Cost: 0.1136\n",
            "Epoch: 095 | Accuracy: 99.60% | Cost: 0.1186\n",
            "Epoch: 070 | Accuracy: 99.80% | Cost: 0.1729\n",
            "Epoch: 080 | Accuracy: 99.80% | Cost: 0.1681\n",
            "Epoch: 073 | Accuracy: 100.00% | Cost: 0.1580\n",
            "Epoch: 076 | Accuracy: 99.80% | Cost: 0.1461\n",
            "Epoch: 102 | Accuracy: 100.00% | Cost: 0.1117\n",
            "Epoch: 076 | Accuracy: 99.60% | Cost: 0.1596\n",
            "Epoch: 071 | Accuracy: 100.00% | Cost: 0.1609\n",
            "Epoch: 082 | Accuracy: 100.00% | Cost: 0.1346\n",
            "Epoch: 072 | Accuracy: 99.80% | Cost: 0.1743\n",
            "Epoch: 089 | Accuracy: 100.00% | Cost: 0.1269\n",
            "Epoch: 074 | Accuracy: 100.00% | Cost: 0.1563\n",
            "Epoch: 074 | Accuracy: 99.60% | Cost: 0.1635\n",
            "Epoch: 025 | Accuracy: 99.60% | Cost: 0.3661\n",
            "Epoch: 081 | Accuracy: 100.00% | Cost: 0.1168\n",
            "Epoch: 068 | Accuracy: 100.00% | Cost: 0.1564\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.2292\n",
            "Epoch: 054 | Accuracy: 100.00% | Cost: 0.1927\n",
            "Epoch: 085 | Accuracy: 100.00% | Cost: 0.1154\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.2527\n",
            "Epoch: 067 | Accuracy: 100.00% | Cost: 0.1508\n",
            "Epoch: 084 | Accuracy: 100.00% | Cost: 0.1154\n",
            "Epoch: 034 | Accuracy: 99.80% | Cost: 0.2940\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3736\n",
            "Epoch: 025 | Accuracy: 99.80% | Cost: 0.3467\n",
            "Epoch: 023 | Accuracy: 100.00% | Cost: 0.3789\n",
            "Epoch: 025 | Accuracy: 100.00% | Cost: 0.3523\n",
            "Epoch: 025 | Accuracy: 100.00% | Cost: 0.3676\n",
            "Epoch: 063 | Accuracy: 100.00% | Cost: 0.1520\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.2331\n",
            "Epoch: 028 | Accuracy: 100.00% | Cost: 0.3282\n",
            "Epoch: 023 | Accuracy: 99.80% | Cost: 0.3842\n",
            "Epoch: 033 | Accuracy: 100.00% | Cost: 0.2917\n",
            "Epoch: 365 | Accuracy: 90.80% | Cost: 0.2957\n",
            "Epoch: 281 | Accuracy: 93.20% | Cost: 0.2618\n",
            "Epoch: 354 | Accuracy: 92.00% | Cost: 0.2546\n",
            "Epoch: 260 | Accuracy: 89.60% | Cost: 0.3136\n",
            "Epoch: 000 | Accuracy: 54.20% | Cost: 0.7649\n",
            "Epoch: 267 | Accuracy: 89.80% | Cost: 0.3243\n",
            "Epoch: 205 | Accuracy: 90.20% | Cost: 0.3119\n",
            "Epoch: 393 | Accuracy: 93.40% | Cost: 0.2233\n",
            "Epoch: 393 | Accuracy: 95.20% | Cost: 0.2031\n",
            "Epoch: 282 | Accuracy: 94.80% | Cost: 0.2341\n",
            "Epoch: 213 | Accuracy: 96.80% | Cost: 0.1822\n",
            "Epoch: 237 | Accuracy: 98.40% | Cost: 0.1455\n",
            "Epoch: 267 | Accuracy: 99.20% | Cost: 0.1260\n",
            "Epoch: 259 | Accuracy: 96.60% | Cost: 0.1546\n",
            "Epoch: 273 | Accuracy: 97.60% | Cost: 0.1513\n",
            "Epoch: 170 | Accuracy: 96.60% | Cost: 0.2224\n",
            "Epoch: 272 | Accuracy: 97.20% | Cost: 0.1756\n",
            "Epoch: 199 | Accuracy: 96.80% | Cost: 0.1959\n",
            "Epoch: 295 | Accuracy: 99.00% | Cost: 0.1075\n",
            "Epoch: 237 | Accuracy: 97.80% | Cost: 0.1406\n",
            "Epoch: 150 | Accuracy: 97.40% | Cost: 0.1823\n",
            "Epoch: 205 | Accuracy: 98.80% | Cost: 0.1264\n",
            "Epoch: 218 | Accuracy: 98.20% | Cost: 0.1407\n",
            "Epoch: 216 | Accuracy: 99.60% | Cost: 0.1096\n",
            "Epoch: 226 | Accuracy: 98.60% | Cost: 0.1090\n",
            "Epoch: 213 | Accuracy: 97.00% | Cost: 0.2009\n",
            "Epoch: 175 | Accuracy: 96.20% | Cost: 0.1874\n",
            "Epoch: 186 | Accuracy: 98.20% | Cost: 0.1529\n",
            "Epoch: 293 | Accuracy: 98.80% | Cost: 0.1125\n",
            "Epoch: 249 | Accuracy: 99.60% | Cost: 0.0921\n",
            "Epoch: 192 | Accuracy: 99.40% | Cost: 0.1067\n",
            "Epoch: 153 | Accuracy: 97.40% | Cost: 0.1998\n",
            "Epoch: 252 | Accuracy: 100.00% | Cost: 0.0767\n",
            "Epoch: 203 | Accuracy: 99.00% | Cost: 0.1068\n",
            "Epoch: 241 | Accuracy: 99.80% | Cost: 0.0758\n",
            "Epoch: 148 | Accuracy: 99.40% | Cost: 0.1540\n",
            "Epoch: 181 | Accuracy: 99.80% | Cost: 0.1234\n",
            "Epoch: 246 | Accuracy: 100.00% | Cost: 0.0784\n",
            "Epoch: 207 | Accuracy: 100.00% | Cost: 0.0929\n",
            "Epoch: 209 | Accuracy: 99.80% | Cost: 0.0935\n",
            "Epoch: 160 | Accuracy: 99.60% | Cost: 0.1186\n",
            "Epoch: 203 | Accuracy: 100.00% | Cost: 0.0817\n",
            "Epoch: 129 | Accuracy: 98.40% | Cost: 0.1647\n",
            "Epoch: 194 | Accuracy: 99.60% | Cost: 0.0975\n",
            "Epoch: 135 | Accuracy: 99.40% | Cost: 0.1494\n",
            "Epoch: 160 | Accuracy: 98.80% | Cost: 0.1269\n",
            "Epoch: 202 | Accuracy: 100.00% | Cost: 0.0928\n",
            "Epoch: 197 | Accuracy: 100.00% | Cost: 0.0970\n",
            "Epoch: 185 | Accuracy: 99.40% | Cost: 0.1076\n",
            "Epoch: 182 | Accuracy: 99.60% | Cost: 0.1055\n",
            "Epoch: 188 | Accuracy: 100.00% | Cost: 0.0851\n",
            "Epoch: 165 | Accuracy: 99.60% | Cost: 0.1158\n",
            "Epoch: 162 | Accuracy: 98.80% | Cost: 0.1319\n",
            "Epoch: 136 | Accuracy: 99.80% | Cost: 0.1378\n",
            "Epoch: 153 | Accuracy: 99.60% | Cost: 0.1096\n",
            "Epoch: 159 | Accuracy: 99.60% | Cost: 0.1150\n",
            "Epoch: 130 | Accuracy: 99.40% | Cost: 0.1442\n",
            "Epoch: 169 | Accuracy: 99.60% | Cost: 0.1139\n",
            "Epoch: 153 | Accuracy: 99.80% | Cost: 0.1094\n",
            "Epoch: 147 | Accuracy: 99.60% | Cost: 0.1328\n",
            "Epoch: 062 | Accuracy: 96.80% | Cost: 0.2997\n",
            "Epoch: 109 | Accuracy: 99.40% | Cost: 0.1541\n",
            "Epoch: 142 | Accuracy: 100.00% | Cost: 0.1061\n",
            "Epoch: 102 | Accuracy: 99.00% | Cost: 0.1797\n",
            "Epoch: 110 | Accuracy: 99.40% | Cost: 0.1611\n",
            "Epoch: 151 | Accuracy: 100.00% | Cost: 0.0960\n",
            "Epoch: 136 | Accuracy: 99.80% | Cost: 0.1285\n",
            "Epoch: 112 | Accuracy: 99.80% | Cost: 0.1452\n",
            "Epoch: 111 | Accuracy: 99.20% | Cost: 0.1651\n",
            "Epoch: 147 | Accuracy: 100.00% | Cost: 0.1120\n",
            "Epoch: 135 | Accuracy: 100.00% | Cost: 0.1010\n",
            "Epoch: 082 | Accuracy: 99.20% | Cost: 0.2144\n",
            "Epoch: 124 | Accuracy: 99.80% | Cost: 0.1189\n",
            "Epoch: 117 | Accuracy: 99.80% | Cost: 0.1292\n",
            "Epoch: 118 | Accuracy: 99.80% | Cost: 0.1200\n",
            "Epoch: 156 | Accuracy: 99.80% | Cost: 0.0980\n",
            "Epoch: 075 | Accuracy: 99.40% | Cost: 0.2202\n",
            "Epoch: 147 | Accuracy: 100.00% | Cost: 0.0917\n",
            "Epoch: 111 | Accuracy: 100.00% | Cost: 0.1255\n",
            "Epoch: 101 | Accuracy: 99.60% | Cost: 0.1509\n",
            "Epoch: 126 | Accuracy: 100.00% | Cost: 0.0981\n",
            "Epoch: 088 | Accuracy: 99.40% | Cost: 0.1707\n",
            "Epoch: 077 | Accuracy: 99.80% | Cost: 0.2031\n",
            "Epoch: 110 | Accuracy: 99.80% | Cost: 0.1153\n",
            "Epoch: 092 | Accuracy: 99.80% | Cost: 0.1462\n",
            "Epoch: 104 | Accuracy: 100.00% | Cost: 0.1343\n",
            "Epoch: 111 | Accuracy: 99.80% | Cost: 0.1185\n",
            "Epoch: 087 | Accuracy: 100.00% | Cost: 0.1549\n",
            "Epoch: 085 | Accuracy: 99.80% | Cost: 0.1677\n",
            "Epoch: 117 | Accuracy: 99.80% | Cost: 0.1141\n",
            "Epoch: 059 | Accuracy: 99.40% | Cost: 0.2224\n",
            "Epoch: 104 | Accuracy: 100.00% | Cost: 0.1167\n",
            "Epoch: 061 | Accuracy: 99.60% | Cost: 0.2233\n",
            "Epoch: 091 | Accuracy: 99.80% | Cost: 0.1335\n",
            "Epoch: 063 | Accuracy: 99.60% | Cost: 0.2220\n",
            "Epoch: 069 | Accuracy: 99.20% | Cost: 0.1977\n",
            "Epoch: 076 | Accuracy: 100.00% | Cost: 0.1736\n",
            "Epoch: 065 | Accuracy: 99.20% | Cost: 0.2119\n",
            "Epoch: 087 | Accuracy: 99.80% | Cost: 0.1484\n",
            "Epoch: 093 | Accuracy: 99.80% | Cost: 0.1391\n",
            "Epoch: 033 | Accuracy: 100.00% | Cost: 0.2992\n",
            "Epoch: 051 | Accuracy: 99.80% | Cost: 0.2041\n",
            "Epoch: 091 | Accuracy: 100.00% | Cost: 0.1124\n",
            "Epoch: 067 | Accuracy: 100.00% | Cost: 0.1592\n",
            "Epoch: 027 | Accuracy: 100.00% | Cost: 0.3709\n",
            "Epoch: 061 | Accuracy: 99.80% | Cost: 0.1859\n",
            "Epoch: 065 | Accuracy: 99.80% | Cost: 0.1620\n",
            "Epoch: 032 | Accuracy: 99.60% | Cost: 0.3316\n",
            "Epoch: 068 | Accuracy: 99.80% | Cost: 0.1542\n",
            "Epoch: 045 | Accuracy: 99.80% | Cost: 0.2553\n",
            "Epoch: 028 | Accuracy: 99.60% | Cost: 0.3234\n",
            "Epoch: 028 | Accuracy: 100.00% | Cost: 0.3240\n",
            "Epoch: 029 | Accuracy: 100.00% | Cost: 0.3243\n",
            "Epoch: 038 | Accuracy: 100.00% | Cost: 0.2634\n",
            "Epoch: 043 | Accuracy: 99.80% | Cost: 0.2257\n",
            "Epoch: 022 | Accuracy: 99.80% | Cost: 0.3915\n",
            "Epoch: 028 | Accuracy: 100.00% | Cost: 0.3274\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.3437\n",
            "Epoch: 026 | Accuracy: 100.00% | Cost: 0.3621\n",
            "Epoch: 057 | Accuracy: 100.00% | Cost: 0.1698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2PfBT_Oo19X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}