{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRukHLbtNl5P",
        "colab_type": "code",
        "outputId": "90ee129c-fa31-4023-83ae-b2e175a449ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "##install pytorch in colab\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.4)\n",
            "Requirement already satisfied: torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4wBaaNRg682",
        "colab_type": "code",
        "outputId": "fec586c4-dac4-4b89-d96e-076d2c6bcd2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "##mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBAG6IknNt9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCzGdrvvOoP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##generate sphere-shell binary data\n",
        "def data_sphere_shell(num_samples,points_dim,radius_of_sphere, radius_of_shell, thickness_of_shell):\n",
        "\n",
        "    def get_sphere_shell_label(v):           \n",
        "        return 1 if np.sqrt(np.sum(np.square(v))) <= radius_of_sphere else 0\n",
        "\n",
        "    points = np.zeros([num_samples, points_dim])\n",
        "    labels = np.zeros([num_samples,1]).astype(int)\n",
        "    \n",
        "    # Generate positive points inside the circle.\n",
        "    for i in range(num_samples // 2):\n",
        "        r = random.uniform(0, radius_of_sphere)\n",
        "        angle = np.zeros(points_dim-1)\n",
        "        for j in range(points_dim-1):\n",
        "            angle[j] = random.uniform(0, 2 * np.pi)\n",
        "        \n",
        "        x = np.zeros(points_dim)\n",
        "        for j in range(points_dim-1):\n",
        "            x[j] = r * np.cos(angle[j])\n",
        "            r = r * np.sin(angle[j])\n",
        "        x[points_dim-1] = r\n",
        "        labels[i] = get_sphere_shell_label(x)\n",
        "        points[i] = x\n",
        "\n",
        "    # Generate negative points outside the circle.\n",
        "    for i in range(num_samples // 2, num_samples):\n",
        "        r = random.uniform(radius_of_shell-(thickness_of_shell/2), radius_of_shell+(thickness_of_shell/2))\n",
        "        angle = np.zeros(points_dim-1)\n",
        "        for j in range(points_dim-1):\n",
        "            angle[j] = random.uniform(0, 2 * np.pi)\n",
        "        \n",
        "        x = np.zeros(points_dim)\n",
        "        for j in range(points_dim-1):\n",
        "            x[j] = r * np.cos(angle[j])\n",
        "            r = r * np.sin(angle[j])\n",
        "        x[points_dim-1] = r\n",
        "        labels[i] = get_sphere_shell_label(x)\n",
        "        points[i] = x\n",
        "        \n",
        "    return points, labels\n",
        "    \n",
        "points_dim = 6\n",
        "num_samples = 500\n",
        "radius_of_sphere = 1\n",
        "radius_of_shell = 2.4\n",
        "thickness_of_shell = 1\n",
        "points, labels = data_sphere_shell(num_samples,points_dim,radius_of_sphere, radius_of_shell, thickness_of_shell)\n",
        "\n",
        "#path to csv file to store generated data\n",
        "csv_path = '/content/drive/My Drive/DL_exp/data/train_sp'+ str(radius_of_sphere) + '_sh'+ str(radius_of_shell) + '_t' + str(thickness_of_shell)+ '_' + str(points_dim) + 'dim.csv'     \n",
        "with open(csv_path, 'w') as writeFile:\n",
        "    writer = csv.writer(writeFile)\n",
        "    header = [\"c\"+str(i) for i in range(points_dim)]\n",
        "    header.append(\"label\")\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(np.hstack((points,labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBKvPDiGfGn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset class\n",
        "class load_dataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.samples = pd.read_csv(data_path).values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx,:-1] ,self.samples[idx,-1]\n",
        "      \n",
        "###Model\n",
        "\n",
        "class MultilayerPerceptron(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MultilayerPerceptron, self).__init__()\n",
        "        \n",
        "        self.hidden = torch.nn.ModuleList()\n",
        "        self.hidden.append(torch.nn.Linear(num_features, hidden_nodes_list[0]))\n",
        "        for k in range(num_hidden_layes-1):\n",
        "            self.hidden.append(torch.nn.Linear(hidden_nodes_list[k], hidden_nodes_list[k+1]))\n",
        "             \n",
        "        ### Output layer\n",
        "        self.hidden.append(torch.nn.Linear(hidden_nodes_list[num_hidden_layes-1], num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        for layer in self.hidden[:-1]:\n",
        "          out = layer(out)\n",
        "          out = F.relu(out)\n",
        "\n",
        "        logits = self.hidden[-1](out)\n",
        "        probas = F.log_softmax(logits, dim=1)\n",
        "        return logits, probas\n",
        "      \n",
        "#weight initialization function\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    if initialisation_method=='xavier':\n",
        "      init.xavier_uniform_(m.weight)\n",
        "    if initialisation_method=='he':\n",
        "      init.kaiming_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n",
        "    \n",
        "#compute accuracy function\n",
        "def compute_accuracy(net, data_loader):\n",
        "    net.eval()\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            features = features.float().to(device)\n",
        "            targets = targets.long().to(device)\n",
        "            logits, probas = net(features)\n",
        "            cost = F.cross_entropy(logits, targets)\n",
        "            _, predicted_labels = torch.max(probas, 1)\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "        return cost,correct_pred.float()/num_examples * 100\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d22O4rJoDeZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#data\n",
        "points_dim = 6\n",
        "radius_of_sphere = 1\n",
        "radius_of_shell = 2.4\n",
        "thickness_of_shell = 1\n",
        "csv_path = '/content/drive/My Drive/DL_exp/data/train_sp'+ str(radius_of_sphere) + '_sh'+ str(radius_of_shell) + '_t' + str(thickness_of_shell)+ '_' + str(points_dim) + 'dim.csv'     \n",
        "\n",
        "dataset = load_dataset(csv_path)\n",
        "size = len(dataset)\n",
        "\n",
        "\n",
        "#architecture\n",
        "num_features  = next(iter(dataset))[0].shape[0]        # Input data dimention\n",
        "hidden_nodes_list   = [4]                              # List of number of nodes at each hidden layer\n",
        "num_hidden_layes = len(hidden_nodes_list)              # The number of hidden layers\n",
        "num_classes   = 2                                      # The number of output classes. In this case, 0 and 1\n",
        "\n",
        "# 'xavier' : Xavier Initialisation\n",
        "# 'he' : He Initialisation\n",
        "initialisation_method = 'xavier'\n",
        "\n",
        "# 'sgd' : SGD (lr) \n",
        "# 'sgdwm' : SGD with Momentum (lr, momentum)\n",
        "# 'adagrad' : AdaGrad\n",
        "# 'adam' : Adam\n",
        "# 'ngd' : Natural gradient descent\n",
        "# 'l1' : L1 Regularisation\n",
        "# 'l2' : L2 Regularisation\n",
        "# 'pathnorm' : PathNorm Regularisation\n",
        "# 'spectralnorm' : Spectral norm Regularisation\n",
        "optimisation_method = 'sgdwm'  \n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = 400\n",
        "learning_rate = 0.03\n",
        "num_epochs = 100\n",
        "batch_size = size\n",
        "\n",
        "##load dataset\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGkhMyIrRSCt",
        "colab_type": "code",
        "outputId": "f68b43ed-dced-482c-af36-a8e3890800ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### training of a model\n",
        "torch.manual_seed(random_seed)\n",
        "model = MultilayerPerceptron()\n",
        "model.apply(init_weights)\n",
        "model = model.to(device)\n",
        "\n",
        "if optimisation_method=='sgd' or optimisation_method=='ngd':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "if optimisation_method=='sgdwm':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "if optimisation_method=='adagrad':\n",
        "  optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
        "if optimisation_method=='adam':\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08)\n",
        "  \n",
        "  \n",
        "start_time = time.time()\n",
        "epoch = 0\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "  cost,best_acc = compute_accuracy(model, train_dataloader)\n",
        "  print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (epoch,best_acc,cost))\n",
        "  \n",
        "# for epoch in range(num_epochs):\n",
        "count = 1\n",
        "prev_acc=best_acc\n",
        "best_epoch = epoch\n",
        "best_cost = cost\n",
        "\n",
        "while True:\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_dataloader):\n",
        "        \n",
        "        features = features.float().to(device)\n",
        "        targets = targets.long().to(device)\n",
        "            \n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        cost,acc = compute_accuracy(model, train_dataloader)\n",
        "        print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (epoch,acc,cost))\n",
        "        \n",
        "    epoch+=1\n",
        "    if prev_acc==acc:\n",
        "      count+=1\n",
        "    else:\n",
        "      prev_acc=acc\n",
        "      count=1\n",
        "    if (epoch>50 and best_acc-acc>=5) or count==20 or epoch==400:\n",
        "      break\n",
        "    if acc>best_acc:\n",
        "      best_acc=acc\n",
        "      best_epoch = epoch\n",
        "      best_cost = cost\n",
        "    \n",
        "#     print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 000 | Accuracy: 53.40% | Cost: 0.9229\n",
            "Epoch: 000 | Accuracy: 52.40% | Cost: 0.9135\n",
            "Epoch: 001 | Accuracy: 49.60% | Cost: 0.8964\n",
            "Epoch: 002 | Accuracy: 46.20% | Cost: 0.8738\n",
            "Epoch: 003 | Accuracy: 41.00% | Cost: 0.8479\n",
            "Epoch: 004 | Accuracy: 36.00% | Cost: 0.8211\n",
            "Epoch: 005 | Accuracy: 30.00% | Cost: 0.7952\n",
            "Epoch: 006 | Accuracy: 25.60% | Cost: 0.7718\n",
            "Epoch: 007 | Accuracy: 30.40% | Cost: 0.7515\n",
            "Epoch: 008 | Accuracy: 33.00% | Cost: 0.7345\n",
            "Epoch: 009 | Accuracy: 36.00% | Cost: 0.7208\n",
            "Epoch: 010 | Accuracy: 38.20% | Cost: 0.7096\n",
            "Epoch: 011 | Accuracy: 39.60% | Cost: 0.7004\n",
            "Epoch: 012 | Accuracy: 40.00% | Cost: 0.6925\n",
            "Epoch: 013 | Accuracy: 40.20% | Cost: 0.6854\n",
            "Epoch: 014 | Accuracy: 40.40% | Cost: 0.6789\n",
            "Epoch: 015 | Accuracy: 41.40% | Cost: 0.6725\n",
            "Epoch: 016 | Accuracy: 41.60% | Cost: 0.6662\n",
            "Epoch: 017 | Accuracy: 41.60% | Cost: 0.6599\n",
            "Epoch: 018 | Accuracy: 41.40% | Cost: 0.6535\n",
            "Epoch: 019 | Accuracy: 41.20% | Cost: 0.6471\n",
            "Epoch: 020 | Accuracy: 40.60% | Cost: 0.6407\n",
            "Epoch: 021 | Accuracy: 41.40% | Cost: 0.6345\n",
            "Epoch: 022 | Accuracy: 54.60% | Cost: 0.6285\n",
            "Epoch: 023 | Accuracy: 59.00% | Cost: 0.6228\n",
            "Epoch: 024 | Accuracy: 61.60% | Cost: 0.6174\n",
            "Epoch: 025 | Accuracy: 63.60% | Cost: 0.6125\n",
            "Epoch: 026 | Accuracy: 65.00% | Cost: 0.6078\n",
            "Epoch: 027 | Accuracy: 65.60% | Cost: 0.6036\n",
            "Epoch: 028 | Accuracy: 66.20% | Cost: 0.5998\n",
            "Epoch: 029 | Accuracy: 66.80% | Cost: 0.5964\n",
            "Epoch: 030 | Accuracy: 67.20% | Cost: 0.5933\n",
            "Epoch: 031 | Accuracy: 68.20% | Cost: 0.5905\n",
            "Epoch: 032 | Accuracy: 68.60% | Cost: 0.5880\n",
            "Epoch: 033 | Accuracy: 68.60% | Cost: 0.5857\n",
            "Epoch: 034 | Accuracy: 68.60% | Cost: 0.5836\n",
            "Epoch: 035 | Accuracy: 69.00% | Cost: 0.5816\n",
            "Epoch: 036 | Accuracy: 69.20% | Cost: 0.5798\n",
            "Epoch: 037 | Accuracy: 69.60% | Cost: 0.5780\n",
            "Epoch: 038 | Accuracy: 69.80% | Cost: 0.5762\n",
            "Epoch: 039 | Accuracy: 69.80% | Cost: 0.5745\n",
            "Epoch: 040 | Accuracy: 70.00% | Cost: 0.5728\n",
            "Epoch: 041 | Accuracy: 70.40% | Cost: 0.5711\n",
            "Epoch: 042 | Accuracy: 70.60% | Cost: 0.5694\n",
            "Epoch: 043 | Accuracy: 70.80% | Cost: 0.5677\n",
            "Epoch: 044 | Accuracy: 71.00% | Cost: 0.5660\n",
            "Epoch: 045 | Accuracy: 71.00% | Cost: 0.5643\n",
            "Epoch: 046 | Accuracy: 71.00% | Cost: 0.5626\n",
            "Epoch: 047 | Accuracy: 71.00% | Cost: 0.5609\n",
            "Epoch: 048 | Accuracy: 71.60% | Cost: 0.5593\n",
            "Epoch: 049 | Accuracy: 71.40% | Cost: 0.5576\n",
            "Epoch: 050 | Accuracy: 71.40% | Cost: 0.5560\n",
            "Epoch: 051 | Accuracy: 71.60% | Cost: 0.5544\n",
            "Epoch: 052 | Accuracy: 72.00% | Cost: 0.5528\n",
            "Epoch: 053 | Accuracy: 72.20% | Cost: 0.5511\n",
            "Epoch: 054 | Accuracy: 72.20% | Cost: 0.5495\n",
            "Epoch: 055 | Accuracy: 72.60% | Cost: 0.5478\n",
            "Epoch: 056 | Accuracy: 72.60% | Cost: 0.5461\n",
            "Epoch: 057 | Accuracy: 72.60% | Cost: 0.5444\n",
            "Epoch: 058 | Accuracy: 72.60% | Cost: 0.5426\n",
            "Epoch: 059 | Accuracy: 73.20% | Cost: 0.5407\n",
            "Epoch: 060 | Accuracy: 73.40% | Cost: 0.5388\n",
            "Epoch: 061 | Accuracy: 73.60% | Cost: 0.5367\n",
            "Epoch: 062 | Accuracy: 73.40% | Cost: 0.5346\n",
            "Epoch: 063 | Accuracy: 73.40% | Cost: 0.5323\n",
            "Epoch: 064 | Accuracy: 73.60% | Cost: 0.5299\n",
            "Epoch: 065 | Accuracy: 73.60% | Cost: 0.5274\n",
            "Epoch: 066 | Accuracy: 74.00% | Cost: 0.5247\n",
            "Epoch: 067 | Accuracy: 74.20% | Cost: 0.5218\n",
            "Epoch: 068 | Accuracy: 74.80% | Cost: 0.5186\n",
            "Epoch: 069 | Accuracy: 75.40% | Cost: 0.5152\n",
            "Epoch: 070 | Accuracy: 75.80% | Cost: 0.5115\n",
            "Epoch: 071 | Accuracy: 76.00% | Cost: 0.5077\n",
            "Epoch: 072 | Accuracy: 76.20% | Cost: 0.5035\n",
            "Epoch: 073 | Accuracy: 76.80% | Cost: 0.4991\n",
            "Epoch: 074 | Accuracy: 77.80% | Cost: 0.4945\n",
            "Epoch: 075 | Accuracy: 78.20% | Cost: 0.4896\n",
            "Epoch: 076 | Accuracy: 79.60% | Cost: 0.4844\n",
            "Epoch: 077 | Accuracy: 80.80% | Cost: 0.4790\n",
            "Epoch: 078 | Accuracy: 82.20% | Cost: 0.4734\n",
            "Epoch: 079 | Accuracy: 82.80% | Cost: 0.4676\n",
            "Epoch: 080 | Accuracy: 83.80% | Cost: 0.4615\n",
            "Epoch: 081 | Accuracy: 84.80% | Cost: 0.4552\n",
            "Epoch: 082 | Accuracy: 86.00% | Cost: 0.4485\n",
            "Epoch: 083 | Accuracy: 86.80% | Cost: 0.4416\n",
            "Epoch: 084 | Accuracy: 87.80% | Cost: 0.4345\n",
            "Epoch: 085 | Accuracy: 88.60% | Cost: 0.4272\n",
            "Epoch: 086 | Accuracy: 89.00% | Cost: 0.4198\n",
            "Epoch: 087 | Accuracy: 89.00% | Cost: 0.4122\n",
            "Epoch: 088 | Accuracy: 90.00% | Cost: 0.4045\n",
            "Epoch: 089 | Accuracy: 90.80% | Cost: 0.3968\n",
            "Epoch: 090 | Accuracy: 91.60% | Cost: 0.3891\n",
            "Epoch: 091 | Accuracy: 91.40% | Cost: 0.3814\n",
            "Epoch: 092 | Accuracy: 91.40% | Cost: 0.3737\n",
            "Epoch: 093 | Accuracy: 92.00% | Cost: 0.3659\n",
            "Epoch: 094 | Accuracy: 92.80% | Cost: 0.3580\n",
            "Epoch: 095 | Accuracy: 92.60% | Cost: 0.3501\n",
            "Epoch: 096 | Accuracy: 93.40% | Cost: 0.3424\n",
            "Epoch: 097 | Accuracy: 93.20% | Cost: 0.3347\n",
            "Epoch: 098 | Accuracy: 93.60% | Cost: 0.3272\n",
            "Epoch: 099 | Accuracy: 93.40% | Cost: 0.3199\n",
            "Epoch: 100 | Accuracy: 93.40% | Cost: 0.3126\n",
            "Epoch: 101 | Accuracy: 93.80% | Cost: 0.3055\n",
            "Epoch: 102 | Accuracy: 94.00% | Cost: 0.2985\n",
            "Epoch: 103 | Accuracy: 94.20% | Cost: 0.2918\n",
            "Epoch: 104 | Accuracy: 94.80% | Cost: 0.2852\n",
            "Epoch: 105 | Accuracy: 94.80% | Cost: 0.2788\n",
            "Epoch: 106 | Accuracy: 95.60% | Cost: 0.2726\n",
            "Epoch: 107 | Accuracy: 95.60% | Cost: 0.2665\n",
            "Epoch: 108 | Accuracy: 95.60% | Cost: 0.2606\n",
            "Epoch: 109 | Accuracy: 95.60% | Cost: 0.2549\n",
            "Epoch: 110 | Accuracy: 95.80% | Cost: 0.2493\n",
            "Epoch: 111 | Accuracy: 96.20% | Cost: 0.2440\n",
            "Epoch: 112 | Accuracy: 96.80% | Cost: 0.2389\n",
            "Epoch: 113 | Accuracy: 97.00% | Cost: 0.2341\n",
            "Epoch: 114 | Accuracy: 96.80% | Cost: 0.2294\n",
            "Epoch: 115 | Accuracy: 97.20% | Cost: 0.2250\n",
            "Epoch: 116 | Accuracy: 97.20% | Cost: 0.2207\n",
            "Epoch: 117 | Accuracy: 97.20% | Cost: 0.2167\n",
            "Epoch: 118 | Accuracy: 97.40% | Cost: 0.2128\n",
            "Epoch: 119 | Accuracy: 97.20% | Cost: 0.2090\n",
            "Epoch: 120 | Accuracy: 97.40% | Cost: 0.2054\n",
            "Epoch: 121 | Accuracy: 97.40% | Cost: 0.2020\n",
            "Epoch: 122 | Accuracy: 97.40% | Cost: 0.1987\n",
            "Epoch: 123 | Accuracy: 97.40% | Cost: 0.1955\n",
            "Epoch: 124 | Accuracy: 97.40% | Cost: 0.1924\n",
            "Epoch: 125 | Accuracy: 97.40% | Cost: 0.1894\n",
            "Epoch: 126 | Accuracy: 97.40% | Cost: 0.1866\n",
            "Epoch: 127 | Accuracy: 97.40% | Cost: 0.1839\n",
            "Epoch: 128 | Accuracy: 97.40% | Cost: 0.1812\n",
            "Epoch: 129 | Accuracy: 97.40% | Cost: 0.1787\n",
            "Epoch: 130 | Accuracy: 97.40% | Cost: 0.1763\n",
            "Epoch: 131 | Accuracy: 97.20% | Cost: 0.1739\n",
            "Epoch: 132 | Accuracy: 97.20% | Cost: 0.1716\n",
            "Epoch: 133 | Accuracy: 97.20% | Cost: 0.1694\n",
            "Epoch: 134 | Accuracy: 97.40% | Cost: 0.1673\n",
            "Epoch: 135 | Accuracy: 97.40% | Cost: 0.1652\n",
            "Epoch: 136 | Accuracy: 97.40% | Cost: 0.1632\n",
            "Epoch: 137 | Accuracy: 97.40% | Cost: 0.1612\n",
            "Epoch: 138 | Accuracy: 97.40% | Cost: 0.1593\n",
            "Epoch: 139 | Accuracy: 97.40% | Cost: 0.1574\n",
            "Epoch: 140 | Accuracy: 97.40% | Cost: 0.1556\n",
            "Epoch: 141 | Accuracy: 97.40% | Cost: 0.1539\n",
            "Epoch: 142 | Accuracy: 97.80% | Cost: 0.1521\n",
            "Epoch: 143 | Accuracy: 97.80% | Cost: 0.1505\n",
            "Epoch: 144 | Accuracy: 97.80% | Cost: 0.1489\n",
            "Epoch: 145 | Accuracy: 97.80% | Cost: 0.1473\n",
            "Epoch: 146 | Accuracy: 97.80% | Cost: 0.1457\n",
            "Epoch: 147 | Accuracy: 97.80% | Cost: 0.1442\n",
            "Epoch: 148 | Accuracy: 97.80% | Cost: 0.1427\n",
            "Epoch: 149 | Accuracy: 97.80% | Cost: 0.1413\n",
            "Epoch: 150 | Accuracy: 97.80% | Cost: 0.1399\n",
            "Epoch: 151 | Accuracy: 97.80% | Cost: 0.1385\n",
            "Epoch: 152 | Accuracy: 97.80% | Cost: 0.1371\n",
            "Epoch: 153 | Accuracy: 97.80% | Cost: 0.1358\n",
            "Epoch: 154 | Accuracy: 97.80% | Cost: 0.1345\n",
            "Epoch: 155 | Accuracy: 97.80% | Cost: 0.1332\n",
            "Epoch: 156 | Accuracy: 97.80% | Cost: 0.1320\n",
            "Epoch: 157 | Accuracy: 97.80% | Cost: 0.1308\n",
            "Epoch: 158 | Accuracy: 98.00% | Cost: 0.1296\n",
            "Epoch: 159 | Accuracy: 98.00% | Cost: 0.1284\n",
            "Epoch: 160 | Accuracy: 98.20% | Cost: 0.1272\n",
            "Epoch: 161 | Accuracy: 98.20% | Cost: 0.1261\n",
            "Epoch: 162 | Accuracy: 98.20% | Cost: 0.1250\n",
            "Epoch: 163 | Accuracy: 98.20% | Cost: 0.1239\n",
            "Epoch: 164 | Accuracy: 98.20% | Cost: 0.1228\n",
            "Epoch: 165 | Accuracy: 98.20% | Cost: 0.1218\n",
            "Epoch: 166 | Accuracy: 98.20% | Cost: 0.1207\n",
            "Epoch: 167 | Accuracy: 98.20% | Cost: 0.1197\n",
            "Epoch: 168 | Accuracy: 98.20% | Cost: 0.1187\n",
            "Epoch: 169 | Accuracy: 98.20% | Cost: 0.1177\n",
            "Epoch: 170 | Accuracy: 98.20% | Cost: 0.1167\n",
            "Epoch: 171 | Accuracy: 98.20% | Cost: 0.1158\n",
            "Epoch: 172 | Accuracy: 98.40% | Cost: 0.1148\n",
            "Epoch: 173 | Accuracy: 98.40% | Cost: 0.1139\n",
            "Epoch: 174 | Accuracy: 98.40% | Cost: 0.1130\n",
            "Epoch: 175 | Accuracy: 98.40% | Cost: 0.1121\n",
            "Epoch: 176 | Accuracy: 98.40% | Cost: 0.1112\n",
            "Epoch: 177 | Accuracy: 98.40% | Cost: 0.1103\n",
            "Epoch: 178 | Accuracy: 98.40% | Cost: 0.1094\n",
            "Epoch: 179 | Accuracy: 98.60% | Cost: 0.1086\n",
            "Epoch: 180 | Accuracy: 98.60% | Cost: 0.1078\n",
            "Epoch: 181 | Accuracy: 98.60% | Cost: 0.1069\n",
            "Epoch: 182 | Accuracy: 98.60% | Cost: 0.1061\n",
            "Epoch: 183 | Accuracy: 98.80% | Cost: 0.1053\n",
            "Epoch: 184 | Accuracy: 98.80% | Cost: 0.1045\n",
            "Epoch: 185 | Accuracy: 98.80% | Cost: 0.1038\n",
            "Epoch: 186 | Accuracy: 98.80% | Cost: 0.1030\n",
            "Epoch: 187 | Accuracy: 98.80% | Cost: 0.1022\n",
            "Epoch: 188 | Accuracy: 98.80% | Cost: 0.1015\n",
            "Epoch: 189 | Accuracy: 98.80% | Cost: 0.1008\n",
            "Epoch: 190 | Accuracy: 98.80% | Cost: 0.1001\n",
            "Epoch: 191 | Accuracy: 98.80% | Cost: 0.0994\n",
            "Epoch: 192 | Accuracy: 98.80% | Cost: 0.0987\n",
            "Epoch: 193 | Accuracy: 98.80% | Cost: 0.0980\n",
            "Epoch: 194 | Accuracy: 98.80% | Cost: 0.0973\n",
            "Epoch: 195 | Accuracy: 98.80% | Cost: 0.0966\n",
            "Epoch: 196 | Accuracy: 98.80% | Cost: 0.0960\n",
            "Epoch: 197 | Accuracy: 98.80% | Cost: 0.0953\n",
            "Epoch: 198 | Accuracy: 98.80% | Cost: 0.0947\n",
            "Epoch: 199 | Accuracy: 98.80% | Cost: 0.0941\n",
            "Epoch: 200 | Accuracy: 98.80% | Cost: 0.0934\n",
            "Epoch: 201 | Accuracy: 98.80% | Cost: 0.0928\n",
            "Epoch: 202 | Accuracy: 99.00% | Cost: 0.0922\n",
            "Epoch: 203 | Accuracy: 99.00% | Cost: 0.0916\n",
            "Epoch: 204 | Accuracy: 99.00% | Cost: 0.0911\n",
            "Epoch: 205 | Accuracy: 99.00% | Cost: 0.0905\n",
            "Epoch: 206 | Accuracy: 99.00% | Cost: 0.0899\n",
            "Epoch: 207 | Accuracy: 99.00% | Cost: 0.0893\n",
            "Epoch: 208 | Accuracy: 99.00% | Cost: 0.0888\n",
            "Epoch: 209 | Accuracy: 99.20% | Cost: 0.0882\n",
            "Epoch: 210 | Accuracy: 99.20% | Cost: 0.0877\n",
            "Epoch: 211 | Accuracy: 99.20% | Cost: 0.0871\n",
            "Epoch: 212 | Accuracy: 99.20% | Cost: 0.0866\n",
            "Epoch: 213 | Accuracy: 99.20% | Cost: 0.0861\n",
            "Epoch: 214 | Accuracy: 99.20% | Cost: 0.0856\n",
            "Epoch: 215 | Accuracy: 99.20% | Cost: 0.0851\n",
            "Epoch: 216 | Accuracy: 99.20% | Cost: 0.0846\n",
            "Epoch: 217 | Accuracy: 99.20% | Cost: 0.0841\n",
            "Epoch: 218 | Accuracy: 99.20% | Cost: 0.0836\n",
            "Epoch: 219 | Accuracy: 99.20% | Cost: 0.0831\n",
            "Epoch: 220 | Accuracy: 99.20% | Cost: 0.0826\n",
            "Epoch: 221 | Accuracy: 99.20% | Cost: 0.0821\n",
            "Epoch: 222 | Accuracy: 99.20% | Cost: 0.0816\n",
            "Epoch: 223 | Accuracy: 99.20% | Cost: 0.0812\n",
            "Epoch: 224 | Accuracy: 99.20% | Cost: 0.0807\n",
            "Epoch: 225 | Accuracy: 99.20% | Cost: 0.0802\n",
            "Epoch: 226 | Accuracy: 99.20% | Cost: 0.0798\n",
            "Epoch: 227 | Accuracy: 99.20% | Cost: 0.0793\n",
            "Epoch: 228 | Accuracy: 99.20% | Cost: 0.0789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pRF-XzwffD-J",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoSuX_AQv3vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d35affbb-df5c-48db-ca36-4ea9158dd1d2"
      },
      "source": [
        "### training of multiple models and save the result in JSON file\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "start_time = time.time()\n",
        "radius_of_sphere = 1\n",
        "radius_of_shell = 2.4\n",
        "thickness_of_shell = 1\n",
        "\n",
        "dimentions = [2,3,4,5,6]          #list of dimention of data\n",
        "for dim in dimentions:\n",
        "  csv_path = '/content/drive/My Drive/DL_exp/data/train_sp'+ str(radius_of_sphere) + '_sh'+ str(radius_of_shell) + '_t' + str(thickness_of_shell)+ '_' + str(dim) + 'dim.csv'\n",
        "  dataset = load_dataset(csv_path)\n",
        "  size = len(dataset)\n",
        "  train_dataloader = DataLoader(dataset, batch_size=size, shuffle=True)\n",
        "\n",
        "\n",
        "  tmp_h = [dim,dim+1,dim+3,dim+5,dim+7,dim+9]             #list of number of nodes in hidden layer\n",
        "  tmp_i = [100,200,300,400,500,600,700,800,900,1000]      #list of random seed for weight initialization\n",
        "\n",
        "  for t_h in tmp_h:\n",
        "    for t_i in tmp_i:\n",
        "\n",
        "      #architecture\n",
        "      num_features  = next(iter(dataset))[0].shape[0]        # Input data dimention\n",
        "      hidden_nodes_list   = [t_h]                              # List of number of nodes at each hidden layer\n",
        "      num_hidden_layes = len(hidden_nodes_list)              # The number of hidden layers\n",
        "      num_classes   = 2                                      # The number of output classes. In this case, 0 and 1\n",
        "\n",
        "      initialisation_method = 'xavier'\n",
        "      optimisation_method = 'sgdwm'  \n",
        "\n",
        "      # Hyperparameters\n",
        "      random_seed = t_i\n",
        "      learning_rate = 0.05\n",
        "            \n",
        "      torch.manual_seed(random_seed)\n",
        "      model = MultilayerPerceptron()\n",
        "      model.apply(init_weights)\n",
        "      model = model.to(device)\n",
        "\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "      \n",
        "      epoch = 0\n",
        "\n",
        "      with torch.set_grad_enabled(False):\n",
        "        cost,best_acc = compute_accuracy(model, train_dataloader)\n",
        "\n",
        "      # for epoch in range(num_epochs):\n",
        "      count = 1\n",
        "      prev_acc=best_acc\n",
        "      best_epoch = epoch\n",
        "      best_cost = cost\n",
        "\n",
        "      while True:\n",
        "          model.train()\n",
        "          for batch_idx, (features, targets) in enumerate(train_dataloader):\n",
        "\n",
        "              features = features.float().to(device)\n",
        "              targets = targets.long().to(device)\n",
        "\n",
        "              ### FORWARD AND BACK PROP\n",
        "              logits, probas = model(features)\n",
        "              cost = F.cross_entropy(logits, targets)\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              cost.backward()\n",
        "\n",
        "              ### UPDATE MODEL PARAMETERS\n",
        "              optimizer.step()\n",
        "\n",
        "\n",
        "          with torch.set_grad_enabled(False):\n",
        "              cost,acc = compute_accuracy(model, train_dataloader)\n",
        "              \n",
        "          epoch+=1\n",
        "          if prev_acc==acc:\n",
        "            count+=1\n",
        "          else:\n",
        "            prev_acc=acc\n",
        "            count=1\n",
        "          if (epoch>50 and best_acc-acc>=5) or count==20 or epoch==400:\n",
        "            break\n",
        "          if acc>best_acc:\n",
        "            best_acc=acc\n",
        "            best_epoch = epoch\n",
        "            best_cost = cost\n",
        " \n",
        "      print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (epoch,best_acc,cost))\n",
        "  \n",
        "      with open('/content/drive/My Drive/DL_exp/result/result.json', mode='r') as readjson:\n",
        "        try: \n",
        "          result = json.loads(readjson.read())\n",
        "        except ValueError: \n",
        "          result = []  \n",
        "      \n",
        "        \n",
        "      with open('/content/drive/My Drive/DL_exp/result/result.json', mode='w') as feedjson:\n",
        "        entry = {'sphere_radius': '1', 'shell_radius': '2.4', 'thickness' : '1', 'dimension':str(dim), 'n_nodes':str(t_h), 'random_seed':str(t_i), 'epoch':str(best_epoch), 'accuracy':str(best_acc.cpu().numpy()), 'cost':str(best_cost.cpu().numpy())}\n",
        "        result.append(entry)\n",
        "        json.dump(result, feedjson)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 154 | Accuracy: 89.40% | Cost: 0.2570\n",
            "Epoch: 150 | Accuracy: 89.40% | Cost: 0.2797\n",
            "Epoch: 051 | Accuracy: 68.60% | Cost: 0.6064\n",
            "Epoch: 141 | Accuracy: 69.00% | Cost: 0.5514\n",
            "Epoch: 197 | Accuracy: 85.20% | Cost: 0.3508\n",
            "Epoch: 178 | Accuracy: 87.80% | Cost: 0.2916\n",
            "Epoch: 209 | Accuracy: 85.60% | Cost: 0.3470\n",
            "Epoch: 187 | Accuracy: 87.80% | Cost: 0.3184\n",
            "Epoch: 138 | Accuracy: 71.20% | Cost: 0.5306\n",
            "Epoch: 215 | Accuracy: 89.80% | Cost: 0.2563\n",
            "Epoch: 073 | Accuracy: 100.00% | Cost: 0.0698\n",
            "Epoch: 112 | Accuracy: 100.00% | Cost: 0.0614\n",
            "Epoch: 150 | Accuracy: 100.00% | Cost: 0.0581\n",
            "Epoch: 073 | Accuracy: 100.00% | Cost: 0.0796\n",
            "Epoch: 124 | Accuracy: 100.00% | Cost: 0.0664\n",
            "Epoch: 102 | Accuracy: 100.00% | Cost: 0.0577\n",
            "Epoch: 091 | Accuracy: 100.00% | Cost: 0.0656\n",
            "Epoch: 069 | Accuracy: 100.00% | Cost: 0.0673\n",
            "Epoch: 072 | Accuracy: 100.00% | Cost: 0.0629\n",
            "Epoch: 136 | Accuracy: 100.00% | Cost: 0.0517\n",
            "Epoch: 071 | Accuracy: 100.00% | Cost: 0.0717\n",
            "Epoch: 084 | Accuracy: 100.00% | Cost: 0.0494\n",
            "Epoch: 087 | Accuracy: 100.00% | Cost: 0.0554\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.0846\n",
            "Epoch: 113 | Accuracy: 100.00% | Cost: 0.0531\n",
            "Epoch: 063 | Accuracy: 100.00% | Cost: 0.0732\n",
            "Epoch: 045 | Accuracy: 100.00% | Cost: 0.0907\n",
            "Epoch: 055 | Accuracy: 100.00% | Cost: 0.0763\n",
            "Epoch: 086 | Accuracy: 100.00% | Cost: 0.0569\n",
            "Epoch: 069 | Accuracy: 100.00% | Cost: 0.0777\n",
            "Epoch: 051 | Accuracy: 100.00% | Cost: 0.1014\n",
            "Epoch: 051 | Accuracy: 100.00% | Cost: 0.0612\n",
            "Epoch: 041 | Accuracy: 100.00% | Cost: 0.0906\n",
            "Epoch: 063 | Accuracy: 100.00% | Cost: 0.0436\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.0801\n",
            "Epoch: 085 | Accuracy: 100.00% | Cost: 0.0326\n",
            "Epoch: 052 | Accuracy: 100.00% | Cost: 0.0553\n",
            "Epoch: 095 | Accuracy: 100.00% | Cost: 0.0389\n",
            "Epoch: 065 | Accuracy: 100.00% | Cost: 0.0647\n",
            "Epoch: 062 | Accuracy: 100.00% | Cost: 0.0697\n",
            "Epoch: 075 | Accuracy: 100.00% | Cost: 0.0328\n",
            "Epoch: 042 | Accuracy: 100.00% | Cost: 0.0825\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.0591\n",
            "Epoch: 049 | Accuracy: 100.00% | Cost: 0.0670\n",
            "Epoch: 058 | Accuracy: 100.00% | Cost: 0.0597\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.0980\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.0537\n",
            "Epoch: 049 | Accuracy: 100.00% | Cost: 0.0879\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.0809\n",
            "Epoch: 045 | Accuracy: 100.00% | Cost: 0.0967\n",
            "Epoch: 053 | Accuracy: 100.00% | Cost: 0.0566\n",
            "Epoch: 050 | Accuracy: 100.00% | Cost: 0.0713\n",
            "Epoch: 044 | Accuracy: 100.00% | Cost: 0.0805\n",
            "Epoch: 045 | Accuracy: 100.00% | Cost: 0.0622\n",
            "Epoch: 039 | Accuracy: 100.00% | Cost: 0.0948\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.0972\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.0837\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.0922\n",
            "Epoch: 054 | Accuracy: 100.00% | Cost: 0.0470\n",
            "Epoch: 033 | Accuracy: 100.00% | Cost: 0.1207\n",
            "Epoch: 177 | Accuracy: 98.00% | Cost: 0.0843\n",
            "Epoch: 257 | Accuracy: 98.00% | Cost: 0.0812\n",
            "Epoch: 173 | Accuracy: 97.00% | Cost: 0.1150\n",
            "Epoch: 221 | Accuracy: 96.00% | Cost: 0.1410\n",
            "Epoch: 169 | Accuracy: 98.40% | Cost: 0.0876\n",
            "Epoch: 118 | Accuracy: 94.60% | Cost: 0.1557\n",
            "Epoch: 267 | Accuracy: 89.40% | Cost: 0.2689\n",
            "Epoch: 085 | Accuracy: 97.80% | Cost: 0.1083\n",
            "Epoch: 197 | Accuracy: 96.40% | Cost: 0.1247\n",
            "Epoch: 222 | Accuracy: 87.80% | Cost: 0.2966\n",
            "Epoch: 131 | Accuracy: 98.00% | Cost: 0.0555\n",
            "Epoch: 090 | Accuracy: 99.80% | Cost: 0.0636\n",
            "Epoch: 155 | Accuracy: 98.60% | Cost: 0.0726\n",
            "Epoch: 087 | Accuracy: 100.00% | Cost: 0.0615\n",
            "Epoch: 257 | Accuracy: 97.80% | Cost: 0.0769\n",
            "Epoch: 069 | Accuracy: 100.00% | Cost: 0.0731\n",
            "Epoch: 088 | Accuracy: 100.00% | Cost: 0.0587\n",
            "Epoch: 122 | Accuracy: 95.20% | Cost: 0.1315\n",
            "Epoch: 103 | Accuracy: 100.00% | Cost: 0.0625\n",
            "Epoch: 111 | Accuracy: 100.00% | Cost: 0.0620\n",
            "Epoch: 119 | Accuracy: 100.00% | Cost: 0.0501\n",
            "Epoch: 140 | Accuracy: 99.80% | Cost: 0.0482\n",
            "Epoch: 088 | Accuracy: 100.00% | Cost: 0.0319\n",
            "Epoch: 044 | Accuracy: 100.00% | Cost: 0.1184\n",
            "Epoch: 062 | Accuracy: 100.00% | Cost: 0.0738\n",
            "Epoch: 132 | Accuracy: 98.00% | Cost: 0.0934\n",
            "Epoch: 058 | Accuracy: 100.00% | Cost: 0.0760\n",
            "Epoch: 073 | Accuracy: 100.00% | Cost: 0.0655\n",
            "Epoch: 085 | Accuracy: 100.00% | Cost: 0.0559\n",
            "Epoch: 061 | Accuracy: 100.00% | Cost: 0.0602\n",
            "Epoch: 129 | Accuracy: 100.00% | Cost: 0.0285\n",
            "Epoch: 080 | Accuracy: 99.80% | Cost: 0.0446\n",
            "Epoch: 089 | Accuracy: 100.00% | Cost: 0.0339\n",
            "Epoch: 089 | Accuracy: 99.80% | Cost: 0.0478\n",
            "Epoch: 060 | Accuracy: 99.80% | Cost: 0.0783\n",
            "Epoch: 071 | Accuracy: 100.00% | Cost: 0.0685\n",
            "Epoch: 078 | Accuracy: 100.00% | Cost: 0.0571\n",
            "Epoch: 072 | Accuracy: 100.00% | Cost: 0.0545\n",
            "Epoch: 065 | Accuracy: 100.00% | Cost: 0.0794\n",
            "Epoch: 058 | Accuracy: 100.00% | Cost: 0.0751\n",
            "Epoch: 058 | Accuracy: 100.00% | Cost: 0.0903\n",
            "Epoch: 078 | Accuracy: 100.00% | Cost: 0.0510\n",
            "Epoch: 091 | Accuracy: 100.00% | Cost: 0.0384\n",
            "Epoch: 090 | Accuracy: 99.80% | Cost: 0.0529\n",
            "Epoch: 083 | Accuracy: 100.00% | Cost: 0.0382\n",
            "Epoch: 093 | Accuracy: 100.00% | Cost: 0.0507\n",
            "Epoch: 079 | Accuracy: 100.00% | Cost: 0.0725\n",
            "Epoch: 048 | Accuracy: 99.80% | Cost: 0.0886\n",
            "Epoch: 049 | Accuracy: 100.00% | Cost: 0.0959\n",
            "Epoch: 073 | Accuracy: 100.00% | Cost: 0.0511\n",
            "Epoch: 045 | Accuracy: 99.80% | Cost: 0.1030\n",
            "Epoch: 071 | Accuracy: 100.00% | Cost: 0.0488\n",
            "Epoch: 049 | Accuracy: 100.00% | Cost: 0.0785\n",
            "Epoch: 055 | Accuracy: 100.00% | Cost: 0.0770\n",
            "Epoch: 089 | Accuracy: 100.00% | Cost: 0.0476\n",
            "Epoch: 046 | Accuracy: 100.00% | Cost: 0.1072\n",
            "Epoch: 085 | Accuracy: 100.00% | Cost: 0.0448\n",
            "Epoch: 053 | Accuracy: 100.00% | Cost: 0.0878\n",
            "Epoch: 086 | Accuracy: 100.00% | Cost: 0.0506\n",
            "Epoch: 043 | Accuracy: 100.00% | Cost: 0.1072\n",
            "Epoch: 162 | Accuracy: 97.20% | Cost: 0.1138\n",
            "Epoch: 143 | Accuracy: 99.40% | Cost: 0.0628\n",
            "Epoch: 148 | Accuracy: 98.20% | Cost: 0.0754\n",
            "Epoch: 150 | Accuracy: 98.60% | Cost: 0.0762\n",
            "Epoch: 176 | Accuracy: 99.20% | Cost: 0.0664\n",
            "Epoch: 185 | Accuracy: 97.20% | Cost: 0.0819\n",
            "Epoch: 181 | Accuracy: 98.00% | Cost: 0.0900\n",
            "Epoch: 094 | Accuracy: 98.80% | Cost: 0.0902\n",
            "Epoch: 196 | Accuracy: 99.20% | Cost: 0.0471\n",
            "Epoch: 132 | Accuracy: 98.60% | Cost: 0.0741\n",
            "Epoch: 098 | Accuracy: 99.00% | Cost: 0.0942\n",
            "Epoch: 124 | Accuracy: 97.60% | Cost: 0.1101\n",
            "Epoch: 122 | Accuracy: 98.80% | Cost: 0.0670\n",
            "Epoch: 152 | Accuracy: 99.60% | Cost: 0.0487\n",
            "Epoch: 122 | Accuracy: 98.80% | Cost: 0.0660\n",
            "Epoch: 216 | Accuracy: 97.80% | Cost: 0.0733\n",
            "Epoch: 095 | Accuracy: 99.40% | Cost: 0.0642\n",
            "Epoch: 134 | Accuracy: 99.60% | Cost: 0.0457\n",
            "Epoch: 190 | Accuracy: 99.60% | Cost: 0.0405\n",
            "Epoch: 121 | Accuracy: 100.00% | Cost: 0.0469\n",
            "Epoch: 143 | Accuracy: 99.60% | Cost: 0.0339\n",
            "Epoch: 079 | Accuracy: 99.00% | Cost: 0.0827\n",
            "Epoch: 092 | Accuracy: 99.80% | Cost: 0.0638\n",
            "Epoch: 080 | Accuracy: 99.80% | Cost: 0.0653\n",
            "Epoch: 122 | Accuracy: 99.40% | Cost: 0.0501\n",
            "Epoch: 083 | Accuracy: 99.00% | Cost: 0.0627\n",
            "Epoch: 089 | Accuracy: 100.00% | Cost: 0.0619\n",
            "Epoch: 107 | Accuracy: 99.60% | Cost: 0.0589\n",
            "Epoch: 090 | Accuracy: 99.80% | Cost: 0.0496\n",
            "Epoch: 084 | Accuracy: 98.40% | Cost: 0.0615\n",
            "Epoch: 087 | Accuracy: 99.40% | Cost: 0.0528\n",
            "Epoch: 106 | Accuracy: 99.80% | Cost: 0.0491\n",
            "Epoch: 095 | Accuracy: 99.80% | Cost: 0.0648\n",
            "Epoch: 075 | Accuracy: 99.40% | Cost: 0.0557\n",
            "Epoch: 080 | Accuracy: 100.00% | Cost: 0.0558\n",
            "Epoch: 062 | Accuracy: 99.40% | Cost: 0.0683\n",
            "Epoch: 075 | Accuracy: 98.80% | Cost: 0.0747\n",
            "Epoch: 058 | Accuracy: 99.00% | Cost: 0.1008\n",
            "Epoch: 138 | Accuracy: 99.80% | Cost: 0.0328\n",
            "Epoch: 131 | Accuracy: 99.60% | Cost: 0.0519\n",
            "Epoch: 085 | Accuracy: 99.80% | Cost: 0.0663\n",
            "Epoch: 123 | Accuracy: 99.80% | Cost: 0.0392\n",
            "Epoch: 077 | Accuracy: 99.20% | Cost: 0.0678\n",
            "Epoch: 112 | Accuracy: 100.00% | Cost: 0.0324\n",
            "Epoch: 094 | Accuracy: 100.00% | Cost: 0.0469\n",
            "Epoch: 069 | Accuracy: 99.80% | Cost: 0.0626\n",
            "Epoch: 077 | Accuracy: 99.80% | Cost: 0.0633\n",
            "Epoch: 146 | Accuracy: 99.80% | Cost: 0.0298\n",
            "Epoch: 054 | Accuracy: 99.60% | Cost: 0.0884\n",
            "Epoch: 089 | Accuracy: 99.40% | Cost: 0.0580\n",
            "Epoch: 114 | Accuracy: 100.00% | Cost: 0.0409\n",
            "Epoch: 075 | Accuracy: 99.80% | Cost: 0.0517\n",
            "Epoch: 061 | Accuracy: 100.00% | Cost: 0.0591\n",
            "Epoch: 076 | Accuracy: 99.80% | Cost: 0.0455\n",
            "Epoch: 071 | Accuracy: 99.60% | Cost: 0.0575\n",
            "Epoch: 061 | Accuracy: 99.40% | Cost: 0.0764\n",
            "Epoch: 098 | Accuracy: 100.00% | Cost: 0.0437\n",
            "Epoch: 088 | Accuracy: 99.80% | Cost: 0.0503\n",
            "Epoch: 068 | Accuracy: 99.60% | Cost: 0.0642\n",
            "Epoch: 059 | Accuracy: 100.00% | Cost: 0.0838\n",
            "Epoch: 151 | Accuracy: 99.60% | Cost: 0.0425\n",
            "Epoch: 091 | Accuracy: 100.00% | Cost: 0.0586\n",
            "Epoch: 091 | Accuracy: 99.40% | Cost: 0.0846\n",
            "Epoch: 170 | Accuracy: 99.40% | Cost: 0.0502\n",
            "Epoch: 133 | Accuracy: 99.20% | Cost: 0.0609\n",
            "Epoch: 122 | Accuracy: 99.80% | Cost: 0.0520\n",
            "Epoch: 149 | Accuracy: 99.60% | Cost: 0.0459\n",
            "Epoch: 096 | Accuracy: 99.20% | Cost: 0.0790\n",
            "Epoch: 088 | Accuracy: 100.00% | Cost: 0.0647\n",
            "Epoch: 090 | Accuracy: 99.20% | Cost: 0.0805\n",
            "Epoch: 223 | Accuracy: 99.20% | Cost: 0.0366\n",
            "Epoch: 118 | Accuracy: 100.00% | Cost: 0.0444\n",
            "Epoch: 168 | Accuracy: 99.80% | Cost: 0.0396\n",
            "Epoch: 133 | Accuracy: 99.80% | Cost: 0.0434\n",
            "Epoch: 083 | Accuracy: 98.80% | Cost: 0.0742\n",
            "Epoch: 147 | Accuracy: 99.40% | Cost: 0.0470\n",
            "Epoch: 114 | Accuracy: 99.40% | Cost: 0.0603\n",
            "Epoch: 112 | Accuracy: 99.40% | Cost: 0.0580\n",
            "Epoch: 091 | Accuracy: 99.00% | Cost: 0.0727\n",
            "Epoch: 099 | Accuracy: 98.00% | Cost: 0.1105\n",
            "Epoch: 130 | Accuracy: 100.00% | Cost: 0.0411\n",
            "Epoch: 066 | Accuracy: 96.80% | Cost: 0.1250\n",
            "Epoch: 085 | Accuracy: 99.00% | Cost: 0.0585\n",
            "Epoch: 086 | Accuracy: 99.60% | Cost: 0.0618\n",
            "Epoch: 101 | Accuracy: 99.00% | Cost: 0.0696\n",
            "Epoch: 089 | Accuracy: 99.60% | Cost: 0.0454\n",
            "Epoch: 099 | Accuracy: 99.80% | Cost: 0.0441\n",
            "Epoch: 128 | Accuracy: 99.00% | Cost: 0.0536\n",
            "Epoch: 079 | Accuracy: 99.80% | Cost: 0.0464\n",
            "Epoch: 079 | Accuracy: 99.40% | Cost: 0.0620\n",
            "Epoch: 074 | Accuracy: 99.20% | Cost: 0.0630\n",
            "Epoch: 101 | Accuracy: 99.40% | Cost: 0.0516\n",
            "Epoch: 140 | Accuracy: 100.00% | Cost: 0.0407\n",
            "Epoch: 173 | Accuracy: 99.80% | Cost: 0.0363\n",
            "Epoch: 111 | Accuracy: 99.80% | Cost: 0.0439\n",
            "Epoch: 087 | Accuracy: 99.40% | Cost: 0.0690\n",
            "Epoch: 097 | Accuracy: 99.80% | Cost: 0.0540\n",
            "Epoch: 100 | Accuracy: 99.80% | Cost: 0.0565\n",
            "Epoch: 124 | Accuracy: 99.80% | Cost: 0.0377\n",
            "Epoch: 127 | Accuracy: 99.80% | Cost: 0.0364\n",
            "Epoch: 070 | Accuracy: 99.80% | Cost: 0.0648\n",
            "Epoch: 109 | Accuracy: 100.00% | Cost: 0.0363\n",
            "Epoch: 101 | Accuracy: 100.00% | Cost: 0.0304\n",
            "Epoch: 050 | Accuracy: 99.20% | Cost: 0.0807\n",
            "Epoch: 118 | Accuracy: 100.00% | Cost: 0.0300\n",
            "Epoch: 102 | Accuracy: 100.00% | Cost: 0.0526\n",
            "Epoch: 078 | Accuracy: 99.80% | Cost: 0.0423\n",
            "Epoch: 072 | Accuracy: 99.80% | Cost: 0.0576\n",
            "Epoch: 082 | Accuracy: 99.20% | Cost: 0.0494\n",
            "Epoch: 088 | Accuracy: 99.20% | Cost: 0.0689\n",
            "Epoch: 060 | Accuracy: 99.80% | Cost: 0.0822\n",
            "Epoch: 082 | Accuracy: 99.80% | Cost: 0.0479\n",
            "Epoch: 052 | Accuracy: 99.80% | Cost: 0.0989\n",
            "Epoch: 066 | Accuracy: 99.80% | Cost: 0.0565\n",
            "Epoch: 067 | Accuracy: 99.20% | Cost: 0.0757\n",
            "Epoch: 070 | Accuracy: 99.80% | Cost: 0.0811\n",
            "Epoch: 127 | Accuracy: 100.00% | Cost: 0.0301\n",
            "Epoch: 076 | Accuracy: 99.40% | Cost: 0.0577\n",
            "Epoch: 048 | Accuracy: 99.40% | Cost: 0.1008\n",
            "Epoch: 095 | Accuracy: 99.80% | Cost: 0.0389\n",
            "Epoch: 127 | Accuracy: 98.80% | Cost: 0.0593\n",
            "Epoch: 113 | Accuracy: 98.80% | Cost: 0.0762\n",
            "Epoch: 088 | Accuracy: 99.20% | Cost: 0.0644\n",
            "Epoch: 101 | Accuracy: 99.00% | Cost: 0.0729\n",
            "Epoch: 149 | Accuracy: 99.80% | Cost: 0.0504\n",
            "Epoch: 126 | Accuracy: 98.40% | Cost: 0.0736\n",
            "Epoch: 077 | Accuracy: 99.60% | Cost: 0.0772\n",
            "Epoch: 101 | Accuracy: 99.60% | Cost: 0.0679\n",
            "Epoch: 099 | Accuracy: 99.80% | Cost: 0.0562\n",
            "Epoch: 106 | Accuracy: 99.00% | Cost: 0.0807\n",
            "Epoch: 144 | Accuracy: 100.00% | Cost: 0.0450\n",
            "Epoch: 080 | Accuracy: 98.60% | Cost: 0.1178\n",
            "Epoch: 165 | Accuracy: 100.00% | Cost: 0.0269\n",
            "Epoch: 100 | Accuracy: 99.60% | Cost: 0.0478\n",
            "Epoch: 144 | Accuracy: 100.00% | Cost: 0.0459\n",
            "Epoch: 119 | Accuracy: 98.80% | Cost: 0.0640\n",
            "Epoch: 114 | Accuracy: 99.60% | Cost: 0.0502\n",
            "Epoch: 129 | Accuracy: 97.60% | Cost: 0.0834\n",
            "Epoch: 090 | Accuracy: 99.40% | Cost: 0.0521\n",
            "Epoch: 126 | Accuracy: 99.40% | Cost: 0.0473\n",
            "Epoch: 108 | Accuracy: 99.80% | Cost: 0.0626\n",
            "Epoch: 140 | Accuracy: 99.80% | Cost: 0.0504\n",
            "Epoch: 095 | Accuracy: 99.80% | Cost: 0.0614\n",
            "Epoch: 096 | Accuracy: 99.40% | Cost: 0.0507\n",
            "Epoch: 115 | Accuracy: 99.60% | Cost: 0.0440\n",
            "Epoch: 062 | Accuracy: 99.60% | Cost: 0.0774\n",
            "Epoch: 139 | Accuracy: 100.00% | Cost: 0.0293\n",
            "Epoch: 115 | Accuracy: 99.80% | Cost: 0.0425\n",
            "Epoch: 101 | Accuracy: 99.60% | Cost: 0.0462\n",
            "Epoch: 088 | Accuracy: 99.80% | Cost: 0.0574\n",
            "Epoch: 084 | Accuracy: 99.60% | Cost: 0.0533\n",
            "Epoch: 093 | Accuracy: 99.40% | Cost: 0.0682\n",
            "Epoch: 082 | Accuracy: 99.80% | Cost: 0.0508\n",
            "Epoch: 120 | Accuracy: 100.00% | Cost: 0.0448\n",
            "Epoch: 097 | Accuracy: 99.60% | Cost: 0.0554\n",
            "Epoch: 050 | Accuracy: 99.60% | Cost: 0.0966\n",
            "Epoch: 100 | Accuracy: 99.80% | Cost: 0.0410\n",
            "Epoch: 111 | Accuracy: 99.60% | Cost: 0.0503\n",
            "Epoch: 074 | Accuracy: 99.20% | Cost: 0.0676\n",
            "Epoch: 106 | Accuracy: 99.40% | Cost: 0.0622\n",
            "Epoch: 106 | Accuracy: 99.80% | Cost: 0.0437\n",
            "Epoch: 083 | Accuracy: 99.40% | Cost: 0.0588\n",
            "Epoch: 071 | Accuracy: 99.40% | Cost: 0.0686\n",
            "Epoch: 100 | Accuracy: 100.00% | Cost: 0.0402\n",
            "Epoch: 110 | Accuracy: 99.80% | Cost: 0.0369\n",
            "Epoch: 084 | Accuracy: 99.60% | Cost: 0.0477\n",
            "Epoch: 107 | Accuracy: 100.00% | Cost: 0.0358\n",
            "Epoch: 106 | Accuracy: 99.80% | Cost: 0.0517\n",
            "Epoch: 071 | Accuracy: 99.40% | Cost: 0.0818\n",
            "Epoch: 117 | Accuracy: 99.60% | Cost: 0.0388\n",
            "Epoch: 079 | Accuracy: 99.80% | Cost: 0.0547\n",
            "Epoch: 088 | Accuracy: 99.60% | Cost: 0.0622\n",
            "Epoch: 089 | Accuracy: 99.40% | Cost: 0.0475\n",
            "Epoch: 074 | Accuracy: 100.00% | Cost: 0.0603\n",
            "Epoch: 099 | Accuracy: 100.00% | Cost: 0.0418\n",
            "Epoch: 072 | Accuracy: 99.00% | Cost: 0.0886\n",
            "Epoch: 090 | Accuracy: 99.80% | Cost: 0.0506\n",
            "Epoch: 056 | Accuracy: 99.40% | Cost: 0.0820\n",
            "Epoch: 074 | Accuracy: 99.40% | Cost: 0.0620\n",
            "Epoch: 090 | Accuracy: 99.80% | Cost: 0.0484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SOB3ze3JrWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/DL_exp/result/result.json', mode='r') as readjson:\n",
        "  result = json.loads(readjson.read())\n",
        "  len(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2TBSraRK2lH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keys = result[0].keys()\n",
        "with open('/content/drive/My Drive/DL_exp/result/result.csv', 'w') as output_file:\n",
        "    dict_writer = csv.DictWriter(output_file, keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k4GpNO1mgIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}