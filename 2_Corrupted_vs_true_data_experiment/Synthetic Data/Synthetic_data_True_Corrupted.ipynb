{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_class 4958 negative_class 5042\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "y = np.ones(10000,dtype=\"long\")\n",
    "idx = np.random.uniform(size =10000)>0.5\n",
    "y[idx] = 0 \n",
    "\n",
    "print(\"positive_class\",sum(y==1),\"negative_class\",sum(y==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = ~idx #positive class indices\n",
    "idx2 = idx #negative class indices \n",
    "\n",
    "x = np.zeros((10000,50))\n",
    "x[idx1,0] = np.random.randn(sum(idx1)) # standard normal\n",
    "x[idx2,0] = np.random.randn(sum(idx2)) +10 # normal with mean 10 and standard deviation 1\n",
    "\n",
    "x[:,1:] = np.random.uniform(-1,1,size=(10000,49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f59c48e9d10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x[idx1,0],density=True,label = \"+1 class\")  #positive class histogram \n",
    "\n",
    "plt.hist(x[idx2,0],density = True, label = \"-1 class\")  #negative class histogram\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"probability density\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthetic_data(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        super(Synthetic_data,self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.y))\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx,:],self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Synthetic_data(x,y)\n",
    "trainloader = DataLoader(dataset,batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 50]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "inp,targ = iter(trainloader).next()\n",
    "print(inp.shape,targ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1 = nn.Linear(50,128)\n",
    "        self.linear2 = nn.Linear(128,128)\n",
    "        self.linear3 = nn.Linear(128,64)\n",
    "        self.linear4 = nn.Linear(64,2)\n",
    "    def forward(self,x):\n",
    "        x =  F.relu(self.linear1(x))\n",
    "        x =  F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0079,  0.1615],\n",
       "        [ 0.0512,  0.2004],\n",
       "        [-0.0076,  0.1433],\n",
       "        [ 0.0818,  0.2063],\n",
       "        [-0.0154,  0.1697],\n",
       "        [ 0.0796,  0.2273],\n",
       "        [ 0.0102,  0.1499],\n",
       "        [ 0.0083,  0.1671],\n",
       "        [-0.0274,  0.1470],\n",
       "        [-0.0199,  0.1580],\n",
       "        [ 0.0548,  0.1873],\n",
       "        [-0.0408,  0.1555],\n",
       "        [ 0.0790,  0.1997],\n",
       "        [ 0.0557,  0.2099],\n",
       "        [ 0.1098,  0.2270],\n",
       "        [-0.0166,  0.1730],\n",
       "        [ 0.0200,  0.1895],\n",
       "        [ 0.0049,  0.1756],\n",
       "        [-0.0058,  0.1769],\n",
       "        [ 0.0602,  0.2003],\n",
       "        [ 0.1187,  0.2245],\n",
       "        [-0.0130,  0.1685],\n",
       "        [-0.0284,  0.1535],\n",
       "        [-0.0128,  0.1392],\n",
       "        [ 0.0007,  0.1559],\n",
       "        [ 0.0695,  0.1964],\n",
       "        [ 0.1033,  0.2083],\n",
       "        [ 0.0394,  0.1944],\n",
       "        [-0.0167,  0.1469],\n",
       "        [-0.0091,  0.1346],\n",
       "        [-0.0167,  0.1511],\n",
       "        [ 0.0643,  0.1853],\n",
       "        [ 0.0187,  0.1685],\n",
       "        [ 0.0727,  0.2187],\n",
       "        [ 0.0974,  0.2296],\n",
       "        [ 0.0368,  0.1731],\n",
       "        [ 0.0786,  0.2193],\n",
       "        [ 0.0911,  0.1967],\n",
       "        [-0.0043,  0.1390],\n",
       "        [ 0.0654,  0.1905],\n",
       "        [-0.0517,  0.1575],\n",
       "        [ 0.0617,  0.1931],\n",
       "        [-0.0163,  0.1512],\n",
       "        [ 0.0849,  0.2043],\n",
       "        [ 0.0754,  0.2148],\n",
       "        [ 0.0506,  0.1816],\n",
       "        [-0.0084,  0.1642],\n",
       "        [ 0.0860,  0.2148],\n",
       "        [-0.0097,  0.1673],\n",
       "        [ 0.0632,  0.1923],\n",
       "        [ 0.0790,  0.2267],\n",
       "        [ 0.0679,  0.2116],\n",
       "        [ 0.0839,  0.2075],\n",
       "        [ 0.0033,  0.1537],\n",
       "        [-0.0127,  0.1683],\n",
       "        [-0.0039,  0.1507],\n",
       "        [ 0.0561,  0.1719],\n",
       "        [-0.0113,  0.1500],\n",
       "        [-0.0303,  0.1704],\n",
       "        [-0.0312,  0.1484],\n",
       "        [ 0.0479,  0.1989],\n",
       "        [-0.0074,  0.1587],\n",
       "        [ 0.0604,  0.2026],\n",
       "        [-0.0274,  0.1374],\n",
       "        [ 0.0030,  0.1761],\n",
       "        [-0.0077,  0.1628],\n",
       "        [-0.0385,  0.1436],\n",
       "        [ 0.0545,  0.1802],\n",
       "        [ 0.0531,  0.1882],\n",
       "        [ 0.1004,  0.2169],\n",
       "        [-0.0239,  0.1460],\n",
       "        [-0.0155,  0.1528],\n",
       "        [-0.0053,  0.1658],\n",
       "        [ 0.1017,  0.2141],\n",
       "        [ 0.0673,  0.1958],\n",
       "        [ 0.0579,  0.1965],\n",
       "        [ 0.0238,  0.2005],\n",
       "        [ 0.0053,  0.1850],\n",
       "        [ 0.1178,  0.2052],\n",
       "        [-0.0031,  0.1710],\n",
       "        [-0.0251,  0.1532],\n",
       "        [ 0.0008,  0.1579],\n",
       "        [ 0.1002,  0.2008],\n",
       "        [-0.0160,  0.1533],\n",
       "        [ 0.0659,  0.2025],\n",
       "        [-0.0245,  0.1783],\n",
       "        [ 0.0912,  0.1953],\n",
       "        [ 0.0814,  0.2185],\n",
       "        [ 0.0726,  0.1896],\n",
       "        [-0.0116,  0.1437],\n",
       "        [ 0.0858,  0.2136],\n",
       "        [ 0.0665,  0.1938],\n",
       "        [ 0.0971,  0.2113],\n",
       "        [-0.0132,  0.1493],\n",
       "        [ 0.0116,  0.1588],\n",
       "        [ 0.0286,  0.2035],\n",
       "        [-0.0358,  0.1567],\n",
       "        [ 0.0121,  0.1693],\n",
       "        [ 0.0645,  0.1909],\n",
       "        [-0.0036,  0.1833]], dtype=torch.float64, grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net().double()\n",
    "net(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 0.468\n",
      "[1,   100] loss: 0.342\n",
      "[2,    50] loss: 0.259\n",
      "[2,   100] loss: 0.205\n",
      "[3,    50] loss: 0.159\n",
      "[3,   100] loss: 0.127\n",
      "[4,    50] loss: 0.104\n",
      "[4,   100] loss: 0.084\n",
      "[5,    50] loss: 0.070\n",
      "[5,   100] loss: 0.059\n",
      "[6,    50] loss: 0.049\n",
      "[6,   100] loss: 0.043\n",
      "[7,    50] loss: 0.037\n",
      "[7,   100] loss: 0.032\n",
      "[8,    50] loss: 0.028\n",
      "[8,   100] loss: 0.026\n",
      "[9,    50] loss: 0.023\n",
      "[9,   100] loss: 0.020\n",
      "[10,    50] loss: 0.018\n",
      "[10,   100] loss: 0.017\n",
      "[11,    50] loss: 0.015\n",
      "[11,   100] loss: 0.014\n",
      "[12,    50] loss: 0.013\n",
      "[12,   100] loss: 0.012\n",
      "[13,    50] loss: 0.011\n",
      "[13,   100] loss: 0.010\n",
      "[14,    50] loss: 0.009\n",
      "[14,   100] loss: 0.009\n",
      "[15,    50] loss: 0.008\n",
      "[15,   100] loss: 0.008\n",
      "[16,    50] loss: 0.007\n",
      "[16,   100] loss: 0.007\n",
      "[17,    50] loss: 0.006\n",
      "[17,   100] loss: 0.007\n",
      "[18,    50] loss: 0.006\n",
      "[18,   100] loss: 0.006\n",
      "[19,    50] loss: 0.005\n",
      "[19,   100] loss: 0.005\n",
      "[20,    50] loss: 0.005\n",
      "[20,   100] loss: 0.005\n",
      "[21,    50] loss: 0.005\n",
      "[21,   100] loss: 0.004\n",
      "[22,    50] loss: 0.004\n",
      "[22,   100] loss: 0.004\n",
      "[23,    50] loss: 0.004\n",
      "[23,   100] loss: 0.004\n",
      "[24,    50] loss: 0.004\n",
      "[24,   100] loss: 0.004\n",
      "[25,    50] loss: 0.003\n",
      "[25,   100] loss: 0.003\n",
      "[26,    50] loss: 0.003\n",
      "[26,   100] loss: 0.003\n",
      "[27,    50] loss: 0.003\n",
      "[27,   100] loss: 0.003\n",
      "[28,    50] loss: 0.003\n",
      "[28,   100] loss: 0.003\n",
      "[29,    50] loss: 0.003\n",
      "[29,   100] loss: 0.003\n",
      "[30,    50] loss: 0.003\n",
      "[30,   100] loss: 0.002\n",
      "[31,    50] loss: 0.002\n",
      "[31,   100] loss: 0.002\n",
      "[32,    50] loss: 0.002\n",
      "[32,   100] loss: 0.002\n",
      "[33,    50] loss: 0.002\n",
      "[33,   100] loss: 0.002\n",
      "[34,    50] loss: 0.002\n",
      "[34,   100] loss: 0.002\n",
      "[35,    50] loss: 0.002\n",
      "[35,   100] loss: 0.002\n",
      "[36,    50] loss: 0.002\n",
      "[36,   100] loss: 0.002\n",
      "[37,    50] loss: 0.002\n",
      "[37,   100] loss: 0.002\n",
      "[38,    50] loss: 0.002\n",
      "[38,   100] loss: 0.002\n",
      "[39,    50] loss: 0.002\n",
      "[39,   100] loss: 0.002\n",
      "[40,    50] loss: 0.002\n",
      "[40,   100] loss: 0.002\n",
      "[41,    50] loss: 0.002\n",
      "[41,   100] loss: 0.001\n",
      "[42,    50] loss: 0.002\n",
      "[42,   100] loss: 0.001\n",
      "[43,    50] loss: 0.001\n",
      "[43,   100] loss: 0.001\n",
      "[44,    50] loss: 0.001\n",
      "[44,   100] loss: 0.001\n",
      "[45,    50] loss: 0.001\n",
      "[45,   100] loss: 0.001\n",
      "[46,    50] loss: 0.001\n",
      "[46,   100] loss: 0.001\n",
      "[47,    50] loss: 0.001\n",
      "[47,   100] loss: 0.001\n",
      "[48,    50] loss: 0.001\n",
      "[48,   100] loss: 0.001\n",
      "[49,    50] loss: 0.001\n",
      "[49,   100] loss: 0.001\n",
      "[50,    50] loss: 0.001\n",
      "[50,   100] loss: 0.001\n",
      "[51,    50] loss: 0.001\n",
      "[51,   100] loss: 0.001\n",
      "[52,    50] loss: 0.001\n",
      "[52,   100] loss: 0.001\n",
      "[53,    50] loss: 0.001\n",
      "[53,   100] loss: 0.001\n",
      "[54,    50] loss: 0.001\n",
      "[54,   100] loss: 0.001\n",
      "[55,    50] loss: 0.001\n",
      "[55,   100] loss: 0.001\n",
      "[56,    50] loss: 0.001\n",
      "[56,   100] loss: 0.001\n",
      "[57,    50] loss: 0.001\n",
      "[57,   100] loss: 0.001\n",
      "[58,    50] loss: 0.001\n",
      "[58,   100] loss: 0.001\n",
      "[59,    50] loss: 0.001\n",
      "[59,   100] loss: 0.001\n",
      "[60,    50] loss: 0.001\n",
      "[60,   100] loss: 0.001\n",
      "[61,    50] loss: 0.001\n",
      "[61,   100] loss: 0.001\n",
      "[62,    50] loss: 0.001\n",
      "[62,   100] loss: 0.001\n",
      "[63,    50] loss: 0.001\n",
      "[63,   100] loss: 0.001\n",
      "[64,    50] loss: 0.001\n",
      "[64,   100] loss: 0.001\n",
      "[65,    50] loss: 0.001\n",
      "[65,   100] loss: 0.001\n",
      "[66,    50] loss: 0.001\n",
      "[66,   100] loss: 0.001\n",
      "[67,    50] loss: 0.001\n",
      "[67,   100] loss: 0.001\n",
      "[68,    50] loss: 0.001\n",
      "[68,   100] loss: 0.001\n",
      "[69,    50] loss: 0.001\n",
      "[69,   100] loss: 0.001\n",
      "[70,    50] loss: 0.001\n",
      "[70,   100] loss: 0.001\n",
      "[71,    50] loss: 0.001\n",
      "[71,   100] loss: 0.001\n",
      "[72,    50] loss: 0.001\n",
      "[72,   100] loss: 0.001\n",
      "[73,    50] loss: 0.001\n",
      "[73,   100] loss: 0.001\n",
      "[74,    50] loss: 0.001\n",
      "[74,   100] loss: 0.001\n",
      "[75,    50] loss: 0.001\n",
      "[75,   100] loss: 0.001\n",
      "[76,    50] loss: 0.001\n",
      "[76,   100] loss: 0.001\n",
      "[77,    50] loss: 0.001\n",
      "[77,   100] loss: 0.001\n",
      "[78,    50] loss: 0.001\n",
      "[78,   100] loss: 0.001\n",
      "[79,    50] loss: 0.001\n",
      "[79,   100] loss: 0.001\n",
      "[80,    50] loss: 0.001\n",
      "[80,   100] loss: 0.001\n",
      "[81,    50] loss: 0.001\n",
      "[81,   100] loss: 0.001\n",
      "[82,    50] loss: 0.001\n",
      "[82,   100] loss: 0.001\n",
      "[83,    50] loss: 0.001\n",
      "[83,   100] loss: 0.001\n",
      "[84,    50] loss: 0.001\n",
      "[84,   100] loss: 0.001\n",
      "[85,    50] loss: 0.001\n",
      "[85,   100] loss: 0.001\n",
      "[86,    50] loss: 0.001\n",
      "[86,   100] loss: 0.001\n",
      "[87,    50] loss: 0.001\n",
      "[87,   100] loss: 0.001\n",
      "[88,    50] loss: 0.001\n",
      "[88,   100] loss: 0.001\n",
      "[89,    50] loss: 0.001\n",
      "[89,   100] loss: 0.001\n",
      "[90,    50] loss: 0.000\n",
      "[90,   100] loss: 0.001\n",
      "[91,    50] loss: 0.001\n",
      "[91,   100] loss: 0.000\n",
      "[92,    50] loss: 0.001\n",
      "[92,   100] loss: 0.000\n",
      "[93,    50] loss: 0.001\n",
      "[93,   100] loss: 0.000\n",
      "[94,    50] loss: 0.000\n",
      "[94,   100] loss: 0.001\n",
      "[95,    50] loss: 0.000\n",
      "[95,   100] loss: 0.000\n",
      "[96,    50] loss: 0.000\n",
      "[96,   100] loss: 0.000\n",
      "[97,    50] loss: 0.000\n",
      "[97,   100] loss: 0.000\n",
      "[98,    50] loss: 0.000\n",
      "[98,   100] loss: 0.000\n",
      "[99,    50] loss: 0.000\n",
      "[99,   100] loss: 0.000\n",
      "[100,    50] loss: 0.000\n",
      "[100,   100] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    cnt = 0 \n",
    "    for i,data in enumerate(trainloader):\n",
    "        x_input ,targets = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(x_input)\n",
    "        \n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs,targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if cnt % 50 == 49:    # print every 6 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "        cnt=cnt+1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
