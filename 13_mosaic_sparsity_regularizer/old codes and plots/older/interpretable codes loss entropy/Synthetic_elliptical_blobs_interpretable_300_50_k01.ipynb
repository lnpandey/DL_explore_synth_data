{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Synthetic_elliptical_blobs_interpretable_300_50_k01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYu3ISwwGks"
      },
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.stats import entropy"
      ],
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEp-LtqiWAf"
      },
      "source": [
        "mu1 = np.array([3,3,3,3,0])\n",
        "sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu2 = np.array([4,4,4,4,0])\n",
        "sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu3 = np.array([10,5,5,10,0])\n",
        "sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu4 = np.array([-10,-10,-10,-10,0])\n",
        "sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu5 = np.array([-21,4,4,-21,0])\n",
        "sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu6 = np.array([-10,18,18,-10,0])\n",
        "sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu7 = np.array([4,20,4,20,0])\n",
        "sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu8 = np.array([4,-20,-20,4,0])\n",
        "sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu9 = np.array([20,20,20,20,0])\n",
        "sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu10 = np.array([20,-10,-10,20,0])\n",
        "sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)\n"
      ],
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NshDNGjY2T3w"
      },
      "source": [
        "# mu1 = np.array([3,3,0,0,0])\n",
        "# sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu2 = np.array([4,4,0,0,0])\n",
        "# sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu3 = np.array([10,5,0,0,0])\n",
        "# sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu4 = np.array([-10,-10,0,0,0])\n",
        "# sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu5 = np.array([-21,4,0,0,0])\n",
        "# sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu6 = np.array([-10,18,0,0,0])\n",
        "# sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu7 = np.array([4,20,0,0,0])\n",
        "# sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu8 = np.array([4,-20,0,0,0])\n",
        "# sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu9 = np.array([20,20,0,0,0])\n",
        "# sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu10 = np.array([20,-10,0,0,0])\n",
        "# sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "# sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "# sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "# sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "# sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "# sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "# sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "# sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "# sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "# sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "# sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)"
      ],
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YDnxeP-2_1V",
        "outputId": "c25e5267-0efe-4aff-8e79-89d8e37617ec"
      },
      "source": [
        "X = np.concatenate((sample1,sample2,sample3,sample4,sample5,sample6,sample7,sample8,sample9,sample10),axis=0)\n",
        "Y = np.concatenate((np.zeros((500,1)),np.ones((500,1)),2*np.ones((500,1)),3*np.ones((500,1)),4*np.ones((500,1)),\n",
        "                    5*np.ones((500,1)),6*np.ones((500,1)),7*np.ones((500,1)),8*np.ones((500,1)),9*np.ones((500,1))),axis=0).astype(int)\n",
        "print(X.shape,Y.shape)\n",
        "# plt.scatter(sample1[:,0],sample1[:,1],label=\"class_0\")\n",
        "# plt.scatter(sample2[:,0],sample2[:,1],label=\"class_1\")\n",
        "# plt.scatter(sample3[:,0],sample3[:,1],label=\"class_2\")\n",
        "# plt.scatter(sample4[:,0],sample4[:,1],label=\"class_3\")\n",
        "# plt.scatter(sample5[:,0],sample5[:,1],label=\"class_4\")\n",
        "# plt.scatter(sample6[:,0],sample6[:,1],label=\"class_5\")\n",
        "# plt.scatter(sample7[:,0],sample7[:,1],label=\"class_6\")\n",
        "# plt.scatter(sample8[:,0],sample8[:,1],label=\"class_7\")\n",
        "# plt.scatter(sample9[:,0],sample9[:,1],label=\"class_8\")\n",
        "# plt.scatter(sample10[:,0],sample10[:,1],label=\"class_9\")\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 5) (5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YzqPUf3CHa"
      },
      "source": [
        "class SyntheticDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    #self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx] , self.y[idx] #, self.fore_idx[idx]"
      ],
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mi3nL5-4D7_"
      },
      "source": [
        "trainset = SyntheticDataset(X,Y)\n",
        "\n",
        "\n",
        "# testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKzc7IgwqoU2",
        "outputId": "b87e33aa-1a80-4d7f-c2c0-04851a3064b1"
      },
      "source": [
        "classes = ('zero','one','two','three','four','five','six','seven','eight','nine')\n",
        "\n",
        "foreground_classes = {'zero','one','two'}\n",
        "fg_used = '012'\n",
        "fg1, fg2, fg3 = 0,1,2\n",
        "\n",
        "\n",
        "all_classes = {'zero','one','two','three','four','five','six','seven','eight','nine'}\n",
        "background_classes = all_classes - foreground_classes\n",
        "background_classes"
      ],
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eight', 'five', 'four', 'nine', 'seven', 'six', 'three'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT6iKHutquR8"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)"
      ],
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKzXkPSq5KU"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=100\n",
        "\n",
        "for i in range(50):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 474,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChdziOP3rF1G"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])\n",
        "      label = foreground_label[fg_idx] - fg1  # minus fg1 because our fore ground classes are fg1,fg2,fg3 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 475,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASrmPqErIDM"
      },
      "source": [
        "desired_num = 3000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "list_set_labels = [] \n",
        "for i in range(desired_num):\n",
        "  set_idx = set()\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,3500,8)\n",
        "  set_idx = set(background_label[bg_idx].tolist())\n",
        "  fg_idx = np.random.randint(0,1500)\n",
        "  set_idx.add(foreground_label[fg_idx].item())\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)\n",
        "  list_set_labels.append(set_idx)"
      ],
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDFN7dCarmmR"
      },
      "source": [
        "def create_avg_image_from_mosaic_dataset(mosaic_dataset,labels,foreground_index,dataset_number):\n",
        "  \"\"\"\n",
        "  mosaic_dataset : mosaic_dataset contains 9 images 32 x 32 each as 1 data point\n",
        "  labels : mosaic_dataset labels\n",
        "  foreground_index : contains list of indexes where foreground image is present so that using this we can take weighted average\n",
        "  dataset_number : will help us to tell what ratio of foreground image to be taken. for eg: if it is \"j\" then fg_image_ratio = j/9 , bg_image_ratio = (9-j)/8*9\n",
        "  \"\"\"\n",
        "  avg_image_dataset = []\n",
        "  for i in range(len(mosaic_dataset)):\n",
        "    img = torch.zeros([5], dtype=torch.float64)\n",
        "    for j in range(9):\n",
        "      if j == foreground_index[i]:\n",
        "        img = img + mosaic_dataset[i][j]*dataset_number/9\n",
        "      else :\n",
        "        img = img + mosaic_dataset[i][j]*(9-dataset_number)/(8*9)\n",
        "    \n",
        "    avg_image_dataset.append(img)\n",
        "    \n",
        "  return torch.stack(avg_image_dataset) , torch.stack(labels) , foreground_index"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgF90qBIt8yN"
      },
      "source": [
        "def calculate_loss(dataloader,model,criter):\n",
        "  model.eval()\n",
        "  r_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      outputs = model(inputs)\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  return r_loss/i"
      ],
      "execution_count": 478,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGsdvMSzIUK"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 479,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5NPRPmb904"
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzPfrih82Bg"
      },
      "source": [
        "**Focus Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN3Bbs8c0fA"
      },
      "source": [
        "class Focus_deep(nn.Module):\n",
        "    '''\n",
        "       deep focus network averaged at zeroth layer\n",
        "       input : elemental data\n",
        "    '''\n",
        "    def __init__(self,inputs,output,K,d):\n",
        "        super(Focus_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.K = K\n",
        "        self.d  = d\n",
        "        self.linear1 = nn.Linear(self.inputs,300)  #,self.output)\n",
        "        self.linear2 = nn.Linear(300,self.output) \n",
        "    def forward(self,z):\n",
        "        batch = z.shape[0]\n",
        "        x = torch.zeros([batch,self.K],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,self.d], dtype=torch.float64)\n",
        "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        for i in range(self.K):\n",
        "            x[:,i] = self.helper(z[:,i] )[:,0]  # self.d*i:self.d*i+self.d\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(self.K):\n",
        "            x1 = x[:,i]          \n",
        "            y = y+torch.mul(x1[:,None],z[:,i])  # self.d*i:self.d*i+self.d\n",
        "        return y , x \n",
        "    def helper(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x\n"
      ],
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjrL0Zb484KO"
      },
      "source": [
        "**Classification Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W0oKcClFZY"
      },
      "source": [
        "class Classification_deep(nn.Module):\n",
        "    '''\n",
        "       input : elemental data\n",
        "       deep classification module data averaged at zeroth layer\n",
        "    '''\n",
        "    def __init__(self,inputs,output):\n",
        "        super(Classification_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.linear1 = nn.Linear(self.inputs,50)\n",
        "        self.linear2 = nn.Linear(50,self.output)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x    "
      ],
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByKHrKis88lW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAPjSKkrd0ru"
      },
      "source": [
        "where = Focus_deep(5,1,9,5).double()\n",
        "what = Classification_deep(5,3).double()\n",
        "where = where.to(\"cuda\")\n",
        "what = what.to(\"cuda\")"
      ],
      "execution_count": 483,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAfQnNwgFYX"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,where,criter,k):\n",
        "  what.eval()\n",
        "  where.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels, fidx = data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      avg,alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "\n",
        "      ent = np.sum(entropy(alpha.cpu().detach().numpy(), base=2, axis=1))/batch\n",
        "      # mx,_ = torch.max(alpha,1)\n",
        "      # entropy = np.mean(-np.log2(mx.cpu().detach().numpy()))\n",
        "      # print(\"entropy of batch\", entropy)\n",
        "\n",
        "      loss = criter(outputs, labels) + k*ent\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis"
      ],
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9HQJMzxBhp"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 485,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOfxUJZ_eFKw",
        "outputId": "337c9b8a-05ba-4eb7-c794-2916ac70463a"
      },
      "source": [
        "print(\"--\"*40)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_where = optim.Adam(where.parameters(),lr =0.001)\n",
        "optimizer_what = optim.Adam(what.parameters(), lr=0.001)\n",
        "acti = []\n",
        "loss_curi = []\n",
        "analysis_data = []\n",
        "epochs = 1000\n",
        "k=0.1\n",
        "running_loss,anlys_data = calculate_attn_loss(train_loader,what,where,criterion,k)\n",
        "loss_curi.append(running_loss)\n",
        "analysis_data.append(anlys_data)\n",
        "print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what.train()\n",
        "  where.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_ = data\n",
        "    inputs = inputs.double()\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    optimizer_where.zero_grad()\n",
        "    optimizer_what.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    avg, alpha = where(inputs)\n",
        "    outputs = what(avg)\n",
        "\n",
        "    ent = np.sum(entropy(alpha.cpu().detach().numpy(), base=2, axis=1))/batch #entropy(alpha.cpu().numpy(), base=2, axis=1)\n",
        "    # mx,_ = torch.max(alpha,1)\n",
        "    # entropy = np.mean(-np.log2(mx.cpu().detach().numpy()))\n",
        "    # print(\"entropy of batch\", entropy)\n",
        "    \n",
        "    loss = criterion(outputs, labels) + k*ent\n",
        "\n",
        "    # loss = criterion(outputs, labels)\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer_where.step()\n",
        "    optimizer_what.step()\n",
        "\n",
        "  running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion,k)\n",
        "  analysis_data.append(anls_data)\n",
        "  print('epoch: [%d] loss: %.3f' %(epoch + 1,running_loss)) \n",
        "  loss_curi.append(running_loss)   #loss per epoch\n",
        "  if running_loss<=0.05:\n",
        "    break\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels,_ = data\n",
        "    images = images.double()\n",
        "    images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    avg, alpha = where(images)\n",
        "    outputs  = what(avg)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    "
      ],
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 2.239\n",
            "epoch: [1] loss: 1.589\n",
            "epoch: [2] loss: 1.498\n",
            "epoch: [3] loss: 1.484\n",
            "epoch: [4] loss: 1.431\n",
            "epoch: [5] loss: 1.404\n",
            "epoch: [6] loss: 1.358\n",
            "epoch: [7] loss: 1.215\n",
            "epoch: [8] loss: 1.060\n",
            "epoch: [9] loss: 0.947\n",
            "epoch: [10] loss: 0.871\n",
            "epoch: [11] loss: 0.806\n",
            "epoch: [12] loss: 0.744\n",
            "epoch: [13] loss: 0.688\n",
            "epoch: [14] loss: 0.635\n",
            "epoch: [15] loss: 0.583\n",
            "epoch: [16] loss: 0.538\n",
            "epoch: [17] loss: 0.492\n",
            "epoch: [18] loss: 0.455\n",
            "epoch: [19] loss: 0.424\n",
            "epoch: [20] loss: 0.398\n",
            "epoch: [21] loss: 0.373\n",
            "epoch: [22] loss: 0.352\n",
            "epoch: [23] loss: 0.335\n",
            "epoch: [24] loss: 0.318\n",
            "epoch: [25] loss: 0.303\n",
            "epoch: [26] loss: 0.291\n",
            "epoch: [27] loss: 0.279\n",
            "epoch: [28] loss: 0.267\n",
            "epoch: [29] loss: 0.258\n",
            "epoch: [30] loss: 0.249\n",
            "epoch: [31] loss: 0.240\n",
            "epoch: [32] loss: 0.233\n",
            "epoch: [33] loss: 0.225\n",
            "epoch: [34] loss: 0.219\n",
            "epoch: [35] loss: 0.213\n",
            "epoch: [36] loss: 0.208\n",
            "epoch: [37] loss: 0.202\n",
            "epoch: [38] loss: 0.198\n",
            "epoch: [39] loss: 0.193\n",
            "epoch: [40] loss: 0.187\n",
            "epoch: [41] loss: 0.185\n",
            "epoch: [42] loss: 0.181\n",
            "epoch: [43] loss: 0.176\n",
            "epoch: [44] loss: 0.174\n",
            "epoch: [45] loss: 0.171\n",
            "epoch: [46] loss: 0.166\n",
            "epoch: [47] loss: 0.164\n",
            "epoch: [48] loss: 0.162\n",
            "epoch: [49] loss: 0.158\n",
            "epoch: [50] loss: 0.155\n",
            "epoch: [51] loss: 0.155\n",
            "epoch: [52] loss: 0.151\n",
            "epoch: [53] loss: 0.148\n",
            "epoch: [54] loss: 0.146\n",
            "epoch: [55] loss: 0.144\n",
            "epoch: [56] loss: 0.142\n",
            "epoch: [57] loss: 0.140\n",
            "epoch: [58] loss: 0.138\n",
            "epoch: [59] loss: 0.136\n",
            "epoch: [60] loss: 0.135\n",
            "epoch: [61] loss: 0.133\n",
            "epoch: [62] loss: 0.130\n",
            "epoch: [63] loss: 0.130\n",
            "epoch: [64] loss: 0.128\n",
            "epoch: [65] loss: 0.126\n",
            "epoch: [66] loss: 0.125\n",
            "epoch: [67] loss: 0.123\n",
            "epoch: [68] loss: 0.122\n",
            "epoch: [69] loss: 0.120\n",
            "epoch: [70] loss: 0.119\n",
            "epoch: [71] loss: 0.119\n",
            "epoch: [72] loss: 0.117\n",
            "epoch: [73] loss: 0.116\n",
            "epoch: [74] loss: 0.114\n",
            "epoch: [75] loss: 0.114\n",
            "epoch: [76] loss: 0.113\n",
            "epoch: [77] loss: 0.112\n",
            "epoch: [78] loss: 0.111\n",
            "epoch: [79] loss: 0.109\n",
            "epoch: [80] loss: 0.109\n",
            "epoch: [81] loss: 0.107\n",
            "epoch: [82] loss: 0.107\n",
            "epoch: [83] loss: 0.106\n",
            "epoch: [84] loss: 0.105\n",
            "epoch: [85] loss: 0.104\n",
            "epoch: [86] loss: 0.104\n",
            "epoch: [87] loss: 0.103\n",
            "epoch: [88] loss: 0.102\n",
            "epoch: [89] loss: 0.101\n",
            "epoch: [90] loss: 0.100\n",
            "epoch: [91] loss: 0.100\n",
            "epoch: [92] loss: 0.099\n",
            "epoch: [93] loss: 0.098\n",
            "epoch: [94] loss: 0.098\n",
            "epoch: [95] loss: 0.097\n",
            "epoch: [96] loss: 0.096\n",
            "epoch: [97] loss: 0.096\n",
            "epoch: [98] loss: 0.095\n",
            "epoch: [99] loss: 0.095\n",
            "epoch: [100] loss: 0.094\n",
            "epoch: [101] loss: 0.094\n",
            "epoch: [102] loss: 0.093\n",
            "epoch: [103] loss: 0.093\n",
            "epoch: [104] loss: 0.092\n",
            "epoch: [105] loss: 0.091\n",
            "epoch: [106] loss: 0.091\n",
            "epoch: [107] loss: 0.090\n",
            "epoch: [108] loss: 0.089\n",
            "epoch: [109] loss: 0.090\n",
            "epoch: [110] loss: 0.089\n",
            "epoch: [111] loss: 0.088\n",
            "epoch: [112] loss: 0.088\n",
            "epoch: [113] loss: 0.087\n",
            "epoch: [114] loss: 0.087\n",
            "epoch: [115] loss: 0.087\n",
            "epoch: [116] loss: 0.086\n",
            "epoch: [117] loss: 0.086\n",
            "epoch: [118] loss: 0.085\n",
            "epoch: [119] loss: 0.084\n",
            "epoch: [120] loss: 0.084\n",
            "epoch: [121] loss: 0.084\n",
            "epoch: [122] loss: 0.084\n",
            "epoch: [123] loss: 0.083\n",
            "epoch: [124] loss: 0.083\n",
            "epoch: [125] loss: 0.082\n",
            "epoch: [126] loss: 0.082\n",
            "epoch: [127] loss: 0.081\n",
            "epoch: [128] loss: 0.081\n",
            "epoch: [129] loss: 0.081\n",
            "epoch: [130] loss: 0.080\n",
            "epoch: [131] loss: 0.080\n",
            "epoch: [132] loss: 0.079\n",
            "epoch: [133] loss: 0.079\n",
            "epoch: [134] loss: 0.079\n",
            "epoch: [135] loss: 0.079\n",
            "epoch: [136] loss: 0.078\n",
            "epoch: [137] loss: 0.079\n",
            "epoch: [138] loss: 0.077\n",
            "epoch: [139] loss: 0.078\n",
            "epoch: [140] loss: 0.077\n",
            "epoch: [141] loss: 0.077\n",
            "epoch: [142] loss: 0.076\n",
            "epoch: [143] loss: 0.076\n",
            "epoch: [144] loss: 0.076\n",
            "epoch: [145] loss: 0.076\n",
            "epoch: [146] loss: 0.076\n",
            "epoch: [147] loss: 0.076\n",
            "epoch: [148] loss: 0.074\n",
            "epoch: [149] loss: 0.074\n",
            "epoch: [150] loss: 0.074\n",
            "epoch: [151] loss: 0.074\n",
            "epoch: [152] loss: 0.074\n",
            "epoch: [153] loss: 0.073\n",
            "epoch: [154] loss: 0.073\n",
            "epoch: [155] loss: 0.073\n",
            "epoch: [156] loss: 0.073\n",
            "epoch: [157] loss: 0.072\n",
            "epoch: [158] loss: 0.071\n",
            "epoch: [159] loss: 0.072\n",
            "epoch: [160] loss: 0.072\n",
            "epoch: [161] loss: 0.071\n",
            "epoch: [162] loss: 0.071\n",
            "epoch: [163] loss: 0.071\n",
            "epoch: [164] loss: 0.070\n",
            "epoch: [165] loss: 0.070\n",
            "epoch: [166] loss: 0.070\n",
            "epoch: [167] loss: 0.070\n",
            "epoch: [168] loss: 0.070\n",
            "epoch: [169] loss: 0.070\n",
            "epoch: [170] loss: 0.069\n",
            "epoch: [171] loss: 0.069\n",
            "epoch: [172] loss: 0.069\n",
            "epoch: [173] loss: 0.069\n",
            "epoch: [174] loss: 0.069\n",
            "epoch: [175] loss: 0.068\n",
            "epoch: [176] loss: 0.068\n",
            "epoch: [177] loss: 0.068\n",
            "epoch: [178] loss: 0.068\n",
            "epoch: [179] loss: 0.068\n",
            "epoch: [180] loss: 0.067\n",
            "epoch: [181] loss: 0.067\n",
            "epoch: [182] loss: 0.067\n",
            "epoch: [183] loss: 0.067\n",
            "epoch: [184] loss: 0.067\n",
            "epoch: [185] loss: 0.067\n",
            "epoch: [186] loss: 0.067\n",
            "epoch: [187] loss: 0.066\n",
            "epoch: [188] loss: 0.067\n",
            "epoch: [189] loss: 0.066\n",
            "epoch: [190] loss: 0.066\n",
            "epoch: [191] loss: 0.066\n",
            "epoch: [192] loss: 0.065\n",
            "epoch: [193] loss: 0.065\n",
            "epoch: [194] loss: 0.066\n",
            "epoch: [195] loss: 0.066\n",
            "epoch: [196] loss: 0.065\n",
            "epoch: [197] loss: 0.064\n",
            "epoch: [198] loss: 0.066\n",
            "epoch: [199] loss: 0.065\n",
            "epoch: [200] loss: 0.065\n",
            "epoch: [201] loss: 0.065\n",
            "epoch: [202] loss: 0.065\n",
            "epoch: [203] loss: 0.064\n",
            "epoch: [204] loss: 0.064\n",
            "epoch: [205] loss: 0.063\n",
            "epoch: [206] loss: 0.065\n",
            "epoch: [207] loss: 0.063\n",
            "epoch: [208] loss: 0.062\n",
            "epoch: [209] loss: 0.063\n",
            "epoch: [210] loss: 0.064\n",
            "epoch: [211] loss: 0.063\n",
            "epoch: [212] loss: 0.064\n",
            "epoch: [213] loss: 0.063\n",
            "epoch: [214] loss: 0.063\n",
            "epoch: [215] loss: 0.062\n",
            "epoch: [216] loss: 0.062\n",
            "epoch: [217] loss: 0.063\n",
            "epoch: [218] loss: 0.062\n",
            "epoch: [219] loss: 0.062\n",
            "epoch: [220] loss: 0.063\n",
            "epoch: [221] loss: 0.062\n",
            "epoch: [222] loss: 0.063\n",
            "epoch: [223] loss: 0.062\n",
            "epoch: [224] loss: 0.062\n",
            "epoch: [225] loss: 0.062\n",
            "epoch: [226] loss: 0.062\n",
            "epoch: [227] loss: 0.062\n",
            "epoch: [228] loss: 0.062\n",
            "epoch: [229] loss: 0.063\n",
            "epoch: [230] loss: 0.062\n",
            "epoch: [231] loss: 0.062\n",
            "epoch: [232] loss: 0.062\n",
            "epoch: [233] loss: 0.062\n",
            "epoch: [234] loss: 0.062\n",
            "epoch: [235] loss: 0.062\n",
            "epoch: [236] loss: 0.061\n",
            "epoch: [237] loss: 0.061\n",
            "epoch: [238] loss: 0.061\n",
            "epoch: [239] loss: 0.061\n",
            "epoch: [240] loss: 0.060\n",
            "epoch: [241] loss: 0.061\n",
            "epoch: [242] loss: 0.061\n",
            "epoch: [243] loss: 0.061\n",
            "epoch: [244] loss: 0.061\n",
            "epoch: [245] loss: 0.060\n",
            "epoch: [246] loss: 0.062\n",
            "epoch: [247] loss: 0.060\n",
            "epoch: [248] loss: 0.060\n",
            "epoch: [249] loss: 0.061\n",
            "epoch: [250] loss: 0.061\n",
            "epoch: [251] loss: 0.061\n",
            "epoch: [252] loss: 0.060\n",
            "epoch: [253] loss: 0.061\n",
            "epoch: [254] loss: 0.060\n",
            "epoch: [255] loss: 0.059\n",
            "epoch: [256] loss: 0.058\n",
            "epoch: [257] loss: 0.057\n",
            "epoch: [258] loss: 0.058\n",
            "epoch: [259] loss: 0.059\n",
            "epoch: [260] loss: 0.059\n",
            "epoch: [261] loss: 0.059\n",
            "epoch: [262] loss: 0.059\n",
            "epoch: [263] loss: 0.059\n",
            "epoch: [264] loss: 0.059\n",
            "epoch: [265] loss: 0.058\n",
            "epoch: [266] loss: 0.059\n",
            "epoch: [267] loss: 0.058\n",
            "epoch: [268] loss: 0.058\n",
            "epoch: [269] loss: 0.059\n",
            "epoch: [270] loss: 0.060\n",
            "epoch: [271] loss: 0.059\n",
            "epoch: [272] loss: 0.059\n",
            "epoch: [273] loss: 0.059\n",
            "epoch: [274] loss: 0.059\n",
            "epoch: [275] loss: 0.058\n",
            "epoch: [276] loss: 0.059\n",
            "epoch: [277] loss: 0.059\n",
            "epoch: [278] loss: 0.058\n",
            "epoch: [279] loss: 0.059\n",
            "epoch: [280] loss: 0.059\n",
            "epoch: [281] loss: 0.059\n",
            "epoch: [282] loss: 0.059\n",
            "epoch: [283] loss: 0.059\n",
            "epoch: [284] loss: 0.059\n",
            "epoch: [285] loss: 0.059\n",
            "epoch: [286] loss: 0.058\n",
            "epoch: [287] loss: 0.058\n",
            "epoch: [288] loss: 0.058\n",
            "epoch: [289] loss: 0.058\n",
            "epoch: [290] loss: 0.058\n",
            "epoch: [291] loss: 0.058\n",
            "epoch: [292] loss: 0.058\n",
            "epoch: [293] loss: 0.058\n",
            "epoch: [294] loss: 0.059\n",
            "epoch: [295] loss: 0.058\n",
            "epoch: [296] loss: 0.058\n",
            "epoch: [297] loss: 0.058\n",
            "epoch: [298] loss: 0.058\n",
            "epoch: [299] loss: 0.057\n",
            "epoch: [300] loss: 0.058\n",
            "epoch: [301] loss: 0.056\n",
            "epoch: [302] loss: 0.058\n",
            "epoch: [303] loss: 0.058\n",
            "epoch: [304] loss: 0.058\n",
            "epoch: [305] loss: 0.059\n",
            "epoch: [306] loss: 0.053\n",
            "epoch: [307] loss: 0.052\n",
            "epoch: [308] loss: 0.055\n",
            "epoch: [309] loss: 0.058\n",
            "epoch: [310] loss: 0.059\n",
            "epoch: [311] loss: 0.058\n",
            "epoch: [312] loss: 0.057\n",
            "epoch: [313] loss: 0.057\n",
            "epoch: [314] loss: 0.057\n",
            "epoch: [315] loss: 0.057\n",
            "epoch: [316] loss: 0.058\n",
            "epoch: [317] loss: 0.058\n",
            "epoch: [318] loss: 0.057\n",
            "epoch: [319] loss: 0.058\n",
            "epoch: [320] loss: 0.057\n",
            "epoch: [321] loss: 0.058\n",
            "epoch: [322] loss: 0.058\n",
            "epoch: [323] loss: 0.058\n",
            "epoch: [324] loss: 0.058\n",
            "epoch: [325] loss: 0.057\n",
            "epoch: [326] loss: 0.058\n",
            "epoch: [327] loss: 0.057\n",
            "epoch: [328] loss: 0.057\n",
            "epoch: [329] loss: 0.057\n",
            "epoch: [330] loss: 0.055\n",
            "epoch: [331] loss: 0.057\n",
            "epoch: [332] loss: 0.056\n",
            "epoch: [333] loss: 0.056\n",
            "epoch: [334] loss: 0.057\n",
            "epoch: [335] loss: 0.055\n",
            "epoch: [336] loss: 0.057\n",
            "epoch: [337] loss: 0.059\n",
            "epoch: [338] loss: 0.056\n",
            "epoch: [339] loss: 0.057\n",
            "epoch: [340] loss: 0.057\n",
            "epoch: [341] loss: 0.056\n",
            "epoch: [342] loss: 0.057\n",
            "epoch: [343] loss: 0.057\n",
            "epoch: [344] loss: 0.056\n",
            "epoch: [345] loss: 0.057\n",
            "epoch: [346] loss: 0.056\n",
            "epoch: [347] loss: 0.057\n",
            "epoch: [348] loss: 0.056\n",
            "epoch: [349] loss: 0.057\n",
            "epoch: [350] loss: 0.056\n",
            "epoch: [351] loss: 0.056\n",
            "epoch: [352] loss: 0.057\n",
            "epoch: [353] loss: 0.056\n",
            "epoch: [354] loss: 0.058\n",
            "epoch: [355] loss: 0.051\n",
            "epoch: [356] loss: 0.055\n",
            "epoch: [357] loss: 0.058\n",
            "epoch: [358] loss: 0.058\n",
            "epoch: [359] loss: 0.058\n",
            "epoch: [360] loss: 0.057\n",
            "epoch: [361] loss: 0.057\n",
            "epoch: [362] loss: 0.057\n",
            "epoch: [363] loss: 0.057\n",
            "epoch: [364] loss: 0.057\n",
            "epoch: [365] loss: 0.057\n",
            "epoch: [366] loss: 0.058\n",
            "epoch: [367] loss: 0.057\n",
            "epoch: [368] loss: 0.058\n",
            "epoch: [369] loss: 0.057\n",
            "epoch: [370] loss: 0.057\n",
            "epoch: [371] loss: 0.057\n",
            "epoch: [372] loss: 0.057\n",
            "epoch: [373] loss: 0.057\n",
            "epoch: [374] loss: 0.057\n",
            "epoch: [375] loss: 0.057\n",
            "epoch: [376] loss: 0.057\n",
            "epoch: [377] loss: 0.056\n",
            "epoch: [378] loss: 0.058\n",
            "epoch: [379] loss: 0.055\n",
            "epoch: [380] loss: 0.057\n",
            "epoch: [381] loss: 0.057\n",
            "epoch: [382] loss: 0.057\n",
            "epoch: [383] loss: 0.057\n",
            "epoch: [384] loss: 0.057\n",
            "epoch: [385] loss: 0.056\n",
            "epoch: [386] loss: 0.057\n",
            "epoch: [387] loss: 0.056\n",
            "epoch: [388] loss: 0.057\n",
            "epoch: [389] loss: 0.056\n",
            "epoch: [390] loss: 0.057\n",
            "epoch: [391] loss: 0.057\n",
            "epoch: [392] loss: 0.057\n",
            "epoch: [393] loss: 0.056\n",
            "epoch: [394] loss: 0.057\n",
            "epoch: [395] loss: 0.055\n",
            "epoch: [396] loss: 0.056\n",
            "epoch: [397] loss: 0.052\n",
            "epoch: [398] loss: 0.056\n",
            "epoch: [399] loss: 0.061\n",
            "epoch: [400] loss: 0.061\n",
            "epoch: [401] loss: 0.059\n",
            "epoch: [402] loss: 0.058\n",
            "epoch: [403] loss: 0.057\n",
            "epoch: [404] loss: 0.057\n",
            "epoch: [405] loss: 0.057\n",
            "epoch: [406] loss: 0.056\n",
            "epoch: [407] loss: 0.056\n",
            "epoch: [408] loss: 0.056\n",
            "epoch: [409] loss: 0.056\n",
            "epoch: [410] loss: 0.057\n",
            "epoch: [411] loss: 0.057\n",
            "epoch: [412] loss: 0.057\n",
            "epoch: [413] loss: 0.057\n",
            "epoch: [414] loss: 0.057\n",
            "epoch: [415] loss: 0.056\n",
            "epoch: [416] loss: 0.056\n",
            "epoch: [417] loss: 0.055\n",
            "epoch: [418] loss: 0.057\n",
            "epoch: [419] loss: 0.056\n",
            "epoch: [420] loss: 0.057\n",
            "epoch: [421] loss: 0.056\n",
            "epoch: [422] loss: 0.056\n",
            "epoch: [423] loss: 0.056\n",
            "epoch: [424] loss: 0.056\n",
            "epoch: [425] loss: 0.056\n",
            "epoch: [426] loss: 0.055\n",
            "epoch: [427] loss: 0.057\n",
            "epoch: [428] loss: 0.056\n",
            "epoch: [429] loss: 0.054\n",
            "epoch: [430] loss: 0.057\n",
            "epoch: [431] loss: 0.053\n",
            "epoch: [432] loss: 0.056\n",
            "epoch: [433] loss: 0.060\n",
            "epoch: [434] loss: 0.057\n",
            "epoch: [435] loss: 0.057\n",
            "epoch: [436] loss: 0.057\n",
            "epoch: [437] loss: 0.057\n",
            "epoch: [438] loss: 0.056\n",
            "epoch: [439] loss: 0.056\n",
            "epoch: [440] loss: 0.056\n",
            "epoch: [441] loss: 0.056\n",
            "epoch: [442] loss: 0.056\n",
            "epoch: [443] loss: 0.056\n",
            "epoch: [444] loss: 0.056\n",
            "epoch: [445] loss: 0.057\n",
            "epoch: [446] loss: 0.056\n",
            "epoch: [447] loss: 0.055\n",
            "epoch: [448] loss: 0.056\n",
            "epoch: [449] loss: 0.056\n",
            "epoch: [450] loss: 0.055\n",
            "epoch: [451] loss: 0.056\n",
            "epoch: [452] loss: 0.056\n",
            "epoch: [453] loss: 0.056\n",
            "epoch: [454] loss: 0.055\n",
            "epoch: [455] loss: 0.055\n",
            "epoch: [456] loss: 0.055\n",
            "epoch: [457] loss: 0.056\n",
            "epoch: [458] loss: 0.054\n",
            "epoch: [459] loss: 0.057\n",
            "epoch: [460] loss: 0.054\n",
            "epoch: [461] loss: 0.053\n",
            "epoch: [462] loss: 0.055\n",
            "epoch: [463] loss: 0.053\n",
            "epoch: [464] loss: 0.054\n",
            "epoch: [465] loss: 0.058\n",
            "epoch: [466] loss: 0.055\n",
            "epoch: [467] loss: 0.055\n",
            "epoch: [468] loss: 0.056\n",
            "epoch: [469] loss: 0.056\n",
            "epoch: [470] loss: 0.054\n",
            "epoch: [471] loss: 0.056\n",
            "epoch: [472] loss: 0.050\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 100 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31RVViMkYM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "2eeb4b83-aa54-435f-a777-a935b759d9df"
      },
      "source": [
        "analysis_data = np.array(analysis_data)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,0],label=\"ftpt\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,1],label=\"ffpt\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,2],label=\"ftpf\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,3],label=\"ffpf\")\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.savefig(\"trends_synthetic_300_300.png\",bbox_inches=\"tight\")\n",
        "plt.savefig(\"trends_synthetic_300_300.pdf\",bbox_inches=\"tight\")\n"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mag3jZ-LMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85295c49-5da8-4217-a137-dcebd004a5b6"
      },
      "source": [
        "analysis_data[-1,:2]/3000"
      ],
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSxFtBWQ1M8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8a5004-53d7-403b-95b6-6d0fc6962fa6"
      },
      "source": [
        "running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion,k)\r\n",
        "print(running_loss, anls_data)"
      ],
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.04986094131146932 [3000, 0, 0, 0, 2837, 163]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncIi9Jc92a4u"
      },
      "source": [
        "what.eval()\r\n",
        "where.eval()\r\n",
        "alphas = []\r\n",
        "max_alpha =[]\r\n",
        "alpha_ftpt=[]\r\n",
        "alpha_ffpt=[]\r\n",
        "alpha_ftpf=[]\r\n",
        "alpha_ffpf=[]\r\n",
        "argmax_more_than_half=0\r\n",
        "argmax_less_than_half=0\r\n",
        "cnt =0\r\n",
        "with torch.no_grad():\r\n",
        "  for i, data in enumerate(train_loader, 0):\r\n",
        "    inputs, labels, fidx = data\r\n",
        "    inputs = inputs.double()\r\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\r\n",
        "    avg, alphas = where(inputs)\r\n",
        "    outputs = what(avg)\r\n",
        "    _, predicted = torch.max(outputs.data, 1)\r\n",
        "    batch = len(predicted)\r\n",
        "    mx,_ = torch.max(alphas,1)\r\n",
        "    max_alpha.append(mx.cpu().detach().numpy())\r\n",
        "    for j in range (batch):\r\n",
        "      cnt+=1\r\n",
        "      focus = torch.argmax(alphas[j]).item()\r\n",
        "      if alphas[j][focus] >= 0.5 :\r\n",
        "        argmax_more_than_half += 1\r\n",
        "      else:\r\n",
        "        argmax_less_than_half += 1\r\n",
        "\r\n",
        "      if (focus == fidx[j].item() and predicted[j].item() == labels[j].item()):\r\n",
        "          alpha_ftpt.append(alphas[j][focus].item())\r\n",
        "          # print(focus, fore_idx[j].item(), predicted[j].item() , labels[j].item() )\r\n",
        "\r\n",
        "      elif (focus != fidx[j].item() and predicted[j].item() == labels[j].item()):\r\n",
        "          alpha_ffpt.append(alphas[j][focus].item())\r\n",
        "\r\n",
        "      elif (focus == fidx[j].item() and predicted[j].item() != labels[j].item()):\r\n",
        "          alpha_ftpf.append(alphas[j][focus].item())\r\n",
        "\r\n",
        "      elif (focus != fidx[j].item() and predicted[j].item() != labels[j].item()):\r\n",
        "          alpha_ffpf.append(alphas[j][focus].item())\r\n"
      ],
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_3nbXu5Zw34",
        "outputId": "be3c619d-8628-43be-e999-a95f58f5674a"
      },
      "source": [
        "np.sum(entropy(alphas.cpu().numpy(), base=2, axis=1))/batch"
      ],
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47420405345430605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 491
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7vDw6cn1q9M",
        "outputId": "a61c6e86-9bd0-401d-8b18-53cc7ed8146a"
      },
      "source": [
        "np.mean(-np.log2(mx.cpu().detach().numpy()))"
      ],
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21855492613220218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 492
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc43myxx2yGI"
      },
      "source": [
        "a = np.array([[0.1,0.9], [0.5, 0.5]])"
      ],
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUdhdSpB23BL",
        "outputId": "fafe4087-7392-4f89-fb18-fa71908fe5b3"
      },
      "source": [
        "-0.1*np.log2(0.1)-0.9*np.log2(0.9)"
      ],
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4689955935892812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 494
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9AKu9cRW7Z5",
        "outputId": "51396a4d-abc7-40b2-fbc0-b0fcb7f84cbf"
      },
      "source": [
        "entropy([9/10, 1/10], base=2), entropy([0.5, 0.5], base=2), entropy(a, base=2, axis=1)"
      ],
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.46899559358928117, 1.0, array([0.46899559, 1.        ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 495
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyEk81R43gPZ",
        "outputId": "da280dc2-5504-4b49-f1d6-fdab2f2b6895"
      },
      "source": [
        "np.mean(-np.log2(a))"
      ],
      "execution_count": 496,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.368482797083103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 496
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPE_6NQd3VHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7919b5c-668e-4dea-a8bb-a278b5d558ee"
      },
      "source": [
        "max_alpha = np.concatenate(max_alpha,axis=0)\r\n",
        "print(max_alpha.shape, cnt)"
      ],
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000,) 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvgu92LY3Zke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c858f94b-c436-4c8a-e113-9eb537a98639"
      },
      "source": [
        "np.array(alpha_ftpt).size, np.array(alpha_ffpt).size, np.array(alpha_ftpf).size, np.array(alpha_ffpf).size"
      ],
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0, 0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 498
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XtgiDDpZ8qH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "4114c2ba-fa5a-4c49-f54f-1491f6928fdc"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(max_alpha,bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values histogram\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uTx4G6PeOgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "2e31d7d2-3940-400b-e4aa-f01886a2741f"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(np.array(alpha_ftpt),bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values in ftpt\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 500,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2Nn1IneTkT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "32c8c1ef-fda8-4fff-aa4f-ebfbea385ee0"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(np.array(alpha_ffpt),bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values in ffpt\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 501,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}