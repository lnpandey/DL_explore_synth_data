{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Synthetic_elliptical_blobs_interpretable_100_50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYu3ISwwGks"
      },
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.stats import entropy"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEp-LtqiWAf"
      },
      "source": [
        "mu1 = np.array([3,3,3,3,0])\n",
        "sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu2 = np.array([4,4,4,4,0])\n",
        "sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu3 = np.array([10,5,5,10,0])\n",
        "sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu4 = np.array([-10,-10,-10,-10,0])\n",
        "sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu5 = np.array([-21,4,4,-21,0])\n",
        "sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu6 = np.array([-10,18,18,-10,0])\n",
        "sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu7 = np.array([4,20,4,20,0])\n",
        "sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu8 = np.array([4,-20,-20,4,0])\n",
        "sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu9 = np.array([20,20,20,20,0])\n",
        "sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu10 = np.array([20,-10,-10,20,0])\n",
        "sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)\n"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NshDNGjY2T3w"
      },
      "source": [
        "# mu1 = np.array([3,3,0,0,0])\n",
        "# sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu2 = np.array([4,4,0,0,0])\n",
        "# sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu3 = np.array([10,5,0,0,0])\n",
        "# sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu4 = np.array([-10,-10,0,0,0])\n",
        "# sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu5 = np.array([-21,4,0,0,0])\n",
        "# sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu6 = np.array([-10,18,0,0,0])\n",
        "# sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu7 = np.array([4,20,0,0,0])\n",
        "# sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu8 = np.array([4,-20,0,0,0])\n",
        "# sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu9 = np.array([20,20,0,0,0])\n",
        "# sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu10 = np.array([20,-10,0,0,0])\n",
        "# sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "# sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "# sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "# sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "# sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "# sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "# sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "# sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "# sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "# sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "# sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YDnxeP-2_1V",
        "outputId": "5c5cdf79-8320-48c2-ff33-e9346f52b172"
      },
      "source": [
        "X = np.concatenate((sample1,sample2,sample3,sample4,sample5,sample6,sample7,sample8,sample9,sample10),axis=0)\n",
        "Y = np.concatenate((np.zeros((500,1)),np.ones((500,1)),2*np.ones((500,1)),3*np.ones((500,1)),4*np.ones((500,1)),\n",
        "                    5*np.ones((500,1)),6*np.ones((500,1)),7*np.ones((500,1)),8*np.ones((500,1)),9*np.ones((500,1))),axis=0).astype(int)\n",
        "print(X.shape,Y.shape)\n",
        "# plt.scatter(sample1[:,0],sample1[:,1],label=\"class_0\")\n",
        "# plt.scatter(sample2[:,0],sample2[:,1],label=\"class_1\")\n",
        "# plt.scatter(sample3[:,0],sample3[:,1],label=\"class_2\")\n",
        "# plt.scatter(sample4[:,0],sample4[:,1],label=\"class_3\")\n",
        "# plt.scatter(sample5[:,0],sample5[:,1],label=\"class_4\")\n",
        "# plt.scatter(sample6[:,0],sample6[:,1],label=\"class_5\")\n",
        "# plt.scatter(sample7[:,0],sample7[:,1],label=\"class_6\")\n",
        "# plt.scatter(sample8[:,0],sample8[:,1],label=\"class_7\")\n",
        "# plt.scatter(sample9[:,0],sample9[:,1],label=\"class_8\")\n",
        "# plt.scatter(sample10[:,0],sample10[:,1],label=\"class_9\")\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 5) (5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YzqPUf3CHa"
      },
      "source": [
        "class SyntheticDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    #self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx] , self.y[idx] #, self.fore_idx[idx]"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mi3nL5-4D7_"
      },
      "source": [
        "trainset = SyntheticDataset(X,Y)\n",
        "\n",
        "\n",
        "# testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKzc7IgwqoU2",
        "outputId": "1fcf4c22-1501-4e83-fd7a-c9e80921f8fc"
      },
      "source": [
        "classes = ('zero','one','two','three','four','five','six','seven','eight','nine')\n",
        "\n",
        "foreground_classes = {'zero','one','two'}\n",
        "fg_used = '012'\n",
        "fg1, fg2, fg3 = 0,1,2\n",
        "\n",
        "\n",
        "all_classes = {'zero','one','two','three','four','five','six','seven','eight','nine'}\n",
        "background_classes = all_classes - foreground_classes\n",
        "background_classes"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eight', 'five', 'four', 'nine', 'seven', 'six', 'three'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT6iKHutquR8"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKzXkPSq5KU"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=100\n",
        "\n",
        "for i in range(50):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChdziOP3rF1G"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])\n",
        "      label = foreground_label[fg_idx] - fg1  # minus fg1 because our fore ground classes are fg1,fg2,fg3 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASrmPqErIDM"
      },
      "source": [
        "desired_num = 3000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "list_set_labels = [] \n",
        "for i in range(desired_num):\n",
        "  set_idx = set()\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,3500,8)\n",
        "  set_idx = set(background_label[bg_idx].tolist())\n",
        "  fg_idx = np.random.randint(0,1500)\n",
        "  set_idx.add(foreground_label[fg_idx].item())\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)\n",
        "  list_set_labels.append(set_idx)"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDFN7dCarmmR"
      },
      "source": [
        "def create_avg_image_from_mosaic_dataset(mosaic_dataset,labels,foreground_index,dataset_number):\n",
        "  \"\"\"\n",
        "  mosaic_dataset : mosaic_dataset contains 9 images 32 x 32 each as 1 data point\n",
        "  labels : mosaic_dataset labels\n",
        "  foreground_index : contains list of indexes where foreground image is present so that using this we can take weighted average\n",
        "  dataset_number : will help us to tell what ratio of foreground image to be taken. for eg: if it is \"j\" then fg_image_ratio = j/9 , bg_image_ratio = (9-j)/8*9\n",
        "  \"\"\"\n",
        "  avg_image_dataset = []\n",
        "  for i in range(len(mosaic_dataset)):\n",
        "    img = torch.zeros([5], dtype=torch.float64)\n",
        "    for j in range(9):\n",
        "      if j == foreground_index[i]:\n",
        "        img = img + mosaic_dataset[i][j]*dataset_number/9\n",
        "      else :\n",
        "        img = img + mosaic_dataset[i][j]*(9-dataset_number)/(8*9)\n",
        "    \n",
        "    avg_image_dataset.append(img)\n",
        "    \n",
        "  return torch.stack(avg_image_dataset) , torch.stack(labels) , foreground_index"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgF90qBIt8yN"
      },
      "source": [
        "def calculate_loss(dataloader,model,criter):\n",
        "  model.eval()\n",
        "  r_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      outputs = model(inputs)\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  return r_loss/i"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGsdvMSzIUK"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5NPRPmb904"
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzPfrih82Bg"
      },
      "source": [
        "**Focus Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN3Bbs8c0fA"
      },
      "source": [
        "class Focus_deep(nn.Module):\n",
        "    '''\n",
        "       deep focus network averaged at zeroth layer\n",
        "       input : elemental data\n",
        "    '''\n",
        "    def __init__(self,inputs,output,K,d):\n",
        "        super(Focus_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.K = K\n",
        "        self.d  = d\n",
        "        self.linear1 = nn.Linear(self.inputs,100)  #,self.output)\n",
        "        self.linear2 = nn.Linear(100,self.output) \n",
        "    def forward(self,z):\n",
        "        batch = z.shape[0]\n",
        "        x = torch.zeros([batch,self.K],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,self.d], dtype=torch.float64)\n",
        "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        for i in range(self.K):\n",
        "            x[:,i] = self.helper(z[:,i] )[:,0]  # self.d*i:self.d*i+self.d\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(self.K):\n",
        "            x1 = x[:,i]          \n",
        "            y = y+torch.mul(x1[:,None],z[:,i])  # self.d*i:self.d*i+self.d\n",
        "        return y , x \n",
        "    def helper(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x\n"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjrL0Zb484KO"
      },
      "source": [
        "**Classification Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W0oKcClFZY"
      },
      "source": [
        "class Classification_deep(nn.Module):\n",
        "    '''\n",
        "       input : elemental data\n",
        "       deep classification module data averaged at zeroth layer\n",
        "    '''\n",
        "    def __init__(self,inputs,output):\n",
        "        super(Classification_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.linear1 = nn.Linear(self.inputs,50)\n",
        "        self.linear2 = nn.Linear(50,self.output)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x    "
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByKHrKis88lW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAPjSKkrd0ru"
      },
      "source": [
        "where = Focus_deep(5,1,9,5).double()\n",
        "what = Classification_deep(5,3).double()\n",
        "where = where.to(\"cuda\")\n",
        "what = what.to(\"cuda\")"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAfQnNwgFYX"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,where,criter,k):\n",
        "  what.eval()\n",
        "  where.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels, fidx = data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      avg,alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "\n",
        "      ent = np.sum(entropy(alpha.cpu().detach().numpy(), base=2, axis=1))/batch\n",
        "      # mx,_ = torch.max(alpha,1)\n",
        "      # entropy = np.mean(-np.log2(mx.cpu().detach().numpy()))\n",
        "      # print(\"entropy of batch\", entropy)\n",
        "\n",
        "      loss = criter(outputs, labels) + k*ent\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9HQJMzxBhp"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MOfxUJZ_eFKw",
        "outputId": "3c86e6da-6e33-4856-c5ea-04578a8e2f07"
      },
      "source": [
        "print(\"--\"*40)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_where = optim.Adam(where.parameters(),lr =0.001)\n",
        "optimizer_what = optim.Adam(what.parameters(), lr=0.001)\n",
        "acti = []\n",
        "loss_curi = []\n",
        "analysis_data = []\n",
        "epochs = 1000\n",
        "k=0.1\n",
        "running_loss,anlys_data = calculate_attn_loss(train_loader,what,where,criterion,k)\n",
        "loss_curi.append(running_loss)\n",
        "analysis_data.append(anlys_data)\n",
        "print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what.train()\n",
        "  where.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_ = data\n",
        "    inputs = inputs.double()\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    optimizer_where.zero_grad()\n",
        "    optimizer_what.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    avg, alpha = where(inputs)\n",
        "    outputs = what(avg)\n",
        "\n",
        "    ent = np.sum(entropy(alpha.cpu().detach().numpy(), base=2, axis=1))/batch #entropy(alpha.cpu().numpy(), base=2, axis=1)\n",
        "    # mx,_ = torch.max(alpha,1)\n",
        "    # entropy = np.mean(-np.log2(mx.cpu().detach().numpy()))\n",
        "    # print(\"entropy of batch\", entropy)\n",
        "    \n",
        "    loss = criterion(outputs, labels) + k*ent\n",
        "\n",
        "    # loss = criterion(outputs, labels)\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer_where.step()\n",
        "    optimizer_what.step()\n",
        "\n",
        "  running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion,k)\n",
        "  analysis_data.append(anls_data)\n",
        "  print('epoch: [%d] loss: %.3f' %(epoch + 1,running_loss)) \n",
        "  loss_curi.append(running_loss)   #loss per epoch\n",
        "  if running_loss<=0.03:\n",
        "    break\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels,_ = data\n",
        "    images = images.double()\n",
        "    images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    avg, alpha = where(images)\n",
        "    outputs  = what(avg)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    "
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 2.969\n",
            "epoch: [1] loss: 1.525\n",
            "epoch: [2] loss: 1.439\n",
            "epoch: [3] loss: 1.403\n",
            "epoch: [4] loss: 1.395\n",
            "epoch: [5] loss: 1.387\n",
            "epoch: [6] loss: 1.383\n",
            "epoch: [7] loss: 1.381\n",
            "epoch: [8] loss: 1.383\n",
            "epoch: [9] loss: 1.380\n",
            "epoch: [10] loss: 1.380\n",
            "epoch: [11] loss: 1.385\n",
            "epoch: [12] loss: 1.383\n",
            "epoch: [13] loss: 1.379\n",
            "epoch: [14] loss: 1.384\n",
            "epoch: [15] loss: 1.381\n",
            "epoch: [16] loss: 1.382\n",
            "epoch: [17] loss: 1.382\n",
            "epoch: [18] loss: 1.385\n",
            "epoch: [19] loss: 1.387\n",
            "epoch: [20] loss: 1.388\n",
            "epoch: [21] loss: 1.393\n",
            "epoch: [22] loss: 1.394\n",
            "epoch: [23] loss: 1.403\n",
            "epoch: [24] loss: 1.409\n",
            "epoch: [25] loss: 1.401\n",
            "epoch: [26] loss: 1.259\n",
            "epoch: [27] loss: 1.017\n",
            "epoch: [28] loss: 0.847\n",
            "epoch: [29] loss: 0.735\n",
            "epoch: [30] loss: 0.655\n",
            "epoch: [31] loss: 0.602\n",
            "epoch: [32] loss: 0.562\n",
            "epoch: [33] loss: 0.530\n",
            "epoch: [34] loss: 0.503\n",
            "epoch: [35] loss: 0.475\n",
            "epoch: [36] loss: 0.449\n",
            "epoch: [37] loss: 0.429\n",
            "epoch: [38] loss: 0.407\n",
            "epoch: [39] loss: 0.389\n",
            "epoch: [40] loss: 0.369\n",
            "epoch: [41] loss: 0.354\n",
            "epoch: [42] loss: 0.338\n",
            "epoch: [43] loss: 0.325\n",
            "epoch: [44] loss: 0.312\n",
            "epoch: [45] loss: 0.298\n",
            "epoch: [46] loss: 0.287\n",
            "epoch: [47] loss: 0.281\n",
            "epoch: [48] loss: 0.266\n",
            "epoch: [49] loss: 0.255\n",
            "epoch: [50] loss: 0.245\n",
            "epoch: [51] loss: 0.235\n",
            "epoch: [52] loss: 0.226\n",
            "epoch: [53] loss: 0.220\n",
            "epoch: [54] loss: 0.211\n",
            "epoch: [55] loss: 0.206\n",
            "epoch: [56] loss: 0.199\n",
            "epoch: [57] loss: 0.194\n",
            "epoch: [58] loss: 0.187\n",
            "epoch: [59] loss: 0.182\n",
            "epoch: [60] loss: 0.177\n",
            "epoch: [61] loss: 0.172\n",
            "epoch: [62] loss: 0.168\n",
            "epoch: [63] loss: 0.165\n",
            "epoch: [64] loss: 0.160\n",
            "epoch: [65] loss: 0.157\n",
            "epoch: [66] loss: 0.154\n",
            "epoch: [67] loss: 0.151\n",
            "epoch: [68] loss: 0.147\n",
            "epoch: [69] loss: 0.144\n",
            "epoch: [70] loss: 0.141\n",
            "epoch: [71] loss: 0.139\n",
            "epoch: [72] loss: 0.136\n",
            "epoch: [73] loss: 0.133\n",
            "epoch: [74] loss: 0.131\n",
            "epoch: [75] loss: 0.130\n",
            "epoch: [76] loss: 0.129\n",
            "epoch: [77] loss: 0.125\n",
            "epoch: [78] loss: 0.125\n",
            "epoch: [79] loss: 0.122\n",
            "epoch: [80] loss: 0.121\n",
            "epoch: [81] loss: 0.119\n",
            "epoch: [82] loss: 0.117\n",
            "epoch: [83] loss: 0.115\n",
            "epoch: [84] loss: 0.113\n",
            "epoch: [85] loss: 0.112\n",
            "epoch: [86] loss: 0.111\n",
            "epoch: [87] loss: 0.109\n",
            "epoch: [88] loss: 0.107\n",
            "epoch: [89] loss: 0.106\n",
            "epoch: [90] loss: 0.104\n",
            "epoch: [91] loss: 0.103\n",
            "epoch: [92] loss: 0.102\n",
            "epoch: [93] loss: 0.102\n",
            "epoch: [94] loss: 0.101\n",
            "epoch: [95] loss: 0.100\n",
            "epoch: [96] loss: 0.103\n",
            "epoch: [97] loss: 0.099\n",
            "epoch: [98] loss: 0.096\n",
            "epoch: [99] loss: 0.095\n",
            "epoch: [100] loss: 0.094\n",
            "epoch: [101] loss: 0.093\n",
            "epoch: [102] loss: 0.093\n",
            "epoch: [103] loss: 0.093\n",
            "epoch: [104] loss: 0.090\n",
            "epoch: [105] loss: 0.089\n",
            "epoch: [106] loss: 0.088\n",
            "epoch: [107] loss: 0.088\n",
            "epoch: [108] loss: 0.088\n",
            "epoch: [109] loss: 0.087\n",
            "epoch: [110] loss: 0.085\n",
            "epoch: [111] loss: 0.085\n",
            "epoch: [112] loss: 0.085\n",
            "epoch: [113] loss: 0.083\n",
            "epoch: [114] loss: 0.082\n",
            "epoch: [115] loss: 0.082\n",
            "epoch: [116] loss: 0.082\n",
            "epoch: [117] loss: 0.084\n",
            "epoch: [118] loss: 0.081\n",
            "epoch: [119] loss: 0.080\n",
            "epoch: [120] loss: 0.079\n",
            "epoch: [121] loss: 0.077\n",
            "epoch: [122] loss: 0.078\n",
            "epoch: [123] loss: 0.078\n",
            "epoch: [124] loss: 0.080\n",
            "epoch: [125] loss: 0.077\n",
            "epoch: [126] loss: 0.076\n",
            "epoch: [127] loss: 0.076\n",
            "epoch: [128] loss: 0.074\n",
            "epoch: [129] loss: 0.074\n",
            "epoch: [130] loss: 0.075\n",
            "epoch: [131] loss: 0.074\n",
            "epoch: [132] loss: 0.074\n",
            "epoch: [133] loss: 0.072\n",
            "epoch: [134] loss: 0.071\n",
            "epoch: [135] loss: 0.071\n",
            "epoch: [136] loss: 0.070\n",
            "epoch: [137] loss: 0.071\n",
            "epoch: [138] loss: 0.071\n",
            "epoch: [139] loss: 0.069\n",
            "epoch: [140] loss: 0.069\n",
            "epoch: [141] loss: 0.070\n",
            "epoch: [142] loss: 0.069\n",
            "epoch: [143] loss: 0.068\n",
            "epoch: [144] loss: 0.069\n",
            "epoch: [145] loss: 0.068\n",
            "epoch: [146] loss: 0.067\n",
            "epoch: [147] loss: 0.067\n",
            "epoch: [148] loss: 0.067\n",
            "epoch: [149] loss: 0.066\n",
            "epoch: [150] loss: 0.065\n",
            "epoch: [151] loss: 0.066\n",
            "epoch: [152] loss: 0.065\n",
            "epoch: [153] loss: 0.065\n",
            "epoch: [154] loss: 0.064\n",
            "epoch: [155] loss: 0.064\n",
            "epoch: [156] loss: 0.064\n",
            "epoch: [157] loss: 0.064\n",
            "epoch: [158] loss: 0.064\n",
            "epoch: [159] loss: 0.062\n",
            "epoch: [160] loss: 0.062\n",
            "epoch: [161] loss: 0.062\n",
            "epoch: [162] loss: 0.062\n",
            "epoch: [163] loss: 0.062\n",
            "epoch: [164] loss: 0.062\n",
            "epoch: [165] loss: 0.061\n",
            "epoch: [166] loss: 0.061\n",
            "epoch: [167] loss: 0.061\n",
            "epoch: [168] loss: 0.061\n",
            "epoch: [169] loss: 0.061\n",
            "epoch: [170] loss: 0.060\n",
            "epoch: [171] loss: 0.060\n",
            "epoch: [172] loss: 0.060\n",
            "epoch: [173] loss: 0.059\n",
            "epoch: [174] loss: 0.059\n",
            "epoch: [175] loss: 0.059\n",
            "epoch: [176] loss: 0.058\n",
            "epoch: [177] loss: 0.058\n",
            "epoch: [178] loss: 0.058\n",
            "epoch: [179] loss: 0.059\n",
            "epoch: [180] loss: 0.057\n",
            "epoch: [181] loss: 0.058\n",
            "epoch: [182] loss: 0.057\n",
            "epoch: [183] loss: 0.056\n",
            "epoch: [184] loss: 0.057\n",
            "epoch: [185] loss: 0.056\n",
            "epoch: [186] loss: 0.056\n",
            "epoch: [187] loss: 0.057\n",
            "epoch: [188] loss: 0.055\n",
            "epoch: [189] loss: 0.056\n",
            "epoch: [190] loss: 0.056\n",
            "epoch: [191] loss: 0.055\n",
            "epoch: [192] loss: 0.056\n",
            "epoch: [193] loss: 0.055\n",
            "epoch: [194] loss: 0.055\n",
            "epoch: [195] loss: 0.054\n",
            "epoch: [196] loss: 0.055\n",
            "epoch: [197] loss: 0.054\n",
            "epoch: [198] loss: 0.055\n",
            "epoch: [199] loss: 0.053\n",
            "epoch: [200] loss: 0.054\n",
            "epoch: [201] loss: 0.054\n",
            "epoch: [202] loss: 0.053\n",
            "epoch: [203] loss: 0.054\n",
            "epoch: [204] loss: 0.053\n",
            "epoch: [205] loss: 0.053\n",
            "epoch: [206] loss: 0.052\n",
            "epoch: [207] loss: 0.053\n",
            "epoch: [208] loss: 0.052\n",
            "epoch: [209] loss: 0.053\n",
            "epoch: [210] loss: 0.052\n",
            "epoch: [211] loss: 0.052\n",
            "epoch: [212] loss: 0.052\n",
            "epoch: [213] loss: 0.052\n",
            "epoch: [214] loss: 0.052\n",
            "epoch: [215] loss: 0.051\n",
            "epoch: [216] loss: 0.052\n",
            "epoch: [217] loss: 0.051\n",
            "epoch: [218] loss: 0.051\n",
            "epoch: [219] loss: 0.051\n",
            "epoch: [220] loss: 0.051\n",
            "epoch: [221] loss: 0.051\n",
            "epoch: [222] loss: 0.050\n",
            "epoch: [223] loss: 0.051\n",
            "epoch: [224] loss: 0.051\n",
            "epoch: [225] loss: 0.050\n",
            "epoch: [226] loss: 0.050\n",
            "epoch: [227] loss: 0.050\n",
            "epoch: [228] loss: 0.050\n",
            "epoch: [229] loss: 0.050\n",
            "epoch: [230] loss: 0.050\n",
            "epoch: [231] loss: 0.050\n",
            "epoch: [232] loss: 0.049\n",
            "epoch: [233] loss: 0.050\n",
            "epoch: [234] loss: 0.049\n",
            "epoch: [235] loss: 0.050\n",
            "epoch: [236] loss: 0.049\n",
            "epoch: [237] loss: 0.050\n",
            "epoch: [238] loss: 0.048\n",
            "epoch: [239] loss: 0.049\n",
            "epoch: [240] loss: 0.049\n",
            "epoch: [241] loss: 0.049\n",
            "epoch: [242] loss: 0.049\n",
            "epoch: [243] loss: 0.048\n",
            "epoch: [244] loss: 0.049\n",
            "epoch: [245] loss: 0.048\n",
            "epoch: [246] loss: 0.048\n",
            "epoch: [247] loss: 0.048\n",
            "epoch: [248] loss: 0.049\n",
            "epoch: [249] loss: 0.048\n",
            "epoch: [250] loss: 0.048\n",
            "epoch: [251] loss: 0.048\n",
            "epoch: [252] loss: 0.048\n",
            "epoch: [253] loss: 0.048\n",
            "epoch: [254] loss: 0.047\n",
            "epoch: [255] loss: 0.048\n",
            "epoch: [256] loss: 0.047\n",
            "epoch: [257] loss: 0.047\n",
            "epoch: [258] loss: 0.047\n",
            "epoch: [259] loss: 0.047\n",
            "epoch: [260] loss: 0.047\n",
            "epoch: [261] loss: 0.047\n",
            "epoch: [262] loss: 0.047\n",
            "epoch: [263] loss: 0.047\n",
            "epoch: [264] loss: 0.046\n",
            "epoch: [265] loss: 0.047\n",
            "epoch: [266] loss: 0.046\n",
            "epoch: [267] loss: 0.047\n",
            "epoch: [268] loss: 0.047\n",
            "epoch: [269] loss: 0.046\n",
            "epoch: [270] loss: 0.047\n",
            "epoch: [271] loss: 0.046\n",
            "epoch: [272] loss: 0.047\n",
            "epoch: [273] loss: 0.046\n",
            "epoch: [274] loss: 0.046\n",
            "epoch: [275] loss: 0.046\n",
            "epoch: [276] loss: 0.046\n",
            "epoch: [277] loss: 0.045\n",
            "epoch: [278] loss: 0.046\n",
            "epoch: [279] loss: 0.045\n",
            "epoch: [280] loss: 0.045\n",
            "epoch: [281] loss: 0.045\n",
            "epoch: [282] loss: 0.045\n",
            "epoch: [283] loss: 0.045\n",
            "epoch: [284] loss: 0.045\n",
            "epoch: [285] loss: 0.045\n",
            "epoch: [286] loss: 0.044\n",
            "epoch: [287] loss: 0.045\n",
            "epoch: [288] loss: 0.045\n",
            "epoch: [289] loss: 0.045\n",
            "epoch: [290] loss: 0.045\n",
            "epoch: [291] loss: 0.044\n",
            "epoch: [292] loss: 0.044\n",
            "epoch: [293] loss: 0.045\n",
            "epoch: [294] loss: 0.044\n",
            "epoch: [295] loss: 0.044\n",
            "epoch: [296] loss: 0.044\n",
            "epoch: [297] loss: 0.044\n",
            "epoch: [298] loss: 0.044\n",
            "epoch: [299] loss: 0.044\n",
            "epoch: [300] loss: 0.044\n",
            "epoch: [301] loss: 0.044\n",
            "epoch: [302] loss: 0.044\n",
            "epoch: [303] loss: 0.044\n",
            "epoch: [304] loss: 0.044\n",
            "epoch: [305] loss: 0.044\n",
            "epoch: [306] loss: 0.044\n",
            "epoch: [307] loss: 0.043\n",
            "epoch: [308] loss: 0.044\n",
            "epoch: [309] loss: 0.044\n",
            "epoch: [310] loss: 0.044\n",
            "epoch: [311] loss: 0.044\n",
            "epoch: [312] loss: 0.044\n",
            "epoch: [313] loss: 0.044\n",
            "epoch: [314] loss: 0.044\n",
            "epoch: [315] loss: 0.043\n",
            "epoch: [316] loss: 0.043\n",
            "epoch: [317] loss: 0.043\n",
            "epoch: [318] loss: 0.043\n",
            "epoch: [319] loss: 0.043\n",
            "epoch: [320] loss: 0.043\n",
            "epoch: [321] loss: 0.043\n",
            "epoch: [322] loss: 0.043\n",
            "epoch: [323] loss: 0.043\n",
            "epoch: [324] loss: 0.043\n",
            "epoch: [325] loss: 0.043\n",
            "epoch: [326] loss: 0.043\n",
            "epoch: [327] loss: 0.043\n",
            "epoch: [328] loss: 0.043\n",
            "epoch: [329] loss: 0.043\n",
            "epoch: [330] loss: 0.043\n",
            "epoch: [331] loss: 0.043\n",
            "epoch: [332] loss: 0.043\n",
            "epoch: [333] loss: 0.043\n",
            "epoch: [334] loss: 0.043\n",
            "epoch: [335] loss: 0.043\n",
            "epoch: [336] loss: 0.043\n",
            "epoch: [337] loss: 0.043\n",
            "epoch: [338] loss: 0.043\n",
            "epoch: [339] loss: 0.043\n",
            "epoch: [340] loss: 0.042\n",
            "epoch: [341] loss: 0.043\n",
            "epoch: [342] loss: 0.043\n",
            "epoch: [343] loss: 0.042\n",
            "epoch: [344] loss: 0.042\n",
            "epoch: [345] loss: 0.043\n",
            "epoch: [346] loss: 0.042\n",
            "epoch: [347] loss: 0.043\n",
            "epoch: [348] loss: 0.043\n",
            "epoch: [349] loss: 0.042\n",
            "epoch: [350] loss: 0.042\n",
            "epoch: [351] loss: 0.042\n",
            "epoch: [352] loss: 0.042\n",
            "epoch: [353] loss: 0.042\n",
            "epoch: [354] loss: 0.042\n",
            "epoch: [355] loss: 0.042\n",
            "epoch: [356] loss: 0.042\n",
            "epoch: [357] loss: 0.042\n",
            "epoch: [358] loss: 0.042\n",
            "epoch: [359] loss: 0.042\n",
            "epoch: [360] loss: 0.042\n",
            "epoch: [361] loss: 0.042\n",
            "epoch: [362] loss: 0.042\n",
            "epoch: [363] loss: 0.042\n",
            "epoch: [364] loss: 0.042\n",
            "epoch: [365] loss: 0.042\n",
            "epoch: [366] loss: 0.042\n",
            "epoch: [367] loss: 0.042\n",
            "epoch: [368] loss: 0.042\n",
            "epoch: [369] loss: 0.042\n",
            "epoch: [370] loss: 0.042\n",
            "epoch: [371] loss: 0.042\n",
            "epoch: [372] loss: 0.041\n",
            "epoch: [373] loss: 0.042\n",
            "epoch: [374] loss: 0.041\n",
            "epoch: [375] loss: 0.042\n",
            "epoch: [376] loss: 0.042\n",
            "epoch: [377] loss: 0.041\n",
            "epoch: [378] loss: 0.042\n",
            "epoch: [379] loss: 0.041\n",
            "epoch: [380] loss: 0.042\n",
            "epoch: [381] loss: 0.041\n",
            "epoch: [382] loss: 0.041\n",
            "epoch: [383] loss: 0.041\n",
            "epoch: [384] loss: 0.041\n",
            "epoch: [385] loss: 0.041\n",
            "epoch: [386] loss: 0.042\n",
            "epoch: [387] loss: 0.041\n",
            "epoch: [388] loss: 0.041\n",
            "epoch: [389] loss: 0.041\n",
            "epoch: [390] loss: 0.041\n",
            "epoch: [391] loss: 0.041\n",
            "epoch: [392] loss: 0.041\n",
            "epoch: [393] loss: 0.041\n",
            "epoch: [394] loss: 0.041\n",
            "epoch: [395] loss: 0.041\n",
            "epoch: [396] loss: 0.041\n",
            "epoch: [397] loss: 0.041\n",
            "epoch: [398] loss: 0.041\n",
            "epoch: [399] loss: 0.041\n",
            "epoch: [400] loss: 0.041\n",
            "epoch: [401] loss: 0.041\n",
            "epoch: [402] loss: 0.041\n",
            "epoch: [403] loss: 0.041\n",
            "epoch: [404] loss: 0.041\n",
            "epoch: [405] loss: 0.041\n",
            "epoch: [406] loss: 0.041\n",
            "epoch: [407] loss: 0.041\n",
            "epoch: [408] loss: 0.041\n",
            "epoch: [409] loss: 0.041\n",
            "epoch: [410] loss: 0.041\n",
            "epoch: [411] loss: 0.041\n",
            "epoch: [412] loss: 0.041\n",
            "epoch: [413] loss: 0.041\n",
            "epoch: [414] loss: 0.041\n",
            "epoch: [415] loss: 0.041\n",
            "epoch: [416] loss: 0.040\n",
            "epoch: [417] loss: 0.041\n",
            "epoch: [418] loss: 0.041\n",
            "epoch: [419] loss: 0.041\n",
            "epoch: [420] loss: 0.041\n",
            "epoch: [421] loss: 0.041\n",
            "epoch: [422] loss: 0.041\n",
            "epoch: [423] loss: 0.041\n",
            "epoch: [424] loss: 0.040\n",
            "epoch: [425] loss: 0.041\n",
            "epoch: [426] loss: 0.040\n",
            "epoch: [427] loss: 0.040\n",
            "epoch: [428] loss: 0.041\n",
            "epoch: [429] loss: 0.041\n",
            "epoch: [430] loss: 0.040\n",
            "epoch: [431] loss: 0.041\n",
            "epoch: [432] loss: 0.041\n",
            "epoch: [433] loss: 0.040\n",
            "epoch: [434] loss: 0.041\n",
            "epoch: [435] loss: 0.041\n",
            "epoch: [436] loss: 0.040\n",
            "epoch: [437] loss: 0.040\n",
            "epoch: [438] loss: 0.041\n",
            "epoch: [439] loss: 0.040\n",
            "epoch: [440] loss: 0.040\n",
            "epoch: [441] loss: 0.040\n",
            "epoch: [442] loss: 0.041\n",
            "epoch: [443] loss: 0.040\n",
            "epoch: [444] loss: 0.040\n",
            "epoch: [445] loss: 0.040\n",
            "epoch: [446] loss: 0.040\n",
            "epoch: [447] loss: 0.040\n",
            "epoch: [448] loss: 0.040\n",
            "epoch: [449] loss: 0.040\n",
            "epoch: [450] loss: 0.040\n",
            "epoch: [451] loss: 0.040\n",
            "epoch: [452] loss: 0.040\n",
            "epoch: [453] loss: 0.040\n",
            "epoch: [454] loss: 0.040\n",
            "epoch: [455] loss: 0.040\n",
            "epoch: [456] loss: 0.040\n",
            "epoch: [457] loss: 0.040\n",
            "epoch: [458] loss: 0.040\n",
            "epoch: [459] loss: 0.040\n",
            "epoch: [460] loss: 0.040\n",
            "epoch: [461] loss: 0.040\n",
            "epoch: [462] loss: 0.040\n",
            "epoch: [463] loss: 0.040\n",
            "epoch: [464] loss: 0.040\n",
            "epoch: [465] loss: 0.040\n",
            "epoch: [466] loss: 0.040\n",
            "epoch: [467] loss: 0.040\n",
            "epoch: [468] loss: 0.040\n",
            "epoch: [469] loss: 0.040\n",
            "epoch: [470] loss: 0.040\n",
            "epoch: [471] loss: 0.040\n",
            "epoch: [472] loss: 0.040\n",
            "epoch: [473] loss: 0.040\n",
            "epoch: [474] loss: 0.040\n",
            "epoch: [475] loss: 0.040\n",
            "epoch: [476] loss: 0.040\n",
            "epoch: [477] loss: 0.040\n",
            "epoch: [478] loss: 0.040\n",
            "epoch: [479] loss: 0.040\n",
            "epoch: [480] loss: 0.040\n",
            "epoch: [481] loss: 0.040\n",
            "epoch: [482] loss: 0.040\n",
            "epoch: [483] loss: 0.040\n",
            "epoch: [484] loss: 0.040\n",
            "epoch: [485] loss: 0.040\n",
            "epoch: [486] loss: 0.040\n",
            "epoch: [487] loss: 0.040\n",
            "epoch: [488] loss: 0.040\n",
            "epoch: [489] loss: 0.040\n",
            "epoch: [490] loss: 0.040\n",
            "epoch: [491] loss: 0.040\n",
            "epoch: [492] loss: 0.040\n",
            "epoch: [493] loss: 0.040\n",
            "epoch: [494] loss: 0.040\n",
            "epoch: [495] loss: 0.040\n",
            "epoch: [496] loss: 0.040\n",
            "epoch: [497] loss: 0.040\n",
            "epoch: [498] loss: 0.040\n",
            "epoch: [499] loss: 0.039\n",
            "epoch: [500] loss: 0.040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-214-a42e99d0a5ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mwhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mwhere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31RVViMkYM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d24eb419-d87e-4846-d6bb-3c071ba5ab06"
      },
      "source": [
        "analysis_data = np.array(analysis_data)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(np.arange(0,epoch+1,1),analysis_data[:,0],label=\"ftpt\")\n",
        "plt.plot(np.arange(0,epoch+1,1),analysis_data[:,1],label=\"ffpt\")\n",
        "plt.plot(np.arange(0,epoch+1,1),analysis_data[:,2],label=\"ftpf\")\n",
        "plt.plot(np.arange(0,epoch+1,1),analysis_data[:,3],label=\"ffpf\")\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.savefig(\"trends_synthetic_300_300.png\",bbox_inches=\"tight\")\n",
        "plt.savefig(\"trends_synthetic_300_300.pdf\",bbox_inches=\"tight\")\n"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mag3jZ-LMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e14cb2-da6c-4979-c298-97d9653ec862"
      },
      "source": [
        "analysis_data[-1,:2]/3000"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.67433333, 0.32566667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSxFtBWQ1M8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0facd282-b4ca-493b-f122-a4cac7e619d1"
      },
      "source": [
        "running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion,k)\r\n",
        "print(running_loss, anls_data)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.039780627803117655 [2023, 977, 0, 0, 2877, 123]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncIi9Jc92a4u"
      },
      "source": [
        "what.eval()\r\n",
        "where.eval()\r\n",
        "alphas = []\r\n",
        "max_alpha =[]\r\n",
        "alpha_ftpt=[]\r\n",
        "alpha_ffpt=[]\r\n",
        "alpha_ftpf=[]\r\n",
        "alpha_ffpf=[]\r\n",
        "argmax_more_than_half=0\r\n",
        "argmax_less_than_half=0\r\n",
        "cnt =0\r\n",
        "with torch.no_grad():\r\n",
        "  for i, data in enumerate(train_loader, 0):\r\n",
        "    inputs, labels, fidx = data\r\n",
        "    inputs = inputs.double()\r\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\r\n",
        "    avg, alphas = where(inputs)\r\n",
        "    outputs = what(avg)\r\n",
        "    _, predicted = torch.max(outputs.data, 1)\r\n",
        "    batch = len(predicted)\r\n",
        "    mx,_ = torch.max(alphas,1)\r\n",
        "    max_alpha.append(mx.cpu().detach().numpy())\r\n",
        "    for j in range (batch):\r\n",
        "      cnt+=1\r\n",
        "      focus = torch.argmax(alphas[j]).item()\r\n",
        "      if alphas[j][focus] >= 0.5 :\r\n",
        "        argmax_more_than_half += 1\r\n",
        "      else:\r\n",
        "        argmax_less_than_half += 1\r\n",
        "\r\n",
        "      if (focus == fidx[j].item() and predicted[j].item() == labels[j].item()):\r\n",
        "          alpha_ftpt.append(alphas[j][focus].item())\r\n",
        "          # print(focus, fore_idx[j].item(), predicted[j].item() , labels[j].item() )\r\n",
        "\r\n",
        "      elif (focus != fidx[j].item() and predicted[j].item() == labels[j].item()):\r\n",
        "          alpha_ffpt.append(alphas[j][focus].item())\r\n",
        "\r\n",
        "      elif (focus == fidx[j].item() and predicted[j].item() != labels[j].item()):\r\n",
        "          alpha_ftpf.append(alphas[j][focus].item())\r\n",
        "\r\n",
        "      elif (focus != fidx[j].item() and predicted[j].item() != labels[j].item()):\r\n",
        "          alpha_ffpf.append(alphas[j][focus].item())\r\n"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_3nbXu5Zw34",
        "outputId": "b3ae0908-00f9-4182-8d71-01161b80b3c2"
      },
      "source": [
        "np.sum(entropy(alphas.cpu().numpy(), base=2, axis=1))/batch"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39374295061315023"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7vDw6cn1q9M",
        "outputId": "a3fefedb-121e-4fb8-933c-240a537d51a3"
      },
      "source": [
        "np.mean(-np.log2(mx.cpu().detach().numpy()))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2284902571701213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc43myxx2yGI"
      },
      "source": [
        "a = np.array([[0.1,0.9], [0.5, 0.5]])"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUdhdSpB23BL",
        "outputId": "d79f3631-1199-4a6f-fa87-171a5d8ac7d1"
      },
      "source": [
        "-0.1*np.log2(0.1)-0.9*np.log2(0.9)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4689955935892812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9AKu9cRW7Z5",
        "outputId": "cda47ad1-c3d1-4d6d-9583-eaea33bf2c1f"
      },
      "source": [
        "entropy([9/10, 1/10], base=2), entropy([0.5, 0.5], base=2), entropy(a, base=2, axis=1)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.46899559358928117, 1.0, array([0.46899559, 1.        ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyEk81R43gPZ",
        "outputId": "a767a1cd-37ea-40fd-ecbc-b1fc2cdc37df"
      },
      "source": [
        "np.mean(-np.log2(a))"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.368482797083103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPE_6NQd3VHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc01277-752d-46aa-f248-95c12cde9755"
      },
      "source": [
        "max_alpha = np.concatenate(max_alpha,axis=0)\r\n",
        "print(max_alpha.shape, cnt)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000,) 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvgu92LY3Zke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42e5986-52d9-40ab-d81b-a3612ec7c657"
      },
      "source": [
        "np.array(alpha_ftpt).size, np.array(alpha_ffpt).size, np.array(alpha_ftpf).size, np.array(alpha_ffpf).size"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2023, 977, 0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XtgiDDpZ8qH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "c20860e7-b1c3-4e88-e5b2-e3d333638c94"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(max_alpha,bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values histogram\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uTx4G6PeOgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "fa52b051-e817-4357-b7c4-b2e040d9387e"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(np.array(alpha_ftpt),bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values in ftpt\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2Nn1IneTkT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "4ed8e376-6786-4f82-f8ab-17c8189f98ae"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(np.array(alpha_ffpt),bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values in ffpt\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZSZor21zD_f"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0RKRgN8BYux"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": 230,
      "outputs": []
    }
  ]
}