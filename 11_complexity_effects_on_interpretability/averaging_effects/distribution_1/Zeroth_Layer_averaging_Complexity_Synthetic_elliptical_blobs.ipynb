{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Zeroth_Layer_averaging_Complexity_Synthetic_elliptical_blobs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYu3ISwwGks"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEp-LtqiWAf"
      },
      "source": [
        "# mu1 = np.array([3,3,3,3,0])\n",
        "# sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu2 = np.array([4,4,4,4,0])\n",
        "# sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu3 = np.array([10,5,5,10,0])\n",
        "# sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu4 = np.array([-10,-10,-10,-10,0])\n",
        "# sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu5 = np.array([-21,4,4,-21,0])\n",
        "# sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu6 = np.array([-10,18,18,-10,0])\n",
        "# sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu7 = np.array([4,20,4,20,0])\n",
        "# sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu8 = np.array([4,-20,-20,4,0])\n",
        "# sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu9 = np.array([20,20,20,20,0])\n",
        "# sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu10 = np.array([20,-10,-10,20,0])\n",
        "# sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "# sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "# sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "# sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "# sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "# sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "# sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "# sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "# sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "# sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "# sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YDnxeP-2_1V"
      },
      "source": [
        "# X = np.concatenate((sample1,sample2,sample3,sample4,sample5,sample6,sample7,sample8,sample9,sample10),axis=0)\n",
        "# Y = np.concatenate((np.zeros((500,1)),np.ones((500,1)),2*np.ones((500,1)),3*np.ones((500,1)),4*np.ones((500,1)),\n",
        "#                     5*np.ones((500,1)),6*np.ones((500,1)),7*np.ones((500,1)),8*np.ones((500,1)),9*np.ones((500,1))),axis=0).astype(int)\n",
        "# print(X.shape,Y.shape)\n",
        "# plt.scatter(sample1[:,0],sample1[:,1],label=\"class_0\")\n",
        "# plt.scatter(sample2[:,0],sample2[:,1],label=\"class_1\")\n",
        "# plt.scatter(sample3[:,0],sample3[:,1],label=\"class_2\")\n",
        "# plt.scatter(sample4[:,0],sample4[:,1],label=\"class_3\")\n",
        "# plt.scatter(sample5[:,0],sample5[:,1],label=\"class_4\")\n",
        "# plt.scatter(sample6[:,0],sample6[:,1],label=\"class_5\")\n",
        "# plt.scatter(sample7[:,0],sample7[:,1],label=\"class_6\")\n",
        "# plt.scatter(sample8[:,0],sample8[:,1],label=\"class_7\")\n",
        "# plt.scatter(sample9[:,0],sample9[:,1],label=\"class_8\")\n",
        "# plt.scatter(sample10[:,0],sample10[:,1],label=\"class_9\")\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YzqPUf3CHa"
      },
      "source": [
        "# class SyntheticDataset(Dataset):\n",
        "#   \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "#   def __init__(self, x, y):\n",
        "#     \"\"\"\n",
        "#       Args:\n",
        "#         csv_file (string): Path to the csv file with annotations.\n",
        "#         root_dir (string): Directory with all the images.\n",
        "#         transform (callable, optional): Optional transform to be applied\n",
        "#             on a sample.\n",
        "#     \"\"\"\n",
        "#     self.x = x\n",
        "#     self.y = y\n",
        "#     #self.fore_idx = fore_idx\n",
        "    \n",
        "#   def __len__(self):\n",
        "#     return len(self.y)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     return self.x[idx] , self.y[idx] #, self.fore_idx[idx]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mi3nL5-4D7_"
      },
      "source": [
        "# trainset = SyntheticDataset(X,Y)\n",
        "# #\n",
        "\n",
        "# # testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKzc7IgwqoU2"
      },
      "source": [
        "# classes = ('zero','one','two','three','four','five','six','seven','eight','nine')\n",
        "\n",
        "# foreground_classes = {'zero','one','two'}\n",
        "# fg_used = '012'\n",
        "# fg1, fg2, fg3 = 0,1,2\n",
        "\n",
        "\n",
        "# all_classes = {'zero','one','two','three','four','five','six','seven','eight','nine'}\n",
        "# background_classes = all_classes - foreground_classes\n",
        "# background_classes"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT6iKHutquR8"
      },
      "source": [
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKzXkPSq5KU"
      },
      "source": [
        "# dataiter = iter(trainloader)\n",
        "# background_data=[]\n",
        "# background_label=[]\n",
        "# foreground_data=[]\n",
        "# foreground_label=[]\n",
        "# batch_size=100\n",
        "\n",
        "# for i in range(50):\n",
        "#   images, labels = dataiter.next()\n",
        "#   for j in range(batch_size):\n",
        "#     if(classes[labels[j]] in background_classes):\n",
        "#       img = images[j].tolist()\n",
        "#       background_data.append(img)\n",
        "#       background_label.append(labels[j])\n",
        "#     else:\n",
        "#       img = images[j].tolist()\n",
        "#       foreground_data.append(img)\n",
        "#       foreground_label.append(labels[j])\n",
        "            \n",
        "# foreground_data = torch.tensor(foreground_data)\n",
        "# foreground_label = torch.tensor(foreground_label)\n",
        "# background_data = torch.tensor(background_data)\n",
        "# background_label = torch.tensor(background_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChdziOP3rF1G"
      },
      "source": [
        "# def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "#   \"\"\"\n",
        "#   bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "#   fg_idx : index of image to be used as foreground image from foreground data\n",
        "#   fg : at what position/index foreground image has to be stored out of 0-8\n",
        "#   \"\"\"\n",
        "#   image_list=[]\n",
        "#   j=0\n",
        "#   for i in range(9):\n",
        "#     if i != fg:\n",
        "#       image_list.append(background_data[bg_idx[j]])\n",
        "#       j+=1\n",
        "#     else: \n",
        "#       image_list.append(foreground_data[fg_idx])\n",
        "#       label = foreground_label[fg_idx] - fg1  # minus fg1 because our fore ground classes are fg1,fg2,fg3 but we have to store it as 0,1,2\n",
        "#   #image_list = np.concatenate(image_list ,axis=0)\n",
        "#   image_list = torch.stack(image_list) \n",
        "#   return image_list,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASrmPqErIDM"
      },
      "source": [
        "# desired_num = 3000\n",
        "# mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "# fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "# mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "# list_set_labels = [] \n",
        "# for i in range(desired_num):\n",
        "#   set_idx = set()\n",
        "#   np.random.seed(i)\n",
        "#   bg_idx = np.random.randint(0,3500,8)\n",
        "#   set_idx = set(background_label[bg_idx].tolist())\n",
        "#   fg_idx = np.random.randint(0,1500)\n",
        "#   set_idx.add(foreground_label[fg_idx].item())\n",
        "#   fg = np.random.randint(0,9)\n",
        "#   fore_idx.append(fg)\n",
        "#   image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "#   mosaic_list_of_images.append(image_list)\n",
        "#   mosaic_label.append(label)\n",
        "#   list_set_labels.append(set_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGsdvMSzIUK"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm4jv30eD_hl"
      },
      "source": [
        "# data =  [{\"mosaic_list\":mosaic_list_of_images, \"mosaic_label\": mosaic_label, \"fore_idx\":fore_idx}]\r\n",
        "# np.save(\"mosaic_data.npy\",data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN7ItmyIEdnB"
      },
      "source": [
        "data = np.load(\"mosaic_data.npy\",allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iifTn7hNEmCU"
      },
      "source": [
        "mosaic_list_of_images = data[0][\"mosaic_list\"]\r\n",
        "mosaic_label = data[0][\"mosaic_label\"]\r\n",
        "fore_idx = data[0][\"fore_idx\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5NPRPmb904"
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN3Bbs8c0fA"
      },
      "source": [
        "class Focus_deep(nn.Module):\n",
        "    '''\n",
        "       deep focus network averaged at zeroth layer\n",
        "       input : elemental data\n",
        "    '''\n",
        "    def __init__(self,inputs,output,K,d):\n",
        "        super(Focus_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.K = K\n",
        "        self.d  = d\n",
        "        self.linear1 = nn.Linear(self.inputs,6)  #,self.output)\n",
        "        self.linear2 = nn.Linear(6,12)\n",
        "        self.linear3 = nn.Linear(12,self.output) \n",
        "    def forward(self,z):\n",
        "        batch = z.shape[0]\n",
        "        x = torch.zeros([batch,self.K],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,self.d], dtype=torch.float64)\n",
        "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        for i in range(self.K):\n",
        "            x[:,i] = self.helper(z[:,i] )[:,0]  # self.d*i:self.d*i+self.d\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(self.K):\n",
        "            x1 = x[:,i]          \n",
        "            y = y+torch.mul(x1[:,None],z[:,i])  # self.d*i:self.d*i+self.d\n",
        "        return y , x \n",
        "    def helper(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = F.relu(self.linear2(x))\n",
        "      x = self.linear3(x)\n",
        "      return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W0oKcClFZY"
      },
      "source": [
        "class Classification_deep(nn.Module):\n",
        "    '''\n",
        "       input : elemental data\n",
        "       deep classification module data averaged at zeroth layer\n",
        "    '''\n",
        "    def __init__(self,inputs,output):\n",
        "        super(Classification_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.linear1 = nn.Linear(self.inputs,6)\n",
        "        self.linear2 = nn.Linear(6,12)\n",
        "        self.linear3 = nn.Linear(12,self.output)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = F.relu(self.linear2(x))\n",
        "      x = self.linear3(x)\n",
        "      return x    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAfQnNwgFYX"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,where,criter):\n",
        "  what.eval()\n",
        "  where.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx = data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      avg,alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9HQJMzxBhp"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOfxUJZ_eFKw"
      },
      "source": [
        "number_runs = 20\n",
        "FTPT_analysis = pd.DataFrame(columns = [\"FTPT\",\"FFPT\", \"FTPF\",\"FFPF\"])\n",
        "for n in range(number_runs):\n",
        "  print(\"--\"*40)\n",
        "  \n",
        "  # instantiate focus and classification Model\n",
        "  torch.manual_seed(n)\n",
        "  where = Focus_deep(5,1,9,5).double()\n",
        "  torch.manual_seed(n)\n",
        "  what = Classification_deep(5,3).double()\n",
        "  where = where.to(\"cuda\")\n",
        "  what = what.to(\"cuda\")\n",
        "\n",
        "\n",
        "\n",
        "  # instantiate optimizer\n",
        "  optimizer_where = optim.Adam(where.parameters(),lr =0.01)\n",
        "  optimizer_what = optim.Adam(what.parameters(), lr=0.01)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  acti = []\n",
        "  analysis_data = []\n",
        "  loss_curi = []\n",
        "  epochs = 2500\n",
        "\n",
        "\n",
        "  # calculate zeroth epoch loss and FTPT values\n",
        "  running_loss,anlys_data = calculate_attn_loss(train_loader,what,where,criterion)\n",
        "  loss_curi.append(running_loss)\n",
        "  analysis_data.append(anlys_data)\n",
        "\n",
        "  print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "\n",
        "  # training starts \n",
        "  for epoch in range(epochs): # loop over the dataset multiple times\n",
        "    ep_lossi = []\n",
        "    running_loss = 0.0\n",
        "    what.train()\n",
        "    where.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      # get the inputs\n",
        "      inputs, labels,_ = data\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer_where.zero_grad()\n",
        "      optimizer_what.zero_grad()\n",
        "      \n",
        "      # forward + backward + optimize\n",
        "      avg, alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      loss.backward()\n",
        "      optimizer_where.step()\n",
        "      optimizer_what.step()\n",
        "\n",
        "    running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion)\n",
        "    analysis_data.append(anls_data)\n",
        "    print('epoch: [%d] loss: %.3f' %(epoch + 1,running_loss)) \n",
        "    loss_curi.append(running_loss)   #loss per epoch\n",
        "    if running_loss<=0.01:\n",
        "      break\n",
        "  print('Finished Training run ' +str(n))\n",
        "  analysis_data = np.array(analysis_data)\n",
        "  FTPT_analysis.loc[n] = analysis_data[-1,:4]/30\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "      images, labels,_ = data\n",
        "      images = images.double()\n",
        "      images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "      avg, alpha = where(images)\n",
        "      outputs  = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31RVViMkYM-"
      },
      "source": [
        "# plt.figure(figsize=(6,6))\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,0],label=\"ftpt\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,1],label=\"ffpt\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,2],label=\"ftpf\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,3],label=\"ffpf\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEabNK9Q1bTE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ed08c885-50c2-4fad-d5a4-0d03fd2d1571"
      },
      "source": [
        "plt.plot(loss_curi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0359821590>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBbboK0mtLTL",
        "outputId": "2c834ba8-79dc-4427-fbdd-36c1fd201ba4"
      },
      "source": [
        "np.mean(np.array(FTPT_analysis),axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.85100000e+01, 1.14233333e+01, 6.50000000e-02, 1.66666667e-03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYS7jRsCz30j"
      },
      "source": [
        "FTPT_analysis.to_csv(\"synthetic_zeroth.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwzQFzul37sQ"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "PzR8ISPlOSbP",
        "outputId": "be8af6dc-79d2-4dee-bdc9-650630ee69af"
      },
      "source": [
        "FTPT_analysis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FTPT</th>\n",
              "      <th>FFPT</th>\n",
              "      <th>FTPF</th>\n",
              "      <th>FFPF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67.833333</td>\n",
              "      <td>32.100000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.500000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84.200000</td>\n",
              "      <td>15.533333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>99.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>94.800000</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>68.000000</td>\n",
              "      <td>31.933333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>65.966667</td>\n",
              "      <td>33.833333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>67.900000</td>\n",
              "      <td>32.066667</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>98.333333</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>99.833333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>83.266667</td>\n",
              "      <td>16.566667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>67.133333</td>\n",
              "      <td>32.700000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>82.633333</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          FTPT       FFPT      FTPF      FFPF\n",
              "0    67.833333  32.100000  0.066667  0.000000\n",
              "1    90.500000   9.300000  0.200000  0.000000\n",
              "2    84.200000  15.533333  0.266667  0.000000\n",
              "3   100.000000   0.000000  0.000000  0.000000\n",
              "4    99.800000   0.200000  0.000000  0.000000\n",
              "5   100.000000   0.000000  0.000000  0.000000\n",
              "6    94.800000   5.200000  0.000000  0.000000\n",
              "7    68.000000  31.933333  0.066667  0.000000\n",
              "8    65.966667  33.833333  0.200000  0.000000\n",
              "9    67.900000  32.066667  0.033333  0.000000\n",
              "10  100.000000   0.000000  0.000000  0.000000\n",
              "11   98.333333   1.666667  0.000000  0.000000\n",
              "12  100.000000   0.000000  0.000000  0.000000\n",
              "13  100.000000   0.000000  0.000000  0.000000\n",
              "14   99.833333   0.166667  0.000000  0.000000\n",
              "15  100.000000   0.000000  0.000000  0.000000\n",
              "16   83.266667  16.566667  0.133333  0.033333\n",
              "17  100.000000   0.000000  0.000000  0.000000\n",
              "18   67.133333  32.700000  0.166667  0.000000\n",
              "19   82.633333  17.200000  0.166667  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JUoGWONAXEk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}