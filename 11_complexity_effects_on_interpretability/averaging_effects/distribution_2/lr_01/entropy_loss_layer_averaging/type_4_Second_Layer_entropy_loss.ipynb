{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "type_4_Second_Layer_entropy_loss.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYu3ISwwGks"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGsdvMSzIUK"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN7ItmyIEdnB"
      },
      "source": [
        "data = np.load(\"type4_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iifTn7hNEmCU"
      },
      "source": [
        "mosaic_list_of_images = data[0][\"mosaic_list\"]\n",
        "mosaic_label = data[0][\"mosaic_label\"]\n",
        "fore_idx = data[0][\"fore_idx\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5NPRPmb904"
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN3Bbs8c0fA"
      },
      "source": [
        "class Focus_deep(nn.Module):\n",
        "    '''\n",
        "       deep focus network averaged at zeroth layer\n",
        "       input : elemental data\n",
        "    '''\n",
        "    def __init__(self,inputs,output,K,d):\n",
        "        super(Focus_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.K = K\n",
        "        self.d  = d\n",
        "        self.linear1 = nn.Linear(self.inputs,50)  #,self.output)\n",
        "        self.linear2 = nn.Linear(50,50)\n",
        "        self.linear3 = nn.Linear(50,self.output) \n",
        "    def forward(self,z):\n",
        "        batch = z.shape[0]\n",
        "        x = torch.zeros([batch,self.K],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,50], dtype=torch.float64)   # number of features of output\n",
        "        features = torch.zeros([batch,self.K,50],dtype=torch.float64)\n",
        "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        features = features.to(\"cuda\")\n",
        "        for i in range(self.K):\n",
        "            alp,ftrs = self.helper(z[:,i] )  # self.d*i:self.d*i+self.d\n",
        "            x[:,i] = alp[:,0]\n",
        "            features[:,i]  = ftrs \n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        log_x = F.log_softmax(x,dim=1)\n",
        "        for i in range(self.K):\n",
        "            x1 = x[:,i]          \n",
        "            y = y+torch.mul(x1[:,None],features[:,i])  # self.d*i:self.d*i+self.d\n",
        "        return y , x,log_x \n",
        "    def helper(self,x):\n",
        "      x = self.linear1(x)\n",
        "      x = F.relu(x) \n",
        "      x = self.linear2(x)\n",
        "      x1 = F.tanh(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.linear3(x)\n",
        "      #print(x1.shape)\n",
        "      return x,x1\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W0oKcClFZY"
      },
      "source": [
        "class Classification_deep(nn.Module):\n",
        "    '''\n",
        "       input : elemental data\n",
        "       deep classification module data averaged at zeroth layer\n",
        "    '''\n",
        "    def __init__(self,inputs,output):\n",
        "        super(Classification_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.linear1 = nn.Linear(self.inputs,50)\n",
        "        #self.linear2 = nn.Linear(50,50)\n",
        "        self.linear2 = nn.Linear(50,self.output)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      #x = F.relu(self.linear2(x))\n",
        "      x = self.linear2(x)\n",
        "      return x    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyBerjJ5J7Gl"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "def my_cross_entropy(x, y,alpha,log_alpha,k):\n",
        "    loss = criterion(x,y)\n",
        "    b = -1.0* alpha * log_alpha\n",
        "    b =  torch.mean(torch.sum(b,dim=1))\n",
        "    closs = loss\n",
        "    entropy = b \n",
        "    loss = (1-k)*loss + ((k)*b)\n",
        "    return loss,closs,entropy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAfQnNwgFYX"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,where,k):\n",
        "  what.eval()\n",
        "  where.eval()\n",
        "  r_loss = 0\n",
        "  cc_loss = 0\n",
        "  cc_entropy = 0 \n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx = data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      avg,alpha,log_alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss,closs,entropy = my_cross_entropy(outputs,labels,alpha,log_alpha,k)\n",
        "      r_loss += loss.item()\n",
        "      cc_loss += closs.item()\n",
        "      cc_entropy += entropy.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,cc_loss/i,cc_entropy/i,analysis"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9HQJMzxBhp"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOfxUJZ_eFKw",
        "outputId": "6beb7c29-2781-4f48-8931-56fa3a77990c"
      },
      "source": [
        "number_runs = 20\n",
        "FTPT_analysis = pd.DataFrame(columns = [\"FTPT\",\"FFPT\", \"FTPF\",\"FFPF\"])\n",
        "k = 0\n",
        "r_loss = []\n",
        "r_closs = [] \n",
        "r_centropy = []\n",
        "for n in range(number_runs):\n",
        "  print(\"--\"*40)\n",
        "  \n",
        "  # instantiate focus and classification Model\n",
        "  torch.manual_seed(n)\n",
        "  where = Focus_deep(2,1,9,2).double()\n",
        "  torch.manual_seed(n)\n",
        "  what = Classification_deep(50,3).double()\n",
        "  where = where.to(\"cuda\")\n",
        "  what = what.to(\"cuda\")\n",
        "\n",
        "\n",
        "\n",
        "  # instantiate optimizer\n",
        "  optimizer_where = optim.Adam(where.parameters(),lr =0.01)#,momentum=0.9)\n",
        "  optimizer_what = optim.Adam(what.parameters(), lr=0.01)#,momentum=0.9)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  acti = []\n",
        "  analysis_data = []\n",
        "  loss_curi = []\n",
        "  cc_loss_curi = []\n",
        "  cc_entropy_curi = []\n",
        "  epochs = 2500\n",
        "\n",
        "\n",
        "  # calculate zeroth epoch loss and FTPT values\n",
        "  running_loss,_,_,anlys_data = calculate_attn_loss(train_loader,what,where,k)\n",
        "  loss_curi.append(running_loss)\n",
        "  analysis_data.append(anlys_data)\n",
        "\n",
        "  print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "\n",
        "  # training starts \n",
        "  for epoch in range(epochs): # loop over the dataset multiple times\n",
        "    ep_lossi = []\n",
        "    running_loss = 0.0\n",
        "    what.train()\n",
        "    where.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      # get the inputs\n",
        "      inputs, labels,_ = data\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer_where.zero_grad()\n",
        "      optimizer_what.zero_grad()\n",
        "      \n",
        "      # forward + backward + optimize\n",
        "      avg, alpha,log_alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      loss,_,_ = my_cross_entropy( outputs,labels,alpha,log_alpha,k)\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      loss.backward()\n",
        "      optimizer_where.step()\n",
        "      optimizer_what.step()\n",
        "\n",
        "    running_loss,ccloss,ccentropy,anls_data = calculate_attn_loss(train_loader,what,where,k)\n",
        "    analysis_data.append(anls_data)\n",
        "    print('epoch: [%d] loss: %.3f celoss: %.3f entropy: %.3f' %(epoch + 1,running_loss,ccloss,ccentropy)) \n",
        "    loss_curi.append(running_loss)   #loss per epoch\n",
        "    cc_loss_curi.append(ccloss)\n",
        "    cc_entropy_curi.append(ccentropy)\n",
        "    if running_loss<=0.01:\n",
        "      break\n",
        "  print('Finished Training run ' +str(n))\n",
        "  analysis_data = np.array(analysis_data)\n",
        "  FTPT_analysis.loc[n] = analysis_data[-1,:4]/30\n",
        "  r_loss.append(np.array(loss_curi))\n",
        "  r_closs.append(np.array(cc_loss_curi))\n",
        "  r_centropy.append(np.array(cc_entropy_curi))\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "      images, labels,_ = data\n",
        "      images = images.double()\n",
        "      images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "      avg, alpha,_ = where(images)\n",
        "      outputs  = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: [1] loss: 1.192 celoss: 1.192 entropy: 2.385\n",
            "epoch: [2] loss: 1.156 celoss: 1.156 entropy: 2.372\n",
            "epoch: [3] loss: 1.039 celoss: 1.039 entropy: 2.312\n",
            "epoch: [4] loss: 0.833 celoss: 0.833 entropy: 2.184\n",
            "epoch: [5] loss: 0.695 celoss: 0.695 entropy: 2.165\n",
            "epoch: [6] loss: 0.526 celoss: 0.526 entropy: 2.114\n",
            "epoch: [7] loss: 0.310 celoss: 0.310 entropy: 2.098\n",
            "epoch: [8] loss: 0.188 celoss: 0.188 entropy: 2.059\n",
            "epoch: [9] loss: 0.051 celoss: 0.051 entropy: 2.021\n",
            "epoch: [10] loss: 0.023 celoss: 0.023 entropy: 2.008\n",
            "epoch: [11] loss: 0.021 celoss: 0.021 entropy: 1.968\n",
            "epoch: [12] loss: 0.025 celoss: 0.025 entropy: 1.991\n",
            "epoch: [13] loss: 0.008 celoss: 0.008 entropy: 1.955\n",
            "Finished Training run 0\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.198\n",
            "epoch: [1] loss: 1.197 celoss: 1.197 entropy: 2.374\n",
            "epoch: [2] loss: 1.182 celoss: 1.182 entropy: 2.359\n",
            "epoch: [3] loss: 1.077 celoss: 1.077 entropy: 2.309\n",
            "epoch: [4] loss: 0.920 celoss: 0.920 entropy: 2.163\n",
            "epoch: [5] loss: 0.716 celoss: 0.716 entropy: 2.173\n",
            "epoch: [6] loss: 0.563 celoss: 0.563 entropy: 2.132\n",
            "epoch: [7] loss: 0.474 celoss: 0.474 entropy: 2.140\n",
            "epoch: [8] loss: 0.271 celoss: 0.271 entropy: 2.073\n",
            "epoch: [9] loss: 0.078 celoss: 0.078 entropy: 1.978\n",
            "epoch: [10] loss: 0.019 celoss: 0.019 entropy: 1.927\n",
            "epoch: [11] loss: 0.006 celoss: 0.006 entropy: 1.860\n",
            "Finished Training run 1\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.221\n",
            "epoch: [1] loss: 1.195 celoss: 1.195 entropy: 2.295\n",
            "epoch: [2] loss: 1.189 celoss: 1.189 entropy: 2.376\n",
            "epoch: [3] loss: 1.148 celoss: 1.148 entropy: 2.359\n",
            "epoch: [4] loss: 1.068 celoss: 1.068 entropy: 2.246\n",
            "epoch: [5] loss: 0.832 celoss: 0.832 entropy: 2.182\n",
            "epoch: [6] loss: 0.616 celoss: 0.616 entropy: 2.171\n",
            "epoch: [7] loss: 0.535 celoss: 0.535 entropy: 2.161\n",
            "epoch: [8] loss: 0.416 celoss: 0.416 entropy: 2.101\n",
            "epoch: [9] loss: 0.272 celoss: 0.272 entropy: 2.062\n",
            "epoch: [10] loss: 0.134 celoss: 0.134 entropy: 2.033\n",
            "epoch: [11] loss: 0.130 celoss: 0.130 entropy: 1.952\n",
            "epoch: [12] loss: 0.064 celoss: 0.064 entropy: 2.000\n",
            "epoch: [13] loss: 0.015 celoss: 0.015 entropy: 1.846\n",
            "epoch: [14] loss: 0.010 celoss: 0.010 entropy: 1.858\n",
            "Finished Training run 2\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.198\n",
            "epoch: [1] loss: 1.196 celoss: 1.196 entropy: 2.387\n",
            "epoch: [2] loss: 1.182 celoss: 1.182 entropy: 2.381\n",
            "epoch: [3] loss: 1.118 celoss: 1.118 entropy: 2.347\n",
            "epoch: [4] loss: 1.060 celoss: 1.060 entropy: 2.136\n",
            "epoch: [5] loss: 0.862 celoss: 0.862 entropy: 2.153\n",
            "epoch: [6] loss: 0.772 celoss: 0.772 entropy: 2.128\n",
            "epoch: [7] loss: 0.552 celoss: 0.552 entropy: 2.145\n",
            "epoch: [8] loss: 0.602 celoss: 0.602 entropy: 2.022\n",
            "epoch: [9] loss: 0.131 celoss: 0.131 entropy: 2.001\n",
            "epoch: [10] loss: 0.056 celoss: 0.056 entropy: 1.960\n",
            "epoch: [11] loss: 0.034 celoss: 0.034 entropy: 1.935\n",
            "epoch: [12] loss: 0.013 celoss: 0.013 entropy: 1.905\n",
            "epoch: [13] loss: 0.007 celoss: 0.007 entropy: 1.887\n",
            "Finished Training run 3\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.198\n",
            "epoch: [1] loss: 1.199 celoss: 1.199 entropy: 2.381\n",
            "epoch: [2] loss: 1.198 celoss: 1.198 entropy: 2.331\n",
            "epoch: [3] loss: 1.194 celoss: 1.194 entropy: 2.365\n",
            "epoch: [4] loss: 1.191 celoss: 1.191 entropy: 2.330\n",
            "epoch: [5] loss: 1.176 celoss: 1.176 entropy: 2.327\n",
            "epoch: [6] loss: 1.140 celoss: 1.140 entropy: 2.258\n",
            "epoch: [7] loss: 1.048 celoss: 1.048 entropy: 2.160\n",
            "epoch: [8] loss: 0.828 celoss: 0.828 entropy: 2.055\n",
            "epoch: [9] loss: 0.664 celoss: 0.664 entropy: 2.059\n",
            "epoch: [10] loss: 0.548 celoss: 0.548 entropy: 2.049\n",
            "epoch: [11] loss: 0.521 celoss: 0.521 entropy: 2.054\n",
            "epoch: [12] loss: 0.468 celoss: 0.468 entropy: 2.023\n",
            "epoch: [13] loss: 0.500 celoss: 0.500 entropy: 2.135\n",
            "epoch: [14] loss: 0.301 celoss: 0.301 entropy: 2.050\n",
            "epoch: [15] loss: 0.244 celoss: 0.244 entropy: 2.007\n",
            "epoch: [16] loss: 0.172 celoss: 0.172 entropy: 1.995\n",
            "epoch: [17] loss: 0.141 celoss: 0.141 entropy: 1.991\n",
            "epoch: [18] loss: 0.049 celoss: 0.049 entropy: 2.066\n",
            "epoch: [19] loss: 0.040 celoss: 0.040 entropy: 1.957\n",
            "epoch: [20] loss: 0.013 celoss: 0.013 entropy: 1.953\n",
            "epoch: [21] loss: 0.015 celoss: 0.015 entropy: 2.013\n",
            "epoch: [22] loss: 0.013 celoss: 0.013 entropy: 1.935\n",
            "epoch: [23] loss: 0.007 celoss: 0.007 entropy: 1.929\n",
            "Finished Training run 4\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.196\n",
            "epoch: [1] loss: 1.205 celoss: 1.205 entropy: 2.378\n",
            "epoch: [2] loss: 1.164 celoss: 1.164 entropy: 2.378\n",
            "epoch: [3] loss: 0.995 celoss: 0.995 entropy: 2.255\n",
            "epoch: [4] loss: 0.817 celoss: 0.817 entropy: 2.108\n",
            "epoch: [5] loss: 0.669 celoss: 0.669 entropy: 2.118\n",
            "epoch: [6] loss: 0.606 celoss: 0.606 entropy: 2.018\n",
            "epoch: [7] loss: 0.382 celoss: 0.382 entropy: 2.010\n",
            "epoch: [8] loss: 0.191 celoss: 0.191 entropy: 1.888\n",
            "epoch: [9] loss: 0.099 celoss: 0.099 entropy: 1.912\n",
            "epoch: [10] loss: 0.082 celoss: 0.082 entropy: 1.800\n",
            "epoch: [11] loss: 0.036 celoss: 0.036 entropy: 1.834\n",
            "epoch: [12] loss: 0.023 celoss: 0.023 entropy: 1.827\n",
            "epoch: [13] loss: 0.014 celoss: 0.014 entropy: 1.816\n",
            "epoch: [14] loss: 0.013 celoss: 0.013 entropy: 1.821\n",
            "epoch: [15] loss: 0.012 celoss: 0.012 entropy: 1.819\n",
            "epoch: [16] loss: 0.007 celoss: 0.007 entropy: 1.832\n",
            "Finished Training run 5\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.205\n",
            "epoch: [1] loss: 1.189 celoss: 1.189 entropy: 2.370\n",
            "epoch: [2] loss: 1.145 celoss: 1.145 entropy: 2.370\n",
            "epoch: [3] loss: 0.963 celoss: 0.963 entropy: 2.238\n",
            "epoch: [4] loss: 0.691 celoss: 0.691 entropy: 2.157\n",
            "epoch: [5] loss: 0.559 celoss: 0.559 entropy: 2.131\n",
            "epoch: [6] loss: 0.511 celoss: 0.511 entropy: 2.128\n",
            "epoch: [7] loss: 0.458 celoss: 0.458 entropy: 2.089\n",
            "epoch: [8] loss: 0.389 celoss: 0.389 entropy: 2.050\n",
            "epoch: [9] loss: 0.255 celoss: 0.255 entropy: 1.978\n",
            "epoch: [10] loss: 0.187 celoss: 0.187 entropy: 1.977\n",
            "epoch: [11] loss: 0.116 celoss: 0.116 entropy: 1.998\n",
            "epoch: [12] loss: 0.081 celoss: 0.081 entropy: 1.955\n",
            "epoch: [13] loss: 0.024 celoss: 0.024 entropy: 1.909\n",
            "epoch: [14] loss: 0.096 celoss: 0.096 entropy: 1.997\n",
            "epoch: [15] loss: 0.027 celoss: 0.027 entropy: 1.900\n",
            "epoch: [16] loss: 0.037 celoss: 0.037 entropy: 1.935\n",
            "epoch: [17] loss: 0.002 celoss: 0.002 entropy: 1.873\n",
            "Finished Training run 6\n",
            "Accuracy of the network on the 3000 train images: 100 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.211\n",
            "epoch: [1] loss: 1.194 celoss: 1.194 entropy: 2.381\n",
            "epoch: [2] loss: 1.181 celoss: 1.181 entropy: 2.370\n",
            "epoch: [3] loss: 1.148 celoss: 1.148 entropy: 2.372\n",
            "epoch: [4] loss: 1.004 celoss: 1.004 entropy: 2.265\n",
            "epoch: [5] loss: 0.821 celoss: 0.821 entropy: 2.127\n",
            "epoch: [6] loss: 0.623 celoss: 0.623 entropy: 2.129\n",
            "epoch: [7] loss: 0.535 celoss: 0.535 entropy: 2.066\n",
            "epoch: [8] loss: 0.499 celoss: 0.499 entropy: 2.104\n",
            "epoch: [9] loss: 0.445 celoss: 0.445 entropy: 2.020\n",
            "epoch: [10] loss: 0.314 celoss: 0.314 entropy: 2.018\n",
            "epoch: [11] loss: 0.145 celoss: 0.145 entropy: 2.030\n",
            "epoch: [12] loss: 0.062 celoss: 0.062 entropy: 2.018\n",
            "epoch: [13] loss: 0.025 celoss: 0.025 entropy: 2.001\n",
            "epoch: [14] loss: 0.015 celoss: 0.015 entropy: 2.001\n",
            "epoch: [15] loss: 0.014 celoss: 0.014 entropy: 1.933\n",
            "epoch: [16] loss: 0.005 celoss: 0.005 entropy: 1.955\n",
            "Finished Training run 7\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.200\n",
            "epoch: [1] loss: 1.192 celoss: 1.192 entropy: 2.388\n",
            "epoch: [2] loss: 1.161 celoss: 1.161 entropy: 2.380\n",
            "epoch: [3] loss: 1.031 celoss: 1.031 entropy: 2.315\n",
            "epoch: [4] loss: 0.872 celoss: 0.872 entropy: 2.196\n",
            "epoch: [5] loss: 0.680 celoss: 0.680 entropy: 2.145\n",
            "epoch: [6] loss: 0.574 celoss: 0.574 entropy: 2.129\n",
            "epoch: [7] loss: 0.558 celoss: 0.558 entropy: 2.116\n",
            "epoch: [8] loss: 0.467 celoss: 0.467 entropy: 2.085\n",
            "epoch: [9] loss: 0.475 celoss: 0.475 entropy: 2.112\n",
            "epoch: [10] loss: 0.357 celoss: 0.357 entropy: 2.037\n",
            "epoch: [11] loss: 0.289 celoss: 0.289 entropy: 1.964\n",
            "epoch: [12] loss: 0.199 celoss: 0.199 entropy: 1.972\n",
            "epoch: [13] loss: 0.079 celoss: 0.079 entropy: 1.933\n",
            "epoch: [14] loss: 0.058 celoss: 0.058 entropy: 1.869\n",
            "epoch: [15] loss: 0.022 celoss: 0.022 entropy: 1.871\n",
            "epoch: [16] loss: 0.012 celoss: 0.012 entropy: 1.844\n",
            "epoch: [17] loss: 0.005 celoss: 0.005 entropy: 1.821\n",
            "Finished Training run 8\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.215\n",
            "epoch: [1] loss: 1.194 celoss: 1.194 entropy: 2.385\n",
            "epoch: [2] loss: 1.171 celoss: 1.171 entropy: 2.373\n",
            "epoch: [3] loss: 1.040 celoss: 1.040 entropy: 2.275\n",
            "epoch: [4] loss: 0.862 celoss: 0.862 entropy: 2.151\n",
            "epoch: [5] loss: 0.682 celoss: 0.682 entropy: 2.119\n",
            "epoch: [6] loss: 0.529 celoss: 0.529 entropy: 2.086\n",
            "epoch: [7] loss: 0.287 celoss: 0.287 entropy: 2.047\n",
            "epoch: [8] loss: 0.153 celoss: 0.153 entropy: 1.959\n",
            "epoch: [9] loss: 0.062 celoss: 0.062 entropy: 1.917\n",
            "epoch: [10] loss: 0.025 celoss: 0.025 entropy: 1.916\n",
            "epoch: [11] loss: 0.028 celoss: 0.028 entropy: 1.924\n",
            "epoch: [12] loss: 0.169 celoss: 0.169 entropy: 1.885\n",
            "epoch: [13] loss: 0.015 celoss: 0.015 entropy: 1.872\n",
            "epoch: [14] loss: 0.036 celoss: 0.036 entropy: 1.946\n",
            "epoch: [15] loss: 0.062 celoss: 0.062 entropy: 1.927\n",
            "epoch: [16] loss: 0.013 celoss: 0.013 entropy: 1.904\n",
            "epoch: [17] loss: 0.009 celoss: 0.009 entropy: 1.821\n",
            "Finished Training run 9\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.226\n",
            "epoch: [1] loss: 1.185 celoss: 1.185 entropy: 2.376\n",
            "epoch: [2] loss: 1.114 celoss: 1.114 entropy: 2.357\n",
            "epoch: [3] loss: 0.986 celoss: 0.986 entropy: 2.157\n",
            "epoch: [4] loss: 0.840 celoss: 0.840 entropy: 2.133\n",
            "epoch: [5] loss: 0.663 celoss: 0.663 entropy: 2.156\n",
            "epoch: [6] loss: 0.556 celoss: 0.556 entropy: 2.141\n",
            "epoch: [7] loss: 0.400 celoss: 0.400 entropy: 2.093\n",
            "epoch: [8] loss: 0.206 celoss: 0.206 entropy: 2.042\n",
            "epoch: [9] loss: 0.341 celoss: 0.341 entropy: 2.030\n",
            "epoch: [10] loss: 0.086 celoss: 0.086 entropy: 1.966\n",
            "epoch: [11] loss: 0.067 celoss: 0.067 entropy: 1.962\n",
            "epoch: [12] loss: 0.017 celoss: 0.017 entropy: 1.960\n",
            "epoch: [13] loss: 0.007 celoss: 0.007 entropy: 1.929\n",
            "Finished Training run 10\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.213\n",
            "epoch: [1] loss: 1.182 celoss: 1.182 entropy: 2.377\n",
            "epoch: [2] loss: 1.119 celoss: 1.119 entropy: 2.338\n",
            "epoch: [3] loss: 1.023 celoss: 1.023 entropy: 2.210\n",
            "epoch: [4] loss: 0.852 celoss: 0.852 entropy: 2.087\n",
            "epoch: [5] loss: 0.711 celoss: 0.711 entropy: 2.082\n",
            "epoch: [6] loss: 0.556 celoss: 0.556 entropy: 2.136\n",
            "epoch: [7] loss: 0.557 celoss: 0.557 entropy: 2.095\n",
            "epoch: [8] loss: 0.428 celoss: 0.428 entropy: 2.024\n",
            "epoch: [9] loss: 0.209 celoss: 0.209 entropy: 1.940\n",
            "epoch: [10] loss: 0.141 celoss: 0.141 entropy: 1.926\n",
            "epoch: [11] loss: 0.065 celoss: 0.065 entropy: 1.920\n",
            "epoch: [12] loss: 0.145 celoss: 0.145 entropy: 1.824\n",
            "epoch: [13] loss: 0.016 celoss: 0.016 entropy: 1.827\n",
            "epoch: [14] loss: 0.012 celoss: 0.012 entropy: 1.843\n",
            "epoch: [15] loss: 0.006 celoss: 0.006 entropy: 1.805\n",
            "Finished Training run 11\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.227\n",
            "epoch: [1] loss: 1.193 celoss: 1.193 entropy: 2.396\n",
            "epoch: [2] loss: 1.181 celoss: 1.181 entropy: 2.389\n",
            "epoch: [3] loss: 1.141 celoss: 1.141 entropy: 2.367\n",
            "epoch: [4] loss: 1.001 celoss: 1.001 entropy: 2.262\n",
            "epoch: [5] loss: 0.726 celoss: 0.726 entropy: 2.127\n",
            "epoch: [6] loss: 0.560 celoss: 0.560 entropy: 2.124\n",
            "epoch: [7] loss: 0.379 celoss: 0.379 entropy: 2.044\n",
            "epoch: [8] loss: 0.234 celoss: 0.234 entropy: 2.057\n",
            "epoch: [9] loss: 0.136 celoss: 0.136 entropy: 2.063\n",
            "epoch: [10] loss: 0.073 celoss: 0.073 entropy: 2.037\n",
            "epoch: [11] loss: 0.041 celoss: 0.041 entropy: 2.010\n",
            "epoch: [12] loss: 0.027 celoss: 0.027 entropy: 2.003\n",
            "epoch: [13] loss: 0.013 celoss: 0.013 entropy: 2.003\n",
            "epoch: [14] loss: 0.009 celoss: 0.009 entropy: 1.980\n",
            "Finished Training run 12\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.200\n",
            "epoch: [1] loss: 1.170 celoss: 1.170 entropy: 2.366\n",
            "epoch: [2] loss: 0.986 celoss: 0.986 entropy: 2.254\n",
            "epoch: [3] loss: 0.717 celoss: 0.717 entropy: 2.132\n",
            "epoch: [4] loss: 0.577 celoss: 0.577 entropy: 2.141\n",
            "epoch: [5] loss: 0.550 celoss: 0.550 entropy: 2.043\n",
            "epoch: [6] loss: 0.122 celoss: 0.122 entropy: 2.017\n",
            "epoch: [7] loss: 0.039 celoss: 0.039 entropy: 2.010\n",
            "epoch: [8] loss: 0.043 celoss: 0.043 entropy: 1.948\n",
            "epoch: [9] loss: 0.132 celoss: 0.132 entropy: 1.932\n",
            "epoch: [10] loss: 0.067 celoss: 0.067 entropy: 1.890\n",
            "epoch: [11] loss: 0.007 celoss: 0.007 entropy: 1.827\n",
            "Finished Training run 13\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.215\n",
            "epoch: [1] loss: 1.184 celoss: 1.184 entropy: 2.359\n",
            "epoch: [2] loss: 1.176 celoss: 1.176 entropy: 2.375\n",
            "epoch: [3] loss: 1.062 celoss: 1.062 entropy: 2.335\n",
            "epoch: [4] loss: 0.856 celoss: 0.856 entropy: 2.237\n",
            "epoch: [5] loss: 0.628 celoss: 0.628 entropy: 2.160\n",
            "epoch: [6] loss: 0.564 celoss: 0.564 entropy: 2.121\n",
            "epoch: [7] loss: 0.550 celoss: 0.550 entropy: 2.147\n",
            "epoch: [8] loss: 0.532 celoss: 0.532 entropy: 2.154\n",
            "epoch: [9] loss: 0.415 celoss: 0.415 entropy: 2.076\n",
            "epoch: [10] loss: 0.295 celoss: 0.295 entropy: 1.979\n",
            "epoch: [11] loss: 0.233 celoss: 0.233 entropy: 1.924\n",
            "epoch: [12] loss: 0.134 celoss: 0.134 entropy: 1.864\n",
            "epoch: [13] loss: 0.053 celoss: 0.053 entropy: 1.871\n",
            "epoch: [14] loss: 0.014 celoss: 0.014 entropy: 1.861\n",
            "epoch: [15] loss: 0.006 celoss: 0.006 entropy: 1.832\n",
            "Finished Training run 14\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.199\n",
            "epoch: [1] loss: 1.204 celoss: 1.204 entropy: 2.328\n",
            "epoch: [2] loss: 1.174 celoss: 1.174 entropy: 2.368\n",
            "epoch: [3] loss: 1.108 celoss: 1.108 entropy: 2.327\n",
            "epoch: [4] loss: 0.921 celoss: 0.921 entropy: 2.226\n",
            "epoch: [5] loss: 0.753 celoss: 0.753 entropy: 2.221\n",
            "epoch: [6] loss: 0.572 celoss: 0.572 entropy: 2.171\n",
            "epoch: [7] loss: 0.515 celoss: 0.515 entropy: 2.110\n",
            "epoch: [8] loss: 0.612 celoss: 0.612 entropy: 2.101\n",
            "epoch: [9] loss: 0.312 celoss: 0.312 entropy: 2.096\n",
            "epoch: [10] loss: 0.170 celoss: 0.170 entropy: 1.987\n",
            "epoch: [11] loss: 0.095 celoss: 0.095 entropy: 1.994\n",
            "epoch: [12] loss: 0.150 celoss: 0.150 entropy: 1.950\n",
            "epoch: [13] loss: 0.021 celoss: 0.021 entropy: 1.906\n",
            "epoch: [14] loss: 0.009 celoss: 0.009 entropy: 1.905\n",
            "Finished Training run 15\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.201\n",
            "epoch: [1] loss: 1.192 celoss: 1.192 entropy: 2.338\n",
            "epoch: [2] loss: 1.177 celoss: 1.177 entropy: 2.376\n",
            "epoch: [3] loss: 1.123 celoss: 1.123 entropy: 2.351\n",
            "epoch: [4] loss: 0.983 celoss: 0.983 entropy: 2.201\n",
            "epoch: [5] loss: 0.813 celoss: 0.813 entropy: 2.126\n",
            "epoch: [6] loss: 0.777 celoss: 0.777 entropy: 2.159\n",
            "epoch: [7] loss: 0.578 celoss: 0.578 entropy: 2.107\n",
            "epoch: [8] loss: 0.449 celoss: 0.449 entropy: 2.109\n",
            "epoch: [9] loss: 0.351 celoss: 0.351 entropy: 2.091\n",
            "epoch: [10] loss: 0.218 celoss: 0.218 entropy: 2.059\n",
            "epoch: [11] loss: 0.139 celoss: 0.139 entropy: 2.045\n",
            "epoch: [12] loss: 0.056 celoss: 0.056 entropy: 1.979\n",
            "epoch: [13] loss: 0.059 celoss: 0.059 entropy: 1.936\n",
            "epoch: [14] loss: 0.021 celoss: 0.021 entropy: 1.906\n",
            "epoch: [15] loss: 0.006 celoss: 0.006 entropy: 1.885\n",
            "Finished Training run 16\n",
            "Accuracy of the network on the 3000 train images: 100 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.201\n",
            "epoch: [1] loss: 1.192 celoss: 1.192 entropy: 2.388\n",
            "epoch: [2] loss: 1.142 celoss: 1.142 entropy: 2.325\n",
            "epoch: [3] loss: 0.985 celoss: 0.985 entropy: 2.218\n",
            "epoch: [4] loss: 0.796 celoss: 0.796 entropy: 2.056\n",
            "epoch: [5] loss: 0.520 celoss: 0.520 entropy: 1.993\n",
            "epoch: [6] loss: 0.349 celoss: 0.349 entropy: 1.855\n",
            "epoch: [7] loss: 0.183 celoss: 0.183 entropy: 1.815\n",
            "epoch: [8] loss: 0.079 celoss: 0.079 entropy: 1.767\n",
            "epoch: [9] loss: 0.032 celoss: 0.032 entropy: 1.732\n",
            "epoch: [10] loss: 0.019 celoss: 0.019 entropy: 1.728\n",
            "epoch: [11] loss: 0.013 celoss: 0.013 entropy: 1.739\n",
            "epoch: [12] loss: 0.078 celoss: 0.078 entropy: 1.847\n",
            "epoch: [13] loss: 0.106 celoss: 0.106 entropy: 1.796\n",
            "epoch: [14] loss: 0.006 celoss: 0.006 entropy: 1.747\n",
            "Finished Training run 17\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.197\n",
            "epoch: [1] loss: 1.185 celoss: 1.185 entropy: 2.389\n",
            "epoch: [2] loss: 1.102 celoss: 1.102 entropy: 2.336\n",
            "epoch: [3] loss: 0.869 celoss: 0.869 entropy: 2.173\n",
            "epoch: [4] loss: 0.665 celoss: 0.665 entropy: 2.066\n",
            "epoch: [5] loss: 0.485 celoss: 0.485 entropy: 2.082\n",
            "epoch: [6] loss: 0.208 celoss: 0.208 entropy: 2.014\n",
            "epoch: [7] loss: 0.118 celoss: 0.118 entropy: 1.997\n",
            "epoch: [8] loss: 0.033 celoss: 0.033 entropy: 1.943\n",
            "epoch: [9] loss: 0.008 celoss: 0.008 entropy: 1.904\n",
            "Finished Training run 18\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.204\n",
            "epoch: [1] loss: 1.197 celoss: 1.197 entropy: 2.304\n",
            "epoch: [2] loss: 1.195 celoss: 1.195 entropy: 2.339\n",
            "epoch: [3] loss: 1.189 celoss: 1.189 entropy: 2.386\n",
            "epoch: [4] loss: 1.166 celoss: 1.166 entropy: 2.384\n",
            "epoch: [5] loss: 1.109 celoss: 1.109 entropy: 2.336\n",
            "epoch: [6] loss: 1.021 celoss: 1.021 entropy: 2.301\n",
            "epoch: [7] loss: 0.966 celoss: 0.966 entropy: 2.219\n",
            "epoch: [8] loss: 0.760 celoss: 0.760 entropy: 2.195\n",
            "epoch: [9] loss: 0.659 celoss: 0.659 entropy: 2.156\n",
            "epoch: [10] loss: 0.595 celoss: 0.595 entropy: 2.135\n",
            "epoch: [11] loss: 0.558 celoss: 0.558 entropy: 2.129\n",
            "epoch: [12] loss: 0.545 celoss: 0.545 entropy: 2.127\n",
            "epoch: [13] loss: 0.511 celoss: 0.511 entropy: 2.125\n",
            "epoch: [14] loss: 0.475 celoss: 0.475 entropy: 2.145\n",
            "epoch: [15] loss: 0.332 celoss: 0.332 entropy: 2.133\n",
            "epoch: [16] loss: 0.140 celoss: 0.140 entropy: 2.018\n",
            "epoch: [17] loss: 0.103 celoss: 0.103 entropy: 1.932\n",
            "epoch: [18] loss: 0.014 celoss: 0.014 entropy: 1.860\n",
            "epoch: [19] loss: 0.004 celoss: 0.004 entropy: 1.836\n",
            "Finished Training run 19\n",
            "Accuracy of the network on the 3000 train images: 99 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31RVViMkYM-"
      },
      "source": [
        "# plt.figure(figsize=(6,6))\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,0],label=\"ftpt\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,1],label=\"ffpt\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,2],label=\"ftpf\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,3],label=\"ffpf\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yEabNK9Q1bTE",
        "outputId": "2289e679-4462-4c1c-b6b4-864b7c30b6ba"
      },
      "source": [
        "plt.plot(loss_curi)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc4e29e8310>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBbboK0mtLTL",
        "outputId": "f3521eb9-c6bb-4115-eab5-6848eb060fdb"
      },
      "source": [
        "np.mean(np.array(FTPT_analysis),axis=0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.04633333e+01, 1.94500000e+01, 6.66666667e-02, 2.00000000e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYS7jRsCz30j"
      },
      "source": [
        "FTPT_analysis.to_csv(\"type4_second_k_value_01.csv\",index=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwzQFzul37sQ"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "PzR8ISPlOSbP",
        "outputId": "ba29885b-ed2d-49d8-b783-0ac58ace29ee"
      },
      "source": [
        "FTPT_analysis"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FTPT</th>\n",
              "      <th>FFPT</th>\n",
              "      <th>FTPF</th>\n",
              "      <th>FFPF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>71.566667</td>\n",
              "      <td>28.400000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98.000000</td>\n",
              "      <td>1.966667</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>76.566667</td>\n",
              "      <td>23.400000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>72.200000</td>\n",
              "      <td>27.733333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>98.400000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>70.900000</td>\n",
              "      <td>28.900000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>81.666667</td>\n",
              "      <td>18.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>77.966667</td>\n",
              "      <td>21.933333</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>73.466667</td>\n",
              "      <td>26.466667</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>72.533333</td>\n",
              "      <td>27.200000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.233333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>79.266667</td>\n",
              "      <td>20.633333</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>80.766667</td>\n",
              "      <td>19.166667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>72.000000</td>\n",
              "      <td>27.933333</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>70.966667</td>\n",
              "      <td>28.933333</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>71.166667</td>\n",
              "      <td>28.766667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>99.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>99.966667</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>71.066667</td>\n",
              "      <td>28.833333</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>70.966667</td>\n",
              "      <td>28.933333</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>99.933333</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         FTPT       FFPT      FTPF      FFPF\n",
              "0   71.566667  28.400000  0.033333  0.000000\n",
              "1   98.000000   1.966667  0.033333  0.000000\n",
              "2   76.566667  23.400000  0.033333  0.000000\n",
              "3   72.200000  27.733333  0.066667  0.000000\n",
              "4   98.400000   1.400000  0.166667  0.033333\n",
              "5   70.900000  28.900000  0.200000  0.000000\n",
              "6   81.666667  18.333333  0.000000  0.000000\n",
              "7   77.966667  21.933333  0.100000  0.000000\n",
              "8   73.466667  26.466667  0.033333  0.033333\n",
              "9   72.533333  27.200000  0.033333  0.233333\n",
              "10  79.266667  20.633333  0.100000  0.000000\n",
              "11  80.766667  19.166667  0.066667  0.000000\n",
              "12  72.000000  27.933333  0.033333  0.033333\n",
              "13  70.966667  28.933333  0.100000  0.000000\n",
              "14  71.166667  28.766667  0.066667  0.000000\n",
              "15  99.900000   0.000000  0.100000  0.000000\n",
              "16  99.966667   0.033333  0.000000  0.000000\n",
              "17  71.066667  28.833333  0.033333  0.066667\n",
              "18  70.966667  28.933333  0.100000  0.000000\n",
              "19  99.933333   0.033333  0.033333  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue9ajqAYmEgb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMECTVXFkoY6"
      },
      "source": [
        "entropy_1  = r_centropy[11]  # FTPT 100 ,FFPT 0  k value =0.01\n",
        "loss_1 = r_loss[11]\n",
        "ce_loss_1 = r_closs[11]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0vVP4RljYA9"
      },
      "source": [
        "entropy_2 = r_centropy[16]   # kvalue = 0 FTPT 99.96, FFPT 0.03\n",
        "ce_loss_2 = r_closs[16]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JUoGWONAXEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a849e3dd-703c-4071-b372-ac41f00b4d6b"
      },
      "source": [
        "# plt.plot(r_closs[1])\n",
        "\n",
        "plt.plot(entropy_1,label = \"entropy k_value=0.01\")\n",
        "plt.plot(loss_1,label = \"overall k_value=0.01\")\n",
        "plt.plot(ce_loss_1,label = \"ce kvalue = 0.01\")\n",
        "plt.plot(entropy_2,label = \"entropy k_value = 0\")\n",
        "plt.plot(ce_loss_2,label = \"ce k_value=0\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.savefig(\"second_layer.png\")\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4AbjFJf0mIr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}