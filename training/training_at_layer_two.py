# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I8wpRknMblk8YCjxEEGyh2ai9LMBNmuF
"""

# Commented out IPython magic to ensure Python compatibility.
from Models import Classification_Module3 as Classification_Module
from Models import Focus_Module3 as Focus_Module
from Mosaic import mosaic_data, MosaicDataset,split_foreground_background
from torch.utils.data import Dataset,DataLoader
import numpy as np
import torch
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
import torch.nn as nn
from matplotlib import pyplot as plt
# %matplotlib inline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)


testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)

data = split_foreground_background(trainloader,total = 50000)
mosaic_list_of_images,mosaic_label,fore_idx = mosaic_data(data,desired_num=30000,total=50000)

batch = 250
train_dataset  = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)
mosaic_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=True)

mimages_val,mlabel_val,fidx_val = mosaic_data(data,desired_num=10000,total=50000)

batch = 250
test_dataset  = MosaicDataset(mimages_val,mlabel_val,fidx_val)
test_loader = DataLoader( test_dataset,batch_size= batch ,shuffle=True)

focus_net =  Focus_Module(3,1).double()
focus_net = focus_net.to(device)

classification_net  = Classification_Module(12,3).double()

classification_net = classification_net.to(device)
classification_net

optimizer_focus = optim.SGD(focus_net.parameters(),lr = 0.01,momentum=0.9)
optimizer_classification = optim.SGD(classification_net.parameters(),lr =0.01, momentum=0.9)

criterion = nn.CrossEntropyLoss()

tr_loss = []
for epoch in range(110):  # loop over the dataset multiple times
    running_loss = 0.0
    cnt=0
    iteration = 30000 // batch
    ep_loss = []
    for i, data in  enumerate(mosaic_loader):
        inputs , labels , fgrnd_idx = data
        inputs,labels = inputs.to("cuda"),labels.to("cuda")
        optimizer_focus.zero_grad()
        optimizer_classification.zero_grad()
        avg_data , alphas = focus_net(inputs)
        outputs = classification_net(avg_data)
        _, predicted = torch.max(outputs.data, 1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer_focus.step()
        optimizer_classification.step()

        running_loss += loss.item()
        mini = 40
        if cnt % mini == mini-1:    # print every mini mini-batches
            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))
            ep_loss.append(running_loss/mini)
            running_loss = 0.0  
        cnt=cnt+1
    tr_loss.append(np.mean(ep_loss))      
print('Finished Training')

train_acc = 0
for i, data in enumerate(mosaic_loader):
    inputs,labels,_ = data
    inputs,labels = inputs.to(device), labels.to(device)
    
    avg_data,alphas = focus_net(inputs)
    outputs = classification_net(avg_data)
    _,predicted = torch.max(outputs.data,1)
    # print(predicted.detach().cpu().numpy())
    train_acc += sum(predicted.cpu().numpy() == labels.cpu().numpy())
print("percentage train accuracy: ",train_acc/300) 

torch.save(focus_net.state_dict(),"focus_net_at_two.pt")
torch.save(classification_net.state_dict(),"classification_net_at_two.pt")

val_acc = 0
for i, data in enumerate(test_loader):
    inputs,labels,_ = data
    inputs,labels = inputs.to(device), labels.to(device)

    avg_data,alphas = focus_net(inputs)
    outputs = classification_net(avg_data)
    _,predicted = torch.max(outputs.data,1)

    val_acc +=sum(predicted.cpu().numpy() == labels.cpu().numpy())
print("percentage validation accuracy: ",val_acc/100)

plt.figure(figsize = (5,4))
plt.plot(tr_loss,label= "training loss")
plt.xlabel("epochs")
plt.ylabel("cross entropy loss")
plt.savefig("training_loss_at_two.png")
plt.savefig("training_loss_at_two.pdf")

