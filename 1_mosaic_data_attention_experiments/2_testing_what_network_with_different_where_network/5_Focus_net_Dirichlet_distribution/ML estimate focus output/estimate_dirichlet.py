# -*- coding: utf-8 -*-
"""Estimate dirichlet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nfKBV6ELBFlObDjwZC7DFL12tj-fxIBK
"""

!pip install git+https://github.com/ericsuh/dirichlet.git

import numpy as np
import dirichlet
import torch.nn as nn
import torch.nn.functional as F

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

from matplotlib import pyplot as plt
from Models import Classification_Module as Classification_Module
from Models import Focus_Module as Focus_Module

import copy

# Ignore warnings
import warnings
warnings.filterwarnings("ignore")
a0 = np.array([1,2,100])
D0 = np.random.dirichlet(a0,30000)
dirichlet.mle(D0,tol=1e-3,)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)


testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)


classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

foreground_classes = {'plane', 'car', 'bird'}

background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}

# print(type(foreground_classes))

dataiter = iter(trainloader)
background_data=[]
background_label=[]
foreground_data=[]
foreground_label=[]
batch_size=10

for i in range(5000):   #5000*batch_size = 50000 data points
  images, labels = dataiter.next()
  for j in range(batch_size):
    if(classes[labels[j]] in background_classes):
      img = images[j].tolist()
      background_data.append(img)
      background_label.append(labels[j])
    else:
      img = images[j].tolist()
      foreground_data.append(img)
      foreground_label.append(labels[j])
            
foreground_data = torch.tensor(foreground_data)
foreground_label = torch.tensor(foreground_label)
background_data = torch.tensor(background_data)
background_label = torch.tensor(background_label)

def create_mosaic_img(bg_idx,fg_idx,fg): 
  """
  bg_idx : list of indexes of background_data[] to be used as background images in mosaic
  fg_idx : index of image to be used as foreground image from foreground data
  fg : at what position/index foreground image has to be stored out of 0-8
  """
  image_list=[]
  j=0
  for i in range(9):
    if i != fg:
      image_list.append(background_data[bg_idx[j]])
      j+=1
    else: 
      image_list.append(foreground_data[fg_idx])
      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2
  #image_list = np.concatenate(image_list ,axis=0)
  image_list = torch.stack(image_list) 
  return image_list,label

desired_num = 30000
mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images
fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               
mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic
for i in range(desired_num):
  np.random.seed(i)
  bg_idx = np.random.randint(0,35000,8)
  fg_idx = np.random.randint(0,15000)
  fg = np.random.randint(0,1)
  fore_idx.append(fg)
  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)
  mosaic_list_of_images.append(image_list)
  mosaic_label.append(label)

class MosaicDataset(Dataset):
  """MosaicDataset dataset."""

  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):
    """
      Args:
        csv_file (string): Path to the csv file with annotations.
        root_dir (string): Directory with all the images.
        transform (callable, optional): Optional transform to be applied
            on a sample.
    """
    self.mosaic = mosaic_list_of_images
    self.label = mosaic_label
    self.fore_idx = fore_idx

  def __len__(self):
    return len(self.label)

  def __getitem__(self, idx):
    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]

batch = 250
msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)
train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)

test_images = []
fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                
test_label=[]                # label of mosaic image = foreground class present in that mosaic
for i in range(10000):
  np.random.seed(i+30000)
  bg_idx = np.random.randint(0,35000,8)
  fg_idx = np.random.randint(0,15000)
  fg = np.random.randint(0,1)
  fore_idx_test.append(fg)
  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)
  test_images.append(image_list)
  test_label.append(label)
test_data = MosaicDataset(test_images,test_label,fore_idx_test)
test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)

focus_net =  Focus_Module(3,1).double()
focus_net = focus_net.to(device)

classify  = Classification_Module(3,3).double()
classify = classify.to(device)
classify

import torch.optim as optim
criterion = nn.CrossEntropyLoss()
optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)
optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)

train_dirich_param = []
test_dirich_param = []

tr_loss = []

for epoch in range(150):  # loop over the dataset multiple times
    running_loss = 0.0
    cnt=0
    iteration = 30000 // batch
    ep_loss = []
    train_alpha = []
    test_alpha = []
    focus_net.train()
    classify.train()

    for i, data in  enumerate(train_loader):
        inputs , labels , fgrnd_idx = data
        inputs = inputs.double()
        inputs,labels = inputs.to("cuda"),labels.to("cuda")
        optimizer_focus.zero_grad()
        optimizer_classify.zero_grad()
        avg_data , alphas = focus_net(inputs)
        outputs = classify(avg_data)
        _, predicted = torch.max(outputs.data, 1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer_focus.step()
        optimizer_classify.step()

        running_loss += loss.item()
        mini = 40
        if cnt % mini == mini-1:    # print every mini mini-batches
            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))
            ep_loss.append(running_loss/mini)
            running_loss = 0.0  
        cnt=cnt+1
        if epoch %5 == 0:
          train_alpha.append(alphas.detach().cpu().numpy())
    
    if epoch %5 == 0 :
      focus_net.eval()
      classify.eval()
      #trunning_loss  = 0
      for i,data in enumerate(test_loader):
        tinput,tlabels,frgnd_idx = data
        tinput = tinput.double()
        tinput,tlabels =  tinput.to(device),tlabels.to(device)
        tavg_data,talpha = focus_net(tinput)
        #toutput = classify(tavg_data)
        test_alpha.append(talpha.detach().cpu().numpy())
        #toutput = classify(avg_data)
        tr_loss.append(np.mean(ep_loss))
      train_alpha = np.concatenate(train_alpha,axis=0)  
      test_alpha = np.concatenate(test_alpha,axis=0)
      print(train_alpha.shape,test_alpha.shape )
      trparam = dirichlet.mle(train_alpha,method = 'fixedpoint',tol=1e-1)
      tsparam = dirichlet.mle(test_alpha,method ='fixedpoint',tol=0.5)
      print("training dirichlet parameter",trparam)
      print("test dirichlet parameter",tsparam)
      train_dirich_param.append(trparam) 
      test_dirich_param.append(tsparam)

#train_dirich_param = np.concatenate(train_dirich_param,axis=0)
#test_dirich_param = np.concatenate(test_dirich_param,axis=0)   
print('Finished Training')

df = pd.DataFrame(np.array(train_dirich_param))

df.to_csv("train_dirich_params.csv",header=False)

df = pd.DataFrame(np.array(test_dirich_param))
df.to_csv("test_dirich_params.csv",header=False)

