{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "blob_both_atttention_weights_lr_0_01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "train_data = np.load(\"train_blob_data.npy\",allow_pickle=True)\n",
        "\n",
        "test_data = np.load(\"test_blob_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL771xuGZC5Q"
      },
      "source": [
        "mosaic_list_of_images = train_data[0][\"mosaic_list\"]\n",
        "mosaic_label = train_data[0][\"mosaic_label\"]\n",
        "fore_idx = train_data[0][\"fore_idx\"]\n",
        "\n",
        "\n",
        "test_mosaic_list_of_images = test_data[0][\"mosaic_list\"]\n",
        "test_mosaic_label = test_data[0][\"mosaic_label\"]\n",
        "test_fore_idx = test_data[0][\"fore_idx\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qfRXfNZCao"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf76JwkxZCT0"
      },
      "source": [
        "batch = 250\n",
        "train_dataset = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=False)\n",
        "test_dataset = MosaicDataset1(test_mosaic_list_of_images, test_mosaic_label, test_fore_idx)\n",
        "test_loader = DataLoader(test_dataset,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "bg = []\n",
        "for i in range(12):\n",
        "  torch.manual_seed(i)\n",
        "  betag = torch.randn(250,9)#torch.ones((250,9))/9\n",
        "  bg.append( betag.requires_grad_() )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzb3ii4drXpu",
        "outputId": "967cdc2f-d26f-4038-c4e2-95828a2f3488"
      },
      "source": [
        "bg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-1.1258, -1.1524, -0.2506,  ..., -0.3160, -2.1152,  0.3223],\n",
              "         [-1.2633,  0.3500,  0.3081,  ..., -0.2473, -1.3527, -1.6959],\n",
              "         [ 0.5667,  0.7935,  0.5988,  ...,  0.7502, -0.5855, -0.1734],\n",
              "         ...,\n",
              "         [ 0.8374, -0.7942, -0.3622,  ...,  0.0121,  0.8032, -0.6962],\n",
              "         [-1.0645,  0.2384, -0.3385,  ...,  0.9635, -1.0340,  0.1894],\n",
              "         [ 0.8253,  1.1038, -1.2491,  ..., -0.5940, -1.7125,  0.3617]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.5256, -0.7502, -0.6540,  ..., -0.9798, -1.6091, -0.7121],\n",
              "         [ 0.3037, -0.7773, -0.2515,  ...,  0.4676, -0.6970, -1.1608],\n",
              "         [ 0.6995,  0.1991,  0.8657,  ...,  1.1017, -0.1759, -2.2456],\n",
              "         ...,\n",
              "         [-0.4302,  0.1508,  0.6937,  ...,  0.0314,  2.6645,  0.1189],\n",
              "         [ 1.4484, -0.0213, -1.3367,  ...,  0.6279, -1.4719, -1.0291],\n",
              "         [ 0.9081, -1.2433,  1.6062,  ..., -0.1177, -0.5548, -0.0595]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0408,  0.9166, -1.3042,  ..., -1.0574, -0.1188, -0.9078],\n",
              "         [ 0.3452, -0.5713, -0.2351,  ..., -0.4327, -1.5071, -0.4586],\n",
              "         [-0.8480,  0.5266,  0.0299,  ...,  0.4640, -0.4986,  0.1289],\n",
              "         ...,\n",
              "         [ 1.5719,  1.0154, -2.1620,  ..., -1.0790,  1.5801, -1.6557],\n",
              "         [-1.1613,  0.3672, -0.3078,  ..., -1.2456, -0.1125,  0.6222],\n",
              "         [ 0.4521, -0.2505,  2.3728,  ..., -0.1377, -0.8815, -0.1671]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.0766,  0.3599, -0.7820,  ...,  1.6206, -1.5967, -0.0517],\n",
              "         [-0.3060,  0.2485, -0.2226,  ...,  0.4163,  0.2615,  0.9311],\n",
              "         [-0.5145, -1.6517,  1.0460,  ...,  0.5638,  2.2566,  1.8693],\n",
              "         ...,\n",
              "         [ 2.1181,  0.1464, -0.0447,  ...,  1.3816,  0.4975,  0.2814],\n",
              "         [-0.7639, -1.4938, -1.1430,  ...,  0.6355,  0.6700,  1.5335],\n",
              "         [-0.0191, -0.3568,  0.4536,  ..., -0.9493,  2.0439, -0.3827]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.9414,  1.2632, -0.1838,  ..., -2.6021,  0.6245, -0.8684],\n",
              "         [-0.2051,  0.3976,  0.6699,  ..., -2.1205,  1.5191, -0.6682],\n",
              "         [ 0.0031, -0.1535,  1.1396,  ..., -0.7588, -0.1853, -0.8558],\n",
              "         ...,\n",
              "         [ 1.6794, -0.5509,  0.4118,  ...,  0.9084, -0.8626, -0.6553],\n",
              "         [ 0.6058, -0.5888,  0.9448,  ...,  0.0072, -0.2579,  1.7659],\n",
              "         [-1.2965,  0.2970, -0.5833,  ...,  1.7838, -0.4794,  0.5579]],\n",
              "        requires_grad=True),\n",
              " tensor([[ 1.8423,  0.5189, -1.7119,  ..., -0.1307, -1.4374,  0.3908],\n",
              "         [-0.0190, -1.3527, -0.7308,  ..., -0.7823,  2.7799,  1.2220],\n",
              "         [-0.3364, -0.9651, -0.1297,  ..., -0.4374,  0.7792, -0.0583],\n",
              "         ...,\n",
              "         [ 0.6700, -0.5400,  0.2353,  ..., -1.0840, -0.6141, -0.0155],\n",
              "         [ 0.4779, -0.4648, -0.1366,  ...,  0.1162,  3.0351, -0.2885],\n",
              "         [-0.6777, -0.1373, -0.7330,  ...,  0.6185, -0.3036, -1.0850]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.2113,  0.6304, -1.4713,  ...,  0.3295,  0.3264, -0.4806],\n",
              "         [ 1.1032,  2.5485,  0.3006,  ..., -1.6279, -1.4801, -1.0631],\n",
              "         [ 0.3630,  0.3995,  0.1457,  ..., -1.3437,  0.8535,  0.8811],\n",
              "         ...,\n",
              "         [-0.5519,  0.2253,  0.4891,  ..., -0.0110, -0.6023, -0.7230],\n",
              "         [-1.1593, -0.6551,  1.6578,  ...,  0.4795, -1.3562,  0.2920],\n",
              "         [ 0.3474, -0.9874, -0.0130,  ...,  0.6061,  0.8639, -0.9552]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8201,  0.3956,  0.8989,  ..., -0.6411, -0.8937,  0.9265],\n",
              "         [-0.5355, -1.1597, -0.4602,  ...,  1.0902, -1.5827, -0.3246],\n",
              "         [ 1.9264, -0.3300,  0.1984,  ..., -0.2093, -0.2153, -1.8157],\n",
              "         ...,\n",
              "         [-0.6910,  0.3328,  2.2102,  ..., -0.0383,  0.4400, -0.8350],\n",
              "         [-0.2194, -0.7611, -0.0921,  ..., -0.3143, -0.4196,  1.1570],\n",
              "         [-0.8934, -1.7705,  0.3805,  ...,  0.1963, -0.7307,  1.3581]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.1892,  1.3932,  2.1059,  ...,  2.1414,  0.1317, -0.6388],\n",
              "         [ 1.3384, -1.1908, -0.7601,  ..., -0.1051,  0.4414,  0.6590],\n",
              "         [-0.7585, -0.6001, -0.3948,  ..., -1.7526,  0.3920,  0.8295],\n",
              "         ...,\n",
              "         [-0.0557, -0.1032, -0.4624,  ..., -0.1339, -1.6662, -0.4955],\n",
              "         [ 1.0884, -0.4479, -0.0847,  ...,  1.7487, -1.6152, -1.8258],\n",
              "         [ 1.7062,  1.1041, -1.3736,  ..., -1.5244,  0.4869, -1.7420]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0674, -0.7172,  1.0897,  ..., -0.7737, -2.4656,  0.9968],\n",
              "         [ 0.4524, -0.3464, -0.7245,  ...,  0.2331, -1.1433,  0.8289],\n",
              "         [ 0.9534,  0.2948,  1.5159,  ...,  0.3971,  0.4058, -0.5274],\n",
              "         ...,\n",
              "         [-0.3297, -0.3700,  1.9490,  ..., -0.0443,  1.8073, -0.6388],\n",
              "         [ 0.0977,  0.1862,  1.4303,  ..., -1.9735, -1.1663,  1.7066],\n",
              "         [-0.8396, -2.5271, -1.0791,  ...,  0.1053,  1.2463, -0.7709]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8173, -0.5556, -0.8267,  ..., -0.5133,  2.6278, -0.7465],\n",
              "         [ 1.0051, -0.2568,  0.4765,  ..., -0.2496,  0.8298,  1.1209],\n",
              "         [ 0.9999,  1.1167,  1.0763,  ...,  0.0562,  0.2456,  0.9535],\n",
              "         ...,\n",
              "         [-1.0042, -0.7732,  0.9129,  ..., -0.4342,  1.3256, -0.6357],\n",
              "         [-0.5979,  1.2285,  1.0288,  ..., -1.4067,  0.2403,  0.5257],\n",
              "         [-1.7332, -0.2443,  0.1425,  ..., -0.9291,  1.4324, -0.2338]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.5108,  1.0283, -0.3532,  ...,  0.1421, -0.5243, -0.2487],\n",
              "         [-0.5252,  2.8922, -0.5947,  ..., -0.0080,  0.2479,  1.5727],\n",
              "         [-1.6395, -1.5925, -0.1546,  ..., -0.3935,  0.6171,  0.7528],\n",
              "         ...,\n",
              "         [-0.3538,  0.1294,  1.1873,  ..., -0.2866, -0.3111,  0.2674],\n",
              "         [ 1.7757, -0.1730,  0.6679,  ..., -0.2519,  0.8360, -0.4348],\n",
              "         [ 0.4242,  0.7649, -0.5807,  ..., -0.7654, -0.1086,  0.4636]],\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    self.linear1 = nn.Linear(5,100)\n",
        "    self.linear2 = nn.Linear(100,3)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "#what_net.load_state_dict(torch.load(\"type4_what_net.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8Wch99l4yB"
      },
      "source": [
        "def attn_avg(x,beta):\n",
        "  y = torch.zeros([batch,5], dtype=torch.float64)\n",
        "  y = y.to(\"cuda\")\n",
        "  alpha = F.softmax(beta,dim=1)   # alphas\n",
        "  #print(alpha[0],x[0,:])\n",
        "  for i in range(9):            \n",
        "    alpha1 = alpha[:,i]      \n",
        "    y = y + torch.mul(alpha1[:,None],x[:,i])\n",
        "  return y,alpha\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz1Kpw12loV6"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,criter):\n",
        "  what.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  correct = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx= data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      beta = bg[i]  # beta for ith batch\n",
        "      inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "      avg,alpha = attn_avg(inputs,beta)\n",
        "      alpha = alpha.to(\"cuda\")\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += sum(predicted == labels)\n",
        "      tot += len(predicted)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis,correct.item(),tot,correct.item()/tot"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAY-x6UAwrwE"
      },
      "source": [
        "# for param in what_net.parameters():\n",
        "#     param.requires_grad = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toCktPanH0S"
      },
      "source": [
        "\n",
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "optim1 = []\n",
        "for i in range(12):\n",
        "  optim1.append(optim.RMSprop([bg[i]], lr=0.01))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPaYaojinMTA",
        "outputId": "db3a3702-5567-4e33-e9a7-9d287c2c45e9"
      },
      "source": [
        "# instantiate optimizer\n",
        "optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.001)#, momentum=0.9)#,nesterov=True)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    beta = bg[i] # alpha for ith batch\n",
        "    #print(labels)\n",
        "    inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,beta)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 1.759 correct: 935.000, total: 3000.000, accuracy: 0.312\n",
            "training epoch: [1 ] loss: 1.196 correct: 1203.000, total: 3000.000, accuracy: 0.401\n",
            "training epoch: [2 ] loss: 1.128 correct: 1456.000, total: 3000.000, accuracy: 0.485\n",
            "training epoch: [3 ] loss: 1.088 correct: 1619.000, total: 3000.000, accuracy: 0.540\n",
            "training epoch: [4 ] loss: 1.043 correct: 1772.000, total: 3000.000, accuracy: 0.591\n",
            "training epoch: [5 ] loss: 0.988 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [6 ] loss: 0.927 correct: 2082.000, total: 3000.000, accuracy: 0.694\n",
            "training epoch: [7 ] loss: 0.863 correct: 2183.000, total: 3000.000, accuracy: 0.728\n",
            "training epoch: [8 ] loss: 0.798 correct: 2268.000, total: 3000.000, accuracy: 0.756\n",
            "training epoch: [9 ] loss: 0.735 correct: 2347.000, total: 3000.000, accuracy: 0.782\n",
            "training epoch: [10 ] loss: 0.676 correct: 2409.000, total: 3000.000, accuracy: 0.803\n",
            "training epoch: [11 ] loss: 0.621 correct: 2455.000, total: 3000.000, accuracy: 0.818\n",
            "training epoch: [12 ] loss: 0.572 correct: 2495.000, total: 3000.000, accuracy: 0.832\n",
            "training epoch: [13 ] loss: 0.527 correct: 2546.000, total: 3000.000, accuracy: 0.849\n",
            "training epoch: [14 ] loss: 0.487 correct: 2603.000, total: 3000.000, accuracy: 0.868\n",
            "training epoch: [15 ] loss: 0.451 correct: 2652.000, total: 3000.000, accuracy: 0.884\n",
            "training epoch: [16 ] loss: 0.419 correct: 2682.000, total: 3000.000, accuracy: 0.894\n",
            "training epoch: [17 ] loss: 0.390 correct: 2712.000, total: 3000.000, accuracy: 0.904\n",
            "training epoch: [18 ] loss: 0.364 correct: 2743.000, total: 3000.000, accuracy: 0.914\n",
            "training epoch: [19 ] loss: 0.341 correct: 2757.000, total: 3000.000, accuracy: 0.919\n",
            "training epoch: [20 ] loss: 0.320 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [21 ] loss: 0.300 correct: 2790.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [22 ] loss: 0.282 correct: 2804.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [23 ] loss: 0.265 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [24 ] loss: 0.250 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [25 ] loss: 0.236 correct: 2835.000, total: 3000.000, accuracy: 0.945\n",
            "training epoch: [26 ] loss: 0.223 correct: 2848.000, total: 3000.000, accuracy: 0.949\n",
            "training epoch: [27 ] loss: 0.211 correct: 2862.000, total: 3000.000, accuracy: 0.954\n",
            "training epoch: [28 ] loss: 0.199 correct: 2869.000, total: 3000.000, accuracy: 0.956\n",
            "training epoch: [29 ] loss: 0.189 correct: 2882.000, total: 3000.000, accuracy: 0.961\n",
            "training epoch: [30 ] loss: 0.179 correct: 2891.000, total: 3000.000, accuracy: 0.964\n",
            "training epoch: [31 ] loss: 0.170 correct: 2894.000, total: 3000.000, accuracy: 0.965\n",
            "training epoch: [32 ] loss: 0.161 correct: 2904.000, total: 3000.000, accuracy: 0.968\n",
            "training epoch: [33 ] loss: 0.153 correct: 2909.000, total: 3000.000, accuracy: 0.970\n",
            "training epoch: [34 ] loss: 0.145 correct: 2914.000, total: 3000.000, accuracy: 0.971\n",
            "training epoch: [35 ] loss: 0.138 correct: 2921.000, total: 3000.000, accuracy: 0.974\n",
            "training epoch: [36 ] loss: 0.132 correct: 2924.000, total: 3000.000, accuracy: 0.975\n",
            "training epoch: [37 ] loss: 0.126 correct: 2929.000, total: 3000.000, accuracy: 0.976\n",
            "training epoch: [38 ] loss: 0.120 correct: 2929.000, total: 3000.000, accuracy: 0.976\n",
            "training epoch: [39 ] loss: 0.114 correct: 2935.000, total: 3000.000, accuracy: 0.978\n",
            "training epoch: [40 ] loss: 0.109 correct: 2939.000, total: 3000.000, accuracy: 0.980\n",
            "training epoch: [41 ] loss: 0.104 correct: 2942.000, total: 3000.000, accuracy: 0.981\n",
            "training epoch: [42 ] loss: 0.099 correct: 2943.000, total: 3000.000, accuracy: 0.981\n",
            "training epoch: [43 ] loss: 0.095 correct: 2947.000, total: 3000.000, accuracy: 0.982\n",
            "training epoch: [44 ] loss: 0.090 correct: 2952.000, total: 3000.000, accuracy: 0.984\n",
            "training epoch: [45 ] loss: 0.087 correct: 2953.000, total: 3000.000, accuracy: 0.984\n",
            "training epoch: [46 ] loss: 0.083 correct: 2954.000, total: 3000.000, accuracy: 0.985\n",
            "training epoch: [47 ] loss: 0.080 correct: 2955.000, total: 3000.000, accuracy: 0.985\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NoQpS_6scRsC",
        "outputId": "ba21c9c9-04de-4f6c-c89b-7e1293b8ab81"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>302</td>\n",
              "      <td>2698</td>\n",
              "      <td>79</td>\n",
              "      <td>856</td>\n",
              "      <td>235</td>\n",
              "      <td>1830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>300</td>\n",
              "      <td>2700</td>\n",
              "      <td>127</td>\n",
              "      <td>1076</td>\n",
              "      <td>202</td>\n",
              "      <td>1595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>308</td>\n",
              "      <td>2692</td>\n",
              "      <td>146</td>\n",
              "      <td>1310</td>\n",
              "      <td>187</td>\n",
              "      <td>1357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>319</td>\n",
              "      <td>2681</td>\n",
              "      <td>167</td>\n",
              "      <td>1452</td>\n",
              "      <td>168</td>\n",
              "      <td>1213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>2678</td>\n",
              "      <td>175</td>\n",
              "      <td>1597</td>\n",
              "      <td>154</td>\n",
              "      <td>1074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>321</td>\n",
              "      <td>2679</td>\n",
              "      <td>194</td>\n",
              "      <td>1752</td>\n",
              "      <td>132</td>\n",
              "      <td>922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>338</td>\n",
              "      <td>2662</td>\n",
              "      <td>201</td>\n",
              "      <td>1881</td>\n",
              "      <td>114</td>\n",
              "      <td>804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>348</td>\n",
              "      <td>2652</td>\n",
              "      <td>208</td>\n",
              "      <td>1975</td>\n",
              "      <td>99</td>\n",
              "      <td>718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>362</td>\n",
              "      <td>2638</td>\n",
              "      <td>213</td>\n",
              "      <td>2055</td>\n",
              "      <td>87</td>\n",
              "      <td>645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>368</td>\n",
              "      <td>2632</td>\n",
              "      <td>216</td>\n",
              "      <td>2131</td>\n",
              "      <td>76</td>\n",
              "      <td>577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>374</td>\n",
              "      <td>2626</td>\n",
              "      <td>224</td>\n",
              "      <td>2185</td>\n",
              "      <td>62</td>\n",
              "      <td>529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>383</td>\n",
              "      <td>2617</td>\n",
              "      <td>222</td>\n",
              "      <td>2233</td>\n",
              "      <td>56</td>\n",
              "      <td>489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>395</td>\n",
              "      <td>2605</td>\n",
              "      <td>223</td>\n",
              "      <td>2272</td>\n",
              "      <td>49</td>\n",
              "      <td>456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>408</td>\n",
              "      <td>2592</td>\n",
              "      <td>224</td>\n",
              "      <td>2322</td>\n",
              "      <td>46</td>\n",
              "      <td>408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>413</td>\n",
              "      <td>2587</td>\n",
              "      <td>227</td>\n",
              "      <td>2376</td>\n",
              "      <td>39</td>\n",
              "      <td>358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>420</td>\n",
              "      <td>2580</td>\n",
              "      <td>224</td>\n",
              "      <td>2428</td>\n",
              "      <td>37</td>\n",
              "      <td>311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>425</td>\n",
              "      <td>2575</td>\n",
              "      <td>218</td>\n",
              "      <td>2464</td>\n",
              "      <td>35</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>435</td>\n",
              "      <td>2565</td>\n",
              "      <td>212</td>\n",
              "      <td>2500</td>\n",
              "      <td>33</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>439</td>\n",
              "      <td>2561</td>\n",
              "      <td>209</td>\n",
              "      <td>2534</td>\n",
              "      <td>33</td>\n",
              "      <td>224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>446</td>\n",
              "      <td>2554</td>\n",
              "      <td>212</td>\n",
              "      <td>2545</td>\n",
              "      <td>31</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>448</td>\n",
              "      <td>2552</td>\n",
              "      <td>207</td>\n",
              "      <td>2572</td>\n",
              "      <td>28</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>454</td>\n",
              "      <td>2546</td>\n",
              "      <td>205</td>\n",
              "      <td>2585</td>\n",
              "      <td>29</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>454</td>\n",
              "      <td>2546</td>\n",
              "      <td>204</td>\n",
              "      <td>2600</td>\n",
              "      <td>27</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>464</td>\n",
              "      <td>2536</td>\n",
              "      <td>199</td>\n",
              "      <td>2615</td>\n",
              "      <td>25</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>460</td>\n",
              "      <td>2540</td>\n",
              "      <td>197</td>\n",
              "      <td>2631</td>\n",
              "      <td>22</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>465</td>\n",
              "      <td>2535</td>\n",
              "      <td>197</td>\n",
              "      <td>2638</td>\n",
              "      <td>25</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>464</td>\n",
              "      <td>2536</td>\n",
              "      <td>197</td>\n",
              "      <td>2651</td>\n",
              "      <td>23</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>474</td>\n",
              "      <td>2526</td>\n",
              "      <td>192</td>\n",
              "      <td>2670</td>\n",
              "      <td>23</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>474</td>\n",
              "      <td>2526</td>\n",
              "      <td>190</td>\n",
              "      <td>2679</td>\n",
              "      <td>21</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>477</td>\n",
              "      <td>2523</td>\n",
              "      <td>187</td>\n",
              "      <td>2695</td>\n",
              "      <td>22</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>482</td>\n",
              "      <td>2518</td>\n",
              "      <td>184</td>\n",
              "      <td>2707</td>\n",
              "      <td>20</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>487</td>\n",
              "      <td>2513</td>\n",
              "      <td>181</td>\n",
              "      <td>2713</td>\n",
              "      <td>20</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>489</td>\n",
              "      <td>2511</td>\n",
              "      <td>181</td>\n",
              "      <td>2723</td>\n",
              "      <td>19</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>498</td>\n",
              "      <td>2502</td>\n",
              "      <td>179</td>\n",
              "      <td>2730</td>\n",
              "      <td>19</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>502</td>\n",
              "      <td>2498</td>\n",
              "      <td>174</td>\n",
              "      <td>2740</td>\n",
              "      <td>20</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>505</td>\n",
              "      <td>2495</td>\n",
              "      <td>171</td>\n",
              "      <td>2750</td>\n",
              "      <td>19</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>507</td>\n",
              "      <td>2493</td>\n",
              "      <td>169</td>\n",
              "      <td>2755</td>\n",
              "      <td>17</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>506</td>\n",
              "      <td>2494</td>\n",
              "      <td>168</td>\n",
              "      <td>2761</td>\n",
              "      <td>16</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>514</td>\n",
              "      <td>2486</td>\n",
              "      <td>166</td>\n",
              "      <td>2763</td>\n",
              "      <td>15</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>513</td>\n",
              "      <td>2487</td>\n",
              "      <td>166</td>\n",
              "      <td>2769</td>\n",
              "      <td>14</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>513</td>\n",
              "      <td>2487</td>\n",
              "      <td>166</td>\n",
              "      <td>2773</td>\n",
              "      <td>13</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>515</td>\n",
              "      <td>2485</td>\n",
              "      <td>164</td>\n",
              "      <td>2778</td>\n",
              "      <td>12</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>515</td>\n",
              "      <td>2485</td>\n",
              "      <td>161</td>\n",
              "      <td>2782</td>\n",
              "      <td>12</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>515</td>\n",
              "      <td>2485</td>\n",
              "      <td>161</td>\n",
              "      <td>2786</td>\n",
              "      <td>12</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>517</td>\n",
              "      <td>2483</td>\n",
              "      <td>160</td>\n",
              "      <td>2792</td>\n",
              "      <td>13</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>45</td>\n",
              "      <td>516</td>\n",
              "      <td>2484</td>\n",
              "      <td>159</td>\n",
              "      <td>2794</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>516</td>\n",
              "      <td>2484</td>\n",
              "      <td>158</td>\n",
              "      <td>2796</td>\n",
              "      <td>13</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>518</td>\n",
              "      <td>2482</td>\n",
              "      <td>157</td>\n",
              "      <td>2798</td>\n",
              "      <td>13</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0           302  ...                    235                    1830\n",
              "1        1           300  ...                    202                    1595\n",
              "2        2           308  ...                    187                    1357\n",
              "3        3           319  ...                    168                    1213\n",
              "4        4           322  ...                    154                    1074\n",
              "5        5           321  ...                    132                     922\n",
              "6        6           338  ...                    114                     804\n",
              "7        7           348  ...                     99                     718\n",
              "8        8           362  ...                     87                     645\n",
              "9        9           368  ...                     76                     577\n",
              "10      10           374  ...                     62                     529\n",
              "11      11           383  ...                     56                     489\n",
              "12      12           395  ...                     49                     456\n",
              "13      13           408  ...                     46                     408\n",
              "14      14           413  ...                     39                     358\n",
              "15      15           420  ...                     37                     311\n",
              "16      16           425  ...                     35                     283\n",
              "17      17           435  ...                     33                     255\n",
              "18      18           439  ...                     33                     224\n",
              "19      19           446  ...                     31                     212\n",
              "20      20           448  ...                     28                     193\n",
              "21      21           454  ...                     29                     181\n",
              "22      22           454  ...                     27                     169\n",
              "23      23           464  ...                     25                     161\n",
              "24      24           460  ...                     22                     150\n",
              "25      25           465  ...                     25                     140\n",
              "26      26           464  ...                     23                     129\n",
              "27      27           474  ...                     23                     115\n",
              "28      28           474  ...                     21                     110\n",
              "29      29           477  ...                     22                      96\n",
              "30      30           482  ...                     20                      89\n",
              "31      31           487  ...                     20                      86\n",
              "32      32           489  ...                     19                      77\n",
              "33      33           498  ...                     19                      72\n",
              "34      34           502  ...                     20                      66\n",
              "35      35           505  ...                     19                      60\n",
              "36      36           507  ...                     17                      59\n",
              "37      37           506  ...                     16                      55\n",
              "38      38           514  ...                     15                      56\n",
              "39      39           513  ...                     14                      51\n",
              "40      40           513  ...                     13                      48\n",
              "41      41           515  ...                     12                      46\n",
              "42      42           515  ...                     12                      45\n",
              "43      43           515  ...                     12                      41\n",
              "44      44           517  ...                     13                      35\n",
              "45      45           516  ...                     13                      34\n",
              "46      46           516  ...                     13                      33\n",
              "47      47           518  ...                     13                      32\n",
              "\n",
              "[48 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "IMAhRdxOcVf6",
        "outputId": "414b2352-fc4b-4c53-b275-75d7bb8eeb25"
      },
      "source": [
        "fig= plt.figure(figsize=(6,6))\n",
        "plt.plot(df_train[columns[0]],df_train[columns[3]]/30, label =\"focus_true_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[4]]/30, label =\"focus_false_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[5]]/30, label =\"focus_true_pred_false \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[6]]/30, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Train set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"percentage of data\")\n",
        "plt.xticks([0,10,20,30,40,50])\n",
        "#plt.vlines(vline_list,min(min(df_train[columns[3]]/300),min(df_train[columns[4]]/300),min(df_train[columns[5]]/300),min(df_train[columns[6]]/300)), max(max(df_train[columns[3]]/300),max(df_train[columns[4]]/300),max(df_train[columns[5]]/300),max(df_train[columns[6]]/300)),linestyles='dotted')\n",
        "plt.show()\n",
        "fig.savefig(\"train_analysis.pdf\")\n",
        "fig.savefig(\"train_analysis.png\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in bg:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "torch.save({\n",
        "            'epoch': 500,\n",
        "            'model_state_dict': what_net.state_dict(),\n",
        "            #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "            \"optimizer_alpha\":optim1,\n",
        "            \"FTPT_analysis\":analysis_data_tr,\n",
        "            \"alpha\":aph\n",
        "\n",
        "            }, \"type4_what_net_500.pt\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVzrDOGS4UxU",
        "outputId": "2c6d058f-2a2b-48c5-cc1b-a72d23d68608"
      },
      "source": [
        "aph[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03752727, 0.02452533, 0.04469988, 0.05065021, 0.48343647,\n",
              "       0.13566622, 0.08872726, 0.02322156, 0.11154584], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}