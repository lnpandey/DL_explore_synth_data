{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar_every_atttention_weights_init_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgw1f4rVkGr9",
        "outputId": "51a5b047-afa7-4be6-c919-2100bbfe72b8"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-xlWYTKkQEn"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "#foreground_classes = {'bird', 'cat', 'deer'}\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
        "#background_classes = {'plane', 'car', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrX68qhikUbz"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD-QJkvnkgyk"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])#.type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])#.type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]-fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs10rfXHkli2"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7km9Swb1kq4O"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=False,num_workers=0,)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "data,labels,fg_index = iter(train_loader).next()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "bg = []\n",
        "for i in range(120):\n",
        "  torch.manual_seed(i)\n",
        "  betag = torch.ones((250,9))/9  #torch.randn(250,9)\n",
        "  a=bg.append( betag.requires_grad_() )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "    self.fc4 = nn.Linear(10,3)\n",
        "\n",
        "  def forward(self,y):  #z batch of list of 9 images\n",
        "    y1 = self.pool(F.relu(self.conv1(y)))\n",
        "    y1 = self.pool(F.relu(self.conv2(y1)))\n",
        "    y1 = y1.view(-1, 16 * 5 * 5)\n",
        "\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "    return y1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "what_net.load_state_dict(torch.load(\"simultaneous_what.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8Wch99l4yB"
      },
      "source": [
        "def attn_avg(x,beta):\n",
        "  y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "  y = y.to(\"cuda\")\n",
        "  alpha = F.softmax(beta,dim=1)   # alphas\n",
        "  for i in range(9):            \n",
        "    alpha1 = alpha[:,i]          \n",
        "    y = y + torch.mul(alpha1[:,None,None,None],x[:,i])\n",
        "  return y,alpha"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz1Kpw12loV6"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,criter):\n",
        "  what.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  correct = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx= data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      beta = bg[i]  # alpha for ith batch\n",
        "      inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "      avg,alpha = attn_avg(inputs,beta)\n",
        "      alpha = alpha.to(\"cuda\")\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += sum(predicted == labels)\n",
        "      tot += len(predicted)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/(i+1),analysis,correct.item(),tot,correct.item()/tot"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAY-x6UAwrwE"
      },
      "source": [
        "for param in what_net.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toCktPanH0S"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "optim1 = []\n",
        "for i in range(120):\n",
        "  optim1.append(optim.RMSprop([bg[i]], lr=10))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPaYaojinMTA",
        "outputId": "ff20caa3-6e89-42eb-f8c8-03ddd0a64d0a"
      },
      "source": [
        "# instantiate optimizer\n",
        "#optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.001)#, momentum=0.9)#,nesterov=True)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  #what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    beta = bg[i] # alpha for ith batch\n",
        "    inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    #optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,beta)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    #optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 3.207 correct: 11145.000, total: 30000.000, accuracy: 0.371\n",
            "training epoch: [1 ] loss: 1.552 correct: 18366.000, total: 30000.000, accuracy: 0.612\n",
            "training epoch: [2 ] loss: 2.355 correct: 20229.000, total: 30000.000, accuracy: 0.674\n",
            "training epoch: [3 ] loss: 2.175 correct: 21140.000, total: 30000.000, accuracy: 0.705\n",
            "training epoch: [4 ] loss: 2.140 correct: 21274.000, total: 30000.000, accuracy: 0.709\n",
            "training epoch: [5 ] loss: 2.119 correct: 21341.000, total: 30000.000, accuracy: 0.711\n",
            "training epoch: [6 ] loss: 2.106 correct: 21381.000, total: 30000.000, accuracy: 0.713\n",
            "training epoch: [7 ] loss: 2.100 correct: 21399.000, total: 30000.000, accuracy: 0.713\n",
            "training epoch: [8 ] loss: 2.094 correct: 21419.000, total: 30000.000, accuracy: 0.714\n",
            "training epoch: [9 ] loss: 2.087 correct: 21434.000, total: 30000.000, accuracy: 0.714\n",
            "training epoch: [10 ] loss: 2.083 correct: 21454.000, total: 30000.000, accuracy: 0.715\n",
            "training epoch: [11 ] loss: 2.080 correct: 21464.000, total: 30000.000, accuracy: 0.715\n",
            "training epoch: [12 ] loss: 2.077 correct: 21474.000, total: 30000.000, accuracy: 0.716\n",
            "training epoch: [13 ] loss: 2.073 correct: 21489.000, total: 30000.000, accuracy: 0.716\n",
            "training epoch: [14 ] loss: 2.071 correct: 21496.000, total: 30000.000, accuracy: 0.717\n",
            "training epoch: [15 ] loss: 2.068 correct: 21507.000, total: 30000.000, accuracy: 0.717\n",
            "training epoch: [16 ] loss: 2.067 correct: 21509.000, total: 30000.000, accuracy: 0.717\n",
            "training epoch: [17 ] loss: 2.066 correct: 21513.000, total: 30000.000, accuracy: 0.717\n",
            "training epoch: [18 ] loss: 2.063 correct: 21519.000, total: 30000.000, accuracy: 0.717\n",
            "training epoch: [19 ] loss: 2.062 correct: 21524.000, total: 30000.000, accuracy: 0.717\n",
            "training epoch: [20 ] loss: 2.060 correct: 21530.000, total: 30000.000, accuracy: 0.718\n",
            "training epoch: [21 ] loss: 2.058 correct: 21535.000, total: 30000.000, accuracy: 0.718\n",
            "training epoch: [22 ] loss: 2.058 correct: 21537.000, total: 30000.000, accuracy: 0.718\n",
            "training epoch: [23 ] loss: 2.056 correct: 21540.000, total: 30000.000, accuracy: 0.718\n",
            "training epoch: [24 ] loss: 2.056 correct: 21541.000, total: 30000.000, accuracy: 0.718\n",
            "training epoch: [25 ] loss: 2.054 correct: 21546.000, total: 30000.000, accuracy: 0.718\n",
            "training epoch: [26 ] loss: 2.053 correct: 21550.000, total: 30000.000, accuracy: 0.718\n",
            "training epoch: [27 ] loss: 2.051 correct: 21553.000, total: 30000.000, accuracy: 0.718\n",
            "training epoch: [28 ] loss: 2.051 correct: 21556.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [29 ] loss: 2.050 correct: 21556.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [30 ] loss: 2.049 correct: 21563.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [31 ] loss: 2.047 correct: 21566.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [32 ] loss: 2.047 correct: 21565.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [33 ] loss: 2.046 correct: 21571.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [34 ] loss: 2.046 correct: 21572.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [35 ] loss: 2.046 correct: 21574.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [36 ] loss: 2.046 correct: 21574.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [37 ] loss: 2.044 correct: 21579.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [38 ] loss: 2.043 correct: 21582.000, total: 30000.000, accuracy: 0.719\n",
            "training epoch: [39 ] loss: 2.041 correct: 21585.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [40 ] loss: 2.040 correct: 21588.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [41 ] loss: 2.039 correct: 21590.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [42 ] loss: 2.038 correct: 21594.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [43 ] loss: 2.039 correct: 21592.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [44 ] loss: 2.039 correct: 21594.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [45 ] loss: 2.039 correct: 21595.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [46 ] loss: 2.038 correct: 21594.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [47 ] loss: 2.037 correct: 21599.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [48 ] loss: 2.037 correct: 21599.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [49 ] loss: 2.037 correct: 21599.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [50 ] loss: 2.036 correct: 21605.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [51 ] loss: 2.035 correct: 21607.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [52 ] loss: 2.035 correct: 21609.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [53 ] loss: 2.035 correct: 21609.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [54 ] loss: 2.035 correct: 21611.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [55 ] loss: 2.036 correct: 21608.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [56 ] loss: 2.036 correct: 21608.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [57 ] loss: 2.035 correct: 21608.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [58 ] loss: 2.034 correct: 21609.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [59 ] loss: 2.034 correct: 21610.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [60 ] loss: 2.034 correct: 21611.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [61 ] loss: 2.034 correct: 21610.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [62 ] loss: 2.034 correct: 21611.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [63 ] loss: 2.034 correct: 21609.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [64 ] loss: 2.034 correct: 21609.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [65 ] loss: 2.033 correct: 21614.000, total: 30000.000, accuracy: 0.720\n",
            "training epoch: [66 ] loss: 2.032 correct: 21616.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [67 ] loss: 2.031 correct: 21617.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [68 ] loss: 2.032 correct: 21618.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [69 ] loss: 2.031 correct: 21620.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [70 ] loss: 2.031 correct: 21619.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [71 ] loss: 2.031 correct: 21620.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [72 ] loss: 2.031 correct: 21624.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [73 ] loss: 2.031 correct: 21624.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [74 ] loss: 2.030 correct: 21626.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [75 ] loss: 2.031 correct: 21626.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [76 ] loss: 2.030 correct: 21626.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [77 ] loss: 2.030 correct: 21628.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [78 ] loss: 2.029 correct: 21630.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [79 ] loss: 2.029 correct: 21630.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [80 ] loss: 2.029 correct: 21630.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [81 ] loss: 2.029 correct: 21631.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [82 ] loss: 2.028 correct: 21632.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [83 ] loss: 2.029 correct: 21632.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [84 ] loss: 2.029 correct: 21632.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [85 ] loss: 2.029 correct: 21632.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [86 ] loss: 2.028 correct: 21634.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [87 ] loss: 2.028 correct: 21635.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [88 ] loss: 2.028 correct: 21636.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [89 ] loss: 2.027 correct: 21639.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [90 ] loss: 2.027 correct: 21637.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [91 ] loss: 2.027 correct: 21638.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [92 ] loss: 2.027 correct: 21639.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [93 ] loss: 2.026 correct: 21642.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [94 ] loss: 2.025 correct: 21643.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [95 ] loss: 2.025 correct: 21644.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [96 ] loss: 2.024 correct: 21642.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [97 ] loss: 2.024 correct: 21642.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [98 ] loss: 2.023 correct: 21645.000, total: 30000.000, accuracy: 0.722\n",
            "training epoch: [99 ] loss: 2.023 correct: 21644.000, total: 30000.000, accuracy: 0.721\n",
            "training epoch: [100 ] loss: 2.022 correct: 21647.000, total: 30000.000, accuracy: 0.722\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]/300\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]/300\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]/300\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]/300\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]/300\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]/300"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoQpS_6scRsC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "b94f5a86-2973-4495-cba0-567064ae0d48"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.103333</td>\n",
              "      <td>33.046667</td>\n",
              "      <td>7.176667</td>\n",
              "      <td>55.673333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9.476667</td>\n",
              "      <td>90.523333</td>\n",
              "      <td>14.216667</td>\n",
              "      <td>47.003333</td>\n",
              "      <td>6.036667</td>\n",
              "      <td>32.743333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>86.566667</td>\n",
              "      <td>13.433333</td>\n",
              "      <td>22.283333</td>\n",
              "      <td>45.146667</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>31.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>88.516667</td>\n",
              "      <td>11.483333</td>\n",
              "      <td>24.706667</td>\n",
              "      <td>45.760000</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>28.673333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>88.833333</td>\n",
              "      <td>11.166667</td>\n",
              "      <td>25.013333</td>\n",
              "      <td>45.900000</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>28.216667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>90.266667</td>\n",
              "      <td>9.733333</td>\n",
              "      <td>26.123333</td>\n",
              "      <td>46.016667</td>\n",
              "      <td>0.846667</td>\n",
              "      <td>27.013333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>90.293333</td>\n",
              "      <td>9.706667</td>\n",
              "      <td>26.126667</td>\n",
              "      <td>46.013333</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>27.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>90.276667</td>\n",
              "      <td>9.723333</td>\n",
              "      <td>26.136667</td>\n",
              "      <td>46.013333</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>90.300000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>26.133333</td>\n",
              "      <td>46.013333</td>\n",
              "      <td>0.853333</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>100</td>\n",
              "      <td>90.300000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>26.130000</td>\n",
              "      <td>46.026667</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>26.993333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0         0      0.000000  ...               7.176667               55.673333\n",
              "1         1      9.476667  ...               6.036667               32.743333\n",
              "2         2     86.566667  ...               1.010000               31.560000\n",
              "3         3     88.516667  ...               0.860000               28.673333\n",
              "4         4     88.833333  ...               0.870000               28.216667\n",
              "..      ...           ...  ...                    ...                     ...\n",
              "96       96     90.266667  ...               0.846667               27.013333\n",
              "97       97     90.293333  ...               0.850000               27.010000\n",
              "98       98     90.276667  ...               0.850000               27.000000\n",
              "99       99     90.300000  ...               0.853333               27.000000\n",
              "100     100     90.300000  ...               0.850000               26.993333\n",
              "\n",
              "[101 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMAhRdxOcVf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "33f38666-c9b1-4338-c7a1-c8d02c6d0e96"
      },
      "source": [
        "fig= plt.figure(figsize=(6,6))\n",
        "plt.plot(df_train[columns[0]],df_train[columns[3]], label =\"focus_true_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[4]], label =\"focus_false_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[5]], label =\"focus_true_pred_false \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[6]], label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Train set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xticks([0,50,100])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"percentage of data\")\n",
        "#plt.vlines(vline_list,min(min(df_train[columns[3]]/300),min(df_train[columns[4]]/300),min(df_train[columns[5]]/300),min(df_train[columns[6]]/300)), max(max(df_train[columns[3]]/300),max(df_train[columns[4]]/300),max(df_train[columns[5]]/300),max(df_train[columns[6]]/300)),linestyles='dotted')\n",
        "plt.show()\n",
        "fig.savefig(\"train_analysis.pdf\")\n",
        "fig.savefig(\"train_analysis.png\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in bg:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "torch.save({\n",
        "            'epoch': 500,\n",
        "            'model_state_dict': what_net.state_dict(),\n",
        "            #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "            \"optimizer_alpha\":optim1,\n",
        "            \"FTPT_analysis\":analysis_data_tr,\n",
        "            \"alpha\":aph\n",
        "\n",
        "            }, \"cifar_what_net_500.pt\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVzrDOGS4UxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d2bddc-bd60-4488-aa0a-f4c84c167139"
      },
      "source": [
        "aph"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0005374e-04, 9.9959618e-01, 0.0000000e+00, ..., 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
              "        9.9902248e-01, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 2.0686431e-01,\n",
              "        8.2193956e-02, 1.6953604e-01],\n",
              "       ...,\n",
              "       [9.8748684e-02, 0.0000000e+00, 2.7218416e-01, ..., 0.0000000e+00,\n",
              "        4.3199906e-01, 1.9706813e-01],\n",
              "       [4.1592899e-01, 5.8407104e-01, 0.0000000e+00, ..., 0.0000000e+00,\n",
              "        0.0000000e+00, 1.2627346e-28],\n",
              "       [0.0000000e+00, 0.0000000e+00, 4.8410900e-02, ..., 0.0000000e+00,\n",
              "        1.9929060e-01, 0.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6heHND15EMz"
      },
      "source": [
        "running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeKhsdpYWQvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae93d462-b3d9-4ef3-d1d1-339cd9a82cc2"
      },
      "source": [
        "print(\"argmax>0.5\",anls_data[-2])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "argmax>0.5 27090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF2bvWdIWUTa"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}