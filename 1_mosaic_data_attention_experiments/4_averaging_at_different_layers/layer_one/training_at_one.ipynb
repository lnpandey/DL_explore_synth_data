{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R2j0wT2NxUG",
        "colab_type": "code",
        "outputId": "bfa3a31f-3937-4063-a66a-f07759e71821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Models import Classification_Module4 as Classification_Module\n",
        "from Models import Focus_Module4 as Focus_Module\n",
        "from Mosaic import mosaic_data, MosaicDataset,split_foreground_background\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SblUamycPE7O",
        "colab_type": "code",
        "outputId": "d14e5f3e-aa12-41ec-dbe7-1af8a5fb2387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsd9DNgUPMBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = split_foreground_background(trainloader,total = 50000)\n",
        "mosaic_list_of_images,mosaic_label,fore_idx = mosaic_data(data,desired_num=30000,total=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC1dUctdPgmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "train_dataset  = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "mosaic_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCm_yFatRxib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mimages_val,mlabel_val,fidx_val = mosaic_data(data,desired_num=10000,total=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RccSHk3DU3jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "test_dataset  = MosaicDataset(mimages_val,mlabel_val,fidx_val)\n",
        "test_loader = DataLoader( test_dataset,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di1vx00TVFgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net =  Focus_Module(3,1).double()\n",
        "focus_net = focus_net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0wsFjYFVPfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classification_net  = Classification_Module(6,3).double()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz6llbjujOm8",
        "colab_type": "code",
        "outputId": "781f546f-0396-4e22-a05f-90fb382115fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "classification_net = classification_net.to(device)\n",
        "classification_net"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification_Module4(\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv1): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(12, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=1280, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emZvvTp0VbIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_focus = optim.SGD(focus_net.parameters(),lr = 0.01,momentum=0.9)\n",
        "optimizer_classification = optim.SGD(classification_net.parameters(),lr =0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cClaMnSRVfS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8iOl6JEVjJJ",
        "colab_type": "code",
        "outputId": "bbc2215b-df00-4462-c408-65f45dcf43a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tr_loss = []\n",
        "for epoch in range(110):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    cnt=0\n",
        "    iteration = 30000 // batch\n",
        "    ep_loss = []\n",
        "    for i, data in  enumerate(mosaic_loader):\n",
        "        inputs , labels , fgrnd_idx = data\n",
        "        inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "        optimizer_focus.zero_grad()\n",
        "        optimizer_classification.zero_grad()\n",
        "        avg_data , alphas = focus_net(inputs)\n",
        "        outputs = classification_net(avg_data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_focus.step()\n",
        "        optimizer_classification.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        mini = 40\n",
        "        if cnt % mini == mini-1:    # print every mini mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "            ep_loss.append(running_loss/mini)\n",
        "            running_loss = 0.0  \n",
        "        cnt=cnt+1\n",
        "    tr_loss.append(np.mean(ep_loss))      \n",
        "print('Finished Training')    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.106\n",
            "[1,    80] loss: 1.099\n",
            "[1,   120] loss: 1.099\n",
            "[2,    40] loss: 1.099\n",
            "[2,    80] loss: 1.098\n",
            "[2,   120] loss: 1.098\n",
            "[3,    40] loss: 1.098\n",
            "[3,    80] loss: 1.098\n",
            "[3,   120] loss: 1.098\n",
            "[4,    40] loss: 1.098\n",
            "[4,    80] loss: 1.098\n",
            "[4,   120] loss: 1.097\n",
            "[5,    40] loss: 1.097\n",
            "[5,    80] loss: 1.096\n",
            "[5,   120] loss: 1.094\n",
            "[6,    40] loss: 1.092\n",
            "[6,    80] loss: 1.091\n",
            "[6,   120] loss: 1.088\n",
            "[7,    40] loss: 1.085\n",
            "[7,    80] loss: 1.085\n",
            "[7,   120] loss: 1.081\n",
            "[8,    40] loss: 1.085\n",
            "[8,    80] loss: 1.078\n",
            "[8,   120] loss: 1.080\n",
            "[9,    40] loss: 1.081\n",
            "[9,    80] loss: 1.078\n",
            "[9,   120] loss: 1.077\n",
            "[10,    40] loss: 1.076\n",
            "[10,    80] loss: 1.077\n",
            "[10,   120] loss: 1.074\n",
            "[11,    40] loss: 1.069\n",
            "[11,    80] loss: 1.070\n",
            "[11,   120] loss: 1.072\n",
            "[12,    40] loss: 1.068\n",
            "[12,    80] loss: 1.063\n",
            "[12,   120] loss: 1.062\n",
            "[13,    40] loss: 1.059\n",
            "[13,    80] loss: 1.054\n",
            "[13,   120] loss: 1.054\n",
            "[14,    40] loss: 1.058\n",
            "[14,    80] loss: 1.050\n",
            "[14,   120] loss: 1.048\n",
            "[15,    40] loss: 1.049\n",
            "[15,    80] loss: 1.046\n",
            "[15,   120] loss: 1.045\n",
            "[16,    40] loss: 1.046\n",
            "[16,    80] loss: 1.040\n",
            "[16,   120] loss: 1.039\n",
            "[17,    40] loss: 1.043\n",
            "[17,    80] loss: 1.038\n",
            "[17,   120] loss: 1.037\n",
            "[18,    40] loss: 1.043\n",
            "[18,    80] loss: 1.036\n",
            "[18,   120] loss: 1.030\n",
            "[19,    40] loss: 1.028\n",
            "[19,    80] loss: 1.026\n",
            "[19,   120] loss: 1.026\n",
            "[20,    40] loss: 1.029\n",
            "[20,    80] loss: 1.016\n",
            "[20,   120] loss: 1.010\n",
            "[21,    40] loss: 1.006\n",
            "[21,    80] loss: 1.000\n",
            "[21,   120] loss: 0.997\n",
            "[22,    40] loss: 0.984\n",
            "[22,    80] loss: 0.984\n",
            "[22,   120] loss: 0.984\n",
            "[23,    40] loss: 0.967\n",
            "[23,    80] loss: 0.967\n",
            "[23,   120] loss: 0.963\n",
            "[24,    40] loss: 0.943\n",
            "[24,    80] loss: 0.949\n",
            "[24,   120] loss: 0.939\n",
            "[25,    40] loss: 0.937\n",
            "[25,    80] loss: 0.928\n",
            "[25,   120] loss: 0.914\n",
            "[26,    40] loss: 0.899\n",
            "[26,    80] loss: 0.911\n",
            "[26,   120] loss: 0.904\n",
            "[27,    40] loss: 0.896\n",
            "[27,    80] loss: 0.890\n",
            "[27,   120] loss: 0.885\n",
            "[28,    40] loss: 0.873\n",
            "[28,    80] loss: 0.877\n",
            "[28,   120] loss: 0.866\n",
            "[29,    40] loss: 0.849\n",
            "[29,    80] loss: 0.855\n",
            "[29,   120] loss: 0.832\n",
            "[30,    40] loss: 0.823\n",
            "[30,    80] loss: 0.814\n",
            "[30,   120] loss: 0.817\n",
            "[31,    40] loss: 0.801\n",
            "[31,    80] loss: 0.790\n",
            "[31,   120] loss: 0.805\n",
            "[32,    40] loss: 0.750\n",
            "[32,    80] loss: 0.769\n",
            "[32,   120] loss: 0.763\n",
            "[33,    40] loss: 0.747\n",
            "[33,    80] loss: 0.736\n",
            "[33,   120] loss: 0.730\n",
            "[34,    40] loss: 0.695\n",
            "[34,    80] loss: 0.711\n",
            "[34,   120] loss: 0.712\n",
            "[35,    40] loss: 0.681\n",
            "[35,    80] loss: 0.685\n",
            "[35,   120] loss: 0.646\n",
            "[36,    40] loss: 0.658\n",
            "[36,    80] loss: 0.647\n",
            "[36,   120] loss: 0.640\n",
            "[37,    40] loss: 0.611\n",
            "[37,    80] loss: 0.620\n",
            "[37,   120] loss: 0.614\n",
            "[38,    40] loss: 0.598\n",
            "[38,    80] loss: 0.596\n",
            "[38,   120] loss: 0.590\n",
            "[39,    40] loss: 0.555\n",
            "[39,    80] loss: 0.553\n",
            "[39,   120] loss: 0.569\n",
            "[40,    40] loss: 0.520\n",
            "[40,    80] loss: 0.539\n",
            "[40,   120] loss: 0.531\n",
            "[41,    40] loss: 0.496\n",
            "[41,    80] loss: 0.515\n",
            "[41,   120] loss: 0.508\n",
            "[42,    40] loss: 0.503\n",
            "[42,    80] loss: 0.486\n",
            "[42,   120] loss: 0.496\n",
            "[43,    40] loss: 0.450\n",
            "[43,    80] loss: 0.457\n",
            "[43,   120] loss: 0.472\n",
            "[44,    40] loss: 0.434\n",
            "[44,    80] loss: 0.434\n",
            "[44,   120] loss: 0.432\n",
            "[45,    40] loss: 0.378\n",
            "[45,    80] loss: 0.434\n",
            "[45,   120] loss: 0.422\n",
            "[46,    40] loss: 0.374\n",
            "[46,    80] loss: 0.384\n",
            "[46,   120] loss: 0.394\n",
            "[47,    40] loss: 0.360\n",
            "[47,    80] loss: 0.397\n",
            "[47,   120] loss: 0.398\n",
            "[48,    40] loss: 0.322\n",
            "[48,    80] loss: 0.393\n",
            "[48,   120] loss: 0.358\n",
            "[49,    40] loss: 0.314\n",
            "[49,    80] loss: 0.315\n",
            "[49,   120] loss: 0.337\n",
            "[50,    40] loss: 0.309\n",
            "[50,    80] loss: 0.315\n",
            "[50,   120] loss: 0.326\n",
            "[51,    40] loss: 0.278\n",
            "[51,    80] loss: 0.297\n",
            "[51,   120] loss: 0.308\n",
            "[52,    40] loss: 0.271\n",
            "[52,    80] loss: 0.286\n",
            "[52,   120] loss: 0.308\n",
            "[53,    40] loss: 0.271\n",
            "[53,    80] loss: 0.263\n",
            "[53,   120] loss: 0.255\n",
            "[54,    40] loss: 0.263\n",
            "[54,    80] loss: 0.268\n",
            "[54,   120] loss: 0.237\n",
            "[55,    40] loss: 0.199\n",
            "[55,    80] loss: 0.229\n",
            "[55,   120] loss: 0.242\n",
            "[56,    40] loss: 0.225\n",
            "[56,    80] loss: 0.214\n",
            "[56,   120] loss: 0.253\n",
            "[57,    40] loss: 0.200\n",
            "[57,    80] loss: 0.238\n",
            "[57,   120] loss: 0.222\n",
            "[58,    40] loss: 0.184\n",
            "[58,    80] loss: 0.216\n",
            "[58,   120] loss: 0.237\n",
            "[59,    40] loss: 0.185\n",
            "[59,    80] loss: 0.181\n",
            "[59,   120] loss: 0.200\n",
            "[60,    40] loss: 0.192\n",
            "[60,    80] loss: 0.172\n",
            "[60,   120] loss: 0.178\n",
            "[61,    40] loss: 0.127\n",
            "[61,    80] loss: 0.157\n",
            "[61,   120] loss: 0.192\n",
            "[62,    40] loss: 0.145\n",
            "[62,    80] loss: 0.153\n",
            "[62,   120] loss: 0.167\n",
            "[63,    40] loss: 0.122\n",
            "[63,    80] loss: 0.139\n",
            "[63,   120] loss: 0.152\n",
            "[64,    40] loss: 0.144\n",
            "[64,    80] loss: 0.143\n",
            "[64,   120] loss: 0.147\n",
            "[65,    40] loss: 0.118\n",
            "[65,    80] loss: 0.120\n",
            "[65,   120] loss: 0.139\n",
            "[66,    40] loss: 0.088\n",
            "[66,    80] loss: 0.155\n",
            "[66,   120] loss: 0.124\n",
            "[67,    40] loss: 0.118\n",
            "[67,    80] loss: 0.112\n",
            "[67,   120] loss: 0.109\n",
            "[68,    40] loss: 0.119\n",
            "[68,    80] loss: 0.119\n",
            "[68,   120] loss: 0.103\n",
            "[69,    40] loss: 0.120\n",
            "[69,    80] loss: 0.101\n",
            "[69,   120] loss: 0.106\n",
            "[70,    40] loss: 0.087\n",
            "[70,    80] loss: 0.105\n",
            "[70,   120] loss: 0.110\n",
            "[71,    40] loss: 0.065\n",
            "[71,    80] loss: 0.096\n",
            "[71,   120] loss: 0.093\n",
            "[72,    40] loss: 0.044\n",
            "[72,    80] loss: 0.080\n",
            "[72,   120] loss: 0.085\n",
            "[73,    40] loss: 0.089\n",
            "[73,    80] loss: 0.089\n",
            "[73,   120] loss: 0.107\n",
            "[74,    40] loss: 0.069\n",
            "[74,    80] loss: 0.083\n",
            "[74,   120] loss: 0.079\n",
            "[75,    40] loss: 0.069\n",
            "[75,    80] loss: 0.080\n",
            "[75,   120] loss: 0.091\n",
            "[76,    40] loss: 0.064\n",
            "[76,    80] loss: 0.061\n",
            "[76,   120] loss: 0.058\n",
            "[77,    40] loss: 0.052\n",
            "[77,    80] loss: 0.072\n",
            "[77,   120] loss: 0.083\n",
            "[78,    40] loss: 0.053\n",
            "[78,    80] loss: 0.040\n",
            "[78,   120] loss: 0.063\n",
            "[79,    40] loss: 0.050\n",
            "[79,    80] loss: 0.056\n",
            "[79,   120] loss: 0.066\n",
            "[80,    40] loss: 0.055\n",
            "[80,    80] loss: 0.068\n",
            "[80,   120] loss: 0.061\n",
            "[81,    40] loss: 0.045\n",
            "[81,    80] loss: 0.043\n",
            "[81,   120] loss: 0.057\n",
            "[82,    40] loss: 0.045\n",
            "[82,    80] loss: 0.041\n",
            "[82,   120] loss: 0.055\n",
            "[83,    40] loss: 0.034\n",
            "[83,    80] loss: 0.037\n",
            "[83,   120] loss: 0.037\n",
            "[84,    40] loss: 0.034\n",
            "[84,    80] loss: 0.053\n",
            "[84,   120] loss: 0.057\n",
            "[85,    40] loss: 0.049\n",
            "[85,    80] loss: 0.060\n",
            "[85,   120] loss: 0.045\n",
            "[86,    40] loss: 0.041\n",
            "[86,    80] loss: 0.054\n",
            "[86,   120] loss: 0.049\n",
            "[87,    40] loss: 0.049\n",
            "[87,    80] loss: 0.038\n",
            "[87,   120] loss: 0.045\n",
            "[88,    40] loss: 0.038\n",
            "[88,    80] loss: 0.053\n",
            "[88,   120] loss: 0.068\n",
            "[89,    40] loss: 0.038\n",
            "[89,    80] loss: 0.039\n",
            "[89,   120] loss: 0.047\n",
            "[90,    40] loss: 0.019\n",
            "[90,    80] loss: 0.032\n",
            "[90,   120] loss: 0.024\n",
            "[91,    40] loss: 0.017\n",
            "[91,    80] loss: 0.029\n",
            "[91,   120] loss: 0.033\n",
            "[92,    40] loss: 0.031\n",
            "[92,    80] loss: 0.030\n",
            "[92,   120] loss: 0.029\n",
            "[93,    40] loss: 0.031\n",
            "[93,    80] loss: 0.023\n",
            "[93,   120] loss: 0.024\n",
            "[94,    40] loss: 0.032\n",
            "[94,    80] loss: 0.021\n",
            "[94,   120] loss: 0.037\n",
            "[95,    40] loss: 0.052\n",
            "[95,    80] loss: 0.033\n",
            "[95,   120] loss: 0.025\n",
            "[96,    40] loss: 0.027\n",
            "[96,    80] loss: 0.024\n",
            "[96,   120] loss: 0.033\n",
            "[97,    40] loss: 0.044\n",
            "[97,    80] loss: 0.024\n",
            "[97,   120] loss: 0.028\n",
            "[98,    40] loss: 0.035\n",
            "[98,    80] loss: 0.027\n",
            "[98,   120] loss: 0.018\n",
            "[99,    40] loss: 0.033\n",
            "[99,    80] loss: 0.031\n",
            "[99,   120] loss: 0.021\n",
            "[100,    40] loss: 0.017\n",
            "[100,    80] loss: 0.015\n",
            "[100,   120] loss: 0.028\n",
            "[101,    40] loss: 0.038\n",
            "[101,    80] loss: 0.044\n",
            "[101,   120] loss: 0.034\n",
            "[102,    40] loss: 0.027\n",
            "[102,    80] loss: 0.033\n",
            "[102,   120] loss: 0.037\n",
            "[103,    40] loss: 0.027\n",
            "[103,    80] loss: 0.020\n",
            "[103,   120] loss: 0.021\n",
            "[104,    40] loss: 0.012\n",
            "[104,    80] loss: 0.012\n",
            "[104,   120] loss: 0.022\n",
            "[105,    40] loss: 0.022\n",
            "[105,    80] loss: 0.025\n",
            "[105,   120] loss: 0.025\n",
            "[106,    40] loss: 0.015\n",
            "[106,    80] loss: 0.016\n",
            "[106,   120] loss: 0.018\n",
            "[107,    40] loss: 0.015\n",
            "[107,    80] loss: 0.013\n",
            "[107,   120] loss: 0.015\n",
            "[108,    40] loss: 0.011\n",
            "[108,    80] loss: 0.014\n",
            "[108,   120] loss: 0.013\n",
            "[109,    40] loss: 0.009\n",
            "[109,    80] loss: 0.008\n",
            "[109,   120] loss: 0.010\n",
            "[110,    40] loss: 0.011\n",
            "[110,    80] loss: 0.014\n",
            "[110,   120] loss: 0.018\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lB7KlwGVpmd",
        "colab_type": "code",
        "outputId": "57970b69-2b75-4db3-c0eb-eb5fe8e2d58f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "train_acc = 0\n",
        "for i, data in enumerate(mosaic_loader):\n",
        "    inputs,labels,_ = data\n",
        "    inputs,labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    avg_data,alphas = focus_net(inputs)\n",
        "    outputs = classification_net(avg_data)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    # print(predicted.detach().cpu().numpy())\n",
        "    train_acc += sum(predicted.cpu().numpy() == labels.cpu().numpy())\n",
        "print(\"percentage train accuracy: \",train_acc/300) \n",
        "\n",
        "torch.save(focus_net.state_dict(),\"focus_net_at_one.pt\")\n",
        "torch.save(classification_net.state_dict(),\"classification_net_at_one.pt\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "percentage train accuracy:  99.55333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEdCv9Lfd6Pf",
        "colab_type": "code",
        "outputId": "bb0f8fab-c036-4a33-ce3c-56aaed26b0f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "val_acc = 0\n",
        "for i, data in enumerate(test_loader):\n",
        "    inputs,labels,_ = data\n",
        "    inputs,labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    avg_data,alphas = focus_net(inputs)\n",
        "    outputs = classification_net(avg_data)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "\n",
        "    val_acc +=sum(predicted.cpu().numpy() == labels.cpu().numpy())\n",
        "print(\"percentage validation accuracy: \",val_acc/100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "percentage validation accuracy:  81.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5MIz98beE2L",
        "colab_type": "code",
        "outputId": "191d9fe4-b5d1-4614-bc0e-29ae46fd7526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.figure(figsize = (5,4))\n",
        "plt.plot(tr_loss,label= \"training loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"cross entropy loss\")\n",
        "plt.savefig(\"training_loss_at_one.png\")\n",
        "plt.savefig(\"training_loss_at_one.pdf\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDF5iDVwYCZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}