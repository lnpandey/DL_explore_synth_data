{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "16 focus_pretrained_classify_pretrained_train_classify.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6bd7745d-bc52-4a33-d280-dd22af1a137b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acRFqJNrZErV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5106543c-9981-4c0b-d311-3ad3408254ce"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V_JUhwCeZErk",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SadRzWBBZEsP",
        "colab": {}
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 2)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBQffkIzTOsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "151bebdb-aa02-4e9f-e2e7-0d87330c03f9"
      },
      "source": [
        "focus_net.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Focus_net_weights/focus_net_6layer_cnn.pt\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZtcA4VOTVxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c315d4d-6764-4bd2-c9f2-b13f999e4bed"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=2, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMpRf9RETYRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "15001863-d8c2-4419-c131-606b46c8676a"
      },
      "source": [
        "print(focus_net.fc4)\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)\n",
        "temp = focus_net.fc4.weight.data\n",
        "temp2 = focus_net.fc4.bias.data\n",
        "focus_net.fc4 = nn.Linear(10,1).double()\n",
        "focus_net.fc4.weight.data = torch.unsqueeze(temp[1,:], 0)\n",
        "focus_net.fc4.bias.data = torch.unsqueeze(temp2[1], 0)\n",
        "focus_net = focus_net.to(\"cuda\")\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=10, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.3974,  0.2455,  0.2787, -0.4295, -0.5508,  0.8661, -0.2221, -0.6396,\n",
            "          0.5014,  0.1486],\n",
            "        [-0.1227,  0.1252, -0.0242,  0.3076,  0.7789, -0.7985, -0.2840,  0.6068,\n",
            "         -0.5138,  0.2816]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2738,  0.0337], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1227,  0.1252, -0.0242,  0.3076,  0.7789, -0.7985, -0.2840,  0.6068,\n",
            "         -0.5138,  0.2816]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0337], device='cuda:0', dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WFfxQ_3TYF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "afc6b996-0054-49ac-935b-0917c21985d9"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=1, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6tBJqBaTnl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  params.requires_grad = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLhPEuVoUBC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb28eea6-3687-44db-d0e4-23715e965d97"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwcTiFhGThJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12749b0d-7603-451f-e33c-711ecba6836c"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.0155e-01,  1.8843e-01, -3.7371e-01],\n",
            "          [ 1.3882e-01,  3.1465e-01, -2.3114e-01],\n",
            "          [-9.8712e-02,  1.7628e-01, -4.7682e-02]],\n",
            "\n",
            "         [[-1.7731e-01,  2.7669e-01, -1.6959e-02],\n",
            "          [-1.3041e-01,  1.1654e-01, -2.3628e-02],\n",
            "          [-1.8088e-01,  1.7182e-02,  2.2703e-01]],\n",
            "\n",
            "         [[ 2.6718e-01,  4.5371e-01, -1.1744e-02],\n",
            "          [ 1.3648e-01,  2.1359e-02, -3.3651e-01],\n",
            "          [-3.4207e-01, -2.8405e-01,  2.1965e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4553e-01, -3.1102e-01, -1.5143e-01],\n",
            "          [-7.8231e-02, -2.3423e-01, -1.1562e-01],\n",
            "          [ 4.3292e-03, -2.9985e-01, -1.6135e-01]],\n",
            "\n",
            "         [[ 2.3403e-01, -7.7107e-02,  2.3617e-01],\n",
            "          [ 7.9921e-03, -1.3719e-03, -1.2427e-01],\n",
            "          [-2.4708e-03, -1.7089e-01,  1.4559e-01]],\n",
            "\n",
            "         [[ 6.0008e-02,  2.2231e-01,  2.0222e-01],\n",
            "          [ 2.2929e-01, -5.4566e-03,  7.7658e-02],\n",
            "          [ 2.1009e-01, -2.0395e-02,  3.0434e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8955e-02, -8.9080e-02, -7.6312e-02],\n",
            "          [ 1.6654e-01,  9.1395e-02, -1.7210e-01],\n",
            "          [ 7.2608e-02,  3.6598e-02, -2.0946e-01]],\n",
            "\n",
            "         [[ 4.9694e-02,  3.4286e-02,  9.6677e-02],\n",
            "          [-9.4347e-02,  1.9066e-01, -1.7569e-01],\n",
            "          [ 2.2628e-01,  1.8944e-01,  1.0318e-01]],\n",
            "\n",
            "         [[-9.5871e-03,  2.3965e-02, -2.2961e-01],\n",
            "          [ 5.0691e-03, -1.2477e-03,  4.3030e-02],\n",
            "          [ 1.1552e-01,  5.2009e-02,  4.5297e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1273e-02,  1.1986e-01,  1.9651e-01],\n",
            "          [-1.0910e-01,  2.1594e-01,  2.3334e-01],\n",
            "          [-7.5300e-02, -1.2681e-01, -5.3049e-02]],\n",
            "\n",
            "         [[-4.8859e-02, -8.2950e-02, -1.8400e-01],\n",
            "          [-2.3791e-01, -8.6627e-02, -1.3185e-01],\n",
            "          [-1.8958e-02, -8.0871e-02, -1.0580e-01]],\n",
            "\n",
            "         [[-7.4944e-02, -1.2411e-01, -5.2474e-02],\n",
            "          [-2.0770e-02,  1.5161e-01, -1.6706e-01],\n",
            "          [-4.3331e-02,  1.3538e-01, -1.8715e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.3778e-03, -7.8674e-02,  1.9848e-01],\n",
            "          [-2.3493e-01,  1.7573e-01,  2.7151e-01],\n",
            "          [-2.2664e-02, -1.1002e-02, -6.5587e-02]],\n",
            "\n",
            "         [[ 1.9978e-01,  1.4815e-02,  1.0615e-02],\n",
            "          [ 2.0002e-01, -1.1983e-01,  1.5939e-01],\n",
            "          [-2.4128e-01, -1.4317e-01,  8.0474e-02]],\n",
            "\n",
            "         [[-1.4341e-01, -1.1064e-01, -2.6179e-01],\n",
            "          [ 2.1648e-01, -9.9564e-02,  1.6842e-02],\n",
            "          [ 1.1194e-01,  1.4890e-02,  1.9808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5718e-01,  6.6356e-03, -8.6083e-02],\n",
            "          [ 8.0345e-02, -1.1381e-01, -4.6426e-03],\n",
            "          [-1.2109e-01,  1.1055e-01,  2.1551e-01]],\n",
            "\n",
            "         [[ 1.5790e-01, -7.3243e-04, -1.1624e-01],\n",
            "          [ 2.9433e-01,  1.5650e-01, -2.7937e-01],\n",
            "          [ 1.0816e-01, -4.2703e-02,  1.1360e-01]],\n",
            "\n",
            "         [[-2.3966e-02, -1.7138e-01, -5.5875e-02],\n",
            "          [-1.1881e-01, -1.9345e-01, -3.4012e-01],\n",
            "          [ 7.5994e-02, -1.8580e-01,  5.1822e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5608e-01,  1.4220e-01, -1.9261e-01],\n",
            "          [ 2.8186e-01, -1.1467e-01, -3.0065e-02],\n",
            "          [-1.9499e-01, -8.0530e-04,  1.7978e-01]],\n",
            "\n",
            "         [[-2.9561e-01, -1.4465e-01, -3.8936e-02],\n",
            "          [ 2.7009e-01, -1.0709e-01,  1.9911e-01],\n",
            "          [-1.6047e-01,  1.9247e-01,  2.6052e-01]],\n",
            "\n",
            "         [[-1.3410e-01, -1.0264e-01, -2.3493e-01],\n",
            "          [ 3.7941e-01, -4.1826e-02, -2.3835e-01],\n",
            "          [ 1.5829e-01,  1.4479e-01, -7.7649e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4260e-02,  7.2909e-02, -4.9308e-01],\n",
            "          [ 1.9709e-01,  2.9608e-01,  4.4813e-02],\n",
            "          [ 1.8176e-01,  3.3937e-01,  1.7607e-01]],\n",
            "\n",
            "         [[-5.0911e-02,  2.4422e-01, -2.6483e-01],\n",
            "          [-2.5324e-01, -2.8686e-01, -1.1130e-01],\n",
            "          [-7.3526e-02, -1.8883e-01, -1.8568e-01]],\n",
            "\n",
            "         [[-3.3020e-02,  3.4905e-01,  9.6184e-02],\n",
            "          [ 9.3889e-02,  5.0457e-02, -4.1922e-02],\n",
            "          [-2.5109e-02, -1.0685e-01, -1.3722e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4828e-02,  9.2095e-04, -7.6290e-02],\n",
            "          [ 3.3454e-02,  3.7860e-01, -2.8654e-01],\n",
            "          [ 1.4552e-01,  7.2081e-02, -1.9682e-01]],\n",
            "\n",
            "         [[-3.7882e-02,  2.0972e-01, -2.3378e-01],\n",
            "          [-7.0486e-02,  4.0031e-01, -3.3082e-01],\n",
            "          [-2.2034e-01,  2.4179e-01, -7.7592e-02]],\n",
            "\n",
            "         [[-2.3171e-01,  2.7509e-01, -2.9406e-02],\n",
            "          [-2.5366e-01,  5.2276e-01, -3.5181e-01],\n",
            "          [ 4.7083e-02,  1.1258e-01, -2.4963e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2920e-02,  1.1366e-01, -1.0895e-01],\n",
            "          [-5.3343e-02,  1.6217e-02, -2.0651e-02],\n",
            "          [ 1.1660e-01,  9.8321e-02, -1.2359e-01]],\n",
            "\n",
            "         [[-3.4368e-02, -7.0742e-02, -2.5050e-01],\n",
            "          [-2.7087e-02,  1.4293e-01, -2.2920e-01],\n",
            "          [ 1.4525e-01,  1.4925e-02, -2.0972e-01]],\n",
            "\n",
            "         [[-2.4625e-01, -2.5307e-03, -2.1292e-02],\n",
            "          [ 2.9386e-02,  8.7204e-02,  1.4329e-01],\n",
            "          [ 2.4719e-01,  2.8453e-01,  9.2273e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.5100e-01, -1.5544e-01,  3.7412e-01],\n",
            "          [ 3.4293e-01, -6.4277e-02, -1.9676e-01],\n",
            "          [ 1.5227e-01, -4.3687e-02, -1.8680e-01]],\n",
            "\n",
            "         [[-3.5154e-01, -4.3465e-02,  7.8562e-02],\n",
            "          [ 3.2783e-01, -9.1473e-02, -7.4105e-02],\n",
            "          [ 1.5686e-01,  6.4711e-03,  4.9247e-02]],\n",
            "\n",
            "         [[ 1.0901e-01,  1.3724e-01,  1.4471e-01],\n",
            "          [ 3.8507e-01, -1.8206e-01, -9.0550e-02],\n",
            "          [ 1.8527e-02, -2.1300e-01, -2.1008e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.0009e-01,  5.2350e-02, -1.7434e-02],\n",
            "          [-1.3890e-01, -2.8554e-01,  1.3410e-01],\n",
            "          [-3.7519e-02, -5.1394e-01,  6.2113e-02]],\n",
            "\n",
            "         [[ 4.7610e-02,  1.4115e-01,  1.9123e-02],\n",
            "          [ 3.4660e-01,  1.0914e-01,  2.8330e-01],\n",
            "          [ 3.0530e-01, -1.6982e-01,  2.7858e-01]],\n",
            "\n",
            "         [[ 3.8899e-02, -4.2711e-03, -1.3205e-01],\n",
            "          [ 1.0196e-01, -2.7844e-01, -8.7242e-03],\n",
            "          [ 1.2730e-01, -2.8913e-01, -8.2701e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6047e-01,  3.1003e-01, -1.1233e-01],\n",
            "          [ 3.3223e-01,  2.9437e-01, -9.5160e-02],\n",
            "          [ 2.0716e-01, -2.9966e-01, -3.4367e-01]],\n",
            "\n",
            "         [[-2.8085e-01,  1.4637e-01, -3.4782e-02],\n",
            "          [ 1.6125e-03,  1.8891e-01,  2.3948e-01],\n",
            "          [-1.1145e-01, -1.3817e-01, -1.6709e-01]],\n",
            "\n",
            "         [[-4.5610e-01,  2.2247e-01,  2.1565e-01],\n",
            "          [-1.8045e-01, -1.5446e-01,  1.1526e-01],\n",
            "          [-1.5825e-01,  7.3281e-02,  3.5264e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1864e-01, -6.0254e-02,  9.2982e-02],\n",
            "          [ 1.4388e-01, -7.3523e-02, -2.0167e-01],\n",
            "          [-2.3147e-01,  1.1375e-01,  7.0444e-02]],\n",
            "\n",
            "         [[-4.4879e-02,  1.4091e-01, -1.9945e-01],\n",
            "          [ 2.1282e-01,  2.5781e-01,  1.0941e-01],\n",
            "          [-8.7437e-02,  1.2557e-01, -1.6704e-01]],\n",
            "\n",
            "         [[-8.5735e-02, -2.8465e-02, -7.9197e-02],\n",
            "          [ 5.6643e-02,  2.0363e-01,  4.2784e-02],\n",
            "          [ 8.6233e-03, -2.0354e-02, -3.6712e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.3492e-02, -1.5458e-01,  5.7564e-03],\n",
            "          [-3.7472e-02,  1.1123e-01, -2.3172e-01],\n",
            "          [ 1.0602e-01, -1.8604e-02, -1.4651e-01]],\n",
            "\n",
            "         [[-2.5336e-04, -5.2469e-03,  1.1831e-01],\n",
            "          [ 4.4008e-02, -9.3524e-02, -9.1982e-02],\n",
            "          [ 3.3203e-02, -1.1195e-01,  5.3600e-02]],\n",
            "\n",
            "         [[ 7.1521e-02,  3.1856e-02,  1.9880e-01],\n",
            "          [ 9.1581e-02, -6.5490e-02, -2.6157e-01],\n",
            "          [-6.2403e-02,  3.3127e-02, -9.8168e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4214e-01, -2.6254e-01, -2.4894e-01],\n",
            "          [ 6.0782e-02,  1.4442e-01, -4.1070e-02],\n",
            "          [ 2.3767e-01,  3.2218e-01,  1.7166e-01]],\n",
            "\n",
            "         [[ 6.9931e-02,  3.2418e-03,  5.9026e-02],\n",
            "          [ 9.8867e-02, -7.6754e-02, -1.1897e-01],\n",
            "          [-1.5324e-01,  2.3701e-01,  7.7406e-02]],\n",
            "\n",
            "         [[-1.8112e-02,  3.6124e-02,  8.8124e-02],\n",
            "          [ 5.1065e-03,  1.4502e-01, -1.0826e-01],\n",
            "          [-1.1482e-01,  1.5715e-01, -2.1675e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9496e-02, -2.3513e-01,  1.3399e-01],\n",
            "          [ 1.5434e-02,  1.2206e-01,  1.7543e-01],\n",
            "          [ 1.8777e-01,  6.9283e-02,  3.6612e-02]],\n",
            "\n",
            "         [[ 1.0813e-01, -9.1666e-02, -5.8822e-02],\n",
            "          [-1.7935e-01, -1.3325e-01, -9.2677e-02],\n",
            "          [ 1.5984e-02,  1.3427e-01, -1.9313e-01]],\n",
            "\n",
            "         [[-1.0145e-01, -1.7560e-01, -1.0277e-01],\n",
            "          [-4.1589e-02, -2.2296e-01, -2.0368e-02],\n",
            "          [-5.1968e-02, -9.4545e-02, -1.5786e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.8242e-01, -1.6982e-02,  1.2589e-01],\n",
            "          [-3.1782e-02, -1.3494e-02, -2.8895e-01],\n",
            "          [ 1.3941e-01, -1.0287e-01, -1.0379e-01]],\n",
            "\n",
            "         [[-2.7262e-01,  1.4852e-01,  1.4684e-01],\n",
            "          [ 7.8490e-02,  2.7467e-01,  1.6855e-02],\n",
            "          [ 3.8027e-01,  3.0940e-01,  1.7866e-02]],\n",
            "\n",
            "         [[-3.0519e-01,  2.7818e-02,  1.2216e-01],\n",
            "          [-2.1921e-01, -7.9760e-02, -2.0103e-04],\n",
            "          [ 1.7404e-01, -1.8248e-01, -1.4009e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0714e-01,  1.7765e-01, -3.0915e-01],\n",
            "          [-2.0353e-02, -1.6578e-01,  3.7074e-01],\n",
            "          [ 1.7386e-01, -2.7412e-01,  2.9055e-02]],\n",
            "\n",
            "         [[-1.2439e-01,  1.0872e-01, -1.7823e-01],\n",
            "          [-1.0632e-01, -2.9516e-01,  3.7788e-01],\n",
            "          [ 3.0583e-01, -4.0840e-01,  1.3042e-01]],\n",
            "\n",
            "         [[ 2.9924e-01,  8.6759e-02, -3.3583e-01],\n",
            "          [-1.1813e-02, -2.6363e-01,  4.2833e-01],\n",
            "          [-3.5804e-02, -3.3204e-01,  2.4581e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.5675e-02,  2.5866e-01,  1.2688e-01],\n",
            "          [-1.1888e-01,  2.3120e-01,  1.8862e-01],\n",
            "          [-1.0078e-01, -2.2704e-01, -3.4244e-01]],\n",
            "\n",
            "         [[ 2.7898e-02,  2.4486e-01,  1.8591e-01],\n",
            "          [ 2.0807e-01,  1.1544e-01,  4.7624e-03],\n",
            "          [ 3.2926e-02,  1.8853e-01, -1.2424e-01]],\n",
            "\n",
            "         [[-2.4558e-01, -1.8506e-01, -1.5971e-01],\n",
            "          [-2.0672e-01,  2.0476e-02, -1.1053e-01],\n",
            "          [ 2.1770e-01,  2.2833e-01, -8.8387e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.5205e-02,  1.5520e-01, -1.9695e-01],\n",
            "          [-7.9760e-02,  8.1679e-02, -6.8232e-02],\n",
            "          [ 1.6093e-03, -1.5213e-01, -1.2683e-01]],\n",
            "\n",
            "         [[ 1.8469e-01, -3.6921e-02, -1.7115e-01],\n",
            "          [ 8.1758e-02, -1.6792e-01, -6.7049e-02],\n",
            "          [ 1.6663e-01, -6.6594e-02,  1.2634e-01]],\n",
            "\n",
            "         [[-3.6184e-01, -6.5170e-02, -1.0652e-01],\n",
            "          [-4.7971e-01,  1.4482e-01,  4.2907e-01],\n",
            "          [-2.5983e-01,  2.9876e-01,  5.4646e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8698e-02, -1.1509e-01,  3.1465e-01],\n",
            "          [-2.2665e-01,  1.1842e-01, -1.0207e-01],\n",
            "          [-2.1049e-01, -7.1634e-02,  2.3764e-01]],\n",
            "\n",
            "         [[ 1.5028e-01, -1.8738e-01,  1.2004e-01],\n",
            "          [ 1.6371e-01, -1.7511e-03, -2.4908e-01],\n",
            "          [-5.7438e-02,  2.1253e-01,  4.7965e-02]],\n",
            "\n",
            "         [[ 2.8607e-01, -1.4524e-01, -2.5859e-01],\n",
            "          [ 2.9987e-01,  5.0431e-02, -5.1815e-01],\n",
            "          [ 2.1397e-01,  2.9649e-01, -3.1808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8467e-02, -9.7171e-02, -6.5884e-02],\n",
            "          [ 4.7044e-03, -1.2399e-01,  1.3729e-01],\n",
            "          [-1.0409e-01,  1.7758e-01,  1.4271e-01]],\n",
            "\n",
            "         [[ 1.8816e-01,  7.7143e-02, -1.2912e-02],\n",
            "          [ 1.1297e-01, -2.5210e-01, -2.2299e-01],\n",
            "          [-2.8796e-01,  8.2649e-02, -8.7493e-02]],\n",
            "\n",
            "         [[ 2.1926e-01,  2.2060e-01,  1.7361e-01],\n",
            "          [-2.0023e-02,  1.5427e-01,  6.1582e-02],\n",
            "          [-2.0668e-01, -1.0826e-01,  1.1648e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5940e-01,  1.1073e-01, -1.7217e-02],\n",
            "          [-1.0682e-01,  6.4494e-02,  1.4025e-01],\n",
            "          [-8.2975e-02, -1.8486e-01, -2.2712e-01]],\n",
            "\n",
            "         [[-8.8423e-02,  1.4320e-01, -2.0304e-02],\n",
            "          [-5.0818e-03,  1.7296e-01, -8.4649e-02],\n",
            "          [ 6.2910e-03, -1.7587e-01, -2.0314e-02]],\n",
            "\n",
            "         [[-8.5325e-02, -1.5731e-01, -1.0675e-01],\n",
            "          [ 1.9048e-01,  1.6936e-01,  6.7662e-03],\n",
            "          [-2.7817e-05,  9.5952e-02, -2.4236e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1579e-01,  1.7570e-01, -1.1779e-01],\n",
            "          [ 2.0060e-03, -1.0404e-01,  1.3824e-01],\n",
            "          [-1.1473e-01,  3.1071e-02,  1.7744e-01]],\n",
            "\n",
            "         [[ 6.9442e-02, -1.5036e-02,  5.4487e-02],\n",
            "          [-5.8634e-02, -1.4846e-01,  9.5080e-02],\n",
            "          [ 1.6324e-01, -1.5676e-02, -8.4563e-02]],\n",
            "\n",
            "         [[ 1.1528e-01, -1.1609e-01,  2.9263e-03],\n",
            "          [ 5.4937e-02, -1.5815e-01,  1.8128e-01],\n",
            "          [ 1.5560e-01,  1.3262e-01,  1.8461e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1694e-01, -2.9142e-01, -2.6329e-01],\n",
            "          [-1.2755e-01, -1.9556e-01,  3.8795e-02],\n",
            "          [ 3.4141e-01,  3.4313e-01,  1.9673e-01]],\n",
            "\n",
            "         [[-1.2067e-01, -2.4652e-01,  3.6027e-03],\n",
            "          [-1.8045e-01,  1.0407e-01, -1.6403e-01],\n",
            "          [ 5.5994e-02,  2.2146e-01, -1.2961e-01]],\n",
            "\n",
            "         [[ 1.9381e-01, -3.1823e-02,  2.0926e-01],\n",
            "          [ 7.3488e-02, -8.3086e-02,  2.8715e-02],\n",
            "          [-1.1377e-01,  2.3878e-01, -1.3486e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6004e-02,  2.2558e-01,  1.3777e-01],\n",
            "          [ 1.4699e-01, -1.7660e-01, -9.6174e-02],\n",
            "          [-8.1804e-02, -1.1437e-01, -6.4043e-02]],\n",
            "\n",
            "         [[-1.8785e-01,  1.2662e-01,  1.1054e-01],\n",
            "          [ 6.8984e-02, -1.8815e-01, -4.3549e-02],\n",
            "          [ 2.6759e-01, -7.3002e-02, -8.8331e-02]],\n",
            "\n",
            "         [[-2.2460e-01, -8.1323e-02,  2.9143e-01],\n",
            "          [-2.5683e-01, -9.4635e-02,  2.5643e-01],\n",
            "          [-1.2625e-02, -2.2122e-01,  4.7715e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.8392e-02, -2.1575e-01, -2.8500e-02],\n",
            "          [-2.5681e-01, -2.5748e-01,  1.5143e-01],\n",
            "          [ 2.5797e-01,  3.1017e-01,  5.0137e-03]],\n",
            "\n",
            "         [[ 8.3711e-02, -2.3980e-01, -7.0890e-02],\n",
            "          [-9.5829e-02, -1.9823e-01,  2.7156e-01],\n",
            "          [-2.6914e-02,  2.7501e-01, -3.1315e-02]],\n",
            "\n",
            "         [[-1.3819e-01,  4.2787e-02,  3.4596e-02],\n",
            "          [-1.1717e-01, -1.7322e-01,  1.3440e-01],\n",
            "          [ 4.9149e-02, -5.2634e-02, -1.1780e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1362e-01,  4.8102e-02,  3.4139e-01],\n",
            "          [ 3.4290e-02, -2.4965e-01,  2.7953e-01],\n",
            "          [-1.6447e-01,  9.0822e-04,  2.3792e-01]],\n",
            "\n",
            "         [[-4.8142e-02, -1.0798e-01,  3.7232e-01],\n",
            "          [-1.0745e-02, -4.9819e-01,  8.5103e-02],\n",
            "          [ 1.1553e-01, -2.4784e-01,  1.5701e-01]],\n",
            "\n",
            "         [[-1.1495e-01, -2.1601e-01,  1.0106e-01],\n",
            "          [ 2.3005e-01, -3.2803e-01, -8.3869e-02],\n",
            "          [ 2.2454e-01, -1.0049e-02,  2.0753e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3836e-01,  3.2456e-01,  3.3695e-01],\n",
            "          [-2.4138e-01, -2.9768e-01, -1.5685e-01],\n",
            "          [-9.5723e-02, -7.9013e-02, -1.9312e-01]],\n",
            "\n",
            "         [[ 1.3153e-01,  6.7787e-02,  2.1433e-01],\n",
            "          [-2.6171e-01, -2.9836e-01, -2.0850e-01],\n",
            "          [ 1.0682e-01,  1.0624e-01, -1.6899e-01]],\n",
            "\n",
            "         [[ 1.7010e-01, -3.2429e-02, -1.2887e-02],\n",
            "          [-3.4082e-02, -2.3638e-01, -8.2708e-02],\n",
            "          [ 8.6260e-02,  2.9735e-01, -1.4077e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4088e-01,  2.0552e-01, -6.8858e-02],\n",
            "          [-1.4319e-02, -1.5148e-01, -2.4972e-01],\n",
            "          [ 2.8147e-01, -1.4573e-01, -1.2848e-01]],\n",
            "\n",
            "         [[-1.1730e-01, -4.3468e-02, -1.5309e-01],\n",
            "          [ 6.0057e-02, -1.9846e-01, -1.4349e-02],\n",
            "          [ 2.6214e-01,  1.4849e-01, -1.9905e-01]],\n",
            "\n",
            "         [[-1.7688e-01,  2.2597e-01, -1.7985e-01],\n",
            "          [ 1.3996e-01, -6.4199e-02, -1.3442e-01],\n",
            "          [ 2.9831e-01, -8.8765e-04,  5.7207e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.3738e-02, -6.5191e-02,  1.1433e-01],\n",
            "          [-5.4104e-02,  1.0246e-01,  1.1657e-01],\n",
            "          [-2.1356e-01, -1.6824e-01,  6.3947e-02]],\n",
            "\n",
            "         [[-9.3507e-02, -3.5852e-02,  4.9805e-02],\n",
            "          [ 1.4713e-01, -1.3346e-01, -1.2432e-01],\n",
            "          [-2.2472e-01, -1.8936e-01,  1.7751e-01]],\n",
            "\n",
            "         [[-7.8939e-02,  4.8241e-02, -1.3442e-01],\n",
            "          [ 1.6475e-02, -3.7413e-02,  2.9886e-01],\n",
            "          [-2.3843e-01, -1.1041e-02,  1.7069e-01]]]], device='cuda:0',\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e417ef6-7176-4534-fbc9-4311ef4c2d7d"
      },
      "source": [
        "classify.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Classify_net_weights/classify_net_6layer_cnn.pt\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJSnUYJyS0Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in classify.parameters():\n",
        "#   params.requires_grad = False"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JM19FiENmBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a3ff56c-fe78-465e-a353-747bea261d57"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break\n",
        "  "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0rkwoqLpya8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84834d3a-eafc-43cf-bf2c-f3ffaec4671f"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0309,  0.1087,  0.1955],\n",
            "          [ 0.2209,  0.0076,  0.0348],\n",
            "          [-0.0854,  0.0774, -0.0973]],\n",
            "\n",
            "         [[ 0.0616, -0.1282,  0.2080],\n",
            "          [ 0.0332, -0.1826, -0.1365],\n",
            "          [-0.1557, -0.0844, -0.1973]],\n",
            "\n",
            "         [[-0.0722,  0.0364,  0.1260],\n",
            "          [ 0.0611, -0.0341,  0.1729],\n",
            "          [ 0.0427,  0.0797,  0.0223]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1835,  0.0366, -0.1656],\n",
            "          [-0.0834,  0.1659,  0.0364],\n",
            "          [ 0.1062,  0.2152,  0.1314]],\n",
            "\n",
            "         [[ 0.0086,  0.2094,  0.2249],\n",
            "          [-0.1404, -0.1745,  0.0035],\n",
            "          [-0.2156,  0.0847,  0.0851]],\n",
            "\n",
            "         [[-0.1070,  0.1605, -0.1541],\n",
            "          [-0.0419, -0.0417,  0.0718],\n",
            "          [-0.0668, -0.2273, -0.2890]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1013,  0.0165, -0.0829],\n",
            "          [-0.1709,  0.1888, -0.0619],\n",
            "          [-0.0676,  0.2545,  0.2560]],\n",
            "\n",
            "         [[-0.0495, -0.0233, -0.0692],\n",
            "          [ 0.0196, -0.1944, -0.2639],\n",
            "          [-0.2429,  0.0565,  0.1495]],\n",
            "\n",
            "         [[ 0.2412, -0.1480, -0.1188],\n",
            "          [ 0.0755,  0.0533, -0.1636],\n",
            "          [ 0.1195,  0.0296, -0.0620]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2049,  0.1405, -0.0744],\n",
            "          [ 0.0715,  0.0253,  0.0548],\n",
            "          [-0.0363, -0.0603, -0.0169]],\n",
            "\n",
            "         [[ 0.1719, -0.0024,  0.1642],\n",
            "          [ 0.0824, -0.1403,  0.0444],\n",
            "          [ 0.1660, -0.0140, -0.0213]],\n",
            "\n",
            "         [[-0.1377,  0.0023,  0.0830],\n",
            "          [-0.0201,  0.0463, -0.1071],\n",
            "          [-0.0089, -0.0475,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1722, -0.1703,  0.0900],\n",
            "          [-0.0026, -0.1981, -0.0808],\n",
            "          [-0.0556, -0.0525, -0.0903]],\n",
            "\n",
            "         [[ 0.0469,  0.1535,  0.1791],\n",
            "          [ 0.0031, -0.1002,  0.1474],\n",
            "          [-0.2295,  0.1191,  0.0080]],\n",
            "\n",
            "         [[ 0.1878,  0.0110,  0.1277],\n",
            "          [ 0.0146,  0.1758,  0.1353],\n",
            "          [-0.1670,  0.1439, -0.0813]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1690,  0.1051, -0.0433],\n",
            "          [-0.2494,  0.0010,  0.0629],\n",
            "          [-0.0552,  0.0004,  0.0097]],\n",
            "\n",
            "         [[ 0.1635,  0.3134,  0.0763],\n",
            "          [-0.1233,  0.0560, -0.2310],\n",
            "          [-0.1199, -0.2663, -0.0928]],\n",
            "\n",
            "         [[ 0.0838,  0.1768,  0.0256],\n",
            "          [-0.2400,  0.1630, -0.2009],\n",
            "          [ 0.0774, -0.0150,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1059,  0.0585, -0.1707],\n",
            "          [ 0.1078, -0.0531, -0.0276],\n",
            "          [ 0.1118, -0.0519, -0.1506]],\n",
            "\n",
            "         [[-0.1614,  0.1542, -0.1130],\n",
            "          [ 0.1823,  0.1833,  0.1834],\n",
            "          [ 0.0840, -0.0238,  0.0096]],\n",
            "\n",
            "         [[ 0.1863,  0.0509, -0.1148],\n",
            "          [-0.0720,  0.1801, -0.0417],\n",
            "          [ 0.0088,  0.0210, -0.0527]]],\n",
            "\n",
            "\n",
            "        [[[-0.0021, -0.1920, -0.1925],\n",
            "          [-0.0794, -0.1094, -0.1952],\n",
            "          [ 0.0640, -0.1527, -0.1590]],\n",
            "\n",
            "         [[ 0.0023, -0.0093,  0.0917],\n",
            "          [ 0.1893,  0.1771, -0.0419],\n",
            "          [ 0.1959,  0.0765, -0.1216]],\n",
            "\n",
            "         [[ 0.1127, -0.0509, -0.0890],\n",
            "          [ 0.0425, -0.0004,  0.0970],\n",
            "          [ 0.1725, -0.0294,  0.2238]]],\n",
            "\n",
            "\n",
            "        [[[-0.1533,  0.2030, -0.1170],\n",
            "          [ 0.0515, -0.0504, -0.1635],\n",
            "          [-0.1322, -0.1429,  0.1475]],\n",
            "\n",
            "         [[ 0.0555, -0.0411,  0.2137],\n",
            "          [-0.0274, -0.0902,  0.0513],\n",
            "          [ 0.0085, -0.1591,  0.1483]],\n",
            "\n",
            "         [[ 0.1163, -0.1371,  0.0318],\n",
            "          [ 0.0841, -0.2464, -0.2148],\n",
            "          [ 0.0637,  0.1322,  0.0676]]],\n",
            "\n",
            "\n",
            "        [[[-0.0227,  0.0487,  0.2023],\n",
            "          [-0.1330,  0.1492, -0.0169],\n",
            "          [ 0.1584,  0.1524, -0.0456]],\n",
            "\n",
            "         [[-0.0525, -0.1646, -0.0814],\n",
            "          [-0.2456, -0.1350,  0.0154],\n",
            "          [ 0.2309, -0.1780, -0.0720]],\n",
            "\n",
            "         [[-0.0142,  0.0480,  0.2516],\n",
            "          [-0.1593,  0.1562,  0.1928],\n",
            "          [-0.1119, -0.2044, -0.1976]]],\n",
            "\n",
            "\n",
            "        [[[-0.0355,  0.1166, -0.0631],\n",
            "          [-0.0836, -0.1515,  0.1577],\n",
            "          [ 0.0235,  0.1110, -0.0250]],\n",
            "\n",
            "         [[-0.2114,  0.1654,  0.2484],\n",
            "          [ 0.0525,  0.2583,  0.0362],\n",
            "          [-0.0713,  0.1357, -0.0152]],\n",
            "\n",
            "         [[-0.0821, -0.0350, -0.1481],\n",
            "          [-0.2171,  0.0489,  0.2106],\n",
            "          [ 0.1037, -0.1230,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.1625,  0.1384],\n",
            "          [-0.1124, -0.1412,  0.2642],\n",
            "          [ 0.0284, -0.0494, -0.0447]],\n",
            "\n",
            "         [[ 0.0205, -0.2302,  0.1754],\n",
            "          [ 0.0924, -0.2460,  0.2219],\n",
            "          [ 0.0863, -0.1062,  0.1210]],\n",
            "\n",
            "         [[ 0.2537, -0.2292, -0.1540],\n",
            "          [ 0.2104, -0.2362,  0.1700],\n",
            "          [ 0.2093, -0.2085, -0.0309]]],\n",
            "\n",
            "\n",
            "        [[[-0.1426,  0.1824, -0.2160],\n",
            "          [ 0.0009, -0.0087,  0.0207],\n",
            "          [ 0.0911, -0.2336, -0.1702]],\n",
            "\n",
            "         [[ 0.2153,  0.1894,  0.0243],\n",
            "          [-0.2433,  0.2294,  0.2479],\n",
            "          [-0.0595, -0.1203,  0.1227]],\n",
            "\n",
            "         [[-0.1597,  0.1976, -0.1576],\n",
            "          [-0.1258, -0.0205, -0.1531],\n",
            "          [ 0.1347,  0.0364, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[-0.0633, -0.0466, -0.0325],\n",
            "          [-0.0601,  0.0621, -0.0215],\n",
            "          [-0.0044, -0.0534,  0.0422]],\n",
            "\n",
            "         [[-0.1383, -0.1374, -0.1793],\n",
            "          [-0.0877, -0.1327,  0.0918],\n",
            "          [-0.0787,  0.0740, -0.0112]],\n",
            "\n",
            "         [[ 0.0814,  0.0275, -0.1438],\n",
            "          [-0.0439,  0.1876,  0.1383],\n",
            "          [-0.0834,  0.1108,  0.0304]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0447,  0.0499, -0.1449],\n",
            "          [-0.1171, -0.0733,  0.0182],\n",
            "          [-0.0587, -0.1367, -0.1931]],\n",
            "\n",
            "         [[ 0.0961,  0.0888, -0.0784],\n",
            "          [ 0.0504, -0.1259,  0.0890],\n",
            "          [-0.1473,  0.0371,  0.1020]],\n",
            "\n",
            "         [[ 0.0476, -0.1709, -0.0371],\n",
            "          [ 0.2308,  0.1298,  0.0326],\n",
            "          [-0.0171, -0.0634, -0.1609]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2378, -0.1200, -0.2246],\n",
            "          [ 0.2465,  0.0634, -0.1682],\n",
            "          [-0.0573, -0.1788,  0.0856]],\n",
            "\n",
            "         [[ 0.2020,  0.1478, -0.0181],\n",
            "          [ 0.1683,  0.0819, -0.0775],\n",
            "          [ 0.1869, -0.2327, -0.2108]],\n",
            "\n",
            "         [[-0.0383, -0.1762, -0.0893],\n",
            "          [-0.1869,  0.0115,  0.0917],\n",
            "          [ 0.0562, -0.0899,  0.1009]]],\n",
            "\n",
            "\n",
            "        [[[-0.0911, -0.2512,  0.0277],\n",
            "          [-0.0324,  0.1520,  0.2214],\n",
            "          [ 0.1329, -0.0946,  0.1157]],\n",
            "\n",
            "         [[ 0.1063, -0.1710,  0.0471],\n",
            "          [-0.1126,  0.1777,  0.2435],\n",
            "          [-0.1798,  0.0235,  0.1735]],\n",
            "\n",
            "         [[ 0.0092, -0.1809,  0.0974],\n",
            "          [ 0.1691, -0.1317,  0.1264],\n",
            "          [-0.1224, -0.1659, -0.2023]]],\n",
            "\n",
            "\n",
            "        [[[-0.2336,  0.2346,  0.0983],\n",
            "          [-0.1950, -0.1840,  0.1690],\n",
            "          [-0.2168,  0.0477,  0.0916]],\n",
            "\n",
            "         [[-0.0561,  0.1103,  0.0033],\n",
            "          [-0.0990, -0.2062, -0.0978],\n",
            "          [ 0.1411, -0.0397,  0.0443]],\n",
            "\n",
            "         [[ 0.1579,  0.1184, -0.1102],\n",
            "          [ 0.1775,  0.0325, -0.1486],\n",
            "          [-0.0702,  0.2019,  0.1233]]],\n",
            "\n",
            "\n",
            "        [[[-0.0797,  0.1350,  0.1679],\n",
            "          [-0.0473,  0.2595,  0.1358],\n",
            "          [-0.2849, -0.0974, -0.0081]],\n",
            "\n",
            "         [[-0.1065, -0.1424, -0.1542],\n",
            "          [-0.2096,  0.1828,  0.1126],\n",
            "          [ 0.0174,  0.0576, -0.0152]],\n",
            "\n",
            "         [[-0.2226,  0.0298, -0.1312],\n",
            "          [-0.1327,  0.2087,  0.1935],\n",
            "          [-0.0249,  0.0243, -0.0377]]],\n",
            "\n",
            "\n",
            "        [[[-0.0588,  0.1742,  0.2010],\n",
            "          [ 0.1427, -0.0923,  0.0899],\n",
            "          [-0.1261, -0.1139, -0.0786]],\n",
            "\n",
            "         [[-0.1481,  0.0529,  0.0481],\n",
            "          [ 0.0126, -0.0323,  0.1211],\n",
            "          [-0.0912, -0.0420, -0.1293]],\n",
            "\n",
            "         [[-0.2270, -0.2813, -0.1512],\n",
            "          [ 0.0183, -0.0734, -0.0467],\n",
            "          [ 0.1668,  0.1287,  0.1416]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1385,  0.0580,  0.3274],\n",
            "          [-0.0714, -0.0263,  0.2946],\n",
            "          [-0.2355, -0.3553,  0.0437]],\n",
            "\n",
            "         [[ 0.0762, -0.1933, -0.1612],\n",
            "          [-0.1279,  0.0055, -0.0561],\n",
            "          [ 0.2241, -0.0410,  0.1810]],\n",
            "\n",
            "         [[ 0.1535, -0.1441, -0.1855],\n",
            "          [ 0.2696, -0.1765,  0.0269],\n",
            "          [ 0.2909, -0.1872, -0.1417]]],\n",
            "\n",
            "\n",
            "        [[[-0.1353, -0.0778,  0.2160],\n",
            "          [-0.2453,  0.0684,  0.2713],\n",
            "          [ 0.0924,  0.0206,  0.2311]],\n",
            "\n",
            "         [[-0.1599,  0.0515, -0.0479],\n",
            "          [-0.1464, -0.0211,  0.0214],\n",
            "          [-0.1591, -0.0081, -0.1259]],\n",
            "\n",
            "         [[-0.0057,  0.1981, -0.0700],\n",
            "          [-0.1581,  0.2080,  0.0793],\n",
            "          [-0.2191,  0.0567,  0.0142]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2331, -0.0791, -0.0360],\n",
            "          [ 0.0551, -0.1573, -0.1605],\n",
            "          [ 0.1258, -0.0884, -0.2061]],\n",
            "\n",
            "         [[-0.2222,  0.1591,  0.1350],\n",
            "          [-0.1694, -0.0935,  0.0388],\n",
            "          [-0.0330,  0.1814,  0.0005]],\n",
            "\n",
            "         [[-0.1377, -0.0267,  0.1763],\n",
            "          [-0.2532,  0.2026,  0.1464],\n",
            "          [-0.0366,  0.2414, -0.1755]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0655, -0.1766, -0.2965],\n",
            "          [ 0.0635, -0.1370,  0.2211],\n",
            "          [ 0.0251, -0.0315,  0.2027]],\n",
            "\n",
            "         [[ 0.2559, -0.1553, -0.1362],\n",
            "          [ 0.2658, -0.1706,  0.1501],\n",
            "          [-0.1731, -0.0166, -0.0638]],\n",
            "\n",
            "         [[-0.1674,  0.0792,  0.1900],\n",
            "          [-0.0342, -0.2272,  0.2679],\n",
            "          [-0.0845, -0.0639,  0.0261]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0958,  0.0557, -0.0319],\n",
            "          [ 0.1302, -0.0530, -0.2087],\n",
            "          [ 0.0320,  0.1967, -0.1969]],\n",
            "\n",
            "         [[ 0.1327, -0.1589,  0.1865],\n",
            "          [-0.0338, -0.2036, -0.2538],\n",
            "          [ 0.1661,  0.1607,  0.1042]],\n",
            "\n",
            "         [[-0.2442, -0.0128, -0.1746],\n",
            "          [-0.0988,  0.0191, -0.2384],\n",
            "          [-0.1124,  0.2998,  0.2225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1305, -0.0375, -0.0713],\n",
            "          [-0.0881,  0.0315, -0.0487],\n",
            "          [-0.1159, -0.0198, -0.0042]],\n",
            "\n",
            "         [[-0.1895,  0.1779, -0.0391],\n",
            "          [ 0.1096, -0.0229,  0.0431],\n",
            "          [ 0.1912, -0.0880,  0.1516]],\n",
            "\n",
            "         [[ 0.1237,  0.1648,  0.0864],\n",
            "          [ 0.1106, -0.1358, -0.0593],\n",
            "          [ 0.0834,  0.1760, -0.1148]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0261,  0.0946, -0.2135],\n",
            "          [-0.0508, -0.2134, -0.0804],\n",
            "          [ 0.2161,  0.1251,  0.1160]],\n",
            "\n",
            "         [[ 0.2439,  0.1499,  0.0541],\n",
            "          [-0.1242, -0.3017, -0.1642],\n",
            "          [ 0.1484,  0.0228, -0.0532]],\n",
            "\n",
            "         [[ 0.2827,  0.0027,  0.2216],\n",
            "          [-0.2123, -0.1097, -0.0140],\n",
            "          [-0.1472, -0.1401,  0.1451]]],\n",
            "\n",
            "\n",
            "        [[[-0.0668, -0.0305, -0.1276],\n",
            "          [-0.0389,  0.0897,  0.0144],\n",
            "          [ 0.0437, -0.0369,  0.2345]],\n",
            "\n",
            "         [[ 0.0160, -0.0964, -0.1077],\n",
            "          [ 0.1918,  0.2170,  0.1363],\n",
            "          [-0.1928, -0.0407,  0.0342]],\n",
            "\n",
            "         [[-0.0021, -0.0420,  0.0836],\n",
            "          [ 0.0767,  0.0022,  0.0412],\n",
            "          [-0.1141, -0.0197,  0.0672]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1341, -0.0483, -0.1076],\n",
            "          [-0.1852, -0.0061,  0.0918],\n",
            "          [-0.1238,  0.0374, -0.0902]],\n",
            "\n",
            "         [[ 0.1261, -0.0141, -0.0833],\n",
            "          [-0.1273, -0.2019, -0.1387],\n",
            "          [-0.0098,  0.2122, -0.0161]],\n",
            "\n",
            "         [[ 0.1478,  0.0007, -0.0934],\n",
            "          [-0.1233,  0.0490,  0.0353],\n",
            "          [ 0.2064, -0.1164,  0.1303]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0583, -0.1114,  0.2957],\n",
            "          [ 0.1703, -0.0507,  0.0694],\n",
            "          [-0.1846,  0.1098, -0.1668]],\n",
            "\n",
            "         [[-0.2051, -0.2725, -0.0990],\n",
            "          [-0.1666,  0.0620, -0.0992],\n",
            "          [ 0.1796,  0.0437, -0.2720]],\n",
            "\n",
            "         [[ 0.1627, -0.1647, -0.0541],\n",
            "          [ 0.0633,  0.2490, -0.1993],\n",
            "          [ 0.1262,  0.2773,  0.0247]]],\n",
            "\n",
            "\n",
            "        [[[-0.2300, -0.1971, -0.0127],\n",
            "          [ 0.0639,  0.0679, -0.0152],\n",
            "          [ 0.2227, -0.0215, -0.0974]],\n",
            "\n",
            "         [[-0.2116, -0.0484,  0.1070],\n",
            "          [ 0.1198, -0.1068, -0.0113],\n",
            "          [ 0.1952,  0.0198,  0.0825]],\n",
            "\n",
            "         [[-0.3352,  0.1302,  0.0801],\n",
            "          [ 0.1699,  0.1231,  0.0742],\n",
            "          [ 0.0210, -0.1424,  0.0352]]],\n",
            "\n",
            "\n",
            "        [[[-0.0857,  0.1421,  0.1182],\n",
            "          [ 0.1262,  0.2026,  0.1068],\n",
            "          [ 0.0704, -0.0585, -0.0306]],\n",
            "\n",
            "         [[ 0.1038, -0.1139,  0.0915],\n",
            "          [ 0.1529,  0.1774, -0.1306],\n",
            "          [-0.2282, -0.2159,  0.0512]],\n",
            "\n",
            "         [[-0.1076, -0.1626,  0.0314],\n",
            "          [-0.1577,  0.1472,  0.1330],\n",
            "          [ 0.1294, -0.0155, -0.0551]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)\n",
        "# optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpg6qeEq0-gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pVofCLG1Cu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "25934c12-cd3a-4e57-c673-8e6182232b0b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29977\n",
            "total train set images 30000\n",
            "focus_true_pred_true 29973 =============> FTPT : 99 %\n",
            "focus_false_pred_true 4 =============> FFPT : 0 %\n",
            "focus_true_pred_false 21 =============> FTPF : 0 %\n",
            "focus_false_pred_false 2 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  30000\n",
            "argmax_less_than_half ==================>  0\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r46wdqIV1Dny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "a48458e9-c10d-4ce6-f563-3ce613ecb3c3"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n",
            "total correct 9987\n",
            "total train set images 10000\n",
            "focus_true_pred_true 9984 =============> FTPT : 99 %\n",
            "focus_false_pred_true 3 =============> FFPT : 0 %\n",
            "focus_true_pred_false 12 =============> FTPF : 0 %\n",
            "focus_false_pred_false 1 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  10000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tFfAJZkcZEsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4639097-fb58-458a-ae45-7085f9853210"
      },
      "source": [
        "nos_epochs = 200\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    # optimizer_focus.zero_grad()\n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "    # optimizer_focus.step()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.003):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    \n",
        "    col1.append(epoch+1)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    focus_net.eval()\n",
        "    classify.eval()\n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 0.008\n",
            "[1,   120] loss: 0.073\n",
            "[1,   180] loss: 0.047\n",
            "[1,   240] loss: 0.036\n",
            "[2,    60] loss: 0.154\n",
            "[2,   120] loss: 0.116\n",
            "[2,   180] loss: 0.092\n",
            "[2,   240] loss: 0.094\n",
            "[3,    60] loss: 0.065\n",
            "[3,   120] loss: 0.058\n",
            "[3,   180] loss: 0.066\n",
            "[3,   240] loss: 0.078\n",
            "[4,    60] loss: 0.062\n",
            "[4,   120] loss: 0.077\n",
            "[4,   180] loss: 0.061\n",
            "[4,   240] loss: 0.054\n",
            "[5,    60] loss: 0.039\n",
            "[5,   120] loss: 0.034\n",
            "[5,   180] loss: 0.055\n",
            "[5,   240] loss: 0.059\n",
            "[6,    60] loss: 0.034\n",
            "[6,   120] loss: 0.048\n",
            "[6,   180] loss: 0.068\n",
            "[6,   240] loss: 0.049\n",
            "[7,    60] loss: 0.027\n",
            "[7,   120] loss: 0.025\n",
            "[7,   180] loss: 0.028\n",
            "[7,   240] loss: 0.031\n",
            "[8,    60] loss: 0.021\n",
            "[8,   120] loss: 0.026\n",
            "[8,   180] loss: 0.029\n",
            "[8,   240] loss: 0.024\n",
            "[9,    60] loss: 0.022\n",
            "[9,   120] loss: 0.016\n",
            "[9,   180] loss: 0.018\n",
            "[9,   240] loss: 0.026\n",
            "[10,    60] loss: 0.018\n",
            "[10,   120] loss: 0.023\n",
            "[10,   180] loss: 0.014\n",
            "[10,   240] loss: 0.018\n",
            "[11,    60] loss: 0.032\n",
            "[11,   120] loss: 0.029\n",
            "[11,   180] loss: 0.016\n",
            "[11,   240] loss: 0.015\n",
            "[12,    60] loss: 0.020\n",
            "[12,   120] loss: 0.017\n",
            "[12,   180] loss: 0.015\n",
            "[12,   240] loss: 0.010\n",
            "[13,    60] loss: 0.012\n",
            "[13,   120] loss: 0.011\n",
            "[13,   180] loss: 0.012\n",
            "[13,   240] loss: 0.017\n",
            "[14,    60] loss: 0.054\n",
            "[14,   120] loss: 0.023\n",
            "[14,   180] loss: 0.012\n",
            "[14,   240] loss: 0.011\n",
            "[15,    60] loss: 0.009\n",
            "[15,   120] loss: 0.006\n",
            "[15,   180] loss: 0.007\n",
            "[15,   240] loss: 0.007\n",
            "[16,    60] loss: 0.008\n",
            "[16,   120] loss: 0.007\n",
            "[16,   180] loss: 0.006\n",
            "[16,   240] loss: 0.008\n",
            "[17,    60] loss: 0.008\n",
            "[17,   120] loss: 0.010\n",
            "[17,   180] loss: 0.008\n",
            "[17,   240] loss: 0.009\n",
            "[18,    60] loss: 0.012\n",
            "[18,   120] loss: 0.027\n",
            "[18,   180] loss: 0.013\n",
            "[18,   240] loss: 0.009\n",
            "[19,    60] loss: 0.005\n",
            "[19,   120] loss: 0.009\n",
            "[19,   180] loss: 0.020\n",
            "[19,   240] loss: 0.017\n",
            "[20,    60] loss: 0.010\n",
            "[20,   120] loss: 0.018\n",
            "[20,   180] loss: 0.008\n",
            "[20,   240] loss: 0.008\n",
            "[21,    60] loss: 0.009\n",
            "[21,   120] loss: 0.009\n",
            "[21,   180] loss: 0.012\n",
            "[21,   240] loss: 0.012\n",
            "[22,    60] loss: 0.004\n",
            "[22,   120] loss: 0.005\n",
            "[22,   180] loss: 0.005\n",
            "[22,   240] loss: 0.004\n",
            "[23,    60] loss: 0.002\n",
            "[23,   120] loss: 0.004\n",
            "[23,   180] loss: 0.003\n",
            "[23,   240] loss: 0.003\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfZ2k3hXy85T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f662b7ec-6427-4b42-88b2-eb1ffc4dd56d"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYD8ohJ8fkBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90846aff-2d3b-47ab-a896-efeac7565248"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0omdiVCzBhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6aa75271-26f4-44d8-f69f-bd2ce4169aad"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.0155e-01,  1.8843e-01, -3.7371e-01],\n",
            "          [ 1.3882e-01,  3.1465e-01, -2.3114e-01],\n",
            "          [-9.8712e-02,  1.7628e-01, -4.7682e-02]],\n",
            "\n",
            "         [[-1.7731e-01,  2.7669e-01, -1.6959e-02],\n",
            "          [-1.3041e-01,  1.1654e-01, -2.3628e-02],\n",
            "          [-1.8088e-01,  1.7182e-02,  2.2703e-01]],\n",
            "\n",
            "         [[ 2.6718e-01,  4.5371e-01, -1.1744e-02],\n",
            "          [ 1.3648e-01,  2.1359e-02, -3.3651e-01],\n",
            "          [-3.4207e-01, -2.8405e-01,  2.1965e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4553e-01, -3.1102e-01, -1.5143e-01],\n",
            "          [-7.8231e-02, -2.3423e-01, -1.1562e-01],\n",
            "          [ 4.3292e-03, -2.9985e-01, -1.6135e-01]],\n",
            "\n",
            "         [[ 2.3403e-01, -7.7107e-02,  2.3617e-01],\n",
            "          [ 7.9921e-03, -1.3719e-03, -1.2427e-01],\n",
            "          [-2.4708e-03, -1.7089e-01,  1.4559e-01]],\n",
            "\n",
            "         [[ 6.0008e-02,  2.2231e-01,  2.0222e-01],\n",
            "          [ 2.2929e-01, -5.4566e-03,  7.7658e-02],\n",
            "          [ 2.1009e-01, -2.0395e-02,  3.0434e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8955e-02, -8.9080e-02, -7.6312e-02],\n",
            "          [ 1.6654e-01,  9.1395e-02, -1.7210e-01],\n",
            "          [ 7.2608e-02,  3.6598e-02, -2.0946e-01]],\n",
            "\n",
            "         [[ 4.9694e-02,  3.4286e-02,  9.6677e-02],\n",
            "          [-9.4347e-02,  1.9066e-01, -1.7569e-01],\n",
            "          [ 2.2628e-01,  1.8944e-01,  1.0318e-01]],\n",
            "\n",
            "         [[-9.5871e-03,  2.3965e-02, -2.2961e-01],\n",
            "          [ 5.0691e-03, -1.2477e-03,  4.3030e-02],\n",
            "          [ 1.1552e-01,  5.2009e-02,  4.5297e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1273e-02,  1.1986e-01,  1.9651e-01],\n",
            "          [-1.0910e-01,  2.1594e-01,  2.3334e-01],\n",
            "          [-7.5300e-02, -1.2681e-01, -5.3049e-02]],\n",
            "\n",
            "         [[-4.8859e-02, -8.2950e-02, -1.8400e-01],\n",
            "          [-2.3791e-01, -8.6627e-02, -1.3185e-01],\n",
            "          [-1.8958e-02, -8.0871e-02, -1.0580e-01]],\n",
            "\n",
            "         [[-7.4944e-02, -1.2411e-01, -5.2474e-02],\n",
            "          [-2.0770e-02,  1.5161e-01, -1.6706e-01],\n",
            "          [-4.3331e-02,  1.3538e-01, -1.8715e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.3778e-03, -7.8674e-02,  1.9848e-01],\n",
            "          [-2.3493e-01,  1.7573e-01,  2.7151e-01],\n",
            "          [-2.2664e-02, -1.1002e-02, -6.5587e-02]],\n",
            "\n",
            "         [[ 1.9978e-01,  1.4815e-02,  1.0615e-02],\n",
            "          [ 2.0002e-01, -1.1983e-01,  1.5939e-01],\n",
            "          [-2.4128e-01, -1.4317e-01,  8.0474e-02]],\n",
            "\n",
            "         [[-1.4341e-01, -1.1064e-01, -2.6179e-01],\n",
            "          [ 2.1648e-01, -9.9564e-02,  1.6842e-02],\n",
            "          [ 1.1194e-01,  1.4890e-02,  1.9808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5718e-01,  6.6356e-03, -8.6083e-02],\n",
            "          [ 8.0345e-02, -1.1381e-01, -4.6426e-03],\n",
            "          [-1.2109e-01,  1.1055e-01,  2.1551e-01]],\n",
            "\n",
            "         [[ 1.5790e-01, -7.3243e-04, -1.1624e-01],\n",
            "          [ 2.9433e-01,  1.5650e-01, -2.7937e-01],\n",
            "          [ 1.0816e-01, -4.2703e-02,  1.1360e-01]],\n",
            "\n",
            "         [[-2.3966e-02, -1.7138e-01, -5.5875e-02],\n",
            "          [-1.1881e-01, -1.9345e-01, -3.4012e-01],\n",
            "          [ 7.5994e-02, -1.8580e-01,  5.1822e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5608e-01,  1.4220e-01, -1.9261e-01],\n",
            "          [ 2.8186e-01, -1.1467e-01, -3.0065e-02],\n",
            "          [-1.9499e-01, -8.0530e-04,  1.7978e-01]],\n",
            "\n",
            "         [[-2.9561e-01, -1.4465e-01, -3.8936e-02],\n",
            "          [ 2.7009e-01, -1.0709e-01,  1.9911e-01],\n",
            "          [-1.6047e-01,  1.9247e-01,  2.6052e-01]],\n",
            "\n",
            "         [[-1.3410e-01, -1.0264e-01, -2.3493e-01],\n",
            "          [ 3.7941e-01, -4.1826e-02, -2.3835e-01],\n",
            "          [ 1.5829e-01,  1.4479e-01, -7.7649e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4260e-02,  7.2909e-02, -4.9308e-01],\n",
            "          [ 1.9709e-01,  2.9608e-01,  4.4813e-02],\n",
            "          [ 1.8176e-01,  3.3937e-01,  1.7607e-01]],\n",
            "\n",
            "         [[-5.0911e-02,  2.4422e-01, -2.6483e-01],\n",
            "          [-2.5324e-01, -2.8686e-01, -1.1130e-01],\n",
            "          [-7.3526e-02, -1.8883e-01, -1.8568e-01]],\n",
            "\n",
            "         [[-3.3020e-02,  3.4905e-01,  9.6184e-02],\n",
            "          [ 9.3889e-02,  5.0457e-02, -4.1922e-02],\n",
            "          [-2.5109e-02, -1.0685e-01, -1.3722e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4828e-02,  9.2095e-04, -7.6290e-02],\n",
            "          [ 3.3454e-02,  3.7860e-01, -2.8654e-01],\n",
            "          [ 1.4552e-01,  7.2081e-02, -1.9682e-01]],\n",
            "\n",
            "         [[-3.7882e-02,  2.0972e-01, -2.3378e-01],\n",
            "          [-7.0486e-02,  4.0031e-01, -3.3082e-01],\n",
            "          [-2.2034e-01,  2.4179e-01, -7.7592e-02]],\n",
            "\n",
            "         [[-2.3171e-01,  2.7509e-01, -2.9406e-02],\n",
            "          [-2.5366e-01,  5.2276e-01, -3.5181e-01],\n",
            "          [ 4.7083e-02,  1.1258e-01, -2.4963e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2920e-02,  1.1366e-01, -1.0895e-01],\n",
            "          [-5.3343e-02,  1.6217e-02, -2.0651e-02],\n",
            "          [ 1.1660e-01,  9.8321e-02, -1.2359e-01]],\n",
            "\n",
            "         [[-3.4368e-02, -7.0742e-02, -2.5050e-01],\n",
            "          [-2.7087e-02,  1.4293e-01, -2.2920e-01],\n",
            "          [ 1.4525e-01,  1.4925e-02, -2.0972e-01]],\n",
            "\n",
            "         [[-2.4625e-01, -2.5307e-03, -2.1292e-02],\n",
            "          [ 2.9386e-02,  8.7204e-02,  1.4329e-01],\n",
            "          [ 2.4719e-01,  2.8453e-01,  9.2273e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.5100e-01, -1.5544e-01,  3.7412e-01],\n",
            "          [ 3.4293e-01, -6.4277e-02, -1.9676e-01],\n",
            "          [ 1.5227e-01, -4.3687e-02, -1.8680e-01]],\n",
            "\n",
            "         [[-3.5154e-01, -4.3465e-02,  7.8562e-02],\n",
            "          [ 3.2783e-01, -9.1473e-02, -7.4105e-02],\n",
            "          [ 1.5686e-01,  6.4711e-03,  4.9247e-02]],\n",
            "\n",
            "         [[ 1.0901e-01,  1.3724e-01,  1.4471e-01],\n",
            "          [ 3.8507e-01, -1.8206e-01, -9.0550e-02],\n",
            "          [ 1.8527e-02, -2.1300e-01, -2.1008e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.0009e-01,  5.2350e-02, -1.7434e-02],\n",
            "          [-1.3890e-01, -2.8554e-01,  1.3410e-01],\n",
            "          [-3.7519e-02, -5.1394e-01,  6.2113e-02]],\n",
            "\n",
            "         [[ 4.7610e-02,  1.4115e-01,  1.9123e-02],\n",
            "          [ 3.4660e-01,  1.0914e-01,  2.8330e-01],\n",
            "          [ 3.0530e-01, -1.6982e-01,  2.7858e-01]],\n",
            "\n",
            "         [[ 3.8899e-02, -4.2711e-03, -1.3205e-01],\n",
            "          [ 1.0196e-01, -2.7844e-01, -8.7242e-03],\n",
            "          [ 1.2730e-01, -2.8913e-01, -8.2701e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6047e-01,  3.1003e-01, -1.1233e-01],\n",
            "          [ 3.3223e-01,  2.9437e-01, -9.5160e-02],\n",
            "          [ 2.0716e-01, -2.9966e-01, -3.4367e-01]],\n",
            "\n",
            "         [[-2.8085e-01,  1.4637e-01, -3.4782e-02],\n",
            "          [ 1.6125e-03,  1.8891e-01,  2.3948e-01],\n",
            "          [-1.1145e-01, -1.3817e-01, -1.6709e-01]],\n",
            "\n",
            "         [[-4.5610e-01,  2.2247e-01,  2.1565e-01],\n",
            "          [-1.8045e-01, -1.5446e-01,  1.1526e-01],\n",
            "          [-1.5825e-01,  7.3281e-02,  3.5264e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1864e-01, -6.0254e-02,  9.2982e-02],\n",
            "          [ 1.4388e-01, -7.3523e-02, -2.0167e-01],\n",
            "          [-2.3147e-01,  1.1375e-01,  7.0444e-02]],\n",
            "\n",
            "         [[-4.4879e-02,  1.4091e-01, -1.9945e-01],\n",
            "          [ 2.1282e-01,  2.5781e-01,  1.0941e-01],\n",
            "          [-8.7437e-02,  1.2557e-01, -1.6704e-01]],\n",
            "\n",
            "         [[-8.5735e-02, -2.8465e-02, -7.9197e-02],\n",
            "          [ 5.6643e-02,  2.0363e-01,  4.2784e-02],\n",
            "          [ 8.6233e-03, -2.0354e-02, -3.6712e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.3492e-02, -1.5458e-01,  5.7564e-03],\n",
            "          [-3.7472e-02,  1.1123e-01, -2.3172e-01],\n",
            "          [ 1.0602e-01, -1.8604e-02, -1.4651e-01]],\n",
            "\n",
            "         [[-2.5336e-04, -5.2469e-03,  1.1831e-01],\n",
            "          [ 4.4008e-02, -9.3524e-02, -9.1982e-02],\n",
            "          [ 3.3203e-02, -1.1195e-01,  5.3600e-02]],\n",
            "\n",
            "         [[ 7.1521e-02,  3.1856e-02,  1.9880e-01],\n",
            "          [ 9.1581e-02, -6.5490e-02, -2.6157e-01],\n",
            "          [-6.2403e-02,  3.3127e-02, -9.8168e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4214e-01, -2.6254e-01, -2.4894e-01],\n",
            "          [ 6.0782e-02,  1.4442e-01, -4.1070e-02],\n",
            "          [ 2.3767e-01,  3.2218e-01,  1.7166e-01]],\n",
            "\n",
            "         [[ 6.9931e-02,  3.2418e-03,  5.9026e-02],\n",
            "          [ 9.8867e-02, -7.6754e-02, -1.1897e-01],\n",
            "          [-1.5324e-01,  2.3701e-01,  7.7406e-02]],\n",
            "\n",
            "         [[-1.8112e-02,  3.6124e-02,  8.8124e-02],\n",
            "          [ 5.1065e-03,  1.4502e-01, -1.0826e-01],\n",
            "          [-1.1482e-01,  1.5715e-01, -2.1675e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9496e-02, -2.3513e-01,  1.3399e-01],\n",
            "          [ 1.5434e-02,  1.2206e-01,  1.7543e-01],\n",
            "          [ 1.8777e-01,  6.9283e-02,  3.6612e-02]],\n",
            "\n",
            "         [[ 1.0813e-01, -9.1666e-02, -5.8822e-02],\n",
            "          [-1.7935e-01, -1.3325e-01, -9.2677e-02],\n",
            "          [ 1.5984e-02,  1.3427e-01, -1.9313e-01]],\n",
            "\n",
            "         [[-1.0145e-01, -1.7560e-01, -1.0277e-01],\n",
            "          [-4.1589e-02, -2.2296e-01, -2.0368e-02],\n",
            "          [-5.1968e-02, -9.4545e-02, -1.5786e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.8242e-01, -1.6982e-02,  1.2589e-01],\n",
            "          [-3.1782e-02, -1.3494e-02, -2.8895e-01],\n",
            "          [ 1.3941e-01, -1.0287e-01, -1.0379e-01]],\n",
            "\n",
            "         [[-2.7262e-01,  1.4852e-01,  1.4684e-01],\n",
            "          [ 7.8490e-02,  2.7467e-01,  1.6855e-02],\n",
            "          [ 3.8027e-01,  3.0940e-01,  1.7866e-02]],\n",
            "\n",
            "         [[-3.0519e-01,  2.7818e-02,  1.2216e-01],\n",
            "          [-2.1921e-01, -7.9760e-02, -2.0103e-04],\n",
            "          [ 1.7404e-01, -1.8248e-01, -1.4009e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0714e-01,  1.7765e-01, -3.0915e-01],\n",
            "          [-2.0353e-02, -1.6578e-01,  3.7074e-01],\n",
            "          [ 1.7386e-01, -2.7412e-01,  2.9055e-02]],\n",
            "\n",
            "         [[-1.2439e-01,  1.0872e-01, -1.7823e-01],\n",
            "          [-1.0632e-01, -2.9516e-01,  3.7788e-01],\n",
            "          [ 3.0583e-01, -4.0840e-01,  1.3042e-01]],\n",
            "\n",
            "         [[ 2.9924e-01,  8.6759e-02, -3.3583e-01],\n",
            "          [-1.1813e-02, -2.6363e-01,  4.2833e-01],\n",
            "          [-3.5804e-02, -3.3204e-01,  2.4581e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.5675e-02,  2.5866e-01,  1.2688e-01],\n",
            "          [-1.1888e-01,  2.3120e-01,  1.8862e-01],\n",
            "          [-1.0078e-01, -2.2704e-01, -3.4244e-01]],\n",
            "\n",
            "         [[ 2.7898e-02,  2.4486e-01,  1.8591e-01],\n",
            "          [ 2.0807e-01,  1.1544e-01,  4.7624e-03],\n",
            "          [ 3.2926e-02,  1.8853e-01, -1.2424e-01]],\n",
            "\n",
            "         [[-2.4558e-01, -1.8506e-01, -1.5971e-01],\n",
            "          [-2.0672e-01,  2.0476e-02, -1.1053e-01],\n",
            "          [ 2.1770e-01,  2.2833e-01, -8.8387e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.5205e-02,  1.5520e-01, -1.9695e-01],\n",
            "          [-7.9760e-02,  8.1679e-02, -6.8232e-02],\n",
            "          [ 1.6093e-03, -1.5213e-01, -1.2683e-01]],\n",
            "\n",
            "         [[ 1.8469e-01, -3.6921e-02, -1.7115e-01],\n",
            "          [ 8.1758e-02, -1.6792e-01, -6.7049e-02],\n",
            "          [ 1.6663e-01, -6.6594e-02,  1.2634e-01]],\n",
            "\n",
            "         [[-3.6184e-01, -6.5170e-02, -1.0652e-01],\n",
            "          [-4.7971e-01,  1.4482e-01,  4.2907e-01],\n",
            "          [-2.5983e-01,  2.9876e-01,  5.4646e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8698e-02, -1.1509e-01,  3.1465e-01],\n",
            "          [-2.2665e-01,  1.1842e-01, -1.0207e-01],\n",
            "          [-2.1049e-01, -7.1634e-02,  2.3764e-01]],\n",
            "\n",
            "         [[ 1.5028e-01, -1.8738e-01,  1.2004e-01],\n",
            "          [ 1.6371e-01, -1.7511e-03, -2.4908e-01],\n",
            "          [-5.7438e-02,  2.1253e-01,  4.7965e-02]],\n",
            "\n",
            "         [[ 2.8607e-01, -1.4524e-01, -2.5859e-01],\n",
            "          [ 2.9987e-01,  5.0431e-02, -5.1815e-01],\n",
            "          [ 2.1397e-01,  2.9649e-01, -3.1808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8467e-02, -9.7171e-02, -6.5884e-02],\n",
            "          [ 4.7044e-03, -1.2399e-01,  1.3729e-01],\n",
            "          [-1.0409e-01,  1.7758e-01,  1.4271e-01]],\n",
            "\n",
            "         [[ 1.8816e-01,  7.7143e-02, -1.2912e-02],\n",
            "          [ 1.1297e-01, -2.5210e-01, -2.2299e-01],\n",
            "          [-2.8796e-01,  8.2649e-02, -8.7493e-02]],\n",
            "\n",
            "         [[ 2.1926e-01,  2.2060e-01,  1.7361e-01],\n",
            "          [-2.0023e-02,  1.5427e-01,  6.1582e-02],\n",
            "          [-2.0668e-01, -1.0826e-01,  1.1648e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5940e-01,  1.1073e-01, -1.7217e-02],\n",
            "          [-1.0682e-01,  6.4494e-02,  1.4025e-01],\n",
            "          [-8.2975e-02, -1.8486e-01, -2.2712e-01]],\n",
            "\n",
            "         [[-8.8423e-02,  1.4320e-01, -2.0304e-02],\n",
            "          [-5.0818e-03,  1.7296e-01, -8.4649e-02],\n",
            "          [ 6.2910e-03, -1.7587e-01, -2.0314e-02]],\n",
            "\n",
            "         [[-8.5325e-02, -1.5731e-01, -1.0675e-01],\n",
            "          [ 1.9048e-01,  1.6936e-01,  6.7662e-03],\n",
            "          [-2.7817e-05,  9.5952e-02, -2.4236e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1579e-01,  1.7570e-01, -1.1779e-01],\n",
            "          [ 2.0060e-03, -1.0404e-01,  1.3824e-01],\n",
            "          [-1.1473e-01,  3.1071e-02,  1.7744e-01]],\n",
            "\n",
            "         [[ 6.9442e-02, -1.5036e-02,  5.4487e-02],\n",
            "          [-5.8634e-02, -1.4846e-01,  9.5080e-02],\n",
            "          [ 1.6324e-01, -1.5676e-02, -8.4563e-02]],\n",
            "\n",
            "         [[ 1.1528e-01, -1.1609e-01,  2.9263e-03],\n",
            "          [ 5.4937e-02, -1.5815e-01,  1.8128e-01],\n",
            "          [ 1.5560e-01,  1.3262e-01,  1.8461e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1694e-01, -2.9142e-01, -2.6329e-01],\n",
            "          [-1.2755e-01, -1.9556e-01,  3.8795e-02],\n",
            "          [ 3.4141e-01,  3.4313e-01,  1.9673e-01]],\n",
            "\n",
            "         [[-1.2067e-01, -2.4652e-01,  3.6027e-03],\n",
            "          [-1.8045e-01,  1.0407e-01, -1.6403e-01],\n",
            "          [ 5.5994e-02,  2.2146e-01, -1.2961e-01]],\n",
            "\n",
            "         [[ 1.9381e-01, -3.1823e-02,  2.0926e-01],\n",
            "          [ 7.3488e-02, -8.3086e-02,  2.8715e-02],\n",
            "          [-1.1377e-01,  2.3878e-01, -1.3486e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6004e-02,  2.2558e-01,  1.3777e-01],\n",
            "          [ 1.4699e-01, -1.7660e-01, -9.6174e-02],\n",
            "          [-8.1804e-02, -1.1437e-01, -6.4043e-02]],\n",
            "\n",
            "         [[-1.8785e-01,  1.2662e-01,  1.1054e-01],\n",
            "          [ 6.8984e-02, -1.8815e-01, -4.3549e-02],\n",
            "          [ 2.6759e-01, -7.3002e-02, -8.8331e-02]],\n",
            "\n",
            "         [[-2.2460e-01, -8.1323e-02,  2.9143e-01],\n",
            "          [-2.5683e-01, -9.4635e-02,  2.5643e-01],\n",
            "          [-1.2625e-02, -2.2122e-01,  4.7715e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.8392e-02, -2.1575e-01, -2.8500e-02],\n",
            "          [-2.5681e-01, -2.5748e-01,  1.5143e-01],\n",
            "          [ 2.5797e-01,  3.1017e-01,  5.0137e-03]],\n",
            "\n",
            "         [[ 8.3711e-02, -2.3980e-01, -7.0890e-02],\n",
            "          [-9.5829e-02, -1.9823e-01,  2.7156e-01],\n",
            "          [-2.6914e-02,  2.7501e-01, -3.1315e-02]],\n",
            "\n",
            "         [[-1.3819e-01,  4.2787e-02,  3.4596e-02],\n",
            "          [-1.1717e-01, -1.7322e-01,  1.3440e-01],\n",
            "          [ 4.9149e-02, -5.2634e-02, -1.1780e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1362e-01,  4.8102e-02,  3.4139e-01],\n",
            "          [ 3.4290e-02, -2.4965e-01,  2.7953e-01],\n",
            "          [-1.6447e-01,  9.0822e-04,  2.3792e-01]],\n",
            "\n",
            "         [[-4.8142e-02, -1.0798e-01,  3.7232e-01],\n",
            "          [-1.0745e-02, -4.9819e-01,  8.5103e-02],\n",
            "          [ 1.1553e-01, -2.4784e-01,  1.5701e-01]],\n",
            "\n",
            "         [[-1.1495e-01, -2.1601e-01,  1.0106e-01],\n",
            "          [ 2.3005e-01, -3.2803e-01, -8.3869e-02],\n",
            "          [ 2.2454e-01, -1.0049e-02,  2.0753e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3836e-01,  3.2456e-01,  3.3695e-01],\n",
            "          [-2.4138e-01, -2.9768e-01, -1.5685e-01],\n",
            "          [-9.5723e-02, -7.9013e-02, -1.9312e-01]],\n",
            "\n",
            "         [[ 1.3153e-01,  6.7787e-02,  2.1433e-01],\n",
            "          [-2.6171e-01, -2.9836e-01, -2.0850e-01],\n",
            "          [ 1.0682e-01,  1.0624e-01, -1.6899e-01]],\n",
            "\n",
            "         [[ 1.7010e-01, -3.2429e-02, -1.2887e-02],\n",
            "          [-3.4082e-02, -2.3638e-01, -8.2708e-02],\n",
            "          [ 8.6260e-02,  2.9735e-01, -1.4077e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4088e-01,  2.0552e-01, -6.8858e-02],\n",
            "          [-1.4319e-02, -1.5148e-01, -2.4972e-01],\n",
            "          [ 2.8147e-01, -1.4573e-01, -1.2848e-01]],\n",
            "\n",
            "         [[-1.1730e-01, -4.3468e-02, -1.5309e-01],\n",
            "          [ 6.0057e-02, -1.9846e-01, -1.4349e-02],\n",
            "          [ 2.6214e-01,  1.4849e-01, -1.9905e-01]],\n",
            "\n",
            "         [[-1.7688e-01,  2.2597e-01, -1.7985e-01],\n",
            "          [ 1.3996e-01, -6.4199e-02, -1.3442e-01],\n",
            "          [ 2.9831e-01, -8.8765e-04,  5.7207e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.3738e-02, -6.5191e-02,  1.1433e-01],\n",
            "          [-5.4104e-02,  1.0246e-01,  1.1657e-01],\n",
            "          [-2.1356e-01, -1.6824e-01,  6.3947e-02]],\n",
            "\n",
            "         [[-9.3507e-02, -3.5852e-02,  4.9805e-02],\n",
            "          [ 1.4713e-01, -1.3346e-01, -1.2432e-01],\n",
            "          [-2.2472e-01, -1.8936e-01,  1.7751e-01]],\n",
            "\n",
            "         [[-7.8939e-02,  4.8241e-02, -1.3442e-01],\n",
            "          [ 1.6475e-02, -3.7413e-02,  2.9886e-01],\n",
            "          [-2.3843e-01, -1.1041e-02,  1.7069e-01]]]], device='cuda:0',\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToKa651tMtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bda8d119-1d51-4bf0-8392-ccd724a6bb5a"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 7.9249e-02,  1.3624e-01,  2.6361e-01],\n",
            "          [ 2.9626e-01,  2.4354e-02,  5.2297e-02],\n",
            "          [-1.0115e-01,  4.1222e-02, -1.6796e-01]],\n",
            "\n",
            "         [[ 4.5007e-02, -1.6673e-01,  2.1509e-01],\n",
            "          [ 4.0675e-02, -2.3312e-01, -1.7725e-01],\n",
            "          [-1.6935e-01, -1.2323e-01, -2.8538e-01]],\n",
            "\n",
            "         [[-8.3673e-02,  2.2607e-02,  1.6626e-01],\n",
            "          [ 8.9338e-02, -4.7270e-02,  1.7979e-01],\n",
            "          [ 6.0615e-02,  7.9741e-02, -2.4362e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1322e-01,  4.8870e-02, -2.1485e-01],\n",
            "          [-6.9976e-02,  2.0148e-01,  6.5757e-02],\n",
            "          [ 9.3240e-02,  2.4641e-01,  1.7948e-01]],\n",
            "\n",
            "         [[ 2.7602e-02,  2.4408e-01,  2.2328e-01],\n",
            "          [-1.7098e-01, -1.6253e-01,  4.2897e-02],\n",
            "          [-2.6602e-01,  8.0901e-02,  1.2624e-01]],\n",
            "\n",
            "         [[-7.8779e-02,  1.9920e-01, -1.4785e-01],\n",
            "          [-9.7449e-02, -7.3093e-02,  7.3348e-02],\n",
            "          [-1.3215e-01, -2.7547e-01, -2.9901e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4083e-01,  2.1093e-02, -1.0631e-01],\n",
            "          [-1.7564e-01,  2.2575e-01, -6.7664e-02],\n",
            "          [-9.3975e-02,  3.5670e-01,  3.6455e-01]],\n",
            "\n",
            "         [[-1.2174e-02, -2.5943e-02, -8.4937e-02],\n",
            "          [ 1.0274e-03, -2.0234e-01, -3.2227e-01],\n",
            "          [-2.7936e-01,  9.7574e-02,  1.8126e-01]],\n",
            "\n",
            "         [[ 3.0214e-01, -1.7221e-01, -1.5335e-01],\n",
            "          [ 8.2430e-02,  2.6975e-02, -2.4025e-01],\n",
            "          [ 1.0778e-01,  6.4402e-02, -5.1006e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5746e-01,  1.8101e-01, -4.0147e-02],\n",
            "          [ 1.1549e-01,  4.8968e-02,  8.1457e-02],\n",
            "          [-3.6460e-02, -7.7019e-02, -1.6160e-02]],\n",
            "\n",
            "         [[ 1.8503e-01, -1.8856e-03,  1.6765e-01],\n",
            "          [ 9.3799e-02, -1.4515e-01,  5.1957e-02],\n",
            "          [ 1.6434e-01, -2.5147e-02, -1.2216e-02]],\n",
            "\n",
            "         [[-1.6170e-01, -2.8921e-02,  6.6440e-02],\n",
            "          [-3.3464e-02,  2.4557e-02, -1.1509e-01],\n",
            "          [-1.1057e-02, -5.3372e-02,  7.9375e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8372e-01, -1.8467e-01,  1.0064e-01],\n",
            "          [-2.8658e-02, -2.1864e-01, -8.4351e-02],\n",
            "          [-1.1398e-01, -1.0310e-01, -1.1633e-01]],\n",
            "\n",
            "         [[ 6.9579e-02,  1.5513e-01,  1.9821e-01],\n",
            "          [-1.8594e-02, -1.0723e-01,  1.5164e-01],\n",
            "          [-2.8021e-01,  8.9760e-02, -4.0315e-03]],\n",
            "\n",
            "         [[ 2.2995e-01,  4.1417e-02,  1.7287e-01],\n",
            "          [ 2.0338e-02,  1.9743e-01,  1.5717e-01],\n",
            "          [-1.9616e-01,  1.3823e-01, -9.2915e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8689e-01,  1.9836e-01, -5.8553e-02],\n",
            "          [-2.7749e-01,  3.6215e-02,  2.0289e-02],\n",
            "          [-1.2308e-01, -6.8922e-02, -5.6418e-02]],\n",
            "\n",
            "         [[ 1.5566e-01,  3.9305e-01,  6.6769e-02],\n",
            "          [-2.0387e-01,  5.3270e-02, -2.9553e-01],\n",
            "          [-1.8321e-01, -3.3366e-01, -1.5621e-01]],\n",
            "\n",
            "         [[ 1.0496e-01,  2.7511e-01,  3.6812e-02],\n",
            "          [-2.4268e-01,  2.1938e-01, -2.2012e-01],\n",
            "          [ 1.1645e-01, -2.4471e-04,  3.7292e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.0046e-02,  3.5138e-02, -2.2145e-01],\n",
            "          [ 1.2498e-01, -4.5481e-02, -5.9585e-02],\n",
            "          [ 1.0866e-01, -6.1866e-02, -1.8031e-01]],\n",
            "\n",
            "         [[-1.3407e-01,  1.7584e-01, -1.1522e-01],\n",
            "          [ 2.2626e-01,  2.2255e-01,  1.8640e-01],\n",
            "          [ 1.0510e-01, -2.7513e-03,  1.2370e-02]],\n",
            "\n",
            "         [[ 2.3625e-01,  9.0945e-02, -9.7977e-02],\n",
            "          [-2.1025e-02,  2.2180e-01, -4.0424e-02],\n",
            "          [ 3.1057e-02,  3.6750e-02, -6.2428e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.7738e-02, -2.7509e-01, -2.4861e-01],\n",
            "          [-7.0417e-02, -1.7198e-01, -2.3767e-01],\n",
            "          [ 7.5856e-02, -2.1013e-01, -1.9373e-01]],\n",
            "\n",
            "         [[ 1.4192e-02, -4.9474e-02,  6.8121e-02],\n",
            "          [ 2.4797e-01,  1.8299e-01, -3.2917e-02],\n",
            "          [ 2.3928e-01,  7.7553e-02, -1.0674e-01]],\n",
            "\n",
            "         [[ 1.2592e-01, -5.7167e-02, -7.6110e-02],\n",
            "          [ 1.0529e-01,  4.0966e-02,  1.4180e-01],\n",
            "          [ 2.2124e-01, -4.1250e-03,  2.6641e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.6079e-01,  2.1781e-01, -8.4646e-02],\n",
            "          [ 3.3492e-02, -1.1130e-01, -1.7431e-01],\n",
            "          [-1.3867e-01, -1.5893e-01,  1.7326e-01]],\n",
            "\n",
            "         [[ 1.9842e-02, -4.5113e-02,  2.4587e-01],\n",
            "          [-6.1608e-02, -1.6925e-01,  2.5254e-02],\n",
            "          [ 6.2427e-03, -1.7202e-01,  1.6992e-01]],\n",
            "\n",
            "         [[ 1.0188e-01, -1.3060e-01,  6.5102e-02],\n",
            "          [ 6.9252e-02, -3.1562e-01, -2.4631e-01],\n",
            "          [ 5.9002e-02,  1.1683e-01,  7.8077e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.0194e-02,  8.8326e-02,  2.4530e-01],\n",
            "          [-1.0519e-01,  2.0530e-01,  2.9170e-02],\n",
            "          [ 1.9185e-01,  1.1108e-01, -6.9194e-02]],\n",
            "\n",
            "         [[-1.0503e-01, -1.7291e-01, -4.1456e-02],\n",
            "          [-2.7927e-01, -1.6229e-01,  9.2315e-03],\n",
            "          [ 2.4018e-01, -2.6073e-01, -1.2182e-01]],\n",
            "\n",
            "         [[-3.0708e-02,  8.0887e-02,  3.2974e-01],\n",
            "          [-1.8221e-01,  1.5806e-01,  2.2134e-01],\n",
            "          [-1.1715e-01, -2.8138e-01, -2.2551e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.4611e-02,  1.2717e-01, -7.7019e-02],\n",
            "          [-8.6626e-02, -1.4050e-01,  1.5427e-01],\n",
            "          [ 4.9021e-02,  1.1222e-01, -2.8021e-02]],\n",
            "\n",
            "         [[-1.9884e-01,  2.0897e-01,  2.8977e-01],\n",
            "          [ 5.7386e-02,  3.0481e-01,  8.7768e-02],\n",
            "          [-2.1885e-02,  1.7759e-01,  3.6026e-02]],\n",
            "\n",
            "         [[-1.7677e-01, -9.7650e-02, -2.0631e-01],\n",
            "          [-2.9870e-01,  6.8107e-03,  1.8125e-01],\n",
            "          [ 1.0972e-01, -1.2852e-01,  3.1497e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.7957e-02, -2.0626e-01,  1.7657e-01],\n",
            "          [-1.3282e-01, -2.1993e-01,  3.8875e-01],\n",
            "          [-1.2643e-02, -1.1419e-01, -5.5063e-02]],\n",
            "\n",
            "         [[ 5.6293e-02, -3.0550e-01,  1.9165e-01],\n",
            "          [ 1.3985e-01, -3.0170e-01,  3.3117e-01],\n",
            "          [ 1.1861e-01, -1.1784e-01,  9.3484e-02]],\n",
            "\n",
            "         [[ 2.8903e-01, -3.3919e-01, -2.2745e-01],\n",
            "          [ 2.6438e-01, -3.1241e-01,  2.2152e-01],\n",
            "          [ 2.8097e-01, -2.0526e-01, -5.7336e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5781e-01,  2.6076e-01, -2.7393e-01],\n",
            "          [-1.6643e-02,  1.8825e-02,  3.6141e-03],\n",
            "          [ 1.2610e-01, -2.8155e-01, -2.0927e-01]],\n",
            "\n",
            "         [[ 2.1192e-01,  3.2403e-01,  4.2334e-02],\n",
            "          [-2.8562e-01,  2.8626e-01,  2.9208e-01],\n",
            "          [-4.1928e-02, -1.4415e-01,  1.6112e-01]],\n",
            "\n",
            "         [[-1.8883e-01,  2.6669e-01, -2.0864e-01],\n",
            "          [-1.9480e-01, -2.1945e-02, -1.7043e-01],\n",
            "          [ 1.6701e-01, -1.0118e-02, -9.7357e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.2279e-02, -8.2585e-02, -7.0415e-02],\n",
            "          [-9.9306e-02,  7.3044e-02, -5.2810e-03],\n",
            "          [-4.0022e-02, -4.5705e-02,  5.8864e-02]],\n",
            "\n",
            "         [[-1.9422e-01, -1.8677e-01, -2.2778e-01],\n",
            "          [-1.4155e-01, -1.3079e-01,  1.0156e-01],\n",
            "          [-1.2601e-01,  6.6283e-02, -9.7865e-03]],\n",
            "\n",
            "         [[ 6.7149e-02,  2.1312e-02, -1.4563e-01],\n",
            "          [-6.2796e-02,  2.2145e-01,  1.7828e-01],\n",
            "          [-9.9404e-02,  1.2947e-01,  4.9608e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7034e-02,  2.1409e-02, -1.9487e-01],\n",
            "          [-1.5890e-01, -1.2418e-01, -2.9651e-02],\n",
            "          [-1.3325e-01, -2.2838e-01, -2.5961e-01]],\n",
            "\n",
            "         [[ 8.4500e-02,  8.1413e-02, -9.2947e-02],\n",
            "          [ 2.3923e-02, -1.5365e-01,  7.1139e-02],\n",
            "          [-2.1405e-01, -4.0265e-02,  5.8036e-02]],\n",
            "\n",
            "         [[ 9.5652e-02, -1.2787e-01, -6.5930e-03],\n",
            "          [ 2.7269e-01,  1.5859e-01,  5.9562e-02],\n",
            "          [-1.6241e-02, -8.7020e-02, -1.6254e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1931e-01, -1.3256e-01, -3.3288e-01],\n",
            "          [ 3.4432e-01,  6.5694e-02, -2.2756e-01],\n",
            "          [-1.1730e-02, -2.3183e-01,  8.1705e-02]],\n",
            "\n",
            "         [[ 3.1156e-01,  1.7649e-01, -6.7742e-02],\n",
            "          [ 2.7704e-01,  1.1012e-01, -1.0357e-01],\n",
            "          [ 2.2673e-01, -2.8505e-01, -2.1485e-01]],\n",
            "\n",
            "         [[-4.1935e-02, -2.0403e-01, -1.1267e-01],\n",
            "          [-1.8417e-01, -1.1283e-02,  1.0115e-01],\n",
            "          [ 5.0485e-02, -1.4551e-01,  1.6301e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.3923e-01, -3.5370e-01, -1.5707e-02],\n",
            "          [-5.0925e-02,  1.6252e-01,  2.8776e-01],\n",
            "          [ 8.1513e-02, -9.6861e-02,  1.6823e-01]],\n",
            "\n",
            "         [[ 1.4955e-01, -1.7367e-01,  9.6924e-02],\n",
            "          [-6.9670e-02,  2.4020e-01,  3.5918e-01],\n",
            "          [-1.6984e-01,  5.1279e-02,  2.5102e-01]],\n",
            "\n",
            "         [[-2.8287e-02, -2.5834e-01,  8.4127e-02],\n",
            "          [ 1.1457e-01, -1.6669e-01,  1.5081e-01],\n",
            "          [-2.1590e-01, -2.4943e-01, -2.3961e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.4664e-01,  2.8305e-01,  1.6768e-01],\n",
            "          [-3.0642e-01, -2.5526e-01,  2.1639e-01],\n",
            "          [-2.9680e-01,  1.3114e-02,  1.7158e-01]],\n",
            "\n",
            "         [[-3.8045e-02,  1.5218e-01,  1.9839e-03],\n",
            "          [-1.7139e-01, -2.8427e-01, -1.3299e-01],\n",
            "          [ 9.5710e-02, -7.4602e-02,  5.2609e-02]],\n",
            "\n",
            "         [[ 2.6500e-01,  2.1516e-01, -1.1869e-01],\n",
            "          [ 2.1218e-01,  4.9636e-03, -2.0594e-01],\n",
            "          [-9.0360e-03,  2.2915e-01,  1.3038e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.5102e-02,  1.6424e-01,  1.7603e-01],\n",
            "          [-1.0337e-01,  3.3584e-01,  1.5404e-01],\n",
            "          [-3.6667e-01, -1.1609e-01, -6.9855e-02]],\n",
            "\n",
            "         [[-1.0785e-01, -1.4423e-01, -1.6160e-01],\n",
            "          [-2.6265e-01,  2.5624e-01,  1.4935e-01],\n",
            "          [-1.0913e-02,  7.3988e-02, -1.6905e-02]],\n",
            "\n",
            "         [[-2.7641e-01, -2.6619e-03, -1.4941e-01],\n",
            "          [-2.1555e-01,  2.7435e-01,  2.3548e-01],\n",
            "          [-4.6279e-02,  6.7240e-02, -9.7843e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.0498e-02,  2.3606e-01,  2.5204e-01],\n",
            "          [ 1.7999e-01, -6.9333e-02,  1.2673e-01],\n",
            "          [-1.3175e-01, -1.5644e-01, -1.2207e-01]],\n",
            "\n",
            "         [[-1.7229e-01,  5.0713e-02,  4.9139e-02],\n",
            "          [ 1.7693e-02, -4.9218e-02,  1.3512e-01],\n",
            "          [-9.6016e-02, -8.0809e-02, -1.5362e-01]],\n",
            "\n",
            "         [[-3.2332e-01, -3.7779e-01, -2.4627e-01],\n",
            "          [ 1.3223e-02, -1.0923e-01, -5.4046e-02],\n",
            "          [ 2.1722e-01,  1.5092e-01,  1.7398e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6498e-01,  1.0137e-01,  4.0124e-01],\n",
            "          [-1.0600e-01, -6.3883e-02,  4.1873e-01],\n",
            "          [-3.4123e-01, -4.8628e-01,  3.6628e-02]],\n",
            "\n",
            "         [[ 8.4989e-02, -2.3476e-01, -1.8406e-01],\n",
            "          [-8.9943e-02, -1.9236e-02,  2.1565e-02],\n",
            "          [ 2.8551e-01, -4.8152e-02,  2.1211e-01]],\n",
            "\n",
            "         [[ 1.8533e-01, -2.1239e-01, -3.0275e-01],\n",
            "          [ 3.4883e-01, -2.0261e-01,  2.1436e-02],\n",
            "          [ 4.1522e-01, -1.6572e-01, -1.4324e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.8759e-01, -7.5656e-02,  2.0628e-01],\n",
            "          [-3.0400e-01,  9.5825e-02,  3.2333e-01],\n",
            "          [ 8.4065e-02,  4.2049e-02,  2.6550e-01]],\n",
            "\n",
            "         [[-2.0523e-01,  5.6664e-02, -6.7589e-02],\n",
            "          [-2.0427e-01, -1.3966e-02,  3.3420e-02],\n",
            "          [-1.6700e-01, -1.3273e-02, -1.2320e-01]],\n",
            "\n",
            "         [[-8.5293e-03,  2.3780e-01, -6.4919e-02],\n",
            "          [-1.8982e-01,  2.4371e-01,  9.8424e-02],\n",
            "          [-2.2629e-01,  7.4890e-02,  2.9925e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4301e-01, -7.0321e-02, -8.1851e-02],\n",
            "          [ 1.4217e-02, -1.8949e-01, -2.2460e-01],\n",
            "          [ 1.4430e-01, -1.0891e-01, -3.3018e-01]],\n",
            "\n",
            "         [[-2.4894e-01,  1.9433e-01,  1.7303e-01],\n",
            "          [-2.2461e-01, -8.7398e-02,  6.0107e-02],\n",
            "          [-8.8620e-04,  2.1153e-01, -5.4067e-02]],\n",
            "\n",
            "         [[-2.0906e-01,  2.1584e-02,  2.5143e-01],\n",
            "          [-3.4269e-01,  2.5055e-01,  2.3358e-01],\n",
            "          [-4.2734e-02,  3.0236e-01, -1.7406e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2090e-01, -2.6302e-01, -3.8755e-01],\n",
            "          [ 1.3351e-01, -1.6324e-01,  2.9190e-01],\n",
            "          [ 1.3072e-02, -1.4107e-02,  2.7012e-01]],\n",
            "\n",
            "         [[ 3.0443e-01, -2.2650e-01, -1.8873e-01],\n",
            "          [ 3.2201e-01, -2.2896e-01,  2.1819e-01],\n",
            "          [-2.0827e-01, -6.7011e-02, -7.1129e-02]],\n",
            "\n",
            "         [[-1.4703e-01,  5.2982e-02,  2.3778e-01],\n",
            "          [-2.3131e-02, -2.6025e-01,  4.2241e-01],\n",
            "          [-1.7264e-01, -1.2050e-01,  6.4014e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6779e-01,  9.5797e-02, -2.6161e-02],\n",
            "          [ 1.8696e-01, -6.9638e-02, -2.9629e-01],\n",
            "          [ 7.9449e-02,  2.5471e-01, -2.1848e-01]],\n",
            "\n",
            "         [[ 1.3908e-01, -1.7901e-01,  1.4297e-01],\n",
            "          [-1.4478e-02, -2.3928e-01, -3.3966e-01],\n",
            "          [ 2.0745e-01,  2.2862e-01,  1.1545e-01]],\n",
            "\n",
            "         [[-2.9650e-01, -9.4545e-02, -2.7566e-01],\n",
            "          [-1.1868e-01, -5.5710e-02, -3.5426e-01],\n",
            "          [-7.5812e-02,  3.7463e-01,  2.5827e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2744e-01, -4.8440e-02, -7.7132e-02],\n",
            "          [-9.0283e-02,  1.8394e-02, -7.2323e-02],\n",
            "          [-1.1824e-01, -2.8231e-02, -5.4844e-03]],\n",
            "\n",
            "         [[-1.6246e-01,  1.8774e-01, -3.3449e-02],\n",
            "          [ 1.2672e-01, -2.9045e-02,  1.3857e-02],\n",
            "          [ 2.0212e-01, -9.8456e-02,  1.3678e-01]],\n",
            "\n",
            "         [[ 1.9076e-01,  2.0601e-01,  1.0684e-01],\n",
            "          [ 1.6238e-01, -1.2169e-01, -8.8417e-02],\n",
            "          [ 1.1842e-01,  1.6999e-01, -1.4782e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 5.7338e-02,  9.2861e-02, -2.5264e-01],\n",
            "          [-4.2727e-02, -3.1952e-01, -1.2076e-01],\n",
            "          [ 3.0599e-01,  1.8022e-01,  1.5950e-01]],\n",
            "\n",
            "         [[ 2.7425e-01,  1.7263e-01,  6.5524e-02],\n",
            "          [-1.5800e-01, -4.4123e-01, -2.1567e-01],\n",
            "          [ 2.0193e-01,  2.7275e-02, -5.4292e-02]],\n",
            "\n",
            "         [[ 3.3610e-01,  8.6910e-02,  2.9808e-01],\n",
            "          [-2.4539e-01, -2.1787e-01, -2.4823e-02],\n",
            "          [-1.4519e-01, -1.6245e-01,  1.5630e-01]]],\n",
            "\n",
            "\n",
            "        [[[-9.0310e-02, -9.1774e-02, -2.0660e-01],\n",
            "          [-2.6375e-04,  1.0420e-01,  2.6782e-02],\n",
            "          [ 3.8867e-02, -2.5113e-02,  2.9832e-01]],\n",
            "\n",
            "         [[ 1.8367e-02, -1.2543e-01, -1.5814e-01],\n",
            "          [ 2.1970e-01,  2.3059e-01,  1.4951e-01],\n",
            "          [-2.2536e-01, -4.8782e-02,  8.5099e-02]],\n",
            "\n",
            "         [[ 2.6249e-02, -3.0546e-02,  7.0475e-02],\n",
            "          [ 1.0361e-01,  2.5507e-02,  6.2368e-02],\n",
            "          [-1.5117e-01, -3.2573e-02,  1.0234e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7204e-01, -8.0220e-02, -1.5229e-01],\n",
            "          [-2.1081e-01, -5.6437e-02,  6.6781e-02],\n",
            "          [-1.2370e-01,  3.3135e-02, -8.9013e-02]],\n",
            "\n",
            "         [[ 1.2684e-01, -6.0970e-02, -1.2896e-01],\n",
            "          [-1.7962e-01, -2.6544e-01, -1.6844e-01],\n",
            "          [-1.9762e-02,  2.0317e-01, -1.7588e-02]],\n",
            "\n",
            "         [[ 1.8674e-01,  9.9812e-03, -7.9792e-02],\n",
            "          [-1.2764e-01,  3.8409e-02,  5.6139e-02],\n",
            "          [ 2.3872e-01, -8.2129e-02,  1.7619e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 8.1877e-02, -1.2555e-01,  4.0475e-01],\n",
            "          [ 2.2018e-01, -1.4386e-02,  8.7058e-02],\n",
            "          [-1.7556e-01,  1.5475e-01, -2.3943e-01]],\n",
            "\n",
            "         [[-2.5662e-01, -3.7730e-01, -1.0636e-01],\n",
            "          [-1.7630e-01,  5.1933e-02, -1.5681e-01],\n",
            "          [ 1.3525e-01,  5.8568e-02, -4.0022e-01]],\n",
            "\n",
            "         [[ 1.9572e-01, -1.8609e-01, -3.2313e-02],\n",
            "          [ 1.5170e-01,  3.3055e-01, -2.0647e-01],\n",
            "          [ 1.9523e-01,  3.9528e-01, -2.4165e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.3534e-01, -2.6236e-01, -5.9272e-03],\n",
            "          [ 6.4816e-02,  4.1662e-02, -2.3163e-02],\n",
            "          [ 2.9131e-01, -2.3842e-02, -1.1513e-01]],\n",
            "\n",
            "         [[-2.9837e-01, -8.5397e-02,  1.3888e-01],\n",
            "          [ 1.4526e-01, -9.5776e-02,  1.1985e-02],\n",
            "          [ 2.6126e-01,  3.3320e-02,  8.3557e-02]],\n",
            "\n",
            "         [[-4.0155e-01,  1.4576e-01,  1.6756e-01],\n",
            "          [ 2.1824e-01,  1.9549e-01,  1.6357e-01],\n",
            "          [ 9.8094e-02, -9.0679e-02,  7.6198e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.2412e-02,  1.9985e-01,  1.8394e-01],\n",
            "          [ 1.7474e-01,  2.7035e-01,  1.5715e-01],\n",
            "          [ 8.1056e-02, -7.9415e-02, -4.6569e-02]],\n",
            "\n",
            "         [[ 1.0323e-01, -1.0411e-01,  1.1057e-01],\n",
            "          [ 1.5617e-01,  2.0208e-01, -1.1775e-01],\n",
            "          [-2.4208e-01, -2.4969e-01,  2.2818e-02]],\n",
            "\n",
            "         [[-1.4389e-01, -1.7680e-01,  4.4717e-02],\n",
            "          [-1.7383e-01,  1.6148e-01,  1.5948e-01],\n",
            "          [ 1.2680e-01, -3.1325e-02, -5.0881e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"16_focus_pretrained_classify_pretrained_train_classify\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0zuujPPzLHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(focus_net.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn/\"+name+\"_focus_net.pt\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn/\"+name+\"_classify.pt\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "5ef6c0b4-d34b-4f82-f8e3-75e05432a481"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>29973</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29998</td>\n",
              "      <td>2</td>\n",
              "      <td>29591</td>\n",
              "      <td>2</td>\n",
              "      <td>401</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>29306</td>\n",
              "      <td>694</td>\n",
              "      <td>28551</td>\n",
              "      <td>943</td>\n",
              "      <td>287</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>29306</td>\n",
              "      <td>694</td>\n",
              "      <td>28679</td>\n",
              "      <td>1075</td>\n",
              "      <td>159</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>29306</td>\n",
              "      <td>694</td>\n",
              "      <td>28813</td>\n",
              "      <td>1117</td>\n",
              "      <td>25</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>29306</td>\n",
              "      <td>694</td>\n",
              "      <td>28775</td>\n",
              "      <td>1111</td>\n",
              "      <td>63</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0       0         30000  ...                     21                       2\n",
              "1       1         29998  ...                    401                       6\n",
              "2       6         29306  ...                    287                     219\n",
              "3      11         29306  ...                    159                      87\n",
              "4      16         29306  ...                     25                      45\n",
              "5      21         29306  ...                     63                      51\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "c9f378d6-318f-49cf-feee-6f46346f04d8"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "4228fdf4-373e-4f8a-caf4-ae37090949c7"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>9984</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9771</td>\n",
              "      <td>229</td>\n",
              "      <td>9043</td>\n",
              "      <td>205</td>\n",
              "      <td>559</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>9771</td>\n",
              "      <td>229</td>\n",
              "      <td>9497</td>\n",
              "      <td>247</td>\n",
              "      <td>105</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>9771</td>\n",
              "      <td>229</td>\n",
              "      <td>9439</td>\n",
              "      <td>258</td>\n",
              "      <td>163</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>9771</td>\n",
              "      <td>229</td>\n",
              "      <td>9504</td>\n",
              "      <td>243</td>\n",
              "      <td>98</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>9771</td>\n",
              "      <td>229</td>\n",
              "      <td>9483</td>\n",
              "      <td>269</td>\n",
              "      <td>119</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0       0         10000  ...                     12                       1\n",
              "1       1          9771  ...                    559                     193\n",
              "2       6          9771  ...                    105                     151\n",
              "3      11          9771  ...                    163                     140\n",
              "4      16          9771  ...                     98                     155\n",
              "5      21          9771  ...                    119                     129\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "06c067fb-c2f4-49f3-c1f2-00cb87963df9"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QrqLdIryOHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "0790884b-a2ea-4991-8458-e723037e0beb"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29981\n",
            "total train set images 30000\n",
            "focus_true_pred_true 28836 =============> FTPT : 96 %\n",
            "focus_false_pred_true 1145 =============> FFPT : 3 %\n",
            "focus_true_pred_false 2 =============> FTPF : 0 %\n",
            "focus_false_pred_false 17 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  29306\n",
            "argmax_less_than_half ==================>  694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvM5QP_FyQyV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "0239b745-874b-43ca-d74e-0ad2ee9fcd05"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n",
            "total correct 9782\n",
            "total train set images 10000\n",
            "focus_true_pred_true 9520 =============> FTPT : 95 %\n",
            "focus_false_pred_true 262 =============> FFPT : 2 %\n",
            "focus_true_pred_false 82 =============> FTPF : 0 %\n",
            "focus_false_pred_false 136 =============> FFPF : 1 %\n",
            "argmax_more_than_half ==================>  9771\n",
            "argmax_less_than_half ==================>  229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "46507c52-db40-4149-b1dd-b4c3ec7be94e"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29981\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3edbe159-b24f-4624-d549-3127843522e3"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n",
            "total correct 9782\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}