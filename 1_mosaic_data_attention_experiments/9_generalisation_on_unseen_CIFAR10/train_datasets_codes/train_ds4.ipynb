{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eba951e4-6056-4433-81d3-dd26de83caea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98ab3307-0c6a-435e-ef3a-efd5915b09e2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f68a1f6e-fde6-453a-d356-36660dfd0e8b"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fc40e5c1-b6b6-4146-c2c1-9e4068478f85"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 30000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4WPsAzBcgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11b4455e-07ee-4229-ca3b-4cf15bfc0fff"
      },
      "source": [
        "print(len(mosaic_list_of_images),len(mosaic_label))"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c71acae3-550f-4f6d-8221-4e85c8a310d2"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.103\n",
            "[1,    80] loss: 1.097\n",
            "[1,   120] loss: 1.096\n",
            "[2,    40] loss: 1.092\n",
            "[2,    80] loss: 1.086\n",
            "[2,   120] loss: 1.079\n",
            "[3,    40] loss: 1.068\n",
            "[3,    80] loss: 1.058\n",
            "[3,   120] loss: 1.050\n",
            "[4,    40] loss: 1.034\n",
            "[4,    80] loss: 1.029\n",
            "[4,   120] loss: 1.018\n",
            "[5,    40] loss: 0.984\n",
            "[5,    80] loss: 0.925\n",
            "[5,   120] loss: 0.854\n",
            "[6,    40] loss: 0.763\n",
            "[6,    80] loss: 0.707\n",
            "[6,   120] loss: 0.662\n",
            "[7,    40] loss: 0.552\n",
            "[7,    80] loss: 0.521\n",
            "[7,   120] loss: 0.477\n",
            "[8,    40] loss: 0.445\n",
            "[8,    80] loss: 0.391\n",
            "[8,   120] loss: 0.344\n",
            "[9,    40] loss: 0.283\n",
            "[9,    80] loss: 0.279\n",
            "[9,   120] loss: 0.283\n",
            "[10,    40] loss: 0.242\n",
            "[10,    80] loss: 0.216\n",
            "[10,   120] loss: 0.228\n",
            "[11,    40] loss: 0.179\n",
            "[11,    80] loss: 0.168\n",
            "[11,   120] loss: 0.217\n",
            "[12,    40] loss: 0.190\n",
            "[12,    80] loss: 0.163\n",
            "[12,   120] loss: 0.149\n",
            "[13,    40] loss: 0.149\n",
            "[13,    80] loss: 0.138\n",
            "[13,   120] loss: 0.128\n",
            "[14,    40] loss: 0.114\n",
            "[14,    80] loss: 0.109\n",
            "[14,   120] loss: 0.105\n",
            "[15,    40] loss: 0.090\n",
            "[15,    80] loss: 0.094\n",
            "[15,   120] loss: 0.096\n",
            "[16,    40] loss: 0.123\n",
            "[16,    80] loss: 0.091\n",
            "[16,   120] loss: 0.086\n",
            "[17,    40] loss: 0.072\n",
            "[17,    80] loss: 0.071\n",
            "[17,   120] loss: 0.072\n",
            "[18,    40] loss: 0.063\n",
            "[18,    80] loss: 0.059\n",
            "[18,   120] loss: 0.060\n",
            "[19,    40] loss: 0.063\n",
            "[19,    80] loss: 0.063\n",
            "[19,   120] loss: 0.071\n",
            "[20,    40] loss: 0.060\n",
            "[20,    80] loss: 0.057\n",
            "[20,   120] loss: 0.058\n",
            "[21,    40] loss: 0.049\n",
            "[21,    80] loss: 0.055\n",
            "[21,   120] loss: 0.058\n",
            "[22,    40] loss: 0.049\n",
            "[22,    80] loss: 0.047\n",
            "[22,   120] loss: 0.060\n",
            "[23,    40] loss: 0.044\n",
            "[23,    80] loss: 0.047\n",
            "[23,   120] loss: 0.060\n",
            "[24,    40] loss: 0.047\n",
            "[24,    80] loss: 0.051\n",
            "[24,   120] loss: 0.059\n",
            "[25,    40] loss: 0.043\n",
            "[25,    80] loss: 0.038\n",
            "[25,   120] loss: 0.048\n",
            "[26,    40] loss: 0.035\n",
            "[26,    80] loss: 0.043\n",
            "[26,   120] loss: 0.041\n",
            "[27,    40] loss: 0.052\n",
            "[27,    80] loss: 0.052\n",
            "[27,   120] loss: 0.044\n",
            "[28,    40] loss: 0.039\n",
            "[28,    80] loss: 0.051\n",
            "[28,   120] loss: 0.058\n",
            "[29,    40] loss: 0.035\n",
            "[29,    80] loss: 0.045\n",
            "[29,   120] loss: 0.048\n",
            "[30,    40] loss: 0.038\n",
            "[30,    80] loss: 0.029\n",
            "[30,   120] loss: 0.036\n",
            "[31,    40] loss: 0.026\n",
            "[31,    80] loss: 0.024\n",
            "[31,   120] loss: 0.023\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds4\""
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6f481cdb-2544-47ac-88cb-e3011cd88496"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29809\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b8582177-6ffc-45c1-ec5c-aab686ed26fd"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "total correct 7142\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fbe77b65-2d9b-4151-deab-c3cf886372b9"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 68 %\n",
            "total correct 6823\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "075860a3-3d46-4f53-faf2-6ef457c64379"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "total correct 7157\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "005574f6-4aea-435d-9ca6-0d62f98fa0a0"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n",
            "total correct 9769\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3e3f146c-b3db-4b6f-c13d-9b33ec3912ce"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 95 %\n",
            "total correct 9515\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e922b6ca-f1af-47a7-d2de-d6453aab0741"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n",
            "total correct 9723\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f7847a04-83c4-46a3-9240-b9c3079ae57a"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "total correct 7642\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9d9a326b-3707-44ac-80ee-5c08e99a13d5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 72 %\n",
            "total correct 7248\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ca79ba41-fa33-41ee-b1ee-d765da183d50"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "total correct 7561\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e4162979-3d3d-4307-be4a-813a655bd02f"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 258,
      "outputs": []
    }
  ]
}