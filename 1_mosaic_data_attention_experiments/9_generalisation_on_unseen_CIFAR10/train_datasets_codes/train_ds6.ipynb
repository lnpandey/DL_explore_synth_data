{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eba951e4-6056-4433-81d3-dd26de83caea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98ab3307-0c6a-435e-ef3a-efd5915b09e2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f68a1f6e-fde6-453a-d356-36660dfd0e8b"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fc40e5c1-b6b6-4146-c2c1-9e4068478f85"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 30000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)"
      ],
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4WPsAzBcgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3919b0a8-47c4-49f8-e509-3f4064528e35"
      },
      "source": [
        "print(len(mosaic_list_of_images),len(mosaic_label))"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3aa70bf7-2cc2-4db2-ea75-a910b9ff6496"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.104\n",
            "[1,    80] loss: 1.093\n",
            "[1,   120] loss: 1.084\n",
            "[2,    40] loss: 1.083\n",
            "[2,    80] loss: 1.079\n",
            "[2,   120] loss: 1.074\n",
            "[3,    40] loss: 1.063\n",
            "[3,    80] loss: 1.052\n",
            "[3,   120] loss: 1.044\n",
            "[4,    40] loss: 1.025\n",
            "[4,    80] loss: 0.994\n",
            "[4,   120] loss: 0.938\n",
            "[5,    40] loss: 0.864\n",
            "[5,    80] loss: 0.811\n",
            "[5,   120] loss: 0.722\n",
            "[6,    40] loss: 0.638\n",
            "[6,    80] loss: 0.612\n",
            "[6,   120] loss: 0.549\n",
            "[7,    40] loss: 0.481\n",
            "[7,    80] loss: 0.454\n",
            "[7,   120] loss: 0.409\n",
            "[8,    40] loss: 0.363\n",
            "[8,    80] loss: 0.348\n",
            "[8,   120] loss: 0.326\n",
            "[9,    40] loss: 0.308\n",
            "[9,    80] loss: 0.274\n",
            "[9,   120] loss: 0.251\n",
            "[10,    40] loss: 0.229\n",
            "[10,    80] loss: 0.244\n",
            "[10,   120] loss: 0.212\n",
            "[11,    40] loss: 0.217\n",
            "[11,    80] loss: 0.192\n",
            "[11,   120] loss: 0.209\n",
            "[12,    40] loss: 0.168\n",
            "[12,    80] loss: 0.149\n",
            "[12,   120] loss: 0.151\n",
            "[13,    40] loss: 0.128\n",
            "[13,    80] loss: 0.128\n",
            "[13,   120] loss: 0.128\n",
            "[14,    40] loss: 0.135\n",
            "[14,    80] loss: 0.134\n",
            "[14,   120] loss: 0.117\n",
            "[15,    40] loss: 0.102\n",
            "[15,    80] loss: 0.111\n",
            "[15,   120] loss: 0.116\n",
            "[16,    40] loss: 0.107\n",
            "[16,    80] loss: 0.095\n",
            "[16,   120] loss: 0.101\n",
            "[17,    40] loss: 0.098\n",
            "[17,    80] loss: 0.098\n",
            "[17,   120] loss: 0.073\n",
            "[18,    40] loss: 0.091\n",
            "[18,    80] loss: 0.084\n",
            "[18,   120] loss: 0.090\n",
            "[19,    40] loss: 0.080\n",
            "[19,    80] loss: 0.084\n",
            "[19,   120] loss: 0.088\n",
            "[20,    40] loss: 0.081\n",
            "[20,    80] loss: 0.075\n",
            "[20,   120] loss: 0.070\n",
            "[21,    40] loss: 0.060\n",
            "[21,    80] loss: 0.060\n",
            "[21,   120] loss: 0.072\n",
            "[22,    40] loss: 0.069\n",
            "[22,    80] loss: 0.063\n",
            "[22,   120] loss: 0.050\n",
            "[23,    40] loss: 0.053\n",
            "[23,    80] loss: 0.059\n",
            "[23,   120] loss: 0.059\n",
            "[24,    40] loss: 0.061\n",
            "[24,    80] loss: 0.064\n",
            "[24,   120] loss: 0.069\n",
            "[25,    40] loss: 0.051\n",
            "[25,    80] loss: 0.044\n",
            "[25,   120] loss: 0.049\n",
            "[26,    40] loss: 0.036\n",
            "[26,    80] loss: 0.037\n",
            "[26,   120] loss: 0.042\n",
            "[27,    40] loss: 0.037\n",
            "[27,    80] loss: 0.048\n",
            "[27,   120] loss: 0.043\n",
            "[28,    40] loss: 0.034\n",
            "[28,    80] loss: 0.042\n",
            "[28,   120] loss: 0.049\n",
            "[29,    40] loss: 0.024\n",
            "[29,    80] loss: 0.029\n",
            "[29,   120] loss: 0.028\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds6\""
      ],
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fafe8c40-2235-4a14-943f-4db5723294ae"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29865\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "aa5d6d0a-048e-446d-a84e-3d893326ff6d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "total correct 7178\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "688f2e7d-333d-47d9-945c-1f5a0d7b75d5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "total correct 7135\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "02e9d868-4715-4f18-9e04-00d355b23a84"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 72 %\n",
            "total correct 7222\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b19221bf-2ed4-42b2-e0e5-37c592c09503"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n",
            "total correct 9783\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4b70b944-a053-45b1-bb85-877d7ad21a7b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n",
            "total correct 9785\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d74f5f76-5676-4c4e-ae9f-8e708a51a7a6"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n",
            "total correct 9791\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6253b467-8aa7-4960-c42f-deb9db54c440"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "total correct 7546\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "06e975af-8f4b-4782-bc66-2d93dd663cf8"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "total correct 7626\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9d2414ad-e30d-4372-ae38-8a0b2a650539"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "total correct 7583\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "045197d4-965b-45c1-a921-4401febdeda1"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 341,
      "outputs": []
    }
  ]
}