{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "focus_random_classify_random_train_both_k_0_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72e561eaa13b4c6bbb9da9f982204c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3bb594e7c0b4f52a911a93ced75c409",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d14274fd5e247dcb9227de6944215c9",
              "IPY_MODEL_8b50fd4b23a0498c934bbebd0ce7bf63"
            ]
          }
        },
        "c3bb594e7c0b4f52a911a93ced75c409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d14274fd5e247dcb9227de6944215c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04aab24c01574f94839c1814681b4672",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_657d40c85e0b47e4b8443f68017993a9"
          }
        },
        "8b50fd4b23a0498c934bbebd0ce7bf63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fce6cf0bd41a4d279732ec694c28500a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:05&lt;00:00, 28531155.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_876c4019e3fe44e0b0f841379e8185ad"
          }
        },
        "04aab24c01574f94839c1814681b4672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "657d40c85e0b47e4b8443f68017993a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fce6cf0bd41a4d279732ec694c28500a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "876c4019e3fe44e0b0f841379e8185ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjG64ra4aFu",
        "outputId": "df941b37-0191-482b-e5e6-a030541b4422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-7SARDZErK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acRFqJNrZErV",
        "outputId": "23fe5d4c-f115-464e-aeef-3581fc78d2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "72e561eaa13b4c6bbb9da9f982204c1c",
            "c3bb594e7c0b4f52a911a93ced75c409",
            "4d14274fd5e247dcb9227de6944215c9",
            "8b50fd4b23a0498c934bbebd0ce7bf63",
            "04aab24c01574f94839c1814681b4672",
            "657d40c85e0b47e4b8443f68017993a9",
            "fce6cf0bd41a4d279732ec694c28500a",
            "876c4019e3fe44e0b0f841379e8185ad"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72e561eaa13b4c6bbb9da9f982204c1c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3BOnEFUZOLx"
      },
      "source": [
        "k = 0.5"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_JUhwCeZErk",
        "outputId": "fcc4d48f-ff91-4eb5-a650-1c48fd1707dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SadRzWBBZEsP"
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w"
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM"
      },
      "source": [
        "def init_weights(m,k=0.5):\n",
        "  if type(m) == nn.Linear:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)\n",
        "  if type(m) == nn.Conv2d:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhjiW2hKZTCY",
        "outputId": "8f0b4dac-e427-45f6-a77f-e775646f71f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "focus_net.apply(init_weights)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.1050,  0.1214,  0.0588],\n",
            "          [-0.1193,  0.0163,  0.0455],\n",
            "          [ 0.0215,  0.0241,  0.1083]],\n",
            "\n",
            "         [[ 0.0433,  0.0966, -0.0650],\n",
            "          [-0.1277,  0.1072, -0.0358],\n",
            "          [-0.0312,  0.0118, -0.0548]],\n",
            "\n",
            "         [[-0.0689, -0.0810,  0.0414],\n",
            "          [ 0.0412,  0.0663,  0.0657],\n",
            "          [-0.1363,  0.1377, -0.0697]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243,  0.1074,  0.0612],\n",
            "          [-0.0413,  0.1226,  0.0983],\n",
            "          [ 0.0922,  0.0167,  0.1221]],\n",
            "\n",
            "         [[ 0.0511,  0.1312, -0.0172],\n",
            "          [-0.0914, -0.0009, -0.0219],\n",
            "          [-0.0516, -0.0447,  0.1076]],\n",
            "\n",
            "         [[-0.1184,  0.0627,  0.1237],\n",
            "          [ 0.1283, -0.0161, -0.0057],\n",
            "          [ 0.0065, -0.0395,  0.0546]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024, -0.1245,  0.0225],\n",
            "          [ 0.1106,  0.0834, -0.0226],\n",
            "          [-0.1247, -0.0061, -0.1214]],\n",
            "\n",
            "         [[ 0.0866,  0.1358,  0.0561],\n",
            "          [-0.0469,  0.0484,  0.1072],\n",
            "          [-0.1322, -0.1119,  0.1240]],\n",
            "\n",
            "         [[ 0.0972,  0.0309, -0.0326],\n",
            "          [ 0.0429, -0.0177,  0.1361],\n",
            "          [-0.0201,  0.0622,  0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0303,  0.0592, -0.0878],\n",
            "          [ 0.0015, -0.0844,  0.0005],\n",
            "          [-0.0110, -0.1320,  0.0073]],\n",
            "\n",
            "         [[-0.0690, -0.0391, -0.1286],\n",
            "          [-0.1111, -0.0964,  0.0491],\n",
            "          [ 0.0080,  0.0899,  0.0564]],\n",
            "\n",
            "         [[ 0.1066, -0.0032,  0.1346],\n",
            "          [-0.0996, -0.0303,  0.0290],\n",
            "          [-0.1192, -0.0811,  0.0647]]],\n",
            "\n",
            "\n",
            "        [[[-0.0746,  0.0155,  0.0927],\n",
            "          [ 0.1275, -0.0648, -0.1212],\n",
            "          [-0.0438,  0.0703,  0.0093]],\n",
            "\n",
            "         [[ 0.0649, -0.1058, -0.1375],\n",
            "          [-0.0805,  0.0599, -0.0410],\n",
            "          [ 0.1259,  0.0705,  0.1220]],\n",
            "\n",
            "         [[ 0.0110,  0.0289,  0.0606],\n",
            "          [ 0.0577,  0.0234, -0.0851],\n",
            "          [ 0.0604, -0.0535,  0.0725]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0470, -0.0210,  0.1061],\n",
            "          [ 0.1273,  0.1034, -0.0953],\n",
            "          [ 0.1343, -0.0333,  0.0573]],\n",
            "\n",
            "         [[ 0.0107, -0.1018, -0.0632],\n",
            "          [-0.1064,  0.0825,  0.0589],\n",
            "          [ 0.1306, -0.1160, -0.0009]],\n",
            "\n",
            "         [[ 0.1033,  0.1369,  0.1329],\n",
            "          [-0.0583, -0.1006, -0.0515],\n",
            "          [ 0.0956, -0.0466,  0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0630, -0.1007, -0.0224],\n",
            "          [ 0.0597,  0.0746, -0.0809],\n",
            "          [ 0.1096, -0.0081,  0.0485]],\n",
            "\n",
            "         [[-0.0192,  0.0433, -0.0180],\n",
            "          [ 0.0555, -0.0442, -0.1342],\n",
            "          [ 0.0390, -0.0937, -0.1160]],\n",
            "\n",
            "         [[ 0.0635, -0.0448,  0.0776],\n",
            "          [-0.0472,  0.1219, -0.0217],\n",
            "          [ 0.0235,  0.1338, -0.1280]]],\n",
            "\n",
            "\n",
            "        [[[-0.1138,  0.0961,  0.0734],\n",
            "          [ 0.1227,  0.0692,  0.0687],\n",
            "          [ 0.0951, -0.0988, -0.1304]],\n",
            "\n",
            "         [[ 0.0414,  0.1211,  0.1038],\n",
            "          [ 0.0472,  0.0314,  0.1127],\n",
            "          [ 0.1249,  0.0592,  0.1128]],\n",
            "\n",
            "         [[-0.0023, -0.0187, -0.0323],\n",
            "          [ 0.0005, -0.0440,  0.1075],\n",
            "          [-0.0339, -0.0237,  0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1025, -0.0733,  0.0263],\n",
            "          [ 0.0634, -0.1255,  0.0807],\n",
            "          [-0.0945, -0.0226, -0.1057]],\n",
            "\n",
            "         [[-0.0354,  0.0731, -0.0700],\n",
            "          [-0.0865, -0.1230, -0.1273],\n",
            "          [-0.1034, -0.0091,  0.0499]],\n",
            "\n",
            "         [[-0.0941, -0.1289, -0.0261],\n",
            "          [-0.0112,  0.0301,  0.1376],\n",
            "          [ 0.0553, -0.1234, -0.0216]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1093, -0.0918,  0.0554],\n",
            "          [-0.0098,  0.0586, -0.0456],\n",
            "          [ 0.0957, -0.0791,  0.0954]],\n",
            "\n",
            "         [[ 0.0342, -0.0692, -0.0776],\n",
            "          [ 0.0679, -0.1333, -0.0824],\n",
            "          [ 0.0169,  0.0182,  0.0261]],\n",
            "\n",
            "         [[-0.0804, -0.0958,  0.0014],\n",
            "          [-0.0349,  0.1200, -0.1340],\n",
            "          [-0.0353, -0.0973,  0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0191,  0.0477, -0.0084],\n",
            "          [ 0.0818,  0.1183, -0.0276],\n",
            "          [-0.0286,  0.0132, -0.0614]],\n",
            "\n",
            "         [[ 0.0330,  0.0598,  0.1111],\n",
            "          [ 0.1165, -0.0417,  0.0480],\n",
            "          [-0.0908,  0.0554,  0.1349]],\n",
            "\n",
            "         [[-0.0483,  0.0873, -0.1318],\n",
            "          [ 0.0756,  0.0214,  0.1137],\n",
            "          [ 0.0039,  0.1094,  0.0119]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0383,  0.1257],\n",
            "          [-0.0961,  0.1246,  0.0706],\n",
            "          [ 0.0321,  0.0388, -0.0594]],\n",
            "\n",
            "         [[-0.1108,  0.0191,  0.1080],\n",
            "          [ 0.1116,  0.0277, -0.0775],\n",
            "          [-0.0249,  0.1057, -0.0952]],\n",
            "\n",
            "         [[ 0.1207, -0.1373, -0.0730],\n",
            "          [ 0.1134,  0.0365, -0.0702],\n",
            "          [-0.0340, -0.1309, -0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1354,  0.1205, -0.1124],\n",
            "          [-0.0645, -0.0902,  0.1234],\n",
            "          [-0.0884,  0.0080,  0.0424]],\n",
            "\n",
            "         [[-0.0670,  0.0203, -0.0854],\n",
            "          [ 0.0503, -0.0132,  0.1265],\n",
            "          [-0.0972,  0.0498,  0.1150]],\n",
            "\n",
            "         [[-0.1209,  0.1248,  0.0428],\n",
            "          [-0.0510,  0.0816,  0.0532],\n",
            "          [-0.0520, -0.0577,  0.1087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1126,  0.0255, -0.1296],\n",
            "          [ 0.0378,  0.0466, -0.0572],\n",
            "          [ 0.0232, -0.0410,  0.1117]],\n",
            "\n",
            "         [[ 0.0124, -0.1374,  0.1032],\n",
            "          [-0.0838, -0.1037,  0.0993],\n",
            "          [-0.0971,  0.0112,  0.1063]],\n",
            "\n",
            "         [[-0.1211,  0.1292, -0.0956],\n",
            "          [ 0.0564, -0.1087,  0.0525],\n",
            "          [ 0.1237,  0.0084,  0.0690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0790,  0.0170,  0.1157],\n",
            "          [-0.1304, -0.1316,  0.1206],\n",
            "          [ 0.1354, -0.1357,  0.0203]],\n",
            "\n",
            "         [[ 0.0671,  0.0099,  0.0534],\n",
            "          [ 0.0526, -0.0304,  0.0219],\n",
            "          [-0.0585,  0.0089, -0.0224]],\n",
            "\n",
            "         [[-0.0058, -0.0208,  0.0841],\n",
            "          [ 0.0215, -0.0465, -0.0621],\n",
            "          [-0.1283,  0.1176, -0.0754]]],\n",
            "\n",
            "\n",
            "        [[[-0.0220,  0.0226,  0.0721],\n",
            "          [-0.0388, -0.0747,  0.0138],\n",
            "          [-0.0008,  0.1340,  0.0115]],\n",
            "\n",
            "         [[-0.1081,  0.1344,  0.0052],\n",
            "          [ 0.1110, -0.1306, -0.1088],\n",
            "          [-0.0309,  0.0023,  0.0570]],\n",
            "\n",
            "         [[-0.0560, -0.1184,  0.0920],\n",
            "          [ 0.0252, -0.0433,  0.0878],\n",
            "          [ 0.0069, -0.1082,  0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0770,  0.0946, -0.0880],\n",
            "          [-0.0460,  0.1173,  0.0226],\n",
            "          [ 0.0407,  0.0980, -0.0654]],\n",
            "\n",
            "         [[-0.0717, -0.0724,  0.0412],\n",
            "          [-0.0562,  0.0682, -0.0425],\n",
            "          [ 0.0033, -0.1061,  0.0760]],\n",
            "\n",
            "         [[-0.1020, -0.0190, -0.0219],\n",
            "          [ 0.0550, -0.0851,  0.1220],\n",
            "          [ 0.0055,  0.0560,  0.1111]]],\n",
            "\n",
            "\n",
            "        [[[-0.0951, -0.0374, -0.1315],\n",
            "          [-0.1089,  0.0229,  0.1351],\n",
            "          [ 0.0422,  0.1377, -0.1347]],\n",
            "\n",
            "         [[-0.0214, -0.0826, -0.1109],\n",
            "          [-0.0246, -0.0491,  0.0648],\n",
            "          [-0.0400,  0.1292, -0.0168]],\n",
            "\n",
            "         [[ 0.0885, -0.0273, -0.0782],\n",
            "          [-0.0131, -0.0099,  0.0111],\n",
            "          [ 0.0437, -0.1332, -0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0438,  0.1056],\n",
            "          [ 0.0402, -0.1309,  0.1371],\n",
            "          [ 0.1017,  0.0284, -0.0202]],\n",
            "\n",
            "         [[ 0.1244, -0.1375,  0.0282],\n",
            "          [ 0.1086,  0.1217,  0.0943],\n",
            "          [-0.0004,  0.0387, -0.0833]],\n",
            "\n",
            "         [[-0.0171, -0.0782, -0.0358],\n",
            "          [ 0.0075, -0.1302,  0.0208],\n",
            "          [-0.0873, -0.0959,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102, -0.1067, -0.1025],\n",
            "          [ 0.1116,  0.0266, -0.1028],\n",
            "          [-0.0635, -0.0708, -0.0697]],\n",
            "\n",
            "         [[ 0.0030,  0.0739, -0.0855],\n",
            "          [-0.0650,  0.1201, -0.0131],\n",
            "          [-0.0618, -0.0680, -0.0356]],\n",
            "\n",
            "         [[-0.0797, -0.1149,  0.0272],\n",
            "          [ 0.0520,  0.0685,  0.0054],\n",
            "          [-0.0097, -0.0302,  0.1144]]],\n",
            "\n",
            "\n",
            "        [[[-0.1193,  0.0028,  0.0314],\n",
            "          [-0.1280,  0.1190, -0.1014],\n",
            "          [-0.1231,  0.0703,  0.0279]],\n",
            "\n",
            "         [[ 0.0904, -0.1331, -0.0808],\n",
            "          [ 0.0591, -0.0654,  0.1076],\n",
            "          [-0.0453, -0.0707,  0.1021]],\n",
            "\n",
            "         [[-0.0887, -0.0770, -0.0189],\n",
            "          [ 0.0863, -0.0374, -0.0307],\n",
            "          [-0.1057,  0.0172, -0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0808, -0.1211, -0.0311],\n",
            "          [-0.1210,  0.1079,  0.1335],\n",
            "          [ 0.0941, -0.0931,  0.1172]],\n",
            "\n",
            "         [[ 0.0292,  0.0663,  0.1289],\n",
            "          [ 0.0864, -0.0247, -0.1160],\n",
            "          [-0.0783,  0.0210,  0.0308]],\n",
            "\n",
            "         [[-0.1219,  0.0811, -0.1078],\n",
            "          [ 0.1174,  0.0290, -0.0027],\n",
            "          [-0.0488, -0.0225,  0.0816]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1049,  0.0749, -0.1125],\n",
            "          [ 0.1378, -0.0721,  0.1281],\n",
            "          [-0.0777,  0.1362,  0.1164]],\n",
            "\n",
            "         [[ 0.0799,  0.0223,  0.1133],\n",
            "          [-0.0881,  0.0412,  0.0543],\n",
            "          [-0.0111, -0.0803, -0.0113]],\n",
            "\n",
            "         [[-0.0609,  0.0141, -0.0534],\n",
            "          [-0.1238,  0.0143,  0.0859],\n",
            "          [-0.0301, -0.0316,  0.0964]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0993,  0.1189, -0.0055],\n",
            "          [ 0.0014, -0.0976,  0.0031],\n",
            "          [ 0.0043,  0.1026, -0.1371]],\n",
            "\n",
            "         [[-0.0154, -0.1327, -0.1321],\n",
            "          [ 0.0735,  0.0689,  0.1124],\n",
            "          [ 0.0417,  0.0066, -0.0752]],\n",
            "\n",
            "         [[-0.1169, -0.0826, -0.0636],\n",
            "          [-0.0801,  0.0542,  0.1322],\n",
            "          [ 0.1274, -0.0805, -0.1321]]],\n",
            "\n",
            "\n",
            "        [[[-0.0321, -0.1013, -0.1340],\n",
            "          [ 0.0549,  0.1229,  0.0187],\n",
            "          [ 0.0635,  0.0855, -0.0793]],\n",
            "\n",
            "         [[ 0.0163,  0.0576, -0.0725],\n",
            "          [ 0.1349,  0.1338,  0.0424],\n",
            "          [-0.0565, -0.0271, -0.0065]],\n",
            "\n",
            "         [[ 0.1057, -0.0662,  0.0843],\n",
            "          [ 0.1218, -0.0181, -0.0132],\n",
            "          [-0.0224,  0.0711,  0.1373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458, -0.0240, -0.0642],\n",
            "          [-0.1284,  0.1301, -0.0221],\n",
            "          [ 0.0513,  0.0357,  0.0685]],\n",
            "\n",
            "         [[ 0.0447,  0.0482,  0.0202],\n",
            "          [ 0.1029, -0.0415,  0.0292],\n",
            "          [ 0.0927, -0.0914,  0.1029]],\n",
            "\n",
            "         [[ 0.0587, -0.0453, -0.0390],\n",
            "          [ 0.0402, -0.1310,  0.1291],\n",
            "          [-0.1203, -0.0834,  0.0932]]],\n",
            "\n",
            "\n",
            "        [[[-0.1195, -0.0345, -0.0670],\n",
            "          [ 0.0642, -0.0037, -0.0502],\n",
            "          [-0.0359,  0.0489,  0.0630]],\n",
            "\n",
            "         [[-0.0950,  0.1065,  0.0999],\n",
            "          [ 0.0028, -0.0237,  0.0881],\n",
            "          [ 0.1140, -0.1286,  0.0987]],\n",
            "\n",
            "         [[-0.0686, -0.0377,  0.0912],\n",
            "          [ 0.1366, -0.0975, -0.0507],\n",
            "          [-0.0163,  0.0094,  0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1173,  0.1334, -0.0506],\n",
            "          [-0.1283, -0.1268,  0.0220],\n",
            "          [ 0.0777, -0.0241, -0.0772]],\n",
            "\n",
            "         [[-0.0849, -0.0376,  0.0414],\n",
            "          [ 0.1200,  0.0639, -0.0089],\n",
            "          [-0.0256,  0.1346,  0.0802]],\n",
            "\n",
            "         [[-0.1187,  0.1279,  0.0268],\n",
            "          [ 0.0801, -0.0363, -0.1048],\n",
            "          [-0.0573, -0.0708,  0.0379]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0796, -0.0600,  0.0439],\n",
            "          [ 0.0550, -0.1245, -0.0892],\n",
            "          [-0.0474, -0.1210,  0.1336]],\n",
            "\n",
            "         [[ 0.0692,  0.0903, -0.0840],\n",
            "          [ 0.1243,  0.1076,  0.1367],\n",
            "          [-0.0511, -0.0784, -0.0105]],\n",
            "\n",
            "         [[ 0.0425, -0.0139,  0.1241],\n",
            "          [-0.0850,  0.0267,  0.0743],\n",
            "          [-0.1332, -0.0337, -0.0154]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0971, -0.0718, -0.0420],\n",
            "          [-0.1062,  0.1183, -0.1028],\n",
            "          [-0.0097,  0.0813, -0.0535]],\n",
            "\n",
            "         [[ 0.1279,  0.1208,  0.0060],\n",
            "          [-0.1352, -0.0636,  0.0192],\n",
            "          [-0.1363, -0.0039,  0.0833]],\n",
            "\n",
            "         [[-0.0234,  0.0114, -0.0031],\n",
            "          [ 0.1271,  0.0990, -0.0219],\n",
            "          [ 0.0717, -0.1184, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[-0.0752,  0.0160,  0.1106],\n",
            "          [-0.1226,  0.0359, -0.0675],\n",
            "          [-0.0148,  0.1298,  0.0941]],\n",
            "\n",
            "         [[ 0.0124, -0.0077, -0.1213],\n",
            "          [ 0.0115, -0.0320,  0.1001],\n",
            "          [ 0.0701,  0.0954, -0.0785]],\n",
            "\n",
            "         [[-0.1014,  0.0947,  0.0171],\n",
            "          [ 0.1316, -0.0220, -0.0368],\n",
            "          [ 0.0536,  0.0620, -0.0759]]],\n",
            "\n",
            "\n",
            "        [[[-0.0462,  0.0865, -0.0109],\n",
            "          [-0.0799, -0.0852,  0.0181],\n",
            "          [-0.0158,  0.0746,  0.1030]],\n",
            "\n",
            "         [[-0.0636,  0.0897, -0.0426],\n",
            "          [ 0.0369, -0.0393, -0.0056],\n",
            "          [-0.0294,  0.1296, -0.1235]],\n",
            "\n",
            "         [[ 0.0002,  0.0252,  0.1291],\n",
            "          [-0.0383,  0.0881,  0.0236],\n",
            "          [-0.0026, -0.0574, -0.0595]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.0525,  0.0607,  0.0294],\n",
            "          [-0.0597,  0.0081,  0.0227],\n",
            "          [ 0.0107,  0.0121,  0.0542]],\n",
            "\n",
            "         [[ 0.0217,  0.0483, -0.0325],\n",
            "          [-0.0638,  0.0536, -0.0179],\n",
            "          [-0.0156,  0.0059, -0.0274]],\n",
            "\n",
            "         [[-0.0345, -0.0405,  0.0207],\n",
            "          [ 0.0206,  0.0331,  0.0328],\n",
            "          [-0.0681,  0.0688, -0.0348]]],\n",
            "\n",
            "\n",
            "        [[[-0.0122,  0.0537,  0.0306],\n",
            "          [-0.0207,  0.0613,  0.0492],\n",
            "          [ 0.0461,  0.0083,  0.0611]],\n",
            "\n",
            "         [[ 0.0256,  0.0656, -0.0086],\n",
            "          [-0.0457, -0.0004, -0.0110],\n",
            "          [-0.0258, -0.0224,  0.0538]],\n",
            "\n",
            "         [[-0.0592,  0.0313,  0.0619],\n",
            "          [ 0.0642, -0.0080, -0.0028],\n",
            "          [ 0.0033, -0.0198,  0.0273]]],\n",
            "\n",
            "\n",
            "        [[[-0.0012, -0.0623,  0.0113],\n",
            "          [ 0.0553,  0.0417, -0.0113],\n",
            "          [-0.0624, -0.0030, -0.0607]],\n",
            "\n",
            "         [[ 0.0433,  0.0679,  0.0281],\n",
            "          [-0.0235,  0.0242,  0.0536],\n",
            "          [-0.0661, -0.0560,  0.0620]],\n",
            "\n",
            "         [[ 0.0486,  0.0155, -0.0163],\n",
            "          [ 0.0214, -0.0089,  0.0680],\n",
            "          [-0.0101,  0.0311,  0.0425]]],\n",
            "\n",
            "\n",
            "        [[[-0.0151,  0.0296, -0.0439],\n",
            "          [ 0.0008, -0.0422,  0.0003],\n",
            "          [-0.0055, -0.0660,  0.0036]],\n",
            "\n",
            "         [[-0.0345, -0.0195, -0.0643],\n",
            "          [-0.0555, -0.0482,  0.0246],\n",
            "          [ 0.0040,  0.0449,  0.0282]],\n",
            "\n",
            "         [[ 0.0533, -0.0016,  0.0673],\n",
            "          [-0.0498, -0.0152,  0.0145],\n",
            "          [-0.0596, -0.0406,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[-0.0373,  0.0078,  0.0463],\n",
            "          [ 0.0638, -0.0324, -0.0606],\n",
            "          [-0.0219,  0.0352,  0.0047]],\n",
            "\n",
            "         [[ 0.0325, -0.0529, -0.0688],\n",
            "          [-0.0402,  0.0299, -0.0205],\n",
            "          [ 0.0630,  0.0352,  0.0610]],\n",
            "\n",
            "         [[ 0.0055,  0.0144,  0.0303],\n",
            "          [ 0.0289,  0.0117, -0.0425],\n",
            "          [ 0.0302, -0.0268,  0.0363]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0235, -0.0105,  0.0530],\n",
            "          [ 0.0637,  0.0517, -0.0476],\n",
            "          [ 0.0672, -0.0167,  0.0286]],\n",
            "\n",
            "         [[ 0.0053, -0.0509, -0.0316],\n",
            "          [-0.0532,  0.0412,  0.0294],\n",
            "          [ 0.0653, -0.0580, -0.0004]],\n",
            "\n",
            "         [[ 0.0516,  0.0685,  0.0665],\n",
            "          [-0.0291, -0.0503, -0.0258],\n",
            "          [ 0.0478, -0.0233,  0.0055]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0315, -0.0504, -0.0112],\n",
            "          [ 0.0299,  0.0373, -0.0404],\n",
            "          [ 0.0548, -0.0041,  0.0243]],\n",
            "\n",
            "         [[-0.0096,  0.0216, -0.0090],\n",
            "          [ 0.0278, -0.0221, -0.0671],\n",
            "          [ 0.0195, -0.0469, -0.0580]],\n",
            "\n",
            "         [[ 0.0318, -0.0224,  0.0388],\n",
            "          [-0.0236,  0.0609, -0.0108],\n",
            "          [ 0.0118,  0.0669, -0.0640]]],\n",
            "\n",
            "\n",
            "        [[[-0.0569,  0.0481,  0.0367],\n",
            "          [ 0.0613,  0.0346,  0.0343],\n",
            "          [ 0.0476, -0.0494, -0.0652]],\n",
            "\n",
            "         [[ 0.0207,  0.0606,  0.0519],\n",
            "          [ 0.0236,  0.0157,  0.0564],\n",
            "          [ 0.0624,  0.0296,  0.0564]],\n",
            "\n",
            "         [[-0.0012, -0.0093, -0.0161],\n",
            "          [ 0.0002, -0.0220,  0.0537],\n",
            "          [-0.0170, -0.0119,  0.0354]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0512, -0.0367,  0.0131],\n",
            "          [ 0.0317, -0.0627,  0.0403],\n",
            "          [-0.0472, -0.0113, -0.0529]],\n",
            "\n",
            "         [[-0.0177,  0.0365, -0.0350],\n",
            "          [-0.0432, -0.0615, -0.0637],\n",
            "          [-0.0517, -0.0045,  0.0250]],\n",
            "\n",
            "         [[-0.0471, -0.0645, -0.0130],\n",
            "          [-0.0056,  0.0150,  0.0688],\n",
            "          [ 0.0277, -0.0617, -0.0108]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0546, -0.0459,  0.0277],\n",
            "          [-0.0049,  0.0293, -0.0228],\n",
            "          [ 0.0478, -0.0396,  0.0477]],\n",
            "\n",
            "         [[ 0.0171, -0.0346, -0.0388],\n",
            "          [ 0.0339, -0.0666, -0.0412],\n",
            "          [ 0.0085,  0.0091,  0.0131]],\n",
            "\n",
            "         [[-0.0402, -0.0479,  0.0007],\n",
            "          [-0.0174,  0.0600, -0.0670],\n",
            "          [-0.0177, -0.0487,  0.0026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0096,  0.0239, -0.0042],\n",
            "          [ 0.0409,  0.0592, -0.0138],\n",
            "          [-0.0143,  0.0066, -0.0307]],\n",
            "\n",
            "         [[ 0.0165,  0.0299,  0.0555],\n",
            "          [ 0.0583, -0.0209,  0.0240],\n",
            "          [-0.0454,  0.0277,  0.0675]],\n",
            "\n",
            "         [[-0.0241,  0.0437, -0.0659],\n",
            "          [ 0.0378,  0.0107,  0.0569],\n",
            "          [ 0.0020,  0.0547,  0.0059]]],\n",
            "\n",
            "\n",
            "        [[[-0.0418, -0.0192,  0.0628],\n",
            "          [-0.0480,  0.0623,  0.0353],\n",
            "          [ 0.0161,  0.0194, -0.0297]],\n",
            "\n",
            "         [[-0.0554,  0.0095,  0.0540],\n",
            "          [ 0.0558,  0.0138, -0.0388],\n",
            "          [-0.0124,  0.0528, -0.0476]],\n",
            "\n",
            "         [[ 0.0603, -0.0686, -0.0365],\n",
            "          [ 0.0567,  0.0183, -0.0351],\n",
            "          [-0.0170, -0.0655, -0.0180]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0677,  0.0602, -0.0562],\n",
            "          [-0.0323, -0.0451,  0.0617],\n",
            "          [-0.0442,  0.0040,  0.0212]],\n",
            "\n",
            "         [[-0.0335,  0.0101, -0.0427],\n",
            "          [ 0.0252, -0.0066,  0.0633],\n",
            "          [-0.0486,  0.0249,  0.0575]],\n",
            "\n",
            "         [[-0.0604,  0.0624,  0.0214],\n",
            "          [-0.0255,  0.0408,  0.0266],\n",
            "          [-0.0260, -0.0288,  0.0544]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0563,  0.0128, -0.0648],\n",
            "          [ 0.0189,  0.0233, -0.0286],\n",
            "          [ 0.0116, -0.0205,  0.0559]],\n",
            "\n",
            "         [[ 0.0062, -0.0687,  0.0516],\n",
            "          [-0.0419, -0.0518,  0.0497],\n",
            "          [-0.0486,  0.0056,  0.0532]],\n",
            "\n",
            "         [[-0.0606,  0.0646, -0.0478],\n",
            "          [ 0.0282, -0.0544,  0.0263],\n",
            "          [ 0.0619,  0.0042,  0.0345]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0395,  0.0085,  0.0578],\n",
            "          [-0.0652, -0.0658,  0.0603],\n",
            "          [ 0.0677, -0.0678,  0.0101]],\n",
            "\n",
            "         [[ 0.0336,  0.0050,  0.0267],\n",
            "          [ 0.0263, -0.0152,  0.0110],\n",
            "          [-0.0292,  0.0044, -0.0112]],\n",
            "\n",
            "         [[-0.0029, -0.0104,  0.0420],\n",
            "          [ 0.0108, -0.0232, -0.0310],\n",
            "          [-0.0641,  0.0588, -0.0377]]],\n",
            "\n",
            "\n",
            "        [[[-0.0110,  0.0113,  0.0361],\n",
            "          [-0.0194, -0.0374,  0.0069],\n",
            "          [-0.0004,  0.0670,  0.0057]],\n",
            "\n",
            "         [[-0.0540,  0.0672,  0.0026],\n",
            "          [ 0.0555, -0.0653, -0.0544],\n",
            "          [-0.0154,  0.0012,  0.0285]],\n",
            "\n",
            "         [[-0.0280, -0.0592,  0.0460],\n",
            "          [ 0.0126, -0.0216,  0.0439],\n",
            "          [ 0.0035, -0.0541,  0.0044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0385,  0.0473, -0.0440],\n",
            "          [-0.0230,  0.0586,  0.0113],\n",
            "          [ 0.0204,  0.0490, -0.0327]],\n",
            "\n",
            "         [[-0.0359, -0.0362,  0.0206],\n",
            "          [-0.0281,  0.0341, -0.0213],\n",
            "          [ 0.0017, -0.0530,  0.0380]],\n",
            "\n",
            "         [[-0.0510, -0.0095, -0.0109],\n",
            "          [ 0.0275, -0.0425,  0.0610],\n",
            "          [ 0.0028,  0.0280,  0.0555]]],\n",
            "\n",
            "\n",
            "        [[[-0.0475, -0.0187, -0.0657],\n",
            "          [-0.0544,  0.0114,  0.0676],\n",
            "          [ 0.0211,  0.0689, -0.0674]],\n",
            "\n",
            "         [[-0.0107, -0.0413, -0.0555],\n",
            "          [-0.0123, -0.0245,  0.0324],\n",
            "          [-0.0200,  0.0646, -0.0084]],\n",
            "\n",
            "         [[ 0.0442, -0.0137, -0.0391],\n",
            "          [-0.0066, -0.0050,  0.0056],\n",
            "          [ 0.0219, -0.0666, -0.0625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0444, -0.0219,  0.0528],\n",
            "          [ 0.0201, -0.0654,  0.0685],\n",
            "          [ 0.0508,  0.0142, -0.0101]],\n",
            "\n",
            "         [[ 0.0622, -0.0688,  0.0141],\n",
            "          [ 0.0543,  0.0609,  0.0472],\n",
            "          [-0.0002,  0.0194, -0.0416]],\n",
            "\n",
            "         [[-0.0085, -0.0391, -0.0179],\n",
            "          [ 0.0038, -0.0651,  0.0104],\n",
            "          [-0.0437, -0.0480,  0.0351]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0051, -0.0534, -0.0513],\n",
            "          [ 0.0558,  0.0133, -0.0514],\n",
            "          [-0.0317, -0.0354, -0.0349]],\n",
            "\n",
            "         [[ 0.0015,  0.0369, -0.0427],\n",
            "          [-0.0325,  0.0600, -0.0065],\n",
            "          [-0.0309, -0.0340, -0.0178]],\n",
            "\n",
            "         [[-0.0398, -0.0575,  0.0136],\n",
            "          [ 0.0260,  0.0343,  0.0027],\n",
            "          [-0.0049, -0.0151,  0.0572]]],\n",
            "\n",
            "\n",
            "        [[[-0.0597,  0.0014,  0.0157],\n",
            "          [-0.0640,  0.0595, -0.0507],\n",
            "          [-0.0615,  0.0351,  0.0139]],\n",
            "\n",
            "         [[ 0.0452, -0.0666, -0.0404],\n",
            "          [ 0.0296, -0.0327,  0.0538],\n",
            "          [-0.0227, -0.0354,  0.0511]],\n",
            "\n",
            "         [[-0.0443, -0.0385, -0.0094],\n",
            "          [ 0.0431, -0.0187, -0.0154],\n",
            "          [-0.0529,  0.0086, -0.0100]]],\n",
            "\n",
            "\n",
            "        [[[-0.0404, -0.0605, -0.0156],\n",
            "          [-0.0605,  0.0539,  0.0668],\n",
            "          [ 0.0471, -0.0465,  0.0586]],\n",
            "\n",
            "         [[ 0.0146,  0.0332,  0.0644],\n",
            "          [ 0.0432, -0.0124, -0.0580],\n",
            "          [-0.0392,  0.0105,  0.0154]],\n",
            "\n",
            "         [[-0.0610,  0.0405, -0.0539],\n",
            "          [ 0.0587,  0.0145, -0.0014],\n",
            "          [-0.0244, -0.0113,  0.0408]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0525,  0.0374, -0.0563],\n",
            "          [ 0.0689, -0.0360,  0.0640],\n",
            "          [-0.0389,  0.0681,  0.0582]],\n",
            "\n",
            "         [[ 0.0399,  0.0111,  0.0567],\n",
            "          [-0.0441,  0.0206,  0.0272],\n",
            "          [-0.0055, -0.0402, -0.0056]],\n",
            "\n",
            "         [[-0.0305,  0.0071, -0.0267],\n",
            "          [-0.0619,  0.0071,  0.0430],\n",
            "          [-0.0151, -0.0158,  0.0482]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0496,  0.0595, -0.0027],\n",
            "          [ 0.0007, -0.0488,  0.0016],\n",
            "          [ 0.0022,  0.0513, -0.0685]],\n",
            "\n",
            "         [[-0.0077, -0.0664, -0.0660],\n",
            "          [ 0.0368,  0.0344,  0.0562],\n",
            "          [ 0.0209,  0.0033, -0.0376]],\n",
            "\n",
            "         [[-0.0584, -0.0413, -0.0318],\n",
            "          [-0.0401,  0.0271,  0.0661],\n",
            "          [ 0.0637, -0.0402, -0.0660]]],\n",
            "\n",
            "\n",
            "        [[[-0.0161, -0.0507, -0.0670],\n",
            "          [ 0.0275,  0.0614,  0.0093],\n",
            "          [ 0.0317,  0.0428, -0.0397]],\n",
            "\n",
            "         [[ 0.0081,  0.0288, -0.0362],\n",
            "          [ 0.0674,  0.0669,  0.0212],\n",
            "          [-0.0282, -0.0136, -0.0033]],\n",
            "\n",
            "         [[ 0.0529, -0.0331,  0.0422],\n",
            "          [ 0.0609, -0.0090, -0.0066],\n",
            "          [-0.0112,  0.0355,  0.0686]]],\n",
            "\n",
            "\n",
            "        [[[-0.0229, -0.0120, -0.0321],\n",
            "          [-0.0642,  0.0650, -0.0111],\n",
            "          [ 0.0257,  0.0179,  0.0342]],\n",
            "\n",
            "         [[ 0.0224,  0.0241,  0.0101],\n",
            "          [ 0.0515, -0.0208,  0.0146],\n",
            "          [ 0.0463, -0.0457,  0.0515]],\n",
            "\n",
            "         [[ 0.0293, -0.0227, -0.0195],\n",
            "          [ 0.0201, -0.0655,  0.0646],\n",
            "          [-0.0601, -0.0417,  0.0466]]],\n",
            "\n",
            "\n",
            "        [[[-0.0597, -0.0173, -0.0335],\n",
            "          [ 0.0321, -0.0019, -0.0251],\n",
            "          [-0.0180,  0.0245,  0.0315]],\n",
            "\n",
            "         [[-0.0475,  0.0533,  0.0499],\n",
            "          [ 0.0014, -0.0119,  0.0441],\n",
            "          [ 0.0570, -0.0643,  0.0494]],\n",
            "\n",
            "         [[-0.0343, -0.0188,  0.0456],\n",
            "          [ 0.0683, -0.0488, -0.0253],\n",
            "          [-0.0082,  0.0047,  0.0089]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0587,  0.0667, -0.0253],\n",
            "          [-0.0642, -0.0634,  0.0110],\n",
            "          [ 0.0388, -0.0121, -0.0386]],\n",
            "\n",
            "         [[-0.0425, -0.0188,  0.0207],\n",
            "          [ 0.0600,  0.0319, -0.0045],\n",
            "          [-0.0128,  0.0673,  0.0401]],\n",
            "\n",
            "         [[-0.0593,  0.0640,  0.0134],\n",
            "          [ 0.0401, -0.0182, -0.0524],\n",
            "          [-0.0286, -0.0354,  0.0189]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0398, -0.0300,  0.0219],\n",
            "          [ 0.0275, -0.0623, -0.0446],\n",
            "          [-0.0237, -0.0605,  0.0668]],\n",
            "\n",
            "         [[ 0.0346,  0.0451, -0.0420],\n",
            "          [ 0.0621,  0.0538,  0.0684],\n",
            "          [-0.0256, -0.0392, -0.0052]],\n",
            "\n",
            "         [[ 0.0213, -0.0069,  0.0621],\n",
            "          [-0.0425,  0.0133,  0.0371],\n",
            "          [-0.0666, -0.0168, -0.0077]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0486, -0.0359, -0.0210],\n",
            "          [-0.0531,  0.0592, -0.0514],\n",
            "          [-0.0049,  0.0406, -0.0267]],\n",
            "\n",
            "         [[ 0.0640,  0.0604,  0.0030],\n",
            "          [-0.0676, -0.0318,  0.0096],\n",
            "          [-0.0681, -0.0019,  0.0416]],\n",
            "\n",
            "         [[-0.0117,  0.0057, -0.0016],\n",
            "          [ 0.0635,  0.0495, -0.0109],\n",
            "          [ 0.0359, -0.0592, -0.0385]]],\n",
            "\n",
            "\n",
            "        [[[-0.0376,  0.0080,  0.0553],\n",
            "          [-0.0613,  0.0180, -0.0337],\n",
            "          [-0.0074,  0.0649,  0.0470]],\n",
            "\n",
            "         [[ 0.0062, -0.0038, -0.0606],\n",
            "          [ 0.0058, -0.0160,  0.0500],\n",
            "          [ 0.0350,  0.0477, -0.0393]],\n",
            "\n",
            "         [[-0.0507,  0.0473,  0.0085],\n",
            "          [ 0.0658, -0.0110, -0.0184],\n",
            "          [ 0.0268,  0.0310, -0.0379]]],\n",
            "\n",
            "\n",
            "        [[[-0.0231,  0.0433, -0.0055],\n",
            "          [-0.0400, -0.0426,  0.0090],\n",
            "          [-0.0079,  0.0373,  0.0515]],\n",
            "\n",
            "         [[-0.0318,  0.0449, -0.0213],\n",
            "          [ 0.0185, -0.0197, -0.0028],\n",
            "          [-0.0147,  0.0648, -0.0617]],\n",
            "\n",
            "         [[ 0.0001,  0.0126,  0.0646],\n",
            "          [-0.0192,  0.0440,  0.0118],\n",
            "          [-0.0013, -0.0287, -0.0298]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 6.3420e-02,  7.3276e-02,  3.5488e-02],\n",
            "          [-7.2040e-02,  9.8323e-03,  2.7458e-02],\n",
            "          [ 1.2968e-02,  1.4557e-02,  6.5395e-02]],\n",
            "\n",
            "         [[ 2.6170e-02,  5.8342e-02, -3.9271e-02],\n",
            "          [-7.7091e-02,  6.4732e-02, -2.1609e-02],\n",
            "          [-1.8860e-02,  7.0977e-03, -3.3068e-02]],\n",
            "\n",
            "         [[-4.1607e-02, -4.8902e-02,  2.5010e-02],\n",
            "          [ 2.4871e-02,  4.0022e-02,  3.9656e-02],\n",
            "          [-8.2284e-02,  8.3118e-02, -4.2069e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.8574e-02, -5.7834e-02,  8.3874e-04],\n",
            "          [-2.1052e-02,  7.2458e-02, -8.0893e-02],\n",
            "          [-2.1344e-02, -5.8761e-02,  3.1942e-03]],\n",
            "\n",
            "         [[ 1.1539e-02,  2.8821e-02, -5.0540e-03],\n",
            "          [ 4.9397e-02,  7.1442e-02, -1.6676e-02],\n",
            "          [-1.7296e-02,  7.9432e-03, -3.7044e-02]],\n",
            "\n",
            "         [[ 1.9931e-02,  3.6135e-02,  6.7053e-02],\n",
            "          [ 7.0346e-02, -2.5206e-02,  2.9000e-02],\n",
            "          [-5.4800e-02,  3.3441e-02,  8.1460e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9146e-02,  5.2727e-02, -7.9582e-02],\n",
            "          [ 4.5671e-02,  1.2910e-02,  6.8654e-02],\n",
            "          [ 2.3663e-03,  6.6062e-02,  7.1735e-03]],\n",
            "\n",
            "         [[-5.0448e-02, -2.3134e-02,  7.5889e-02],\n",
            "          [-5.8021e-02,  7.5218e-02,  4.2656e-02],\n",
            "          [ 1.9394e-02,  2.3413e-02, -3.5866e-02]],\n",
            "\n",
            "         [[-6.6916e-02,  1.1513e-02,  6.5213e-02],\n",
            "          [ 6.7408e-02,  1.6709e-02, -4.6795e-02],\n",
            "          [-1.5024e-02,  6.3795e-02, -5.7492e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4604e-02, -8.0372e-02, -4.8780e-02],\n",
            "          [ 3.5713e-02, -3.9517e-02,  6.4963e-02],\n",
            "          [-2.7380e-02, -4.2717e-02,  6.1674e-02]],\n",
            "\n",
            "         [[-5.3551e-02, -4.6499e-02, -1.1385e-02],\n",
            "          [ 5.2103e-02, -2.2561e-02, -1.8564e-02],\n",
            "          [-6.3842e-02,  1.0369e-02, -1.2117e-02]],\n",
            "\n",
            "         [[-4.8763e-02, -7.3097e-02, -1.8784e-02],\n",
            "          [-7.3069e-02,  6.5139e-02,  8.0630e-02],\n",
            "          [ 5.6838e-02, -5.6211e-02,  7.0789e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7635e-02,  4.0050e-02,  7.7815e-02],\n",
            "          [ 5.2183e-02, -1.4920e-02, -7.0026e-02],\n",
            "          [-4.7301e-02,  1.2658e-02,  1.8608e-02]],\n",
            "\n",
            "         [[-7.3607e-02,  4.8940e-02, -6.5101e-02],\n",
            "          [ 7.0861e-02,  1.7530e-02, -1.6527e-03],\n",
            "          [-2.9492e-02, -1.3609e-02,  4.9277e-02]],\n",
            "\n",
            "         [[ 6.3353e-02,  4.5206e-02, -6.7958e-02],\n",
            "          [ 8.3224e-02, -4.3525e-02,  7.7330e-02],\n",
            "          [-4.6917e-02,  8.2215e-02,  7.0256e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7900e-02,  5.2240e-02, -6.5858e-03],\n",
            "          [-4.8251e-02, -5.1474e-02,  1.0904e-02],\n",
            "          [-9.5620e-03,  4.5054e-02,  6.2167e-02]],\n",
            "\n",
            "         [[-3.8407e-02,  5.4180e-02, -2.5712e-02],\n",
            "          [ 2.2288e-02, -2.3744e-02, -3.3917e-03],\n",
            "          [-1.7741e-02,  7.8265e-02, -7.4556e-02]],\n",
            "\n",
            "         [[ 1.3336e-04,  1.5187e-02,  7.7969e-02],\n",
            "          [-2.3130e-02,  5.3177e-02,  1.4256e-02],\n",
            "          [-1.5449e-03, -3.4685e-02, -3.5939e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5518e-02, -7.8106e-03,  1.1188e-02],\n",
            "          [ 5.8566e-02, -7.5503e-02, -4.8799e-02],\n",
            "          [ 7.8534e-02, -7.6864e-03, -5.4235e-03]],\n",
            "\n",
            "         [[-4.8229e-02, -2.4747e-02,  1.4032e-02],\n",
            "          [-2.6408e-02, -3.0844e-02, -6.4617e-02],\n",
            "          [ 7.1523e-02,  7.5792e-03, -1.8219e-02]],\n",
            "\n",
            "         [[-1.2435e-02,  5.9314e-02,  6.8632e-02],\n",
            "          [ 6.1398e-02,  2.9868e-02, -8.2195e-02],\n",
            "          [-3.4634e-03,  2.8007e-02,  2.8763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0223e-02, -7.1725e-02, -5.0124e-02],\n",
            "          [ 9.6777e-03,  2.4223e-02, -7.1778e-02],\n",
            "          [ 3.2490e-02, -8.2311e-02, -3.7245e-02]],\n",
            "\n",
            "         [[-6.6682e-02, -3.9517e-02,  6.0189e-04],\n",
            "          [ 4.7752e-02,  4.7375e-02,  4.6630e-02],\n",
            "          [ 4.7163e-03,  8.7263e-03,  4.0087e-02]],\n",
            "\n",
            "         [[-8.1609e-02, -7.4239e-02, -6.0175e-02],\n",
            "          [ 7.7161e-02,  1.4216e-02,  2.8079e-02],\n",
            "          [-2.9038e-02, -7.9810e-02, -5.7194e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3276e-02,  6.2281e-02, -6.5992e-02],\n",
            "          [ 1.6867e-02,  4.9823e-02,  3.7555e-02],\n",
            "          [ 7.6220e-02,  6.5295e-02, -2.0038e-03]],\n",
            "\n",
            "         [[-4.5562e-02,  7.9474e-02,  1.4381e-02],\n",
            "          [-2.2909e-02, -8.0703e-02, -6.7262e-02],\n",
            "          [ 6.5767e-02, -7.8513e-02, -3.2978e-02]],\n",
            "\n",
            "         [[-8.0295e-02,  7.5996e-02, -8.0098e-02],\n",
            "          [ 3.8228e-02,  5.9146e-03,  3.0472e-02],\n",
            "          [ 7.3772e-02,  4.7300e-02, -5.7094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4906e-02,  1.9164e-02, -2.9368e-02],\n",
            "          [-2.2259e-02,  4.3675e-02, -8.1335e-02],\n",
            "          [-2.6379e-02,  8.2509e-02, -5.6902e-02]],\n",
            "\n",
            "         [[ 4.8517e-02, -5.3306e-02, -4.5405e-02],\n",
            "          [-7.2836e-02,  6.9791e-04, -2.0265e-02],\n",
            "          [ 3.9212e-02,  3.0947e-02,  8.1954e-02]],\n",
            "\n",
            "         [[-1.0525e-02,  3.9170e-02,  8.1547e-02],\n",
            "          [ 1.0298e-02,  2.4142e-02,  8.1552e-02],\n",
            "          [-4.1315e-02, -6.6417e-02, -4.2100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7834e-02, -3.7336e-02, -5.6150e-02],\n",
            "          [ 1.4851e-03,  2.7738e-02, -5.7369e-02],\n",
            "          [-7.0169e-02, -4.1213e-05, -4.9262e-02]],\n",
            "\n",
            "         [[-1.4965e-02,  4.0813e-02,  6.4681e-02],\n",
            "          [-4.0381e-02, -5.2670e-03,  3.8095e-02],\n",
            "          [ 5.0829e-02,  7.8358e-02, -5.9338e-03]],\n",
            "\n",
            "         [[ 5.0548e-02,  6.9506e-02,  3.5774e-03],\n",
            "          [-2.0453e-02, -2.2837e-02,  2.7631e-02],\n",
            "          [ 2.2321e-03,  4.0112e-03,  5.9683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7560e-02,  2.7013e-02,  3.8514e-02],\n",
            "          [-6.2757e-02,  7.1732e-02,  3.4445e-02],\n",
            "          [-5.7345e-03, -4.4443e-02, -7.9402e-02]],\n",
            "\n",
            "         [[-8.3232e-02,  3.6605e-02,  3.9557e-02],\n",
            "          [-3.0950e-02, -1.1902e-02,  2.3066e-02],\n",
            "          [ 8.3602e-03,  1.4968e-02, -6.2327e-02]],\n",
            "\n",
            "         [[ 3.4100e-02,  4.9295e-02,  2.1340e-02],\n",
            "          [-2.3296e-02,  3.6142e-02,  3.7400e-03],\n",
            "          [-1.0772e-02, -7.1674e-02, -2.9318e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.1710e-02,  3.6638e-02,  1.7744e-02],\n",
            "          [-3.6020e-02,  4.9161e-03,  1.3729e-02],\n",
            "          [ 6.4840e-03,  7.2786e-03,  3.2698e-02]],\n",
            "\n",
            "         [[ 1.3085e-02,  2.9171e-02, -1.9635e-02],\n",
            "          [-3.8546e-02,  3.2366e-02, -1.0805e-02],\n",
            "          [-9.4300e-03,  3.5489e-03, -1.6534e-02]],\n",
            "\n",
            "         [[-2.0803e-02, -2.4451e-02,  1.2505e-02],\n",
            "          [ 1.2436e-02,  2.0011e-02,  1.9828e-02],\n",
            "          [-4.1142e-02,  4.1559e-02, -2.1035e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4287e-02, -2.8917e-02,  4.1937e-04],\n",
            "          [-1.0526e-02,  3.6229e-02, -4.0446e-02],\n",
            "          [-1.0672e-02, -2.9381e-02,  1.5971e-03]],\n",
            "\n",
            "         [[ 5.7697e-03,  1.4410e-02, -2.5270e-03],\n",
            "          [ 2.4699e-02,  3.5721e-02, -8.3378e-03],\n",
            "          [-8.6479e-03,  3.9716e-03, -1.8522e-02]],\n",
            "\n",
            "         [[ 9.9656e-03,  1.8068e-02,  3.3527e-02],\n",
            "          [ 3.5173e-02, -1.2603e-02,  1.4500e-02],\n",
            "          [-2.7400e-02,  1.6720e-02,  4.0730e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4573e-02,  2.6364e-02, -3.9791e-02],\n",
            "          [ 2.2836e-02,  6.4549e-03,  3.4327e-02],\n",
            "          [ 1.1832e-03,  3.3031e-02,  3.5868e-03]],\n",
            "\n",
            "         [[-2.5224e-02, -1.1567e-02,  3.7945e-02],\n",
            "          [-2.9010e-02,  3.7609e-02,  2.1328e-02],\n",
            "          [ 9.6970e-03,  1.1707e-02, -1.7933e-02]],\n",
            "\n",
            "         [[-3.3458e-02,  5.7565e-03,  3.2606e-02],\n",
            "          [ 3.3704e-02,  8.3544e-03, -2.3398e-02],\n",
            "          [-7.5121e-03,  3.1898e-02, -2.8746e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7302e-02, -4.0186e-02, -2.4390e-02],\n",
            "          [ 1.7857e-02, -1.9759e-02,  3.2482e-02],\n",
            "          [-1.3690e-02, -2.1359e-02,  3.0837e-02]],\n",
            "\n",
            "         [[-2.6776e-02, -2.3250e-02, -5.6927e-03],\n",
            "          [ 2.6051e-02, -1.1280e-02, -9.2821e-03],\n",
            "          [-3.1921e-02,  5.1847e-03, -6.0585e-03]],\n",
            "\n",
            "         [[-2.4381e-02, -3.6548e-02, -9.3918e-03],\n",
            "          [-3.6534e-02,  3.2569e-02,  4.0315e-02],\n",
            "          [ 2.8419e-02, -2.8105e-02,  3.5394e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.8174e-03,  2.0025e-02,  3.8908e-02],\n",
            "          [ 2.6091e-02, -7.4599e-03, -3.5013e-02],\n",
            "          [-2.3650e-02,  6.3288e-03,  9.3041e-03]],\n",
            "\n",
            "         [[-3.6804e-02,  2.4470e-02, -3.2551e-02],\n",
            "          [ 3.5430e-02,  8.7649e-03, -8.2635e-04],\n",
            "          [-1.4746e-02, -6.8046e-03,  2.4638e-02]],\n",
            "\n",
            "         [[ 3.1676e-02,  2.2603e-02, -3.3979e-02],\n",
            "          [ 4.1612e-02, -2.1762e-02,  3.8665e-02],\n",
            "          [-2.3459e-02,  4.1107e-02,  3.5128e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3950e-02,  2.6120e-02, -3.2929e-03],\n",
            "          [-2.4125e-02, -2.5737e-02,  5.4522e-03],\n",
            "          [-4.7810e-03,  2.2527e-02,  3.1083e-02]],\n",
            "\n",
            "         [[-1.9203e-02,  2.7090e-02, -1.2856e-02],\n",
            "          [ 1.1144e-02, -1.1872e-02, -1.6958e-03],\n",
            "          [-8.8707e-03,  3.9133e-02, -3.7278e-02]],\n",
            "\n",
            "         [[ 6.6678e-05,  7.5935e-03,  3.8985e-02],\n",
            "          [-1.1565e-02,  2.6588e-02,  7.1282e-03],\n",
            "          [-7.7244e-04, -1.7343e-02, -1.7969e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.2759e-02, -3.9053e-03,  5.5939e-03],\n",
            "          [ 2.9283e-02, -3.7751e-02, -2.4399e-02],\n",
            "          [ 3.9267e-02, -3.8432e-03, -2.7117e-03]],\n",
            "\n",
            "         [[-2.4115e-02, -1.2373e-02,  7.0158e-03],\n",
            "          [-1.3204e-02, -1.5422e-02, -3.2308e-02],\n",
            "          [ 3.5761e-02,  3.7896e-03, -9.1093e-03]],\n",
            "\n",
            "         [[-6.2177e-03,  2.9657e-02,  3.4316e-02],\n",
            "          [ 3.0699e-02,  1.4934e-02, -4.1098e-02],\n",
            "          [-1.7317e-03,  1.4004e-02,  1.4382e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0111e-02, -3.5862e-02, -2.5062e-02],\n",
            "          [ 4.8388e-03,  1.2111e-02, -3.5889e-02],\n",
            "          [ 1.6245e-02, -4.1156e-02, -1.8622e-02]],\n",
            "\n",
            "         [[-3.3341e-02, -1.9758e-02,  3.0094e-04],\n",
            "          [ 2.3876e-02,  2.3688e-02,  2.3315e-02],\n",
            "          [ 2.3582e-03,  4.3631e-03,  2.0044e-02]],\n",
            "\n",
            "         [[-4.0805e-02, -3.7120e-02, -3.0088e-02],\n",
            "          [ 3.8580e-02,  7.1080e-03,  1.4040e-02],\n",
            "          [-1.4519e-02, -3.9905e-02, -2.8597e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1638e-02,  3.1141e-02, -3.2996e-02],\n",
            "          [ 8.4333e-03,  2.4912e-02,  1.8777e-02],\n",
            "          [ 3.8110e-02,  3.2648e-02, -1.0019e-03]],\n",
            "\n",
            "         [[-2.2781e-02,  3.9737e-02,  7.1907e-03],\n",
            "          [-1.1454e-02, -4.0352e-02, -3.3631e-02],\n",
            "          [ 3.2883e-02, -3.9256e-02, -1.6489e-02]],\n",
            "\n",
            "         [[-4.0147e-02,  3.7998e-02, -4.0049e-02],\n",
            "          [ 1.9114e-02,  2.9573e-03,  1.5236e-02],\n",
            "          [ 3.6886e-02,  2.3650e-02, -2.8547e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2453e-02,  9.5822e-03, -1.4684e-02],\n",
            "          [-1.1130e-02,  2.1838e-02, -4.0668e-02],\n",
            "          [-1.3189e-02,  4.1254e-02, -2.8451e-02]],\n",
            "\n",
            "         [[ 2.4258e-02, -2.6653e-02, -2.2703e-02],\n",
            "          [-3.6418e-02,  3.4895e-04, -1.0133e-02],\n",
            "          [ 1.9606e-02,  1.5474e-02,  4.0977e-02]],\n",
            "\n",
            "         [[-5.2624e-03,  1.9585e-02,  4.0773e-02],\n",
            "          [ 5.1489e-03,  1.2071e-02,  4.0776e-02],\n",
            "          [-2.0658e-02, -3.3209e-02, -2.1050e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.8917e-02, -1.8668e-02, -2.8075e-02],\n",
            "          [ 7.4255e-04,  1.3869e-02, -2.8684e-02],\n",
            "          [-3.5085e-02, -2.0607e-05, -2.4631e-02]],\n",
            "\n",
            "         [[-7.4824e-03,  2.0406e-02,  3.2341e-02],\n",
            "          [-2.0191e-02, -2.6335e-03,  1.9047e-02],\n",
            "          [ 2.5414e-02,  3.9179e-02, -2.9669e-03]],\n",
            "\n",
            "         [[ 2.5274e-02,  3.4753e-02,  1.7887e-03],\n",
            "          [-1.0227e-02, -1.1419e-02,  1.3815e-02],\n",
            "          [ 1.1161e-03,  2.0056e-03,  2.9841e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8780e-02,  1.3506e-02,  1.9257e-02],\n",
            "          [-3.1378e-02,  3.5866e-02,  1.7222e-02],\n",
            "          [-2.8672e-03, -2.2222e-02, -3.9701e-02]],\n",
            "\n",
            "         [[-4.1616e-02,  1.8303e-02,  1.9778e-02],\n",
            "          [-1.5475e-02, -5.9509e-03,  1.1533e-02],\n",
            "          [ 4.1801e-03,  7.4842e-03, -3.1163e-02]],\n",
            "\n",
            "         [[ 1.7050e-02,  2.4647e-02,  1.0670e-02],\n",
            "          [-1.1648e-02,  1.8071e-02,  1.8700e-03],\n",
            "          [-5.3860e-03, -3.5837e-02, -1.4659e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 4.4845e-02,  5.1814e-02,  2.5094e-02],\n",
            "          [-5.0940e-02,  6.9525e-03,  1.9416e-02],\n",
            "          [ 9.1698e-03,  1.0294e-02,  4.6242e-02]],\n",
            "\n",
            "         [[ 1.8505e-02,  4.1254e-02, -2.7769e-02],\n",
            "          [-5.4512e-02,  4.5773e-02, -1.5280e-02],\n",
            "          [-1.3336e-02,  5.0188e-03, -2.3383e-02]],\n",
            "\n",
            "         [[-2.9420e-02, -3.4579e-02,  1.7685e-02],\n",
            "          [ 1.7587e-02,  2.8300e-02,  2.8041e-02],\n",
            "          [-5.8184e-02,  5.8773e-02, -2.9748e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8611e-02, -5.6831e-02, -3.4493e-02],\n",
            "          [ 2.5253e-02, -2.7943e-02,  4.5936e-02],\n",
            "          [-1.9361e-02, -3.0206e-02,  4.3610e-02]],\n",
            "\n",
            "         [[-3.7867e-02, -3.2880e-02, -8.0507e-03],\n",
            "          [ 3.6842e-02, -1.5953e-02, -1.3127e-02],\n",
            "          [-4.5143e-02,  7.3322e-03, -8.5680e-03]],\n",
            "\n",
            "         [[-3.4480e-02, -5.1687e-02, -1.3282e-02],\n",
            "          [-5.1667e-02,  4.6060e-02,  5.7014e-02],\n",
            "          [ 4.0191e-02, -3.9747e-02,  5.0055e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2470e-02,  2.8320e-02,  5.5024e-02],\n",
            "          [ 3.6899e-02, -1.0550e-02, -4.9516e-02],\n",
            "          [-3.3447e-02,  8.9503e-03,  1.3158e-02]],\n",
            "\n",
            "         [[-5.2048e-02,  3.4606e-02, -4.6034e-02],\n",
            "          [ 5.0106e-02,  1.2395e-02, -1.1686e-03],\n",
            "          [-2.0854e-02, -9.6232e-03,  3.4844e-02]],\n",
            "\n",
            "         [[ 4.4797e-02,  3.1965e-02, -4.8054e-02],\n",
            "          [ 5.8849e-02, -3.0777e-02,  5.4680e-02],\n",
            "          [-3.3176e-02,  5.8135e-02,  4.9679e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8018e-02, -2.8994e-02, -1.9422e-02],\n",
            "          [-4.2067e-02,  4.9561e-02,  2.3140e-02],\n",
            "          [-3.1462e-02, -5.2222e-02, -2.3686e-02]],\n",
            "\n",
            "         [[ 2.6994e-02,  9.5118e-03,  4.8858e-02],\n",
            "          [-5.1181e-02, -2.8469e-02, -5.3310e-02],\n",
            "          [ 8.7096e-03, -4.6548e-02, -4.4055e-02]],\n",
            "\n",
            "         [[-2.0991e-02,  1.5334e-02, -2.1385e-05],\n",
            "          [-4.1707e-02, -2.3136e-02,  5.4723e-02],\n",
            "          [ 4.3699e-02, -2.4382e-02,  4.2242e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6010e-02,  4.3814e-02, -1.2413e-02],\n",
            "          [ 1.4332e-02,  2.2193e-02,  4.1069e-02],\n",
            "          [ 5.7213e-02,  5.2797e-02,  4.5663e-03]],\n",
            "\n",
            "         [[ 3.8029e-02,  1.2206e-02,  4.8959e-03],\n",
            "          [-2.0712e-02, -9.2328e-03, -5.3781e-02],\n",
            "          [ 5.6189e-02, -4.4071e-02,  3.2018e-02]],\n",
            "\n",
            "         [[-3.9593e-02,  2.4511e-02, -3.7413e-02],\n",
            "          [-2.7640e-02, -1.7677e-02, -4.9695e-02],\n",
            "          [ 3.8388e-02,  2.2945e-02,  3.6923e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1702e-02, -5.3557e-02,  6.4093e-03],\n",
            "          [ 1.3410e-03,  6.7015e-04, -3.5026e-02],\n",
            "          [-2.9028e-02, -5.0844e-02,  3.7384e-02]],\n",
            "\n",
            "         [[-3.0373e-02,  1.5145e-02, -4.7163e-02],\n",
            "          [ 4.8873e-02, -5.2805e-02,  5.1437e-02],\n",
            "          [ 3.3870e-02, -4.1796e-02, -3.0026e-02]],\n",
            "\n",
            "         [[ 5.5603e-02, -5.5660e-02, -3.8751e-02],\n",
            "          [-3.9777e-02, -3.9544e-03,  4.7205e-02],\n",
            "          [-4.0660e-02, -5.1045e-02,  1.9755e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.4225e-03,  5.8966e-03, -5.2181e-02],\n",
            "          [ 1.2877e-02,  2.1004e-02,  1.3849e-02],\n",
            "          [-4.5653e-02,  4.2465e-02,  4.4422e-02]],\n",
            "\n",
            "         [[ 4.0491e-02, -2.8070e-02, -1.0315e-02],\n",
            "          [-3.4855e-02,  1.6074e-03,  4.2435e-02],\n",
            "          [-2.5890e-02, -5.4121e-02,  4.9705e-02]],\n",
            "\n",
            "         [[ 2.6590e-02, -3.9334e-02,  1.9364e-02],\n",
            "          [ 1.3269e-02, -3.1462e-02, -1.2197e-02],\n",
            "          [-1.9240e-02, -2.5462e-02, -3.7559e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8641e-02,  5.1524e-03,  4.0639e-02],\n",
            "          [ 1.4711e-02, -5.1846e-02, -1.3381e-02],\n",
            "          [-1.2564e-02,  4.3656e-02,  2.9459e-02]],\n",
            "\n",
            "         [[ 2.5456e-02, -2.1583e-02, -1.7562e-03],\n",
            "          [-2.9417e-03,  1.4950e-02, -4.5875e-02],\n",
            "          [-1.3552e-02, -3.3755e-02, -1.1766e-02]],\n",
            "\n",
            "         [[-5.7903e-02, -9.0666e-03, -3.3530e-02],\n",
            "          [ 1.6275e-02,  2.2725e-02,  4.1409e-02],\n",
            "          [ 3.3421e-02, -4.1847e-02, -3.3518e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8453e-02,  3.0810e-02, -4.1492e-02],\n",
            "          [-4.9423e-04, -1.5643e-02, -9.2124e-05],\n",
            "          [ 3.8616e-02,  5.6951e-02, -8.8304e-03]],\n",
            "\n",
            "         [[-3.4053e-02,  5.7430e-02, -5.2374e-02],\n",
            "          [ 7.4370e-03,  4.7341e-02, -1.1173e-02],\n",
            "          [-2.9683e-02,  4.2699e-02,  1.0138e-02]],\n",
            "\n",
            "         [[ 1.4564e-02,  4.0759e-02,  3.0126e-02],\n",
            "          [-4.3103e-02,  3.3635e-02, -3.7708e-03],\n",
            "          [-4.5272e-02,  4.4780e-02,  3.5606e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9362e-03, -4.5270e-02,  3.2289e-02],\n",
            "          [-1.6807e-02, -4.4908e-03, -3.3104e-02],\n",
            "          [-3.9801e-02, -1.2665e-02, -8.7887e-03]],\n",
            "\n",
            "         [[ 5.3640e-02,  4.6053e-02,  2.0436e-03],\n",
            "          [-1.4994e-03, -4.7443e-02,  3.9075e-02],\n",
            "          [-1.6432e-02, -5.1907e-02, -2.9914e-02]],\n",
            "\n",
            "         [[ 2.9734e-03,  1.2944e-02,  3.5550e-03],\n",
            "          [ 4.5563e-02, -4.2431e-03, -5.0833e-02],\n",
            "          [ 6.6308e-03,  4.3820e-02, -4.6857e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7160e-02, -4.5592e-02,  2.1544e-02],\n",
            "          [ 1.9051e-02,  2.2201e-02, -5.4873e-02],\n",
            "          [ 4.6079e-02,  4.9803e-02, -5.8571e-02]],\n",
            "\n",
            "         [[ 5.2928e-02, -5.1257e-03,  5.3019e-02],\n",
            "          [-2.8608e-02,  5.2892e-02, -1.0667e-02],\n",
            "          [-2.4313e-02, -7.1462e-03,  2.9066e-02]],\n",
            "\n",
            "         [[ 4.2359e-02,  2.2497e-02, -5.1829e-02],\n",
            "          [-5.7952e-02,  2.0746e-02, -5.8498e-02],\n",
            "          [-1.8216e-02, -3.7258e-03, -5.3728e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8317e-03, -4.4953e-02,  5.4703e-02],\n",
            "          [-4.5709e-02,  4.0591e-02, -1.4609e-02],\n",
            "          [-3.5994e-02, -2.0875e-02,  4.4330e-02]],\n",
            "\n",
            "         [[ 2.5360e-02, -5.0337e-02, -1.6996e-02],\n",
            "          [ 4.8848e-02,  1.2624e-02, -3.9590e-02],\n",
            "          [-4.1340e-02,  3.8589e-02,  4.0635e-02]],\n",
            "\n",
            "         [[-2.7707e-02, -4.9222e-02,  6.5755e-03],\n",
            "          [ 2.0375e-02, -3.3991e-02,  1.6203e-02],\n",
            "          [ 1.3942e-02,  5.4028e-02, -5.4231e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 2.2422e-02,  2.5907e-02,  1.2547e-02],\n",
            "          [-2.5470e-02,  3.4762e-03,  9.7079e-03],\n",
            "          [ 4.5849e-03,  5.1468e-03,  2.3121e-02]],\n",
            "\n",
            "         [[ 9.2524e-03,  2.0627e-02, -1.3884e-02],\n",
            "          [-2.7256e-02,  2.2886e-02, -7.6401e-03],\n",
            "          [-6.6680e-03,  2.5094e-03, -1.1691e-02]],\n",
            "\n",
            "         [[-1.4710e-02, -1.7290e-02,  8.8423e-03],\n",
            "          [ 8.7933e-03,  1.4150e-02,  1.4020e-02],\n",
            "          [-2.9092e-02,  2.9387e-02, -1.4874e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9305e-02, -2.8416e-02, -1.7246e-02],\n",
            "          [ 1.2627e-02, -1.3971e-02,  2.2968e-02],\n",
            "          [-9.6803e-03, -1.5103e-02,  2.1805e-02]],\n",
            "\n",
            "         [[-1.8933e-02, -1.6440e-02, -4.0254e-03],\n",
            "          [ 1.8421e-02, -7.9764e-03, -6.5634e-03],\n",
            "          [-2.2572e-02,  3.6661e-03, -4.2840e-03]],\n",
            "\n",
            "         [[-1.7240e-02, -2.5844e-02, -6.6410e-03],\n",
            "          [-2.5834e-02,  2.3030e-02,  2.8507e-02],\n",
            "          [ 2.0095e-02, -1.9873e-02,  2.5028e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.2349e-03,  1.4160e-02,  2.7512e-02],\n",
            "          [ 1.8449e-02, -5.2749e-03, -2.4758e-02],\n",
            "          [-1.6723e-02,  4.4752e-03,  6.5790e-03]],\n",
            "\n",
            "         [[-2.6024e-02,  1.7303e-02, -2.3017e-02],\n",
            "          [ 2.5053e-02,  6.1977e-03, -5.8432e-04],\n",
            "          [-1.0427e-02, -4.8116e-03,  1.7422e-02]],\n",
            "\n",
            "         [[ 2.2399e-02,  1.5983e-02, -2.4027e-02],\n",
            "          [ 2.9424e-02, -1.5388e-02,  2.7340e-02],\n",
            "          [-1.6588e-02,  2.9067e-02,  2.4839e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9009e-02, -1.4497e-02, -9.7111e-03],\n",
            "          [-2.1034e-02,  2.4781e-02,  1.1570e-02],\n",
            "          [-1.5731e-02, -2.6111e-02, -1.1843e-02]],\n",
            "\n",
            "         [[ 1.3497e-02,  4.7559e-03,  2.4429e-02],\n",
            "          [-2.5590e-02, -1.4234e-02, -2.6655e-02],\n",
            "          [ 4.3548e-03, -2.3274e-02, -2.2027e-02]],\n",
            "\n",
            "         [[-1.0496e-02,  7.6671e-03, -1.0693e-05],\n",
            "          [-2.0853e-02, -1.1568e-02,  2.7362e-02],\n",
            "          [ 2.1849e-02, -1.2191e-02,  2.1121e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.3005e-02,  2.1907e-02, -6.2067e-03],\n",
            "          [ 7.1661e-03,  1.1097e-02,  2.0534e-02],\n",
            "          [ 2.8607e-02,  2.6399e-02,  2.2831e-03]],\n",
            "\n",
            "         [[ 1.9014e-02,  6.1028e-03,  2.4479e-03],\n",
            "          [-1.0356e-02, -4.6164e-03, -2.6890e-02],\n",
            "          [ 2.8095e-02, -2.2036e-02,  1.6009e-02]],\n",
            "\n",
            "         [[-1.9797e-02,  1.2256e-02, -1.8706e-02],\n",
            "          [-1.3820e-02, -8.8387e-03, -2.4848e-02],\n",
            "          [ 1.9194e-02,  1.1472e-02,  1.8461e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5851e-02, -2.6779e-02,  3.2047e-03],\n",
            "          [ 6.7052e-04,  3.3507e-04, -1.7513e-02],\n",
            "          [-1.4514e-02, -2.5422e-02,  1.8692e-02]],\n",
            "\n",
            "         [[-1.5186e-02,  7.5726e-03, -2.3581e-02],\n",
            "          [ 2.4436e-02, -2.6403e-02,  2.5719e-02],\n",
            "          [ 1.6935e-02, -2.0898e-02, -1.5013e-02]],\n",
            "\n",
            "         [[ 2.7802e-02, -2.7830e-02, -1.9375e-02],\n",
            "          [-1.9889e-02, -1.9772e-03,  2.3602e-02],\n",
            "          [-2.0330e-02, -2.5522e-02,  9.8773e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.2112e-03,  2.9483e-03, -2.6090e-02],\n",
            "          [ 6.4383e-03,  1.0502e-02,  6.9247e-03],\n",
            "          [-2.2827e-02,  2.1233e-02,  2.2211e-02]],\n",
            "\n",
            "         [[ 2.0246e-02, -1.4035e-02, -5.1574e-03],\n",
            "          [-1.7428e-02,  8.0372e-04,  2.1218e-02],\n",
            "          [-1.2945e-02, -2.7060e-02,  2.4852e-02]],\n",
            "\n",
            "         [[ 1.3295e-02, -1.9667e-02,  9.6822e-03],\n",
            "          [ 6.6344e-03, -1.5731e-02, -6.0987e-03],\n",
            "          [-9.6199e-03, -1.2731e-02, -1.8779e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9321e-02,  2.5762e-03,  2.0320e-02],\n",
            "          [ 7.3555e-03, -2.5923e-02, -6.6904e-03],\n",
            "          [-6.2819e-03,  2.1828e-02,  1.4729e-02]],\n",
            "\n",
            "         [[ 1.2728e-02, -1.0792e-02, -8.7812e-04],\n",
            "          [-1.4708e-03,  7.4752e-03, -2.2938e-02],\n",
            "          [-6.7758e-03, -1.6877e-02, -5.8832e-03]],\n",
            "\n",
            "         [[-2.8951e-02, -4.5333e-03, -1.6765e-02],\n",
            "          [ 8.1373e-03,  1.1363e-02,  2.0705e-02],\n",
            "          [ 1.6711e-02, -2.0924e-02, -1.6759e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9227e-02,  1.5405e-02, -2.0746e-02],\n",
            "          [-2.4711e-04, -7.8213e-03, -4.6062e-05],\n",
            "          [ 1.9308e-02,  2.8476e-02, -4.4152e-03]],\n",
            "\n",
            "         [[-1.7026e-02,  2.8715e-02, -2.6187e-02],\n",
            "          [ 3.7185e-03,  2.3671e-02, -5.5866e-03],\n",
            "          [-1.4842e-02,  2.1350e-02,  5.0688e-03]],\n",
            "\n",
            "         [[ 7.2821e-03,  2.0379e-02,  1.5063e-02],\n",
            "          [-2.1552e-02,  1.6818e-02, -1.8854e-03],\n",
            "          [-2.2636e-02,  2.2390e-02,  1.7803e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.9681e-03, -2.2635e-02,  1.6144e-02],\n",
            "          [-8.4033e-03, -2.2454e-03, -1.6552e-02],\n",
            "          [-1.9900e-02, -6.3325e-03, -4.3944e-03]],\n",
            "\n",
            "         [[ 2.6820e-02,  2.3026e-02,  1.0218e-03],\n",
            "          [-7.4970e-04, -2.3721e-02,  1.9538e-02],\n",
            "          [-8.2158e-03, -2.5953e-02, -1.4957e-02]],\n",
            "\n",
            "         [[ 1.4867e-03,  6.4721e-03,  1.7775e-03],\n",
            "          [ 2.2781e-02, -2.1216e-03, -2.5416e-02],\n",
            "          [ 3.3154e-03,  2.1910e-02, -2.3428e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5801e-03, -2.2796e-02,  1.0772e-02],\n",
            "          [ 9.5253e-03,  1.1100e-02, -2.7436e-02],\n",
            "          [ 2.3039e-02,  2.4901e-02, -2.9285e-02]],\n",
            "\n",
            "         [[ 2.6464e-02, -2.5628e-03,  2.6510e-02],\n",
            "          [-1.4304e-02,  2.6446e-02, -5.3335e-03],\n",
            "          [-1.2157e-02, -3.5731e-03,  1.4533e-02]],\n",
            "\n",
            "         [[ 2.1180e-02,  1.1249e-02, -2.5914e-02],\n",
            "          [-2.8976e-02,  1.0373e-02, -2.9249e-02],\n",
            "          [-9.1081e-03, -1.8629e-03, -2.6864e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.1585e-04, -2.2477e-02,  2.7352e-02],\n",
            "          [-2.2855e-02,  2.0296e-02, -7.3043e-03],\n",
            "          [-1.7997e-02, -1.0437e-02,  2.2165e-02]],\n",
            "\n",
            "         [[ 1.2680e-02, -2.5169e-02, -8.4982e-03],\n",
            "          [ 2.4424e-02,  6.3120e-03, -1.9795e-02],\n",
            "          [-2.0670e-02,  1.9294e-02,  2.0317e-02]],\n",
            "\n",
            "         [[-1.3853e-02, -2.4611e-02,  3.2878e-03],\n",
            "          [ 1.0187e-02, -1.6995e-02,  8.1016e-03],\n",
            "          [ 6.9710e-03,  2.7014e-02, -2.7116e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 1.9418e-02,  2.2436e-02,  1.0866e-02],\n",
            "          [-2.2058e-02,  3.0105e-03,  8.4073e-03],\n",
            "          [ 3.9706e-03,  4.4572e-03,  2.0023e-02]],\n",
            "\n",
            "         [[ 8.0129e-03,  1.7864e-02, -1.2024e-02],\n",
            "          [-2.3604e-02,  1.9820e-02, -6.6165e-03],\n",
            "          [-5.7747e-03,  2.1732e-03, -1.0125e-02]],\n",
            "\n",
            "         [[-1.2739e-02, -1.4973e-02,  7.6577e-03],\n",
            "          [ 7.6152e-03,  1.2254e-02,  1.2142e-02],\n",
            "          [-2.5194e-02,  2.5449e-02, -1.2881e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5123e-02, -1.2555e-02, -8.4101e-03],\n",
            "          [-1.8216e-02,  2.1461e-02,  1.0020e-02],\n",
            "          [-1.3623e-02, -2.2613e-02, -1.0256e-02]],\n",
            "\n",
            "         [[ 1.1689e-02,  4.1187e-03,  2.1156e-02],\n",
            "          [-2.2162e-02, -1.2327e-02, -2.3084e-02],\n",
            "          [ 3.7713e-03, -2.0156e-02, -1.9076e-02]],\n",
            "\n",
            "         [[-9.0895e-03,  6.6399e-03, -9.2600e-06],\n",
            "          [-1.8059e-02, -1.0018e-02,  2.3696e-02],\n",
            "          [ 1.8922e-02, -1.0558e-02,  1.8291e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9923e-02,  1.8972e-02, -5.3751e-03],\n",
            "          [ 6.2060e-03,  9.6099e-03,  1.7783e-02],\n",
            "          [ 2.4774e-02,  2.2862e-02,  1.9772e-03]],\n",
            "\n",
            "         [[ 1.6467e-02,  5.2852e-03,  2.1200e-03],\n",
            "          [-8.9686e-03, -3.9979e-03, -2.3288e-02],\n",
            "          [ 2.4331e-02, -1.9083e-02,  1.3864e-02]],\n",
            "\n",
            "         [[-1.7144e-02,  1.0614e-02, -1.6200e-02],\n",
            "          [-1.1968e-02, -7.6545e-03, -2.1519e-02],\n",
            "          [ 1.6622e-02,  9.9354e-03,  1.5988e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5532e-03,  5.5162e-03,  2.2438e-02],\n",
            "          [-5.2952e-04,  6.0305e-03, -1.9347e-02],\n",
            "          [-7.1844e-03, -2.5350e-02,  6.4293e-03]],\n",
            "\n",
            "         [[ 5.6110e-04,  1.7873e-02,  2.9161e-03],\n",
            "          [ 5.9827e-03, -1.1958e-02,  1.6452e-02],\n",
            "          [ 1.0894e-02,  1.8592e-02, -7.3609e-03]],\n",
            "\n",
            "         [[-9.8439e-03,  1.2798e-02, -1.2116e-02],\n",
            "          [-1.6322e-02, -2.4927e-02,  1.7279e-02],\n",
            "          [-1.9452e-02,  2.3898e-02,  1.0367e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.7261e-03,  3.2239e-03, -3.8240e-03],\n",
            "          [-1.4618e-02, -2.0673e-02,  2.6474e-03],\n",
            "          [ 2.3666e-02, -7.7527e-03,  1.6703e-02]],\n",
            "\n",
            "         [[ 5.4446e-03, -2.0056e-02,  1.1919e-02],\n",
            "          [ 2.4070e-02,  1.3055e-02,  7.5409e-03],\n",
            "          [ 2.4379e-02, -1.0493e-02, -3.7355e-03]],\n",
            "\n",
            "         [[ 1.7356e-02, -7.0822e-03, -1.7125e-02],\n",
            "          [ 2.1443e-02,  1.2825e-02, -1.7417e-02],\n",
            "          [-9.8088e-03, -8.1646e-03, -5.1392e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6548e-03, -2.0493e-02, -2.3682e-02],\n",
            "          [ 6.1891e-03,  4.3905e-03,  5.5676e-04],\n",
            "          [-2.1339e-03,  2.1845e-03,  2.2021e-03]],\n",
            "\n",
            "         [[ 1.3727e-03,  8.1400e-04,  2.3482e-02],\n",
            "          [ 1.3169e-02,  2.4825e-02,  1.4014e-02],\n",
            "          [-5.1866e-03, -6.9157e-03, -2.5065e-02]],\n",
            "\n",
            "         [[ 1.2348e-02,  4.2818e-03, -1.6565e-02],\n",
            "          [-1.3449e-02,  2.0257e-02, -5.6973e-03],\n",
            "          [-1.9683e-02,  9.1907e-03, -4.1826e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4486e-02,  2.4080e-02,  8.9872e-03],\n",
            "          [-9.8901e-03, -8.5381e-03, -1.4673e-02],\n",
            "          [ 1.4513e-02,  1.3736e-02,  3.1022e-03]],\n",
            "\n",
            "         [[ 2.1312e-03, -1.6245e-03, -6.0728e-03],\n",
            "          [-1.7882e-03, -1.4505e-02, -1.8643e-02],\n",
            "          [-1.4159e-02, -1.9761e-02, -1.9291e-03]],\n",
            "\n",
            "         [[ 8.3926e-03, -1.1816e-03, -1.4055e-03],\n",
            "          [-9.4168e-03, -1.5861e-02, -5.9180e-03],\n",
            "          [ 4.4754e-03, -1.9528e-02, -6.3413e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4897e-03, -2.6907e-04, -7.5718e-03],\n",
            "          [-2.1725e-02,  6.7425e-03,  6.5060e-03],\n",
            "          [-4.6834e-04, -1.4008e-02, -2.0583e-02]],\n",
            "\n",
            "         [[-6.3640e-04,  1.7243e-02, -1.4627e-02],\n",
            "          [-4.6118e-03, -1.2100e-02,  4.2745e-03],\n",
            "          [ 1.7266e-02,  1.0979e-02,  9.4358e-03]],\n",
            "\n",
            "         [[-1.3317e-02,  1.3472e-02,  5.2924e-03],\n",
            "          [-2.4383e-02,  1.0932e-02,  4.9484e-03],\n",
            "          [-1.8592e-02, -1.3917e-02, -2.4307e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0075e-02, -2.4037e-03, -1.7149e-02],\n",
            "          [ 5.6013e-03,  6.6462e-04,  1.6778e-02],\n",
            "          [-1.9758e-02,  1.5468e-02, -2.0466e-02]],\n",
            "\n",
            "         [[-1.1458e-02,  9.7341e-03, -1.1136e-02],\n",
            "          [ 1.4908e-03,  1.8266e-02,  1.3727e-02],\n",
            "          [-6.8782e-03,  1.0342e-04, -7.2181e-03]],\n",
            "\n",
            "         [[-2.4661e-02, -2.0726e-02, -7.1855e-03],\n",
            "          [-1.5941e-02,  9.5535e-03,  2.3179e-02],\n",
            "          [ 1.1575e-02,  3.9184e-03, -2.3550e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3134e-02,  1.7768e-02,  2.3761e-02],\n",
            "          [ 2.3992e-02,  2.1643e-02,  1.6617e-02],\n",
            "          [ 3.3297e-03, -1.1240e-02,  1.1079e-02]],\n",
            "\n",
            "         [[ 2.4046e-02, -5.1523e-03,  9.3083e-03],\n",
            "          [ 1.9743e-02, -1.0902e-02, -2.7816e-03],\n",
            "          [ 1.0701e-02, -1.6276e-02, -1.5705e-02]],\n",
            "\n",
            "         [[ 8.2027e-03,  1.1091e-02,  1.3847e-02],\n",
            "          [-1.1058e-02, -3.7134e-03, -4.0717e-03],\n",
            "          [ 9.4203e-03,  4.1429e-03, -6.5186e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.4610e-02,  2.3450e-02, -6.8661e-03],\n",
            "          [ 7.4763e-03, -2.4373e-02, -1.3816e-02],\n",
            "          [-3.3717e-03,  1.9845e-02, -1.7222e-02]],\n",
            "\n",
            "         [[-4.3553e-03, -5.8362e-03, -2.5045e-02],\n",
            "          [-2.0971e-02,  2.5230e-02, -1.8925e-02],\n",
            "          [ 5.7844e-03, -1.9974e-02, -1.2245e-02]],\n",
            "\n",
            "         [[-4.5670e-03, -2.4255e-02, -2.2740e-02],\n",
            "          [ 1.7771e-02, -2.2311e-02, -1.9162e-02],\n",
            "          [ 2.1118e-02, -5.1721e-03, -2.0334e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3835e-02,  6.0042e-03,  1.1660e-02],\n",
            "          [-1.8193e-02,  1.7197e-03, -9.1749e-03],\n",
            "          [ 5.9905e-03,  2.4834e-02, -1.7811e-02]],\n",
            "\n",
            "         [[-1.9852e-02, -4.5635e-03, -9.9507e-04],\n",
            "          [ 2.3334e-03, -2.1448e-02, -2.0054e-02],\n",
            "          [ 1.3109e-02,  1.8304e-02, -6.5293e-03]],\n",
            "\n",
            "         [[ 1.9108e-02, -1.2034e-02, -1.0975e-02],\n",
            "          [ 4.1844e-04,  2.4048e-04,  1.9689e-02],\n",
            "          [ 1.0571e-02,  7.2097e-03,  2.2302e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 1.9418e-02,  2.2436e-02,  1.0866e-02],\n",
            "          [-2.2058e-02,  3.0105e-03,  8.4073e-03],\n",
            "          [ 3.9706e-03,  4.4572e-03,  2.0023e-02]],\n",
            "\n",
            "         [[ 8.0129e-03,  1.7864e-02, -1.2024e-02],\n",
            "          [-2.3604e-02,  1.9820e-02, -6.6165e-03],\n",
            "          [-5.7747e-03,  2.1732e-03, -1.0125e-02]],\n",
            "\n",
            "         [[-1.2739e-02, -1.4973e-02,  7.6577e-03],\n",
            "          [ 7.6152e-03,  1.2254e-02,  1.2142e-02],\n",
            "          [-2.5194e-02,  2.5449e-02, -1.2881e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5123e-02, -1.2555e-02, -8.4101e-03],\n",
            "          [-1.8216e-02,  2.1461e-02,  1.0020e-02],\n",
            "          [-1.3623e-02, -2.2613e-02, -1.0256e-02]],\n",
            "\n",
            "         [[ 1.1689e-02,  4.1187e-03,  2.1156e-02],\n",
            "          [-2.2162e-02, -1.2327e-02, -2.3084e-02],\n",
            "          [ 3.7713e-03, -2.0156e-02, -1.9076e-02]],\n",
            "\n",
            "         [[-9.0895e-03,  6.6399e-03, -9.2600e-06],\n",
            "          [-1.8059e-02, -1.0018e-02,  2.3696e-02],\n",
            "          [ 1.8922e-02, -1.0558e-02,  1.8291e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9923e-02,  1.8972e-02, -5.3751e-03],\n",
            "          [ 6.2060e-03,  9.6099e-03,  1.7783e-02],\n",
            "          [ 2.4774e-02,  2.2862e-02,  1.9772e-03]],\n",
            "\n",
            "         [[ 1.6467e-02,  5.2852e-03,  2.1200e-03],\n",
            "          [-8.9686e-03, -3.9979e-03, -2.3288e-02],\n",
            "          [ 2.4331e-02, -1.9083e-02,  1.3864e-02]],\n",
            "\n",
            "         [[-1.7144e-02,  1.0614e-02, -1.6200e-02],\n",
            "          [-1.1968e-02, -7.6545e-03, -2.1519e-02],\n",
            "          [ 1.6622e-02,  9.9354e-03,  1.5988e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5532e-03,  5.5162e-03,  2.2438e-02],\n",
            "          [-5.2952e-04,  6.0305e-03, -1.9347e-02],\n",
            "          [-7.1844e-03, -2.5350e-02,  6.4293e-03]],\n",
            "\n",
            "         [[ 5.6110e-04,  1.7873e-02,  2.9161e-03],\n",
            "          [ 5.9827e-03, -1.1958e-02,  1.6452e-02],\n",
            "          [ 1.0894e-02,  1.8592e-02, -7.3609e-03]],\n",
            "\n",
            "         [[-9.8439e-03,  1.2798e-02, -1.2116e-02],\n",
            "          [-1.6322e-02, -2.4927e-02,  1.7279e-02],\n",
            "          [-1.9452e-02,  2.3898e-02,  1.0367e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.7261e-03,  3.2239e-03, -3.8240e-03],\n",
            "          [-1.4618e-02, -2.0673e-02,  2.6474e-03],\n",
            "          [ 2.3666e-02, -7.7527e-03,  1.6703e-02]],\n",
            "\n",
            "         [[ 5.4446e-03, -2.0056e-02,  1.1919e-02],\n",
            "          [ 2.4070e-02,  1.3055e-02,  7.5409e-03],\n",
            "          [ 2.4379e-02, -1.0493e-02, -3.7355e-03]],\n",
            "\n",
            "         [[ 1.7356e-02, -7.0822e-03, -1.7125e-02],\n",
            "          [ 2.1443e-02,  1.2825e-02, -1.7417e-02],\n",
            "          [-9.8088e-03, -8.1646e-03, -5.1392e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6548e-03, -2.0493e-02, -2.3682e-02],\n",
            "          [ 6.1891e-03,  4.3905e-03,  5.5676e-04],\n",
            "          [-2.1339e-03,  2.1845e-03,  2.2021e-03]],\n",
            "\n",
            "         [[ 1.3727e-03,  8.1400e-04,  2.3482e-02],\n",
            "          [ 1.3169e-02,  2.4825e-02,  1.4014e-02],\n",
            "          [-5.1866e-03, -6.9157e-03, -2.5065e-02]],\n",
            "\n",
            "         [[ 1.2348e-02,  4.2818e-03, -1.6565e-02],\n",
            "          [-1.3449e-02,  2.0257e-02, -5.6973e-03],\n",
            "          [-1.9683e-02,  9.1907e-03, -4.1826e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4486e-02,  2.4080e-02,  8.9872e-03],\n",
            "          [-9.8901e-03, -8.5381e-03, -1.4673e-02],\n",
            "          [ 1.4513e-02,  1.3736e-02,  3.1022e-03]],\n",
            "\n",
            "         [[ 2.1312e-03, -1.6245e-03, -6.0728e-03],\n",
            "          [-1.7882e-03, -1.4505e-02, -1.8643e-02],\n",
            "          [-1.4159e-02, -1.9761e-02, -1.9291e-03]],\n",
            "\n",
            "         [[ 8.3926e-03, -1.1816e-03, -1.4055e-03],\n",
            "          [-9.4168e-03, -1.5861e-02, -5.9180e-03],\n",
            "          [ 4.4754e-03, -1.9528e-02, -6.3413e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4897e-03, -2.6907e-04, -7.5718e-03],\n",
            "          [-2.1725e-02,  6.7425e-03,  6.5060e-03],\n",
            "          [-4.6834e-04, -1.4008e-02, -2.0583e-02]],\n",
            "\n",
            "         [[-6.3640e-04,  1.7243e-02, -1.4627e-02],\n",
            "          [-4.6118e-03, -1.2100e-02,  4.2745e-03],\n",
            "          [ 1.7266e-02,  1.0979e-02,  9.4358e-03]],\n",
            "\n",
            "         [[-1.3317e-02,  1.3472e-02,  5.2924e-03],\n",
            "          [-2.4383e-02,  1.0932e-02,  4.9484e-03],\n",
            "          [-1.8592e-02, -1.3917e-02, -2.4307e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0075e-02, -2.4037e-03, -1.7149e-02],\n",
            "          [ 5.6013e-03,  6.6462e-04,  1.6778e-02],\n",
            "          [-1.9758e-02,  1.5468e-02, -2.0466e-02]],\n",
            "\n",
            "         [[-1.1458e-02,  9.7341e-03, -1.1136e-02],\n",
            "          [ 1.4908e-03,  1.8266e-02,  1.3727e-02],\n",
            "          [-6.8782e-03,  1.0342e-04, -7.2181e-03]],\n",
            "\n",
            "         [[-2.4661e-02, -2.0726e-02, -7.1855e-03],\n",
            "          [-1.5941e-02,  9.5535e-03,  2.3179e-02],\n",
            "          [ 1.1575e-02,  3.9184e-03, -2.3550e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3134e-02,  1.7768e-02,  2.3761e-02],\n",
            "          [ 2.3992e-02,  2.1643e-02,  1.6617e-02],\n",
            "          [ 3.3297e-03, -1.1240e-02,  1.1079e-02]],\n",
            "\n",
            "         [[ 2.4046e-02, -5.1523e-03,  9.3083e-03],\n",
            "          [ 1.9743e-02, -1.0902e-02, -2.7816e-03],\n",
            "          [ 1.0701e-02, -1.6276e-02, -1.5705e-02]],\n",
            "\n",
            "         [[ 8.2027e-03,  1.1091e-02,  1.3847e-02],\n",
            "          [-1.1058e-02, -3.7134e-03, -4.0717e-03],\n",
            "          [ 9.4203e-03,  4.1429e-03, -6.5186e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.4610e-02,  2.3450e-02, -6.8661e-03],\n",
            "          [ 7.4763e-03, -2.4373e-02, -1.3816e-02],\n",
            "          [-3.3717e-03,  1.9845e-02, -1.7222e-02]],\n",
            "\n",
            "         [[-4.3553e-03, -5.8362e-03, -2.5045e-02],\n",
            "          [-2.0971e-02,  2.5230e-02, -1.8925e-02],\n",
            "          [ 5.7844e-03, -1.9974e-02, -1.2245e-02]],\n",
            "\n",
            "         [[-4.5670e-03, -2.4255e-02, -2.2740e-02],\n",
            "          [ 1.7771e-02, -2.2311e-02, -1.9162e-02],\n",
            "          [ 2.1118e-02, -5.1721e-03, -2.0334e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3835e-02,  6.0042e-03,  1.1660e-02],\n",
            "          [-1.8193e-02,  1.7197e-03, -9.1749e-03],\n",
            "          [ 5.9905e-03,  2.4834e-02, -1.7811e-02]],\n",
            "\n",
            "         [[-1.9852e-02, -4.5635e-03, -9.9507e-04],\n",
            "          [ 2.3334e-03, -2.1448e-02, -2.0054e-02],\n",
            "          [ 1.3109e-02,  1.8304e-02, -6.5293e-03]],\n",
            "\n",
            "         [[ 1.9108e-02, -1.2034e-02, -1.0975e-02],\n",
            "          [ 4.1844e-04,  2.4048e-04,  1.9689e-02],\n",
            "          [ 1.0571e-02,  7.2097e-03,  2.2302e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 1.9418e-02,  2.2436e-02,  1.0866e-02],\n",
            "          [-2.2058e-02,  3.0105e-03,  8.4073e-03],\n",
            "          [ 3.9706e-03,  4.4572e-03,  2.0023e-02]],\n",
            "\n",
            "         [[ 8.0129e-03,  1.7864e-02, -1.2024e-02],\n",
            "          [-2.3604e-02,  1.9820e-02, -6.6165e-03],\n",
            "          [-5.7747e-03,  2.1732e-03, -1.0125e-02]],\n",
            "\n",
            "         [[-1.2739e-02, -1.4973e-02,  7.6577e-03],\n",
            "          [ 7.6152e-03,  1.2254e-02,  1.2142e-02],\n",
            "          [-2.5194e-02,  2.5449e-02, -1.2881e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5123e-02, -1.2555e-02, -8.4101e-03],\n",
            "          [-1.8216e-02,  2.1461e-02,  1.0020e-02],\n",
            "          [-1.3623e-02, -2.2613e-02, -1.0256e-02]],\n",
            "\n",
            "         [[ 1.1689e-02,  4.1187e-03,  2.1156e-02],\n",
            "          [-2.2162e-02, -1.2327e-02, -2.3084e-02],\n",
            "          [ 3.7713e-03, -2.0156e-02, -1.9076e-02]],\n",
            "\n",
            "         [[-9.0895e-03,  6.6399e-03, -9.2600e-06],\n",
            "          [-1.8059e-02, -1.0018e-02,  2.3696e-02],\n",
            "          [ 1.8922e-02, -1.0558e-02,  1.8291e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9923e-02,  1.8972e-02, -5.3751e-03],\n",
            "          [ 6.2060e-03,  9.6099e-03,  1.7783e-02],\n",
            "          [ 2.4774e-02,  2.2862e-02,  1.9772e-03]],\n",
            "\n",
            "         [[ 1.6467e-02,  5.2852e-03,  2.1200e-03],\n",
            "          [-8.9686e-03, -3.9979e-03, -2.3288e-02],\n",
            "          [ 2.4331e-02, -1.9083e-02,  1.3864e-02]],\n",
            "\n",
            "         [[-1.7144e-02,  1.0614e-02, -1.6200e-02],\n",
            "          [-1.1968e-02, -7.6545e-03, -2.1519e-02],\n",
            "          [ 1.6622e-02,  9.9354e-03,  1.5988e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5532e-03,  5.5162e-03,  2.2438e-02],\n",
            "          [-5.2952e-04,  6.0305e-03, -1.9347e-02],\n",
            "          [-7.1844e-03, -2.5350e-02,  6.4293e-03]],\n",
            "\n",
            "         [[ 5.6110e-04,  1.7873e-02,  2.9161e-03],\n",
            "          [ 5.9827e-03, -1.1958e-02,  1.6452e-02],\n",
            "          [ 1.0894e-02,  1.8592e-02, -7.3609e-03]],\n",
            "\n",
            "         [[-9.8439e-03,  1.2798e-02, -1.2116e-02],\n",
            "          [-1.6322e-02, -2.4927e-02,  1.7279e-02],\n",
            "          [-1.9452e-02,  2.3898e-02,  1.0367e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.7261e-03,  3.2239e-03, -3.8240e-03],\n",
            "          [-1.4618e-02, -2.0673e-02,  2.6474e-03],\n",
            "          [ 2.3666e-02, -7.7527e-03,  1.6703e-02]],\n",
            "\n",
            "         [[ 5.4446e-03, -2.0056e-02,  1.1919e-02],\n",
            "          [ 2.4070e-02,  1.3055e-02,  7.5409e-03],\n",
            "          [ 2.4379e-02, -1.0493e-02, -3.7355e-03]],\n",
            "\n",
            "         [[ 1.7356e-02, -7.0822e-03, -1.7125e-02],\n",
            "          [ 2.1443e-02,  1.2825e-02, -1.7417e-02],\n",
            "          [-9.8088e-03, -8.1646e-03, -5.1392e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6548e-03, -2.0493e-02, -2.3682e-02],\n",
            "          [ 6.1891e-03,  4.3905e-03,  5.5676e-04],\n",
            "          [-2.1339e-03,  2.1845e-03,  2.2021e-03]],\n",
            "\n",
            "         [[ 1.3727e-03,  8.1400e-04,  2.3482e-02],\n",
            "          [ 1.3169e-02,  2.4825e-02,  1.4014e-02],\n",
            "          [-5.1866e-03, -6.9157e-03, -2.5065e-02]],\n",
            "\n",
            "         [[ 1.2348e-02,  4.2818e-03, -1.6565e-02],\n",
            "          [-1.3449e-02,  2.0257e-02, -5.6973e-03],\n",
            "          [-1.9683e-02,  9.1907e-03, -4.1826e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4486e-02,  2.4080e-02,  8.9872e-03],\n",
            "          [-9.8901e-03, -8.5381e-03, -1.4673e-02],\n",
            "          [ 1.4513e-02,  1.3736e-02,  3.1022e-03]],\n",
            "\n",
            "         [[ 2.1312e-03, -1.6245e-03, -6.0728e-03],\n",
            "          [-1.7882e-03, -1.4505e-02, -1.8643e-02],\n",
            "          [-1.4159e-02, -1.9761e-02, -1.9291e-03]],\n",
            "\n",
            "         [[ 8.3926e-03, -1.1816e-03, -1.4055e-03],\n",
            "          [-9.4168e-03, -1.5861e-02, -5.9180e-03],\n",
            "          [ 4.4754e-03, -1.9528e-02, -6.3413e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4897e-03, -2.6907e-04, -7.5718e-03],\n",
            "          [-2.1725e-02,  6.7425e-03,  6.5060e-03],\n",
            "          [-4.6834e-04, -1.4008e-02, -2.0583e-02]],\n",
            "\n",
            "         [[-6.3640e-04,  1.7243e-02, -1.4627e-02],\n",
            "          [-4.6118e-03, -1.2100e-02,  4.2745e-03],\n",
            "          [ 1.7266e-02,  1.0979e-02,  9.4358e-03]],\n",
            "\n",
            "         [[-1.3317e-02,  1.3472e-02,  5.2924e-03],\n",
            "          [-2.4383e-02,  1.0932e-02,  4.9484e-03],\n",
            "          [-1.8592e-02, -1.3917e-02, -2.4307e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0075e-02, -2.4037e-03, -1.7149e-02],\n",
            "          [ 5.6013e-03,  6.6462e-04,  1.6778e-02],\n",
            "          [-1.9758e-02,  1.5468e-02, -2.0466e-02]],\n",
            "\n",
            "         [[-1.1458e-02,  9.7341e-03, -1.1136e-02],\n",
            "          [ 1.4908e-03,  1.8266e-02,  1.3727e-02],\n",
            "          [-6.8782e-03,  1.0342e-04, -7.2181e-03]],\n",
            "\n",
            "         [[-2.4661e-02, -2.0726e-02, -7.1855e-03],\n",
            "          [-1.5941e-02,  9.5535e-03,  2.3179e-02],\n",
            "          [ 1.1575e-02,  3.9184e-03, -2.3550e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3134e-02,  1.7768e-02,  2.3761e-02],\n",
            "          [ 2.3992e-02,  2.1643e-02,  1.6617e-02],\n",
            "          [ 3.3297e-03, -1.1240e-02,  1.1079e-02]],\n",
            "\n",
            "         [[ 2.4046e-02, -5.1523e-03,  9.3083e-03],\n",
            "          [ 1.9743e-02, -1.0902e-02, -2.7816e-03],\n",
            "          [ 1.0701e-02, -1.6276e-02, -1.5705e-02]],\n",
            "\n",
            "         [[ 8.2027e-03,  1.1091e-02,  1.3847e-02],\n",
            "          [-1.1058e-02, -3.7134e-03, -4.0717e-03],\n",
            "          [ 9.4203e-03,  4.1429e-03, -6.5186e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.4610e-02,  2.3450e-02, -6.8661e-03],\n",
            "          [ 7.4763e-03, -2.4373e-02, -1.3816e-02],\n",
            "          [-3.3717e-03,  1.9845e-02, -1.7222e-02]],\n",
            "\n",
            "         [[-4.3553e-03, -5.8362e-03, -2.5045e-02],\n",
            "          [-2.0971e-02,  2.5230e-02, -1.8925e-02],\n",
            "          [ 5.7844e-03, -1.9974e-02, -1.2245e-02]],\n",
            "\n",
            "         [[-4.5670e-03, -2.4255e-02, -2.2740e-02],\n",
            "          [ 1.7771e-02, -2.2311e-02, -1.9162e-02],\n",
            "          [ 2.1118e-02, -5.1721e-03, -2.0334e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3835e-02,  6.0042e-03,  1.1660e-02],\n",
            "          [-1.8193e-02,  1.7197e-03, -9.1749e-03],\n",
            "          [ 5.9905e-03,  2.4834e-02, -1.7811e-02]],\n",
            "\n",
            "         [[-1.9852e-02, -4.5635e-03, -9.9507e-04],\n",
            "          [ 2.3334e-03, -2.1448e-02, -2.0054e-02],\n",
            "          [ 1.3109e-02,  1.8304e-02, -6.5293e-03]],\n",
            "\n",
            "         [[ 1.9108e-02, -1.2034e-02, -1.0975e-02],\n",
            "          [ 4.1844e-04,  2.4048e-04,  1.9689e-02],\n",
            "          [ 1.0571e-02,  7.2097e-03,  2.2302e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1345,  0.1554,  0.0753,  ...,  0.1563,  0.0141,  0.0370],\n",
            "        [ 0.0776,  0.0739,  0.0299,  ..., -0.0886, -0.0994,  0.0869],\n",
            "        [-0.1707, -0.1056,  0.0217,  ..., -0.1671, -0.1686,  0.1544],\n",
            "        ...,\n",
            "        [ 0.1737, -0.1332,  0.1021,  ...,  0.0214, -0.1230,  0.1506],\n",
            "        [ 0.0612,  0.0354, -0.0323,  ..., -0.0069,  0.1272, -0.1179],\n",
            "        [ 0.0882, -0.1238, -0.0774,  ...,  0.0117,  0.1326,  0.1735]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.0673,  0.0777,  0.0376,  ...,  0.0781,  0.0071,  0.0185],\n",
            "        [ 0.0388,  0.0370,  0.0150,  ..., -0.0443, -0.0497,  0.0435],\n",
            "        [-0.0854, -0.0528,  0.0109,  ..., -0.0835, -0.0843,  0.0772],\n",
            "        ...,\n",
            "        [ 0.0869, -0.0666,  0.0511,  ...,  0.0107, -0.0615,  0.0753],\n",
            "        [ 0.0306,  0.0177, -0.0162,  ..., -0.0034,  0.0636, -0.0590],\n",
            "        [ 0.0441, -0.0619, -0.0387,  ...,  0.0059,  0.0663,  0.0868]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1903,  0.2198,  0.1065,  ..., -0.0110, -0.2199,  0.1569],\n",
            "        [ 0.2459,  0.1016, -0.0850,  ...,  0.2210,  0.0200,  0.0523],\n",
            "        [ 0.1097,  0.1046,  0.0423,  ..., -0.2061,  0.1741,  0.1329],\n",
            "        ...,\n",
            "        [-0.2453,  0.0792, -0.2213,  ...,  0.0881, -0.0387, -0.1407],\n",
            "        [-0.2055, -0.2485,  0.1241,  ...,  0.1913, -0.1581, -0.0015],\n",
            "        [ 0.0482,  0.0903, -0.2478,  ..., -0.1664,  0.2418, -0.0021]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.0951,  0.1099,  0.0532,  ..., -0.0055, -0.1099,  0.0785],\n",
            "        [ 0.1230,  0.0508, -0.0425,  ...,  0.1105,  0.0100,  0.0261],\n",
            "        [ 0.0549,  0.0523,  0.0212,  ..., -0.1031,  0.0870,  0.0664],\n",
            "        ...,\n",
            "        [-0.1227,  0.0396, -0.1106,  ...,  0.0440, -0.0193, -0.0704],\n",
            "        [-0.1027, -0.1243,  0.0620,  ...,  0.0956, -0.0790, -0.0008],\n",
            "        [ 0.0241,  0.0452, -0.1239,  ..., -0.0832,  0.1209, -0.0011]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2876,  0.3324,  0.1610, -0.3267,  0.0446,  0.1245,  0.0588,  0.0660,\n",
            "          0.2966,  0.1187,  0.2646, -0.1781, -0.3497,  0.2936, -0.0980, -0.0855,\n",
            "          0.0322, -0.1500, -0.1887, -0.2218,  0.1134,  0.1128,  0.1815,  0.1799,\n",
            "         -0.3732,  0.3770, -0.1908, -0.0666,  0.2940,  0.1676, -0.1132,  0.3359],\n",
            "        [ 0.2693,  0.2526,  0.0457,  0.3344,  0.1400,  0.3594, -0.0472, -0.2504,\n",
            "         -0.0024, -0.0601, -0.1412, -0.1225,  0.2946, -0.3243,  0.1717,  0.3388,\n",
            "          0.3514, -0.0440, -0.0156,  0.0179, -0.1082,  0.1496, -0.0065, -0.3410,\n",
            "          0.0617,  0.3029,  0.2283, -0.0619, -0.3415, -0.0166, -0.3324,  0.2373],\n",
            "        [ 0.3718,  0.1536, -0.1285,  0.1325,  0.2936, -0.3619, -0.3065,  0.3395,\n",
            "          0.2661,  0.0847, -0.0894,  0.1175, -0.0485,  0.3726, -0.0551,  0.1704,\n",
            "          0.2330, -0.0829,  0.1621, -0.2405,  0.0042, -0.2313,  0.0014, -0.0303,\n",
            "         -0.3615,  0.0199, -0.1888, -0.1070, -0.3523, -0.3042, -0.2639,  0.1346],\n",
            "        [ 0.0220,  0.2461,  0.1544,  0.2919, -0.0088,  0.3688, -0.2728, -0.0831,\n",
            "          0.0794, -0.3264, -0.2222,  0.1773, -0.2044,  0.0425,  0.2537,  0.3493,\n",
            "         -0.1775, -0.3320, -0.1200,  0.1926,  0.0255,  0.1778, -0.2897, -0.3766,\n",
            "         -0.2204,  0.1639, -0.1122,  0.3449,  0.1931,  0.3341,  0.0302,  0.0791],\n",
            "        [ 0.1659,  0.1581,  0.0640, -0.2330,  0.1653, -0.1465,  0.1987,  0.1287,\n",
            "         -0.0574,  0.2905,  0.3487,  0.2831, -0.2610,  0.3678, -0.0913,  0.1569,\n",
            "          0.0292, -0.2788, -0.1731, -0.2915,  0.2259,  0.1612,  0.3578, -0.3176,\n",
            "         -0.0024,  0.2828,  0.3750,  0.3640, -0.1596, -0.2755, -0.1410,  0.2619],\n",
            "        [-0.1277,  0.0303,  0.1724, -0.2758, -0.0612,  0.1635,  0.2044, -0.2215,\n",
            "          0.3003, -0.0222,  0.1329, -0.0526,  0.1186, -0.0493,  0.1521, -0.1209,\n",
            "         -0.3676,  0.1067, -0.2567, -0.3178,  0.1740, -0.1226,  0.2126, -0.1293,\n",
            "          0.3338, -0.0593,  0.0644,  0.3663, -0.3504, -0.3116,  0.2632,  0.2009],\n",
            "        [ 0.3360,  0.1896,  0.1881,  0.2605, -0.2705, -0.3571,  0.1134,  0.3317,\n",
            "          0.2843,  0.1291,  0.0860,  0.3087,  0.3420,  0.1620,  0.3090, -0.0063,\n",
            "         -0.0511, -0.0883,  0.0013, -0.1205,  0.2943, -0.0929, -0.0650,  0.1938,\n",
            "          0.2806, -0.2008,  0.0719,  0.1736, -0.3436,  0.2210, -0.2587, -0.0619],\n",
            "        [-0.2896, -0.0970,  0.2001, -0.1918, -0.2368, -0.3368, -0.3487, -0.2831,\n",
            "         -0.0249,  0.1367, -0.2578, -0.3531, -0.0714, -0.0308,  0.0823,  0.3769,\n",
            "          0.1515, -0.3381, -0.0591,  0.2992, -0.2515,  0.1517, -0.0268,  0.1605,\n",
            "         -0.1250,  0.2620, -0.2167,  0.2611,  0.0937, -0.1894, -0.2125,  0.1859],\n",
            "        [-0.3650, -0.2258,  0.0464,  0.0498,  0.0715, -0.2203, -0.2623,  0.0038,\n",
            "         -0.0955,  0.3286, -0.3669, -0.0968, -0.2665,  0.0145,  0.0523,  0.1307,\n",
            "         -0.0229,  0.2240,  0.3240, -0.0756, -0.0784,  0.0360, -0.1680,  0.0904,\n",
            "          0.1639,  0.3041,  0.3191, -0.1143,  0.1315, -0.2486,  0.1517,  0.3695],\n",
            "        [-0.1322,  0.2391, -0.3609,  0.2071,  0.0586,  0.3114,  0.0107,  0.2996,\n",
            "          0.0325, -0.2288, -0.1049,  0.3442, -0.2632,  0.3412,  0.1935,  0.0880,\n",
            "          0.1062, -0.1627, -0.3035,  0.0522,  0.2958,  0.3057,  0.0758, -0.2122,\n",
            "         -0.0681,  0.2893, -0.2608,  0.3305, -0.3759, -0.1999,  0.3105,  0.1000]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1438,  0.1662,  0.0805, -0.1634,  0.0223,  0.0623,  0.0294,  0.0330,\n",
            "          0.1483,  0.0593,  0.1323, -0.0891, -0.1748,  0.1468, -0.0490, -0.0428,\n",
            "          0.0161, -0.0750, -0.0944, -0.1109,  0.0567,  0.0564,  0.0908,  0.0899,\n",
            "         -0.1866,  0.1885, -0.0954, -0.0333,  0.1470,  0.0838, -0.0566,  0.1679],\n",
            "        [ 0.1346,  0.1263,  0.0228,  0.1672,  0.0700,  0.1797, -0.0236, -0.1252,\n",
            "         -0.0012, -0.0300, -0.0706, -0.0612,  0.1473, -0.1621,  0.0858,  0.1694,\n",
            "          0.1757, -0.0220, -0.0078,  0.0090, -0.0541,  0.0748, -0.0032, -0.1705,\n",
            "          0.0309,  0.1514,  0.1141, -0.0310, -0.1708, -0.0083, -0.1662,  0.1186],\n",
            "        [ 0.1859,  0.0768, -0.0642,  0.0662,  0.1468, -0.1810, -0.1532,  0.1697,\n",
            "          0.1330,  0.0423, -0.0447,  0.0587, -0.0243,  0.1863, -0.0276,  0.0852,\n",
            "          0.1165, -0.0414,  0.0810, -0.1202,  0.0021, -0.1156,  0.0007, -0.0151,\n",
            "         -0.1808,  0.0100, -0.0944, -0.0535, -0.1762, -0.1521, -0.1320,  0.0673],\n",
            "        [ 0.0110,  0.1231,  0.0772,  0.1459, -0.0044,  0.1844, -0.1364, -0.0416,\n",
            "          0.0397, -0.1632, -0.1111,  0.0887, -0.1022,  0.0213,  0.1269,  0.1746,\n",
            "         -0.0888, -0.1660, -0.0600,  0.0963,  0.0127,  0.0889, -0.1449, -0.1883,\n",
            "         -0.1102,  0.0820, -0.0561,  0.1724,  0.0965,  0.1671,  0.0151,  0.0395],\n",
            "        [ 0.0830,  0.0790,  0.0320, -0.1165,  0.0826, -0.0733,  0.0993,  0.0644,\n",
            "         -0.0287,  0.1453,  0.1744,  0.1415, -0.1305,  0.1839, -0.0457,  0.0785,\n",
            "          0.0146, -0.1394, -0.0865, -0.1457,  0.1129,  0.0806,  0.1789, -0.1588,\n",
            "         -0.0012,  0.1414,  0.1875,  0.1820, -0.0798, -0.1378, -0.0705,  0.1310],\n",
            "        [-0.0638,  0.0152,  0.0862, -0.1379, -0.0306,  0.0818,  0.1022, -0.1108,\n",
            "          0.1501, -0.0111,  0.0665, -0.0263,  0.0593, -0.0247,  0.0761, -0.0605,\n",
            "         -0.1838,  0.0534, -0.1284, -0.1589,  0.0870, -0.0613,  0.1063, -0.0647,\n",
            "          0.1669, -0.0296,  0.0322,  0.1832, -0.1752, -0.1558,  0.1316,  0.1005],\n",
            "        [ 0.1680,  0.0948,  0.0940,  0.1303, -0.1353, -0.1786,  0.0567,  0.1659,\n",
            "          0.1421,  0.0646,  0.0430,  0.1544,  0.1710,  0.0810,  0.1545, -0.0032,\n",
            "         -0.0256, -0.0442,  0.0007, -0.0602,  0.1471, -0.0464, -0.0325,  0.0969,\n",
            "          0.1403, -0.1004,  0.0360,  0.0868, -0.1718,  0.1105, -0.1294, -0.0309],\n",
            "        [-0.1448, -0.0485,  0.1000, -0.0959, -0.1184, -0.1684, -0.1744, -0.1415,\n",
            "         -0.0125,  0.0683, -0.1289, -0.1765, -0.0357, -0.0154,  0.0412,  0.1884,\n",
            "          0.0758, -0.1690, -0.0296,  0.1496, -0.1257,  0.0758, -0.0134,  0.0802,\n",
            "         -0.0625,  0.1310, -0.1083,  0.1306,  0.0468, -0.0947, -0.1063,  0.0930],\n",
            "        [-0.1825, -0.1129,  0.0232,  0.0249,  0.0358, -0.1102, -0.1312,  0.0019,\n",
            "         -0.0477,  0.1643, -0.1834, -0.0484, -0.1333,  0.0072,  0.0262,  0.0654,\n",
            "         -0.0115,  0.1120,  0.1620, -0.0378, -0.0392,  0.0180, -0.0840,  0.0452,\n",
            "          0.0819,  0.1521,  0.1595, -0.0572,  0.0658, -0.1243,  0.0758,  0.1847],\n",
            "        [-0.0661,  0.1196, -0.1805,  0.1036,  0.0293,  0.1557,  0.0054,  0.1498,\n",
            "          0.0163, -0.1144, -0.0525,  0.1721, -0.1316,  0.1706,  0.0967,  0.0440,\n",
            "          0.0531, -0.0813, -0.1518,  0.0261,  0.1479,  0.1529,  0.0379, -0.1061,\n",
            "         -0.0341,  0.1447, -0.1304,  0.1652, -0.1880, -0.0999,  0.1552,  0.0500]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.5621,  0.6494,  0.3145, -0.6385,  0.0871,  0.2434,  0.1149,  0.1290,\n",
            "          0.5796,  0.2319]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2810,  0.3247,  0.1573, -0.3192,  0.0436,  0.1217,  0.0575,  0.0645,\n",
            "          0.2898,  0.1160]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Focus(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (dropout1): Dropout2d(p=0.05, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9"
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I"
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX"
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7"
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylCWkAlwv6EL"
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQASTbrKv586",
        "outputId": "828886f0-d710-4ed9-c727-9537a2130079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 33 %\n",
            "total correct 9907\n",
            "total train set images 30000\n",
            "focus_true_pred_true 886 =============> FTPT : 2 %\n",
            "focus_false_pred_true 9021 =============> FFPT : 30 %\n",
            "focus_true_pred_false 2184 =============> FTPF : 7 %\n",
            "focus_false_pred_false 17909 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  0\n",
            "argmax_less_than_half ==================>  30000\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZmkgV3cv55D",
        "outputId": "35c6ff6b-e657-423a-b128-1f2e4488aad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 33 %\n",
            "total correct 3387\n",
            "total train set images 10000\n",
            "focus_true_pred_true 356 =============> FTPT : 3 %\n",
            "focus_false_pred_true 3031 =============> FFPT : 30 %\n",
            "focus_true_pred_false 692 =============> FTPF : 6 %\n",
            "focus_false_pred_false 5921 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  0\n",
            "argmax_less_than_half ==================>  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFfAJZkcZEsY",
        "outputId": "e89eb9a0-6f1d-42eb-8387-b661d2b853d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "nos_epochs = 300\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_focus.step()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    col1.append(epoch+1)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 1.101\n",
            "[1,   120] loss: 1.097\n",
            "[1,   180] loss: 1.093\n",
            "[1,   240] loss: 1.084\n",
            "[2,    60] loss: 1.068\n",
            "[2,   120] loss: 1.060\n",
            "[2,   180] loss: 1.054\n",
            "[2,   240] loss: 1.049\n",
            "[3,    60] loss: 1.035\n",
            "[3,   120] loss: 1.035\n",
            "[3,   180] loss: 1.036\n",
            "[3,   240] loss: 1.029\n",
            "[4,    60] loss: 1.016\n",
            "[4,   120] loss: 1.020\n",
            "[4,   180] loss: 1.016\n",
            "[4,   240] loss: 1.016\n",
            "[5,    60] loss: 0.983\n",
            "[5,   120] loss: 0.987\n",
            "[5,   180] loss: 0.968\n",
            "[5,   240] loss: 0.948\n",
            "[6,    60] loss: 0.900\n",
            "[6,   120] loss: 0.890\n",
            "[6,   180] loss: 0.879\n",
            "[6,   240] loss: 0.845\n",
            "[7,    60] loss: 0.801\n",
            "[7,   120] loss: 0.799\n",
            "[7,   180] loss: 0.780\n",
            "[7,   240] loss: 0.739\n",
            "[8,    60] loss: 0.699\n",
            "[8,   120] loss: 0.686\n",
            "[8,   180] loss: 0.676\n",
            "[8,   240] loss: 0.670\n",
            "[9,    60] loss: 0.612\n",
            "[9,   120] loss: 0.596\n",
            "[9,   180] loss: 0.602\n",
            "[9,   240] loss: 0.578\n",
            "[10,    60] loss: 0.530\n",
            "[10,   120] loss: 0.526\n",
            "[10,   180] loss: 0.518\n",
            "[10,   240] loss: 0.490\n",
            "[11,    60] loss: 0.437\n",
            "[11,   120] loss: 0.469\n",
            "[11,   180] loss: 0.468\n",
            "[11,   240] loss: 0.467\n",
            "[12,    60] loss: 0.402\n",
            "[12,   120] loss: 0.419\n",
            "[12,   180] loss: 0.417\n",
            "[12,   240] loss: 0.400\n",
            "[13,    60] loss: 0.368\n",
            "[13,   120] loss: 0.353\n",
            "[13,   180] loss: 0.375\n",
            "[13,   240] loss: 0.366\n",
            "[14,    60] loss: 0.314\n",
            "[14,   120] loss: 0.339\n",
            "[14,   180] loss: 0.334\n",
            "[14,   240] loss: 0.333\n",
            "[15,    60] loss: 0.299\n",
            "[15,   120] loss: 0.312\n",
            "[15,   180] loss: 0.291\n",
            "[15,   240] loss: 0.298\n",
            "[16,    60] loss: 0.263\n",
            "[16,   120] loss: 0.293\n",
            "[16,   180] loss: 0.270\n",
            "[16,   240] loss: 0.271\n",
            "[17,    60] loss: 0.218\n",
            "[17,   120] loss: 0.246\n",
            "[17,   180] loss: 0.235\n",
            "[17,   240] loss: 0.262\n",
            "[18,    60] loss: 0.216\n",
            "[18,   120] loss: 0.228\n",
            "[18,   180] loss: 0.235\n",
            "[18,   240] loss: 0.220\n",
            "[19,    60] loss: 0.200\n",
            "[19,   120] loss: 0.202\n",
            "[19,   180] loss: 0.183\n",
            "[19,   240] loss: 0.188\n",
            "[20,    60] loss: 0.181\n",
            "[20,   120] loss: 0.179\n",
            "[20,   180] loss: 0.206\n",
            "[20,   240] loss: 0.194\n",
            "[21,    60] loss: 0.156\n",
            "[21,   120] loss: 0.166\n",
            "[21,   180] loss: 0.186\n",
            "[21,   240] loss: 0.172\n",
            "[22,    60] loss: 0.147\n",
            "[22,   120] loss: 0.133\n",
            "[22,   180] loss: 0.140\n",
            "[22,   240] loss: 0.142\n",
            "[23,    60] loss: 0.121\n",
            "[23,   120] loss: 0.141\n",
            "[23,   180] loss: 0.132\n",
            "[23,   240] loss: 0.147\n",
            "[24,    60] loss: 0.108\n",
            "[24,   120] loss: 0.117\n",
            "[24,   180] loss: 0.130\n",
            "[24,   240] loss: 0.135\n",
            "[25,    60] loss: 0.110\n",
            "[25,   120] loss: 0.114\n",
            "[25,   180] loss: 0.113\n",
            "[25,   240] loss: 0.128\n",
            "[26,    60] loss: 0.093\n",
            "[26,   120] loss: 0.104\n",
            "[26,   180] loss: 0.102\n",
            "[26,   240] loss: 0.125\n",
            "[27,    60] loss: 0.106\n",
            "[27,   120] loss: 0.087\n",
            "[27,   180] loss: 0.098\n",
            "[27,   240] loss: 0.090\n",
            "[28,    60] loss: 0.068\n",
            "[28,   120] loss: 0.095\n",
            "[28,   180] loss: 0.089\n",
            "[28,   240] loss: 0.095\n",
            "[29,    60] loss: 0.076\n",
            "[29,   120] loss: 0.078\n",
            "[29,   180] loss: 0.076\n",
            "[29,   240] loss: 0.087\n",
            "[30,    60] loss: 0.073\n",
            "[30,   120] loss: 0.079\n",
            "[30,   180] loss: 0.080\n",
            "[30,   240] loss: 0.092\n",
            "[31,    60] loss: 0.063\n",
            "[31,   120] loss: 0.069\n",
            "[31,   180] loss: 0.065\n",
            "[31,   240] loss: 0.077\n",
            "[32,    60] loss: 0.059\n",
            "[32,   120] loss: 0.060\n",
            "[32,   180] loss: 0.079\n",
            "[32,   240] loss: 0.068\n",
            "[33,    60] loss: 0.056\n",
            "[33,   120] loss: 0.063\n",
            "[33,   180] loss: 0.065\n",
            "[33,   240] loss: 0.071\n",
            "[34,    60] loss: 0.040\n",
            "[34,   120] loss: 0.066\n",
            "[34,   180] loss: 0.052\n",
            "[34,   240] loss: 0.065\n",
            "[35,    60] loss: 0.054\n",
            "[35,   120] loss: 0.053\n",
            "[35,   180] loss: 0.051\n",
            "[35,   240] loss: 0.044\n",
            "[36,    60] loss: 0.053\n",
            "[36,   120] loss: 0.051\n",
            "[36,   180] loss: 0.044\n",
            "[36,   240] loss: 0.060\n",
            "[37,    60] loss: 0.047\n",
            "[37,   120] loss: 0.032\n",
            "[37,   180] loss: 0.055\n",
            "[37,   240] loss: 0.067\n",
            "[38,    60] loss: 0.034\n",
            "[38,   120] loss: 0.041\n",
            "[38,   180] loss: 0.033\n",
            "[38,   240] loss: 0.050\n",
            "[39,    60] loss: 0.035\n",
            "[39,   120] loss: 0.052\n",
            "[39,   180] loss: 0.041\n",
            "[39,   240] loss: 0.039\n",
            "[40,    60] loss: 0.041\n",
            "[40,   120] loss: 0.025\n",
            "[40,   180] loss: 0.027\n",
            "[40,   240] loss: 0.049\n",
            "[41,    60] loss: 0.028\n",
            "[41,   120] loss: 0.027\n",
            "[41,   180] loss: 0.031\n",
            "[41,   240] loss: 0.030\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "outputId": "9e568026-a690-4fc7-faee-b4a38dfab77e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "name = \"focus_random_classify_random_train_both_0_5\"\n",
        "name"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'focus_random_classify_random_train_both_0_5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE"
      },
      "source": [
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/focus_net_params_multiplied_by_k/\"+name+\".pt\")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o"
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO"
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "outputId": "c718b883-44c4-4cee-bf80-9253d8b4b024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "df_train"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>886</td>\n",
              "      <td>9021</td>\n",
              "      <td>2184</td>\n",
              "      <td>17909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>1200</td>\n",
              "      <td>10052</td>\n",
              "      <td>1859</td>\n",
              "      <td>16889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1564</td>\n",
              "      <td>28436</td>\n",
              "      <td>8576</td>\n",
              "      <td>9147</td>\n",
              "      <td>3350</td>\n",
              "      <td>8927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>15670</td>\n",
              "      <td>14330</td>\n",
              "      <td>17463</td>\n",
              "      <td>6828</td>\n",
              "      <td>1807</td>\n",
              "      <td>3902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>18487</td>\n",
              "      <td>11513</td>\n",
              "      <td>20568</td>\n",
              "      <td>6269</td>\n",
              "      <td>1026</td>\n",
              "      <td>2137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>19612</td>\n",
              "      <td>10388</td>\n",
              "      <td>22121</td>\n",
              "      <td>5995</td>\n",
              "      <td>598</td>\n",
              "      <td>1286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>19715</td>\n",
              "      <td>10285</td>\n",
              "      <td>22916</td>\n",
              "      <td>5970</td>\n",
              "      <td>377</td>\n",
              "      <td>737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>19498</td>\n",
              "      <td>10502</td>\n",
              "      <td>23331</td>\n",
              "      <td>5964</td>\n",
              "      <td>275</td>\n",
              "      <td>430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>19358</td>\n",
              "      <td>10642</td>\n",
              "      <td>23410</td>\n",
              "      <td>6076</td>\n",
              "      <td>206</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0       0             0  ...                   2184                   17909\n",
              "1       1             0  ...                   1859                   16889\n",
              "2       6          1564  ...                   3350                    8927\n",
              "3      11         15670  ...                   1807                    3902\n",
              "4      16         18487  ...                   1026                    2137\n",
              "5      21         19612  ...                    598                    1286\n",
              "6      26         19715  ...                    377                     737\n",
              "7      31         19498  ...                    275                     430\n",
              "8      36         19358  ...                    206                     308\n",
              "\n",
              "[9 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "outputId": "f05df0d0-fc4e-417f-ea27-3529c3d7e67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAEWCAYAAABoup70AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU5dnH/881W1ikLL2XXToLCMoKiCjGEkti0GBLNKIoxvokJo/R5Pf8ElN/0SSaJzExQUXQmKixP8ZoCBoFla4oIALSkaX3suzuXL8/zlkYcCvs7MzOfN+v13nNzH3uOXPNKHudcp/rNndHRERE0kck0QGIiIhI/VLyFxERSTNK/iIiImlGyV9ERCTNKPmLiIikGSV/ERGRNKPkL5IAZrbIzM6s674iIjWh5C8pzcyuNbOPzGyfmRWZ2UNm1uIYttPNzPbELG5me2Nen16b7bn7AHf/T133rQ9mNtnMfpboOETk2Cn5S8oys+8C9wJ3ArnACKA7MNXMsmuzLXdf4+5Ny5eweXBM2/SYz82so68gIhIXSv6SksysOfBj4HZ3f83dS9x9FXA5kAdcHfa7x8yeMbPHzWx3eIq9sJafda2ZvWNmD5jZVuAeM+tpZm+Y2VYz22JmT8aecTCzVWZ2Tk1iqGXfk83s/XDd383s6cqO0s2sl5m9ZWY7wxifjlnXz8ymmtk2M/vEzC4P228ErgK+F57x+L/a/FYikhyU/CVVjQRygOdjG919D/AqcG5M81eAp4AWwMvAg8fwecOBFUB74OeAAf8f0AnoD3QF7qni/bWJocK+4dmMF4DJQCvgb8AlVWznp8C/gJZAF+D34XaaAFOBvwLtgCuBP5pZgbtPBJ4E7gvPeFxUxfZFJEkp+UuqagNscffSCtZtCNeXm+Hur7p7GfAEMPgYPu8zd/+9u5e6+353X+7uU9292N03A/cDo6t4f21iqKzvCCAT+F14puN5YHYV2ykhuAzSyd0PuPuMsP3LwCp3fyz8Pu8DzwGXVfMbiEgDoeQvqWoL0KaS6+8dw/XlimKe7wNyjuG6/drYF2bW3syeMrP1ZrYL+AtH7nAcrTYxVNa3E7Dej5yt64i4jvI9gjMUs8PLB+PD9u7AcDPbUb4QnOrvUMW2RKQBUfKXVPUeUAx8NbbRzJoCFwDT6vjzjp4e8xdh2yB3b04wxsDq+DOPtgHobGaxn9O1ss7uXuTuE9y9E/BNglP7vQh2GN5y9xYxS1N3v7n8rXH7BiJSL5T8JSW5+06CAX+/N7PzzSzLzPKAZ4B1BKfL46kZsAfYaWadCe44iLf3gDLgNjPLNLMxwLDKOpvZZWbWJXy5nSCpR4FXgD5m9o3wd8sys1PMrH/YdyPQI35fQ0TiTclfUpa73wf8APg1sAuYRXBUe7a7F8f5438MnAzsBP7BUQMP48HdDxKc6bge2EFwtuEVgjMgFTkFmGVmewgGDn7L3Ve4+27giwQD/T4juMxwL9AofN+jQEF4SeDFeH0fEYkfO/LyoIikEjObBfzJ3R9LdCwikjx05C+SQsxstJl1CE/7jwNOBF5LdFwiklxUiUwktfQlGNfQhKDuwKXuviGxIYlIstFpfxERkTSj0/4iIiJpJu1O+7dp08bz8vISHYaISIMyb968Le7eNtFxSN1Iu+Sfl5fH3LlzEx2GiEiDYmarEx2D1B2d9hcREUkzSv4iIiJpRslfREQkzSj5i4iIpBklfxERkTQTt+RvZjlmNtvMFoRzhf84bM83s1lmttzMnjaz7LC9Ufh6ebg+L2Zb3w/bPzGz82Lazw/blpvZ3fH6LiIiIqkknkf+xcBZ7j4YGAKcb2YjCGYHe8DdexFMI3p92P96YHvY/kDYDzMrIJhdbABwPsGc4xlmlgH8gWBu9gLga2FfERERqULc7vP3oG7wnvBlVrg4cBbw9bB9CnAP8BAwJnwO8CzwoJlZ2P5UOAXrSjNbzuE5ype7+woAM3sq7Ls4Ll9o1p9h75aq+2TlQJdToHMhZJ8QlzBERESOV1yL/IRH5/OAXgRH6Z8CO9y9NOyyDugcPu9MMNc67l5qZjuB1mH7zJjNxr5n7VHtwyuJ40bgRoBu3bod25eZ+xhsXlJNp3CehEgWdB4K3UdC99Og23Bo1OzYPldERKSOxTX5u3sZMMTMWgAvAP3i+XlVxDERmAhQWFh4bDMZ3Tqz+j4HdsKaWbD6nWB593cw436wCHQcHOwIdD8Nuo2AE1odUxgiIiLHq17K+7r7DjN7EzgVaGFmmeHRfxdgfdhtPdAVWGdmmUAusDWmvVzseyprT4ycXOjzxWABOLgX1s2BVe/A6ndh9sPw3oOAQfsB4ZmB8OxA03YJDV1ERNJH3JK/mbUFSsLE3xg4l2AQ35vApcBTwDjgpfAtL4ev3wvXv+HubmYvA381s/uBTkBvYDZgQG8zyydI+ldyeCxBcshuAj3ODBaAkgPw2fxwZ+AdeP9JmD0xWNe6N+SFZwa6j4TcLomJWUREUl48j/w7AlPC6/4R4Bl3f8XMFgNPmdnPgPeBR8P+jwJPhAP6thEkc9x9kZk9QzCQrxS4NbycgJndBrwOZACT3H1RHL/P8cvKOXy0z51QVgIbFgQ7AqvegYUvwLzJQd8W3YMdgbxwZ6BlPpglMnoREUkRFgzKTx+FhYWetLP6Rctg46LDYwZWvwv7tgbrmnU6vOOQNwra9NHOgIjUGzOb5+6FiY5D6kbaTemb1CIZ0PHEYBlxM7jD5k9g9YxgR2DVDFj4bND3hDaHxwt0HxmMIYhkJDZ+ERFpEJT8k5kZtOsXLKfcEOwMbFsR7AiUnx34+OWgb04udDs13CEYFexAZGQlNn4REUlKSv4NiRm07hksJ38jaNux9sidgaWvBe1ZTYL6AuU7A51PhsxGiYtdRESShpJ/Q9eiK7S4AgZfEbzevfHweIHV78IbPwvaMxoF1QfzTgvGDOSdrjEDIiJpSgP+Ut2+bbDmvcO3FxZ9CB6FC+6D4d9MdHQi0kBowF9q0ZF/qjuhFfT7UrAAHNgFf70c3vkdFI7XuAARkTQUz1n9JBnlNIdRd8CudbDohURHIyIiCaDkn456nQtt+gZzD6TZZR8REVHyT0+RCIy8HYo+ghX/SXQ0IiJSz5T809WJl0OTdvDu7xMdiYiI1DMl/3SV2SgY7f/pNChamOhoRESkHin5p7PC8UExoPceTHQkIiJSj5T809kJrYJKgR/9HXauT3Q0IiJST5T8092IW4KiP7P+lOhIRESknij5p7uW3aHgYpg3OSgAJCIiKU/JX4Lb/op3wfwpiY5ERETqgZK/BDP+5Z0OMx+CspJERyMiInGm5C+BkbfDrvWw8PlERyIiInGm5C+BXudC235B0R+V/BURSWlK/hKIRODU22DjR7DizURHIyIicaTkL4edeDk0ba+SvyIiKU7JXw47VPL3DZX8FRFJYUr+cqTykr86+hcRSVlK/nKkxi3h5Gtg4bMq+SsikqLilvzNrKuZvWlmi81skZl9K2y/x8zWm9kH4XJhzHu+b2bLzewTMzsvpv38sG25md0d055vZrPC9qfNLDte3yetjLg5GPE/66FERyIiInEQzyP/UuC77l4AjABuNbOCcN0D7j4kXF4FCNddCQwAzgf+aGYZZpYB/AG4ACgAvhaznXvDbfUCtgPXx/H7pI+W3WHAxTB3MhzYmehoRESkjsUt+bv7BnefHz7fDXwMdK7iLWOAp9y92N1XAsuBYeGy3N1XuPtB4ClgjJkZcBbwbPj+KcDF8fk2aWjk7XBwN8xTyV8RkVRTL9f8zSwPOAmYFTbdZmYfmtkkM2sZtnUG1sa8bV3YVll7a2CHu5ce1V7R599oZnPNbO7mzZvr4BulgU4nHS75W3ow0dGIiEgdinvyN7OmwHPAt919F/AQ0BMYAmwAfhPvGNx9orsXunth27Zt4/1xqWPkf8Huz2DRC4mORERE6lBck7+ZZREk/ifd/XkAd9/o7mXuHgUeJjitD7Ae6Brz9i5hW2XtW4EWZpZ5VLvUld7lJX9/p5K/IiIpJJ6j/Q14FPjY3e+Pae8Y0+0SoLyazMvAlWbWyMzygd7AbGAO0Dsc2Z9NMCjwZXd34E3g0vD944CX4vV90pJZcO1/40KV/BURSSHxPPI/DfgGcNZRt/XdZ2YfmdmHwBeAOwDcfRHwDLAYeA24NTxDUArcBrxOMGjwmbAvwF3Ad8xsOcEYgEfj+H3S06DLoGkHeOd3iY5ERETqiHmanc4tLCz0uXPnJjqMhmX6/TDtx3DTDOgwKNHRiEgCmNk8dy9MdBxSN1ThT6pXeJ1K/oqIpBAlf6le45YwdBwsfA52rkt0NCIicpyU/KVmDpX8/VOiIxERkeOk5C8106IbDLhEJX9FRFKAkr/U3MjbVPJXRCQFKPlLzankr4hISlDyl9o57Vthyd/nEx2JiIgcIyV/qZ1e50Db/kHRnzSrESEikiqU/KV2ykv+bloEn76R6GhEROQYKPlL7Q26NCj5q6I/IiINkpK/1F5mIxhxUzDZz4YPEx2NiIjUkpK/HJuh10F2U3jvwURHIiIitaTkL8emcQs4+RqV/BURaYCU/OXYlZf8nflQoiMREZFaUPKXY1de8nfeFJX8FRFpQJT85fiMvD0s+Ts50ZGIiEgNKfnL8ek0BPLPgJl/UslfEZEGQslfjt/IsOTvwucSHYmIiNSAkr8cv15nQ7uCoOiPSv6KiCQ9JX85fmZw6m1hyd9piY5GRESqoeQvdWPQZdCso0r+iog0AEr+Ujcys2H4N2HFf2DDgkRHIyIiVVDyl7pTXvL3XZX8FRFJZkr+Uncat4CTx6nkr4hIkotb8jezrmb2ppktNrNFZvatsL2VmU01s2XhY8uw3czsd2a23Mw+NLOTY7Y1Luy/zMzGxbQPNbOPwvf8zswsXt9HamjEzcGjSv6KiCSteB75lwLfdfcCYARwq5kVAHcD09y9NzAtfA1wAdA7XG4EHoJgZwH4ETAcGAb8qHyHIewzIeZ958fx+0hNtOgKA78aVPzbvyPR0YiISAXilvzdfYO7zw+f7wY+BjoDY4ApYbcpwMXh8zHA4x6YCbQws47AecBUd9/m7tuBqcD54brm7j7T3R14PGZbkkgjb4eDe1TyV0QkSdXLNX8zywNOAmYB7d19Q7iqCGgfPu8MrI1527qwrar2dRW0V/T5N5rZXDObu3nz5uP6LlIDHQdD/miYpZK/IiLJKDPeH2BmTYHngG+7+67Yy/Lu7mYW95Jw7j4RmAhQWFioEnT1YeR/wZNjYeGzMOTriY5GQnuKSzlYGqU0GqUs6pSWefAYdUqj0SNel4Vth16XhX3K1x3R93B7SdmRr4/sH6Xk0LYq6Re2Z0YiNMqMkJOVQU5WhEaZwWNOVsah9kYxz3MyIzQKH4N1EXIyM47snxkhEtHQIJG4Jn8zyyJI/E+6+/Nh80Yz6+juG8JT95vC9vVA15i3dwnb1gNnHtX+n7C9SwX9JRnElvwd/LWgCqDUm/0Hy1i2aTdLinbzSbgsKdrNlj3F9RpHxCAzEiEjYmRGjIyM8DFiZEYiZGbY4XWRyKF1GRGjNFpGcUkZB0rKKC6NcqCkjAMlUQ6Ulh1XFensjAiNKtmZOGInIzMjpl8lfbIyyM6IkJUZIStiZGUG3yErI0J2zPNgsbBf8DwjYmiMsiRKtcnfzNoCdwEFQE55u7ufVc37DHgU+Njd749Z9TIwDvhl+PhSTPttZvYUweC+neEOwuvAL2IG+X0R+L67bzOzXWY2guBywjWAysslC7Pg2v+LNwclf3udk+iIUlJZ1Fm1de+hBP9J0W4+2bibVVv3HkqQjTIj9GnfjDP7tqVn26Y0zoqQmXE40QYJOOZ1xI5cH5Osy/tnlr8+IpkfldTN4nKU7R6cXThQWkZxSTTcOQh2DI5+PHrH4ej24pKyw9sJ1+3cX/K59xaXRDlYFq3z75Id7hRkxu4gHPEY/JZZGRGyY57Hri9/nhmJkJVpQb/wefmORvlOxyUndyYrQ3d4S82O/J8Enga+BNxEkLBrcuH8NOAbwEdm9kHY9gOCpP+MmV0PrAYuD9e9ClwILAf2AdcBhEn+p8CcsN9P3H1b+PwWYDLQGPhnuEiyGHgpTPsJvPM7Jf/j5O5s3l186Eh+SdFuPtm4i2Ub91BcGiQlM8hr3YS+7ZvxlcGd6NehGX07NKN76yZkpNCpbjMjO9PIzozEHI7EXzTqh3cGyncoSss4WBqlpMwpKQsum5SUBTsK5c+D5cjnpeHzgzHPS6JOSemRz0uj4fZKo+wvKaPkwJHbKi3z8LOC9oNhe2VnRsac1Kn+fjBJaubVnD8zs3nuPtTMPnT3E8O2Oe5+Sr1EWMcKCwt97ty5iQ4jfcz4Lfz7R/DNt4OBgFKtPcWlMUfyu1hStJulG3ezfV/JoT5tmzUKknv7IMH369CcXu2a0jg7I4GRS7Ioi35+Z+NgWZTOLRof86WGMBcU1nGokiA1OfIv/4uzwcy+BHwGtIpfSJJShl4Lb/8quPY/9pFER5NUSsqirNi8lyVFu444Zb9u+/5DfZpkZ9CnQzPOH9iBPjGJvlWT7ARGLskuGDcRjFUQqUhNkv/PzCwX+C7BNfXmwLfjGpWkjsYtgh2AmQ/B2T8KigClGXdn/Y79h5J7eaL/dPMeSsqCM28ZEaNHmyYM6dqCK0/pSt8OzenXoRmdWzTW6HQRqXM1Sf7b3X0nsBP4AoCZnRbXqCS1DL8pSP4zH4Lzf5HoaOJq576S4Eh+4+GR9kuLdrO7uPRQn065OfTt0Iwz+7Y7dF2+R9smNMrUUZqI1I+aJP/fAyfXoE2kYi26wsCxMH8KjP5ecDYgRew7WMpz89bx7483saRoFxt3Hb6VrnlOJv06NGfMSZ0OHcn3ad+M3MZZCYxYRKSK5G9mpwIjgbZm9p2YVc0BHaJI7Yy8HT56Jij5O6rhXzX6bMd+pry3ir/NWsOuA6X0ateUkT3b0LdD+XX5ZnRonqP7uEUkKVV15J8NNA37NItp3wVcGs+gJAV1PBF6nBmU/B1xC2Q2zAFr89dsZ9KMlfxzYRHuzgUDOzJ+VB4nd2upRC8iDUalyd/d3wLeMrPJ7r66HmOSVDXydvhLwyv5W1IW5bWFRTw6YyUfrN1Bs5xMrh+VzzWndqdLyxMSHZ6ISK3V5Jr/PjP7FTCAWlT4E/mcnmdDuwENpuTvzn0l/G3OGqa8u4oNOw+Q1/oEfvyVAVw6tAtNGsV9WgwRkbipTYW/L1O7Cn8iRzpU8vcmWD4Neidn1b9PN+/hsXdW8ty89ewvKWNkz9b8dMxAzurXTrfdiUhKqEnyb+3uj5rZt2IuBcyp9l0iFRk4Nij5++7/JlXyd3feWb6VR2es4M1PNpOdEWHMkE6MH5VP/47NEx2eiEidUoU/qV+Z2TDiJpj6Q/jsA+g0JKHhHCgp48X31zPpnZUs3biHNk2z+fY5vblqeHfaNmuU0NhEROLlWCv83RHXqCS1Db0W3voVvPdgwkr+btp1gCdmrubJWWvYtvcg/Ts259eXDeaiwR1VbEekhubNm9cuMzPzEWAgoOkCk0cUWFhaWnrD0KFDN1XUodrk7+6vhE8PVfgTOS45uTB0XFjy94fQolu9ffTC9TuZNGMl//fhZ5RGnbP7tef6UfmM6NFKt+qJ1FJmZuYjHTp06N+2bdvtkUik6lnipN5Eo1HbvHlzQVFR0SPAVyrqU1WRn98Dlf7HdPf/Ov4QJW2NuDm453/mn+Je8rcs6kxdvJFJ76xk9sptNMnO4Krh3bl2ZB55bZrE9bNFUtxAJf7kE4lEvG3btjuLiooGVtanqiP/8nlvTwMKCEb8A1wGLK6bECVt5XaBAV+Na8nf3QdKeGbuOia/u5K12/bTuUVj/udL/bmssKtK7IrUjYgSf3IK/7tUeimmqiI/UwDM7GZglLuXhq//BEyv4zglHR0q+fsYjKq7YSRrtu5j8rureGbuWvYUl1LYvSU/uKA/5xa0JzNDlyVFJHlFo1HGjx/f9Y033sjNycmJTpo0adWoUaP2Hd1v2LBhfTdt2pSVk5MTBZg2bdrSzp07l35+ixWryYC/lgSD/LaFr5uGbSLHp7zk78zykr/HPrre3Zm9chuT3lnJ1MUbiZjx5RM7ct1p+QzumjoTCYlI7ZWWlpKZmbjCXJs3b85o27ZtWU36/v3vf89dsWJFzqpVqxa++eabTW655ZZuH3744ZKK+j7++OMrzjjjjM/tGNRETQ6Dfgm8b2aTzWwKMB9I7XlZpf6M/C/YUwQfPXtMbz9YGuX5+eu46MEZXDFxJrNWbuPmM3sy466z+O2VJynxi6S4c845p+eAAQP69+rVa8Cvf/3rNuXtJ5xwwkkTJkzo0rdv34Jp06Y1feCBB9rk5eUNHDRoUP8rr7yy+zXXXNMNYOzYsXlXXXVVt8GDB/fr0qXLoFdeeaXZZZddltejR48BY8eOzSvf3lVXXdVt4MCB/Xv16jXgjjvu6ASwdevWjLy8vIELFixoBHDRRRfl/+Y3v2lzVIjccMMN3UaMGNHnoYcearVv374qRxa/9NJLLa666qqtkUiEs88+e++uXbsyV69eXefXKWsy2v8xM/snMDxsusvdi+o6EElTPc+C9gODkr9Dvl7jkr9b9xTz11lreHzmajbvLqZXu6b84pJBXHJSZxpn61Y9kfp257MLui4t2l2nk1306dBs368uHby2qj5PPvnkqvbt25ft2bPHTjrppIKrr756e4cOHcr2798fGT58+N6HH3543apVq7LGjx+fP3/+/MUtWrSIjhw5ss+AAQP2l29j586dme+///6Sv/71ry2uvPLKXm+88caSoUOH7j/xxBP7v/vuu41Hjhy5//7771/fvn37stLSUkaOHNl31qxZjYcPH77/gQceWDNu3Lj8W265ZeOOHTsyv/vd7245OsaXXnpp5fTp00+YOHFim1/84hedzjrrrJ033XTTllNPPXX/0X03bNiQlZeXd7D8dceOHQ+uXr06q3v37iVH973hhhvyIpEIF1100fZ77713QyRS88uaNerp7kXu/lK4KPFL3Skv+bv5Y1j+72q7f1K0m7uf+5CRv3yD30xdSkHH5kwZP4ypd5zB14d3U+IXSTP33ntv+759+xYMHTq0f1FRUdaiRYtyADIyMrj22mu3A0yfPr3J8OHDd7dv376sUaNGfskll2yP3caXvvSlHZFIhJNPPnlf69atS4YNG7Y/IyODPn367P/0008bAUyZMqVVQUFB/4KCgoJly5blLFiwIAfgkksu2dW/f//93/ve97pPnjx5VWVxnn766fueeOKJNZ988smiXr16FY8ePbr/Pffc0/5Yv/fTTz+9YunSpYvfe++9Je+++27TP/7xj61r837NTiKJN+Cr8O8fw7u/g97nfm51NOq8tXQzk95ZyfRlW8jJijB2aBeuG5lH7/bNKtigiNS36o7Q4+GVV15p9tZbbzWbO3fukmbNmkWHDRvWd//+/RGA7OzsaE2v8+fk5DgEOwzZ2dmH7l6IRCKUlpbakiVLsh988MH28+bN+7ht27ZlY8eOzTtw4EAEoKysjKVLl+bk5OREt27dmtmzZ8/PHaEDlJSU8Mwzz+Q+9thjbVavXp1z5513fjZhwoStR/fr2LFjyapVqw7Neb5hw4bsio768/PzSwBatmwZveKKK7bNnj27CfC57VVGQ58l8TKzg/v+V74dlPwN7TtYyhMzV3POA29x3eQ5LN24mzvP68t7d5/NLy4ZpMQvkuZ27NiRkZubW9asWbPo+++/n7NgwYIKC3eMGjVq76xZs5pt3rw5o6SkhJdeeqlWg9a3b9+e0bhx42irVq3K1q5dm/mf//wnt3zdT37yk/Z9+vQ5MHny5BXjx4/PKy4u/ty1y3vuuad9fn7+oOeee67lf//3f29ctmzZop///OdFFY3O/8pXvrLjySefbB2NRpk2bVqTZs2alR2d/EtKStiwYUMmQHFxsb366qu5AwcO/NwlhKpUu1tkZhXV8d/t7hXu3Ygck6Hj4K37gmv/lz5KNOpc8eeZfLR+J4O75PK/Vw7hwkEdydKteiISGjt27M6JEye27dGjx4AePXocGDx48N6K+uXn55fccccdGwoLC/vn5uaW9urV60Bubm6NRt8DnHrqqfsHDhy4r2fPngM7dux4cOjQoXsAFixY0OiJJ55oM2/evI9btmwZffbZZ3fffffdHR944IHPYt8/ZMiQfR9++OGiVq1aRav7rMsvv3znP/7xj9zu3bsPbNy4cfSRRx5ZVb6uX79+BUuWLFm8f//+yDnnnNO7pKTEotGonX766bu+853v1Gq2XXOvuj6Dma0CugLbAQNaAEXARmCCu8+rzQcmWmFhoc+dO7f6jlL/Xv9/gpK/3/qAN4tyuG7yHH46ZgBXj+iu0rsiCWZm89y9MLZtwYIFqwYPHvy5AW7JaOfOnZHc3NxoSUkJ5513Xq9rr712yzXXXLMj0XHF04IFC9oMHjw4r6J1NTmMmgpc6O5t3L01cAHwCnAL8MfK3mRmk8xsk5ktjGm7x8zWm9kH4XJhzLrvm9lyM/vEzM6LaT8/bFtuZnfHtOeb2ayw/Wkzy0YathE3BwMAZz7ExLdX0DE3hyuHdVPiF5Hjduedd3bq169fQZ8+fQZ069at+Oqrr07pxF+dmoyGGOHuE8pfuPu/zOzX7v5NM6uqKstk4EHg8aPaH3D3X8c2mFkBcCUwAOgE/NvM+oSr/wCcC6wD5pjZy+6+GLg33NZTYdXB64GHavB9JFnldoGBYymbO5lFe4Zw+4Wn6DS/iNSJiRMnrkt0DMmkJn9ZN5jZXWbWPVy+B2w0swyCaQMr5O5vc7gqYHXGAE+5e7G7rwSWA8PCZbm7r3D3g8BTwBgLDgXPAsorw0wBLq7hZ0kyG3k7GaX7GN/oP1w5rGuioxERSUk1Sf5fB7oAL4ZLt7AtA7j8GD7zNjP7MLwsUD7isjMQe5vIurCtsvbWwI7y+QZi2itkZjea2Vwzm7t5c63GREg9W5vdk+nRQVyf/S+aZVY7NkZERI5Btcnf3be4++3uflK43Obum+ifLa0AABsUSURBVN39oLsvr+XnPQT0BIYAG4DfHEPMtebuE9290N0L27ZtWx8fKcdo0jsreaTsyzQr2QIf/T3R4YiIpKRqk7+Z9TGziWb2LzN7o3w5lg9z943uXubuUeBhgtP6AOsJ7igo1yVsq6x9K9DCzDKPapcGbOe+Ep6es5bWg847XPK3mrtRRESk9mpy2v/vwPvA/wB3xiy1ZmYdY15eApTfCfAycKWZNTKzfKA3MBuYA/QOR/ZnEwwKfNmD+xPfBC4N3z8OeOlYYpLk8ZdZq9l3sIwJo3uGJX+XwLJ/JTosEZF6E41Gufbaa7t269ZtYJ8+fQpmzJhR4XwJw4YN65uXlzewX79+Bf369StYv359rSr21qRzqbvXehS9mf0NOBNoY2brgB8BZ5rZEMCBVcA3Adx9kZk9AywGSoFb3b0s3M5twOsEYwwmufui8CPuAp4ys58R7Jw8WtsYJXkUl5Yx+d1VnN67Df07Nod2Y+GNn8NTV8HAscFtgJ2GJDpMEWmAEj2lb2Uqmuo3mab0/T8zu8XMOppZq/Kluje5+9fcvaO7Z7l7F3d/1N2/4e6D3P1Ed/+Ku2+I6f9zd+/p7n3d/Z8x7a+6e59w3c9j2le4+zB37+Xul7l7ca2/vSSNl97/jM27i/nmGT2DhowsuO4fcMr1sOQVmDgaHrsQPv4/iNa4MJeIpLiGMKVvrPXr12f+8Ic/bN+7d+8Bjz322OdyadJM6UtwSh2OPNXvQI+6DkbSUzTqTJy+gv4dm3Nar5iJqVp0gwvuhS/8AOY/AbP+DE9fDS26w/Cb4KSrIad54gIXkcNevLUrmxbX6ZS+tCvYx8V/aPBT+paVlfHCCy80f+SRR9osW7as8dixY7e99tprSyuaBChppvR19/wKFiV+qTP/WbqJ5Zv2cOMZ+RVX88vJhZG3wX+9D5c/Ds07wevfh/sL4LXvw7aV9R+0iCSFhjCl77nnntvr1ltvzbvhhhu2LFu2bNF99923obLZ/2oqblP6mtlZ7v6GmX21ovXu/nxtgxWpSHkp3y+f2KnqjhmZUDAmWNbPD+YBmD0RZv0J+l4II26B7iODEsEiUr+qOUKPh4Yype9999237o9//GPb7373u91efPHFXRMmTNgyevToCq/VJ8OUvqPDx4sqWL5c0w8QqcqH63Ywc8U2xp+WX7tSvp1PhrEPw7cXwqg7YPU7MPnCYGzAgqeg9GD12xCRBq2hTOlbWFh4YNKkSWs/+eSTRaNHj979gx/8oHOfPn0Knn/++c9dt0z4lL7u/qPw8brabFCkNia+vYJmjTKPvZRv845w9g/h9P+GD58Ozga88E2Y+kM4ZQIUXgdNqhx/IyINVEOZ0rdcTk6OT5gwYfuECRO2L126NHvjxo2fy8HJNKVvI2AskEfMzoK7/6Q2H5QsNKVv8li7bR+jf/UmE07vwfcv7F83G3WHT9+AmX+E5f+GzBw48XIYfjO0L6ibzxBJQ5rSt+GpakrfmlwQeQnYCcwDdDud1JlHZ6wkYsZ1p+XX3UbNoNfZwbL5k+BMwIKnYP7j0OMLwbiAXudALUbFikjDd+edd3Z6++23mxcXF9vo0aN3aUrf6nVx9/PjHomklR37DvLM3LV8ZUgnOuTmxOdD2vaFi34bXBaYNxlmPwx/vQxa94YRN8Hgr0F2hZcIRSTFaErfI9Xk8OddMxsU90gkrTw5a01Qyvf0erhr9IRWcPp34NsfwthHoVEz+Md34f7+wdiAnfqbICLppSbJfxQwz8w+Cafi/cjMPox3YJK6ikvLeOydVZzRp21Qyre+ZGTBoEthwhsw/l/Q48xg8qDfngh/vw7Wzqm/WERSQzQajere2iQU/nepdF70mpz2v6DuwhGBF99fz5Y9xdxYH0f9FTGDbsODZceaoFbAvMdh0fPQ5ZRgHoH+Y4K6AiJSlYWbN28uaNu27c5IJKIpOJNENBq1zZs353J48rzPqarIT3N33wXsjkdwkp6iUefh6SspOLqUb6K06AZf/BmMvgs++BvMegieHQ/Nu8CwCTB0HDSu1S3BImmjtLT0hqKiokeKiooGUrMzyVI/osDC0tLSGyrrUOmtfmb2irt/2cxWEtTyjz214w21xK9u9UusN5ZsZPzkufz2iiFcfFLnRIfzedEoLHs9uFVw5duQdQIM+Xowl0Cb3omOTiRhKrrVTxquqor8fDl8rMP7sCTd/fmtFXTKzeFLJ3ZMdCgVi0Sg7wXBUvQRzPxTcJvgnEeg93nBJYEeZ6qEsIg0aDU6TWNmLc1smJmdUb7EOzBJPQvW7mDWym2MH1XLUr6J0mEQXPwHuGMRnPl9+Gw+PHExPDQy2CEoqVU1TRGRpFHtX2AzuwF4G3gd+HH4eE98w5JUNHF6UMr3ilOOsZRvojRtB2feHewEjPkjWARevh0eGABv/Bx2FyU6QhGRWqnJcOZvAacAM939C2bWD/hFfMOSVLN22z7++dEGJpzRg2Y5WYkO59hkNoKTrgrGAKyaHlQPfPtXMOMB6Hs+dBwM7QYEZYRzu6mKoIgkrZok/wPufsDMMLNG7r7EzPrGPTJJKY/OWElGxLhuZAoMITGD/DOCZeunMOvPsPSf8PH/He6T3RTa9Q+XcIeg3QBokgR3OIhI2qtJ8l9nZi2AF4GpZrYdWB3fsCSV7Nh3kKfnrOUrgzvHr5RvorTuCRfeFyzFu2HTEti0CDYuhk2L4eNXgvEB5Zq2h3YF0H5A+FgAbfpC9gmJ+w4iknaqTf7ufkn49B4zexPIBV6La1SSUp6ctYb9JWVMOCMFjvqr0qgZdD0lWMq5w56NsHFRsDOwcXGwczDnESg9EPSxCLTMP3x2oPyxVT5EMhLzXUQkpVWZ/M0sA1jk7v0A3P2teolKUsaBkqCU7+g+benXoR5L+SYLM2jWIVh6nX24PVoG21bGnCUIHz9+haCsBpDZOJicqPwsQbv+wfOm7XWroYgclyqTv7uXhTX9u7n7mvoKSlLHSx+EpXzPaJA1oeInkgFtegVLwZjD7Qf3weYlMWcJFsPyf8MHTx7u07jVkZcN2g2Adv2CMw8iIjVQk2v+LYFFZjYb2Fve6O5fiVtUkhKiUWfi2yso6NickT010K1Gsk+AzicHS6y9W468bLBxMbz/FyjZe7hPi+4xOwThuILWvYIJjSQ+ykqDyzfREigrXw4Gj9Hy56Xh40GIlh5eX963yvfWpF8tPvfuNcFdK5L2apL8/9+4RyEp6c1PNvHp5r3875VDMJ2mPj5N2hy+w6BcNAo7VsOmj48cZLjsX+BlQZ+MbGjTJ2ZwYR/IagyRLIhkhktGzPPwdUbW59uOfp1MolEoKw4KL5UeCJaSA1C6H0qPp72aPuW/czxEsoL/fhmZ4WN28NtnZAf/fTLC9ZGsIKE3anp4XWXvRf8OJVCT5H+hu98V22Bm9wJVXv83s0nAl4FN7j4wbGsFPA3kAauAy919uwWZ4X+BC4F9wLXuPj98zzjgf8LN/szdp4TtQ4HJQGPgVeBbXtlEBZIQf347KOV74aAkLeXb0EUiwaDAVvnQ78LD7aXFsGXpkWcJVr8DHz1Thx9uVe8cZGRWs/NQ3fqM4Gi1pkm7rPj4vktmDmTlBOMsMhsFO0iZOcGS0xwy23++vbx/Rph8j0jM1SThihL4Ea8zNa5D4qomyf9c4K6j2i6ooO1ok4EHgZj7nLgbmObuvzSzu8PXd4Xb6x0uw4GHgOHhzsKPgEKCUVDzzOxld98e9pkAzCJI/ucD/6zB95F68MHaHcxeuY3/+VL/hlHKN5VkNgpKE3cYdGT7/h2w7VMoDU8DR0uDgYeHnpcc9bqCPmUV9anoPVWsLysNEnh0byXvLwtiyciKSbRhUs7JDZPuUe2ZjWvWXlGSz8hWopW0U9WUvjcDtwA9zOzDmFXNgHeq27C7v21meUc1jwHODJ9PAf5DkPzHAI+HR+4zzayFmXUM+051921hTFOB883sP0Bzd58Ztj8OXIySf9J4ePoKmuVkcuWwbokORco1bgGdhyY6ChFJAlUd+f+VIJn+fwRH6OV2lyfjY9De3TeEz4uA9uHzzsDamH7rwraq2tdV0F4hM7sRuBGgWzclo3hbszUo5XvjGT1p2qgmJ5dERKQ+VTWl705gJ/C1eHywu7uZ1cs1enefCEwEKCws1LiAOJv0TlDK99qReYkORUREKlDfF2M3hqfzCR83he3rgdip3rqEbVW1d6mgXRJs+94ULuUrIpIi6jv5vwyMC5+PA16Kab/GAiOAneHlgdeBL5pZSzNrCXwReD1ct8vMRoR3ClwTsy1JoCdnrWZ/SZmK+oiIJLG4XZA1s78RDNhrY2brCEbt/xJ4xsyuJ5gc6PKw+6sEt/ktJ7jV7zoAd99mZj8F5oT9fhIz3uAWDt/q90802C/hDpSUMfnd1Yzu05a+HVRtTkQkWcUt+bt7ZWMFzj66IRzlf2sl25kETKqgfS4w8HhilLr14vtBKd9v6qhfRCSp6QZsqRPRqPPw9BUM6NScU1XKV0QkqSn5S514Y0lQyvfGM3qolK+ISJJT8pc6MXH6Cjq3aKxSviIiDYCSvxy38lK+152Wp1K+IiINgP5Sy3F7+G2V8hURaUiU/OW4rNm6j38u3MBVw7urlK+ISAOh5C/H5dEZK8iIGNedlpfoUEREpIaU/OWYbd97kGfmrmPMkM60b65SviIiDYWSvxyzv8xUKV8RkYZIyV+OyYGSMqa8t4oz+7alT3uV8hURaUiU/OWYvPD+erbsOciNp+uoX0SkoVHyl1orL+U7sLNK+YqINERK/lJr05ZsYsXmvUw4XaV8RUQaIiV/qbWH3w5K+X5JpXxFRBokJX+plffXbGf2qm2MH5VPpkr5iog0SPrrLbXy8PQVNM/J5IpTuiY6FBEROUZK/lJjq7fu5bWFRVw1QqV8RUQaMiV/qbFHZ6wkI2JcOzIv0aGIiMhxUPKXGglK+a7lYpXyFRFp8JT8pUaemLmaAyVRJqiUr4hIg6fkL9U6UFLGlHdX8QWV8hURSQlK/lKt5+evZ+vegzrqFxFJEUr+UqVo1Hlk+goGdc7l1B4q5SsikgqU/KVK05ZsYsWWvUw4Q6V8RURSRUKSv5mtMrOPzOwDM5sbtrUys6lmtix8bBm2m5n9zsyWm9mHZnZyzHbGhf2Xmdm4RHyXVDfx7U/p3KIxFw7skOhQRESkjiTyyP8L7j7E3QvD13cD09y9NzAtfA1wAdA7XG4EHoJgZwH4ETAcGAb8qHyHQerG/DXbmbNqO9erlK+ISEpJpr/oY4Ap4fMpwMUx7Y97YCbQwsw6AucBU919m7tvB6YC59d30Kns4bdVyldEJBUlKvk78C8zm2dmN4Zt7d19Q/i8CGgfPu8MrI1577qwrbL2zzGzG81srpnN3bx5c119h5S2euteXltUxNUjutNEpXxFRFJKov6qj3L39WbWDphqZktiV7q7m5nX1Ye5+0RgIkBhYWGdbTeVPTJ9JVmRiEr5ioikoIQc+bv7+vBxE/ACwTX7jeHpfMLHTWH39UDseecuYVtl7XKctu09yN/nreXikzrRTqV8RURSTr0nfzNrYmbNyp8DXwQWAi8D5SP2xwEvhc9fBq4JR/2PAHaGlwdeB75oZi3DgX5fDNvkOP0lLOV7w+kq6iMikooScdq/PfBCeM94JvBXd3/NzOYAz5jZ9cBq4PKw/6vAhcByYB9wHYC7bzOznwJzwn4/cfdt9fc1UpNK+YqIpL56T/7uvgIYXEH7VuDsCtoduLWSbU0CJtV1jOmsvJTvjWf0THQoIiISJ8l0q58kWGwp3xE9WiU6HBERiRMlfznk3x9vZMWWvdyoUr4iIilNyV8Omfj2Crq0bMwFKuUrIpLSlPwFgHmrtzN3tUr5ioikA/2VFwAemR6U8r28UKV8RURSnZK/sGqLSvmKiKQTJX/h0Rkq5Ssikk6U/NOcSvmKiKQfJf8098R7QSnfCSrlKyKSNpT809iBkjIef28VZ/VrR2+V8hURSRtK/mnsufnrwlK+OuoXEUknSv5pKijlu5ITu+QyPF+lfEVE0omSf5qa+vFGVm7Zy4TTVcpXRCTdKPmnqYdVyldEJG0p+achlfIVEUlv+sufZtydiW9/Sm7jLJXyFRFJU6rlmuLcnRVb9jJrxTZmr9zK7JXb+GznAW79Qk+V8hURSVP6659iolHnk427mb1yG7NXbmPWym1s2VMMQJumjRjeoxU392jNFTrqFxFJW0r+DVxpWZTFG3Yxe+U2Zq7YxpxV29i5vwSATrk5nN67DcPzWzEsvxX5bZpoZL+IiCj5NzQHS6N8tH4HM1cER/bzVm9nT3EpAHmtT+D8AR0YFib7rq1OSHC0IiKSjJT8k9yBkjLmr9l+6DT+/DXbOVASBaB3u6ZcfFInhuW3Znh+K9prYh4REakBJf8ks6e4lHmrtzN75VZmrdjGgnU7KClzzKCgY3O+Nqwbw/Nbc0peS1o3bZTocEVEpAFS8k+wnftKmLNqG7PCkfgLP9tFWdTJiBiDOucyflQ+w/NbMbR7K3IbZyU6XBERSQFK/vVsy57iI0biLynahTtkZ0YY0rUFt5zZk+H5rTmpWwvdiiciInHR4LOLmZ0P/C+QATzi7r9McEhH2LBz/6FEP2vFVj7dvBeAxlkZDO3ekjvO6cPw/FYM7tqCnKyMBEcrIiLpoEEnfzPLAP4AnAusA+aY2cvuvjgR8bg7a7ftZ9bKrcwKj+7XbNsHQLNGmRTmteSywq4My2/FoM65ZKm0roiIJECDTv7AMGC5u68AMLOngDFAnSf/G6bMYfXWfVX22bm/hE27g4I6LU/IYlh+K8aNzGN4fiv6d2xORkT32IuISOI19OTfGVgb83odMPzoTmZ2I3AjQLdu3Y7pg7q1akJ2ZtVH6jmZGZzUvSXD81vRq21TIkr2IiKShBp68q8Rd58ITAQoLCz0Y9nGDy8qqNOYREREEqWhX3ReD8QWqe8StomIiEglGnrynwP0NrN8M8sGrgReTnBMIiIiSa1Bn/Z391Izuw14neBWv0nuvijBYYmIiCS1Bp38Adz9VeDVRMchIiLSUDT00/4iIiJSS0r+IiIiaUbJX0REJM0o+YuIiKQZcz+mmjcNlpltBlYf49vbAFvqMJx4UZx1r6HEqjjrXkOJNd5xdnf3tnHcvtSjtEv+x8PM5rp7YaLjqI7irHsNJVbFWfcaSqwNJU5JDjrtLyIikmaU/EVERNKMkn/tTEx0ADWkOOteQ4lVcda9hhJrQ4lTkoCu+YuIiKQZHfmLiIikGSV/ERGRNKPkXwNmdr6ZfWJmy83s7kTHUxUzW2VmH5nZB2Y2N9HxlDOzSWa2ycwWxrS1MrOpZrYsfGyZyBjDmCqK8x4zWx/+ph+Y2YWJjDGMqauZvWlmi81skZl9K2xPxt+0sliT6nc1sxwzm21mC8I4fxy255vZrPDf/9Ph9OHJGOdkM1sZ83sOSWScktx0zb8aZpYBLAXOBdYBc4CvufvihAZWCTNbBRS6e1IVJTGzM4A9wOPuPjBsuw/Y5u6/DHeqWrr7XUkY5z3AHnf/dSJji2VmHYGO7j7fzJoB84CLgWtJvt+0slgvJ4l+VzMzoIm77zGzLGAG8C3gO8Dz7v6Umf0JWODuDyVhnDcBr7j7s4mKTRoOHflXbxiw3N1XuPtB4ClgTIJjanDc/W1g21HNY4Ap4fMpBAkhoSqJM+m4+wZ3nx8+3w18DHQmOX/TymJNKh7YE77MChcHzgLKE2rCf9Mq4hSpMSX/6nUG1sa8XkcS/uGK4cC/zGyemd2Y6GCq0d7dN4TPi4D2iQymGreZ2YfhZYGEn0qPZWZ5wEnALJL8Nz0qVkiy39XMMszsA2ATMBX4FNjh7qVhl6T49390nO5e/nv+PPw9HzCzRgkMUZKckn/qGeXuJwMXALeGp7GTngfXn5L16OUhoCcwBNgA/Cax4RxmZk2B54Bvu/uu2HXJ9ptWEGvS/a7uXubuQ4AuBGf9+iU4pAodHaeZDQS+TxDvKUArIKGXeyS5KflXbz3QNeZ1l7AtKbn7+vBxE/ACwR+wZLUxvB5cfl14U4LjqZC7bwz/2EaBh0mS3zS83vsc8KS7Px82J+VvWlGsyfq7Arj7DuBN4FSghZllhquS6t9/TJznh5dX3N2LgcdIot9Tko+Sf/XmAL3DEb/ZwJXAywmOqUJm1iQcUIWZNQG+CCys+l0J9TIwLnw+DngpgbFUqjyZhi4hCX7TcNDXo8DH7n5/zKqk+00rizXZflcza2tmLcLnjQkG+X5MkFwvDbsl/DetJM4lMTt9RjAuIeH/n0ry0mj/GghvQfotkAFMcvefJzikCplZD4KjfYBM4K/JEquZ/Q04k2Da0Y3Aj4AXgWeAbgTTLF/u7gkdbFdJnGcSnJp2YBXwzZjr6glhZqOA6cBHQDRs/gHBtfRk+00ri/VrJNHvamYnEgzoyyA4MHrG3X8S/rt6iuBU+vvA1eHRdbLF+QbQFjDgA+CmmIGBIkdQ8hcREUkzOu0vIiKSZpT8RURE0oySv4iISJpR8hcREUkzSv4iIiJpRslfJMmZ2Zlm9kqi4xCR1KHkLyIikmaU/EXqiJldHc6z/oGZ/TmcfGVPOMnKIjObZmZtw75DzGxmOAnLC+WT2phZLzP7dzhX+3wz6xluvqmZPWtmS8zsybCKG2b2SzNbHG4nKabGFZHkp+QvUgfMrD9wBXBaOOFKGXAV0ASY6+4DgLcIKgYCPA7c5e4nElS+K29/EviDuw8GRhJMeAPBTHjfBgqAHsBpZtaaoCzugHA7P4vvtxSRVKHkL1I3zgaGAnPCqVbPJkjSUeDpsM9fgFFmlgu0cPe3wvYpwBnhvAyd3f0FAHc/4O77wj6z3X1dOAnOB0AesBM4ADxqZl8FyvuKiFRJyV+kbhgwxd2HhEtfd7+ngn7HWk87tpZ8GZAZzjE/DHgW+DLw2jFuW0TSjJK/SN2YBlxqZu0AzKyVmXUn+DdWPiPc14EZ7r4T2G5mp4ft3wDecvfdwDozuzjcRiMzO6GyDzSzpkCuu78K3AEMjscXE5HUk1l9FxGpjrsvNrP/Af5lZhGgBLgV2AsMC9dtIhgXAMHUsH8Kk/sK4Lqw/RvAn83sJ+E2LqviY5sBL5lZDsGZh+/U8dcSkRSlWf1E4sjM9rh700THISISS6f9RURE0oyO/EVERNKMjvxFRETSjJK/iIhImlHyFxERSTNK/iIiImlGyV9ERCTN/P8DQ+Cz43uREAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "outputId": "39eee94b-799d-4eaf-aaa8-98868243f178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "df_test"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>356</td>\n",
              "      <td>3031</td>\n",
              "      <td>692</td>\n",
              "      <td>5921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>492</td>\n",
              "      <td>3673</td>\n",
              "      <td>581</td>\n",
              "      <td>5254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1128</td>\n",
              "      <td>8872</td>\n",
              "      <td>3421</td>\n",
              "      <td>2631</td>\n",
              "      <td>1124</td>\n",
              "      <td>2824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>5191</td>\n",
              "      <td>4809</td>\n",
              "      <td>5821</td>\n",
              "      <td>1971</td>\n",
              "      <td>756</td>\n",
              "      <td>1452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>6636</td>\n",
              "      <td>3364</td>\n",
              "      <td>6665</td>\n",
              "      <td>1789</td>\n",
              "      <td>536</td>\n",
              "      <td>1010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>5987</td>\n",
              "      <td>4013</td>\n",
              "      <td>6779</td>\n",
              "      <td>1705</td>\n",
              "      <td>516</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>6413</td>\n",
              "      <td>3587</td>\n",
              "      <td>7152</td>\n",
              "      <td>1651</td>\n",
              "      <td>476</td>\n",
              "      <td>721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>6489</td>\n",
              "      <td>3511</td>\n",
              "      <td>7315</td>\n",
              "      <td>1546</td>\n",
              "      <td>429</td>\n",
              "      <td>710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>6208</td>\n",
              "      <td>3792</td>\n",
              "      <td>7272</td>\n",
              "      <td>1568</td>\n",
              "      <td>413</td>\n",
              "      <td>747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0       0             0  ...                    692                    5921\n",
              "1       1             0  ...                    581                    5254\n",
              "2       6          1128  ...                   1124                    2824\n",
              "3      11          5191  ...                    756                    1452\n",
              "4      16          6636  ...                    536                    1010\n",
              "5      21          5987  ...                    516                    1000\n",
              "6      26          6413  ...                    476                     721\n",
              "7      31          6489  ...                    429                     710\n",
              "8      36          6208  ...                    413                     747\n",
              "\n",
              "[9 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "outputId": "be69ef5d-a2dc-4664-edef-5313563f2328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLfaVcgE7pK",
        "outputId": "7e5d91f7-c4b9-4d89-9e82-d8e744980a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29812\n",
            "total train set images 30000\n",
            "focus_true_pred_true 23762 =============> FTPT : 79 %\n",
            "focus_false_pred_true 6050 =============> FFPT : 20 %\n",
            "focus_true_pred_false 81 =============> FTPF : 0 %\n",
            "focus_false_pred_false 107 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  19111\n",
            "argmax_less_than_half ==================>  10889\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cSh5sGfFAlg",
        "outputId": "b44de9bd-f25f-42f8-c908-a8d63d40a6b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 88 %\n",
            "total correct 8884\n",
            "total train set images 10000\n",
            "focus_true_pred_true 7339 =============> FTPT : 73 %\n",
            "focus_false_pred_true 1545 =============> FFPT : 15 %\n",
            "focus_true_pred_false 441 =============> FTPF : 4 %\n",
            "focus_false_pred_false 675 =============> FFPF : 6 %\n",
            "argmax_more_than_half ==================>  6077\n",
            "argmax_less_than_half ==================>  3923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "outputId": "b62eb0e9-9a0a-4520-c46d-9d74400fdf87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "                                            correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29801\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "outputId": "5083e6bb-6f8b-49f5-efbb-3701f434baff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 89 %\n",
            "total correct 8926\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}