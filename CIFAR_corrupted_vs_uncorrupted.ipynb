{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR corrupted vs uncorrupted.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olq-MKcdmOnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    '''expand + depthwise + pointwise + squeeze-excitation'''\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
        "        super(Block, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        planes = expansion * in_planes\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, groups=planes, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride == 1 and in_planes != out_planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1,\n",
        "                          stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_planes),\n",
        "            )\n",
        "\n",
        "        # SE layers\n",
        "        self.fc1 = nn.Conv2d(out_planes, out_planes//16, kernel_size=1)\n",
        "        self.fc2 = nn.Conv2d(out_planes//16, out_planes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        shortcut = self.shortcut(x) if self.stride == 1 else out\n",
        "        # Squeeze-Excitation\n",
        "        w = F.avg_pool2d(out, out.size(2))\n",
        "        w = F.relu(self.fc1(w))\n",
        "        w = self.fc2(w).sigmoid()\n",
        "        out = out * w + shortcut\n",
        "        return out\n",
        "\n",
        "\n",
        "class EfficientNet(nn.Module):\n",
        "    def __init__(self, cfg, num_classes=10):\n",
        "        super(EfficientNet, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layers = self._make_layers(in_planes=32)\n",
        "        self.linear = nn.Linear(cfg[-1][1], num_classes)\n",
        "\n",
        "    def _make_layers(self, in_planes):\n",
        "        layers = []\n",
        "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
        "            strides = [stride] + [1]*(num_blocks-1)\n",
        "            for stride in strides:\n",
        "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
        "                in_planes = out_planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layers(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def EfficientNetB0():\n",
        "    # (expansion, out_planes, num_blocks, stride)\n",
        "    cfg = [(1,  16, 1, 2),\n",
        "           (6,  24, 2, 1),\n",
        "           (6,  40, 2, 2),\n",
        "           (6,  80, 3, 2),\n",
        "           (6, 112, 3, 1),\n",
        "           (6, 192, 4, 2),\n",
        "           (6, 320, 1, 2)]\n",
        "    return EfficientNet(cfg)\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = EfficientNetB0()\n",
        "    x = torch.randn(2, 3, 32, 32)\n",
        "    y = net(x)\n",
        "    print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khlZDWDZm6ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "\n",
        "\n",
        "# _, term_width = os.popen('stty size', 'r').read().split()\n",
        "term_width = 80\n",
        "term_width = int(term_width)\n",
        "\n",
        "TOTAL_BAR_LENGTH = 65.\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_ubk0aCmSD7",
        "colab_type": "code",
        "outputId": "ad6d696c-3a72-4f35-f6c6-eddd2648351e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "# from models import *\n",
        "# from utils import progress_bar\n",
        "\n",
        "\n",
        "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "# parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "# net = VGG('VGG19')\n",
        "# net = ResNet18()\n",
        "# net = PreActResNet18()\n",
        "# net = GoogLeNet()\n",
        "# net = DenseNet121()\n",
        "# net = ResNeXt29_2x64d()\n",
        "# net = MobileNet()\n",
        "# net = MobileNetV2()\n",
        "# net = DPN92()\n",
        "# net = ShuffleNetG2()\n",
        "# net = SENet18()\n",
        "# net = ShuffleNetV2(1)\n",
        "net = EfficientNetB0()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "# if args.resume:\n",
        "#     # Load checkpoint.\n",
        "#     print('==> Resuming from checkpoint..')\n",
        "#     assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "#     checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "#     net.load_state_dict(checkpoint['net'])\n",
        "#     best_acc = checkpoint['acc']\n",
        "#     start_epoch = checkpoint['epoch']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr, momentum=0.9, weight_decay=5e-4)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "#         progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    print(\"train accuracy \", correct/total)\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "#             progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "#                 % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    print(\"test accuracy \", correct/total)\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+200):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "\n",
            "Epoch: 0\n",
            "train accuracy  0.37968\n",
            "test accuracy  0.4732\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            "train accuracy  0.50992\n",
            "test accuracy  0.5451\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            "train accuracy  0.57264\n",
            "test accuracy  0.6083\n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            "train accuracy  0.61622\n",
            "test accuracy  0.6581\n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            "train accuracy  0.65184\n",
            "test accuracy  0.6661\n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            "train accuracy  0.67342\n",
            "test accuracy  0.6911\n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            "train accuracy  0.70048\n",
            "test accuracy  0.7227\n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            "train accuracy  0.71724\n",
            "test accuracy  0.7375\n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            "train accuracy  0.73728\n",
            "test accuracy  0.7448\n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            "train accuracy  0.74746\n",
            "test accuracy  0.7484\n",
            "Saving..\n",
            "\n",
            "Epoch: 10\n",
            "train accuracy  0.7626\n",
            "test accuracy  0.7525\n",
            "Saving..\n",
            "\n",
            "Epoch: 11\n",
            "train accuracy  0.7736\n",
            "test accuracy  0.7841\n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            "train accuracy  0.78388\n",
            "test accuracy  0.7773\n",
            "\n",
            "Epoch: 13\n",
            "train accuracy  0.78936\n",
            "test accuracy  0.7809\n",
            "\n",
            "Epoch: 14\n",
            "train accuracy  0.8013\n",
            "test accuracy  0.7874\n",
            "Saving..\n",
            "\n",
            "Epoch: 15\n",
            "train accuracy  0.80726\n",
            "test accuracy  0.7995\n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            "train accuracy  0.81646\n",
            "test accuracy  0.8135\n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            "train accuracy  0.8225\n",
            "test accuracy  0.8095\n",
            "\n",
            "Epoch: 18\n",
            "train accuracy  0.82428\n",
            "test accuracy  0.8144\n",
            "Saving..\n",
            "\n",
            "Epoch: 19\n",
            "train accuracy  0.82992\n",
            "test accuracy  0.818\n",
            "Saving..\n",
            "\n",
            "Epoch: 20\n",
            "train accuracy  0.83744\n",
            "test accuracy  0.8187\n",
            "Saving..\n",
            "\n",
            "Epoch: 21\n",
            "train accuracy  0.84082\n",
            "test accuracy  0.8165\n",
            "\n",
            "Epoch: 22\n",
            "train accuracy  0.84266\n",
            "test accuracy  0.8242\n",
            "Saving..\n",
            "\n",
            "Epoch: 23\n",
            "train accuracy  0.84892\n",
            "test accuracy  0.8187\n",
            "\n",
            "Epoch: 24\n",
            "train accuracy  0.85214\n",
            "test accuracy  0.8225\n",
            "\n",
            "Epoch: 25\n",
            "train accuracy  0.85348\n",
            "test accuracy  0.8362\n",
            "Saving..\n",
            "\n",
            "Epoch: 26\n",
            "train accuracy  0.85612\n",
            "test accuracy  0.8234\n",
            "\n",
            "Epoch: 27\n",
            "train accuracy  0.86112\n",
            "test accuracy  0.8421\n",
            "Saving..\n",
            "\n",
            "Epoch: 28\n",
            "train accuracy  0.86402\n",
            "test accuracy  0.8359\n",
            "\n",
            "Epoch: 29\n",
            "train accuracy  0.86606\n",
            "test accuracy  0.8451\n",
            "Saving..\n",
            "\n",
            "Epoch: 30\n",
            "train accuracy  0.86548\n",
            "test accuracy  0.8367\n",
            "\n",
            "Epoch: 31\n",
            "train accuracy  0.86958\n",
            "test accuracy  0.8328\n",
            "\n",
            "Epoch: 32\n",
            "train accuracy  0.8743\n",
            "test accuracy  0.846\n",
            "Saving..\n",
            "\n",
            "Epoch: 33\n",
            "train accuracy  0.87532\n",
            "test accuracy  0.843\n",
            "\n",
            "Epoch: 34\n",
            "train accuracy  0.87676\n",
            "test accuracy  0.8394\n",
            "\n",
            "Epoch: 35\n",
            "train accuracy  0.87916\n",
            "test accuracy  0.8473\n",
            "Saving..\n",
            "\n",
            "Epoch: 36\n",
            "train accuracy  0.87986\n",
            "test accuracy  0.8471\n",
            "\n",
            "Epoch: 37\n",
            "train accuracy  0.8824\n",
            "test accuracy  0.852\n",
            "Saving..\n",
            "\n",
            "Epoch: 38\n",
            "train accuracy  0.88396\n",
            "test accuracy  0.846\n",
            "\n",
            "Epoch: 39\n",
            "train accuracy  0.88496\n",
            "test accuracy  0.8498\n",
            "\n",
            "Epoch: 40\n",
            "train accuracy  0.88588\n",
            "test accuracy  0.8517\n",
            "\n",
            "Epoch: 41\n",
            "train accuracy  0.8896\n",
            "test accuracy  0.8522\n",
            "Saving..\n",
            "\n",
            "Epoch: 42\n",
            "train accuracy  0.89022\n",
            "test accuracy  0.8515\n",
            "\n",
            "Epoch: 43\n",
            "train accuracy  0.8906\n",
            "test accuracy  0.8465\n",
            "\n",
            "Epoch: 44\n",
            "train accuracy  0.89482\n",
            "test accuracy  0.8426\n",
            "\n",
            "Epoch: 45\n",
            "train accuracy  0.89164\n",
            "test accuracy  0.8576\n",
            "Saving..\n",
            "\n",
            "Epoch: 46\n",
            "train accuracy  0.89318\n",
            "test accuracy  0.8539\n",
            "\n",
            "Epoch: 47\n",
            "train accuracy  0.8955\n",
            "test accuracy  0.8412\n",
            "\n",
            "Epoch: 48\n",
            "train accuracy  0.89496\n",
            "test accuracy  0.8497\n",
            "\n",
            "Epoch: 49\n",
            "train accuracy  0.89692\n",
            "test accuracy  0.8512\n",
            "\n",
            "Epoch: 50\n",
            "train accuracy  0.89704\n",
            "test accuracy  0.8504\n",
            "\n",
            "Epoch: 51\n",
            "train accuracy  0.89824\n",
            "test accuracy  0.8535\n",
            "\n",
            "Epoch: 52\n",
            "train accuracy  0.89842\n",
            "test accuracy  0.8559\n",
            "\n",
            "Epoch: 53\n",
            "train accuracy  0.90206\n",
            "test accuracy  0.8545\n",
            "\n",
            "Epoch: 54\n",
            "train accuracy  0.90132\n",
            "test accuracy  0.8466\n",
            "\n",
            "Epoch: 55\n",
            "train accuracy  0.90434\n",
            "test accuracy  0.8525\n",
            "\n",
            "Epoch: 56\n",
            "train accuracy  0.9039\n",
            "test accuracy  0.8651\n",
            "Saving..\n",
            "\n",
            "Epoch: 57\n",
            "train accuracy  0.90558\n",
            "test accuracy  0.8609\n",
            "\n",
            "Epoch: 58\n",
            "train accuracy  0.9079\n",
            "test accuracy  0.8604\n",
            "\n",
            "Epoch: 59\n",
            "train accuracy  0.90748\n",
            "test accuracy  0.8505\n",
            "\n",
            "Epoch: 60\n",
            "train accuracy  0.91008\n",
            "test accuracy  0.8635\n",
            "\n",
            "Epoch: 61\n",
            "train accuracy  0.90876\n",
            "test accuracy  0.8572\n",
            "\n",
            "Epoch: 62\n",
            "train accuracy  0.90992\n",
            "test accuracy  0.8658\n",
            "Saving..\n",
            "\n",
            "Epoch: 63\n",
            "train accuracy  0.90694\n",
            "test accuracy  0.8667\n",
            "Saving..\n",
            "\n",
            "Epoch: 64\n",
            "train accuracy  0.91256\n",
            "test accuracy  0.8671\n",
            "Saving..\n",
            "\n",
            "Epoch: 65\n",
            "train accuracy  0.9113\n",
            "test accuracy  0.8634\n",
            "\n",
            "Epoch: 66\n",
            "train accuracy  0.91082\n",
            "test accuracy  0.8597\n",
            "\n",
            "Epoch: 67\n",
            "train accuracy  0.91318\n",
            "test accuracy  0.8659\n",
            "\n",
            "Epoch: 68\n",
            "train accuracy  0.9121\n",
            "test accuracy  0.8609\n",
            "\n",
            "Epoch: 69\n",
            "train accuracy  0.91356\n",
            "test accuracy  0.8628\n",
            "\n",
            "Epoch: 70\n",
            "train accuracy  0.91414\n",
            "test accuracy  0.8656\n",
            "\n",
            "Epoch: 71\n",
            "train accuracy  0.9144\n",
            "test accuracy  0.8578\n",
            "\n",
            "Epoch: 72\n",
            "train accuracy  0.9122\n",
            "test accuracy  0.8583\n",
            "\n",
            "Epoch: 73\n",
            "train accuracy  0.91598\n",
            "test accuracy  0.863\n",
            "\n",
            "Epoch: 74\n",
            "train accuracy  0.91564\n",
            "test accuracy  0.8612\n",
            "\n",
            "Epoch: 75\n",
            "train accuracy  0.91852\n",
            "test accuracy  0.8631\n",
            "\n",
            "Epoch: 76\n",
            "train accuracy  0.91914\n",
            "test accuracy  0.866\n",
            "\n",
            "Epoch: 77\n",
            "train accuracy  0.91776\n",
            "test accuracy  0.8656\n",
            "\n",
            "Epoch: 78\n",
            "train accuracy  0.91816\n",
            "test accuracy  0.859\n",
            "\n",
            "Epoch: 79\n",
            "train accuracy  0.91676\n",
            "test accuracy  0.8637\n",
            "\n",
            "Epoch: 80\n",
            "train accuracy  0.9212\n",
            "test accuracy  0.8603\n",
            "\n",
            "Epoch: 81\n",
            "train accuracy  0.91966\n",
            "test accuracy  0.8641\n",
            "\n",
            "Epoch: 82\n",
            "train accuracy  0.92128\n",
            "test accuracy  0.8583\n",
            "\n",
            "Epoch: 83\n",
            "train accuracy  0.91952\n",
            "test accuracy  0.8684\n",
            "Saving..\n",
            "\n",
            "Epoch: 84\n",
            "train accuracy  0.92378\n",
            "test accuracy  0.8681\n",
            "\n",
            "Epoch: 85\n",
            "train accuracy  0.91966\n",
            "test accuracy  0.8688\n",
            "Saving..\n",
            "\n",
            "Epoch: 86\n",
            "train accuracy  0.92042\n",
            "test accuracy  0.8679\n",
            "\n",
            "Epoch: 87\n",
            "train accuracy  0.92238\n",
            "test accuracy  0.8654\n",
            "\n",
            "Epoch: 88\n",
            "train accuracy  0.92358\n",
            "test accuracy  0.8618\n",
            "\n",
            "Epoch: 89\n",
            "train accuracy  0.92328\n",
            "test accuracy  0.8699\n",
            "Saving..\n",
            "\n",
            "Epoch: 90\n",
            "train accuracy  0.9236\n",
            "test accuracy  0.8712\n",
            "Saving..\n",
            "\n",
            "Epoch: 91\n",
            "train accuracy  0.92306\n",
            "test accuracy  0.8529\n",
            "\n",
            "Epoch: 92\n",
            "train accuracy  0.92612\n",
            "test accuracy  0.8649\n",
            "\n",
            "Epoch: 93\n",
            "train accuracy  0.92492\n",
            "test accuracy  0.8661\n",
            "\n",
            "Epoch: 94\n",
            "train accuracy  0.92598\n",
            "test accuracy  0.8616\n",
            "\n",
            "Epoch: 95\n",
            "train accuracy  0.92292\n",
            "test accuracy  0.8689\n",
            "\n",
            "Epoch: 96\n",
            "train accuracy  0.9274\n",
            "test accuracy  0.8641\n",
            "\n",
            "Epoch: 97\n",
            "train accuracy  0.92418\n",
            "test accuracy  0.871\n",
            "\n",
            "Epoch: 98\n",
            "train accuracy  0.92734\n",
            "test accuracy  0.8684\n",
            "\n",
            "Epoch: 99\n",
            "train accuracy  0.92612\n",
            "test accuracy  0.8627\n",
            "\n",
            "Epoch: 100\n",
            "train accuracy  0.92846\n",
            "test accuracy  0.8669\n",
            "\n",
            "Epoch: 101\n",
            "train accuracy  0.92844\n",
            "test accuracy  0.8626\n",
            "\n",
            "Epoch: 102\n",
            "train accuracy  0.9275\n",
            "test accuracy  0.8683\n",
            "\n",
            "Epoch: 103\n",
            "train accuracy  0.92874\n",
            "test accuracy  0.8673\n",
            "\n",
            "Epoch: 104\n",
            "train accuracy  0.9285\n",
            "test accuracy  0.87\n",
            "\n",
            "Epoch: 105\n",
            "train accuracy  0.92754\n",
            "test accuracy  0.8627\n",
            "\n",
            "Epoch: 106\n",
            "train accuracy  0.929\n",
            "test accuracy  0.858\n",
            "\n",
            "Epoch: 107\n",
            "train accuracy  0.93112\n",
            "test accuracy  0.8657\n",
            "\n",
            "Epoch: 108\n",
            "train accuracy  0.93064\n",
            "test accuracy  0.8685\n",
            "\n",
            "Epoch: 109\n",
            "train accuracy  0.9306\n",
            "test accuracy  0.8718\n",
            "Saving..\n",
            "\n",
            "Epoch: 110\n",
            "train accuracy  0.93118\n",
            "test accuracy  0.8716\n",
            "\n",
            "Epoch: 111\n",
            "train accuracy  0.93\n",
            "test accuracy  0.865\n",
            "\n",
            "Epoch: 112\n",
            "train accuracy  0.93012\n",
            "test accuracy  0.8692\n",
            "\n",
            "Epoch: 113\n",
            "train accuracy  0.93054\n",
            "test accuracy  0.862\n",
            "\n",
            "Epoch: 114\n",
            "train accuracy  0.9329\n",
            "test accuracy  0.8707\n",
            "\n",
            "Epoch: 115\n",
            "train accuracy  0.9312\n",
            "test accuracy  0.8688\n",
            "\n",
            "Epoch: 116\n",
            "train accuracy  0.9339\n",
            "test accuracy  0.8715\n",
            "\n",
            "Epoch: 117\n",
            "train accuracy  0.9312\n",
            "test accuracy  0.8706\n",
            "\n",
            "Epoch: 118\n",
            "train accuracy  0.93088\n",
            "test accuracy  0.8806\n",
            "Saving..\n",
            "\n",
            "Epoch: 119\n",
            "train accuracy  0.93344\n",
            "test accuracy  0.8708\n",
            "\n",
            "Epoch: 120\n",
            "train accuracy  0.93468\n",
            "test accuracy  0.8666\n",
            "\n",
            "Epoch: 121\n",
            "train accuracy  0.936\n",
            "test accuracy  0.8655\n",
            "\n",
            "Epoch: 122\n",
            "train accuracy  0.93332\n",
            "test accuracy  0.8712\n",
            "\n",
            "Epoch: 123\n",
            "train accuracy  0.93416\n",
            "test accuracy  0.8678\n",
            "\n",
            "Epoch: 124\n",
            "train accuracy  0.93304\n",
            "test accuracy  0.8755\n",
            "\n",
            "Epoch: 125\n",
            "train accuracy  0.93532\n",
            "test accuracy  0.8745\n",
            "\n",
            "Epoch: 126\n",
            "train accuracy  0.93606\n",
            "test accuracy  0.8704\n",
            "\n",
            "Epoch: 127\n",
            "train accuracy  0.93626\n",
            "test accuracy  0.8701\n",
            "\n",
            "Epoch: 128\n",
            "train accuracy  0.9372\n",
            "test accuracy  0.8657\n",
            "\n",
            "Epoch: 129\n",
            "train accuracy  0.93678\n",
            "test accuracy  0.8756\n",
            "\n",
            "Epoch: 130\n",
            "train accuracy  0.93514\n",
            "test accuracy  0.8676\n",
            "\n",
            "Epoch: 131\n",
            "train accuracy  0.93762\n",
            "test accuracy  0.8692\n",
            "\n",
            "Epoch: 132\n",
            "train accuracy  0.93728\n",
            "test accuracy  0.8592\n",
            "\n",
            "Epoch: 133\n",
            "train accuracy  0.93594\n",
            "test accuracy  0.8651\n",
            "\n",
            "Epoch: 134\n",
            "train accuracy  0.9352\n",
            "test accuracy  0.8768\n",
            "\n",
            "Epoch: 135\n",
            "train accuracy  0.93686\n",
            "test accuracy  0.8757\n",
            "\n",
            "Epoch: 136\n",
            "train accuracy  0.93832\n",
            "test accuracy  0.8725\n",
            "\n",
            "Epoch: 137\n",
            "train accuracy  0.93908\n",
            "test accuracy  0.8696\n",
            "\n",
            "Epoch: 138\n",
            "train accuracy  0.93576\n",
            "test accuracy  0.8761\n",
            "\n",
            "Epoch: 139\n",
            "train accuracy  0.93948\n",
            "test accuracy  0.8798\n",
            "\n",
            "Epoch: 140\n",
            "train accuracy  0.93922\n",
            "test accuracy  0.8775\n",
            "\n",
            "Epoch: 141\n",
            "train accuracy  0.9395\n",
            "test accuracy  0.8657\n",
            "\n",
            "Epoch: 142\n",
            "train accuracy  0.93904\n",
            "test accuracy  0.8657\n",
            "\n",
            "Epoch: 143\n",
            "train accuracy  0.93836\n",
            "test accuracy  0.8663\n",
            "\n",
            "Epoch: 144\n",
            "train accuracy  0.94022\n",
            "test accuracy  0.8654\n",
            "\n",
            "Epoch: 145\n",
            "train accuracy  0.94072\n",
            "test accuracy  0.8779\n",
            "\n",
            "Epoch: 146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60qM9zDOmwIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}