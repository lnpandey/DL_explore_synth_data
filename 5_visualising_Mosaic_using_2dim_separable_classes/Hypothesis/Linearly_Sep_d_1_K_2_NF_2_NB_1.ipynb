{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(0,3,150)\n",
    "idx= []\n",
    "for i in range(3):\n",
    "    print(i,sum(y==i))\n",
    "    idx.append(y==i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.zeros((150,))\n",
    "# x1 = np.zeros((500,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[idx[0]] = np.random.uniform(low =-1,high =0,size= sum(idx[0]))\n",
    "x[idx[1]] = np.random.uniform(low =2,high =3,size= sum(idx[1]))\n",
    "x[idx[2]] = np.random.uniform(low =0,high =1,size= sum(idx[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx= []\n",
    "for i in range(3):\n",
    "    idx.append(y==i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualise data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    y= np.zeros(x[idx[i]].shape[0])\n",
    "    plt.scatter(x[idx[i]],y,label=\"class_\"+str(i))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foreground_classes = {'class_0','class_1'}\n",
    "\n",
    "background_classes = {'class_2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_class  = np.random.randint(0,2)\n",
    "fg_idx = np.random.randint(0,2)\n",
    "\n",
    "a = []\n",
    "for i in range(2):\n",
    "    if i == fg_idx:\n",
    "        b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
    "        a.append(x[b])\n",
    "        print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
    "    else:\n",
    "        bg_class = np.random.randint(2,3)\n",
    "        b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
    "        a.append(x[b])\n",
    "        print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
    "a = np.concatenate(a,axis=0)\n",
    "#print(a.shape)\n",
    "\n",
    "print(fg_class , fg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desired_num = 1000\n",
    "mosaic_list =[]\n",
    "mosaic_label = []\n",
    "fore_idx=[]\n",
    "for j in range(desired_num):\n",
    "    fg_class  = np.random.randint(0,2)\n",
    "    fg_idx = np.random.randint(0,2)\n",
    "    a = []\n",
    "    for i in range(2):\n",
    "        if i == fg_idx:\n",
    "            b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
    "            a.append(x[b])\n",
    "#             print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
    "        else:\n",
    "            bg_class = np.random.randint(2,3)\n",
    "            b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
    "            a.append(x[b])\n",
    "#             print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
    "    a = np.concatenate(a,axis=0)\n",
    "    mosaic_list.append(np.reshape(a,(2,1)))\n",
    "    mosaic_label.append(fg_class)\n",
    "    fore_idx.append(fg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_list = np.concatenate(mosaic_list,axis=1).T\n",
    "print(mosaic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(mosaic_label))\n",
    "print(np.shape(fore_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MosaicDataset(Dataset):\n",
    "    \"\"\"MosaicDataset dataset.\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, mosaic_list, mosaic_label, fore_idx):\n",
    "        \"\"\"\n",
    "          Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mosaic = mosaic_list\n",
    "        self.label = mosaic_label\n",
    "        self.fore_idx = fore_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
    "\n",
    "batch = 250\n",
    "msd = MosaicDataset(mosaic_list, mosaic_label , fore_idx)\n",
    "train_loader = DataLoader( msd,batch_size= batch ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Wherenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Wherenet,self).__init__()\n",
    "        self.linear1 = nn.Linear(1,1)\n",
    "\n",
    "    def forward(self,z):\n",
    "        x = torch.zeros([batch,2],dtype=torch.float64)\n",
    "        y = torch.zeros([batch], dtype=torch.float64)\n",
    "        #x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
    "        for i in range(2):\n",
    "            x[:,i] = self.helper(z[:,i])[:,0]\n",
    "            #print(k[:,0].shape,x[:,i].shape)\n",
    "        x = F.softmax(x,dim=1)   # alphas\n",
    "        \n",
    "        #print(\"after network\",x.shape)\n",
    "        x1 = x[:,0]\n",
    "        #print(\"alphas before\",y.shape)\n",
    "        for i in range(2):\n",
    "            x1 = x[:,i]          \n",
    "            #print(torch.mul(x1,z[:,i]).shape)\n",
    "            y = y+torch.mul(x1,z[:,i])\n",
    "            #print(\"alphas\",y.shape)\n",
    "        #print(y[0])\n",
    "        return y[:,None] , x \n",
    "\n",
    "    \n",
    "    def helper(self,x):\n",
    "        #print(x.shape)\n",
    "        x = self.linear1(x[:,None])\n",
    "#         x = F.relu(self.linear2(x))\n",
    "#         x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainiter = iter(train_loader)\n",
    "input1,labels1,index1 = trainiter.next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "where = Wherenet().double()\n",
    "where = where\n",
    "out_avg,alphas = where(input1)\n",
    "#out_where.shape,alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_avg.shape,alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i, data in  enumerate(train_loader):\n",
    "    inputs , labels , fore_idx = data\n",
    "        \n",
    "    X.append(inputs.numpy())\n",
    "    Y.append(labels.numpy())\n",
    "X = np.concatenate(X,axis=0)\n",
    "Y  = np.concatenate(Y,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[Y==0,0],X[Y==0,1],label = \"fg class 0 \")\n",
    "plt.scatter(X[Y==1,0],X[Y==1,1],label = \"fg class 1\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above plot data is linearly separable. We can check this using SVM Classifier with C value large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(C = 10000,kernel= \"linear\",gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X,Y)\n",
    "print(clf.score(X,Y)) #Returns the mean accuracy on the given data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mesh to plot \n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.coolwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Whatnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Whatnet,self).__init__()\n",
    "        self.linear1 = nn.Linear(1,2)\n",
    "#         self.linear2 = nn.Linear(8,16)\n",
    "#         self.linear3 = nn.Linear(16,3)\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "#         x = F.relu(self.linear2(x))\n",
    "#         x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what =Whatnet().double()\n",
    "#what(out_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def disp_plot(data,avg_data,i,true_label,pred_label,alpha,true_idx):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    data = data.numpy()\n",
    "    alpha = alpha.detach().numpy()\n",
    "    avg_data = avg_data.detach().numpy()\n",
    "    \n",
    "    #print(\"data\",data)\n",
    "    #print(\"avg_data\",avg_data)\n",
    "    #print(\"alpha0\",alpha[0])\n",
    "    #print(\"alpha1\",alpha[1])\n",
    "    x = data[:,0] \n",
    "    y = data[:,1]\n",
    "    \n",
    "    \n",
    "    #print(inputs[0])\n",
    "    #print(x)\n",
    "    #np.random.seed(1234)\n",
    "    x1 = np.arange(0,10,1)#np.random.randint(low=0,high=10,size= x.size)\n",
    "    #print(\"s\",x)\n",
    "    #print(avg_data[0])\n",
    "    for i in range(0,10):\n",
    "        plt.plot([x[i],y[i]],[x1[i],x1[i]],'ro-')\n",
    "        plt.scatter(avg_data[i],x1[i],marker=\"X\",linewidths=10)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_where = optim.SGD(where.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_what = optim.SGD(what.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "nos_epochs = 100\n",
    "\n",
    "train_loss=[]\n",
    "\n",
    "train_acc = [] \n",
    "ig = np.random.randint(0,250)\n",
    "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0\n",
    "    cnt=0\n",
    "    c = 0\n",
    "    iteration = desired_num // batch\n",
    "    \n",
    "    for i, data in  enumerate(train_loader):\n",
    "        inputs , labels , fore_idx = data\n",
    "        \n",
    "        optimizer_what.zero_grad()\n",
    "        optimizer_where.zero_grad()\n",
    "        \n",
    "        avg_inp,alphas = where(inputs)\n",
    "        \n",
    "        outputs = what(avg_inp)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # display plots \n",
    "        #print(inputs[:10])\n",
    "        \n",
    "        if(c==0):\n",
    "            #p = inputs[:10].numpy()\n",
    "            #print(\"kkldsksd\",p)\n",
    "            #print(\"ddasdas\",p[:,0])\n",
    "            disp_plot(inputs[:10,:],avg_inp[:10],1,labels[:10].numpy()\n",
    "                      ,predicted[:10].numpy(), alphas[:10,:], fore_idx[:10].numpy())\n",
    "            c+=1\n",
    "            \n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward() \n",
    "        \n",
    "        optimizer_what.step()\n",
    "        optimizer_where.step() \n",
    "        \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_acc+=sum(predicted.cpu().numpy()== labels.cpu().numpy())\n",
    "        \n",
    "        if cnt % 4 == 3:    # print every 6 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss/4 ))\n",
    "            print('[%d,%5d] accuracy: %.3f' %(epoch + 1, cnt+1,running_acc/1000))\n",
    "            \n",
    "            train_loss.append(running_loss)\n",
    "            train_acc.append(running_acc /1000)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0\n",
    "#             torch.save(where.state_dict(),\"weight_elemental/where_model_epoch\"+str(epoch)+\".pt\")\n",
    "#             torch.save(what.state_dict(),\"weight_elemental/what_model_epoch\"+str(epoch)+\".pt\")\n",
    "        cnt=cnt+1\n",
    "        \n",
    "print('Finished Training')\n",
    "# torch.save(where.state_dict(),\"weight_elemental/where_model_epoch\"+str(nos_epochs)+\".pt\")\n",
    "# torch.save(what.state_dict(),\"weight_elemental/what_model_epoch\"+str(epoch)+\".pt\")       \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss,label = \"train loss\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc,label =\"train_acc\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
