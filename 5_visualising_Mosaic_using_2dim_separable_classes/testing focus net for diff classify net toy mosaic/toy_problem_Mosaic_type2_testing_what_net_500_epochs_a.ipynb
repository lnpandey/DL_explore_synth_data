{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "toy_problem_Mosaic_type2_testing_what_net_500_epochs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2_J4Rw2r0SQ",
        "outputId": "c57809b8-5a27-408e-811e-7cb8b4198e7e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6fjud_Fr0Sa"
      },
      "source": [
        "# Generate dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqdXHO0Cr0Sd",
        "outputId": "a90ab11a-0b24-4b82-d5b1-65621bda5b0f"
      },
      "source": [
        "y = np.random.randint(0,10,5000)\n",
        "idx= []\n",
        "for i in range(10):\n",
        "    print(i,sum(y==i))\n",
        "    idx.append(y==i)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 500\n",
            "1 506\n",
            "2 482\n",
            "3 483\n",
            "4 498\n",
            "5 495\n",
            "6 490\n",
            "7 498\n",
            "8 509\n",
            "9 539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddhXyODwr0Sk"
      },
      "source": [
        "x = np.zeros((5000,2))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyV3N2DIr0Sp"
      },
      "source": [
        "x[idx[0],:] = np.random.multivariate_normal(mean = [5,5],cov=[[0.1,0],[0,0.1]],size=sum(idx[0]))\n",
        "\n",
        "x[idx[1],:] = np.random.multivariate_normal(mean = [-6,7],cov=[[0.1,0],[0,0.1]],size=sum(idx[1]))\n",
        "\n",
        "x[idx[2],:] = np.random.multivariate_normal(mean = [-5,-4],cov=[[0.1,0],[0,0.1]],size=sum(idx[2]))\n",
        "\n",
        "# x[idx[0],:] = np.random.multivariate_normal(mean = [5,5],cov=[[0.1,0],[0,0.1]],size=sum(idx[0]))\n",
        "\n",
        "# x[idx[1],:] = np.random.multivariate_normal(mean = [6,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[1]))\n",
        "\n",
        "# x[idx[2],:] = np.random.multivariate_normal(mean = [5.5,6.5],cov=[[0.1,0],[0,0.1]],size=sum(idx[2]))\n",
        "\n",
        "x[idx[3],:] = np.random.multivariate_normal(mean = [-1,0],cov=[[0.1,0],[0,0.1]],size=sum(idx[3]))\n",
        "\n",
        "\n",
        "x[idx[4],:] = np.random.multivariate_normal(mean = [0,2],cov=[[0.1,0],[0,0.1]],size=sum(idx[4]))\n",
        "\n",
        "x[idx[5],:] = np.random.multivariate_normal(mean = [1,0],cov=[[0.1,0],[0,0.1]],size=sum(idx[5]))\n",
        "\n",
        "x[idx[6],:] = np.random.multivariate_normal(mean = [0,-1],cov=[[0.1,0],[0,0.1]],size=sum(idx[6]))\n",
        "\n",
        "x[idx[7],:] = np.random.multivariate_normal(mean = [0,0],cov=[[0.1,0],[0,0.1]],size=sum(idx[7]))\n",
        "\n",
        "x[idx[8],:] = np.random.multivariate_normal(mean = [-0.5,-0.5],cov=[[0.1,0],[0,0.1]],size=sum(idx[8]))\n",
        "\n",
        "x[idx[9],:] = np.random.multivariate_normal(mean = [0.4,0.2],cov=[[0.1,0],[0,0.1]],size=sum(idx[9]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "hJ8Jm7YUr0St",
        "outputId": "180217e0-5621-42e1-8973-a3c521a1403a"
      },
      "source": [
        "for i in range(10):\n",
        "    plt.scatter(x[idx[i],0],x[idx[i],1],label=\"class_\"+str(i))\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4fc1347a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfFHcZJOr0Sz"
      },
      "source": [
        "foreground_classes = {'class_0','class_1', 'class_2'}\n",
        "\n",
        "background_classes = {'class_3','class_4', 'class_5', 'class_6','class_7', 'class_8', 'class_9'}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OplNpNQVr0S2",
        "outputId": "d268b267-e5a8-45d3-b1e8-a04273bae698"
      },
      "source": [
        "fg_class  = np.random.randint(0,3)\n",
        "fg_idx = np.random.randint(0,9)\n",
        "\n",
        "a = []\n",
        "for i in range(9):\n",
        "    if i == fg_idx:\n",
        "        b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
        "        a.append(x[b])\n",
        "        print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
        "    else:\n",
        "        bg_class = np.random.randint(3,10)\n",
        "        b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
        "        a.append(x[b])\n",
        "        print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
        "a = np.concatenate(a,axis=0)\n",
        "print(a.shape)\n",
        "\n",
        "print(fg_class , fg_idx)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "background 7 present at 0\n",
            "background 8 present at 1\n",
            "foreground 0 present at 2\n",
            "background 5 present at 3\n",
            "background 9 present at 4\n",
            "background 7 present at 5\n",
            "background 5 present at 6\n",
            "background 4 present at 7\n",
            "background 9 present at 8\n",
            "(9, 2)\n",
            "0 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwZVmmRBr0S8",
        "outputId": "f1a24b1b-7294-4697-d77d-a213492bab6e"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoxzYI-ur0S_",
        "outputId": "f6b0e518-74a4-4fda-f0c0-11860044694a"
      },
      "source": [
        "np.reshape(a,(18,1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.21318991e-01],\n",
              "       [ 2.00711654e-01],\n",
              "       [-5.58106266e-01],\n",
              "       [-9.13987748e-02],\n",
              "       [ 4.82763869e+00],\n",
              "       [ 5.09104156e+00],\n",
              "       [ 1.65582387e+00],\n",
              "       [-1.10746258e-01],\n",
              "       [ 8.81774529e-01],\n",
              "       [ 2.99594881e-01],\n",
              "       [-4.43855652e-01],\n",
              "       [-7.38298106e-01],\n",
              "       [ 1.04372712e+00],\n",
              "       [-4.54398269e-02],\n",
              "       [-1.14905859e-01],\n",
              "       [ 2.11617282e+00],\n",
              "       [ 8.43501287e-04],\n",
              "       [ 1.16806267e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ruI0cxr0TE"
      },
      "source": [
        "a=np.reshape(a,(3,6))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "RTUTFhJIr0TI",
        "outputId": "db90b0b9-47d7-45d0-d0f8-b6e9e15bf345"
      },
      "source": [
        "plt.imshow(a)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4fc0e3e2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqbvfbwVr0TN"
      },
      "source": [
        "desired_num = 1000\n",
        "mosaic_list_of_images =[]\n",
        "mosaic_label = []\n",
        "fore_idx=[]\n",
        "for j in range(desired_num):\n",
        "    fg_class  = np.random.randint(0,3)\n",
        "    fg_idx = 0\n",
        "    a = []\n",
        "    for i in range(9):\n",
        "        if i == fg_idx:\n",
        "            b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
        "            a.append(x[b])\n",
        "#             print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
        "        else:\n",
        "            bg_class = np.random.randint(3,10)\n",
        "            b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
        "            a.append(x[b])\n",
        "#             print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
        "    a = np.concatenate(a,axis=0)\n",
        "    mosaic_list_of_images.append(np.reshape(a,(18,1)))\n",
        "    mosaic_label.append(fg_class)\n",
        "    fore_idx.append(fg_idx)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOsFmWfMr0TR"
      },
      "source": [
        "mosaic_list_of_images = np.concatenate(mosaic_list_of_images,axis=1).T\n",
        "# print(mosaic_list)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2PnW7aQr0TT",
        "outputId": "d58d3d8b-dc03-45d5-e39b-c30b33ee313a"
      },
      "source": [
        "print(np.shape(mosaic_list_of_images))\n",
        "print(np.shape(fore_idx))\n",
        "print(np.shape(mosaic_label))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 18)\n",
            "(1000,)\n",
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPoIwbMHx44n"
      },
      "source": [
        "def create_avg_image_from_mosaic_dataset(mosaic_dataset,labels,foreground_index,dataset_number):\n",
        "  \"\"\"\n",
        "  mosaic_dataset : mosaic_dataset contains 9 images 32 x 32 each as 1 data point\n",
        "  labels : mosaic_dataset labels\n",
        "  foreground_index : contains list of indexes where foreground image is present so that using this we can take weighted average\n",
        "  dataset_number : will help us to tell what ratio of foreground image to be taken. for eg: if it is \"j\" then fg_image_ratio = j/9 , bg_image_ratio = (9-j)/8*9\n",
        "  \"\"\"\n",
        "  avg_image_dataset = []\n",
        "  cnt = 0\n",
        "  counter = np.array([0,0,0,0,0,0,0,0,0])\n",
        "  for i in range(len(mosaic_dataset)):\n",
        "    img = torch.zeros([18], dtype=torch.float64)\n",
        "    np.random.seed(dataset_number*10000 + i)\n",
        "    give_pref = foreground_index[i] #np.random.randint(0,9)\n",
        "    # print(\"outside\", give_pref,foreground_index[i])\n",
        "    for j in range(9):\n",
        "      if j == give_pref:\n",
        "        img = img + mosaic_dataset[i][j]*dataset_number/9\n",
        "      else :\n",
        "        img = img + mosaic_dataset[i][j]*(9-dataset_number)/(8*9)\n",
        "\n",
        "    if give_pref == foreground_index[i] :\n",
        "      # print(\"equal are\", give_pref,foreground_index[i])\n",
        "      cnt += 1\n",
        "      counter[give_pref] += 1\n",
        "    else :\n",
        "      counter[give_pref] += 1\n",
        "\n",
        "    avg_image_dataset.append(img)\n",
        "\n",
        "  print(\"number of correct averaging happened for dataset \"+str(dataset_number)+\" is \"+str(cnt)) \n",
        "  print(\"the averaging are done as \", counter) \n",
        "  return avg_image_dataset , labels , foreground_index\n",
        "        \n",
        "  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ZAjix3x8CM",
        "outputId": "2b2a678a-5d17-4fee-b904-7aaccd55745d"
      },
      "source": [
        "avg_image_dataset_1 , labels_1,  fg_index_1 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 1)\n",
        "avg_image_dataset_2 , labels_2,  fg_index_2 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 2)\n",
        "avg_image_dataset_3 , labels_3,  fg_index_3 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 3)\n",
        "avg_image_dataset_4 , labels_4,  fg_index_4 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 4)\n",
        "avg_image_dataset_5 , labels_5,  fg_index_5 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 5)\n",
        "avg_image_dataset_6 , labels_6,  fg_index_6 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 6)\n",
        "avg_image_dataset_7 , labels_7,  fg_index_7 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 7)\n",
        "avg_image_dataset_8 , labels_8,  fg_index_8 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 8)\n",
        "avg_image_dataset_9 , labels_9,  fg_index_9 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 9)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of correct averaging happened for dataset 1 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 2 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 3 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 4 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 5 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 6 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 7 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 8 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 9 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL0BRf8er0TX"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    #self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] #, self.fore_idx[idx]\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY2l62APygaV"
      },
      "source": [
        "batch = 200\n",
        "epochs = 300\n",
        "\n",
        "# training_data = avg_image_dataset_5    #just change this and training_label to desired dataset for training\n",
        "# training_label = labels_5\n",
        "\n",
        "traindata_1 = MosaicDataset(avg_image_dataset_1, labels_1 )\n",
        "trainloader_1 = DataLoader( traindata_1 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_2 = MosaicDataset(avg_image_dataset_2, labels_2 )\n",
        "trainloader_2 = DataLoader( traindata_2 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_3 = MosaicDataset(avg_image_dataset_3, labels_3 )\n",
        "trainloader_3 = DataLoader( traindata_3 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_4 = MosaicDataset(avg_image_dataset_4, labels_4 )\n",
        "trainloader_4 = DataLoader( traindata_4 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_5 = MosaicDataset(avg_image_dataset_5, labels_5 )\n",
        "trainloader_5 = DataLoader( traindata_5 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_6 = MosaicDataset(avg_image_dataset_6, labels_6 )\n",
        "trainloader_6 = DataLoader( traindata_6 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_7 = MosaicDataset(avg_image_dataset_7, labels_7 )\n",
        "trainloader_7 = DataLoader( traindata_7 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_8 = MosaicDataset(avg_image_dataset_8, labels_8 )\n",
        "trainloader_8 = DataLoader( traindata_8 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_9 = MosaicDataset(avg_image_dataset_9, labels_9 )\n",
        "trainloader_9 = DataLoader( traindata_9 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "testdata_1 = MosaicDataset(avg_image_dataset_1, labels_1 )\n",
        "testloader_1 = DataLoader( testdata_1 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_2 = MosaicDataset(avg_image_dataset_2, labels_2 )\n",
        "testloader_2 = DataLoader( testdata_2 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_3 = MosaicDataset(avg_image_dataset_3, labels_3 )\n",
        "testloader_3 = DataLoader( testdata_3 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_4 = MosaicDataset(avg_image_dataset_4, labels_4 )\n",
        "testloader_4 = DataLoader( testdata_4 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_5 = MosaicDataset(avg_image_dataset_5, labels_5 )\n",
        "testloader_5 = DataLoader( testdata_5 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_6 = MosaicDataset(avg_image_dataset_6, labels_6 )\n",
        "testloader_6 = DataLoader( testdata_6 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_7 = MosaicDataset(avg_image_dataset_7, labels_7 )\n",
        "testloader_7 = DataLoader( testdata_7 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_8 = MosaicDataset(avg_image_dataset_8, labels_8 )\n",
        "testloader_8 = DataLoader( testdata_8 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_9 = MosaicDataset(avg_image_dataset_9, labels_9 )\n",
        "testloader_9 = DataLoader( testdata_9 , batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVRXgwwNr0Tb"
      },
      "source": [
        "class Wherenet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Wherenet,self).__init__()\n",
        "        self.linear1 = nn.Linear(2,128)\n",
        "        self.linear2 = nn.Linear(128,256)\n",
        "        self.linear3 = nn.Linear(256,128)\n",
        "        self.linear4 = nn.Linear(128,64)\n",
        "        self.linear5 = nn.Linear(64,1)\n",
        "    def forward(self,z):\n",
        "        x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,2], dtype=torch.float64)\n",
        "        #x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        for i in range(9):\n",
        "            x[:,i] = self.helper(z[:,2*i:2*i+2])[:,0]\n",
        "            #print(k[:,0].shape,x[:,i].shape)\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(9):\n",
        "            x1 = x[:,i]          \n",
        "            #print()\n",
        "            y = y+torch.mul(x1[:,None],z[:,2*i:2*i+2])\n",
        "        return y , x \n",
        "\n",
        "    \n",
        "    def helper(self,x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = F.relu(self.linear4(x))\n",
        "        x = self.linear5(x)\n",
        "        return x\n",
        "\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Ek05Kxr0Te",
        "outputId": "552168fb-6d52-4d7c-8c3a-d7cc682f23ce"
      },
      "source": [
        "trainiter = iter(trainloader_1)\n",
        "input1,labels1 = trainiter.next()\n",
        "\n",
        "input1.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxEmWZI6r0Ti",
        "outputId": "e69d4402-8bd4-4fd9-d8d5-878d3275e6cb"
      },
      "source": [
        "where = Wherenet().double()\n",
        "where = where\n",
        "out_where,alphas = where(input1)\n",
        "out_where.shape,alphas.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([200, 2]), torch.Size([200, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_XeIUk0r0Tl"
      },
      "source": [
        "class Whatnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Whatnet,self).__init__()\n",
        "        self.linear1 = nn.Linear(2,128)\n",
        "        self.linear2 = nn.Linear(128,256)\n",
        "        self.linear3 = nn.Linear(256,128)\n",
        "        self.linear4 = nn.Linear(128,64)\n",
        "        self.linear5 = nn.Linear(64,3)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = F.relu(self.linear4(x))\n",
        "        x = self.linear5(x)\n",
        "        return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l35i9bIlr0Tp"
      },
      "source": [
        "# what = Whatnet().double()\n",
        "# what(out_where)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uALi25pmzQHV"
      },
      "source": [
        "def test_all(number, testloader,what, where):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    out = []\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            # images, labels = images.to(\"cuda\"),labels.to(\"cuda\")\n",
        "            out.append(labels.cpu().numpy())\n",
        "            avg_inp,alphas = where(inputs)        \n",
        "            outputs = what(avg_inp)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            pred.append(predicted.cpu().numpy())\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test dataset %d: %d %%' % (number , 100 * correct / total))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmNprlPzTjP"
      },
      "source": [
        "def train_all(trainloader, ds_number, testloader_list):\n",
        "    \n",
        "    print(\"--\"*40)\n",
        "    print(\"training on data set  \", ds_number)\n",
        "    \n",
        "    where = Wherenet().double()\n",
        "    what = Whatnet().double()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # optimizer_where = optim.SGD(where.parameters(), lr=0.001, momentum=0.9)\n",
        "    optimizer_where = optim.Adam(where.parameters(), lr=1e-2, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=True)\n",
        "    # optimizer_what = optim.SGD(what.parameters(), lr=0.001, momentum=0.9)\n",
        "    optimizer_what = optim.Adam(what.parameters(), lr=1e-2, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=True)\n",
        "    \n",
        "    acti = []\n",
        "    loss_curi = []\n",
        "    epochs = 500\n",
        "    \n",
        "    for epoch in range(epochs): # loop over the dataset multiple times\n",
        "        ep_lossi = []\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            # inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer_what.zero_grad()\n",
        "            optimizer_where.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            avg_inp,alphas = where(inputs) \n",
        "            # print(avg_inp.shape)       \n",
        "            outputs = what(avg_inp)\n",
        "            \n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_what.step()\n",
        "            optimizer_where.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            mini = 4\n",
        "            if i % mini == mini-1:    # print every 10 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / mini))\n",
        "                ep_lossi.append(running_loss/mini) # loss per minibatch\n",
        "                running_loss = 0.0\n",
        "                \n",
        "        loss_curi.append(np.mean(ep_lossi))   #loss per epoch\n",
        "        if (np.mean(ep_lossi) <= 0.05):\n",
        "            break\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    # torch.save(inc.state_dict(),\"train_dataset_\"+str(ds_number)+\"_\"+str(epochs)+\".pt\")\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in trainloader:\n",
        "            inputs, labels = data\n",
        "            # images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            avg_inp,alphas = where(inputs)        \n",
        "            outputs = what(avg_inp)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 train images: %d %%' % (  100 * correct / total))\n",
        "    \n",
        "    for i, j in enumerate(testloader_list):\n",
        "        test_all(i+1, j,what, where)\n",
        "    \n",
        "    print(\"--\"*40)\n",
        "    \n",
        "    return loss_curi\n",
        "    "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl41sE8vFERk"
      },
      "source": [
        "train_loss_all=[]\n",
        "\n",
        "testloader_list= [ testloader_1, testloader_2, testloader_3, testloader_4, testloader_5, testloader_6,\n",
        "                 testloader_7, testloader_8, testloader_9]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gQoPST5zW2t",
        "outputId": "3811e2e3-bca7-4370-8525-35c77384f27f"
      },
      "source": [
        "train_loss_all=[]\n",
        "\n",
        "testloader_list= [ testloader_1, testloader_2, testloader_3, testloader_4, testloader_5, testloader_6,\n",
        "                 testloader_7, testloader_8, testloader_9]\n",
        "\n",
        "train_loss_all.append(train_all(trainloader_1, 1, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_2, 2, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_3, 3, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_4, 4, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_5, 5, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_6, 6, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_7, 7, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_8, 8, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_9, 9, testloader_list))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "training on data set   1\n",
            "[1,     4] loss: 0.847\n",
            "[2,     4] loss: 0.126\n",
            "[3,     4] loss: 0.142\n",
            "[4,     4] loss: 0.105\n",
            "[5,     4] loss: 0.094\n",
            "[6,     4] loss: 0.077\n",
            "[7,     4] loss: 0.069\n",
            "[8,     4] loss: 0.078\n",
            "[9,     4] loss: 0.055\n",
            "[10,     4] loss: 0.054\n",
            "[11,     4] loss: 0.081\n",
            "[12,     4] loss: 0.072\n",
            "[13,     4] loss: 0.070\n",
            "[14,     4] loss: 0.074\n",
            "[15,     4] loss: 0.047\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 98 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 98 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 69 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 63 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   2\n",
            "[1,     4] loss: 0.801\n",
            "[2,     4] loss: 0.222\n",
            "[3,     4] loss: 0.078\n",
            "[4,     4] loss: 0.076\n",
            "[5,     4] loss: 0.087\n",
            "[6,     4] loss: 0.078\n",
            "[7,     4] loss: 0.059\n",
            "[8,     4] loss: 0.054\n",
            "[9,     4] loss: 0.062\n",
            "[10,     4] loss: 0.069\n",
            "[11,     4] loss: 0.069\n",
            "[12,     4] loss: 0.062\n",
            "[13,     4] loss: 0.057\n",
            "[14,     4] loss: 0.058\n",
            "[15,     4] loss: 0.054\n",
            "[16,     4] loss: 0.060\n",
            "[17,     4] loss: 0.049\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 98 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 68 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 98 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 65 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 63 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   3\n",
            "[1,     4] loss: 0.751\n",
            "[2,     4] loss: 0.480\n",
            "[3,     4] loss: 0.453\n",
            "[4,     4] loss: 0.419\n",
            "[5,     4] loss: 0.273\n",
            "[6,     4] loss: 0.212\n",
            "[7,     4] loss: 0.170\n",
            "[8,     4] loss: 0.141\n",
            "[9,     4] loss: 0.159\n",
            "[10,     4] loss: 0.167\n",
            "[11,     4] loss: 0.156\n",
            "[12,     4] loss: 0.153\n",
            "[13,     4] loss: 0.150\n",
            "[14,     4] loss: 0.133\n",
            "[15,     4] loss: 0.156\n",
            "[16,     4] loss: 0.184\n",
            "[17,     4] loss: 0.178\n",
            "[18,     4] loss: 0.184\n",
            "[19,     4] loss: 0.154\n",
            "[20,     4] loss: 0.172\n",
            "[21,     4] loss: 0.160\n",
            "[22,     4] loss: 0.164\n",
            "[23,     4] loss: 0.167\n",
            "[24,     4] loss: 0.145\n",
            "[25,     4] loss: 0.141\n",
            "[26,     4] loss: 0.151\n",
            "[27,     4] loss: 0.146\n",
            "[28,     4] loss: 0.149\n",
            "[29,     4] loss: 0.144\n",
            "[30,     4] loss: 0.175\n",
            "[31,     4] loss: 0.155\n",
            "[32,     4] loss: 0.172\n",
            "[33,     4] loss: 0.149\n",
            "[34,     4] loss: 0.164\n",
            "[35,     4] loss: 0.134\n",
            "[36,     4] loss: 0.140\n",
            "[37,     4] loss: 0.157\n",
            "[38,     4] loss: 0.151\n",
            "[39,     4] loss: 0.138\n",
            "[40,     4] loss: 0.135\n",
            "[41,     4] loss: 0.127\n",
            "[42,     4] loss: 0.136\n",
            "[43,     4] loss: 0.143\n",
            "[44,     4] loss: 0.154\n",
            "[45,     4] loss: 0.152\n",
            "[46,     4] loss: 0.144\n",
            "[47,     4] loss: 0.169\n",
            "[48,     4] loss: 0.146\n",
            "[49,     4] loss: 0.173\n",
            "[50,     4] loss: 0.158\n",
            "[51,     4] loss: 0.142\n",
            "[52,     4] loss: 0.152\n",
            "[53,     4] loss: 0.147\n",
            "[54,     4] loss: 0.141\n",
            "[55,     4] loss: 0.151\n",
            "[56,     4] loss: 0.139\n",
            "[57,     4] loss: 0.128\n",
            "[58,     4] loss: 0.158\n",
            "[59,     4] loss: 0.157\n",
            "[60,     4] loss: 0.158\n",
            "[61,     4] loss: 0.160\n",
            "[62,     4] loss: 0.143\n",
            "[63,     4] loss: 0.142\n",
            "[64,     4] loss: 0.131\n",
            "[65,     4] loss: 0.172\n",
            "[66,     4] loss: 0.156\n",
            "[67,     4] loss: 0.157\n",
            "[68,     4] loss: 0.152\n",
            "[69,     4] loss: 0.134\n",
            "[70,     4] loss: 0.139\n",
            "[71,     4] loss: 0.146\n",
            "[72,     4] loss: 0.152\n",
            "[73,     4] loss: 0.152\n",
            "[74,     4] loss: 0.143\n",
            "[75,     4] loss: 0.139\n",
            "[76,     4] loss: 0.148\n",
            "[77,     4] loss: 0.139\n",
            "[78,     4] loss: 0.149\n",
            "[79,     4] loss: 0.153\n",
            "[80,     4] loss: 0.139\n",
            "[81,     4] loss: 0.158\n",
            "[82,     4] loss: 0.152\n",
            "[83,     4] loss: 0.135\n",
            "[84,     4] loss: 0.158\n",
            "[85,     4] loss: 0.150\n",
            "[86,     4] loss: 0.152\n",
            "[87,     4] loss: 0.162\n",
            "[88,     4] loss: 0.155\n",
            "[89,     4] loss: 0.160\n",
            "[90,     4] loss: 0.142\n",
            "[91,     4] loss: 0.156\n",
            "[92,     4] loss: 0.152\n",
            "[93,     4] loss: 0.140\n",
            "[94,     4] loss: 0.140\n",
            "[95,     4] loss: 0.159\n",
            "[96,     4] loss: 0.153\n",
            "[97,     4] loss: 0.143\n",
            "[98,     4] loss: 0.176\n",
            "[99,     4] loss: 0.166\n",
            "[100,     4] loss: 0.170\n",
            "[101,     4] loss: 0.169\n",
            "[102,     4] loss: 0.146\n",
            "[103,     4] loss: 0.149\n",
            "[104,     4] loss: 0.127\n",
            "[105,     4] loss: 0.149\n",
            "[106,     4] loss: 0.139\n",
            "[107,     4] loss: 0.142\n",
            "[108,     4] loss: 0.157\n",
            "[109,     4] loss: 0.154\n",
            "[110,     4] loss: 0.140\n",
            "[111,     4] loss: 0.149\n",
            "[112,     4] loss: 0.143\n",
            "[113,     4] loss: 0.144\n",
            "[114,     4] loss: 0.146\n",
            "[115,     4] loss: 0.147\n",
            "[116,     4] loss: 0.137\n",
            "[117,     4] loss: 0.138\n",
            "[118,     4] loss: 0.129\n",
            "[119,     4] loss: 0.162\n",
            "[120,     4] loss: 0.170\n",
            "[121,     4] loss: 0.154\n",
            "[122,     4] loss: 0.144\n",
            "[123,     4] loss: 0.152\n",
            "[124,     4] loss: 0.144\n",
            "[125,     4] loss: 0.146\n",
            "[126,     4] loss: 0.139\n",
            "[127,     4] loss: 0.141\n",
            "[128,     4] loss: 0.143\n",
            "[129,     4] loss: 0.133\n",
            "[130,     4] loss: 0.153\n",
            "[131,     4] loss: 0.138\n",
            "[132,     4] loss: 0.140\n",
            "[133,     4] loss: 0.132\n",
            "[134,     4] loss: 0.149\n",
            "[135,     4] loss: 0.145\n",
            "[136,     4] loss: 0.140\n",
            "[137,     4] loss: 0.154\n",
            "[138,     4] loss: 0.150\n",
            "[139,     4] loss: 0.156\n",
            "[140,     4] loss: 0.155\n",
            "[141,     4] loss: 0.151\n",
            "[142,     4] loss: 0.159\n",
            "[143,     4] loss: 0.150\n",
            "[144,     4] loss: 0.148\n",
            "[145,     4] loss: 0.150\n",
            "[146,     4] loss: 0.146\n",
            "[147,     4] loss: 0.151\n",
            "[148,     4] loss: 0.148\n",
            "[149,     4] loss: 0.147\n",
            "[150,     4] loss: 0.150\n",
            "[151,     4] loss: 0.142\n",
            "[152,     4] loss: 0.154\n",
            "[153,     4] loss: 0.152\n",
            "[154,     4] loss: 0.150\n",
            "[155,     4] loss: 0.147\n",
            "[156,     4] loss: 0.151\n",
            "[157,     4] loss: 0.139\n",
            "[158,     4] loss: 0.135\n",
            "[159,     4] loss: 0.139\n",
            "[160,     4] loss: 0.155\n",
            "[161,     4] loss: 0.147\n",
            "[162,     4] loss: 0.142\n",
            "[163,     4] loss: 0.140\n",
            "[164,     4] loss: 0.158\n",
            "[165,     4] loss: 0.141\n",
            "[166,     4] loss: 0.147\n",
            "[167,     4] loss: 0.159\n",
            "[168,     4] loss: 0.138\n",
            "[169,     4] loss: 0.132\n",
            "[170,     4] loss: 0.158\n",
            "[171,     4] loss: 0.150\n",
            "[172,     4] loss: 0.139\n",
            "[173,     4] loss: 0.139\n",
            "[174,     4] loss: 0.173\n",
            "[175,     4] loss: 0.160\n",
            "[176,     4] loss: 0.150\n",
            "[177,     4] loss: 0.139\n",
            "[178,     4] loss: 0.142\n",
            "[179,     4] loss: 0.142\n",
            "[180,     4] loss: 0.173\n",
            "[181,     4] loss: 0.160\n",
            "[182,     4] loss: 0.159\n",
            "[183,     4] loss: 0.158\n",
            "[184,     4] loss: 0.155\n",
            "[185,     4] loss: 0.151\n",
            "[186,     4] loss: 0.150\n",
            "[187,     4] loss: 0.114\n",
            "[188,     4] loss: 0.157\n",
            "[189,     4] loss: 0.143\n",
            "[190,     4] loss: 0.143\n",
            "[191,     4] loss: 0.150\n",
            "[192,     4] loss: 0.153\n",
            "[193,     4] loss: 0.135\n",
            "[194,     4] loss: 0.152\n",
            "[195,     4] loss: 0.136\n",
            "[196,     4] loss: 0.138\n",
            "[197,     4] loss: 0.152\n",
            "[198,     4] loss: 0.153\n",
            "[199,     4] loss: 0.148\n",
            "[200,     4] loss: 0.151\n",
            "[201,     4] loss: 0.136\n",
            "[202,     4] loss: 0.153\n",
            "[203,     4] loss: 0.147\n",
            "[204,     4] loss: 0.156\n",
            "[205,     4] loss: 0.147\n",
            "[206,     4] loss: 0.151\n",
            "[207,     4] loss: 0.144\n",
            "[208,     4] loss: 0.139\n",
            "[209,     4] loss: 0.142\n",
            "[210,     4] loss: 0.138\n",
            "[211,     4] loss: 0.146\n",
            "[212,     4] loss: 0.134\n",
            "[213,     4] loss: 0.125\n",
            "[214,     4] loss: 0.145\n",
            "[215,     4] loss: 0.137\n",
            "[216,     4] loss: 0.142\n",
            "[217,     4] loss: 0.136\n",
            "[218,     4] loss: 0.161\n",
            "[219,     4] loss: 0.141\n",
            "[220,     4] loss: 0.142\n",
            "[221,     4] loss: 0.152\n",
            "[222,     4] loss: 0.150\n",
            "[223,     4] loss: 0.152\n",
            "[224,     4] loss: 0.154\n",
            "[225,     4] loss: 0.170\n",
            "[226,     4] loss: 0.155\n",
            "[227,     4] loss: 0.166\n",
            "[228,     4] loss: 0.143\n",
            "[229,     4] loss: 0.148\n",
            "[230,     4] loss: 0.147\n",
            "[231,     4] loss: 0.141\n",
            "[232,     4] loss: 0.138\n",
            "[233,     4] loss: 0.137\n",
            "[234,     4] loss: 0.148\n",
            "[235,     4] loss: 0.151\n",
            "[236,     4] loss: 0.158\n",
            "[237,     4] loss: 0.135\n",
            "[238,     4] loss: 0.141\n",
            "[239,     4] loss: 0.150\n",
            "[240,     4] loss: 0.157\n",
            "[241,     4] loss: 0.154\n",
            "[242,     4] loss: 0.154\n",
            "[243,     4] loss: 0.149\n",
            "[244,     4] loss: 0.142\n",
            "[245,     4] loss: 0.150\n",
            "[246,     4] loss: 0.156\n",
            "[247,     4] loss: 0.145\n",
            "[248,     4] loss: 0.147\n",
            "[249,     4] loss: 0.140\n",
            "[250,     4] loss: 0.154\n",
            "[251,     4] loss: 0.152\n",
            "[252,     4] loss: 0.146\n",
            "[253,     4] loss: 0.139\n",
            "[254,     4] loss: 0.141\n",
            "[255,     4] loss: 0.146\n",
            "[256,     4] loss: 0.134\n",
            "[257,     4] loss: 0.146\n",
            "[258,     4] loss: 0.136\n",
            "[259,     4] loss: 0.154\n",
            "[260,     4] loss: 0.149\n",
            "[261,     4] loss: 0.138\n",
            "[262,     4] loss: 0.155\n",
            "[263,     4] loss: 0.147\n",
            "[264,     4] loss: 0.152\n",
            "[265,     4] loss: 0.156\n",
            "[266,     4] loss: 0.158\n",
            "[267,     4] loss: 0.155\n",
            "[268,     4] loss: 0.146\n",
            "[269,     4] loss: 0.142\n",
            "[270,     4] loss: 0.136\n",
            "[271,     4] loss: 0.154\n",
            "[272,     4] loss: 0.142\n",
            "[273,     4] loss: 0.139\n",
            "[274,     4] loss: 0.151\n",
            "[275,     4] loss: 0.131\n",
            "[276,     4] loss: 0.148\n",
            "[277,     4] loss: 0.148\n",
            "[278,     4] loss: 0.153\n",
            "[279,     4] loss: 0.155\n",
            "[280,     4] loss: 0.142\n",
            "[281,     4] loss: 0.144\n",
            "[282,     4] loss: 0.134\n",
            "[283,     4] loss: 0.140\n",
            "[284,     4] loss: 0.138\n",
            "[285,     4] loss: 0.153\n",
            "[286,     4] loss: 0.137\n",
            "[287,     4] loss: 0.148\n",
            "[288,     4] loss: 0.134\n",
            "[289,     4] loss: 0.155\n",
            "[290,     4] loss: 0.155\n",
            "[291,     4] loss: 0.143\n",
            "[292,     4] loss: 0.142\n",
            "[293,     4] loss: 0.141\n",
            "[294,     4] loss: 0.152\n",
            "[295,     4] loss: 0.136\n",
            "[296,     4] loss: 0.150\n",
            "[297,     4] loss: 0.148\n",
            "[298,     4] loss: 0.155\n",
            "[299,     4] loss: 0.152\n",
            "[300,     4] loss: 0.148\n",
            "[301,     4] loss: 0.142\n",
            "[302,     4] loss: 0.133\n",
            "[303,     4] loss: 0.137\n",
            "[304,     4] loss: 0.138\n",
            "[305,     4] loss: 0.133\n",
            "[306,     4] loss: 0.162\n",
            "[307,     4] loss: 0.155\n",
            "[308,     4] loss: 0.146\n",
            "[309,     4] loss: 0.165\n",
            "[310,     4] loss: 0.160\n",
            "[311,     4] loss: 0.157\n",
            "[312,     4] loss: 0.152\n",
            "[313,     4] loss: 0.154\n",
            "[314,     4] loss: 0.143\n",
            "[315,     4] loss: 0.148\n",
            "[316,     4] loss: 0.159\n",
            "[317,     4] loss: 0.150\n",
            "[318,     4] loss: 0.143\n",
            "[319,     4] loss: 0.145\n",
            "[320,     4] loss: 0.143\n",
            "[321,     4] loss: 0.159\n",
            "[322,     4] loss: 0.143\n",
            "[323,     4] loss: 0.146\n",
            "[324,     4] loss: 0.148\n",
            "[325,     4] loss: 0.151\n",
            "[326,     4] loss: 0.147\n",
            "[327,     4] loss: 0.152\n",
            "[328,     4] loss: 0.139\n",
            "[329,     4] loss: 0.151\n",
            "[330,     4] loss: 0.136\n",
            "[331,     4] loss: 0.146\n",
            "[332,     4] loss: 0.156\n",
            "[333,     4] loss: 0.124\n",
            "[334,     4] loss: 0.140\n",
            "[335,     4] loss: 0.141\n",
            "[336,     4] loss: 0.141\n",
            "[337,     4] loss: 0.142\n",
            "[338,     4] loss: 0.151\n",
            "[339,     4] loss: 0.140\n",
            "[340,     4] loss: 0.149\n",
            "[341,     4] loss: 0.165\n",
            "[342,     4] loss: 0.155\n",
            "[343,     4] loss: 0.140\n",
            "[344,     4] loss: 0.149\n",
            "[345,     4] loss: 0.150\n",
            "[346,     4] loss: 0.156\n",
            "[347,     4] loss: 0.169\n",
            "[348,     4] loss: 0.158\n",
            "[349,     4] loss: 0.146\n",
            "[350,     4] loss: 0.136\n",
            "[351,     4] loss: 0.133\n",
            "[352,     4] loss: 0.147\n",
            "[353,     4] loss: 0.151\n",
            "[354,     4] loss: 0.137\n",
            "[355,     4] loss: 0.153\n",
            "[356,     4] loss: 0.150\n",
            "[357,     4] loss: 0.151\n",
            "[358,     4] loss: 0.141\n",
            "[359,     4] loss: 0.137\n",
            "[360,     4] loss: 0.136\n",
            "[361,     4] loss: 0.144\n",
            "[362,     4] loss: 0.150\n",
            "[363,     4] loss: 0.148\n",
            "[364,     4] loss: 0.140\n",
            "[365,     4] loss: 0.144\n",
            "[366,     4] loss: 0.151\n",
            "[367,     4] loss: 0.147\n",
            "[368,     4] loss: 0.151\n",
            "[369,     4] loss: 0.165\n",
            "[370,     4] loss: 0.167\n",
            "[371,     4] loss: 0.134\n",
            "[372,     4] loss: 0.163\n",
            "[373,     4] loss: 0.150\n",
            "[374,     4] loss: 0.142\n",
            "[375,     4] loss: 0.144\n",
            "[376,     4] loss: 0.143\n",
            "[377,     4] loss: 0.140\n",
            "[378,     4] loss: 0.137\n",
            "[379,     4] loss: 0.141\n",
            "[380,     4] loss: 0.134\n",
            "[381,     4] loss: 0.136\n",
            "[382,     4] loss: 0.150\n",
            "[383,     4] loss: 0.139\n",
            "[384,     4] loss: 0.140\n",
            "[385,     4] loss: 0.159\n",
            "[386,     4] loss: 0.147\n",
            "[387,     4] loss: 0.151\n",
            "[388,     4] loss: 0.148\n",
            "[389,     4] loss: 0.159\n",
            "[390,     4] loss: 0.144\n",
            "[391,     4] loss: 0.145\n",
            "[392,     4] loss: 0.136\n",
            "[393,     4] loss: 0.133\n",
            "[394,     4] loss: 0.144\n",
            "[395,     4] loss: 0.146\n",
            "[396,     4] loss: 0.152\n",
            "[397,     4] loss: 0.143\n",
            "[398,     4] loss: 0.146\n",
            "[399,     4] loss: 0.158\n",
            "[400,     4] loss: 0.151\n",
            "[401,     4] loss: 0.142\n",
            "[402,     4] loss: 0.154\n",
            "[403,     4] loss: 0.151\n",
            "[404,     4] loss: 0.148\n",
            "[405,     4] loss: 0.140\n",
            "[406,     4] loss: 0.142\n",
            "[407,     4] loss: 0.141\n",
            "[408,     4] loss: 0.137\n",
            "[409,     4] loss: 0.140\n",
            "[410,     4] loss: 0.153\n",
            "[411,     4] loss: 0.132\n",
            "[412,     4] loss: 0.149\n",
            "[413,     4] loss: 0.139\n",
            "[414,     4] loss: 0.136\n",
            "[415,     4] loss: 0.135\n",
            "[416,     4] loss: 0.142\n",
            "[417,     4] loss: 0.151\n",
            "[418,     4] loss: 0.148\n",
            "[419,     4] loss: 0.155\n",
            "[420,     4] loss: 0.155\n",
            "[421,     4] loss: 0.150\n",
            "[422,     4] loss: 0.132\n",
            "[423,     4] loss: 0.148\n",
            "[424,     4] loss: 0.143\n",
            "[425,     4] loss: 0.147\n",
            "[426,     4] loss: 0.141\n",
            "[427,     4] loss: 0.129\n",
            "[428,     4] loss: 0.134\n",
            "[429,     4] loss: 0.146\n",
            "[430,     4] loss: 0.140\n",
            "[431,     4] loss: 0.140\n",
            "[432,     4] loss: 0.145\n",
            "[433,     4] loss: 0.145\n",
            "[434,     4] loss: 0.135\n",
            "[435,     4] loss: 0.159\n",
            "[436,     4] loss: 0.139\n",
            "[437,     4] loss: 0.143\n",
            "[438,     4] loss: 0.141\n",
            "[439,     4] loss: 0.146\n",
            "[440,     4] loss: 0.147\n",
            "[441,     4] loss: 0.140\n",
            "[442,     4] loss: 0.155\n",
            "[443,     4] loss: 0.137\n",
            "[444,     4] loss: 0.152\n",
            "[445,     4] loss: 0.128\n",
            "[446,     4] loss: 0.139\n",
            "[447,     4] loss: 0.146\n",
            "[448,     4] loss: 0.138\n",
            "[449,     4] loss: 0.138\n",
            "[450,     4] loss: 0.142\n",
            "[451,     4] loss: 0.151\n",
            "[452,     4] loss: 0.142\n",
            "[453,     4] loss: 0.147\n",
            "[454,     4] loss: 0.153\n",
            "[455,     4] loss: 0.136\n",
            "[456,     4] loss: 0.144\n",
            "[457,     4] loss: 0.157\n",
            "[458,     4] loss: 0.144\n",
            "[459,     4] loss: 0.157\n",
            "[460,     4] loss: 0.139\n",
            "[461,     4] loss: 0.136\n",
            "[462,     4] loss: 0.139\n",
            "[463,     4] loss: 0.149\n",
            "[464,     4] loss: 0.149\n",
            "[465,     4] loss: 0.147\n",
            "[466,     4] loss: 0.140\n",
            "[467,     4] loss: 0.143\n",
            "[468,     4] loss: 0.146\n",
            "[469,     4] loss: 0.141\n",
            "[470,     4] loss: 0.165\n",
            "[471,     4] loss: 0.159\n",
            "[472,     4] loss: 0.159\n",
            "[473,     4] loss: 0.152\n",
            "[474,     4] loss: 0.153\n",
            "[475,     4] loss: 0.157\n",
            "[476,     4] loss: 0.142\n",
            "[477,     4] loss: 0.134\n",
            "[478,     4] loss: 0.155\n",
            "[479,     4] loss: 0.149\n",
            "[480,     4] loss: 0.149\n",
            "[481,     4] loss: 0.132\n",
            "[482,     4] loss: 0.146\n",
            "[483,     4] loss: 0.146\n",
            "[484,     4] loss: 0.140\n",
            "[485,     4] loss: 0.134\n",
            "[486,     4] loss: 0.131\n",
            "[487,     4] loss: 0.142\n",
            "[488,     4] loss: 0.139\n",
            "[489,     4] loss: 0.132\n",
            "[490,     4] loss: 0.135\n",
            "[491,     4] loss: 0.149\n",
            "[492,     4] loss: 0.148\n",
            "[493,     4] loss: 0.149\n",
            "[494,     4] loss: 0.159\n",
            "[495,     4] loss: 0.144\n",
            "[496,     4] loss: 0.143\n",
            "[497,     4] loss: 0.152\n",
            "[498,     4] loss: 0.157\n",
            "[499,     4] loss: 0.151\n",
            "[500,     4] loss: 0.152\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 94 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 50 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 74 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 94 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 63 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   4\n",
            "[1,     4] loss: 0.820\n",
            "[2,     4] loss: 0.536\n",
            "[3,     4] loss: 0.480\n",
            "[4,     4] loss: 0.473\n",
            "[5,     4] loss: 0.453\n",
            "[6,     4] loss: 0.466\n",
            "[7,     4] loss: 0.469\n",
            "[8,     4] loss: 0.464\n",
            "[9,     4] loss: 0.458\n",
            "[10,     4] loss: 0.454\n",
            "[11,     4] loss: 0.464\n",
            "[12,     4] loss: 0.452\n",
            "[13,     4] loss: 0.419\n",
            "[14,     4] loss: 0.385\n",
            "[15,     4] loss: 0.405\n",
            "[16,     4] loss: 0.369\n",
            "[17,     4] loss: 0.369\n",
            "[18,     4] loss: 0.339\n",
            "[19,     4] loss: 0.343\n",
            "[20,     4] loss: 0.333\n",
            "[21,     4] loss: 0.322\n",
            "[22,     4] loss: 0.364\n",
            "[23,     4] loss: 0.330\n",
            "[24,     4] loss: 0.339\n",
            "[25,     4] loss: 0.324\n",
            "[26,     4] loss: 0.347\n",
            "[27,     4] loss: 0.328\n",
            "[28,     4] loss: 0.331\n",
            "[29,     4] loss: 0.333\n",
            "[30,     4] loss: 0.345\n",
            "[31,     4] loss: 0.341\n",
            "[32,     4] loss: 0.344\n",
            "[33,     4] loss: 0.322\n",
            "[34,     4] loss: 0.324\n",
            "[35,     4] loss: 0.346\n",
            "[36,     4] loss: 0.342\n",
            "[37,     4] loss: 0.336\n",
            "[38,     4] loss: 0.354\n",
            "[39,     4] loss: 0.353\n",
            "[40,     4] loss: 0.329\n",
            "[41,     4] loss: 0.320\n",
            "[42,     4] loss: 0.320\n",
            "[43,     4] loss: 0.337\n",
            "[44,     4] loss: 0.337\n",
            "[45,     4] loss: 0.329\n",
            "[46,     4] loss: 0.335\n",
            "[47,     4] loss: 0.336\n",
            "[48,     4] loss: 0.338\n",
            "[49,     4] loss: 0.321\n",
            "[50,     4] loss: 0.323\n",
            "[51,     4] loss: 0.320\n",
            "[52,     4] loss: 0.324\n",
            "[53,     4] loss: 0.328\n",
            "[54,     4] loss: 0.325\n",
            "[55,     4] loss: 0.330\n",
            "[56,     4] loss: 0.337\n",
            "[57,     4] loss: 0.320\n",
            "[58,     4] loss: 0.319\n",
            "[59,     4] loss: 0.335\n",
            "[60,     4] loss: 0.330\n",
            "[61,     4] loss: 0.332\n",
            "[62,     4] loss: 0.325\n",
            "[63,     4] loss: 0.315\n",
            "[64,     4] loss: 0.337\n",
            "[65,     4] loss: 0.330\n",
            "[66,     4] loss: 0.352\n",
            "[67,     4] loss: 0.346\n",
            "[68,     4] loss: 0.345\n",
            "[69,     4] loss: 0.342\n",
            "[70,     4] loss: 0.333\n",
            "[71,     4] loss: 0.321\n",
            "[72,     4] loss: 0.319\n",
            "[73,     4] loss: 0.340\n",
            "[74,     4] loss: 0.321\n",
            "[75,     4] loss: 0.319\n",
            "[76,     4] loss: 0.314\n",
            "[77,     4] loss: 0.335\n",
            "[78,     4] loss: 0.332\n",
            "[79,     4] loss: 0.331\n",
            "[80,     4] loss: 0.324\n",
            "[81,     4] loss: 0.336\n",
            "[82,     4] loss: 0.322\n",
            "[83,     4] loss: 0.319\n",
            "[84,     4] loss: 0.335\n",
            "[85,     4] loss: 0.322\n",
            "[86,     4] loss: 0.310\n",
            "[87,     4] loss: 0.325\n",
            "[88,     4] loss: 0.338\n",
            "[89,     4] loss: 0.319\n",
            "[90,     4] loss: 0.316\n",
            "[91,     4] loss: 0.333\n",
            "[92,     4] loss: 0.336\n",
            "[93,     4] loss: 0.317\n",
            "[94,     4] loss: 0.320\n",
            "[95,     4] loss: 0.322\n",
            "[96,     4] loss: 0.317\n",
            "[97,     4] loss: 0.330\n",
            "[98,     4] loss: 0.321\n",
            "[99,     4] loss: 0.334\n",
            "[100,     4] loss: 0.333\n",
            "[101,     4] loss: 0.329\n",
            "[102,     4] loss: 0.332\n",
            "[103,     4] loss: 0.352\n",
            "[104,     4] loss: 0.351\n",
            "[105,     4] loss: 0.343\n",
            "[106,     4] loss: 0.346\n",
            "[107,     4] loss: 0.333\n",
            "[108,     4] loss: 0.336\n",
            "[109,     4] loss: 0.328\n",
            "[110,     4] loss: 0.336\n",
            "[111,     4] loss: 0.333\n",
            "[112,     4] loss: 0.336\n",
            "[113,     4] loss: 0.325\n",
            "[114,     4] loss: 0.329\n",
            "[115,     4] loss: 0.332\n",
            "[116,     4] loss: 0.331\n",
            "[117,     4] loss: 0.329\n",
            "[118,     4] loss: 0.317\n",
            "[119,     4] loss: 0.332\n",
            "[120,     4] loss: 0.324\n",
            "[121,     4] loss: 0.321\n",
            "[122,     4] loss: 0.324\n",
            "[123,     4] loss: 0.323\n",
            "[124,     4] loss: 0.334\n",
            "[125,     4] loss: 0.323\n",
            "[126,     4] loss: 0.331\n",
            "[127,     4] loss: 0.348\n",
            "[128,     4] loss: 0.327\n",
            "[129,     4] loss: 0.333\n",
            "[130,     4] loss: 0.322\n",
            "[131,     4] loss: 0.315\n",
            "[132,     4] loss: 0.325\n",
            "[133,     4] loss: 0.353\n",
            "[134,     4] loss: 0.342\n",
            "[135,     4] loss: 0.338\n",
            "[136,     4] loss: 0.322\n",
            "[137,     4] loss: 0.333\n",
            "[138,     4] loss: 0.343\n",
            "[139,     4] loss: 0.316\n",
            "[140,     4] loss: 0.324\n",
            "[141,     4] loss: 0.336\n",
            "[142,     4] loss: 0.338\n",
            "[143,     4] loss: 0.330\n",
            "[144,     4] loss: 0.324\n",
            "[145,     4] loss: 0.354\n",
            "[146,     4] loss: 0.347\n",
            "[147,     4] loss: 0.353\n",
            "[148,     4] loss: 0.354\n",
            "[149,     4] loss: 0.336\n",
            "[150,     4] loss: 0.330\n",
            "[151,     4] loss: 0.339\n",
            "[152,     4] loss: 0.332\n",
            "[153,     4] loss: 0.358\n",
            "[154,     4] loss: 0.342\n",
            "[155,     4] loss: 0.317\n",
            "[156,     4] loss: 0.337\n",
            "[157,     4] loss: 0.339\n",
            "[158,     4] loss: 0.334\n",
            "[159,     4] loss: 0.338\n",
            "[160,     4] loss: 0.317\n",
            "[161,     4] loss: 0.329\n",
            "[162,     4] loss: 0.322\n",
            "[163,     4] loss: 0.343\n",
            "[164,     4] loss: 0.317\n",
            "[165,     4] loss: 0.329\n",
            "[166,     4] loss: 0.331\n",
            "[167,     4] loss: 0.323\n",
            "[168,     4] loss: 0.333\n",
            "[169,     4] loss: 0.341\n",
            "[170,     4] loss: 0.354\n",
            "[171,     4] loss: 0.323\n",
            "[172,     4] loss: 0.327\n",
            "[173,     4] loss: 0.315\n",
            "[174,     4] loss: 0.323\n",
            "[175,     4] loss: 0.318\n",
            "[176,     4] loss: 0.326\n",
            "[177,     4] loss: 0.322\n",
            "[178,     4] loss: 0.321\n",
            "[179,     4] loss: 0.318\n",
            "[180,     4] loss: 0.330\n",
            "[181,     4] loss: 0.332\n",
            "[182,     4] loss: 0.318\n",
            "[183,     4] loss: 0.328\n",
            "[184,     4] loss: 0.322\n",
            "[185,     4] loss: 0.332\n",
            "[186,     4] loss: 0.323\n",
            "[187,     4] loss: 0.326\n",
            "[188,     4] loss: 0.317\n",
            "[189,     4] loss: 0.305\n",
            "[190,     4] loss: 0.326\n",
            "[191,     4] loss: 0.334\n",
            "[192,     4] loss: 0.328\n",
            "[193,     4] loss: 0.343\n",
            "[194,     4] loss: 0.320\n",
            "[195,     4] loss: 0.334\n",
            "[196,     4] loss: 0.324\n",
            "[197,     4] loss: 0.331\n",
            "[198,     4] loss: 0.329\n",
            "[199,     4] loss: 0.319\n",
            "[200,     4] loss: 0.318\n",
            "[201,     4] loss: 0.324\n",
            "[202,     4] loss: 0.332\n",
            "[203,     4] loss: 0.317\n",
            "[204,     4] loss: 0.324\n",
            "[205,     4] loss: 0.323\n",
            "[206,     4] loss: 0.346\n",
            "[207,     4] loss: 0.339\n",
            "[208,     4] loss: 0.322\n",
            "[209,     4] loss: 0.314\n",
            "[210,     4] loss: 0.320\n",
            "[211,     4] loss: 0.317\n",
            "[212,     4] loss: 0.315\n",
            "[213,     4] loss: 0.321\n",
            "[214,     4] loss: 0.323\n",
            "[215,     4] loss: 0.324\n",
            "[216,     4] loss: 0.337\n",
            "[217,     4] loss: 0.328\n",
            "[218,     4] loss: 0.326\n",
            "[219,     4] loss: 0.334\n",
            "[220,     4] loss: 0.329\n",
            "[221,     4] loss: 0.319\n",
            "[222,     4] loss: 0.319\n",
            "[223,     4] loss: 0.329\n",
            "[224,     4] loss: 0.334\n",
            "[225,     4] loss: 0.313\n",
            "[226,     4] loss: 0.357\n",
            "[227,     4] loss: 0.340\n",
            "[228,     4] loss: 0.318\n",
            "[229,     4] loss: 0.332\n",
            "[230,     4] loss: 0.337\n",
            "[231,     4] loss: 0.315\n",
            "[232,     4] loss: 0.313\n",
            "[233,     4] loss: 0.327\n",
            "[234,     4] loss: 0.306\n",
            "[235,     4] loss: 0.321\n",
            "[236,     4] loss: 0.320\n",
            "[237,     4] loss: 0.317\n",
            "[238,     4] loss: 0.310\n",
            "[239,     4] loss: 0.336\n",
            "[240,     4] loss: 0.328\n",
            "[241,     4] loss: 0.311\n",
            "[242,     4] loss: 0.322\n",
            "[243,     4] loss: 0.339\n",
            "[244,     4] loss: 0.329\n",
            "[245,     4] loss: 0.341\n",
            "[246,     4] loss: 0.326\n",
            "[247,     4] loss: 0.324\n",
            "[248,     4] loss: 0.315\n",
            "[249,     4] loss: 0.332\n",
            "[250,     4] loss: 0.337\n",
            "[251,     4] loss: 0.347\n",
            "[252,     4] loss: 0.319\n",
            "[253,     4] loss: 0.325\n",
            "[254,     4] loss: 0.325\n",
            "[255,     4] loss: 0.335\n",
            "[256,     4] loss: 0.328\n",
            "[257,     4] loss: 0.319\n",
            "[258,     4] loss: 0.355\n",
            "[259,     4] loss: 0.329\n",
            "[260,     4] loss: 0.334\n",
            "[261,     4] loss: 0.331\n",
            "[262,     4] loss: 0.334\n",
            "[263,     4] loss: 0.323\n",
            "[264,     4] loss: 0.332\n",
            "[265,     4] loss: 0.329\n",
            "[266,     4] loss: 0.332\n",
            "[267,     4] loss: 0.321\n",
            "[268,     4] loss: 0.323\n",
            "[269,     4] loss: 0.326\n",
            "[270,     4] loss: 0.334\n",
            "[271,     4] loss: 0.332\n",
            "[272,     4] loss: 0.321\n",
            "[273,     4] loss: 0.321\n",
            "[274,     4] loss: 0.325\n",
            "[275,     4] loss: 0.315\n",
            "[276,     4] loss: 0.325\n",
            "[277,     4] loss: 0.328\n",
            "[278,     4] loss: 0.331\n",
            "[279,     4] loss: 0.314\n",
            "[280,     4] loss: 0.314\n",
            "[281,     4] loss: 0.331\n",
            "[282,     4] loss: 0.331\n",
            "[283,     4] loss: 0.323\n",
            "[284,     4] loss: 0.339\n",
            "[285,     4] loss: 0.333\n",
            "[286,     4] loss: 0.308\n",
            "[287,     4] loss: 0.333\n",
            "[288,     4] loss: 0.322\n",
            "[289,     4] loss: 0.313\n",
            "[290,     4] loss: 0.314\n",
            "[291,     4] loss: 0.320\n",
            "[292,     4] loss: 0.314\n",
            "[293,     4] loss: 0.335\n",
            "[294,     4] loss: 0.316\n",
            "[295,     4] loss: 0.325\n",
            "[296,     4] loss: 0.314\n",
            "[297,     4] loss: 0.335\n",
            "[298,     4] loss: 0.316\n",
            "[299,     4] loss: 0.314\n",
            "[300,     4] loss: 0.324\n",
            "[301,     4] loss: 0.319\n",
            "[302,     4] loss: 0.334\n",
            "[303,     4] loss: 0.322\n",
            "[304,     4] loss: 0.336\n",
            "[305,     4] loss: 0.316\n",
            "[306,     4] loss: 0.325\n",
            "[307,     4] loss: 0.334\n",
            "[308,     4] loss: 0.322\n",
            "[309,     4] loss: 0.343\n",
            "[310,     4] loss: 0.354\n",
            "[311,     4] loss: 0.356\n",
            "[312,     4] loss: 0.329\n",
            "[313,     4] loss: 0.327\n",
            "[314,     4] loss: 0.326\n",
            "[315,     4] loss: 0.312\n",
            "[316,     4] loss: 0.323\n",
            "[317,     4] loss: 0.315\n",
            "[318,     4] loss: 0.324\n",
            "[319,     4] loss: 0.319\n",
            "[320,     4] loss: 0.326\n",
            "[321,     4] loss: 0.325\n",
            "[322,     4] loss: 0.324\n",
            "[323,     4] loss: 0.315\n",
            "[324,     4] loss: 0.322\n",
            "[325,     4] loss: 0.317\n",
            "[326,     4] loss: 0.321\n",
            "[327,     4] loss: 0.326\n",
            "[328,     4] loss: 0.311\n",
            "[329,     4] loss: 0.330\n",
            "[330,     4] loss: 0.325\n",
            "[331,     4] loss: 0.318\n",
            "[332,     4] loss: 0.332\n",
            "[333,     4] loss: 0.319\n",
            "[334,     4] loss: 0.311\n",
            "[335,     4] loss: 0.322\n",
            "[336,     4] loss: 0.311\n",
            "[337,     4] loss: 0.319\n",
            "[338,     4] loss: 0.324\n",
            "[339,     4] loss: 0.321\n",
            "[340,     4] loss: 0.342\n",
            "[341,     4] loss: 0.319\n",
            "[342,     4] loss: 0.330\n",
            "[343,     4] loss: 0.331\n",
            "[344,     4] loss: 0.332\n",
            "[345,     4] loss: 0.351\n",
            "[346,     4] loss: 0.333\n",
            "[347,     4] loss: 0.314\n",
            "[348,     4] loss: 0.327\n",
            "[349,     4] loss: 0.324\n",
            "[350,     4] loss: 0.324\n",
            "[351,     4] loss: 0.315\n",
            "[352,     4] loss: 0.299\n",
            "[353,     4] loss: 0.339\n",
            "[354,     4] loss: 0.317\n",
            "[355,     4] loss: 0.310\n",
            "[356,     4] loss: 0.334\n",
            "[357,     4] loss: 0.315\n",
            "[358,     4] loss: 0.319\n",
            "[359,     4] loss: 0.316\n",
            "[360,     4] loss: 0.322\n",
            "[361,     4] loss: 0.327\n",
            "[362,     4] loss: 0.313\n",
            "[363,     4] loss: 0.325\n",
            "[364,     4] loss: 0.319\n",
            "[365,     4] loss: 0.319\n",
            "[366,     4] loss: 0.329\n",
            "[367,     4] loss: 0.338\n",
            "[368,     4] loss: 0.333\n",
            "[369,     4] loss: 0.314\n",
            "[370,     4] loss: 0.316\n",
            "[371,     4] loss: 0.318\n",
            "[372,     4] loss: 0.328\n",
            "[373,     4] loss: 0.317\n",
            "[374,     4] loss: 0.332\n",
            "[375,     4] loss: 0.324\n",
            "[376,     4] loss: 0.326\n",
            "[377,     4] loss: 0.309\n",
            "[378,     4] loss: 0.321\n",
            "[379,     4] loss: 0.324\n",
            "[380,     4] loss: 0.318\n",
            "[381,     4] loss: 0.326\n",
            "[382,     4] loss: 0.318\n",
            "[383,     4] loss: 0.326\n",
            "[384,     4] loss: 0.330\n",
            "[385,     4] loss: 0.320\n",
            "[386,     4] loss: 0.316\n",
            "[387,     4] loss: 0.321\n",
            "[388,     4] loss: 0.329\n",
            "[389,     4] loss: 0.314\n",
            "[390,     4] loss: 0.319\n",
            "[391,     4] loss: 0.313\n",
            "[392,     4] loss: 0.318\n",
            "[393,     4] loss: 0.334\n",
            "[394,     4] loss: 0.318\n",
            "[395,     4] loss: 0.330\n",
            "[396,     4] loss: 0.309\n",
            "[397,     4] loss: 0.309\n",
            "[398,     4] loss: 0.322\n",
            "[399,     4] loss: 0.317\n",
            "[400,     4] loss: 0.320\n",
            "[401,     4] loss: 0.313\n",
            "[402,     4] loss: 0.318\n",
            "[403,     4] loss: 0.315\n",
            "[404,     4] loss: 0.331\n",
            "[405,     4] loss: 0.323\n",
            "[406,     4] loss: 0.320\n",
            "[407,     4] loss: 0.327\n",
            "[408,     4] loss: 0.327\n",
            "[409,     4] loss: 0.317\n",
            "[410,     4] loss: 0.319\n",
            "[411,     4] loss: 0.312\n",
            "[412,     4] loss: 0.330\n",
            "[413,     4] loss: 0.305\n",
            "[414,     4] loss: 0.319\n",
            "[415,     4] loss: 0.319\n",
            "[416,     4] loss: 0.321\n",
            "[417,     4] loss: 0.326\n",
            "[418,     4] loss: 0.312\n",
            "[419,     4] loss: 0.332\n",
            "[420,     4] loss: 0.319\n",
            "[421,     4] loss: 0.343\n",
            "[422,     4] loss: 0.324\n",
            "[423,     4] loss: 0.315\n",
            "[424,     4] loss: 0.330\n",
            "[425,     4] loss: 0.326\n",
            "[426,     4] loss: 0.331\n",
            "[427,     4] loss: 0.331\n",
            "[428,     4] loss: 0.320\n",
            "[429,     4] loss: 0.323\n",
            "[430,     4] loss: 0.325\n",
            "[431,     4] loss: 0.315\n",
            "[432,     4] loss: 0.322\n",
            "[433,     4] loss: 0.333\n",
            "[434,     4] loss: 0.329\n",
            "[435,     4] loss: 0.331\n",
            "[436,     4] loss: 0.313\n",
            "[437,     4] loss: 0.322\n",
            "[438,     4] loss: 0.313\n",
            "[439,     4] loss: 0.323\n",
            "[440,     4] loss: 0.337\n",
            "[441,     4] loss: 0.340\n",
            "[442,     4] loss: 0.360\n",
            "[443,     4] loss: 0.354\n",
            "[444,     4] loss: 0.317\n",
            "[445,     4] loss: 0.313\n",
            "[446,     4] loss: 0.316\n",
            "[447,     4] loss: 0.318\n",
            "[448,     4] loss: 0.326\n",
            "[449,     4] loss: 0.322\n",
            "[450,     4] loss: 0.315\n",
            "[451,     4] loss: 0.334\n",
            "[452,     4] loss: 0.313\n",
            "[453,     4] loss: 0.328\n",
            "[454,     4] loss: 0.309\n",
            "[455,     4] loss: 0.319\n",
            "[456,     4] loss: 0.317\n",
            "[457,     4] loss: 0.319\n",
            "[458,     4] loss: 0.323\n",
            "[459,     4] loss: 0.334\n",
            "[460,     4] loss: 0.330\n",
            "[461,     4] loss: 0.324\n",
            "[462,     4] loss: 0.323\n",
            "[463,     4] loss: 0.335\n",
            "[464,     4] loss: 0.310\n",
            "[465,     4] loss: 0.322\n",
            "[466,     4] loss: 0.329\n",
            "[467,     4] loss: 0.336\n",
            "[468,     4] loss: 0.338\n",
            "[469,     4] loss: 0.321\n",
            "[470,     4] loss: 0.327\n",
            "[471,     4] loss: 0.332\n",
            "[472,     4] loss: 0.321\n",
            "[473,     4] loss: 0.321\n",
            "[474,     4] loss: 0.324\n",
            "[475,     4] loss: 0.332\n",
            "[476,     4] loss: 0.327\n",
            "[477,     4] loss: 0.330\n",
            "[478,     4] loss: 0.304\n",
            "[479,     4] loss: 0.345\n",
            "[480,     4] loss: 0.328\n",
            "[481,     4] loss: 0.331\n",
            "[482,     4] loss: 0.328\n",
            "[483,     4] loss: 0.324\n",
            "[484,     4] loss: 0.325\n",
            "[485,     4] loss: 0.318\n",
            "[486,     4] loss: 0.325\n",
            "[487,     4] loss: 0.320\n",
            "[488,     4] loss: 0.342\n",
            "[489,     4] loss: 0.317\n",
            "[490,     4] loss: 0.322\n",
            "[491,     4] loss: 0.351\n",
            "[492,     4] loss: 0.317\n",
            "[493,     4] loss: 0.335\n",
            "[494,     4] loss: 0.328\n",
            "[495,     4] loss: 0.314\n",
            "[496,     4] loss: 0.323\n",
            "[497,     4] loss: 0.315\n",
            "[498,     4] loss: 0.312\n",
            "[499,     4] loss: 0.318\n",
            "[500,     4] loss: 0.321\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 83 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 66 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 69 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 70 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 83 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 63 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   5\n",
            "[1,     4] loss: 0.749\n",
            "[2,     4] loss: 0.487\n",
            "[3,     4] loss: 0.467\n",
            "[4,     4] loss: 0.468\n",
            "[5,     4] loss: 0.468\n",
            "[6,     4] loss: 0.452\n",
            "[7,     4] loss: 0.480\n",
            "[8,     4] loss: 0.464\n",
            "[9,     4] loss: 0.473\n",
            "[10,     4] loss: 0.474\n",
            "[11,     4] loss: 0.473\n",
            "[12,     4] loss: 0.466\n",
            "[13,     4] loss: 0.470\n",
            "[14,     4] loss: 0.465\n",
            "[15,     4] loss: 0.467\n",
            "[16,     4] loss: 0.456\n",
            "[17,     4] loss: 0.463\n",
            "[18,     4] loss: 0.456\n",
            "[19,     4] loss: 0.476\n",
            "[20,     4] loss: 0.471\n",
            "[21,     4] loss: 0.464\n",
            "[22,     4] loss: 0.461\n",
            "[23,     4] loss: 0.476\n",
            "[24,     4] loss: 0.462\n",
            "[25,     4] loss: 0.462\n",
            "[26,     4] loss: 0.470\n",
            "[27,     4] loss: 0.467\n",
            "[28,     4] loss: 0.469\n",
            "[29,     4] loss: 0.476\n",
            "[30,     4] loss: 0.461\n",
            "[31,     4] loss: 0.461\n",
            "[32,     4] loss: 0.466\n",
            "[33,     4] loss: 0.468\n",
            "[34,     4] loss: 0.460\n",
            "[35,     4] loss: 0.456\n",
            "[36,     4] loss: 0.462\n",
            "[37,     4] loss: 0.464\n",
            "[38,     4] loss: 0.465\n",
            "[39,     4] loss: 0.458\n",
            "[40,     4] loss: 0.476\n",
            "[41,     4] loss: 0.465\n",
            "[42,     4] loss: 0.464\n",
            "[43,     4] loss: 0.465\n",
            "[44,     4] loss: 0.469\n",
            "[45,     4] loss: 0.477\n",
            "[46,     4] loss: 0.469\n",
            "[47,     4] loss: 0.460\n",
            "[48,     4] loss: 0.461\n",
            "[49,     4] loss: 0.460\n",
            "[50,     4] loss: 0.461\n",
            "[51,     4] loss: 0.459\n",
            "[52,     4] loss: 0.449\n",
            "[53,     4] loss: 0.459\n",
            "[54,     4] loss: 0.467\n",
            "[55,     4] loss: 0.457\n",
            "[56,     4] loss: 0.458\n",
            "[57,     4] loss: 0.469\n",
            "[58,     4] loss: 0.468\n",
            "[59,     4] loss: 0.461\n",
            "[60,     4] loss: 0.465\n",
            "[61,     4] loss: 0.470\n",
            "[62,     4] loss: 0.454\n",
            "[63,     4] loss: 0.468\n",
            "[64,     4] loss: 0.454\n",
            "[65,     4] loss: 0.457\n",
            "[66,     4] loss: 0.460\n",
            "[67,     4] loss: 0.468\n",
            "[68,     4] loss: 0.458\n",
            "[69,     4] loss: 0.471\n",
            "[70,     4] loss: 0.463\n",
            "[71,     4] loss: 0.467\n",
            "[72,     4] loss: 0.470\n",
            "[73,     4] loss: 0.475\n",
            "[74,     4] loss: 0.465\n",
            "[75,     4] loss: 0.455\n",
            "[76,     4] loss: 0.466\n",
            "[77,     4] loss: 0.464\n",
            "[78,     4] loss: 0.463\n",
            "[79,     4] loss: 0.470\n",
            "[80,     4] loss: 0.465\n",
            "[81,     4] loss: 0.469\n",
            "[82,     4] loss: 0.469\n",
            "[83,     4] loss: 0.460\n",
            "[84,     4] loss: 0.459\n",
            "[85,     4] loss: 0.445\n",
            "[86,     4] loss: 0.466\n",
            "[87,     4] loss: 0.463\n",
            "[88,     4] loss: 0.463\n",
            "[89,     4] loss: 0.465\n",
            "[90,     4] loss: 0.476\n",
            "[91,     4] loss: 0.464\n",
            "[92,     4] loss: 0.458\n",
            "[93,     4] loss: 0.463\n",
            "[94,     4] loss: 0.467\n",
            "[95,     4] loss: 0.461\n",
            "[96,     4] loss: 0.461\n",
            "[97,     4] loss: 0.479\n",
            "[98,     4] loss: 0.472\n",
            "[99,     4] loss: 0.460\n",
            "[100,     4] loss: 0.466\n",
            "[101,     4] loss: 0.460\n",
            "[102,     4] loss: 0.457\n",
            "[103,     4] loss: 0.463\n",
            "[104,     4] loss: 0.457\n",
            "[105,     4] loss: 0.456\n",
            "[106,     4] loss: 0.461\n",
            "[107,     4] loss: 0.458\n",
            "[108,     4] loss: 0.477\n",
            "[109,     4] loss: 0.463\n",
            "[110,     4] loss: 0.471\n",
            "[111,     4] loss: 0.456\n",
            "[112,     4] loss: 0.461\n",
            "[113,     4] loss: 0.465\n",
            "[114,     4] loss: 0.458\n",
            "[115,     4] loss: 0.464\n",
            "[116,     4] loss: 0.464\n",
            "[117,     4] loss: 0.462\n",
            "[118,     4] loss: 0.472\n",
            "[119,     4] loss: 0.460\n",
            "[120,     4] loss: 0.459\n",
            "[121,     4] loss: 0.469\n",
            "[122,     4] loss: 0.461\n",
            "[123,     4] loss: 0.459\n",
            "[124,     4] loss: 0.461\n",
            "[125,     4] loss: 0.466\n",
            "[126,     4] loss: 0.470\n",
            "[127,     4] loss: 0.467\n",
            "[128,     4] loss: 0.459\n",
            "[129,     4] loss: 0.469\n",
            "[130,     4] loss: 0.460\n",
            "[131,     4] loss: 0.461\n",
            "[132,     4] loss: 0.457\n",
            "[133,     4] loss: 0.469\n",
            "[134,     4] loss: 0.456\n",
            "[135,     4] loss: 0.460\n",
            "[136,     4] loss: 0.463\n",
            "[137,     4] loss: 0.465\n",
            "[138,     4] loss: 0.461\n",
            "[139,     4] loss: 0.458\n",
            "[140,     4] loss: 0.461\n",
            "[141,     4] loss: 0.458\n",
            "[142,     4] loss: 0.459\n",
            "[143,     4] loss: 0.457\n",
            "[144,     4] loss: 0.468\n",
            "[145,     4] loss: 0.471\n",
            "[146,     4] loss: 0.467\n",
            "[147,     4] loss: 0.469\n",
            "[148,     4] loss: 0.469\n",
            "[149,     4] loss: 0.469\n",
            "[150,     4] loss: 0.469\n",
            "[151,     4] loss: 0.464\n",
            "[152,     4] loss: 0.462\n",
            "[153,     4] loss: 0.467\n",
            "[154,     4] loss: 0.470\n",
            "[155,     4] loss: 0.458\n",
            "[156,     4] loss: 0.465\n",
            "[157,     4] loss: 0.474\n",
            "[158,     4] loss: 0.457\n",
            "[159,     4] loss: 0.464\n",
            "[160,     4] loss: 0.470\n",
            "[161,     4] loss: 0.463\n",
            "[162,     4] loss: 0.465\n",
            "[163,     4] loss: 0.468\n",
            "[164,     4] loss: 0.458\n",
            "[165,     4] loss: 0.458\n",
            "[166,     4] loss: 0.456\n",
            "[167,     4] loss: 0.464\n",
            "[168,     4] loss: 0.467\n",
            "[169,     4] loss: 0.462\n",
            "[170,     4] loss: 0.463\n",
            "[171,     4] loss: 0.467\n",
            "[172,     4] loss: 0.454\n",
            "[173,     4] loss: 0.465\n",
            "[174,     4] loss: 0.459\n",
            "[175,     4] loss: 0.459\n",
            "[176,     4] loss: 0.457\n",
            "[177,     4] loss: 0.465\n",
            "[178,     4] loss: 0.457\n",
            "[179,     4] loss: 0.459\n",
            "[180,     4] loss: 0.457\n",
            "[181,     4] loss: 0.465\n",
            "[182,     4] loss: 0.460\n",
            "[183,     4] loss: 0.461\n",
            "[184,     4] loss: 0.463\n",
            "[185,     4] loss: 0.476\n",
            "[186,     4] loss: 0.467\n",
            "[187,     4] loss: 0.466\n",
            "[188,     4] loss: 0.466\n",
            "[189,     4] loss: 0.462\n",
            "[190,     4] loss: 0.460\n",
            "[191,     4] loss: 0.457\n",
            "[192,     4] loss: 0.468\n",
            "[193,     4] loss: 0.466\n",
            "[194,     4] loss: 0.465\n",
            "[195,     4] loss: 0.466\n",
            "[196,     4] loss: 0.460\n",
            "[197,     4] loss: 0.458\n",
            "[198,     4] loss: 0.466\n",
            "[199,     4] loss: 0.467\n",
            "[200,     4] loss: 0.455\n",
            "[201,     4] loss: 0.463\n",
            "[202,     4] loss: 0.458\n",
            "[203,     4] loss: 0.471\n",
            "[204,     4] loss: 0.457\n",
            "[205,     4] loss: 0.458\n",
            "[206,     4] loss: 0.466\n",
            "[207,     4] loss: 0.461\n",
            "[208,     4] loss: 0.463\n",
            "[209,     4] loss: 0.464\n",
            "[210,     4] loss: 0.454\n",
            "[211,     4] loss: 0.464\n",
            "[212,     4] loss: 0.457\n",
            "[213,     4] loss: 0.472\n",
            "[214,     4] loss: 0.457\n",
            "[215,     4] loss: 0.456\n",
            "[216,     4] loss: 0.464\n",
            "[217,     4] loss: 0.461\n",
            "[218,     4] loss: 0.455\n",
            "[219,     4] loss: 0.463\n",
            "[220,     4] loss: 0.455\n",
            "[221,     4] loss: 0.463\n",
            "[222,     4] loss: 0.462\n",
            "[223,     4] loss: 0.465\n",
            "[224,     4] loss: 0.466\n",
            "[225,     4] loss: 0.466\n",
            "[226,     4] loss: 0.458\n",
            "[227,     4] loss: 0.454\n",
            "[228,     4] loss: 0.470\n",
            "[229,     4] loss: 0.461\n",
            "[230,     4] loss: 0.448\n",
            "[231,     4] loss: 0.469\n",
            "[232,     4] loss: 0.459\n",
            "[233,     4] loss: 0.455\n",
            "[234,     4] loss: 0.465\n",
            "[235,     4] loss: 0.471\n",
            "[236,     4] loss: 0.457\n",
            "[237,     4] loss: 0.454\n",
            "[238,     4] loss: 0.459\n",
            "[239,     4] loss: 0.452\n",
            "[240,     4] loss: 0.461\n",
            "[241,     4] loss: 0.453\n",
            "[242,     4] loss: 0.469\n",
            "[243,     4] loss: 0.457\n",
            "[244,     4] loss: 0.472\n",
            "[245,     4] loss: 0.461\n",
            "[246,     4] loss: 0.453\n",
            "[247,     4] loss: 0.464\n",
            "[248,     4] loss: 0.453\n",
            "[249,     4] loss: 0.471\n",
            "[250,     4] loss: 0.466\n",
            "[251,     4] loss: 0.467\n",
            "[252,     4] loss: 0.460\n",
            "[253,     4] loss: 0.457\n",
            "[254,     4] loss: 0.461\n",
            "[255,     4] loss: 0.456\n",
            "[256,     4] loss: 0.461\n",
            "[257,     4] loss: 0.466\n",
            "[258,     4] loss: 0.464\n",
            "[259,     4] loss: 0.460\n",
            "[260,     4] loss: 0.458\n",
            "[261,     4] loss: 0.471\n",
            "[262,     4] loss: 0.456\n",
            "[263,     4] loss: 0.456\n",
            "[264,     4] loss: 0.468\n",
            "[265,     4] loss: 0.459\n",
            "[266,     4] loss: 0.464\n",
            "[267,     4] loss: 0.459\n",
            "[268,     4] loss: 0.466\n",
            "[269,     4] loss: 0.472\n",
            "[270,     4] loss: 0.464\n",
            "[271,     4] loss: 0.466\n",
            "[272,     4] loss: 0.457\n",
            "[273,     4] loss: 0.467\n",
            "[274,     4] loss: 0.455\n",
            "[275,     4] loss: 0.463\n",
            "[276,     4] loss: 0.459\n",
            "[277,     4] loss: 0.464\n",
            "[278,     4] loss: 0.454\n",
            "[279,     4] loss: 0.462\n",
            "[280,     4] loss: 0.455\n",
            "[281,     4] loss: 0.465\n",
            "[282,     4] loss: 0.456\n",
            "[283,     4] loss: 0.454\n",
            "[284,     4] loss: 0.465\n",
            "[285,     4] loss: 0.459\n",
            "[286,     4] loss: 0.462\n",
            "[287,     4] loss: 0.455\n",
            "[288,     4] loss: 0.452\n",
            "[289,     4] loss: 0.465\n",
            "[290,     4] loss: 0.478\n",
            "[291,     4] loss: 0.458\n",
            "[292,     4] loss: 0.459\n",
            "[293,     4] loss: 0.464\n",
            "[294,     4] loss: 0.470\n",
            "[295,     4] loss: 0.455\n",
            "[296,     4] loss: 0.451\n",
            "[297,     4] loss: 0.454\n",
            "[298,     4] loss: 0.464\n",
            "[299,     4] loss: 0.461\n",
            "[300,     4] loss: 0.465\n",
            "[301,     4] loss: 0.466\n",
            "[302,     4] loss: 0.467\n",
            "[303,     4] loss: 0.464\n",
            "[304,     4] loss: 0.461\n",
            "[305,     4] loss: 0.455\n",
            "[306,     4] loss: 0.466\n",
            "[307,     4] loss: 0.472\n",
            "[308,     4] loss: 0.460\n",
            "[309,     4] loss: 0.469\n",
            "[310,     4] loss: 0.463\n",
            "[311,     4] loss: 0.454\n",
            "[312,     4] loss: 0.463\n",
            "[313,     4] loss: 0.460\n",
            "[314,     4] loss: 0.463\n",
            "[315,     4] loss: 0.465\n",
            "[316,     4] loss: 0.464\n",
            "[317,     4] loss: 0.457\n",
            "[318,     4] loss: 0.458\n",
            "[319,     4] loss: 0.463\n",
            "[320,     4] loss: 0.458\n",
            "[321,     4] loss: 0.470\n",
            "[322,     4] loss: 0.462\n",
            "[323,     4] loss: 0.463\n",
            "[324,     4] loss: 0.459\n",
            "[325,     4] loss: 0.454\n",
            "[326,     4] loss: 0.466\n",
            "[327,     4] loss: 0.462\n",
            "[328,     4] loss: 0.463\n",
            "[329,     4] loss: 0.463\n",
            "[330,     4] loss: 0.453\n",
            "[331,     4] loss: 0.471\n",
            "[332,     4] loss: 0.451\n",
            "[333,     4] loss: 0.462\n",
            "[334,     4] loss: 0.455\n",
            "[335,     4] loss: 0.462\n",
            "[336,     4] loss: 0.457\n",
            "[337,     4] loss: 0.464\n",
            "[338,     4] loss: 0.457\n",
            "[339,     4] loss: 0.451\n",
            "[340,     4] loss: 0.467\n",
            "[341,     4] loss: 0.462\n",
            "[342,     4] loss: 0.464\n",
            "[343,     4] loss: 0.460\n",
            "[344,     4] loss: 0.462\n",
            "[345,     4] loss: 0.456\n",
            "[346,     4] loss: 0.458\n",
            "[347,     4] loss: 0.458\n",
            "[348,     4] loss: 0.457\n",
            "[349,     4] loss: 0.455\n",
            "[350,     4] loss: 0.460\n",
            "[351,     4] loss: 0.467\n",
            "[352,     4] loss: 0.464\n",
            "[353,     4] loss: 0.457\n",
            "[354,     4] loss: 0.467\n",
            "[355,     4] loss: 0.452\n",
            "[356,     4] loss: 0.453\n",
            "[357,     4] loss: 0.466\n",
            "[358,     4] loss: 0.462\n",
            "[359,     4] loss: 0.464\n",
            "[360,     4] loss: 0.449\n",
            "[361,     4] loss: 0.457\n",
            "[362,     4] loss: 0.468\n",
            "[363,     4] loss: 0.465\n",
            "[364,     4] loss: 0.470\n",
            "[365,     4] loss: 0.467\n",
            "[366,     4] loss: 0.458\n",
            "[367,     4] loss: 0.457\n",
            "[368,     4] loss: 0.465\n",
            "[369,     4] loss: 0.463\n",
            "[370,     4] loss: 0.467\n",
            "[371,     4] loss: 0.452\n",
            "[372,     4] loss: 0.453\n",
            "[373,     4] loss: 0.452\n",
            "[374,     4] loss: 0.453\n",
            "[375,     4] loss: 0.462\n",
            "[376,     4] loss: 0.462\n",
            "[377,     4] loss: 0.469\n",
            "[378,     4] loss: 0.459\n",
            "[379,     4] loss: 0.465\n",
            "[380,     4] loss: 0.453\n",
            "[381,     4] loss: 0.466\n",
            "[382,     4] loss: 0.459\n",
            "[383,     4] loss: 0.467\n",
            "[384,     4] loss: 0.460\n",
            "[385,     4] loss: 0.462\n",
            "[386,     4] loss: 0.470\n",
            "[387,     4] loss: 0.459\n",
            "[388,     4] loss: 0.464\n",
            "[389,     4] loss: 0.455\n",
            "[390,     4] loss: 0.463\n",
            "[391,     4] loss: 0.455\n",
            "[392,     4] loss: 0.458\n",
            "[393,     4] loss: 0.466\n",
            "[394,     4] loss: 0.463\n",
            "[395,     4] loss: 0.466\n",
            "[396,     4] loss: 0.464\n",
            "[397,     4] loss: 0.463\n",
            "[398,     4] loss: 0.470\n",
            "[399,     4] loss: 0.459\n",
            "[400,     4] loss: 0.467\n",
            "[401,     4] loss: 0.469\n",
            "[402,     4] loss: 0.462\n",
            "[403,     4] loss: 0.464\n",
            "[404,     4] loss: 0.463\n",
            "[405,     4] loss: 0.453\n",
            "[406,     4] loss: 0.461\n",
            "[407,     4] loss: 0.455\n",
            "[408,     4] loss: 0.463\n",
            "[409,     4] loss: 0.459\n",
            "[410,     4] loss: 0.473\n",
            "[411,     4] loss: 0.464\n",
            "[412,     4] loss: 0.459\n",
            "[413,     4] loss: 0.469\n",
            "[414,     4] loss: 0.465\n",
            "[415,     4] loss: 0.453\n",
            "[416,     4] loss: 0.464\n",
            "[417,     4] loss: 0.468\n",
            "[418,     4] loss: 0.463\n",
            "[419,     4] loss: 0.459\n",
            "[420,     4] loss: 0.462\n",
            "[421,     4] loss: 0.458\n",
            "[422,     4] loss: 0.461\n",
            "[423,     4] loss: 0.468\n",
            "[424,     4] loss: 0.463\n",
            "[425,     4] loss: 0.458\n",
            "[426,     4] loss: 0.456\n",
            "[427,     4] loss: 0.469\n",
            "[428,     4] loss: 0.461\n",
            "[429,     4] loss: 0.462\n",
            "[430,     4] loss: 0.460\n",
            "[431,     4] loss: 0.463\n",
            "[432,     4] loss: 0.457\n",
            "[433,     4] loss: 0.458\n",
            "[434,     4] loss: 0.462\n",
            "[435,     4] loss: 0.473\n",
            "[436,     4] loss: 0.456\n",
            "[437,     4] loss: 0.464\n",
            "[438,     4] loss: 0.462\n",
            "[439,     4] loss: 0.466\n",
            "[440,     4] loss: 0.458\n",
            "[441,     4] loss: 0.450\n",
            "[442,     4] loss: 0.470\n",
            "[443,     4] loss: 0.455\n",
            "[444,     4] loss: 0.461\n",
            "[445,     4] loss: 0.457\n",
            "[446,     4] loss: 0.470\n",
            "[447,     4] loss: 0.464\n",
            "[448,     4] loss: 0.454\n",
            "[449,     4] loss: 0.461\n",
            "[450,     4] loss: 0.449\n",
            "[451,     4] loss: 0.459\n",
            "[452,     4] loss: 0.454\n",
            "[453,     4] loss: 0.450\n",
            "[454,     4] loss: 0.464\n",
            "[455,     4] loss: 0.466\n",
            "[456,     4] loss: 0.458\n",
            "[457,     4] loss: 0.468\n",
            "[458,     4] loss: 0.472\n",
            "[459,     4] loss: 0.445\n",
            "[460,     4] loss: 0.459\n",
            "[461,     4] loss: 0.456\n",
            "[462,     4] loss: 0.455\n",
            "[463,     4] loss: 0.465\n",
            "[464,     4] loss: 0.454\n",
            "[465,     4] loss: 0.464\n",
            "[466,     4] loss: 0.463\n",
            "[467,     4] loss: 0.459\n",
            "[468,     4] loss: 0.464\n",
            "[469,     4] loss: 0.459\n",
            "[470,     4] loss: 0.456\n",
            "[471,     4] loss: 0.457\n",
            "[472,     4] loss: 0.456\n",
            "[473,     4] loss: 0.470\n",
            "[474,     4] loss: 0.459\n",
            "[475,     4] loss: 0.456\n",
            "[476,     4] loss: 0.460\n",
            "[477,     4] loss: 0.461\n",
            "[478,     4] loss: 0.466\n",
            "[479,     4] loss: 0.456\n",
            "[480,     4] loss: 0.453\n",
            "[481,     4] loss: 0.460\n",
            "[482,     4] loss: 0.473\n",
            "[483,     4] loss: 0.456\n",
            "[484,     4] loss: 0.463\n",
            "[485,     4] loss: 0.456\n",
            "[486,     4] loss: 0.451\n",
            "[487,     4] loss: 0.469\n",
            "[488,     4] loss: 0.464\n",
            "[489,     4] loss: 0.458\n",
            "[490,     4] loss: 0.450\n",
            "[491,     4] loss: 0.453\n",
            "[492,     4] loss: 0.461\n",
            "[493,     4] loss: 0.464\n",
            "[494,     4] loss: 0.465\n",
            "[495,     4] loss: 0.461\n",
            "[496,     4] loss: 0.458\n",
            "[497,     4] loss: 0.455\n",
            "[498,     4] loss: 0.454\n",
            "[499,     4] loss: 0.466\n",
            "[500,     4] loss: 0.472\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 69 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 62 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 47 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 69 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 52 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 62 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 63 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   6\n",
            "[1,     4] loss: 0.715\n",
            "[2,     4] loss: 0.498\n",
            "[3,     4] loss: 0.468\n",
            "[4,     4] loss: 0.465\n",
            "[5,     4] loss: 0.483\n",
            "[6,     4] loss: 0.470\n",
            "[7,     4] loss: 0.469\n",
            "[8,     4] loss: 0.461\n",
            "[9,     4] loss: 0.469\n",
            "[10,     4] loss: 0.465\n",
            "[11,     4] loss: 0.478\n",
            "[12,     4] loss: 0.453\n",
            "[13,     4] loss: 0.467\n",
            "[14,     4] loss: 0.453\n",
            "[15,     4] loss: 0.461\n",
            "[16,     4] loss: 0.459\n",
            "[17,     4] loss: 0.459\n",
            "[18,     4] loss: 0.462\n",
            "[19,     4] loss: 0.461\n",
            "[20,     4] loss: 0.463\n",
            "[21,     4] loss: 0.460\n",
            "[22,     4] loss: 0.464\n",
            "[23,     4] loss: 0.451\n",
            "[24,     4] loss: 0.451\n",
            "[25,     4] loss: 0.458\n",
            "[26,     4] loss: 0.450\n",
            "[27,     4] loss: 0.449\n",
            "[28,     4] loss: 0.444\n",
            "[29,     4] loss: 0.412\n",
            "[30,     4] loss: 0.436\n",
            "[31,     4] loss: 0.439\n",
            "[32,     4] loss: 0.424\n",
            "[33,     4] loss: 0.421\n",
            "[34,     4] loss: 0.419\n",
            "[35,     4] loss: 0.417\n",
            "[36,     4] loss: 0.400\n",
            "[37,     4] loss: 0.400\n",
            "[38,     4] loss: 0.408\n",
            "[39,     4] loss: 0.403\n",
            "[40,     4] loss: 0.403\n",
            "[41,     4] loss: 0.424\n",
            "[42,     4] loss: 0.408\n",
            "[43,     4] loss: 0.396\n",
            "[44,     4] loss: 0.416\n",
            "[45,     4] loss: 0.417\n",
            "[46,     4] loss: 0.400\n",
            "[47,     4] loss: 0.388\n",
            "[48,     4] loss: 0.384\n",
            "[49,     4] loss: 0.400\n",
            "[50,     4] loss: 0.390\n",
            "[51,     4] loss: 0.410\n",
            "[52,     4] loss: 0.405\n",
            "[53,     4] loss: 0.409\n",
            "[54,     4] loss: 0.416\n",
            "[55,     4] loss: 0.393\n",
            "[56,     4] loss: 0.393\n",
            "[57,     4] loss: 0.400\n",
            "[58,     4] loss: 0.385\n",
            "[59,     4] loss: 0.399\n",
            "[60,     4] loss: 0.401\n",
            "[61,     4] loss: 0.389\n",
            "[62,     4] loss: 0.404\n",
            "[63,     4] loss: 0.399\n",
            "[64,     4] loss: 0.404\n",
            "[65,     4] loss: 0.379\n",
            "[66,     4] loss: 0.388\n",
            "[67,     4] loss: 0.422\n",
            "[68,     4] loss: 0.401\n",
            "[69,     4] loss: 0.401\n",
            "[70,     4] loss: 0.398\n",
            "[71,     4] loss: 0.387\n",
            "[72,     4] loss: 0.387\n",
            "[73,     4] loss: 0.385\n",
            "[74,     4] loss: 0.415\n",
            "[75,     4] loss: 0.439\n",
            "[76,     4] loss: 0.425\n",
            "[77,     4] loss: 0.412\n",
            "[78,     4] loss: 0.399\n",
            "[79,     4] loss: 0.386\n",
            "[80,     4] loss: 0.396\n",
            "[81,     4] loss: 0.394\n",
            "[82,     4] loss: 0.398\n",
            "[83,     4] loss: 0.396\n",
            "[84,     4] loss: 0.393\n",
            "[85,     4] loss: 0.390\n",
            "[86,     4] loss: 0.390\n",
            "[87,     4] loss: 0.410\n",
            "[88,     4] loss: 0.386\n",
            "[89,     4] loss: 0.392\n",
            "[90,     4] loss: 0.409\n",
            "[91,     4] loss: 0.396\n",
            "[92,     4] loss: 0.386\n",
            "[93,     4] loss: 0.385\n",
            "[94,     4] loss: 0.384\n",
            "[95,     4] loss: 0.385\n",
            "[96,     4] loss: 0.401\n",
            "[97,     4] loss: 0.405\n",
            "[98,     4] loss: 0.399\n",
            "[99,     4] loss: 0.403\n",
            "[100,     4] loss: 0.398\n",
            "[101,     4] loss: 0.398\n",
            "[102,     4] loss: 0.398\n",
            "[103,     4] loss: 0.404\n",
            "[104,     4] loss: 0.403\n",
            "[105,     4] loss: 0.415\n",
            "[106,     4] loss: 0.409\n",
            "[107,     4] loss: 0.400\n",
            "[108,     4] loss: 0.395\n",
            "[109,     4] loss: 0.390\n",
            "[110,     4] loss: 0.416\n",
            "[111,     4] loss: 0.391\n",
            "[112,     4] loss: 0.390\n",
            "[113,     4] loss: 0.391\n",
            "[114,     4] loss: 0.393\n",
            "[115,     4] loss: 0.397\n",
            "[116,     4] loss: 0.403\n",
            "[117,     4] loss: 0.403\n",
            "[118,     4] loss: 0.402\n",
            "[119,     4] loss: 0.396\n",
            "[120,     4] loss: 0.393\n",
            "[121,     4] loss: 0.397\n",
            "[122,     4] loss: 0.392\n",
            "[123,     4] loss: 0.397\n",
            "[124,     4] loss: 0.419\n",
            "[125,     4] loss: 0.398\n",
            "[126,     4] loss: 0.396\n",
            "[127,     4] loss: 0.398\n",
            "[128,     4] loss: 0.392\n",
            "[129,     4] loss: 0.399\n",
            "[130,     4] loss: 0.396\n",
            "[131,     4] loss: 0.393\n",
            "[132,     4] loss: 0.397\n",
            "[133,     4] loss: 0.416\n",
            "[134,     4] loss: 0.402\n",
            "[135,     4] loss: 0.394\n",
            "[136,     4] loss: 0.391\n",
            "[137,     4] loss: 0.391\n",
            "[138,     4] loss: 0.403\n",
            "[139,     4] loss: 0.420\n",
            "[140,     4] loss: 0.436\n",
            "[141,     4] loss: 0.429\n",
            "[142,     4] loss: 0.412\n",
            "[143,     4] loss: 0.401\n",
            "[144,     4] loss: 0.412\n",
            "[145,     4] loss: 0.402\n",
            "[146,     4] loss: 0.400\n",
            "[147,     4] loss: 0.385\n",
            "[148,     4] loss: 0.401\n",
            "[149,     4] loss: 0.394\n",
            "[150,     4] loss: 0.393\n",
            "[151,     4] loss: 0.391\n",
            "[152,     4] loss: 0.382\n",
            "[153,     4] loss: 0.391\n",
            "[154,     4] loss: 0.397\n",
            "[155,     4] loss: 0.399\n",
            "[156,     4] loss: 0.404\n",
            "[157,     4] loss: 0.413\n",
            "[158,     4] loss: 0.408\n",
            "[159,     4] loss: 0.409\n",
            "[160,     4] loss: 0.414\n",
            "[161,     4] loss: 0.385\n",
            "[162,     4] loss: 0.402\n",
            "[163,     4] loss: 0.394\n",
            "[164,     4] loss: 0.404\n",
            "[165,     4] loss: 0.394\n",
            "[166,     4] loss: 0.405\n",
            "[167,     4] loss: 0.392\n",
            "[168,     4] loss: 0.396\n",
            "[169,     4] loss: 0.387\n",
            "[170,     4] loss: 0.394\n",
            "[171,     4] loss: 0.404\n",
            "[172,     4] loss: 0.419\n",
            "[173,     4] loss: 0.394\n",
            "[174,     4] loss: 0.386\n",
            "[175,     4] loss: 0.377\n",
            "[176,     4] loss: 0.395\n",
            "[177,     4] loss: 0.390\n",
            "[178,     4] loss: 0.392\n",
            "[179,     4] loss: 0.392\n",
            "[180,     4] loss: 0.390\n",
            "[181,     4] loss: 0.400\n",
            "[182,     4] loss: 0.399\n",
            "[183,     4] loss: 0.383\n",
            "[184,     4] loss: 0.390\n",
            "[185,     4] loss: 0.400\n",
            "[186,     4] loss: 0.402\n",
            "[187,     4] loss: 0.393\n",
            "[188,     4] loss: 0.411\n",
            "[189,     4] loss: 0.394\n",
            "[190,     4] loss: 0.400\n",
            "[191,     4] loss: 0.407\n",
            "[192,     4] loss: 0.425\n",
            "[193,     4] loss: 0.386\n",
            "[194,     4] loss: 0.391\n",
            "[195,     4] loss: 0.388\n",
            "[196,     4] loss: 0.384\n",
            "[197,     4] loss: 0.411\n",
            "[198,     4] loss: 0.400\n",
            "[199,     4] loss: 0.390\n",
            "[200,     4] loss: 0.390\n",
            "[201,     4] loss: 0.399\n",
            "[202,     4] loss: 0.385\n",
            "[203,     4] loss: 0.398\n",
            "[204,     4] loss: 0.385\n",
            "[205,     4] loss: 0.402\n",
            "[206,     4] loss: 0.394\n",
            "[207,     4] loss: 0.387\n",
            "[208,     4] loss: 0.397\n",
            "[209,     4] loss: 0.395\n",
            "[210,     4] loss: 0.397\n",
            "[211,     4] loss: 0.382\n",
            "[212,     4] loss: 0.401\n",
            "[213,     4] loss: 0.391\n",
            "[214,     4] loss: 0.392\n",
            "[215,     4] loss: 0.377\n",
            "[216,     4] loss: 0.382\n",
            "[217,     4] loss: 0.392\n",
            "[218,     4] loss: 0.402\n",
            "[219,     4] loss: 0.392\n",
            "[220,     4] loss: 0.396\n",
            "[221,     4] loss: 0.393\n",
            "[222,     4] loss: 0.401\n",
            "[223,     4] loss: 0.391\n",
            "[224,     4] loss: 0.387\n",
            "[225,     4] loss: 0.394\n",
            "[226,     4] loss: 0.408\n",
            "[227,     4] loss: 0.391\n",
            "[228,     4] loss: 0.378\n",
            "[229,     4] loss: 0.390\n",
            "[230,     4] loss: 0.396\n",
            "[231,     4] loss: 0.392\n",
            "[232,     4] loss: 0.395\n",
            "[233,     4] loss: 0.385\n",
            "[234,     4] loss: 0.401\n",
            "[235,     4] loss: 0.390\n",
            "[236,     4] loss: 0.404\n",
            "[237,     4] loss: 0.390\n",
            "[238,     4] loss: 0.397\n",
            "[239,     4] loss: 0.393\n",
            "[240,     4] loss: 0.396\n",
            "[241,     4] loss: 0.393\n",
            "[242,     4] loss: 0.382\n",
            "[243,     4] loss: 0.391\n",
            "[244,     4] loss: 0.406\n",
            "[245,     4] loss: 0.396\n",
            "[246,     4] loss: 0.382\n",
            "[247,     4] loss: 0.396\n",
            "[248,     4] loss: 0.407\n",
            "[249,     4] loss: 0.404\n",
            "[250,     4] loss: 0.415\n",
            "[251,     4] loss: 0.392\n",
            "[252,     4] loss: 0.390\n",
            "[253,     4] loss: 0.388\n",
            "[254,     4] loss: 0.399\n",
            "[255,     4] loss: 0.386\n",
            "[256,     4] loss: 0.395\n",
            "[257,     4] loss: 0.404\n",
            "[258,     4] loss: 0.406\n",
            "[259,     4] loss: 0.410\n",
            "[260,     4] loss: 0.395\n",
            "[261,     4] loss: 0.391\n",
            "[262,     4] loss: 0.381\n",
            "[263,     4] loss: 0.393\n",
            "[264,     4] loss: 0.410\n",
            "[265,     4] loss: 0.389\n",
            "[266,     4] loss: 0.386\n",
            "[267,     4] loss: 0.386\n",
            "[268,     4] loss: 0.398\n",
            "[269,     4] loss: 0.373\n",
            "[270,     4] loss: 0.396\n",
            "[271,     4] loss: 0.380\n",
            "[272,     4] loss: 0.387\n",
            "[273,     4] loss: 0.381\n",
            "[274,     4] loss: 0.387\n",
            "[275,     4] loss: 0.399\n",
            "[276,     4] loss: 0.403\n",
            "[277,     4] loss: 0.398\n",
            "[278,     4] loss: 0.399\n",
            "[279,     4] loss: 0.390\n",
            "[280,     4] loss: 0.392\n",
            "[281,     4] loss: 0.395\n",
            "[282,     4] loss: 0.390\n",
            "[283,     4] loss: 0.385\n",
            "[284,     4] loss: 0.381\n",
            "[285,     4] loss: 0.396\n",
            "[286,     4] loss: 0.404\n",
            "[287,     4] loss: 0.405\n",
            "[288,     4] loss: 0.387\n",
            "[289,     4] loss: 0.391\n",
            "[290,     4] loss: 0.394\n",
            "[291,     4] loss: 0.401\n",
            "[292,     4] loss: 0.400\n",
            "[293,     4] loss: 0.426\n",
            "[294,     4] loss: 0.405\n",
            "[295,     4] loss: 0.410\n",
            "[296,     4] loss: 0.411\n",
            "[297,     4] loss: 0.413\n",
            "[298,     4] loss: 0.402\n",
            "[299,     4] loss: 0.381\n",
            "[300,     4] loss: 0.389\n",
            "[301,     4] loss: 0.393\n",
            "[302,     4] loss: 0.389\n",
            "[303,     4] loss: 0.398\n",
            "[304,     4] loss: 0.391\n",
            "[305,     4] loss: 0.399\n",
            "[306,     4] loss: 0.386\n",
            "[307,     4] loss: 0.409\n",
            "[308,     4] loss: 0.394\n",
            "[309,     4] loss: 0.400\n",
            "[310,     4] loss: 0.397\n",
            "[311,     4] loss: 0.398\n",
            "[312,     4] loss: 0.417\n",
            "[313,     4] loss: 0.406\n",
            "[314,     4] loss: 0.413\n",
            "[315,     4] loss: 0.391\n",
            "[316,     4] loss: 0.389\n",
            "[317,     4] loss: 0.384\n",
            "[318,     4] loss: 0.385\n",
            "[319,     4] loss: 0.388\n",
            "[320,     4] loss: 0.398\n",
            "[321,     4] loss: 0.379\n",
            "[322,     4] loss: 0.392\n",
            "[323,     4] loss: 0.378\n",
            "[324,     4] loss: 0.387\n",
            "[325,     4] loss: 0.400\n",
            "[326,     4] loss: 0.394\n",
            "[327,     4] loss: 0.391\n",
            "[328,     4] loss: 0.395\n",
            "[329,     4] loss: 0.393\n",
            "[330,     4] loss: 0.398\n",
            "[331,     4] loss: 0.394\n",
            "[332,     4] loss: 0.403\n",
            "[333,     4] loss: 0.404\n",
            "[334,     4] loss: 0.398\n",
            "[335,     4] loss: 0.404\n",
            "[336,     4] loss: 0.397\n",
            "[337,     4] loss: 0.390\n",
            "[338,     4] loss: 0.390\n",
            "[339,     4] loss: 0.390\n",
            "[340,     4] loss: 0.392\n",
            "[341,     4] loss: 0.400\n",
            "[342,     4] loss: 0.406\n",
            "[343,     4] loss: 0.399\n",
            "[344,     4] loss: 0.400\n",
            "[345,     4] loss: 0.385\n",
            "[346,     4] loss: 0.390\n",
            "[347,     4] loss: 0.403\n",
            "[348,     4] loss: 0.383\n",
            "[349,     4] loss: 0.398\n",
            "[350,     4] loss: 0.396\n",
            "[351,     4] loss: 0.400\n",
            "[352,     4] loss: 0.398\n",
            "[353,     4] loss: 0.402\n",
            "[354,     4] loss: 0.385\n",
            "[355,     4] loss: 0.392\n",
            "[356,     4] loss: 0.390\n",
            "[357,     4] loss: 0.395\n",
            "[358,     4] loss: 0.404\n",
            "[359,     4] loss: 0.408\n",
            "[360,     4] loss: 0.403\n",
            "[361,     4] loss: 0.388\n",
            "[362,     4] loss: 0.397\n",
            "[363,     4] loss: 0.384\n",
            "[364,     4] loss: 0.420\n",
            "[365,     4] loss: 0.395\n",
            "[366,     4] loss: 0.388\n",
            "[367,     4] loss: 0.388\n",
            "[368,     4] loss: 0.403\n",
            "[369,     4] loss: 0.391\n",
            "[370,     4] loss: 0.397\n",
            "[371,     4] loss: 0.399\n",
            "[372,     4] loss: 0.395\n",
            "[373,     4] loss: 0.402\n",
            "[374,     4] loss: 0.395\n",
            "[375,     4] loss: 0.390\n",
            "[376,     4] loss: 0.403\n",
            "[377,     4] loss: 0.405\n",
            "[378,     4] loss: 0.404\n",
            "[379,     4] loss: 0.414\n",
            "[380,     4] loss: 0.400\n",
            "[381,     4] loss: 0.399\n",
            "[382,     4] loss: 0.402\n",
            "[383,     4] loss: 0.399\n",
            "[384,     4] loss: 0.384\n",
            "[385,     4] loss: 0.395\n",
            "[386,     4] loss: 0.392\n",
            "[387,     4] loss: 0.404\n",
            "[388,     4] loss: 0.403\n",
            "[389,     4] loss: 0.393\n",
            "[390,     4] loss: 0.397\n",
            "[391,     4] loss: 0.386\n",
            "[392,     4] loss: 0.380\n",
            "[393,     4] loss: 0.382\n",
            "[394,     4] loss: 0.391\n",
            "[395,     4] loss: 0.381\n",
            "[396,     4] loss: 0.373\n",
            "[397,     4] loss: 0.401\n",
            "[398,     4] loss: 0.400\n",
            "[399,     4] loss: 0.402\n",
            "[400,     4] loss: 0.409\n",
            "[401,     4] loss: 0.405\n",
            "[402,     4] loss: 0.396\n",
            "[403,     4] loss: 0.388\n",
            "[404,     4] loss: 0.391\n",
            "[405,     4] loss: 0.394\n",
            "[406,     4] loss: 0.391\n",
            "[407,     4] loss: 0.406\n",
            "[408,     4] loss: 0.400\n",
            "[409,     4] loss: 0.399\n",
            "[410,     4] loss: 0.379\n",
            "[411,     4] loss: 0.395\n",
            "[412,     4] loss: 0.397\n",
            "[413,     4] loss: 0.409\n",
            "[414,     4] loss: 0.403\n",
            "[415,     4] loss: 0.391\n",
            "[416,     4] loss: 0.378\n",
            "[417,     4] loss: 0.385\n",
            "[418,     4] loss: 0.386\n",
            "[419,     4] loss: 0.381\n",
            "[420,     4] loss: 0.397\n",
            "[421,     4] loss: 0.395\n",
            "[422,     4] loss: 0.385\n",
            "[423,     4] loss: 0.392\n",
            "[424,     4] loss: 0.390\n",
            "[425,     4] loss: 0.401\n",
            "[426,     4] loss: 0.387\n",
            "[427,     4] loss: 0.388\n",
            "[428,     4] loss: 0.396\n",
            "[429,     4] loss: 0.389\n",
            "[430,     4] loss: 0.386\n",
            "[431,     4] loss: 0.380\n",
            "[432,     4] loss: 0.391\n",
            "[433,     4] loss: 0.392\n",
            "[434,     4] loss: 0.396\n",
            "[435,     4] loss: 0.387\n",
            "[436,     4] loss: 0.392\n",
            "[437,     4] loss: 0.394\n",
            "[438,     4] loss: 0.399\n",
            "[439,     4] loss: 0.393\n",
            "[440,     4] loss: 0.393\n",
            "[441,     4] loss: 0.400\n",
            "[442,     4] loss: 0.404\n",
            "[443,     4] loss: 0.395\n",
            "[444,     4] loss: 0.387\n",
            "[445,     4] loss: 0.407\n",
            "[446,     4] loss: 0.400\n",
            "[447,     4] loss: 0.389\n",
            "[448,     4] loss: 0.384\n",
            "[449,     4] loss: 0.403\n",
            "[450,     4] loss: 0.406\n",
            "[451,     4] loss: 0.393\n",
            "[452,     4] loss: 0.392\n",
            "[453,     4] loss: 0.394\n",
            "[454,     4] loss: 0.390\n",
            "[455,     4] loss: 0.395\n",
            "[456,     4] loss: 0.384\n",
            "[457,     4] loss: 0.398\n",
            "[458,     4] loss: 0.390\n",
            "[459,     4] loss: 0.393\n",
            "[460,     4] loss: 0.408\n",
            "[461,     4] loss: 0.391\n",
            "[462,     4] loss: 0.399\n",
            "[463,     4] loss: 0.385\n",
            "[464,     4] loss: 0.387\n",
            "[465,     4] loss: 0.401\n",
            "[466,     4] loss: 0.377\n",
            "[467,     4] loss: 0.394\n",
            "[468,     4] loss: 0.381\n",
            "[469,     4] loss: 0.392\n",
            "[470,     4] loss: 0.389\n",
            "[471,     4] loss: 0.394\n",
            "[472,     4] loss: 0.387\n",
            "[473,     4] loss: 0.383\n",
            "[474,     4] loss: 0.387\n",
            "[475,     4] loss: 0.381\n",
            "[476,     4] loss: 0.380\n",
            "[477,     4] loss: 0.395\n",
            "[478,     4] loss: 0.389\n",
            "[479,     4] loss: 0.391\n",
            "[480,     4] loss: 0.385\n",
            "[481,     4] loss: 0.388\n",
            "[482,     4] loss: 0.391\n",
            "[483,     4] loss: 0.406\n",
            "[484,     4] loss: 0.395\n",
            "[485,     4] loss: 0.397\n",
            "[486,     4] loss: 0.401\n",
            "[487,     4] loss: 0.397\n",
            "[488,     4] loss: 0.402\n",
            "[489,     4] loss: 0.394\n",
            "[490,     4] loss: 0.395\n",
            "[491,     4] loss: 0.389\n",
            "[492,     4] loss: 0.408\n",
            "[493,     4] loss: 0.404\n",
            "[494,     4] loss: 0.409\n",
            "[495,     4] loss: 0.391\n",
            "[496,     4] loss: 0.402\n",
            "[497,     4] loss: 0.396\n",
            "[498,     4] loss: 0.410\n",
            "[499,     4] loss: 0.396\n",
            "[500,     4] loss: 0.384\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 78 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 78 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 70 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 69 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 69 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   7\n",
            "[1,     4] loss: 0.890\n",
            "[2,     4] loss: 0.565\n",
            "[3,     4] loss: 0.507\n",
            "[4,     4] loss: 0.459\n",
            "[5,     4] loss: 0.461\n",
            "[6,     4] loss: 0.466\n",
            "[7,     4] loss: 0.464\n",
            "[8,     4] loss: 0.472\n",
            "[9,     4] loss: 0.458\n",
            "[10,     4] loss: 0.456\n",
            "[11,     4] loss: 0.456\n",
            "[12,     4] loss: 0.451\n",
            "[13,     4] loss: 0.445\n",
            "[14,     4] loss: 0.455\n",
            "[15,     4] loss: 0.450\n",
            "[16,     4] loss: 0.443\n",
            "[17,     4] loss: 0.446\n",
            "[18,     4] loss: 0.451\n",
            "[19,     4] loss: 0.452\n",
            "[20,     4] loss: 0.433\n",
            "[21,     4] loss: 0.432\n",
            "[22,     4] loss: 0.429\n",
            "[23,     4] loss: 0.395\n",
            "[24,     4] loss: 0.394\n",
            "[25,     4] loss: 0.360\n",
            "[26,     4] loss: 0.397\n",
            "[27,     4] loss: 0.358\n",
            "[28,     4] loss: 0.335\n",
            "[29,     4] loss: 0.322\n",
            "[30,     4] loss: 0.305\n",
            "[31,     4] loss: 0.327\n",
            "[32,     4] loss: 0.310\n",
            "[33,     4] loss: 0.278\n",
            "[34,     4] loss: 0.248\n",
            "[35,     4] loss: 0.289\n",
            "[36,     4] loss: 0.259\n",
            "[37,     4] loss: 0.248\n",
            "[38,     4] loss: 0.265\n",
            "[39,     4] loss: 0.279\n",
            "[40,     4] loss: 0.309\n",
            "[41,     4] loss: 0.274\n",
            "[42,     4] loss: 0.286\n",
            "[43,     4] loss: 0.283\n",
            "[44,     4] loss: 0.269\n",
            "[45,     4] loss: 0.265\n",
            "[46,     4] loss: 0.263\n",
            "[47,     4] loss: 0.259\n",
            "[48,     4] loss: 0.248\n",
            "[49,     4] loss: 0.266\n",
            "[50,     4] loss: 0.275\n",
            "[51,     4] loss: 0.253\n",
            "[52,     4] loss: 0.256\n",
            "[53,     4] loss: 0.255\n",
            "[54,     4] loss: 0.261\n",
            "[55,     4] loss: 0.258\n",
            "[56,     4] loss: 0.243\n",
            "[57,     4] loss: 0.247\n",
            "[58,     4] loss: 0.278\n",
            "[59,     4] loss: 0.277\n",
            "[60,     4] loss: 0.281\n",
            "[61,     4] loss: 0.263\n",
            "[62,     4] loss: 0.272\n",
            "[63,     4] loss: 0.287\n",
            "[64,     4] loss: 0.266\n",
            "[65,     4] loss: 0.236\n",
            "[66,     4] loss: 0.248\n",
            "[67,     4] loss: 0.261\n",
            "[68,     4] loss: 0.263\n",
            "[69,     4] loss: 0.273\n",
            "[70,     4] loss: 0.255\n",
            "[71,     4] loss: 0.240\n",
            "[72,     4] loss: 0.262\n",
            "[73,     4] loss: 0.246\n",
            "[74,     4] loss: 0.254\n",
            "[75,     4] loss: 0.264\n",
            "[76,     4] loss: 0.257\n",
            "[77,     4] loss: 0.254\n",
            "[78,     4] loss: 0.258\n",
            "[79,     4] loss: 0.268\n",
            "[80,     4] loss: 0.251\n",
            "[81,     4] loss: 0.260\n",
            "[82,     4] loss: 0.279\n",
            "[83,     4] loss: 0.276\n",
            "[84,     4] loss: 0.230\n",
            "[85,     4] loss: 0.255\n",
            "[86,     4] loss: 0.246\n",
            "[87,     4] loss: 0.273\n",
            "[88,     4] loss: 0.283\n",
            "[89,     4] loss: 0.302\n",
            "[90,     4] loss: 0.285\n",
            "[91,     4] loss: 0.289\n",
            "[92,     4] loss: 0.269\n",
            "[93,     4] loss: 0.266\n",
            "[94,     4] loss: 0.267\n",
            "[95,     4] loss: 0.255\n",
            "[96,     4] loss: 0.242\n",
            "[97,     4] loss: 0.273\n",
            "[98,     4] loss: 0.256\n",
            "[99,     4] loss: 0.238\n",
            "[100,     4] loss: 0.248\n",
            "[101,     4] loss: 0.249\n",
            "[102,     4] loss: 0.245\n",
            "[103,     4] loss: 0.249\n",
            "[104,     4] loss: 0.251\n",
            "[105,     4] loss: 0.254\n",
            "[106,     4] loss: 0.254\n",
            "[107,     4] loss: 0.252\n",
            "[108,     4] loss: 0.236\n",
            "[109,     4] loss: 0.256\n",
            "[110,     4] loss: 0.251\n",
            "[111,     4] loss: 0.268\n",
            "[112,     4] loss: 0.239\n",
            "[113,     4] loss: 0.276\n",
            "[114,     4] loss: 0.275\n",
            "[115,     4] loss: 0.279\n",
            "[116,     4] loss: 0.262\n",
            "[117,     4] loss: 0.261\n",
            "[118,     4] loss: 0.255\n",
            "[119,     4] loss: 0.244\n",
            "[120,     4] loss: 0.253\n",
            "[121,     4] loss: 0.253\n",
            "[122,     4] loss: 0.263\n",
            "[123,     4] loss: 0.271\n",
            "[124,     4] loss: 0.255\n",
            "[125,     4] loss: 0.257\n",
            "[126,     4] loss: 0.270\n",
            "[127,     4] loss: 0.238\n",
            "[128,     4] loss: 0.256\n",
            "[129,     4] loss: 0.268\n",
            "[130,     4] loss: 0.269\n",
            "[131,     4] loss: 0.281\n",
            "[132,     4] loss: 0.284\n",
            "[133,     4] loss: 0.276\n",
            "[134,     4] loss: 0.273\n",
            "[135,     4] loss: 0.295\n",
            "[136,     4] loss: 0.270\n",
            "[137,     4] loss: 0.255\n",
            "[138,     4] loss: 0.239\n",
            "[139,     4] loss: 0.252\n",
            "[140,     4] loss: 0.256\n",
            "[141,     4] loss: 0.280\n",
            "[142,     4] loss: 0.265\n",
            "[143,     4] loss: 0.269\n",
            "[144,     4] loss: 0.236\n",
            "[145,     4] loss: 0.271\n",
            "[146,     4] loss: 0.260\n",
            "[147,     4] loss: 0.242\n",
            "[148,     4] loss: 0.254\n",
            "[149,     4] loss: 0.251\n",
            "[150,     4] loss: 0.243\n",
            "[151,     4] loss: 0.240\n",
            "[152,     4] loss: 0.253\n",
            "[153,     4] loss: 0.286\n",
            "[154,     4] loss: 0.269\n",
            "[155,     4] loss: 0.264\n",
            "[156,     4] loss: 0.250\n",
            "[157,     4] loss: 0.246\n",
            "[158,     4] loss: 0.252\n",
            "[159,     4] loss: 0.266\n",
            "[160,     4] loss: 0.264\n",
            "[161,     4] loss: 0.241\n",
            "[162,     4] loss: 0.257\n",
            "[163,     4] loss: 0.258\n",
            "[164,     4] loss: 0.246\n",
            "[165,     4] loss: 0.245\n",
            "[166,     4] loss: 0.256\n",
            "[167,     4] loss: 0.291\n",
            "[168,     4] loss: 0.286\n",
            "[169,     4] loss: 0.268\n",
            "[170,     4] loss: 0.256\n",
            "[171,     4] loss: 0.264\n",
            "[172,     4] loss: 0.256\n",
            "[173,     4] loss: 0.255\n",
            "[174,     4] loss: 0.256\n",
            "[175,     4] loss: 0.249\n",
            "[176,     4] loss: 0.234\n",
            "[177,     4] loss: 0.254\n",
            "[178,     4] loss: 0.258\n",
            "[179,     4] loss: 0.246\n",
            "[180,     4] loss: 0.240\n",
            "[181,     4] loss: 0.244\n",
            "[182,     4] loss: 0.252\n",
            "[183,     4] loss: 0.241\n",
            "[184,     4] loss: 0.256\n",
            "[185,     4] loss: 0.249\n",
            "[186,     4] loss: 0.255\n",
            "[187,     4] loss: 0.245\n",
            "[188,     4] loss: 0.249\n",
            "[189,     4] loss: 0.261\n",
            "[190,     4] loss: 0.266\n",
            "[191,     4] loss: 0.255\n",
            "[192,     4] loss: 0.271\n",
            "[193,     4] loss: 0.258\n",
            "[194,     4] loss: 0.244\n",
            "[195,     4] loss: 0.257\n",
            "[196,     4] loss: 0.250\n",
            "[197,     4] loss: 0.243\n",
            "[198,     4] loss: 0.247\n",
            "[199,     4] loss: 0.236\n",
            "[200,     4] loss: 0.249\n",
            "[201,     4] loss: 0.240\n",
            "[202,     4] loss: 0.254\n",
            "[203,     4] loss: 0.245\n",
            "[204,     4] loss: 0.259\n",
            "[205,     4] loss: 0.233\n",
            "[206,     4] loss: 0.246\n",
            "[207,     4] loss: 0.242\n",
            "[208,     4] loss: 0.249\n",
            "[209,     4] loss: 0.252\n",
            "[210,     4] loss: 0.248\n",
            "[211,     4] loss: 0.244\n",
            "[212,     4] loss: 0.249\n",
            "[213,     4] loss: 0.255\n",
            "[214,     4] loss: 0.249\n",
            "[215,     4] loss: 0.235\n",
            "[216,     4] loss: 0.247\n",
            "[217,     4] loss: 0.249\n",
            "[218,     4] loss: 0.239\n",
            "[219,     4] loss: 0.281\n",
            "[220,     4] loss: 0.301\n",
            "[221,     4] loss: 0.253\n",
            "[222,     4] loss: 0.240\n",
            "[223,     4] loss: 0.243\n",
            "[224,     4] loss: 0.266\n",
            "[225,     4] loss: 0.273\n",
            "[226,     4] loss: 0.256\n",
            "[227,     4] loss: 0.269\n",
            "[228,     4] loss: 0.272\n",
            "[229,     4] loss: 0.247\n",
            "[230,     4] loss: 0.265\n",
            "[231,     4] loss: 0.253\n",
            "[232,     4] loss: 0.254\n",
            "[233,     4] loss: 0.253\n",
            "[234,     4] loss: 0.248\n",
            "[235,     4] loss: 0.253\n",
            "[236,     4] loss: 0.263\n",
            "[237,     4] loss: 0.244\n",
            "[238,     4] loss: 0.264\n",
            "[239,     4] loss: 0.256\n",
            "[240,     4] loss: 0.268\n",
            "[241,     4] loss: 0.260\n",
            "[242,     4] loss: 0.257\n",
            "[243,     4] loss: 0.247\n",
            "[244,     4] loss: 0.254\n",
            "[245,     4] loss: 0.261\n",
            "[246,     4] loss: 0.246\n",
            "[247,     4] loss: 0.245\n",
            "[248,     4] loss: 0.257\n",
            "[249,     4] loss: 0.239\n",
            "[250,     4] loss: 0.255\n",
            "[251,     4] loss: 0.242\n",
            "[252,     4] loss: 0.255\n",
            "[253,     4] loss: 0.262\n",
            "[254,     4] loss: 0.279\n",
            "[255,     4] loss: 0.282\n",
            "[256,     4] loss: 0.258\n",
            "[257,     4] loss: 0.242\n",
            "[258,     4] loss: 0.245\n",
            "[259,     4] loss: 0.269\n",
            "[260,     4] loss: 0.260\n",
            "[261,     4] loss: 0.242\n",
            "[262,     4] loss: 0.254\n",
            "[263,     4] loss: 0.249\n",
            "[264,     4] loss: 0.253\n",
            "[265,     4] loss: 0.248\n",
            "[266,     4] loss: 0.246\n",
            "[267,     4] loss: 0.256\n",
            "[268,     4] loss: 0.256\n",
            "[269,     4] loss: 0.251\n",
            "[270,     4] loss: 0.237\n",
            "[271,     4] loss: 0.242\n",
            "[272,     4] loss: 0.249\n",
            "[273,     4] loss: 0.245\n",
            "[274,     4] loss: 0.247\n",
            "[275,     4] loss: 0.252\n",
            "[276,     4] loss: 0.251\n",
            "[277,     4] loss: 0.241\n",
            "[278,     4] loss: 0.272\n",
            "[279,     4] loss: 0.253\n",
            "[280,     4] loss: 0.252\n",
            "[281,     4] loss: 0.242\n",
            "[282,     4] loss: 0.272\n",
            "[283,     4] loss: 0.248\n",
            "[284,     4] loss: 0.241\n",
            "[285,     4] loss: 0.248\n",
            "[286,     4] loss: 0.232\n",
            "[287,     4] loss: 0.237\n",
            "[288,     4] loss: 0.242\n",
            "[289,     4] loss: 0.241\n",
            "[290,     4] loss: 0.253\n",
            "[291,     4] loss: 0.245\n",
            "[292,     4] loss: 0.266\n",
            "[293,     4] loss: 0.271\n",
            "[294,     4] loss: 0.262\n",
            "[295,     4] loss: 0.272\n",
            "[296,     4] loss: 0.256\n",
            "[297,     4] loss: 0.256\n",
            "[298,     4] loss: 0.245\n",
            "[299,     4] loss: 0.263\n",
            "[300,     4] loss: 0.238\n",
            "[301,     4] loss: 0.256\n",
            "[302,     4] loss: 0.241\n",
            "[303,     4] loss: 0.235\n",
            "[304,     4] loss: 0.244\n",
            "[305,     4] loss: 0.258\n",
            "[306,     4] loss: 0.244\n",
            "[307,     4] loss: 0.254\n",
            "[308,     4] loss: 0.259\n",
            "[309,     4] loss: 0.266\n",
            "[310,     4] loss: 0.256\n",
            "[311,     4] loss: 0.241\n",
            "[312,     4] loss: 0.257\n",
            "[313,     4] loss: 0.246\n",
            "[314,     4] loss: 0.239\n",
            "[315,     4] loss: 0.255\n",
            "[316,     4] loss: 0.244\n",
            "[317,     4] loss: 0.247\n",
            "[318,     4] loss: 0.245\n",
            "[319,     4] loss: 0.250\n",
            "[320,     4] loss: 0.236\n",
            "[321,     4] loss: 0.254\n",
            "[322,     4] loss: 0.264\n",
            "[323,     4] loss: 0.268\n",
            "[324,     4] loss: 0.241\n",
            "[325,     4] loss: 0.253\n",
            "[326,     4] loss: 0.253\n",
            "[327,     4] loss: 0.250\n",
            "[328,     4] loss: 0.247\n",
            "[329,     4] loss: 0.245\n",
            "[330,     4] loss: 0.251\n",
            "[331,     4] loss: 0.242\n",
            "[332,     4] loss: 0.249\n",
            "[333,     4] loss: 0.256\n",
            "[334,     4] loss: 0.269\n",
            "[335,     4] loss: 0.268\n",
            "[336,     4] loss: 0.248\n",
            "[337,     4] loss: 0.272\n",
            "[338,     4] loss: 0.230\n",
            "[339,     4] loss: 0.269\n",
            "[340,     4] loss: 0.268\n",
            "[341,     4] loss: 0.269\n",
            "[342,     4] loss: 0.252\n",
            "[343,     4] loss: 0.256\n",
            "[344,     4] loss: 0.264\n",
            "[345,     4] loss: 0.243\n",
            "[346,     4] loss: 0.237\n",
            "[347,     4] loss: 0.264\n",
            "[348,     4] loss: 0.264\n",
            "[349,     4] loss: 0.257\n",
            "[350,     4] loss: 0.270\n",
            "[351,     4] loss: 0.263\n",
            "[352,     4] loss: 0.260\n",
            "[353,     4] loss: 0.251\n",
            "[354,     4] loss: 0.242\n",
            "[355,     4] loss: 0.237\n",
            "[356,     4] loss: 0.250\n",
            "[357,     4] loss: 0.266\n",
            "[358,     4] loss: 0.243\n",
            "[359,     4] loss: 0.254\n",
            "[360,     4] loss: 0.245\n",
            "[361,     4] loss: 0.256\n",
            "[362,     4] loss: 0.268\n",
            "[363,     4] loss: 0.254\n",
            "[364,     4] loss: 0.260\n",
            "[365,     4] loss: 0.253\n",
            "[366,     4] loss: 0.253\n",
            "[367,     4] loss: 0.271\n",
            "[368,     4] loss: 0.247\n",
            "[369,     4] loss: 0.246\n",
            "[370,     4] loss: 0.251\n",
            "[371,     4] loss: 0.253\n",
            "[372,     4] loss: 0.256\n",
            "[373,     4] loss: 0.281\n",
            "[374,     4] loss: 0.274\n",
            "[375,     4] loss: 0.263\n",
            "[376,     4] loss: 0.254\n",
            "[377,     4] loss: 0.244\n",
            "[378,     4] loss: 0.242\n",
            "[379,     4] loss: 0.250\n",
            "[380,     4] loss: 0.254\n",
            "[381,     4] loss: 0.244\n",
            "[382,     4] loss: 0.251\n",
            "[383,     4] loss: 0.236\n",
            "[384,     4] loss: 0.241\n",
            "[385,     4] loss: 0.245\n",
            "[386,     4] loss: 0.251\n",
            "[387,     4] loss: 0.238\n",
            "[388,     4] loss: 0.267\n",
            "[389,     4] loss: 0.258\n",
            "[390,     4] loss: 0.254\n",
            "[391,     4] loss: 0.247\n",
            "[392,     4] loss: 0.250\n",
            "[393,     4] loss: 0.256\n",
            "[394,     4] loss: 0.243\n",
            "[395,     4] loss: 0.261\n",
            "[396,     4] loss: 0.245\n",
            "[397,     4] loss: 0.246\n",
            "[398,     4] loss: 0.257\n",
            "[399,     4] loss: 0.239\n",
            "[400,     4] loss: 0.246\n",
            "[401,     4] loss: 0.254\n",
            "[402,     4] loss: 0.265\n",
            "[403,     4] loss: 0.257\n",
            "[404,     4] loss: 0.262\n",
            "[405,     4] loss: 0.244\n",
            "[406,     4] loss: 0.250\n",
            "[407,     4] loss: 0.252\n",
            "[408,     4] loss: 0.238\n",
            "[409,     4] loss: 0.250\n",
            "[410,     4] loss: 0.238\n",
            "[411,     4] loss: 0.245\n",
            "[412,     4] loss: 0.252\n",
            "[413,     4] loss: 0.245\n",
            "[414,     4] loss: 0.249\n",
            "[415,     4] loss: 0.255\n",
            "[416,     4] loss: 0.255\n",
            "[417,     4] loss: 0.275\n",
            "[418,     4] loss: 0.246\n",
            "[419,     4] loss: 0.236\n",
            "[420,     4] loss: 0.257\n",
            "[421,     4] loss: 0.249\n",
            "[422,     4] loss: 0.233\n",
            "[423,     4] loss: 0.246\n",
            "[424,     4] loss: 0.250\n",
            "[425,     4] loss: 0.244\n",
            "[426,     4] loss: 0.246\n",
            "[427,     4] loss: 0.247\n",
            "[428,     4] loss: 0.257\n",
            "[429,     4] loss: 0.255\n",
            "[430,     4] loss: 0.249\n",
            "[431,     4] loss: 0.227\n",
            "[432,     4] loss: 0.258\n",
            "[433,     4] loss: 0.253\n",
            "[434,     4] loss: 0.242\n",
            "[435,     4] loss: 0.236\n",
            "[436,     4] loss: 0.237\n",
            "[437,     4] loss: 0.255\n",
            "[438,     4] loss: 0.254\n",
            "[439,     4] loss: 0.247\n",
            "[440,     4] loss: 0.245\n",
            "[441,     4] loss: 0.271\n",
            "[442,     4] loss: 0.282\n",
            "[443,     4] loss: 0.276\n",
            "[444,     4] loss: 0.250\n",
            "[445,     4] loss: 0.250\n",
            "[446,     4] loss: 0.256\n",
            "[447,     4] loss: 0.270\n",
            "[448,     4] loss: 0.258\n",
            "[449,     4] loss: 0.245\n",
            "[450,     4] loss: 0.242\n",
            "[451,     4] loss: 0.244\n",
            "[452,     4] loss: 0.267\n",
            "[453,     4] loss: 0.242\n",
            "[454,     4] loss: 0.241\n",
            "[455,     4] loss: 0.247\n",
            "[456,     4] loss: 0.251\n",
            "[457,     4] loss: 0.263\n",
            "[458,     4] loss: 0.235\n",
            "[459,     4] loss: 0.251\n",
            "[460,     4] loss: 0.242\n",
            "[461,     4] loss: 0.269\n",
            "[462,     4] loss: 0.247\n",
            "[463,     4] loss: 0.241\n",
            "[464,     4] loss: 0.255\n",
            "[465,     4] loss: 0.245\n",
            "[466,     4] loss: 0.240\n",
            "[467,     4] loss: 0.245\n",
            "[468,     4] loss: 0.226\n",
            "[469,     4] loss: 0.262\n",
            "[470,     4] loss: 0.256\n",
            "[471,     4] loss: 0.249\n",
            "[472,     4] loss: 0.254\n",
            "[473,     4] loss: 0.265\n",
            "[474,     4] loss: 0.252\n",
            "[475,     4] loss: 0.246\n",
            "[476,     4] loss: 0.220\n",
            "[477,     4] loss: 0.246\n",
            "[478,     4] loss: 0.271\n",
            "[479,     4] loss: 0.274\n",
            "[480,     4] loss: 0.267\n",
            "[481,     4] loss: 0.257\n",
            "[482,     4] loss: 0.270\n",
            "[483,     4] loss: 0.266\n",
            "[484,     4] loss: 0.261\n",
            "[485,     4] loss: 0.247\n",
            "[486,     4] loss: 0.257\n",
            "[487,     4] loss: 0.240\n",
            "[488,     4] loss: 0.241\n",
            "[489,     4] loss: 0.238\n",
            "[490,     4] loss: 0.245\n",
            "[491,     4] loss: 0.233\n",
            "[492,     4] loss: 0.252\n",
            "[493,     4] loss: 0.241\n",
            "[494,     4] loss: 0.241\n",
            "[495,     4] loss: 0.237\n",
            "[496,     4] loss: 0.251\n",
            "[497,     4] loss: 0.236\n",
            "[498,     4] loss: 0.252\n",
            "[499,     4] loss: 0.283\n",
            "[500,     4] loss: 0.254\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 89 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 32 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 32 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 32 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 40 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 62 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 89 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 73 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 69 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   8\n",
            "[1,     4] loss: 0.806\n",
            "[2,     4] loss: 0.493\n",
            "[3,     4] loss: 0.466\n",
            "[4,     4] loss: 0.463\n",
            "[5,     4] loss: 0.457\n",
            "[6,     4] loss: 0.453\n",
            "[7,     4] loss: 0.453\n",
            "[8,     4] loss: 0.454\n",
            "[9,     4] loss: 0.442\n",
            "[10,     4] loss: 0.445\n",
            "[11,     4] loss: 0.443\n",
            "[12,     4] loss: 0.442\n",
            "[13,     4] loss: 0.430\n",
            "[14,     4] loss: 0.420\n",
            "[15,     4] loss: 0.424\n",
            "[16,     4] loss: 0.402\n",
            "[17,     4] loss: 0.372\n",
            "[18,     4] loss: 0.318\n",
            "[19,     4] loss: 0.314\n",
            "[20,     4] loss: 0.284\n",
            "[21,     4] loss: 0.248\n",
            "[22,     4] loss: 0.314\n",
            "[23,     4] loss: 0.294\n",
            "[24,     4] loss: 0.233\n",
            "[25,     4] loss: 0.195\n",
            "[26,     4] loss: 0.155\n",
            "[27,     4] loss: 0.144\n",
            "[28,     4] loss: 0.147\n",
            "[29,     4] loss: 0.158\n",
            "[30,     4] loss: 0.161\n",
            "[31,     4] loss: 0.135\n",
            "[32,     4] loss: 0.144\n",
            "[33,     4] loss: 0.151\n",
            "[34,     4] loss: 0.169\n",
            "[35,     4] loss: 0.168\n",
            "[36,     4] loss: 0.160\n",
            "[37,     4] loss: 0.158\n",
            "[38,     4] loss: 0.147\n",
            "[39,     4] loss: 0.137\n",
            "[40,     4] loss: 0.143\n",
            "[41,     4] loss: 0.153\n",
            "[42,     4] loss: 0.153\n",
            "[43,     4] loss: 0.141\n",
            "[44,     4] loss: 0.173\n",
            "[45,     4] loss: 0.178\n",
            "[46,     4] loss: 0.221\n",
            "[47,     4] loss: 0.216\n",
            "[48,     4] loss: 0.172\n",
            "[49,     4] loss: 0.177\n",
            "[50,     4] loss: 0.181\n",
            "[51,     4] loss: 0.176\n",
            "[52,     4] loss: 0.159\n",
            "[53,     4] loss: 0.151\n",
            "[54,     4] loss: 0.151\n",
            "[55,     4] loss: 0.142\n",
            "[56,     4] loss: 0.138\n",
            "[57,     4] loss: 0.156\n",
            "[58,     4] loss: 0.137\n",
            "[59,     4] loss: 0.141\n",
            "[60,     4] loss: 0.145\n",
            "[61,     4] loss: 0.152\n",
            "[62,     4] loss: 0.153\n",
            "[63,     4] loss: 0.161\n",
            "[64,     4] loss: 0.148\n",
            "[65,     4] loss: 0.145\n",
            "[66,     4] loss: 0.150\n",
            "[67,     4] loss: 0.136\n",
            "[68,     4] loss: 0.153\n",
            "[69,     4] loss: 0.144\n",
            "[70,     4] loss: 0.154\n",
            "[71,     4] loss: 0.141\n",
            "[72,     4] loss: 0.137\n",
            "[73,     4] loss: 0.186\n",
            "[74,     4] loss: 0.182\n",
            "[75,     4] loss: 0.173\n",
            "[76,     4] loss: 0.167\n",
            "[77,     4] loss: 0.168\n",
            "[78,     4] loss: 0.162\n",
            "[79,     4] loss: 0.141\n",
            "[80,     4] loss: 0.177\n",
            "[81,     4] loss: 0.163\n",
            "[82,     4] loss: 0.184\n",
            "[83,     4] loss: 0.174\n",
            "[84,     4] loss: 0.159\n",
            "[85,     4] loss: 0.150\n",
            "[86,     4] loss: 0.137\n",
            "[87,     4] loss: 0.138\n",
            "[88,     4] loss: 0.149\n",
            "[89,     4] loss: 0.146\n",
            "[90,     4] loss: 0.156\n",
            "[91,     4] loss: 0.143\n",
            "[92,     4] loss: 0.151\n",
            "[93,     4] loss: 0.159\n",
            "[94,     4] loss: 0.165\n",
            "[95,     4] loss: 0.169\n",
            "[96,     4] loss: 0.164\n",
            "[97,     4] loss: 0.142\n",
            "[98,     4] loss: 0.163\n",
            "[99,     4] loss: 0.213\n",
            "[100,     4] loss: 0.181\n",
            "[101,     4] loss: 0.189\n",
            "[102,     4] loss: 0.150\n",
            "[103,     4] loss: 0.147\n",
            "[104,     4] loss: 0.153\n",
            "[105,     4] loss: 0.155\n",
            "[106,     4] loss: 0.140\n",
            "[107,     4] loss: 0.162\n",
            "[108,     4] loss: 0.166\n",
            "[109,     4] loss: 0.162\n",
            "[110,     4] loss: 0.155\n",
            "[111,     4] loss: 0.154\n",
            "[112,     4] loss: 0.158\n",
            "[113,     4] loss: 0.136\n",
            "[114,     4] loss: 0.196\n",
            "[115,     4] loss: 0.187\n",
            "[116,     4] loss: 0.190\n",
            "[117,     4] loss: 0.174\n",
            "[118,     4] loss: 0.178\n",
            "[119,     4] loss: 0.150\n",
            "[120,     4] loss: 0.146\n",
            "[121,     4] loss: 0.147\n",
            "[122,     4] loss: 0.138\n",
            "[123,     4] loss: 0.151\n",
            "[124,     4] loss: 0.157\n",
            "[125,     4] loss: 0.150\n",
            "[126,     4] loss: 0.148\n",
            "[127,     4] loss: 0.153\n",
            "[128,     4] loss: 0.141\n",
            "[129,     4] loss: 0.159\n",
            "[130,     4] loss: 0.167\n",
            "[131,     4] loss: 0.166\n",
            "[132,     4] loss: 0.155\n",
            "[133,     4] loss: 0.147\n",
            "[134,     4] loss: 0.149\n",
            "[135,     4] loss: 0.149\n",
            "[136,     4] loss: 0.169\n",
            "[137,     4] loss: 0.153\n",
            "[138,     4] loss: 0.154\n",
            "[139,     4] loss: 0.145\n",
            "[140,     4] loss: 0.147\n",
            "[141,     4] loss: 0.140\n",
            "[142,     4] loss: 0.133\n",
            "[143,     4] loss: 0.148\n",
            "[144,     4] loss: 0.160\n",
            "[145,     4] loss: 0.141\n",
            "[146,     4] loss: 0.165\n",
            "[147,     4] loss: 0.151\n",
            "[148,     4] loss: 0.150\n",
            "[149,     4] loss: 0.143\n",
            "[150,     4] loss: 0.133\n",
            "[151,     4] loss: 0.150\n",
            "[152,     4] loss: 0.144\n",
            "[153,     4] loss: 0.162\n",
            "[154,     4] loss: 0.141\n",
            "[155,     4] loss: 0.161\n",
            "[156,     4] loss: 0.148\n",
            "[157,     4] loss: 0.160\n",
            "[158,     4] loss: 0.166\n",
            "[159,     4] loss: 0.161\n",
            "[160,     4] loss: 0.166\n",
            "[161,     4] loss: 0.190\n",
            "[162,     4] loss: 0.199\n",
            "[163,     4] loss: 0.179\n",
            "[164,     4] loss: 0.200\n",
            "[165,     4] loss: 0.184\n",
            "[166,     4] loss: 0.175\n",
            "[167,     4] loss: 0.172\n",
            "[168,     4] loss: 0.182\n",
            "[169,     4] loss: 0.152\n",
            "[170,     4] loss: 0.158\n",
            "[171,     4] loss: 0.165\n",
            "[172,     4] loss: 0.146\n",
            "[173,     4] loss: 0.135\n",
            "[174,     4] loss: 0.154\n",
            "[175,     4] loss: 0.149\n",
            "[176,     4] loss: 0.161\n",
            "[177,     4] loss: 0.162\n",
            "[178,     4] loss: 0.148\n",
            "[179,     4] loss: 0.173\n",
            "[180,     4] loss: 0.170\n",
            "[181,     4] loss: 0.169\n",
            "[182,     4] loss: 0.161\n",
            "[183,     4] loss: 0.157\n",
            "[184,     4] loss: 0.141\n",
            "[185,     4] loss: 0.147\n",
            "[186,     4] loss: 0.157\n",
            "[187,     4] loss: 0.146\n",
            "[188,     4] loss: 0.150\n",
            "[189,     4] loss: 0.150\n",
            "[190,     4] loss: 0.162\n",
            "[191,     4] loss: 0.160\n",
            "[192,     4] loss: 0.151\n",
            "[193,     4] loss: 0.156\n",
            "[194,     4] loss: 0.140\n",
            "[195,     4] loss: 0.152\n",
            "[196,     4] loss: 0.151\n",
            "[197,     4] loss: 0.180\n",
            "[198,     4] loss: 0.172\n",
            "[199,     4] loss: 0.153\n",
            "[200,     4] loss: 0.182\n",
            "[201,     4] loss: 0.156\n",
            "[202,     4] loss: 0.156\n",
            "[203,     4] loss: 0.163\n",
            "[204,     4] loss: 0.159\n",
            "[205,     4] loss: 0.150\n",
            "[206,     4] loss: 0.150\n",
            "[207,     4] loss: 0.150\n",
            "[208,     4] loss: 0.161\n",
            "[209,     4] loss: 0.146\n",
            "[210,     4] loss: 0.157\n",
            "[211,     4] loss: 0.149\n",
            "[212,     4] loss: 0.142\n",
            "[213,     4] loss: 0.142\n",
            "[214,     4] loss: 0.146\n",
            "[215,     4] loss: 0.170\n",
            "[216,     4] loss: 0.164\n",
            "[217,     4] loss: 0.153\n",
            "[218,     4] loss: 0.151\n",
            "[219,     4] loss: 0.158\n",
            "[220,     4] loss: 0.175\n",
            "[221,     4] loss: 0.165\n",
            "[222,     4] loss: 0.141\n",
            "[223,     4] loss: 0.174\n",
            "[224,     4] loss: 0.153\n",
            "[225,     4] loss: 0.165\n",
            "[226,     4] loss: 0.147\n",
            "[227,     4] loss: 0.148\n",
            "[228,     4] loss: 0.152\n",
            "[229,     4] loss: 0.149\n",
            "[230,     4] loss: 0.136\n",
            "[231,     4] loss: 0.147\n",
            "[232,     4] loss: 0.157\n",
            "[233,     4] loss: 0.144\n",
            "[234,     4] loss: 0.158\n",
            "[235,     4] loss: 0.139\n",
            "[236,     4] loss: 0.141\n",
            "[237,     4] loss: 0.165\n",
            "[238,     4] loss: 0.145\n",
            "[239,     4] loss: 0.133\n",
            "[240,     4] loss: 0.152\n",
            "[241,     4] loss: 0.148\n",
            "[242,     4] loss: 0.172\n",
            "[243,     4] loss: 0.177\n",
            "[244,     4] loss: 0.171\n",
            "[245,     4] loss: 0.165\n",
            "[246,     4] loss: 0.144\n",
            "[247,     4] loss: 0.161\n",
            "[248,     4] loss: 0.153\n",
            "[249,     4] loss: 0.143\n",
            "[250,     4] loss: 0.154\n",
            "[251,     4] loss: 0.158\n",
            "[252,     4] loss: 0.157\n",
            "[253,     4] loss: 0.139\n",
            "[254,     4] loss: 0.162\n",
            "[255,     4] loss: 0.150\n",
            "[256,     4] loss: 0.156\n",
            "[257,     4] loss: 0.149\n",
            "[258,     4] loss: 0.150\n",
            "[259,     4] loss: 0.154\n",
            "[260,     4] loss: 0.138\n",
            "[261,     4] loss: 0.154\n",
            "[262,     4] loss: 0.163\n",
            "[263,     4] loss: 0.178\n",
            "[264,     4] loss: 0.170\n",
            "[265,     4] loss: 0.139\n",
            "[266,     4] loss: 0.159\n",
            "[267,     4] loss: 0.146\n",
            "[268,     4] loss: 0.149\n",
            "[269,     4] loss: 0.140\n",
            "[270,     4] loss: 0.149\n",
            "[271,     4] loss: 0.166\n",
            "[272,     4] loss: 0.141\n",
            "[273,     4] loss: 0.154\n",
            "[274,     4] loss: 0.148\n",
            "[275,     4] loss: 0.156\n",
            "[276,     4] loss: 0.158\n",
            "[277,     4] loss: 0.143\n",
            "[278,     4] loss: 0.153\n",
            "[279,     4] loss: 0.153\n",
            "[280,     4] loss: 0.151\n",
            "[281,     4] loss: 0.153\n",
            "[282,     4] loss: 0.157\n",
            "[283,     4] loss: 0.150\n",
            "[284,     4] loss: 0.153\n",
            "[285,     4] loss: 0.134\n",
            "[286,     4] loss: 0.153\n",
            "[287,     4] loss: 0.139\n",
            "[288,     4] loss: 0.150\n",
            "[289,     4] loss: 0.155\n",
            "[290,     4] loss: 0.150\n",
            "[291,     4] loss: 0.152\n",
            "[292,     4] loss: 0.143\n",
            "[293,     4] loss: 0.145\n",
            "[294,     4] loss: 0.146\n",
            "[295,     4] loss: 0.147\n",
            "[296,     4] loss: 0.142\n",
            "[297,     4] loss: 0.148\n",
            "[298,     4] loss: 0.142\n",
            "[299,     4] loss: 0.140\n",
            "[300,     4] loss: 0.135\n",
            "[301,     4] loss: 0.157\n",
            "[302,     4] loss: 0.146\n",
            "[303,     4] loss: 0.139\n",
            "[304,     4] loss: 0.151\n",
            "[305,     4] loss: 0.158\n",
            "[306,     4] loss: 0.136\n",
            "[307,     4] loss: 0.150\n",
            "[308,     4] loss: 0.136\n",
            "[309,     4] loss: 0.149\n",
            "[310,     4] loss: 0.170\n",
            "[311,     4] loss: 0.147\n",
            "[312,     4] loss: 0.150\n",
            "[313,     4] loss: 0.162\n",
            "[314,     4] loss: 0.145\n",
            "[315,     4] loss: 0.142\n",
            "[316,     4] loss: 0.146\n",
            "[317,     4] loss: 0.158\n",
            "[318,     4] loss: 0.149\n",
            "[319,     4] loss: 0.141\n",
            "[320,     4] loss: 0.147\n",
            "[321,     4] loss: 0.141\n",
            "[322,     4] loss: 0.159\n",
            "[323,     4] loss: 0.148\n",
            "[324,     4] loss: 0.156\n",
            "[325,     4] loss: 0.162\n",
            "[326,     4] loss: 0.152\n",
            "[327,     4] loss: 0.144\n",
            "[328,     4] loss: 0.145\n",
            "[329,     4] loss: 0.156\n",
            "[330,     4] loss: 0.148\n",
            "[331,     4] loss: 0.144\n",
            "[332,     4] loss: 0.145\n",
            "[333,     4] loss: 0.140\n",
            "[334,     4] loss: 0.137\n",
            "[335,     4] loss: 0.170\n",
            "[336,     4] loss: 0.148\n",
            "[337,     4] loss: 0.180\n",
            "[338,     4] loss: 0.165\n",
            "[339,     4] loss: 0.157\n",
            "[340,     4] loss: 0.156\n",
            "[341,     4] loss: 0.152\n",
            "[342,     4] loss: 0.153\n",
            "[343,     4] loss: 0.159\n",
            "[344,     4] loss: 0.170\n",
            "[345,     4] loss: 0.157\n",
            "[346,     4] loss: 0.157\n",
            "[347,     4] loss: 0.180\n",
            "[348,     4] loss: 0.150\n",
            "[349,     4] loss: 0.164\n",
            "[350,     4] loss: 0.157\n",
            "[351,     4] loss: 0.185\n",
            "[352,     4] loss: 0.153\n",
            "[353,     4] loss: 0.147\n",
            "[354,     4] loss: 0.138\n",
            "[355,     4] loss: 0.167\n",
            "[356,     4] loss: 0.152\n",
            "[357,     4] loss: 0.147\n",
            "[358,     4] loss: 0.154\n",
            "[359,     4] loss: 0.144\n",
            "[360,     4] loss: 0.139\n",
            "[361,     4] loss: 0.144\n",
            "[362,     4] loss: 0.168\n",
            "[363,     4] loss: 0.148\n",
            "[364,     4] loss: 0.154\n",
            "[365,     4] loss: 0.136\n",
            "[366,     4] loss: 0.146\n",
            "[367,     4] loss: 0.135\n",
            "[368,     4] loss: 0.150\n",
            "[369,     4] loss: 0.146\n",
            "[370,     4] loss: 0.161\n",
            "[371,     4] loss: 0.159\n",
            "[372,     4] loss: 0.153\n",
            "[373,     4] loss: 0.142\n",
            "[374,     4] loss: 0.150\n",
            "[375,     4] loss: 0.141\n",
            "[376,     4] loss: 0.144\n",
            "[377,     4] loss: 0.151\n",
            "[378,     4] loss: 0.145\n",
            "[379,     4] loss: 0.144\n",
            "[380,     4] loss: 0.141\n",
            "[381,     4] loss: 0.142\n",
            "[382,     4] loss: 0.130\n",
            "[383,     4] loss: 0.155\n",
            "[384,     4] loss: 0.157\n",
            "[385,     4] loss: 0.141\n",
            "[386,     4] loss: 0.147\n",
            "[387,     4] loss: 0.150\n",
            "[388,     4] loss: 0.148\n",
            "[389,     4] loss: 0.138\n",
            "[390,     4] loss: 0.132\n",
            "[391,     4] loss: 0.143\n",
            "[392,     4] loss: 0.138\n",
            "[393,     4] loss: 0.144\n",
            "[394,     4] loss: 0.156\n",
            "[395,     4] loss: 0.147\n",
            "[396,     4] loss: 0.151\n",
            "[397,     4] loss: 0.155\n",
            "[398,     4] loss: 0.134\n",
            "[399,     4] loss: 0.159\n",
            "[400,     4] loss: 0.139\n",
            "[401,     4] loss: 0.157\n",
            "[402,     4] loss: 0.137\n",
            "[403,     4] loss: 0.139\n",
            "[404,     4] loss: 0.157\n",
            "[405,     4] loss: 0.163\n",
            "[406,     4] loss: 0.161\n",
            "[407,     4] loss: 0.141\n",
            "[408,     4] loss: 0.150\n",
            "[409,     4] loss: 0.150\n",
            "[410,     4] loss: 0.167\n",
            "[411,     4] loss: 0.184\n",
            "[412,     4] loss: 0.161\n",
            "[413,     4] loss: 0.165\n",
            "[414,     4] loss: 0.146\n",
            "[415,     4] loss: 0.139\n",
            "[416,     4] loss: 0.142\n",
            "[417,     4] loss: 0.152\n",
            "[418,     4] loss: 0.156\n",
            "[419,     4] loss: 0.166\n",
            "[420,     4] loss: 0.159\n",
            "[421,     4] loss: 0.155\n",
            "[422,     4] loss: 0.149\n",
            "[423,     4] loss: 0.151\n",
            "[424,     4] loss: 0.144\n",
            "[425,     4] loss: 0.149\n",
            "[426,     4] loss: 0.148\n",
            "[427,     4] loss: 0.160\n",
            "[428,     4] loss: 0.135\n",
            "[429,     4] loss: 0.154\n",
            "[430,     4] loss: 0.139\n",
            "[431,     4] loss: 0.141\n",
            "[432,     4] loss: 0.138\n",
            "[433,     4] loss: 0.151\n",
            "[434,     4] loss: 0.147\n",
            "[435,     4] loss: 0.142\n",
            "[436,     4] loss: 0.158\n",
            "[437,     4] loss: 0.143\n",
            "[438,     4] loss: 0.151\n",
            "[439,     4] loss: 0.145\n",
            "[440,     4] loss: 0.145\n",
            "[441,     4] loss: 0.148\n",
            "[442,     4] loss: 0.151\n",
            "[443,     4] loss: 0.136\n",
            "[444,     4] loss: 0.149\n",
            "[445,     4] loss: 0.158\n",
            "[446,     4] loss: 0.145\n",
            "[447,     4] loss: 0.141\n",
            "[448,     4] loss: 0.136\n",
            "[449,     4] loss: 0.149\n",
            "[450,     4] loss: 0.151\n",
            "[451,     4] loss: 0.147\n",
            "[452,     4] loss: 0.149\n",
            "[453,     4] loss: 0.152\n",
            "[454,     4] loss: 0.151\n",
            "[455,     4] loss: 0.135\n",
            "[456,     4] loss: 0.150\n",
            "[457,     4] loss: 0.157\n",
            "[458,     4] loss: 0.160\n",
            "[459,     4] loss: 0.156\n",
            "[460,     4] loss: 0.156\n",
            "[461,     4] loss: 0.143\n",
            "[462,     4] loss: 0.154\n",
            "[463,     4] loss: 0.140\n",
            "[464,     4] loss: 0.139\n",
            "[465,     4] loss: 0.151\n",
            "[466,     4] loss: 0.161\n",
            "[467,     4] loss: 0.160\n",
            "[468,     4] loss: 0.160\n",
            "[469,     4] loss: 0.149\n",
            "[470,     4] loss: 0.131\n",
            "[471,     4] loss: 0.149\n",
            "[472,     4] loss: 0.151\n",
            "[473,     4] loss: 0.140\n",
            "[474,     4] loss: 0.145\n",
            "[475,     4] loss: 0.142\n",
            "[476,     4] loss: 0.145\n",
            "[477,     4] loss: 0.146\n",
            "[478,     4] loss: 0.149\n",
            "[479,     4] loss: 0.143\n",
            "[480,     4] loss: 0.148\n",
            "[481,     4] loss: 0.158\n",
            "[482,     4] loss: 0.144\n",
            "[483,     4] loss: 0.166\n",
            "[484,     4] loss: 0.157\n",
            "[485,     4] loss: 0.139\n",
            "[486,     4] loss: 0.155\n",
            "[487,     4] loss: 0.146\n",
            "[488,     4] loss: 0.141\n",
            "[489,     4] loss: 0.136\n",
            "[490,     4] loss: 0.146\n",
            "[491,     4] loss: 0.164\n",
            "[492,     4] loss: 0.147\n",
            "[493,     4] loss: 0.155\n",
            "[494,     4] loss: 0.153\n",
            "[495,     4] loss: 0.142\n",
            "[496,     4] loss: 0.126\n",
            "[497,     4] loss: 0.155\n",
            "[498,     4] loss: 0.140\n",
            "[499,     4] loss: 0.132\n",
            "[500,     4] loss: 0.154\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 94 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 62 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 64 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 94 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 80 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   9\n",
            "[1,     4] loss: 0.869\n",
            "[2,     4] loss: 0.467\n",
            "[3,     4] loss: 0.481\n",
            "[4,     4] loss: 0.463\n",
            "[5,     4] loss: 0.464\n",
            "[6,     4] loss: 0.462\n",
            "[7,     4] loss: 0.450\n",
            "[8,     4] loss: 0.451\n",
            "[9,     4] loss: 0.447\n",
            "[10,     4] loss: 0.450\n",
            "[11,     4] loss: 0.434\n",
            "[12,     4] loss: 0.426\n",
            "[13,     4] loss: 0.422\n",
            "[14,     4] loss: 0.402\n",
            "[15,     4] loss: 0.357\n",
            "[16,     4] loss: 0.310\n",
            "[17,     4] loss: 0.333\n",
            "[18,     4] loss: 0.210\n",
            "[19,     4] loss: 0.239\n",
            "[20,     4] loss: 0.192\n",
            "[21,     4] loss: 0.107\n",
            "[22,     4] loss: 0.101\n",
            "[23,     4] loss: 0.166\n",
            "[24,     4] loss: 0.175\n",
            "[25,     4] loss: 0.175\n",
            "[26,     4] loss: 0.190\n",
            "[27,     4] loss: 0.154\n",
            "[28,     4] loss: 0.116\n",
            "[29,     4] loss: 0.105\n",
            "[30,     4] loss: 0.102\n",
            "[31,     4] loss: 0.090\n",
            "[32,     4] loss: 0.105\n",
            "[33,     4] loss: 0.092\n",
            "[34,     4] loss: 0.093\n",
            "[35,     4] loss: 0.103\n",
            "[36,     4] loss: 0.117\n",
            "[37,     4] loss: 0.131\n",
            "[38,     4] loss: 0.110\n",
            "[39,     4] loss: 0.098\n",
            "[40,     4] loss: 0.103\n",
            "[41,     4] loss: 0.089\n",
            "[42,     4] loss: 0.115\n",
            "[43,     4] loss: 0.102\n",
            "[44,     4] loss: 0.078\n",
            "[45,     4] loss: 0.092\n",
            "[46,     4] loss: 0.074\n",
            "[47,     4] loss: 0.103\n",
            "[48,     4] loss: 0.100\n",
            "[49,     4] loss: 0.165\n",
            "[50,     4] loss: 0.115\n",
            "[51,     4] loss: 0.091\n",
            "[52,     4] loss: 0.094\n",
            "[53,     4] loss: 0.093\n",
            "[54,     4] loss: 0.125\n",
            "[55,     4] loss: 0.103\n",
            "[56,     4] loss: 0.118\n",
            "[57,     4] loss: 0.085\n",
            "[58,     4] loss: 0.095\n",
            "[59,     4] loss: 0.103\n",
            "[60,     4] loss: 0.091\n",
            "[61,     4] loss: 0.102\n",
            "[62,     4] loss: 0.128\n",
            "[63,     4] loss: 0.123\n",
            "[64,     4] loss: 0.108\n",
            "[65,     4] loss: 0.097\n",
            "[66,     4] loss: 0.089\n",
            "[67,     4] loss: 0.086\n",
            "[68,     4] loss: 0.101\n",
            "[69,     4] loss: 0.122\n",
            "[70,     4] loss: 0.111\n",
            "[71,     4] loss: 0.108\n",
            "[72,     4] loss: 0.097\n",
            "[73,     4] loss: 0.086\n",
            "[74,     4] loss: 0.090\n",
            "[75,     4] loss: 0.074\n",
            "[76,     4] loss: 0.131\n",
            "[77,     4] loss: 0.099\n",
            "[78,     4] loss: 0.101\n",
            "[79,     4] loss: 0.097\n",
            "[80,     4] loss: 0.081\n",
            "[81,     4] loss: 0.082\n",
            "[82,     4] loss: 0.090\n",
            "[83,     4] loss: 0.094\n",
            "[84,     4] loss: 0.088\n",
            "[85,     4] loss: 0.085\n",
            "[86,     4] loss: 0.098\n",
            "[87,     4] loss: 0.088\n",
            "[88,     4] loss: 0.095\n",
            "[89,     4] loss: 0.090\n",
            "[90,     4] loss: 0.115\n",
            "[91,     4] loss: 0.093\n",
            "[92,     4] loss: 0.100\n",
            "[93,     4] loss: 0.086\n",
            "[94,     4] loss: 0.106\n",
            "[95,     4] loss: 0.136\n",
            "[96,     4] loss: 0.120\n",
            "[97,     4] loss: 0.134\n",
            "[98,     4] loss: 0.106\n",
            "[99,     4] loss: 0.113\n",
            "[100,     4] loss: 0.080\n",
            "[101,     4] loss: 0.102\n",
            "[102,     4] loss: 0.102\n",
            "[103,     4] loss: 0.085\n",
            "[104,     4] loss: 0.082\n",
            "[105,     4] loss: 0.084\n",
            "[106,     4] loss: 0.096\n",
            "[107,     4] loss: 0.085\n",
            "[108,     4] loss: 0.096\n",
            "[109,     4] loss: 0.121\n",
            "[110,     4] loss: 0.101\n",
            "[111,     4] loss: 0.115\n",
            "[112,     4] loss: 0.116\n",
            "[113,     4] loss: 0.121\n",
            "[114,     4] loss: 0.140\n",
            "[115,     4] loss: 0.092\n",
            "[116,     4] loss: 0.089\n",
            "[117,     4] loss: 0.090\n",
            "[118,     4] loss: 0.104\n",
            "[119,     4] loss: 0.108\n",
            "[120,     4] loss: 0.115\n",
            "[121,     4] loss: 0.108\n",
            "[122,     4] loss: 0.094\n",
            "[123,     4] loss: 0.081\n",
            "[124,     4] loss: 0.096\n",
            "[125,     4] loss: 0.102\n",
            "[126,     4] loss: 0.097\n",
            "[127,     4] loss: 0.094\n",
            "[128,     4] loss: 0.091\n",
            "[129,     4] loss: 0.090\n",
            "[130,     4] loss: 0.082\n",
            "[131,     4] loss: 0.120\n",
            "[132,     4] loss: 0.101\n",
            "[133,     4] loss: 0.085\n",
            "[134,     4] loss: 0.104\n",
            "[135,     4] loss: 0.101\n",
            "[136,     4] loss: 0.105\n",
            "[137,     4] loss: 0.096\n",
            "[138,     4] loss: 0.108\n",
            "[139,     4] loss: 0.100\n",
            "[140,     4] loss: 0.094\n",
            "[141,     4] loss: 0.106\n",
            "[142,     4] loss: 0.111\n",
            "[143,     4] loss: 0.083\n",
            "[144,     4] loss: 0.088\n",
            "[145,     4] loss: 0.097\n",
            "[146,     4] loss: 0.101\n",
            "[147,     4] loss: 0.102\n",
            "[148,     4] loss: 0.101\n",
            "[149,     4] loss: 0.111\n",
            "[150,     4] loss: 0.102\n",
            "[151,     4] loss: 0.091\n",
            "[152,     4] loss: 0.083\n",
            "[153,     4] loss: 0.104\n",
            "[154,     4] loss: 0.090\n",
            "[155,     4] loss: 0.104\n",
            "[156,     4] loss: 0.100\n",
            "[157,     4] loss: 0.091\n",
            "[158,     4] loss: 0.105\n",
            "[159,     4] loss: 0.106\n",
            "[160,     4] loss: 0.093\n",
            "[161,     4] loss: 0.087\n",
            "[162,     4] loss: 0.092\n",
            "[163,     4] loss: 0.092\n",
            "[164,     4] loss: 0.086\n",
            "[165,     4] loss: 0.111\n",
            "[166,     4] loss: 0.113\n",
            "[167,     4] loss: 0.095\n",
            "[168,     4] loss: 0.087\n",
            "[169,     4] loss: 0.085\n",
            "[170,     4] loss: 0.083\n",
            "[171,     4] loss: 0.083\n",
            "[172,     4] loss: 0.080\n",
            "[173,     4] loss: 0.097\n",
            "[174,     4] loss: 0.103\n",
            "[175,     4] loss: 0.102\n",
            "[176,     4] loss: 0.089\n",
            "[177,     4] loss: 0.095\n",
            "[178,     4] loss: 0.092\n",
            "[179,     4] loss: 0.097\n",
            "[180,     4] loss: 0.097\n",
            "[181,     4] loss: 0.093\n",
            "[182,     4] loss: 0.088\n",
            "[183,     4] loss: 0.095\n",
            "[184,     4] loss: 0.093\n",
            "[185,     4] loss: 0.103\n",
            "[186,     4] loss: 0.111\n",
            "[187,     4] loss: 0.109\n",
            "[188,     4] loss: 0.101\n",
            "[189,     4] loss: 0.108\n",
            "[190,     4] loss: 0.100\n",
            "[191,     4] loss: 0.109\n",
            "[192,     4] loss: 0.099\n",
            "[193,     4] loss: 0.091\n",
            "[194,     4] loss: 0.093\n",
            "[195,     4] loss: 0.078\n",
            "[196,     4] loss: 0.079\n",
            "[197,     4] loss: 0.090\n",
            "[198,     4] loss: 0.095\n",
            "[199,     4] loss: 0.095\n",
            "[200,     4] loss: 0.088\n",
            "[201,     4] loss: 0.099\n",
            "[202,     4] loss: 0.092\n",
            "[203,     4] loss: 0.095\n",
            "[204,     4] loss: 0.105\n",
            "[205,     4] loss: 0.103\n",
            "[206,     4] loss: 0.086\n",
            "[207,     4] loss: 0.087\n",
            "[208,     4] loss: 0.090\n",
            "[209,     4] loss: 0.087\n",
            "[210,     4] loss: 0.095\n",
            "[211,     4] loss: 0.089\n",
            "[212,     4] loss: 0.084\n",
            "[213,     4] loss: 0.087\n",
            "[214,     4] loss: 0.086\n",
            "[215,     4] loss: 0.104\n",
            "[216,     4] loss: 0.123\n",
            "[217,     4] loss: 0.094\n",
            "[218,     4] loss: 0.103\n",
            "[219,     4] loss: 0.107\n",
            "[220,     4] loss: 0.086\n",
            "[221,     4] loss: 0.076\n",
            "[222,     4] loss: 0.091\n",
            "[223,     4] loss: 0.098\n",
            "[224,     4] loss: 0.114\n",
            "[225,     4] loss: 0.106\n",
            "[226,     4] loss: 0.100\n",
            "[227,     4] loss: 0.098\n",
            "[228,     4] loss: 0.138\n",
            "[229,     4] loss: 0.098\n",
            "[230,     4] loss: 0.118\n",
            "[231,     4] loss: 0.099\n",
            "[232,     4] loss: 0.085\n",
            "[233,     4] loss: 0.098\n",
            "[234,     4] loss: 0.084\n",
            "[235,     4] loss: 0.141\n",
            "[236,     4] loss: 0.124\n",
            "[237,     4] loss: 0.104\n",
            "[238,     4] loss: 0.122\n",
            "[239,     4] loss: 0.112\n",
            "[240,     4] loss: 0.091\n",
            "[241,     4] loss: 0.106\n",
            "[242,     4] loss: 0.117\n",
            "[243,     4] loss: 0.100\n",
            "[244,     4] loss: 0.124\n",
            "[245,     4] loss: 0.103\n",
            "[246,     4] loss: 0.093\n",
            "[247,     4] loss: 0.094\n",
            "[248,     4] loss: 0.094\n",
            "[249,     4] loss: 0.092\n",
            "[250,     4] loss: 0.081\n",
            "[251,     4] loss: 0.091\n",
            "[252,     4] loss: 0.087\n",
            "[253,     4] loss: 0.090\n",
            "[254,     4] loss: 0.099\n",
            "[255,     4] loss: 0.084\n",
            "[256,     4] loss: 0.086\n",
            "[257,     4] loss: 0.096\n",
            "[258,     4] loss: 0.113\n",
            "[259,     4] loss: 0.088\n",
            "[260,     4] loss: 0.086\n",
            "[261,     4] loss: 0.087\n",
            "[262,     4] loss: 0.078\n",
            "[263,     4] loss: 0.102\n",
            "[264,     4] loss: 0.104\n",
            "[265,     4] loss: 0.116\n",
            "[266,     4] loss: 0.103\n",
            "[267,     4] loss: 0.103\n",
            "[268,     4] loss: 0.123\n",
            "[269,     4] loss: 0.105\n",
            "[270,     4] loss: 0.096\n",
            "[271,     4] loss: 0.086\n",
            "[272,     4] loss: 0.110\n",
            "[273,     4] loss: 0.086\n",
            "[274,     4] loss: 0.097\n",
            "[275,     4] loss: 0.092\n",
            "[276,     4] loss: 0.096\n",
            "[277,     4] loss: 0.088\n",
            "[278,     4] loss: 0.083\n",
            "[279,     4] loss: 0.097\n",
            "[280,     4] loss: 0.081\n",
            "[281,     4] loss: 0.075\n",
            "[282,     4] loss: 0.076\n",
            "[283,     4] loss: 0.092\n",
            "[284,     4] loss: 0.076\n",
            "[285,     4] loss: 0.086\n",
            "[286,     4] loss: 0.081\n",
            "[287,     4] loss: 0.087\n",
            "[288,     4] loss: 0.092\n",
            "[289,     4] loss: 0.090\n",
            "[290,     4] loss: 0.114\n",
            "[291,     4] loss: 0.100\n",
            "[292,     4] loss: 0.104\n",
            "[293,     4] loss: 0.094\n",
            "[294,     4] loss: 0.093\n",
            "[295,     4] loss: 0.079\n",
            "[296,     4] loss: 0.089\n",
            "[297,     4] loss: 0.087\n",
            "[298,     4] loss: 0.082\n",
            "[299,     4] loss: 0.093\n",
            "[300,     4] loss: 0.087\n",
            "[301,     4] loss: 0.089\n",
            "[302,     4] loss: 0.094\n",
            "[303,     4] loss: 0.093\n",
            "[304,     4] loss: 0.101\n",
            "[305,     4] loss: 0.115\n",
            "[306,     4] loss: 0.092\n",
            "[307,     4] loss: 0.098\n",
            "[308,     4] loss: 0.082\n",
            "[309,     4] loss: 0.094\n",
            "[310,     4] loss: 0.089\n",
            "[311,     4] loss: 0.088\n",
            "[312,     4] loss: 0.088\n",
            "[313,     4] loss: 0.085\n",
            "[314,     4] loss: 0.093\n",
            "[315,     4] loss: 0.095\n",
            "[316,     4] loss: 0.083\n",
            "[317,     4] loss: 0.083\n",
            "[318,     4] loss: 0.090\n",
            "[319,     4] loss: 0.085\n",
            "[320,     4] loss: 0.088\n",
            "[321,     4] loss: 0.095\n",
            "[322,     4] loss: 0.082\n",
            "[323,     4] loss: 0.099\n",
            "[324,     4] loss: 0.096\n",
            "[325,     4] loss: 0.086\n",
            "[326,     4] loss: 0.097\n",
            "[327,     4] loss: 0.097\n",
            "[328,     4] loss: 0.109\n",
            "[329,     4] loss: 0.113\n",
            "[330,     4] loss: 0.084\n",
            "[331,     4] loss: 0.126\n",
            "[332,     4] loss: 0.127\n",
            "[333,     4] loss: 0.107\n",
            "[334,     4] loss: 0.099\n",
            "[335,     4] loss: 0.104\n",
            "[336,     4] loss: 2.123\n",
            "[337,     4] loss: 0.274\n",
            "[338,     4] loss: 0.103\n",
            "[339,     4] loss: 0.093\n",
            "[340,     4] loss: 0.091\n",
            "[341,     4] loss: 0.117\n",
            "[342,     4] loss: 0.118\n",
            "[343,     4] loss: 0.095\n",
            "[344,     4] loss: 0.090\n",
            "[345,     4] loss: 0.096\n",
            "[346,     4] loss: 0.105\n",
            "[347,     4] loss: 0.094\n",
            "[348,     4] loss: 0.109\n",
            "[349,     4] loss: 0.111\n",
            "[350,     4] loss: 0.089\n",
            "[351,     4] loss: 0.085\n",
            "[352,     4] loss: 0.093\n",
            "[353,     4] loss: 0.095\n",
            "[354,     4] loss: 0.088\n",
            "[355,     4] loss: 0.094\n",
            "[356,     4] loss: 0.104\n",
            "[357,     4] loss: 0.124\n",
            "[358,     4] loss: 0.095\n",
            "[359,     4] loss: 0.113\n",
            "[360,     4] loss: 0.107\n",
            "[361,     4] loss: 0.137\n",
            "[362,     4] loss: 0.151\n",
            "[363,     4] loss: 0.110\n",
            "[364,     4] loss: 0.103\n",
            "[365,     4] loss: 0.099\n",
            "[366,     4] loss: 0.088\n",
            "[367,     4] loss: 0.096\n",
            "[368,     4] loss: 0.088\n",
            "[369,     4] loss: 0.091\n",
            "[370,     4] loss: 0.091\n",
            "[371,     4] loss: 0.085\n",
            "[372,     4] loss: 0.082\n",
            "[373,     4] loss: 0.102\n",
            "[374,     4] loss: 0.101\n",
            "[375,     4] loss: 0.095\n",
            "[376,     4] loss: 0.097\n",
            "[377,     4] loss: 0.086\n",
            "[378,     4] loss: 0.088\n",
            "[379,     4] loss: 0.088\n",
            "[380,     4] loss: 0.092\n",
            "[381,     4] loss: 0.111\n",
            "[382,     4] loss: 0.101\n",
            "[383,     4] loss: 0.097\n",
            "[384,     4] loss: 0.084\n",
            "[385,     4] loss: 0.094\n",
            "[386,     4] loss: 0.092\n",
            "[387,     4] loss: 0.083\n",
            "[388,     4] loss: 0.086\n",
            "[389,     4] loss: 0.077\n",
            "[390,     4] loss: 0.080\n",
            "[391,     4] loss: 0.083\n",
            "[392,     4] loss: 0.102\n",
            "[393,     4] loss: 0.092\n",
            "[394,     4] loss: 0.072\n",
            "[395,     4] loss: 0.092\n",
            "[396,     4] loss: 0.093\n",
            "[397,     4] loss: 0.086\n",
            "[398,     4] loss: 0.092\n",
            "[399,     4] loss: 0.127\n",
            "[400,     4] loss: 0.098\n",
            "[401,     4] loss: 0.089\n",
            "[402,     4] loss: 0.087\n",
            "[403,     4] loss: 0.071\n",
            "[404,     4] loss: 0.094\n",
            "[405,     4] loss: 0.098\n",
            "[406,     4] loss: 0.088\n",
            "[407,     4] loss: 0.091\n",
            "[408,     4] loss: 0.107\n",
            "[409,     4] loss: 0.101\n",
            "[410,     4] loss: 0.108\n",
            "[411,     4] loss: 0.096\n",
            "[412,     4] loss: 0.105\n",
            "[413,     4] loss: 0.107\n",
            "[414,     4] loss: 0.098\n",
            "[415,     4] loss: 0.108\n",
            "[416,     4] loss: 0.087\n",
            "[417,     4] loss: 0.092\n",
            "[418,     4] loss: 0.100\n",
            "[419,     4] loss: 0.088\n",
            "[420,     4] loss: 0.107\n",
            "[421,     4] loss: 0.095\n",
            "[422,     4] loss: 0.096\n",
            "[423,     4] loss: 0.116\n",
            "[424,     4] loss: 0.116\n",
            "[425,     4] loss: 0.118\n",
            "[426,     4] loss: 0.101\n",
            "[427,     4] loss: 0.087\n",
            "[428,     4] loss: 0.076\n",
            "[429,     4] loss: 0.089\n",
            "[430,     4] loss: 0.085\n",
            "[431,     4] loss: 0.083\n",
            "[432,     4] loss: 0.094\n",
            "[433,     4] loss: 0.090\n",
            "[434,     4] loss: 0.080\n",
            "[435,     4] loss: 0.084\n",
            "[436,     4] loss: 0.086\n",
            "[437,     4] loss: 0.092\n",
            "[438,     4] loss: 0.103\n",
            "[439,     4] loss: 0.102\n",
            "[440,     4] loss: 0.105\n",
            "[441,     4] loss: 0.099\n",
            "[442,     4] loss: 0.108\n",
            "[443,     4] loss: 0.080\n",
            "[444,     4] loss: 0.087\n",
            "[445,     4] loss: 0.083\n",
            "[446,     4] loss: 0.093\n",
            "[447,     4] loss: 0.084\n",
            "[448,     4] loss: 0.087\n",
            "[449,     4] loss: 0.103\n",
            "[450,     4] loss: 0.092\n",
            "[451,     4] loss: 0.096\n",
            "[452,     4] loss: 0.096\n",
            "[453,     4] loss: 0.101\n",
            "[454,     4] loss: 0.097\n",
            "[455,     4] loss: 0.086\n",
            "[456,     4] loss: 0.088\n",
            "[457,     4] loss: 0.087\n",
            "[458,     4] loss: 0.082\n",
            "[459,     4] loss: 0.087\n",
            "[460,     4] loss: 0.087\n",
            "[461,     4] loss: 0.099\n",
            "[462,     4] loss: 0.077\n",
            "[463,     4] loss: 0.085\n",
            "[464,     4] loss: 0.093\n",
            "[465,     4] loss: 0.112\n",
            "[466,     4] loss: 0.098\n",
            "[467,     4] loss: 0.089\n",
            "[468,     4] loss: 0.085\n",
            "[469,     4] loss: 0.080\n",
            "[470,     4] loss: 0.086\n",
            "[471,     4] loss: 0.076\n",
            "[472,     4] loss: 0.094\n",
            "[473,     4] loss: 0.137\n",
            "[474,     4] loss: 0.119\n",
            "[475,     4] loss: 0.098\n",
            "[476,     4] loss: 0.111\n",
            "[477,     4] loss: 0.108\n",
            "[478,     4] loss: 0.114\n",
            "[479,     4] loss: 0.093\n",
            "[480,     4] loss: 0.096\n",
            "[481,     4] loss: 0.088\n",
            "[482,     4] loss: 0.078\n",
            "[483,     4] loss: 0.085\n",
            "[484,     4] loss: 0.087\n",
            "[485,     4] loss: 0.092\n",
            "[486,     4] loss: 0.097\n",
            "[487,     4] loss: 0.086\n",
            "[488,     4] loss: 0.082\n",
            "[489,     4] loss: 0.089\n",
            "[490,     4] loss: 0.082\n",
            "[491,     4] loss: 0.088\n",
            "[492,     4] loss: 0.090\n",
            "[493,     4] loss: 0.095\n",
            "[494,     4] loss: 0.088\n",
            "[495,     4] loss: 0.083\n",
            "[496,     4] loss: 0.087\n",
            "[497,     4] loss: 0.089\n",
            "[498,     4] loss: 0.092\n",
            "[499,     4] loss: 0.080\n",
            "[500,     4] loss: 0.089\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 96 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 32 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 32 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 32 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 32 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 33 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 53 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 62 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 72 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 96 %\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In76SYH_zZHV"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "BS4HtOHEzZ0E",
        "outputId": "91e9e1bc-a744-442a-a7a5-36e66baf3fb8"
      },
      "source": [
        "for i,j in enumerate(train_loss_all):\n",
        "    plt.plot(j,label =\"dataset \"+str(i+1))\n",
        "    \n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4fc036e240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS5D_SpOzj9n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va4L2IZ1zj6o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}