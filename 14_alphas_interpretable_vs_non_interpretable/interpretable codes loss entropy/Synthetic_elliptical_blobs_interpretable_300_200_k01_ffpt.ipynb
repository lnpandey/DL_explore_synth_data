{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Synthetic_elliptical_blobs_interpretable_300_100_k01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYu3ISwwGks"
      },
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.stats import entropy"
      ],
      "execution_count": 616,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEp-LtqiWAf"
      },
      "source": [
        "mu1 = np.array([3,3,3,3,0])\n",
        "sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu2 = np.array([4,4,4,4,0])\n",
        "sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu3 = np.array([10,5,5,10,0])\n",
        "sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu4 = np.array([-10,-10,-10,-10,0])\n",
        "sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu5 = np.array([-21,4,4,-21,0])\n",
        "sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu6 = np.array([-10,18,18,-10,0])\n",
        "sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu7 = np.array([4,20,4,20,0])\n",
        "sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu8 = np.array([4,-20,-20,4,0])\n",
        "sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu9 = np.array([20,20,20,20,0])\n",
        "sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu10 = np.array([20,-10,-10,20,0])\n",
        "sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)\n"
      ],
      "execution_count": 617,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NshDNGjY2T3w"
      },
      "source": [
        "# mu1 = np.array([3,3,0,0,0])\n",
        "# sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu2 = np.array([4,4,0,0,0])\n",
        "# sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu3 = np.array([10,5,0,0,0])\n",
        "# sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu4 = np.array([-10,-10,0,0,0])\n",
        "# sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu5 = np.array([-21,4,0,0,0])\n",
        "# sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu6 = np.array([-10,18,0,0,0])\n",
        "# sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu7 = np.array([4,20,0,0,0])\n",
        "# sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu8 = np.array([4,-20,0,0,0])\n",
        "# sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu9 = np.array([20,20,0,0,0])\n",
        "# sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu10 = np.array([20,-10,0,0,0])\n",
        "# sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "# sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "# sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "# sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "# sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "# sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "# sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "# sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "# sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "# sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "# sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)"
      ],
      "execution_count": 618,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YDnxeP-2_1V",
        "outputId": "17c0ace3-4333-4ccf-ac53-96b18c24d5c6"
      },
      "source": [
        "X = np.concatenate((sample1,sample2,sample3,sample4,sample5,sample6,sample7,sample8,sample9,sample10),axis=0)\n",
        "Y = np.concatenate((np.zeros((500,1)),np.ones((500,1)),2*np.ones((500,1)),3*np.ones((500,1)),4*np.ones((500,1)),\n",
        "                    5*np.ones((500,1)),6*np.ones((500,1)),7*np.ones((500,1)),8*np.ones((500,1)),9*np.ones((500,1))),axis=0).astype(int)\n",
        "print(X.shape,Y.shape)\n",
        "# plt.scatter(sample1[:,0],sample1[:,1],label=\"class_0\")\n",
        "# plt.scatter(sample2[:,0],sample2[:,1],label=\"class_1\")\n",
        "# plt.scatter(sample3[:,0],sample3[:,1],label=\"class_2\")\n",
        "# plt.scatter(sample4[:,0],sample4[:,1],label=\"class_3\")\n",
        "# plt.scatter(sample5[:,0],sample5[:,1],label=\"class_4\")\n",
        "# plt.scatter(sample6[:,0],sample6[:,1],label=\"class_5\")\n",
        "# plt.scatter(sample7[:,0],sample7[:,1],label=\"class_6\")\n",
        "# plt.scatter(sample8[:,0],sample8[:,1],label=\"class_7\")\n",
        "# plt.scatter(sample9[:,0],sample9[:,1],label=\"class_8\")\n",
        "# plt.scatter(sample10[:,0],sample10[:,1],label=\"class_9\")\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
      ],
      "execution_count": 619,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 5) (5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YzqPUf3CHa"
      },
      "source": [
        "class SyntheticDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    #self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx] , self.y[idx] #, self.fore_idx[idx]"
      ],
      "execution_count": 620,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mi3nL5-4D7_"
      },
      "source": [
        "trainset = SyntheticDataset(X,Y)\n",
        "\n",
        "\n",
        "# testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 621,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKzc7IgwqoU2",
        "outputId": "423ba21e-6a45-4819-ef5a-5f76c6e7ffb9"
      },
      "source": [
        "classes = ('zero','one','two','three','four','five','six','seven','eight','nine')\n",
        "\n",
        "foreground_classes = {'zero','one','two'}\n",
        "fg_used = '012'\n",
        "fg1, fg2, fg3 = 0,1,2\n",
        "\n",
        "\n",
        "all_classes = {'zero','one','two','three','four','five','six','seven','eight','nine'}\n",
        "background_classes = all_classes - foreground_classes\n",
        "background_classes"
      ],
      "execution_count": 622,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eight', 'five', 'four', 'nine', 'seven', 'six', 'three'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 622
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT6iKHutquR8"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)"
      ],
      "execution_count": 623,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKzXkPSq5KU"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=100\n",
        "\n",
        "for i in range(50):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 624,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChdziOP3rF1G"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])\n",
        "      label = foreground_label[fg_idx] - fg1  # minus fg1 because our fore ground classes are fg1,fg2,fg3 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 625,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASrmPqErIDM"
      },
      "source": [
        "desired_num = 3000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "list_set_labels = [] \n",
        "for i in range(desired_num):\n",
        "  set_idx = set()\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,3500,8)\n",
        "  set_idx = set(background_label[bg_idx].tolist())\n",
        "  fg_idx = np.random.randint(0,1500)\n",
        "  set_idx.add(foreground_label[fg_idx].item())\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)\n",
        "  list_set_labels.append(set_idx)"
      ],
      "execution_count": 626,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDFN7dCarmmR"
      },
      "source": [
        "def create_avg_image_from_mosaic_dataset(mosaic_dataset,labels,foreground_index,dataset_number):\n",
        "  \"\"\"\n",
        "  mosaic_dataset : mosaic_dataset contains 9 images 32 x 32 each as 1 data point\n",
        "  labels : mosaic_dataset labels\n",
        "  foreground_index : contains list of indexes where foreground image is present so that using this we can take weighted average\n",
        "  dataset_number : will help us to tell what ratio of foreground image to be taken. for eg: if it is \"j\" then fg_image_ratio = j/9 , bg_image_ratio = (9-j)/8*9\n",
        "  \"\"\"\n",
        "  avg_image_dataset = []\n",
        "  for i in range(len(mosaic_dataset)):\n",
        "    img = torch.zeros([5], dtype=torch.float64)\n",
        "    for j in range(9):\n",
        "      if j == foreground_index[i]:\n",
        "        img = img + mosaic_dataset[i][j]*dataset_number/9\n",
        "      else :\n",
        "        img = img + mosaic_dataset[i][j]*(9-dataset_number)/(8*9)\n",
        "    \n",
        "    avg_image_dataset.append(img)\n",
        "    \n",
        "  return torch.stack(avg_image_dataset) , torch.stack(labels) , foreground_index"
      ],
      "execution_count": 627,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgF90qBIt8yN"
      },
      "source": [
        "def calculate_loss(dataloader,model,criter):\n",
        "  model.eval()\n",
        "  r_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      outputs = model(inputs)\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  return r_loss/i"
      ],
      "execution_count": 628,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGsdvMSzIUK"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 629,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5NPRPmb904"
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 630,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzPfrih82Bg"
      },
      "source": [
        "**Focus Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN3Bbs8c0fA"
      },
      "source": [
        "class Focus_deep(nn.Module):\n",
        "    '''\n",
        "       deep focus network averaged at zeroth layer\n",
        "       input : elemental data\n",
        "    '''\n",
        "    def __init__(self,inputs,output,K,d):\n",
        "        super(Focus_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.K = K\n",
        "        self.d  = d\n",
        "        self.linear1 = nn.Linear(self.inputs,300)  #,self.output)\n",
        "        self.linear2 = nn.Linear(300,self.output) \n",
        "    def forward(self,z):\n",
        "        batch = z.shape[0]\n",
        "        x = torch.zeros([batch,self.K],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,self.d], dtype=torch.float64)\n",
        "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        for i in range(self.K):\n",
        "            x[:,i] = self.helper(z[:,i] )[:,0]  # self.d*i:self.d*i+self.d\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(self.K):\n",
        "            x1 = x[:,i]          \n",
        "            y = y+torch.mul(x1[:,None],z[:,i])  # self.d*i:self.d*i+self.d\n",
        "        return y , x \n",
        "    def helper(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x\n"
      ],
      "execution_count": 631,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjrL0Zb484KO"
      },
      "source": [
        "**Classification Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W0oKcClFZY"
      },
      "source": [
        "class Classification_deep(nn.Module):\n",
        "    '''\n",
        "       input : elemental data\n",
        "       deep classification module data averaged at zeroth layer\n",
        "    '''\n",
        "    def __init__(self,inputs,output):\n",
        "        super(Classification_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.linear1 = nn.Linear(self.inputs,200)\n",
        "        self.linear2 = nn.Linear(200,self.output)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x    "
      ],
      "execution_count": 632,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByKHrKis88lW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAPjSKkrd0ru"
      },
      "source": [
        "where = Focus_deep(5,1,9,5).double()\n",
        "what = Classification_deep(5,3).double()\n",
        "where = where.to(\"cuda\")\n",
        "what = what.to(\"cuda\")"
      ],
      "execution_count": 633,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAfQnNwgFYX"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,where,criter,k):\n",
        "  what.eval()\n",
        "  where.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels, fidx = data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      avg,alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "\n",
        "      ent = np.sum(entropy(alpha.cpu().detach().numpy(), base=2, axis=1))/batch\n",
        "      # mx,_ = torch.max(alpha,1)\n",
        "      # entropy = np.mean(-np.log2(mx.cpu().detach().numpy()))\n",
        "      # print(\"entropy of batch\", entropy)\n",
        "\n",
        "      loss = criter(outputs, labels) + k*ent\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis"
      ],
      "execution_count": 634,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9HQJMzxBhp"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 635,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOfxUJZ_eFKw",
        "outputId": "d8d973c1-96a1-42cf-d619-640b3d7e03a6"
      },
      "source": [
        "print(\"--\"*40)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_where = optim.Adam(where.parameters(),lr =0.001)\n",
        "optimizer_what = optim.Adam(what.parameters(), lr=0.001)\n",
        "acti = []\n",
        "loss_curi = []\n",
        "analysis_data = []\n",
        "epochs = 1000\n",
        "k=0.1\n",
        "running_loss,anlys_data = calculate_attn_loss(train_loader,what,where,criterion,k)\n",
        "loss_curi.append(running_loss)\n",
        "analysis_data.append(anlys_data)\n",
        "print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what.train()\n",
        "  where.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_ = data\n",
        "    inputs = inputs.double()\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    optimizer_where.zero_grad()\n",
        "    optimizer_what.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    avg, alpha = where(inputs)\n",
        "    outputs = what(avg)\n",
        "\n",
        "    ent = np.sum(entropy(alpha.cpu().detach().numpy(), base=2, axis=1))/batch #entropy(alpha.cpu().numpy(), base=2, axis=1)\n",
        "    # mx,_ = torch.max(alpha,1)\n",
        "    # entropy = np.mean(-np.log2(mx.cpu().detach().numpy()))\n",
        "    # print(\"entropy of batch\", entropy)\n",
        "    \n",
        "    loss = criterion(outputs, labels) + k*ent\n",
        "\n",
        "    # loss = criterion(outputs, labels)\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer_where.step()\n",
        "    optimizer_what.step()\n",
        "\n",
        "  running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion,k)\n",
        "  analysis_data.append(anls_data)\n",
        "  print('epoch: [%d] loss: %.3f' %(epoch + 1,running_loss)) \n",
        "  loss_curi.append(running_loss)   #loss per epoch\n",
        "  if running_loss<=0.05:\n",
        "    break\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels,_ = data\n",
        "    images = images.double()\n",
        "    images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    avg, alpha = where(images)\n",
        "    outputs  = what(avg)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    "
      ],
      "execution_count": 636,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 2.284\n",
            "epoch: [1] loss: 1.410\n",
            "epoch: [2] loss: 1.328\n",
            "epoch: [3] loss: 1.311\n",
            "epoch: [4] loss: 1.315\n",
            "epoch: [5] loss: 1.318\n",
            "epoch: [6] loss: 1.325\n",
            "epoch: [7] loss: 1.342\n",
            "epoch: [8] loss: 1.342\n",
            "epoch: [9] loss: 1.344\n",
            "epoch: [10] loss: 1.383\n",
            "epoch: [11] loss: 1.054\n",
            "epoch: [12] loss: 0.658\n",
            "epoch: [13] loss: 0.544\n",
            "epoch: [14] loss: 0.480\n",
            "epoch: [15] loss: 0.414\n",
            "epoch: [16] loss: 0.374\n",
            "epoch: [17] loss: 0.331\n",
            "epoch: [18] loss: 0.301\n",
            "epoch: [19] loss: 0.275\n",
            "epoch: [20] loss: 0.254\n",
            "epoch: [21] loss: 0.234\n",
            "epoch: [22] loss: 0.220\n",
            "epoch: [23] loss: 0.204\n",
            "epoch: [24] loss: 0.192\n",
            "epoch: [25] loss: 0.181\n",
            "epoch: [26] loss: 0.172\n",
            "epoch: [27] loss: 0.165\n",
            "epoch: [28] loss: 0.155\n",
            "epoch: [29] loss: 0.150\n",
            "epoch: [30] loss: 0.142\n",
            "epoch: [31] loss: 0.136\n",
            "epoch: [32] loss: 0.131\n",
            "epoch: [33] loss: 0.127\n",
            "epoch: [34] loss: 0.122\n",
            "epoch: [35] loss: 0.119\n",
            "epoch: [36] loss: 0.116\n",
            "epoch: [37] loss: 0.111\n",
            "epoch: [38] loss: 0.108\n",
            "epoch: [39] loss: 0.105\n",
            "epoch: [40] loss: 0.102\n",
            "epoch: [41] loss: 0.101\n",
            "epoch: [42] loss: 0.097\n",
            "epoch: [43] loss: 0.095\n",
            "epoch: [44] loss: 0.095\n",
            "epoch: [45] loss: 0.091\n",
            "epoch: [46] loss: 0.090\n",
            "epoch: [47] loss: 0.087\n",
            "epoch: [48] loss: 0.086\n",
            "epoch: [49] loss: 0.086\n",
            "epoch: [50] loss: 0.083\n",
            "epoch: [51] loss: 0.082\n",
            "epoch: [52] loss: 0.080\n",
            "epoch: [53] loss: 0.080\n",
            "epoch: [54] loss: 0.078\n",
            "epoch: [55] loss: 0.078\n",
            "epoch: [56] loss: 0.076\n",
            "epoch: [57] loss: 0.078\n",
            "epoch: [58] loss: 0.076\n",
            "epoch: [59] loss: 0.076\n",
            "epoch: [60] loss: 0.073\n",
            "epoch: [61] loss: 0.074\n",
            "epoch: [62] loss: 0.074\n",
            "epoch: [63] loss: 0.073\n",
            "epoch: [64] loss: 0.074\n",
            "epoch: [65] loss: 0.074\n",
            "epoch: [66] loss: 0.071\n",
            "epoch: [67] loss: 0.071\n",
            "epoch: [68] loss: 0.069\n",
            "epoch: [69] loss: 0.070\n",
            "epoch: [70] loss: 0.069\n",
            "epoch: [71] loss: 0.070\n",
            "epoch: [72] loss: 0.068\n",
            "epoch: [73] loss: 0.067\n",
            "epoch: [74] loss: 0.071\n",
            "epoch: [75] loss: 0.067\n",
            "epoch: [76] loss: 0.069\n",
            "epoch: [77] loss: 0.067\n",
            "epoch: [78] loss: 0.068\n",
            "epoch: [79] loss: 0.067\n",
            "epoch: [80] loss: 0.065\n",
            "epoch: [81] loss: 0.066\n",
            "epoch: [82] loss: 0.066\n",
            "epoch: [83] loss: 0.068\n",
            "epoch: [84] loss: 0.066\n",
            "epoch: [85] loss: 0.065\n",
            "epoch: [86] loss: 0.064\n",
            "epoch: [87] loss: 0.067\n",
            "epoch: [88] loss: 0.065\n",
            "epoch: [89] loss: 0.065\n",
            "epoch: [90] loss: 0.063\n",
            "epoch: [91] loss: 0.062\n",
            "epoch: [92] loss: 0.066\n",
            "epoch: [93] loss: 0.065\n",
            "epoch: [94] loss: 0.062\n",
            "epoch: [95] loss: 0.063\n",
            "epoch: [96] loss: 0.064\n",
            "epoch: [97] loss: 0.065\n",
            "epoch: [98] loss: 0.063\n",
            "epoch: [99] loss: 0.063\n",
            "epoch: [100] loss: 0.064\n",
            "epoch: [101] loss: 0.062\n",
            "epoch: [102] loss: 0.061\n",
            "epoch: [103] loss: 0.064\n",
            "epoch: [104] loss: 0.063\n",
            "epoch: [105] loss: 0.063\n",
            "epoch: [106] loss: 0.063\n",
            "epoch: [107] loss: 0.065\n",
            "epoch: [108] loss: 0.062\n",
            "epoch: [109] loss: 0.061\n",
            "epoch: [110] loss: 0.062\n",
            "epoch: [111] loss: 0.061\n",
            "epoch: [112] loss: 0.061\n",
            "epoch: [113] loss: 0.061\n",
            "epoch: [114] loss: 0.061\n",
            "epoch: [115] loss: 0.062\n",
            "epoch: [116] loss: 0.060\n",
            "epoch: [117] loss: 0.061\n",
            "epoch: [118] loss: 0.061\n",
            "epoch: [119] loss: 0.059\n",
            "epoch: [120] loss: 0.062\n",
            "epoch: [121] loss: 0.061\n",
            "epoch: [122] loss: 0.061\n",
            "epoch: [123] loss: 0.061\n",
            "epoch: [124] loss: 0.062\n",
            "epoch: [125] loss: 0.061\n",
            "epoch: [126] loss: 0.059\n",
            "epoch: [127] loss: 0.060\n",
            "epoch: [128] loss: 0.062\n",
            "epoch: [129] loss: 0.059\n",
            "epoch: [130] loss: 0.058\n",
            "epoch: [131] loss: 0.062\n",
            "epoch: [132] loss: 0.058\n",
            "epoch: [133] loss: 0.059\n",
            "epoch: [134] loss: 0.060\n",
            "epoch: [135] loss: 0.059\n",
            "epoch: [136] loss: 0.060\n",
            "epoch: [137] loss: 0.060\n",
            "epoch: [138] loss: 0.061\n",
            "epoch: [139] loss: 0.059\n",
            "epoch: [140] loss: 0.061\n",
            "epoch: [141] loss: 0.057\n",
            "epoch: [142] loss: 0.059\n",
            "epoch: [143] loss: 0.059\n",
            "epoch: [144] loss: 0.058\n",
            "epoch: [145] loss: 0.059\n",
            "epoch: [146] loss: 0.060\n",
            "epoch: [147] loss: 0.058\n",
            "epoch: [148] loss: 0.058\n",
            "epoch: [149] loss: 0.059\n",
            "epoch: [150] loss: 0.058\n",
            "epoch: [151] loss: 0.058\n",
            "epoch: [152] loss: 0.059\n",
            "epoch: [153] loss: 0.058\n",
            "epoch: [154] loss: 0.059\n",
            "epoch: [155] loss: 0.058\n",
            "epoch: [156] loss: 0.059\n",
            "epoch: [157] loss: 0.058\n",
            "epoch: [158] loss: 0.059\n",
            "epoch: [159] loss: 0.057\n",
            "epoch: [160] loss: 0.058\n",
            "epoch: [161] loss: 0.058\n",
            "epoch: [162] loss: 0.060\n",
            "epoch: [163] loss: 0.055\n",
            "epoch: [164] loss: 0.060\n",
            "epoch: [165] loss: 0.058\n",
            "epoch: [166] loss: 0.058\n",
            "epoch: [167] loss: 0.055\n",
            "epoch: [168] loss: 0.058\n",
            "epoch: [169] loss: 0.057\n",
            "epoch: [170] loss: 0.057\n",
            "epoch: [171] loss: 0.058\n",
            "epoch: [172] loss: 0.059\n",
            "epoch: [173] loss: 0.058\n",
            "epoch: [174] loss: 0.057\n",
            "epoch: [175] loss: 0.058\n",
            "epoch: [176] loss: 0.057\n",
            "epoch: [177] loss: 0.055\n",
            "epoch: [178] loss: 0.058\n",
            "epoch: [179] loss: 0.058\n",
            "epoch: [180] loss: 0.057\n",
            "epoch: [181] loss: 0.057\n",
            "epoch: [182] loss: 0.057\n",
            "epoch: [183] loss: 0.057\n",
            "epoch: [184] loss: 0.057\n",
            "epoch: [185] loss: 0.058\n",
            "epoch: [186] loss: 0.057\n",
            "epoch: [187] loss: 0.057\n",
            "epoch: [188] loss: 0.058\n",
            "epoch: [189] loss: 0.056\n",
            "epoch: [190] loss: 0.057\n",
            "epoch: [191] loss: 0.056\n",
            "epoch: [192] loss: 0.056\n",
            "epoch: [193] loss: 0.057\n",
            "epoch: [194] loss: 0.057\n",
            "epoch: [195] loss: 0.057\n",
            "epoch: [196] loss: 0.057\n",
            "epoch: [197] loss: 0.056\n",
            "epoch: [198] loss: 0.057\n",
            "epoch: [199] loss: 0.057\n",
            "epoch: [200] loss: 0.056\n",
            "epoch: [201] loss: 0.056\n",
            "epoch: [202] loss: 0.057\n",
            "epoch: [203] loss: 0.056\n",
            "epoch: [204] loss: 0.056\n",
            "epoch: [205] loss: 0.057\n",
            "epoch: [206] loss: 0.057\n",
            "epoch: [207] loss: 0.055\n",
            "epoch: [208] loss: 0.057\n",
            "epoch: [209] loss: 0.057\n",
            "epoch: [210] loss: 0.057\n",
            "epoch: [211] loss: 0.057\n",
            "epoch: [212] loss: 0.056\n",
            "epoch: [213] loss: 0.057\n",
            "epoch: [214] loss: 0.055\n",
            "epoch: [215] loss: 0.056\n",
            "epoch: [216] loss: 0.056\n",
            "epoch: [217] loss: 0.056\n",
            "epoch: [218] loss: 0.055\n",
            "epoch: [219] loss: 0.057\n",
            "epoch: [220] loss: 0.056\n",
            "epoch: [221] loss: 0.055\n",
            "epoch: [222] loss: 0.055\n",
            "epoch: [223] loss: 0.056\n",
            "epoch: [224] loss: 0.056\n",
            "epoch: [225] loss: 0.056\n",
            "epoch: [226] loss: 0.056\n",
            "epoch: [227] loss: 0.056\n",
            "epoch: [228] loss: 0.055\n",
            "epoch: [229] loss: 0.055\n",
            "epoch: [230] loss: 0.056\n",
            "epoch: [231] loss: 0.056\n",
            "epoch: [232] loss: 0.055\n",
            "epoch: [233] loss: 0.056\n",
            "epoch: [234] loss: 0.055\n",
            "epoch: [235] loss: 0.057\n",
            "epoch: [236] loss: 0.055\n",
            "epoch: [237] loss: 0.055\n",
            "epoch: [238] loss: 0.055\n",
            "epoch: [239] loss: 0.055\n",
            "epoch: [240] loss: 0.056\n",
            "epoch: [241] loss: 0.055\n",
            "epoch: [242] loss: 0.055\n",
            "epoch: [243] loss: 0.056\n",
            "epoch: [244] loss: 0.056\n",
            "epoch: [245] loss: 0.054\n",
            "epoch: [246] loss: 0.055\n",
            "epoch: [247] loss: 0.055\n",
            "epoch: [248] loss: 0.056\n",
            "epoch: [249] loss: 0.055\n",
            "epoch: [250] loss: 0.054\n",
            "epoch: [251] loss: 0.056\n",
            "epoch: [252] loss: 0.056\n",
            "epoch: [253] loss: 0.055\n",
            "epoch: [254] loss: 0.053\n",
            "epoch: [255] loss: 0.057\n",
            "epoch: [256] loss: 0.055\n",
            "epoch: [257] loss: 0.055\n",
            "epoch: [258] loss: 0.054\n",
            "epoch: [259] loss: 0.056\n",
            "epoch: [260] loss: 0.054\n",
            "epoch: [261] loss: 0.055\n",
            "epoch: [262] loss: 0.055\n",
            "epoch: [263] loss: 0.054\n",
            "epoch: [264] loss: 0.055\n",
            "epoch: [265] loss: 0.055\n",
            "epoch: [266] loss: 0.055\n",
            "epoch: [267] loss: 0.055\n",
            "epoch: [268] loss: 0.054\n",
            "epoch: [269] loss: 0.054\n",
            "epoch: [270] loss: 0.056\n",
            "epoch: [271] loss: 0.054\n",
            "epoch: [272] loss: 0.053\n",
            "epoch: [273] loss: 0.055\n",
            "epoch: [274] loss: 0.056\n",
            "epoch: [275] loss: 0.053\n",
            "epoch: [276] loss: 0.054\n",
            "epoch: [277] loss: 0.054\n",
            "epoch: [278] loss: 0.055\n",
            "epoch: [279] loss: 0.054\n",
            "epoch: [280] loss: 0.054\n",
            "epoch: [281] loss: 0.055\n",
            "epoch: [282] loss: 0.055\n",
            "epoch: [283] loss: 0.053\n",
            "epoch: [284] loss: 0.056\n",
            "epoch: [285] loss: 0.053\n",
            "epoch: [286] loss: 0.054\n",
            "epoch: [287] loss: 0.055\n",
            "epoch: [288] loss: 0.054\n",
            "epoch: [289] loss: 0.054\n",
            "epoch: [290] loss: 0.054\n",
            "epoch: [291] loss: 0.054\n",
            "epoch: [292] loss: 0.054\n",
            "epoch: [293] loss: 0.054\n",
            "epoch: [294] loss: 0.054\n",
            "epoch: [295] loss: 0.054\n",
            "epoch: [296] loss: 0.055\n",
            "epoch: [297] loss: 0.054\n",
            "epoch: [298] loss: 0.054\n",
            "epoch: [299] loss: 0.053\n",
            "epoch: [300] loss: 0.056\n",
            "epoch: [301] loss: 0.054\n",
            "epoch: [302] loss: 0.052\n",
            "epoch: [303] loss: 0.055\n",
            "epoch: [304] loss: 0.053\n",
            "epoch: [305] loss: 0.054\n",
            "epoch: [306] loss: 0.055\n",
            "epoch: [307] loss: 0.053\n",
            "epoch: [308] loss: 0.054\n",
            "epoch: [309] loss: 0.054\n",
            "epoch: [310] loss: 0.053\n",
            "epoch: [311] loss: 0.053\n",
            "epoch: [312] loss: 0.055\n",
            "epoch: [313] loss: 0.054\n",
            "epoch: [314] loss: 0.053\n",
            "epoch: [315] loss: 0.053\n",
            "epoch: [316] loss: 0.054\n",
            "epoch: [317] loss: 0.054\n",
            "epoch: [318] loss: 0.054\n",
            "epoch: [319] loss: 0.054\n",
            "epoch: [320] loss: 0.054\n",
            "epoch: [321] loss: 0.054\n",
            "epoch: [322] loss: 0.054\n",
            "epoch: [323] loss: 0.054\n",
            "epoch: [324] loss: 0.053\n",
            "epoch: [325] loss: 0.054\n",
            "epoch: [326] loss: 0.054\n",
            "epoch: [327] loss: 0.054\n",
            "epoch: [328] loss: 0.053\n",
            "epoch: [329] loss: 0.053\n",
            "epoch: [330] loss: 0.055\n",
            "epoch: [331] loss: 0.052\n",
            "epoch: [332] loss: 0.054\n",
            "epoch: [333] loss: 0.053\n",
            "epoch: [334] loss: 0.054\n",
            "epoch: [335] loss: 0.053\n",
            "epoch: [336] loss: 0.054\n",
            "epoch: [337] loss: 0.054\n",
            "epoch: [338] loss: 0.054\n",
            "epoch: [339] loss: 0.053\n",
            "epoch: [340] loss: 0.053\n",
            "epoch: [341] loss: 0.054\n",
            "epoch: [342] loss: 0.053\n",
            "epoch: [343] loss: 0.054\n",
            "epoch: [344] loss: 0.054\n",
            "epoch: [345] loss: 0.054\n",
            "epoch: [346] loss: 0.054\n",
            "epoch: [347] loss: 0.053\n",
            "epoch: [348] loss: 0.053\n",
            "epoch: [349] loss: 0.054\n",
            "epoch: [350] loss: 0.053\n",
            "epoch: [351] loss: 0.054\n",
            "epoch: [352] loss: 0.054\n",
            "epoch: [353] loss: 0.052\n",
            "epoch: [354] loss: 0.054\n",
            "epoch: [355] loss: 0.053\n",
            "epoch: [356] loss: 0.054\n",
            "epoch: [357] loss: 0.053\n",
            "epoch: [358] loss: 0.054\n",
            "epoch: [359] loss: 0.053\n",
            "epoch: [360] loss: 0.053\n",
            "epoch: [361] loss: 0.054\n",
            "epoch: [362] loss: 0.053\n",
            "epoch: [363] loss: 0.053\n",
            "epoch: [364] loss: 0.053\n",
            "epoch: [365] loss: 0.053\n",
            "epoch: [366] loss: 0.053\n",
            "epoch: [367] loss: 0.054\n",
            "epoch: [368] loss: 0.053\n",
            "epoch: [369] loss: 0.053\n",
            "epoch: [370] loss: 0.054\n",
            "epoch: [371] loss: 0.052\n",
            "epoch: [372] loss: 0.054\n",
            "epoch: [373] loss: 0.054\n",
            "epoch: [374] loss: 0.052\n",
            "epoch: [375] loss: 0.054\n",
            "epoch: [376] loss: 0.053\n",
            "epoch: [377] loss: 0.052\n",
            "epoch: [378] loss: 0.053\n",
            "epoch: [379] loss: 0.054\n",
            "epoch: [380] loss: 0.053\n",
            "epoch: [381] loss: 0.053\n",
            "epoch: [382] loss: 0.053\n",
            "epoch: [383] loss: 0.053\n",
            "epoch: [384] loss: 0.053\n",
            "epoch: [385] loss: 0.053\n",
            "epoch: [386] loss: 0.053\n",
            "epoch: [387] loss: 0.053\n",
            "epoch: [388] loss: 0.053\n",
            "epoch: [389] loss: 0.053\n",
            "epoch: [390] loss: 0.053\n",
            "epoch: [391] loss: 0.053\n",
            "epoch: [392] loss: 0.053\n",
            "epoch: [393] loss: 0.053\n",
            "epoch: [394] loss: 0.053\n",
            "epoch: [395] loss: 0.053\n",
            "epoch: [396] loss: 0.053\n",
            "epoch: [397] loss: 0.053\n",
            "epoch: [398] loss: 0.054\n",
            "epoch: [399] loss: 0.052\n",
            "epoch: [400] loss: 0.053\n",
            "epoch: [401] loss: 0.053\n",
            "epoch: [402] loss: 0.053\n",
            "epoch: [403] loss: 0.053\n",
            "epoch: [404] loss: 0.052\n",
            "epoch: [405] loss: 0.053\n",
            "epoch: [406] loss: 0.053\n",
            "epoch: [407] loss: 0.053\n",
            "epoch: [408] loss: 0.053\n",
            "epoch: [409] loss: 0.053\n",
            "epoch: [410] loss: 0.052\n",
            "epoch: [411] loss: 0.052\n",
            "epoch: [412] loss: 0.053\n",
            "epoch: [413] loss: 0.053\n",
            "epoch: [414] loss: 0.053\n",
            "epoch: [415] loss: 0.053\n",
            "epoch: [416] loss: 0.051\n",
            "epoch: [417] loss: 0.053\n",
            "epoch: [418] loss: 0.052\n",
            "epoch: [419] loss: 0.052\n",
            "epoch: [420] loss: 0.053\n",
            "epoch: [421] loss: 0.053\n",
            "epoch: [422] loss: 0.053\n",
            "epoch: [423] loss: 0.053\n",
            "epoch: [424] loss: 0.052\n",
            "epoch: [425] loss: 0.053\n",
            "epoch: [426] loss: 0.053\n",
            "epoch: [427] loss: 0.053\n",
            "epoch: [428] loss: 0.052\n",
            "epoch: [429] loss: 0.052\n",
            "epoch: [430] loss: 0.052\n",
            "epoch: [431] loss: 0.053\n",
            "epoch: [432] loss: 0.052\n",
            "epoch: [433] loss: 0.053\n",
            "epoch: [434] loss: 0.053\n",
            "epoch: [435] loss: 0.053\n",
            "epoch: [436] loss: 0.052\n",
            "epoch: [437] loss: 0.053\n",
            "epoch: [438] loss: 0.053\n",
            "epoch: [439] loss: 0.052\n",
            "epoch: [440] loss: 0.053\n",
            "epoch: [441] loss: 0.052\n",
            "epoch: [442] loss: 0.053\n",
            "epoch: [443] loss: 0.052\n",
            "epoch: [444] loss: 0.052\n",
            "epoch: [445] loss: 0.053\n",
            "epoch: [446] loss: 0.053\n",
            "epoch: [447] loss: 0.052\n",
            "epoch: [448] loss: 0.053\n",
            "epoch: [449] loss: 0.052\n",
            "epoch: [450] loss: 0.052\n",
            "epoch: [451] loss: 0.053\n",
            "epoch: [452] loss: 0.050\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 100 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31RVViMkYM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "664fd29f-9d9e-4d2c-dc28-04edadaa3a9b"
      },
      "source": [
        "analysis_data = np.array(analysis_data)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,0],label=\"ftpt\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,1],label=\"ffpt\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,2],label=\"ftpf\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,3],label=\"ffpf\")\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.savefig(\"trends_synthetic_300_300.png\",bbox_inches=\"tight\")\n",
        "plt.savefig(\"trends_synthetic_300_300.pdf\",bbox_inches=\"tight\")\n"
      ],
      "execution_count": 637,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mag3jZ-LMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2b51e2-cb72-4590-c2f7-fffa0c02f615"
      },
      "source": [
        "analysis_data[-1,:2]/3000"
      ],
      "execution_count": 638,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.676, 0.324])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 638
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSxFtBWQ1M8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907f165b-63b7-4798-f5fd-429f90754ca5"
      },
      "source": [
        "running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion,k)\r\n",
        "print(running_loss, anls_data)"
      ],
      "execution_count": 639,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.049593835898486316 [2028, 972, 0, 0, 2602, 398]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncIi9Jc92a4u"
      },
      "source": [
        "what.eval()\r\n",
        "where.eval()\r\n",
        "alphas = []\r\n",
        "max_alpha =[]\r\n",
        "alpha_ftpt=[]\r\n",
        "alpha_ffpt=[]\r\n",
        "alpha_ftpf=[]\r\n",
        "alpha_ffpf=[]\r\n",
        "argmax_more_than_half=0\r\n",
        "argmax_less_than_half=0\r\n",
        "cnt =0\r\n",
        "with torch.no_grad():\r\n",
        "  for i, data in enumerate(train_loader, 0):\r\n",
        "    inputs, labels, fidx = data\r\n",
        "    inputs = inputs.double()\r\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\r\n",
        "    avg, alphas = where(inputs)\r\n",
        "    outputs = what(avg)\r\n",
        "    _, predicted = torch.max(outputs.data, 1)\r\n",
        "    batch = len(predicted)\r\n",
        "    mx,_ = torch.max(alphas,1)\r\n",
        "    max_alpha.append(mx.cpu().detach().numpy())\r\n",
        "    for j in range (batch):\r\n",
        "      cnt+=1\r\n",
        "      focus = torch.argmax(alphas[j]).item()\r\n",
        "      if alphas[j][focus] >= 0.5 :\r\n",
        "        argmax_more_than_half += 1\r\n",
        "      else:\r\n",
        "        argmax_less_than_half += 1\r\n",
        "\r\n",
        "      if (focus == fidx[j].item() and predicted[j].item() == labels[j].item()):\r\n",
        "          alpha_ftpt.append(alphas[j][focus].item())\r\n",
        "          # print(focus, fore_idx[j].item(), predicted[j].item() , labels[j].item() )\r\n",
        "\r\n",
        "      elif (focus != fidx[j].item() and predicted[j].item() == labels[j].item()):\r\n",
        "          alpha_ffpt.append(alphas[j][focus].item())\r\n",
        "\r\n",
        "      elif (focus == fidx[j].item() and predicted[j].item() != labels[j].item()):\r\n",
        "          alpha_ftpf.append(alphas[j][focus].item())\r\n",
        "\r\n",
        "      elif (focus != fidx[j].item() and predicted[j].item() != labels[j].item()):\r\n",
        "          alpha_ffpf.append(alphas[j][focus].item())\r\n"
      ],
      "execution_count": 640,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_3nbXu5Zw34",
        "outputId": "fd5f936c-6aa5-4d9e-ccbb-78e56671ecbf"
      },
      "source": [
        "np.sum(entropy(alphas.cpu().numpy(), base=2, axis=1))/batch"
      ],
      "execution_count": 641,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5316495139709819"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 641
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7vDw6cn1q9M",
        "outputId": "76f80c1d-9689-4107-a682-aad34c66c90d"
      },
      "source": [
        "np.mean(-np.log2(mx.cpu().detach().numpy()))"
      ],
      "execution_count": 642,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38396014388910366"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 642
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc43myxx2yGI"
      },
      "source": [
        "a = np.array([[0.1,0.9], [0.5, 0.5]])"
      ],
      "execution_count": 643,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUdhdSpB23BL",
        "outputId": "96aa5cd0-86b0-4855-9b5b-acec410e032b"
      },
      "source": [
        "-0.1*np.log2(0.1)-0.9*np.log2(0.9)"
      ],
      "execution_count": 644,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4689955935892812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 644
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9AKu9cRW7Z5",
        "outputId": "abcd7f5d-630d-4b08-b3b7-880cb012f38f"
      },
      "source": [
        "entropy([9/10, 1/10], base=2), entropy([0.5, 0.5], base=2), entropy(a, base=2, axis=1)"
      ],
      "execution_count": 645,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.46899559358928117, 1.0, array([0.46899559, 1.        ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 645
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyEk81R43gPZ",
        "outputId": "a99c2882-7ace-4c37-9da1-b88e869735c8"
      },
      "source": [
        "np.mean(-np.log2(a))"
      ],
      "execution_count": 646,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.368482797083103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 646
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPE_6NQd3VHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58947602-00a2-4003-c82e-4ed025df96fb"
      },
      "source": [
        "max_alpha = np.concatenate(max_alpha,axis=0)\r\n",
        "print(max_alpha.shape, cnt)"
      ],
      "execution_count": 647,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000,) 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvgu92LY3Zke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd811cb-485d-45fc-9f35-343656380659"
      },
      "source": [
        "np.array(alpha_ftpt).size, np.array(alpha_ffpt).size, np.array(alpha_ftpf).size, np.array(alpha_ffpf).size"
      ],
      "execution_count": 648,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2028, 972, 0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 648
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XtgiDDpZ8qH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "ac59e884-a8ca-4658-8a2a-bec822dc81e1"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(max_alpha,bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values histogram\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 649,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uTx4G6PeOgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "02712dee-c8e6-4c02-93e8-36de063eebed"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(np.array(alpha_ftpt),bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values in ftpt\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 650,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2Nn1IneTkT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "42f2cd1d-c7e5-4623-fef1-d39fb49f8469"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(np.array(alpha_ffpt),bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values in ffpt\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 651,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}