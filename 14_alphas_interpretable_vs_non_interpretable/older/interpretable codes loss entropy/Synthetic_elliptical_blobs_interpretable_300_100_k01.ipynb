{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Synthetic_elliptical_blobs_interpretable_300_100_k01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYu3ISwwGks"
      },
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.stats import entropy"
      ],
      "execution_count": 580,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEp-LtqiWAf"
      },
      "source": [
        "mu1 = np.array([3,3,3,3,0])\n",
        "sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu2 = np.array([4,4,4,4,0])\n",
        "sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu3 = np.array([10,5,5,10,0])\n",
        "sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu4 = np.array([-10,-10,-10,-10,0])\n",
        "sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu5 = np.array([-21,4,4,-21,0])\n",
        "sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu6 = np.array([-10,18,18,-10,0])\n",
        "sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu7 = np.array([4,20,4,20,0])\n",
        "sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu8 = np.array([4,-20,-20,4,0])\n",
        "sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu9 = np.array([20,20,20,20,0])\n",
        "sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu10 = np.array([20,-10,-10,20,0])\n",
        "sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)\n"
      ],
      "execution_count": 581,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NshDNGjY2T3w"
      },
      "source": [
        "# mu1 = np.array([3,3,0,0,0])\n",
        "# sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu2 = np.array([4,4,0,0,0])\n",
        "# sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu3 = np.array([10,5,0,0,0])\n",
        "# sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu4 = np.array([-10,-10,0,0,0])\n",
        "# sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu5 = np.array([-21,4,0,0,0])\n",
        "# sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu6 = np.array([-10,18,0,0,0])\n",
        "# sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu7 = np.array([4,20,0,0,0])\n",
        "# sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu8 = np.array([4,-20,0,0,0])\n",
        "# sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu9 = np.array([20,20,0,0,0])\n",
        "# sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu10 = np.array([20,-10,0,0,0])\n",
        "# sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "# sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "# sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "# sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "# sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "# sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "# sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "# sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "# sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "# sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "# sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)"
      ],
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YDnxeP-2_1V",
        "outputId": "cd9b3e36-1511-4bac-f154-c536b89d714f"
      },
      "source": [
        "X = np.concatenate((sample1,sample2,sample3,sample4,sample5,sample6,sample7,sample8,sample9,sample10),axis=0)\n",
        "Y = np.concatenate((np.zeros((500,1)),np.ones((500,1)),2*np.ones((500,1)),3*np.ones((500,1)),4*np.ones((500,1)),\n",
        "                    5*np.ones((500,1)),6*np.ones((500,1)),7*np.ones((500,1)),8*np.ones((500,1)),9*np.ones((500,1))),axis=0).astype(int)\n",
        "print(X.shape,Y.shape)\n",
        "# plt.scatter(sample1[:,0],sample1[:,1],label=\"class_0\")\n",
        "# plt.scatter(sample2[:,0],sample2[:,1],label=\"class_1\")\n",
        "# plt.scatter(sample3[:,0],sample3[:,1],label=\"class_2\")\n",
        "# plt.scatter(sample4[:,0],sample4[:,1],label=\"class_3\")\n",
        "# plt.scatter(sample5[:,0],sample5[:,1],label=\"class_4\")\n",
        "# plt.scatter(sample6[:,0],sample6[:,1],label=\"class_5\")\n",
        "# plt.scatter(sample7[:,0],sample7[:,1],label=\"class_6\")\n",
        "# plt.scatter(sample8[:,0],sample8[:,1],label=\"class_7\")\n",
        "# plt.scatter(sample9[:,0],sample9[:,1],label=\"class_8\")\n",
        "# plt.scatter(sample10[:,0],sample10[:,1],label=\"class_9\")\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
      ],
      "execution_count": 583,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 5) (5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YzqPUf3CHa"
      },
      "source": [
        "class SyntheticDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    #self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx] , self.y[idx] #, self.fore_idx[idx]"
      ],
      "execution_count": 584,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mi3nL5-4D7_"
      },
      "source": [
        "trainset = SyntheticDataset(X,Y)\n",
        "\n",
        "\n",
        "# testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKzc7IgwqoU2",
        "outputId": "c6f9b84c-0c0a-4f20-cd03-d571dbf0cac7"
      },
      "source": [
        "classes = ('zero','one','two','three','four','five','six','seven','eight','nine')\n",
        "\n",
        "foreground_classes = {'zero','one','two'}\n",
        "fg_used = '012'\n",
        "fg1, fg2, fg3 = 0,1,2\n",
        "\n",
        "\n",
        "all_classes = {'zero','one','two','three','four','five','six','seven','eight','nine'}\n",
        "background_classes = all_classes - foreground_classes\n",
        "background_classes"
      ],
      "execution_count": 586,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eight', 'five', 'four', 'nine', 'seven', 'six', 'three'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 586
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT6iKHutquR8"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)"
      ],
      "execution_count": 587,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKzXkPSq5KU"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=100\n",
        "\n",
        "for i in range(50):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 588,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChdziOP3rF1G"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])\n",
        "      label = foreground_label[fg_idx] - fg1  # minus fg1 because our fore ground classes are fg1,fg2,fg3 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASrmPqErIDM"
      },
      "source": [
        "desired_num = 3000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "list_set_labels = [] \n",
        "for i in range(desired_num):\n",
        "  set_idx = set()\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,3500,8)\n",
        "  set_idx = set(background_label[bg_idx].tolist())\n",
        "  fg_idx = np.random.randint(0,1500)\n",
        "  set_idx.add(foreground_label[fg_idx].item())\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)\n",
        "  list_set_labels.append(set_idx)"
      ],
      "execution_count": 590,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDFN7dCarmmR"
      },
      "source": [
        "def create_avg_image_from_mosaic_dataset(mosaic_dataset,labels,foreground_index,dataset_number):\n",
        "  \"\"\"\n",
        "  mosaic_dataset : mosaic_dataset contains 9 images 32 x 32 each as 1 data point\n",
        "  labels : mosaic_dataset labels\n",
        "  foreground_index : contains list of indexes where foreground image is present so that using this we can take weighted average\n",
        "  dataset_number : will help us to tell what ratio of foreground image to be taken. for eg: if it is \"j\" then fg_image_ratio = j/9 , bg_image_ratio = (9-j)/8*9\n",
        "  \"\"\"\n",
        "  avg_image_dataset = []\n",
        "  for i in range(len(mosaic_dataset)):\n",
        "    img = torch.zeros([5], dtype=torch.float64)\n",
        "    for j in range(9):\n",
        "      if j == foreground_index[i]:\n",
        "        img = img + mosaic_dataset[i][j]*dataset_number/9\n",
        "      else :\n",
        "        img = img + mosaic_dataset[i][j]*(9-dataset_number)/(8*9)\n",
        "    \n",
        "    avg_image_dataset.append(img)\n",
        "    \n",
        "  return torch.stack(avg_image_dataset) , torch.stack(labels) , foreground_index"
      ],
      "execution_count": 591,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgF90qBIt8yN"
      },
      "source": [
        "def calculate_loss(dataloader,model,criter):\n",
        "  model.eval()\n",
        "  r_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      outputs = model(inputs)\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  return r_loss/i"
      ],
      "execution_count": 592,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGsdvMSzIUK"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 593,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5NPRPmb904"
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 594,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzPfrih82Bg"
      },
      "source": [
        "**Focus Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN3Bbs8c0fA"
      },
      "source": [
        "class Focus_deep(nn.Module):\n",
        "    '''\n",
        "       deep focus network averaged at zeroth layer\n",
        "       input : elemental data\n",
        "    '''\n",
        "    def __init__(self,inputs,output,K,d):\n",
        "        super(Focus_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.K = K\n",
        "        self.d  = d\n",
        "        self.linear1 = nn.Linear(self.inputs,300)  #,self.output)\n",
        "        self.linear2 = nn.Linear(300,self.output) \n",
        "    def forward(self,z):\n",
        "        batch = z.shape[0]\n",
        "        x = torch.zeros([batch,self.K],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,self.d], dtype=torch.float64)\n",
        "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        for i in range(self.K):\n",
        "            x[:,i] = self.helper(z[:,i] )[:,0]  # self.d*i:self.d*i+self.d\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(self.K):\n",
        "            x1 = x[:,i]          \n",
        "            y = y+torch.mul(x1[:,None],z[:,i])  # self.d*i:self.d*i+self.d\n",
        "        return y , x \n",
        "    def helper(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x\n"
      ],
      "execution_count": 595,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjrL0Zb484KO"
      },
      "source": [
        "**Classification Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W0oKcClFZY"
      },
      "source": [
        "class Classification_deep(nn.Module):\n",
        "    '''\n",
        "       input : elemental data\n",
        "       deep classification module data averaged at zeroth layer\n",
        "    '''\n",
        "    def __init__(self,inputs,output):\n",
        "        super(Classification_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.linear1 = nn.Linear(self.inputs,100)\n",
        "        self.linear2 = nn.Linear(100,self.output)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x    "
      ],
      "execution_count": 596,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByKHrKis88lW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAPjSKkrd0ru"
      },
      "source": [
        "where = Focus_deep(5,1,9,5).double()\n",
        "what = Classification_deep(5,3).double()\n",
        "where = where.to(\"cuda\")\n",
        "what = what.to(\"cuda\")"
      ],
      "execution_count": 597,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAfQnNwgFYX"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,where,criter,k):\n",
        "  what.eval()\n",
        "  where.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels, fidx = data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      avg,alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "\n",
        "      ent = np.sum(entropy(alpha.cpu().detach().numpy(), base=2, axis=1))/batch\n",
        "      # mx,_ = torch.max(alpha,1)\n",
        "      # entropy = np.mean(-np.log2(mx.cpu().detach().numpy()))\n",
        "      # print(\"entropy of batch\", entropy)\n",
        "\n",
        "      loss = criter(outputs, labels) + k*ent\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis"
      ],
      "execution_count": 598,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9HQJMzxBhp"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 599,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOfxUJZ_eFKw",
        "outputId": "2cf78511-4d28-42ff-c413-c25c71b7fea3"
      },
      "source": [
        "print(\"--\"*40)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_where = optim.Adam(where.parameters(),lr =0.001)\n",
        "optimizer_what = optim.Adam(what.parameters(), lr=0.001)\n",
        "acti = []\n",
        "loss_curi = []\n",
        "analysis_data = []\n",
        "epochs = 1000\n",
        "k=0.1\n",
        "running_loss,anlys_data = calculate_attn_loss(train_loader,what,where,criterion,k)\n",
        "loss_curi.append(running_loss)\n",
        "analysis_data.append(anlys_data)\n",
        "print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what.train()\n",
        "  where.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_ = data\n",
        "    inputs = inputs.double()\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    optimizer_where.zero_grad()\n",
        "    optimizer_what.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    avg, alpha = where(inputs)\n",
        "    outputs = what(avg)\n",
        "\n",
        "    ent = np.sum(entropy(alpha.cpu().detach().numpy(), base=2, axis=1))/batch #entropy(alpha.cpu().numpy(), base=2, axis=1)\n",
        "    # mx,_ = torch.max(alpha,1)\n",
        "    # entropy = np.mean(-np.log2(mx.cpu().detach().numpy()))\n",
        "    # print(\"entropy of batch\", entropy)\n",
        "    \n",
        "    loss = criterion(outputs, labels) + k*ent\n",
        "\n",
        "    # loss = criterion(outputs, labels)\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer_where.step()\n",
        "    optimizer_what.step()\n",
        "\n",
        "  running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion,k)\n",
        "  analysis_data.append(anls_data)\n",
        "  print('epoch: [%d] loss: %.3f' %(epoch + 1,running_loss)) \n",
        "  loss_curi.append(running_loss)   #loss per epoch\n",
        "  if running_loss<=0.05:\n",
        "    break\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels,_ = data\n",
        "    images = images.double()\n",
        "    images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    avg, alpha = where(images)\n",
        "    outputs  = what(avg)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    "
      ],
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 2.640\n",
            "epoch: [1] loss: 1.618\n",
            "epoch: [2] loss: 1.538\n",
            "epoch: [3] loss: 1.493\n",
            "epoch: [4] loss: 1.483\n",
            "epoch: [5] loss: 1.447\n",
            "epoch: [6] loss: 1.372\n",
            "epoch: [7] loss: 1.139\n",
            "epoch: [8] loss: 0.957\n",
            "epoch: [9] loss: 0.832\n",
            "epoch: [10] loss: 0.728\n",
            "epoch: [11] loss: 0.654\n",
            "epoch: [12] loss: 0.605\n",
            "epoch: [13] loss: 0.560\n",
            "epoch: [14] loss: 0.523\n",
            "epoch: [15] loss: 0.493\n",
            "epoch: [16] loss: 0.460\n",
            "epoch: [17] loss: 0.435\n",
            "epoch: [18] loss: 0.408\n",
            "epoch: [19] loss: 0.388\n",
            "epoch: [20] loss: 0.363\n",
            "epoch: [21] loss: 0.344\n",
            "epoch: [22] loss: 0.324\n",
            "epoch: [23] loss: 0.312\n",
            "epoch: [24] loss: 0.292\n",
            "epoch: [25] loss: 0.283\n",
            "epoch: [26] loss: 0.265\n",
            "epoch: [27] loss: 0.255\n",
            "epoch: [28] loss: 0.242\n",
            "epoch: [29] loss: 0.236\n",
            "epoch: [30] loss: 0.229\n",
            "epoch: [31] loss: 0.217\n",
            "epoch: [32] loss: 0.210\n",
            "epoch: [33] loss: 0.200\n",
            "epoch: [34] loss: 0.194\n",
            "epoch: [35] loss: 0.191\n",
            "epoch: [36] loss: 0.184\n",
            "epoch: [37] loss: 0.178\n",
            "epoch: [38] loss: 0.174\n",
            "epoch: [39] loss: 0.167\n",
            "epoch: [40] loss: 0.165\n",
            "epoch: [41] loss: 0.159\n",
            "epoch: [42] loss: 0.156\n",
            "epoch: [43] loss: 0.153\n",
            "epoch: [44] loss: 0.146\n",
            "epoch: [45] loss: 0.140\n",
            "epoch: [46] loss: 0.139\n",
            "epoch: [47] loss: 0.134\n",
            "epoch: [48] loss: 0.132\n",
            "epoch: [49] loss: 0.130\n",
            "epoch: [50] loss: 0.126\n",
            "epoch: [51] loss: 0.123\n",
            "epoch: [52] loss: 0.121\n",
            "epoch: [53] loss: 0.117\n",
            "epoch: [54] loss: 0.115\n",
            "epoch: [55] loss: 0.114\n",
            "epoch: [56] loss: 0.111\n",
            "epoch: [57] loss: 0.109\n",
            "epoch: [58] loss: 0.108\n",
            "epoch: [59] loss: 0.105\n",
            "epoch: [60] loss: 0.104\n",
            "epoch: [61] loss: 0.102\n",
            "epoch: [62] loss: 0.100\n",
            "epoch: [63] loss: 0.099\n",
            "epoch: [64] loss: 0.096\n",
            "epoch: [65] loss: 0.095\n",
            "epoch: [66] loss: 0.094\n",
            "epoch: [67] loss: 0.093\n",
            "epoch: [68] loss: 0.092\n",
            "epoch: [69] loss: 0.089\n",
            "epoch: [70] loss: 0.089\n",
            "epoch: [71] loss: 0.087\n",
            "epoch: [72] loss: 0.086\n",
            "epoch: [73] loss: 0.085\n",
            "epoch: [74] loss: 0.084\n",
            "epoch: [75] loss: 0.083\n",
            "epoch: [76] loss: 0.081\n",
            "epoch: [77] loss: 0.081\n",
            "epoch: [78] loss: 0.079\n",
            "epoch: [79] loss: 0.079\n",
            "epoch: [80] loss: 0.077\n",
            "epoch: [81] loss: 0.077\n",
            "epoch: [82] loss: 0.076\n",
            "epoch: [83] loss: 0.075\n",
            "epoch: [84] loss: 0.075\n",
            "epoch: [85] loss: 0.075\n",
            "epoch: [86] loss: 0.072\n",
            "epoch: [87] loss: 0.073\n",
            "epoch: [88] loss: 0.072\n",
            "epoch: [89] loss: 0.070\n",
            "epoch: [90] loss: 0.070\n",
            "epoch: [91] loss: 0.070\n",
            "epoch: [92] loss: 0.070\n",
            "epoch: [93] loss: 0.069\n",
            "epoch: [94] loss: 0.067\n",
            "epoch: [95] loss: 0.069\n",
            "epoch: [96] loss: 0.068\n",
            "epoch: [97] loss: 0.068\n",
            "epoch: [98] loss: 0.068\n",
            "epoch: [99] loss: 0.068\n",
            "epoch: [100] loss: 0.069\n",
            "epoch: [101] loss: 0.069\n",
            "epoch: [102] loss: 0.070\n",
            "epoch: [103] loss: 0.070\n",
            "epoch: [104] loss: 0.071\n",
            "epoch: [105] loss: 0.071\n",
            "epoch: [106] loss: 0.071\n",
            "epoch: [107] loss: 0.072\n",
            "epoch: [108] loss: 0.072\n",
            "epoch: [109] loss: 0.072\n",
            "epoch: [110] loss: 0.072\n",
            "epoch: [111] loss: 0.072\n",
            "epoch: [112] loss: 0.072\n",
            "epoch: [113] loss: 0.073\n",
            "epoch: [114] loss: 0.072\n",
            "epoch: [115] loss: 0.072\n",
            "epoch: [116] loss: 0.072\n",
            "epoch: [117] loss: 0.071\n",
            "epoch: [118] loss: 0.071\n",
            "epoch: [119] loss: 0.071\n",
            "epoch: [120] loss: 0.070\n",
            "epoch: [121] loss: 0.069\n",
            "epoch: [122] loss: 0.070\n",
            "epoch: [123] loss: 0.069\n",
            "epoch: [124] loss: 0.070\n",
            "epoch: [125] loss: 0.069\n",
            "epoch: [126] loss: 0.070\n",
            "epoch: [127] loss: 0.069\n",
            "epoch: [128] loss: 0.068\n",
            "epoch: [129] loss: 0.068\n",
            "epoch: [130] loss: 0.067\n",
            "epoch: [131] loss: 0.067\n",
            "epoch: [132] loss: 0.068\n",
            "epoch: [133] loss: 0.067\n",
            "epoch: [134] loss: 0.066\n",
            "epoch: [135] loss: 0.067\n",
            "epoch: [136] loss: 0.067\n",
            "epoch: [137] loss: 0.066\n",
            "epoch: [138] loss: 0.066\n",
            "epoch: [139] loss: 0.064\n",
            "epoch: [140] loss: 0.065\n",
            "epoch: [141] loss: 0.067\n",
            "epoch: [142] loss: 0.064\n",
            "epoch: [143] loss: 0.066\n",
            "epoch: [144] loss: 0.063\n",
            "epoch: [145] loss: 0.064\n",
            "epoch: [146] loss: 0.065\n",
            "epoch: [147] loss: 0.063\n",
            "epoch: [148] loss: 0.065\n",
            "epoch: [149] loss: 0.061\n",
            "epoch: [150] loss: 0.064\n",
            "epoch: [151] loss: 0.064\n",
            "epoch: [152] loss: 0.062\n",
            "epoch: [153] loss: 0.063\n",
            "epoch: [154] loss: 0.063\n",
            "epoch: [155] loss: 0.063\n",
            "epoch: [156] loss: 0.062\n",
            "epoch: [157] loss: 0.062\n",
            "epoch: [158] loss: 0.063\n",
            "epoch: [159] loss: 0.062\n",
            "epoch: [160] loss: 0.062\n",
            "epoch: [161] loss: 0.063\n",
            "epoch: [162] loss: 0.063\n",
            "epoch: [163] loss: 0.063\n",
            "epoch: [164] loss: 0.062\n",
            "epoch: [165] loss: 0.061\n",
            "epoch: [166] loss: 0.061\n",
            "epoch: [167] loss: 0.062\n",
            "epoch: [168] loss: 0.061\n",
            "epoch: [169] loss: 0.061\n",
            "epoch: [170] loss: 0.056\n",
            "epoch: [171] loss: 0.059\n",
            "epoch: [172] loss: 0.065\n",
            "epoch: [173] loss: 0.062\n",
            "epoch: [174] loss: 0.061\n",
            "epoch: [175] loss: 0.061\n",
            "epoch: [176] loss: 0.060\n",
            "epoch: [177] loss: 0.059\n",
            "epoch: [178] loss: 0.059\n",
            "epoch: [179] loss: 0.061\n",
            "epoch: [180] loss: 0.059\n",
            "epoch: [181] loss: 0.061\n",
            "epoch: [182] loss: 0.060\n",
            "epoch: [183] loss: 0.060\n",
            "epoch: [184] loss: 0.060\n",
            "epoch: [185] loss: 0.060\n",
            "epoch: [186] loss: 0.059\n",
            "epoch: [187] loss: 0.059\n",
            "epoch: [188] loss: 0.060\n",
            "epoch: [189] loss: 0.060\n",
            "epoch: [190] loss: 0.060\n",
            "epoch: [191] loss: 0.059\n",
            "epoch: [192] loss: 0.060\n",
            "epoch: [193] loss: 0.058\n",
            "epoch: [194] loss: 0.060\n",
            "epoch: [195] loss: 0.059\n",
            "epoch: [196] loss: 0.060\n",
            "epoch: [197] loss: 0.059\n",
            "epoch: [198] loss: 0.059\n",
            "epoch: [199] loss: 0.056\n",
            "epoch: [200] loss: 0.059\n",
            "epoch: [201] loss: 0.058\n",
            "epoch: [202] loss: 0.060\n",
            "epoch: [203] loss: 0.059\n",
            "epoch: [204] loss: 0.059\n",
            "epoch: [205] loss: 0.059\n",
            "epoch: [206] loss: 0.057\n",
            "epoch: [207] loss: 0.059\n",
            "epoch: [208] loss: 0.059\n",
            "epoch: [209] loss: 0.057\n",
            "epoch: [210] loss: 0.059\n",
            "epoch: [211] loss: 0.056\n",
            "epoch: [212] loss: 0.059\n",
            "epoch: [213] loss: 0.057\n",
            "epoch: [214] loss: 0.060\n",
            "epoch: [215] loss: 0.058\n",
            "epoch: [216] loss: 0.059\n",
            "epoch: [217] loss: 0.058\n",
            "epoch: [218] loss: 0.059\n",
            "epoch: [219] loss: 0.057\n",
            "epoch: [220] loss: 0.057\n",
            "epoch: [221] loss: 0.059\n",
            "epoch: [222] loss: 0.057\n",
            "epoch: [223] loss: 0.059\n",
            "epoch: [224] loss: 0.058\n",
            "epoch: [225] loss: 0.056\n",
            "epoch: [226] loss: 0.059\n",
            "epoch: [227] loss: 0.052\n",
            "epoch: [228] loss: 0.059\n",
            "epoch: [229] loss: 0.053\n",
            "epoch: [230] loss: 0.053\n",
            "epoch: [231] loss: 0.058\n",
            "epoch: [232] loss: 0.056\n",
            "epoch: [233] loss: 0.056\n",
            "epoch: [234] loss: 0.056\n",
            "epoch: [235] loss: 0.056\n",
            "epoch: [236] loss: 0.056\n",
            "epoch: [237] loss: 0.055\n",
            "epoch: [238] loss: 0.057\n",
            "epoch: [239] loss: 0.056\n",
            "epoch: [240] loss: 0.056\n",
            "epoch: [241] loss: 0.057\n",
            "epoch: [242] loss: 0.057\n",
            "epoch: [243] loss: 0.058\n",
            "epoch: [244] loss: 0.057\n",
            "epoch: [245] loss: 0.057\n",
            "epoch: [246] loss: 0.057\n",
            "epoch: [247] loss: 0.058\n",
            "epoch: [248] loss: 0.053\n",
            "epoch: [249] loss: 0.062\n",
            "epoch: [250] loss: 0.055\n",
            "epoch: [251] loss: 0.061\n",
            "epoch: [252] loss: 0.056\n",
            "epoch: [253] loss: 0.055\n",
            "epoch: [254] loss: 0.057\n",
            "epoch: [255] loss: 0.055\n",
            "epoch: [256] loss: 0.055\n",
            "epoch: [257] loss: 0.056\n",
            "epoch: [258] loss: 0.055\n",
            "epoch: [259] loss: 0.056\n",
            "epoch: [260] loss: 0.055\n",
            "epoch: [261] loss: 0.056\n",
            "epoch: [262] loss: 0.056\n",
            "epoch: [263] loss: 0.056\n",
            "epoch: [264] loss: 0.056\n",
            "epoch: [265] loss: 0.056\n",
            "epoch: [266] loss: 0.057\n",
            "epoch: [267] loss: 0.056\n",
            "epoch: [268] loss: 0.059\n",
            "epoch: [269] loss: 0.052\n",
            "epoch: [270] loss: 0.058\n",
            "epoch: [271] loss: 0.055\n",
            "epoch: [272] loss: 0.058\n",
            "epoch: [273] loss: 0.057\n",
            "epoch: [274] loss: 0.056\n",
            "epoch: [275] loss: 0.057\n",
            "epoch: [276] loss: 0.057\n",
            "epoch: [277] loss: 0.057\n",
            "epoch: [278] loss: 0.057\n",
            "epoch: [279] loss: 0.056\n",
            "epoch: [280] loss: 0.057\n",
            "epoch: [281] loss: 0.057\n",
            "epoch: [282] loss: 0.055\n",
            "epoch: [283] loss: 0.057\n",
            "epoch: [284] loss: 0.056\n",
            "epoch: [285] loss: 0.057\n",
            "epoch: [286] loss: 0.058\n",
            "epoch: [287] loss: 0.056\n",
            "epoch: [288] loss: 0.058\n",
            "epoch: [289] loss: 0.057\n",
            "epoch: [290] loss: 0.057\n",
            "epoch: [291] loss: 0.058\n",
            "epoch: [292] loss: 0.057\n",
            "epoch: [293] loss: 0.057\n",
            "epoch: [294] loss: 0.057\n",
            "epoch: [295] loss: 0.056\n",
            "epoch: [296] loss: 0.058\n",
            "epoch: [297] loss: 0.056\n",
            "epoch: [298] loss: 0.061\n",
            "epoch: [299] loss: 0.025\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 100 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31RVViMkYM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9339ed85-75a0-4f90-8a84-eddbadafba9a"
      },
      "source": [
        "analysis_data = np.array(analysis_data)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,0],label=\"ftpt\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,1],label=\"ffpt\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,2],label=\"ftpf\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,3],label=\"ffpf\")\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.savefig(\"trends_synthetic_300_300.png\",bbox_inches=\"tight\")\n",
        "plt.savefig(\"trends_synthetic_300_300.pdf\",bbox_inches=\"tight\")\n"
      ],
      "execution_count": 601,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mag3jZ-LMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7772258-797b-4d1c-e21d-6c3ceb2913bd"
      },
      "source": [
        "analysis_data[-1,:2]/3000"
      ],
      "execution_count": 602,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 602
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSxFtBWQ1M8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54eac30-c10e-4f32-896b-033afbc787dd"
      },
      "source": [
        "running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion,k)\r\n",
        "print(running_loss, anls_data)"
      ],
      "execution_count": 603,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.024956435488334896 [3000, 0, 0, 0, 2998, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncIi9Jc92a4u"
      },
      "source": [
        "what.eval()\r\n",
        "where.eval()\r\n",
        "alphas = []\r\n",
        "max_alpha =[]\r\n",
        "alpha_ftpt=[]\r\n",
        "alpha_ffpt=[]\r\n",
        "alpha_ftpf=[]\r\n",
        "alpha_ffpf=[]\r\n",
        "argmax_more_than_half=0\r\n",
        "argmax_less_than_half=0\r\n",
        "cnt =0\r\n",
        "with torch.no_grad():\r\n",
        "  for i, data in enumerate(train_loader, 0):\r\n",
        "    inputs, labels, fidx = data\r\n",
        "    inputs = inputs.double()\r\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\r\n",
        "    avg, alphas = where(inputs)\r\n",
        "    outputs = what(avg)\r\n",
        "    _, predicted = torch.max(outputs.data, 1)\r\n",
        "    batch = len(predicted)\r\n",
        "    mx,_ = torch.max(alphas,1)\r\n",
        "    max_alpha.append(mx.cpu().detach().numpy())\r\n",
        "    for j in range (batch):\r\n",
        "      cnt+=1\r\n",
        "      focus = torch.argmax(alphas[j]).item()\r\n",
        "      if alphas[j][focus] >= 0.5 :\r\n",
        "        argmax_more_than_half += 1\r\n",
        "      else:\r\n",
        "        argmax_less_than_half += 1\r\n",
        "\r\n",
        "      if (focus == fidx[j].item() and predicted[j].item() == labels[j].item()):\r\n",
        "          alpha_ftpt.append(alphas[j][focus].item())\r\n",
        "          # print(focus, fore_idx[j].item(), predicted[j].item() , labels[j].item() )\r\n",
        "\r\n",
        "      elif (focus != fidx[j].item() and predicted[j].item() == labels[j].item()):\r\n",
        "          alpha_ffpt.append(alphas[j][focus].item())\r\n",
        "\r\n",
        "      elif (focus == fidx[j].item() and predicted[j].item() != labels[j].item()):\r\n",
        "          alpha_ftpf.append(alphas[j][focus].item())\r\n",
        "\r\n",
        "      elif (focus != fidx[j].item() and predicted[j].item() != labels[j].item()):\r\n",
        "          alpha_ffpf.append(alphas[j][focus].item())\r\n"
      ],
      "execution_count": 604,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_3nbXu5Zw34",
        "outputId": "260cb8ac-a751-4ef0-9c1f-4cf94bf221c2"
      },
      "source": [
        "np.sum(entropy(alphas.cpu().numpy(), base=2, axis=1))/batch"
      ],
      "execution_count": 605,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1783444055115979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 605
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7vDw6cn1q9M",
        "outputId": "56ae0b7c-42b1-4e87-837a-dc1ccff09aac"
      },
      "source": [
        "np.mean(-np.log2(mx.cpu().detach().numpy()))"
      ],
      "execution_count": 606,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06209113714475355"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 606
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc43myxx2yGI"
      },
      "source": [
        "a = np.array([[0.1,0.9], [0.5, 0.5]])"
      ],
      "execution_count": 607,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUdhdSpB23BL",
        "outputId": "75b0e3b9-4bb3-4153-ef8f-2ba2c82e0691"
      },
      "source": [
        "-0.1*np.log2(0.1)-0.9*np.log2(0.9)"
      ],
      "execution_count": 608,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4689955935892812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 608
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9AKu9cRW7Z5",
        "outputId": "2ceeb50d-d02f-47f1-8ba1-7d8e76523e82"
      },
      "source": [
        "entropy([9/10, 1/10], base=2), entropy([0.5, 0.5], base=2), entropy(a, base=2, axis=1)"
      ],
      "execution_count": 609,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.46899559358928117, 1.0, array([0.46899559, 1.        ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 609
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyEk81R43gPZ",
        "outputId": "663e4ba5-eb6b-4b28-bb9c-9b35aee059e3"
      },
      "source": [
        "np.mean(-np.log2(a))"
      ],
      "execution_count": 610,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.368482797083103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 610
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPE_6NQd3VHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6e55c4-d9c6-4ecd-de42-188390dfebde"
      },
      "source": [
        "max_alpha = np.concatenate(max_alpha,axis=0)\r\n",
        "print(max_alpha.shape, cnt)"
      ],
      "execution_count": 611,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000,) 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvgu92LY3Zke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db34c0cd-93dd-4ac0-98e1-70e04a26282f"
      },
      "source": [
        "np.array(alpha_ftpt).size, np.array(alpha_ffpt).size, np.array(alpha_ftpf).size, np.array(alpha_ffpf).size"
      ],
      "execution_count": 612,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0, 0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 612
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XtgiDDpZ8qH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "6d8457e3-e93d-4782-bf36-d5cffec0f668"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(max_alpha,bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values histogram\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 613,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uTx4G6PeOgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "9abf6090-c706-47d4-8bcc-a1ea03d5fc10"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(np.array(alpha_ftpt),bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values in ftpt\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 614,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2Nn1IneTkT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "ca12895b-f811-480e-bfaf-4cee0889fc66"
      },
      "source": [
        "plt.figure(figsize=(6,6))\r\n",
        "_,bins,_ = plt.hist(np.array(alpha_ffpt),bins=50,color =\"c\")\r\n",
        "plt.title(\"alpha values in ffpt\")\r\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 615,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}