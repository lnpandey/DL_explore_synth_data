{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "toy_problem_Mosaic_type5_testing_what_net_500_epochs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2_J4Rw2r0SQ",
        "outputId": "2fdd8a5a-830e-48c4-9d7c-96ed314de287"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6fjud_Fr0Sa"
      },
      "source": [
        "# Generate dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqdXHO0Cr0Sd",
        "outputId": "6017e5b3-8f40-4522-b19f-eea5b9800d88"
      },
      "source": [
        "y = np.random.randint(0,10,5000)\n",
        "idx= []\n",
        "for i in range(10):\n",
        "    print(i,sum(y==i))\n",
        "    idx.append(y==i)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 522\n",
            "1 539\n",
            "2 478\n",
            "3 508\n",
            "4 495\n",
            "5 476\n",
            "6 477\n",
            "7 495\n",
            "8 540\n",
            "9 470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddhXyODwr0Sk"
      },
      "source": [
        "x = np.zeros((5000,2))\n",
        "x1 = np.zeros((5000,2))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyV3N2DIr0Sp"
      },
      "source": [
        "x[idx[0],:] = np.random.multivariate_normal(mean = [2,7],cov=[[0.1,0],[0,0.1]],size=sum(idx[0]))\n",
        "x1[idx[0],:] = np.random.multivariate_normal(mean = [0,-10],cov=[[0.1,0],[0,0.1]],size=sum(idx[0]))\n",
        "\n",
        "x[idx[1],:] = np.random.multivariate_normal(mean = [-15,-7],cov=[[0.1,0],[0,0.1]],size=sum(idx[1]))\n",
        "x1[idx[1],:] = np.random.multivariate_normal(mean = [-5,15],cov=[[0.1,0],[0,0.1]],size=sum(idx[1]))\n",
        "\n",
        "x[idx[2],:] = np.random.multivariate_normal(mean = [4,-2],cov=[[0.1,0],[0,0.1]],size=sum(idx[2]))\n",
        "x1[idx[2],:] = np.random.multivariate_normal(mean = [-10,0],cov=[[0.1,0],[0,0.1]],size=sum(idx[2]))\n",
        "\n",
        "\n",
        "x[idx[3],:] = np.random.multivariate_normal(mean = [-5,0],cov=[[0.1,0],[0,0.1]],size=sum(idx[3]))\n",
        "x1[idx[3],:] = np.random.multivariate_normal(mean = [-20,10],cov=[[0.1,0],[0,0.1]],size=sum(idx[3]))\n",
        "\n",
        "x[idx[4],:] = np.random.multivariate_normal(mean =[-8,10] ,cov=[[0.1,0],[0,0.1]],size=sum(idx[4]))\n",
        "x1[idx[4],:] = np.random.multivariate_normal(mean = [10,20],cov=[[0.1,0],[0,0.1]],size=sum(idx[4]))\n",
        "\n",
        "\n",
        "x[idx[5],:] = np.random.multivariate_normal(mean = [-15,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[5]))\n",
        "x1[idx[5],:] = np.random.multivariate_normal(mean = [0,2],cov=[[0.1,0],[0,0.1]],size=sum(idx[5]))\n",
        "\n",
        "x[idx[6],:] = np.random.multivariate_normal(mean = [2,-18],cov=[[0.1,0],[0,0.1]],size=sum(idx[6]))\n",
        "x1[idx[6],:] = np.random.multivariate_normal(mean = [7,7],cov=[[0.1,0],[0,0.1]],size=sum(idx[6]))\n",
        "\n",
        "x[idx[7],:] = np.random.multivariate_normal(mean = [10,-10],cov=[[0.1,0],[0,0.1]],size=sum(idx[7]))\n",
        "x1[idx[7],:] = np.random.multivariate_normal(mean = [-8,-11],cov=[[0.1,0],[0,0.1]],size=sum(idx[7]))\n",
        "\n",
        "x[idx[8],:] = np.random.multivariate_normal(mean = [-10,-15],cov=[[0.1,0],[0,0.1]],size=sum(idx[8]))\n",
        "x1[idx[8],:] = np.random.multivariate_normal(mean = [10,-2],cov=[[0.1,0],[0,0.1]],size=sum(idx[8]))\n",
        "\n",
        "x[idx[9],:] = np.random.multivariate_normal(mean = [15,8],cov=[[0.1,0],[0,0.1]],size=sum(idx[9]))\n",
        "x1[idx[9],:] = np.random.multivariate_normal(mean = [2,20],cov=[[0.1,0],[0,0.1]],size=sum(idx[9]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhNegG80nREX",
        "outputId": "97813cec-bd07-429f-d994-069369a506e7"
      },
      "source": [
        "x,y = np.concatenate((x,x1),axis=0),np.concatenate((y,y),axis=0)\n",
        "x.shape,y.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 2), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhG5W1KDnQ-T"
      },
      "source": [
        "# y = np.random.randint(0,10,1000)\n",
        "idx= []\n",
        "for i in range(10):\n",
        "    #print(i,sum(y==i))\n",
        "    idx.append(y==i)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "hJ8Jm7YUr0St",
        "outputId": "22a256db-15ed-4313-b441-9ef16315be97"
      },
      "source": [
        "for i in range(10):\n",
        "    plt.scatter(x[idx[i],0],x[idx[i],1],label=\"class_\"+str(i))\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1bd9285cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfFHcZJOr0Sz"
      },
      "source": [
        "foreground_classes = {'class_0','class_1', 'class_2'}\n",
        "\n",
        "background_classes = {'class_3','class_4', 'class_5', 'class_6','class_7', 'class_8', 'class_9'}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OplNpNQVr0S2",
        "outputId": "9a523b9c-1d52-4384-baee-e5e7d84bd52b"
      },
      "source": [
        "fg_class  = np.random.randint(0,3)\n",
        "fg_idx = np.random.randint(0,9)\n",
        "\n",
        "a = []\n",
        "for i in range(9):\n",
        "    if i == fg_idx:\n",
        "        b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
        "        a.append(x[b])\n",
        "        print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
        "    else:\n",
        "        bg_class = np.random.randint(3,10)\n",
        "        b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
        "        a.append(x[b])\n",
        "        print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
        "a = np.concatenate(a,axis=0)\n",
        "print(a.shape)\n",
        "\n",
        "print(fg_class , fg_idx)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "background 8 present at 0\n",
            "background 3 present at 1\n",
            "background 7 present at 2\n",
            "background 3 present at 3\n",
            "background 3 present at 4\n",
            "background 5 present at 5\n",
            "background 7 present at 6\n",
            "background 9 present at 7\n",
            "foreground 0 present at 8\n",
            "(9, 2)\n",
            "0 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwZVmmRBr0S8",
        "outputId": "f206d1e0-09f3-409e-81a9-c6d979df1433"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoxzYI-ur0S_",
        "outputId": "ec990181-e76e-4c49-da33-7b4eefa86143"
      },
      "source": [
        "np.reshape(a,(18,1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-10.33005218],\n",
              "       [-15.42405007],\n",
              "       [-20.00675131],\n",
              "       [ 10.73239539],\n",
              "       [ 10.3884767 ],\n",
              "       [ -9.49763993],\n",
              "       [-20.06437888],\n",
              "       [ 10.14213866],\n",
              "       [-20.24719078],\n",
              "       [ 10.05376864],\n",
              "       [ -0.18067161],\n",
              "       [  2.1866232 ],\n",
              "       [ -8.3796824 ],\n",
              "       [-10.93592104],\n",
              "       [ 15.04564279],\n",
              "       [  8.03610228],\n",
              "       [  1.81432212],\n",
              "       [  6.91206613]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ruI0cxr0TE"
      },
      "source": [
        "a=np.reshape(a,(3,6))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "RTUTFhJIr0TI",
        "outputId": "44a280e7-7db0-4e60-94e1-8e9b1e3b5694"
      },
      "source": [
        "plt.imshow(a)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1bd8d949e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqbvfbwVr0TN"
      },
      "source": [
        "desired_num = 1000\n",
        "mosaic_list_of_images =[]\n",
        "mosaic_label = []\n",
        "fore_idx=[]\n",
        "for j in range(desired_num):\n",
        "    fg_class  = np.random.randint(0,3)\n",
        "    fg_idx = 0\n",
        "    a = []\n",
        "    for i in range(9):\n",
        "        if i == fg_idx:\n",
        "            b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
        "            a.append(x[b])\n",
        "#             print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
        "        else:\n",
        "            bg_class = np.random.randint(3,10)\n",
        "            b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
        "            a.append(x[b])\n",
        "#             print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
        "    a = np.concatenate(a,axis=0)\n",
        "    mosaic_list_of_images.append(np.reshape(a,(18,1)))\n",
        "    mosaic_label.append(fg_class)\n",
        "    fore_idx.append(fg_idx)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOsFmWfMr0TR"
      },
      "source": [
        "mosaic_list_of_images = np.concatenate(mosaic_list_of_images,axis=1).T\n",
        "# print(mosaic_list)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2PnW7aQr0TT",
        "outputId": "22540898-80b2-4a32-dcbc-d106cb070f22"
      },
      "source": [
        "print(np.shape(mosaic_list_of_images))\n",
        "print(np.shape(fore_idx))\n",
        "print(np.shape(mosaic_label))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 18)\n",
            "(1000,)\n",
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPoIwbMHx44n"
      },
      "source": [
        "def create_avg_image_from_mosaic_dataset(mosaic_dataset,labels,foreground_index,dataset_number):\n",
        "  \"\"\"\n",
        "  mosaic_dataset : mosaic_dataset contains 9 images 32 x 32 each as 1 data point\n",
        "  labels : mosaic_dataset labels\n",
        "  foreground_index : contains list of indexes where foreground image is present so that using this we can take weighted average\n",
        "  dataset_number : will help us to tell what ratio of foreground image to be taken. for eg: if it is \"j\" then fg_image_ratio = j/9 , bg_image_ratio = (9-j)/8*9\n",
        "  \"\"\"\n",
        "  avg_image_dataset = []\n",
        "  cnt = 0\n",
        "  counter = np.array([0,0,0,0,0,0,0,0,0])\n",
        "  for i in range(len(mosaic_dataset)):\n",
        "    img = torch.zeros([18], dtype=torch.float64)\n",
        "    np.random.seed(dataset_number*10000 + i)\n",
        "    give_pref = foreground_index[i] #np.random.randint(0,9)\n",
        "    # print(\"outside\", give_pref,foreground_index[i])\n",
        "    for j in range(9):\n",
        "      if j == give_pref:\n",
        "        img = img + mosaic_dataset[i][j]*dataset_number/9\n",
        "      else :\n",
        "        img = img + mosaic_dataset[i][j]*(9-dataset_number)/(8*9)\n",
        "\n",
        "    if give_pref == foreground_index[i] :\n",
        "      # print(\"equal are\", give_pref,foreground_index[i])\n",
        "      cnt += 1\n",
        "      counter[give_pref] += 1\n",
        "    else :\n",
        "      counter[give_pref] += 1\n",
        "\n",
        "    avg_image_dataset.append(img)\n",
        "\n",
        "  print(\"number of correct averaging happened for dataset \"+str(dataset_number)+\" is \"+str(cnt)) \n",
        "  print(\"the averaging are done as \", counter) \n",
        "  return avg_image_dataset , labels , foreground_index\n",
        "        \n",
        "  "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ZAjix3x8CM",
        "outputId": "1a5f3ffa-16d9-4cbb-d58c-73d3c2b6a7b5"
      },
      "source": [
        "avg_image_dataset_1 , labels_1,  fg_index_1 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 1)\n",
        "avg_image_dataset_2 , labels_2,  fg_index_2 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 2)\n",
        "avg_image_dataset_3 , labels_3,  fg_index_3 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 3)\n",
        "avg_image_dataset_4 , labels_4,  fg_index_4 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 4)\n",
        "avg_image_dataset_5 , labels_5,  fg_index_5 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 5)\n",
        "avg_image_dataset_6 , labels_6,  fg_index_6 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 6)\n",
        "avg_image_dataset_7 , labels_7,  fg_index_7 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 7)\n",
        "avg_image_dataset_8 , labels_8,  fg_index_8 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx , 8)\n",
        "avg_image_dataset_9 , labels_9,  fg_index_9 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 9)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of correct averaging happened for dataset 1 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 2 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 3 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 4 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 5 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 6 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 7 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 8 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n",
            "number of correct averaging happened for dataset 9 is 1000\n",
            "the averaging are done as  [1000    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL0BRf8er0TX"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    #self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] #, self.fore_idx[idx]\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY2l62APygaV"
      },
      "source": [
        "batch = 200\n",
        "epochs = 300\n",
        "\n",
        "# training_data = avg_image_dataset_5    #just change this and training_label to desired dataset for training\n",
        "# training_label = labels_5\n",
        "\n",
        "traindata_1 = MosaicDataset(avg_image_dataset_1, labels_1 )\n",
        "trainloader_1 = DataLoader( traindata_1 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_2 = MosaicDataset(avg_image_dataset_2, labels_2 )\n",
        "trainloader_2 = DataLoader( traindata_2 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_3 = MosaicDataset(avg_image_dataset_3, labels_3 )\n",
        "trainloader_3 = DataLoader( traindata_3 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_4 = MosaicDataset(avg_image_dataset_4, labels_4 )\n",
        "trainloader_4 = DataLoader( traindata_4 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_5 = MosaicDataset(avg_image_dataset_5, labels_5 )\n",
        "trainloader_5 = DataLoader( traindata_5 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_6 = MosaicDataset(avg_image_dataset_6, labels_6 )\n",
        "trainloader_6 = DataLoader( traindata_6 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_7 = MosaicDataset(avg_image_dataset_7, labels_7 )\n",
        "trainloader_7 = DataLoader( traindata_7 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_8 = MosaicDataset(avg_image_dataset_8, labels_8 )\n",
        "trainloader_8 = DataLoader( traindata_8 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_9 = MosaicDataset(avg_image_dataset_9, labels_9 )\n",
        "trainloader_9 = DataLoader( traindata_9 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "testdata_1 = MosaicDataset(avg_image_dataset_1, labels_1 )\n",
        "testloader_1 = DataLoader( testdata_1 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_2 = MosaicDataset(avg_image_dataset_2, labels_2 )\n",
        "testloader_2 = DataLoader( testdata_2 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_3 = MosaicDataset(avg_image_dataset_3, labels_3 )\n",
        "testloader_3 = DataLoader( testdata_3 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_4 = MosaicDataset(avg_image_dataset_4, labels_4 )\n",
        "testloader_4 = DataLoader( testdata_4 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_5 = MosaicDataset(avg_image_dataset_5, labels_5 )\n",
        "testloader_5 = DataLoader( testdata_5 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_6 = MosaicDataset(avg_image_dataset_6, labels_6 )\n",
        "testloader_6 = DataLoader( testdata_6 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_7 = MosaicDataset(avg_image_dataset_7, labels_7 )\n",
        "testloader_7 = DataLoader( testdata_7 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_8 = MosaicDataset(avg_image_dataset_8, labels_8 )\n",
        "testloader_8 = DataLoader( testdata_8 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "testdata_9 = MosaicDataset(avg_image_dataset_9, labels_9 )\n",
        "testloader_9 = DataLoader( testdata_9 , batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVRXgwwNr0Tb"
      },
      "source": [
        "class Wherenet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Wherenet,self).__init__()\n",
        "        self.linear1 = nn.Linear(2,128)\n",
        "        self.linear2 = nn.Linear(128,256)\n",
        "        self.linear3 = nn.Linear(256,128)\n",
        "        self.linear4 = nn.Linear(128,64)\n",
        "        self.linear5 = nn.Linear(64,1)\n",
        "    def forward(self,z):\n",
        "        x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,2], dtype=torch.float64)\n",
        "        #x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        for i in range(9):\n",
        "            x[:,i] = self.helper(z[:,2*i:2*i+2])[:,0]\n",
        "            #print(k[:,0].shape,x[:,i].shape)\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(9):\n",
        "            x1 = x[:,i]          \n",
        "            #print()\n",
        "            y = y+torch.mul(x1[:,None],z[:,2*i:2*i+2])\n",
        "        return y , x \n",
        "\n",
        "    \n",
        "    def helper(self,x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = F.relu(self.linear4(x))\n",
        "        x = self.linear5(x)\n",
        "        return x\n",
        "\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Ek05Kxr0Te",
        "outputId": "7d73bf0d-85b5-4650-f2ca-57b826c03160"
      },
      "source": [
        "trainiter = iter(trainloader_1)\n",
        "input1,labels1 = trainiter.next()\n",
        "\n",
        "input1.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxEmWZI6r0Ti",
        "outputId": "26948f63-6464-4274-a33e-d1dcc34d1238"
      },
      "source": [
        "where = Wherenet().double()\n",
        "where = where\n",
        "out_where,alphas = where(input1)\n",
        "out_where.shape,alphas.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([200, 2]), torch.Size([200, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_XeIUk0r0Tl"
      },
      "source": [
        "class Whatnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Whatnet,self).__init__()\n",
        "        self.linear1 = nn.Linear(2,128)\n",
        "        self.linear2 = nn.Linear(128,256)\n",
        "        self.linear3 = nn.Linear(256,128)\n",
        "        self.linear4 = nn.Linear(128,64)\n",
        "        self.linear5 = nn.Linear(64,3)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = F.relu(self.linear4(x))\n",
        "        x = self.linear5(x)\n",
        "        return x"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l35i9bIlr0Tp"
      },
      "source": [
        "# what = Whatnet().double()\n",
        "# what(out_where)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uALi25pmzQHV"
      },
      "source": [
        "def test_all(number, testloader,what, where):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    out = []\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            # images, labels = images.to(\"cuda\"),labels.to(\"cuda\")\n",
        "            out.append(labels.cpu().numpy())\n",
        "            avg_inp,alphas = where(inputs)        \n",
        "            outputs = what(avg_inp)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            pred.append(predicted.cpu().numpy())\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test dataset %d: %d %%' % (number , 100 * correct / total))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmNprlPzTjP"
      },
      "source": [
        "def train_all(trainloader, ds_number, testloader_list):\n",
        "    \n",
        "    print(\"--\"*40)\n",
        "    print(\"training on data set  \", ds_number)\n",
        "    \n",
        "    where = Wherenet().double()\n",
        "    what = Whatnet().double()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # optimizer_where = optim.SGD(where.parameters(), lr=0.001, momentum=0.9)\n",
        "    optimizer_where = optim.Adam(where.parameters(), lr=1e-2, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=True)\n",
        "    # optimizer_what = optim.SGD(what.parameters(), lr=0.001, momentum=0.9)\n",
        "    optimizer_what = optim.Adam(what.parameters(), lr=1e-2, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=True)\n",
        "    \n",
        "    acti = []\n",
        "    loss_curi = []\n",
        "    epochs = 500\n",
        "    \n",
        "    for epoch in range(epochs): # loop over the dataset multiple times\n",
        "        ep_lossi = []\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            # inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer_what.zero_grad()\n",
        "            optimizer_where.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            avg_inp,alphas = where(inputs) \n",
        "            # print(avg_inp.shape)       \n",
        "            outputs = what(avg_inp)\n",
        "            \n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_what.step()\n",
        "            optimizer_where.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            mini = 4\n",
        "            if i % mini == mini-1:    # print every 10 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / mini))\n",
        "                ep_lossi.append(running_loss/mini) # loss per minibatch\n",
        "                running_loss = 0.0\n",
        "                \n",
        "        loss_curi.append(np.mean(ep_lossi))   #loss per epoch\n",
        "        if (np.mean(ep_lossi) <= 0.05):\n",
        "            break\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    # torch.save(inc.state_dict(),\"train_dataset_\"+str(ds_number)+\"_\"+str(epochs)+\".pt\")\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in trainloader:\n",
        "            inputs, labels = data\n",
        "            # images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            avg_inp,alphas = where(inputs)        \n",
        "            outputs = what(avg_inp)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 train images: %d %%' % (  100 * correct / total))\n",
        "    \n",
        "    for i, j in enumerate(testloader_list):\n",
        "        test_all(i+1, j,what, where)\n",
        "    \n",
        "    print(\"--\"*40)\n",
        "    \n",
        "    return loss_curi\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl41sE8vFERk"
      },
      "source": [
        "train_loss_all=[]\n",
        "\n",
        "testloader_list= [ testloader_1, testloader_2, testloader_3, testloader_4, testloader_5, testloader_6,\n",
        "                 testloader_7, testloader_8, testloader_9]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gQoPST5zW2t",
        "outputId": "f675d85b-da3c-4cee-c0a3-d4b58e85bb3a"
      },
      "source": [
        "train_loss_all.append(train_all(trainloader_1, 1, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_2, 2, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_3, 3, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_4, 4, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_5, 5, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_6, 6, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_7, 7, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_8, 8, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_9, 9, testloader_list))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "training on data set   1\n",
            "[1,     4] loss: 1.189\n",
            "[2,     4] loss: 1.100\n",
            "[3,     4] loss: 1.099\n",
            "[4,     4] loss: 1.096\n",
            "[5,     4] loss: 1.098\n",
            "[6,     4] loss: 1.095\n",
            "[7,     4] loss: 1.098\n",
            "[8,     4] loss: 1.095\n",
            "[9,     4] loss: 1.096\n",
            "[10,     4] loss: 1.091\n",
            "[11,     4] loss: 1.098\n",
            "[12,     4] loss: 1.095\n",
            "[13,     4] loss: 1.095\n",
            "[14,     4] loss: 1.091\n",
            "[15,     4] loss: 1.091\n",
            "[16,     4] loss: 1.092\n",
            "[17,     4] loss: 1.093\n",
            "[18,     4] loss: 1.093\n",
            "[19,     4] loss: 1.094\n",
            "[20,     4] loss: 1.089\n",
            "[21,     4] loss: 1.090\n",
            "[22,     4] loss: 1.094\n",
            "[23,     4] loss: 1.089\n",
            "[24,     4] loss: 1.092\n",
            "[25,     4] loss: 1.092\n",
            "[26,     4] loss: 1.091\n",
            "[27,     4] loss: 1.088\n",
            "[28,     4] loss: 1.089\n",
            "[29,     4] loss: 1.095\n",
            "[30,     4] loss: 1.091\n",
            "[31,     4] loss: 1.091\n",
            "[32,     4] loss: 1.091\n",
            "[33,     4] loss: 1.094\n",
            "[34,     4] loss: 1.093\n",
            "[35,     4] loss: 1.093\n",
            "[36,     4] loss: 1.087\n",
            "[37,     4] loss: 1.094\n",
            "[38,     4] loss: 1.090\n",
            "[39,     4] loss: 1.090\n",
            "[40,     4] loss: 1.091\n",
            "[41,     4] loss: 1.091\n",
            "[42,     4] loss: 1.090\n",
            "[43,     4] loss: 1.090\n",
            "[44,     4] loss: 1.089\n",
            "[45,     4] loss: 1.088\n",
            "[46,     4] loss: 1.089\n",
            "[47,     4] loss: 1.086\n",
            "[48,     4] loss: 1.087\n",
            "[49,     4] loss: 1.087\n",
            "[50,     4] loss: 1.089\n",
            "[51,     4] loss: 1.085\n",
            "[52,     4] loss: 1.091\n",
            "[53,     4] loss: 1.087\n",
            "[54,     4] loss: 1.087\n",
            "[55,     4] loss: 1.085\n",
            "[56,     4] loss: 1.088\n",
            "[57,     4] loss: 1.088\n",
            "[58,     4] loss: 1.087\n",
            "[59,     4] loss: 1.087\n",
            "[60,     4] loss: 1.093\n",
            "[61,     4] loss: 1.086\n",
            "[62,     4] loss: 1.089\n",
            "[63,     4] loss: 1.090\n",
            "[64,     4] loss: 1.090\n",
            "[65,     4] loss: 1.088\n",
            "[66,     4] loss: 1.088\n",
            "[67,     4] loss: 1.090\n",
            "[68,     4] loss: 1.086\n",
            "[69,     4] loss: 1.090\n",
            "[70,     4] loss: 1.086\n",
            "[71,     4] loss: 1.085\n",
            "[72,     4] loss: 1.086\n",
            "[73,     4] loss: 1.086\n",
            "[74,     4] loss: 1.090\n",
            "[75,     4] loss: 1.092\n",
            "[76,     4] loss: 1.087\n",
            "[77,     4] loss: 1.087\n",
            "[78,     4] loss: 1.086\n",
            "[79,     4] loss: 1.085\n",
            "[80,     4] loss: 1.084\n",
            "[81,     4] loss: 1.086\n",
            "[82,     4] loss: 1.087\n",
            "[83,     4] loss: 1.084\n",
            "[84,     4] loss: 1.088\n",
            "[85,     4] loss: 1.083\n",
            "[86,     4] loss: 1.093\n",
            "[87,     4] loss: 1.084\n",
            "[88,     4] loss: 1.086\n",
            "[89,     4] loss: 1.087\n",
            "[90,     4] loss: 1.085\n",
            "[91,     4] loss: 1.085\n",
            "[92,     4] loss: 1.083\n",
            "[93,     4] loss: 1.084\n",
            "[94,     4] loss: 1.083\n",
            "[95,     4] loss: 1.083\n",
            "[96,     4] loss: 1.087\n",
            "[97,     4] loss: 1.086\n",
            "[98,     4] loss: 1.083\n",
            "[99,     4] loss: 1.086\n",
            "[100,     4] loss: 1.085\n",
            "[101,     4] loss: 1.085\n",
            "[102,     4] loss: 1.088\n",
            "[103,     4] loss: 1.086\n",
            "[104,     4] loss: 1.086\n",
            "[105,     4] loss: 1.085\n",
            "[106,     4] loss: 1.083\n",
            "[107,     4] loss: 1.083\n",
            "[108,     4] loss: 1.087\n",
            "[109,     4] loss: 1.082\n",
            "[110,     4] loss: 1.085\n",
            "[111,     4] loss: 1.083\n",
            "[112,     4] loss: 1.088\n",
            "[113,     4] loss: 1.083\n",
            "[114,     4] loss: 1.086\n",
            "[115,     4] loss: 1.083\n",
            "[116,     4] loss: 1.087\n",
            "[117,     4] loss: 1.083\n",
            "[118,     4] loss: 1.084\n",
            "[119,     4] loss: 1.083\n",
            "[120,     4] loss: 1.084\n",
            "[121,     4] loss: 1.082\n",
            "[122,     4] loss: 1.088\n",
            "[123,     4] loss: 1.083\n",
            "[124,     4] loss: 1.084\n",
            "[125,     4] loss: 1.083\n",
            "[126,     4] loss: 1.080\n",
            "[127,     4] loss: 1.085\n",
            "[128,     4] loss: 1.087\n",
            "[129,     4] loss: 1.077\n",
            "[130,     4] loss: 1.085\n",
            "[131,     4] loss: 1.077\n",
            "[132,     4] loss: 1.079\n",
            "[133,     4] loss: 1.087\n",
            "[134,     4] loss: 1.083\n",
            "[135,     4] loss: 1.080\n",
            "[136,     4] loss: 1.082\n",
            "[137,     4] loss: 1.080\n",
            "[138,     4] loss: 1.078\n",
            "[139,     4] loss: 1.082\n",
            "[140,     4] loss: 1.082\n",
            "[141,     4] loss: 1.079\n",
            "[142,     4] loss: 1.083\n",
            "[143,     4] loss: 1.080\n",
            "[144,     4] loss: 1.082\n",
            "[145,     4] loss: 1.087\n",
            "[146,     4] loss: 1.087\n",
            "[147,     4] loss: 1.083\n",
            "[148,     4] loss: 1.085\n",
            "[149,     4] loss: 1.079\n",
            "[150,     4] loss: 1.090\n",
            "[151,     4] loss: 1.087\n",
            "[152,     4] loss: 1.078\n",
            "[153,     4] loss: 1.081\n",
            "[154,     4] loss: 1.086\n",
            "[155,     4] loss: 1.083\n",
            "[156,     4] loss: 1.084\n",
            "[157,     4] loss: 1.081\n",
            "[158,     4] loss: 1.081\n",
            "[159,     4] loss: 1.078\n",
            "[160,     4] loss: 1.085\n",
            "[161,     4] loss: 1.079\n",
            "[162,     4] loss: 1.079\n",
            "[163,     4] loss: 1.090\n",
            "[164,     4] loss: 1.087\n",
            "[165,     4] loss: 1.087\n",
            "[166,     4] loss: 1.081\n",
            "[167,     4] loss: 1.080\n",
            "[168,     4] loss: 1.090\n",
            "[169,     4] loss: 1.084\n",
            "[170,     4] loss: 1.084\n",
            "[171,     4] loss: 1.076\n",
            "[172,     4] loss: 1.079\n",
            "[173,     4] loss: 1.079\n",
            "[174,     4] loss: 1.079\n",
            "[175,     4] loss: 1.080\n",
            "[176,     4] loss: 1.072\n",
            "[177,     4] loss: 1.076\n",
            "[178,     4] loss: 1.091\n",
            "[179,     4] loss: 1.080\n",
            "[180,     4] loss: 1.077\n",
            "[181,     4] loss: 1.085\n",
            "[182,     4] loss: 1.078\n",
            "[183,     4] loss: 1.075\n",
            "[184,     4] loss: 1.075\n",
            "[185,     4] loss: 1.080\n",
            "[186,     4] loss: 1.074\n",
            "[187,     4] loss: 1.080\n",
            "[188,     4] loss: 1.070\n",
            "[189,     4] loss: 1.082\n",
            "[190,     4] loss: 1.084\n",
            "[191,     4] loss: 1.079\n",
            "[192,     4] loss: 1.084\n",
            "[193,     4] loss: 1.088\n",
            "[194,     4] loss: 1.086\n",
            "[195,     4] loss: 1.084\n",
            "[196,     4] loss: 1.079\n",
            "[197,     4] loss: 1.080\n",
            "[198,     4] loss: 1.079\n",
            "[199,     4] loss: 1.079\n",
            "[200,     4] loss: 1.084\n",
            "[201,     4] loss: 1.087\n",
            "[202,     4] loss: 1.077\n",
            "[203,     4] loss: 1.080\n",
            "[204,     4] loss: 1.083\n",
            "[205,     4] loss: 1.081\n",
            "[206,     4] loss: 1.081\n",
            "[207,     4] loss: 1.081\n",
            "[208,     4] loss: 1.073\n",
            "[209,     4] loss: 1.078\n",
            "[210,     4] loss: 1.078\n",
            "[211,     4] loss: 1.076\n",
            "[212,     4] loss: 1.076\n",
            "[213,     4] loss: 1.078\n",
            "[214,     4] loss: 1.073\n",
            "[215,     4] loss: 1.073\n",
            "[216,     4] loss: 1.076\n",
            "[217,     4] loss: 1.076\n",
            "[218,     4] loss: 1.079\n",
            "[219,     4] loss: 1.077\n",
            "[220,     4] loss: 1.077\n",
            "[221,     4] loss: 1.078\n",
            "[222,     4] loss: 1.073\n",
            "[223,     4] loss: 1.076\n",
            "[224,     4] loss: 1.078\n",
            "[225,     4] loss: 1.075\n",
            "[226,     4] loss: 1.076\n",
            "[227,     4] loss: 1.080\n",
            "[228,     4] loss: 1.077\n",
            "[229,     4] loss: 1.075\n",
            "[230,     4] loss: 1.075\n",
            "[231,     4] loss: 1.067\n",
            "[232,     4] loss: 1.073\n",
            "[233,     4] loss: 1.073\n",
            "[234,     4] loss: 1.074\n",
            "[235,     4] loss: 1.074\n",
            "[236,     4] loss: 1.074\n",
            "[237,     4] loss: 1.078\n",
            "[238,     4] loss: 1.076\n",
            "[239,     4] loss: 1.075\n",
            "[240,     4] loss: 1.077\n",
            "[241,     4] loss: 1.075\n",
            "[242,     4] loss: 1.093\n",
            "[243,     4] loss: 1.092\n",
            "[244,     4] loss: 1.079\n",
            "[245,     4] loss: 1.085\n",
            "[246,     4] loss: 1.080\n",
            "[247,     4] loss: 1.073\n",
            "[248,     4] loss: 1.083\n",
            "[249,     4] loss: 1.076\n",
            "[250,     4] loss: 1.072\n",
            "[251,     4] loss: 1.064\n",
            "[252,     4] loss: 1.074\n",
            "[253,     4] loss: 1.068\n",
            "[254,     4] loss: 1.076\n",
            "[255,     4] loss: 1.067\n",
            "[256,     4] loss: 1.074\n",
            "[257,     4] loss: 1.074\n",
            "[258,     4] loss: 1.073\n",
            "[259,     4] loss: 1.078\n",
            "[260,     4] loss: 1.071\n",
            "[261,     4] loss: 1.076\n",
            "[262,     4] loss: 1.075\n",
            "[263,     4] loss: 1.075\n",
            "[264,     4] loss: 1.084\n",
            "[265,     4] loss: 1.071\n",
            "[266,     4] loss: 1.072\n",
            "[267,     4] loss: 1.069\n",
            "[268,     4] loss: 1.074\n",
            "[269,     4] loss: 1.076\n",
            "[270,     4] loss: 1.073\n",
            "[271,     4] loss: 1.070\n",
            "[272,     4] loss: 1.075\n",
            "[273,     4] loss: 1.069\n",
            "[274,     4] loss: 1.074\n",
            "[275,     4] loss: 1.077\n",
            "[276,     4] loss: 1.064\n",
            "[277,     4] loss: 1.066\n",
            "[278,     4] loss: 1.075\n",
            "[279,     4] loss: 1.067\n",
            "[280,     4] loss: 1.075\n",
            "[281,     4] loss: 1.071\n",
            "[282,     4] loss: 1.068\n",
            "[283,     4] loss: 1.080\n",
            "[284,     4] loss: 1.071\n",
            "[285,     4] loss: 1.072\n",
            "[286,     4] loss: 1.071\n",
            "[287,     4] loss: 1.065\n",
            "[288,     4] loss: 1.072\n",
            "[289,     4] loss: 1.070\n",
            "[290,     4] loss: 1.069\n",
            "[291,     4] loss: 1.066\n",
            "[292,     4] loss: 1.074\n",
            "[293,     4] loss: 1.078\n",
            "[294,     4] loss: 1.074\n",
            "[295,     4] loss: 1.068\n",
            "[296,     4] loss: 1.070\n",
            "[297,     4] loss: 1.067\n",
            "[298,     4] loss: 1.065\n",
            "[299,     4] loss: 1.070\n",
            "[300,     4] loss: 1.074\n",
            "[301,     4] loss: 1.073\n",
            "[302,     4] loss: 1.070\n",
            "[303,     4] loss: 1.079\n",
            "[304,     4] loss: 1.078\n",
            "[305,     4] loss: 1.077\n",
            "[306,     4] loss: 1.074\n",
            "[307,     4] loss: 1.079\n",
            "[308,     4] loss: 1.077\n",
            "[309,     4] loss: 1.070\n",
            "[310,     4] loss: 1.071\n",
            "[311,     4] loss: 1.074\n",
            "[312,     4] loss: 1.073\n",
            "[313,     4] loss: 1.074\n",
            "[314,     4] loss: 1.070\n",
            "[315,     4] loss: 1.071\n",
            "[316,     4] loss: 1.079\n",
            "[317,     4] loss: 1.071\n",
            "[318,     4] loss: 1.068\n",
            "[319,     4] loss: 1.068\n",
            "[320,     4] loss: 1.066\n",
            "[321,     4] loss: 1.068\n",
            "[322,     4] loss: 1.061\n",
            "[323,     4] loss: 1.068\n",
            "[324,     4] loss: 1.065\n",
            "[325,     4] loss: 1.066\n",
            "[326,     4] loss: 1.068\n",
            "[327,     4] loss: 1.062\n",
            "[328,     4] loss: 1.066\n",
            "[329,     4] loss: 1.069\n",
            "[330,     4] loss: 1.082\n",
            "[331,     4] loss: 1.072\n",
            "[332,     4] loss: 1.063\n",
            "[333,     4] loss: 1.072\n",
            "[334,     4] loss: 1.066\n",
            "[335,     4] loss: 1.070\n",
            "[336,     4] loss: 1.068\n",
            "[337,     4] loss: 1.062\n",
            "[338,     4] loss: 1.071\n",
            "[339,     4] loss: 1.066\n",
            "[340,     4] loss: 1.067\n",
            "[341,     4] loss: 1.069\n",
            "[342,     4] loss: 1.073\n",
            "[343,     4] loss: 1.072\n",
            "[344,     4] loss: 1.070\n",
            "[345,     4] loss: 1.069\n",
            "[346,     4] loss: 1.069\n",
            "[347,     4] loss: 1.068\n",
            "[348,     4] loss: 1.070\n",
            "[349,     4] loss: 1.071\n",
            "[350,     4] loss: 1.076\n",
            "[351,     4] loss: 1.072\n",
            "[352,     4] loss: 1.069\n",
            "[353,     4] loss: 1.072\n",
            "[354,     4] loss: 1.070\n",
            "[355,     4] loss: 1.073\n",
            "[356,     4] loss: 1.069\n",
            "[357,     4] loss: 1.068\n",
            "[358,     4] loss: 1.075\n",
            "[359,     4] loss: 1.075\n",
            "[360,     4] loss: 1.078\n",
            "[361,     4] loss: 1.070\n",
            "[362,     4] loss: 1.067\n",
            "[363,     4] loss: 1.075\n",
            "[364,     4] loss: 1.071\n",
            "[365,     4] loss: 1.071\n",
            "[366,     4] loss: 1.075\n",
            "[367,     4] loss: 1.072\n",
            "[368,     4] loss: 1.074\n",
            "[369,     4] loss: 1.068\n",
            "[370,     4] loss: 1.067\n",
            "[371,     4] loss: 1.076\n",
            "[372,     4] loss: 1.067\n",
            "[373,     4] loss: 1.068\n",
            "[374,     4] loss: 1.063\n",
            "[375,     4] loss: 1.072\n",
            "[376,     4] loss: 1.064\n",
            "[377,     4] loss: 1.067\n",
            "[378,     4] loss: 1.068\n",
            "[379,     4] loss: 1.074\n",
            "[380,     4] loss: 1.068\n",
            "[381,     4] loss: 1.069\n",
            "[382,     4] loss: 1.068\n",
            "[383,     4] loss: 1.068\n",
            "[384,     4] loss: 1.065\n",
            "[385,     4] loss: 1.070\n",
            "[386,     4] loss: 1.066\n",
            "[387,     4] loss: 1.062\n",
            "[388,     4] loss: 1.068\n",
            "[389,     4] loss: 1.058\n",
            "[390,     4] loss: 1.068\n",
            "[391,     4] loss: 1.069\n",
            "[392,     4] loss: 1.069\n",
            "[393,     4] loss: 1.067\n",
            "[394,     4] loss: 1.062\n",
            "[395,     4] loss: 1.064\n",
            "[396,     4] loss: 1.067\n",
            "[397,     4] loss: 1.085\n",
            "[398,     4] loss: 1.070\n",
            "[399,     4] loss: 1.066\n",
            "[400,     4] loss: 1.078\n",
            "[401,     4] loss: 1.077\n",
            "[402,     4] loss: 1.078\n",
            "[403,     4] loss: 1.082\n",
            "[404,     4] loss: 1.076\n",
            "[405,     4] loss: 1.075\n",
            "[406,     4] loss: 1.073\n",
            "[407,     4] loss: 1.065\n",
            "[408,     4] loss: 1.082\n",
            "[409,     4] loss: 1.079\n",
            "[410,     4] loss: 1.075\n",
            "[411,     4] loss: 1.079\n",
            "[412,     4] loss: 1.074\n",
            "[413,     4] loss: 1.070\n",
            "[414,     4] loss: 1.082\n",
            "[415,     4] loss: 1.068\n",
            "[416,     4] loss: 1.073\n",
            "[417,     4] loss: 1.069\n",
            "[418,     4] loss: 1.073\n",
            "[419,     4] loss: 1.073\n",
            "[420,     4] loss: 1.084\n",
            "[421,     4] loss: 1.081\n",
            "[422,     4] loss: 1.082\n",
            "[423,     4] loss: 1.070\n",
            "[424,     4] loss: 1.075\n",
            "[425,     4] loss: 1.076\n",
            "[426,     4] loss: 1.075\n",
            "[427,     4] loss: 1.078\n",
            "[428,     4] loss: 1.076\n",
            "[429,     4] loss: 1.075\n",
            "[430,     4] loss: 1.074\n",
            "[431,     4] loss: 1.069\n",
            "[432,     4] loss: 1.071\n",
            "[433,     4] loss: 1.067\n",
            "[434,     4] loss: 1.068\n",
            "[435,     4] loss: 1.072\n",
            "[436,     4] loss: 1.070\n",
            "[437,     4] loss: 1.067\n",
            "[438,     4] loss: 1.065\n",
            "[439,     4] loss: 1.071\n",
            "[440,     4] loss: 1.066\n",
            "[441,     4] loss: 1.072\n",
            "[442,     4] loss: 1.065\n",
            "[443,     4] loss: 1.071\n",
            "[444,     4] loss: 1.075\n",
            "[445,     4] loss: 1.073\n",
            "[446,     4] loss: 1.075\n",
            "[447,     4] loss: 1.076\n",
            "[448,     4] loss: 1.069\n",
            "[449,     4] loss: 1.070\n",
            "[450,     4] loss: 1.070\n",
            "[451,     4] loss: 1.064\n",
            "[452,     4] loss: 1.069\n",
            "[453,     4] loss: 1.071\n",
            "[454,     4] loss: 1.075\n",
            "[455,     4] loss: 1.078\n",
            "[456,     4] loss: 1.077\n",
            "[457,     4] loss: 1.072\n",
            "[458,     4] loss: 1.079\n",
            "[459,     4] loss: 1.068\n",
            "[460,     4] loss: 1.071\n",
            "[461,     4] loss: 1.077\n",
            "[462,     4] loss: 1.072\n",
            "[463,     4] loss: 1.073\n",
            "[464,     4] loss: 1.068\n",
            "[465,     4] loss: 1.075\n",
            "[466,     4] loss: 1.076\n",
            "[467,     4] loss: 1.074\n",
            "[468,     4] loss: 1.073\n",
            "[469,     4] loss: 1.079\n",
            "[470,     4] loss: 1.073\n",
            "[471,     4] loss: 1.074\n",
            "[472,     4] loss: 1.072\n",
            "[473,     4] loss: 1.069\n",
            "[474,     4] loss: 1.068\n",
            "[475,     4] loss: 1.069\n",
            "[476,     4] loss: 1.064\n",
            "[477,     4] loss: 1.074\n",
            "[478,     4] loss: 1.068\n",
            "[479,     4] loss: 1.075\n",
            "[480,     4] loss: 1.071\n",
            "[481,     4] loss: 1.066\n",
            "[482,     4] loss: 1.069\n",
            "[483,     4] loss: 1.064\n",
            "[484,     4] loss: 1.064\n",
            "[485,     4] loss: 1.068\n",
            "[486,     4] loss: 1.069\n",
            "[487,     4] loss: 1.064\n",
            "[488,     4] loss: 1.070\n",
            "[489,     4] loss: 1.069\n",
            "[490,     4] loss: 1.070\n",
            "[491,     4] loss: 1.070\n",
            "[492,     4] loss: 1.069\n",
            "[493,     4] loss: 1.075\n",
            "[494,     4] loss: 1.072\n",
            "[495,     4] loss: 1.071\n",
            "[496,     4] loss: 1.075\n",
            "[497,     4] loss: 1.070\n",
            "[498,     4] loss: 1.076\n",
            "[499,     4] loss: 1.063\n",
            "[500,     4] loss: 1.065\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 40 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 40 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 37 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 41 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 44 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 48 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 48 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 49 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 44 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   2\n",
            "[1,     4] loss: 1.115\n",
            "[2,     4] loss: 1.082\n",
            "[3,     4] loss: 1.073\n",
            "[4,     4] loss: 1.079\n",
            "[5,     4] loss: 1.066\n",
            "[6,     4] loss: 1.070\n",
            "[7,     4] loss: 1.067\n",
            "[8,     4] loss: 1.069\n",
            "[9,     4] loss: 1.068\n",
            "[10,     4] loss: 1.071\n",
            "[11,     4] loss: 1.071\n",
            "[12,     4] loss: 1.070\n",
            "[13,     4] loss: 1.071\n",
            "[14,     4] loss: 1.062\n",
            "[15,     4] loss: 1.064\n",
            "[16,     4] loss: 1.070\n",
            "[17,     4] loss: 1.071\n",
            "[18,     4] loss: 1.072\n",
            "[19,     4] loss: 1.073\n",
            "[20,     4] loss: 1.070\n",
            "[21,     4] loss: 1.073\n",
            "[22,     4] loss: 1.067\n",
            "[23,     4] loss: 1.069\n",
            "[24,     4] loss: 1.063\n",
            "[25,     4] loss: 1.069\n",
            "[26,     4] loss: 1.071\n",
            "[27,     4] loss: 1.068\n",
            "[28,     4] loss: 1.071\n",
            "[29,     4] loss: 1.072\n",
            "[30,     4] loss: 1.068\n",
            "[31,     4] loss: 1.067\n",
            "[32,     4] loss: 1.071\n",
            "[33,     4] loss: 1.066\n",
            "[34,     4] loss: 1.061\n",
            "[35,     4] loss: 1.063\n",
            "[36,     4] loss: 1.062\n",
            "[37,     4] loss: 1.061\n",
            "[38,     4] loss: 1.066\n",
            "[39,     4] loss: 1.063\n",
            "[40,     4] loss: 1.060\n",
            "[41,     4] loss: 1.067\n",
            "[42,     4] loss: 1.068\n",
            "[43,     4] loss: 1.059\n",
            "[44,     4] loss: 1.061\n",
            "[45,     4] loss: 1.066\n",
            "[46,     4] loss: 1.065\n",
            "[47,     4] loss: 1.070\n",
            "[48,     4] loss: 1.069\n",
            "[49,     4] loss: 1.070\n",
            "[50,     4] loss: 1.056\n",
            "[51,     4] loss: 1.064\n",
            "[52,     4] loss: 1.064\n",
            "[53,     4] loss: 1.066\n",
            "[54,     4] loss: 1.054\n",
            "[55,     4] loss: 1.068\n",
            "[56,     4] loss: 1.056\n",
            "[57,     4] loss: 1.065\n",
            "[58,     4] loss: 1.061\n",
            "[59,     4] loss: 1.073\n",
            "[60,     4] loss: 1.071\n",
            "[61,     4] loss: 1.064\n",
            "[62,     4] loss: 1.061\n",
            "[63,     4] loss: 1.067\n",
            "[64,     4] loss: 1.064\n",
            "[65,     4] loss: 1.067\n",
            "[66,     4] loss: 1.063\n",
            "[67,     4] loss: 1.064\n",
            "[68,     4] loss: 1.058\n",
            "[69,     4] loss: 1.058\n",
            "[70,     4] loss: 1.068\n",
            "[71,     4] loss: 1.062\n",
            "[72,     4] loss: 1.066\n",
            "[73,     4] loss: 1.066\n",
            "[74,     4] loss: 1.062\n",
            "[75,     4] loss: 1.065\n",
            "[76,     4] loss: 1.052\n",
            "[77,     4] loss: 1.060\n",
            "[78,     4] loss: 1.066\n",
            "[79,     4] loss: 1.060\n",
            "[80,     4] loss: 1.063\n",
            "[81,     4] loss: 1.057\n",
            "[82,     4] loss: 1.056\n",
            "[83,     4] loss: 1.058\n",
            "[84,     4] loss: 1.059\n",
            "[85,     4] loss: 1.056\n",
            "[86,     4] loss: 1.066\n",
            "[87,     4] loss: 1.054\n",
            "[88,     4] loss: 1.057\n",
            "[89,     4] loss: 1.055\n",
            "[90,     4] loss: 1.061\n",
            "[91,     4] loss: 1.067\n",
            "[92,     4] loss: 1.055\n",
            "[93,     4] loss: 1.068\n",
            "[94,     4] loss: 1.055\n",
            "[95,     4] loss: 1.058\n",
            "[96,     4] loss: 1.057\n",
            "[97,     4] loss: 1.056\n",
            "[98,     4] loss: 1.056\n",
            "[99,     4] loss: 1.062\n",
            "[100,     4] loss: 1.059\n",
            "[101,     4] loss: 1.063\n",
            "[102,     4] loss: 1.057\n",
            "[103,     4] loss: 1.069\n",
            "[104,     4] loss: 1.066\n",
            "[105,     4] loss: 1.058\n",
            "[106,     4] loss: 1.052\n",
            "[107,     4] loss: 1.060\n",
            "[108,     4] loss: 1.052\n",
            "[109,     4] loss: 1.055\n",
            "[110,     4] loss: 1.066\n",
            "[111,     4] loss: 1.056\n",
            "[112,     4] loss: 1.054\n",
            "[113,     4] loss: 1.054\n",
            "[114,     4] loss: 1.052\n",
            "[115,     4] loss: 1.057\n",
            "[116,     4] loss: 1.045\n",
            "[117,     4] loss: 1.061\n",
            "[118,     4] loss: 1.057\n",
            "[119,     4] loss: 1.052\n",
            "[120,     4] loss: 1.060\n",
            "[121,     4] loss: 1.058\n",
            "[122,     4] loss: 1.052\n",
            "[123,     4] loss: 1.051\n",
            "[124,     4] loss: 1.058\n",
            "[125,     4] loss: 1.057\n",
            "[126,     4] loss: 1.059\n",
            "[127,     4] loss: 1.061\n",
            "[128,     4] loss: 1.059\n",
            "[129,     4] loss: 1.051\n",
            "[130,     4] loss: 1.061\n",
            "[131,     4] loss: 1.051\n",
            "[132,     4] loss: 1.050\n",
            "[133,     4] loss: 1.049\n",
            "[134,     4] loss: 1.059\n",
            "[135,     4] loss: 1.056\n",
            "[136,     4] loss: 1.065\n",
            "[137,     4] loss: 1.057\n",
            "[138,     4] loss: 1.060\n",
            "[139,     4] loss: 1.057\n",
            "[140,     4] loss: 1.053\n",
            "[141,     4] loss: 1.054\n",
            "[142,     4] loss: 1.055\n",
            "[143,     4] loss: 1.052\n",
            "[144,     4] loss: 1.050\n",
            "[145,     4] loss: 1.053\n",
            "[146,     4] loss: 1.049\n",
            "[147,     4] loss: 1.061\n",
            "[148,     4] loss: 1.063\n",
            "[149,     4] loss: 1.056\n",
            "[150,     4] loss: 1.051\n",
            "[151,     4] loss: 1.056\n",
            "[152,     4] loss: 1.052\n",
            "[153,     4] loss: 1.048\n",
            "[154,     4] loss: 1.058\n",
            "[155,     4] loss: 1.051\n",
            "[156,     4] loss: 1.060\n",
            "[157,     4] loss: 1.065\n",
            "[158,     4] loss: 1.049\n",
            "[159,     4] loss: 1.052\n",
            "[160,     4] loss: 1.053\n",
            "[161,     4] loss: 1.053\n",
            "[162,     4] loss: 1.054\n",
            "[163,     4] loss: 1.048\n",
            "[164,     4] loss: 1.045\n",
            "[165,     4] loss: 1.061\n",
            "[166,     4] loss: 1.050\n",
            "[167,     4] loss: 1.049\n",
            "[168,     4] loss: 1.059\n",
            "[169,     4] loss: 1.045\n",
            "[170,     4] loss: 1.055\n",
            "[171,     4] loss: 1.053\n",
            "[172,     4] loss: 1.051\n",
            "[173,     4] loss: 1.060\n",
            "[174,     4] loss: 1.055\n",
            "[175,     4] loss: 1.052\n",
            "[176,     4] loss: 1.063\n",
            "[177,     4] loss: 1.049\n",
            "[178,     4] loss: 1.042\n",
            "[179,     4] loss: 1.055\n",
            "[180,     4] loss: 1.060\n",
            "[181,     4] loss: 1.058\n",
            "[182,     4] loss: 1.054\n",
            "[183,     4] loss: 1.053\n",
            "[184,     4] loss: 1.055\n",
            "[185,     4] loss: 1.068\n",
            "[186,     4] loss: 1.051\n",
            "[187,     4] loss: 1.048\n",
            "[188,     4] loss: 1.051\n",
            "[189,     4] loss: 1.052\n",
            "[190,     4] loss: 1.050\n",
            "[191,     4] loss: 1.047\n",
            "[192,     4] loss: 1.058\n",
            "[193,     4] loss: 1.060\n",
            "[194,     4] loss: 1.048\n",
            "[195,     4] loss: 1.063\n",
            "[196,     4] loss: 1.053\n",
            "[197,     4] loss: 1.060\n",
            "[198,     4] loss: 1.055\n",
            "[199,     4] loss: 1.061\n",
            "[200,     4] loss: 1.052\n",
            "[201,     4] loss: 1.051\n",
            "[202,     4] loss: 1.059\n",
            "[203,     4] loss: 1.058\n",
            "[204,     4] loss: 1.051\n",
            "[205,     4] loss: 1.059\n",
            "[206,     4] loss: 1.054\n",
            "[207,     4] loss: 1.054\n",
            "[208,     4] loss: 1.052\n",
            "[209,     4] loss: 1.051\n",
            "[210,     4] loss: 1.058\n",
            "[211,     4] loss: 1.057\n",
            "[212,     4] loss: 1.055\n",
            "[213,     4] loss: 1.055\n",
            "[214,     4] loss: 1.050\n",
            "[215,     4] loss: 1.047\n",
            "[216,     4] loss: 1.047\n",
            "[217,     4] loss: 1.040\n",
            "[218,     4] loss: 1.053\n",
            "[219,     4] loss: 1.052\n",
            "[220,     4] loss: 1.053\n",
            "[221,     4] loss: 1.050\n",
            "[222,     4] loss: 1.049\n",
            "[223,     4] loss: 1.050\n",
            "[224,     4] loss: 1.055\n",
            "[225,     4] loss: 1.047\n",
            "[226,     4] loss: 1.058\n",
            "[227,     4] loss: 1.055\n",
            "[228,     4] loss: 1.044\n",
            "[229,     4] loss: 1.055\n",
            "[230,     4] loss: 1.055\n",
            "[231,     4] loss: 1.055\n",
            "[232,     4] loss: 1.040\n",
            "[233,     4] loss: 1.047\n",
            "[234,     4] loss: 1.046\n",
            "[235,     4] loss: 1.048\n",
            "[236,     4] loss: 1.044\n",
            "[237,     4] loss: 1.049\n",
            "[238,     4] loss: 1.047\n",
            "[239,     4] loss: 1.047\n",
            "[240,     4] loss: 1.048\n",
            "[241,     4] loss: 1.047\n",
            "[242,     4] loss: 1.055\n",
            "[243,     4] loss: 1.045\n",
            "[244,     4] loss: 1.048\n",
            "[245,     4] loss: 1.050\n",
            "[246,     4] loss: 1.050\n",
            "[247,     4] loss: 1.049\n",
            "[248,     4] loss: 1.047\n",
            "[249,     4] loss: 1.045\n",
            "[250,     4] loss: 1.049\n",
            "[251,     4] loss: 1.053\n",
            "[252,     4] loss: 1.038\n",
            "[253,     4] loss: 1.056\n",
            "[254,     4] loss: 1.059\n",
            "[255,     4] loss: 1.061\n",
            "[256,     4] loss: 1.048\n",
            "[257,     4] loss: 1.043\n",
            "[258,     4] loss: 1.045\n",
            "[259,     4] loss: 1.050\n",
            "[260,     4] loss: 1.048\n",
            "[261,     4] loss: 1.049\n",
            "[262,     4] loss: 1.050\n",
            "[263,     4] loss: 1.050\n",
            "[264,     4] loss: 1.052\n",
            "[265,     4] loss: 1.056\n",
            "[266,     4] loss: 1.042\n",
            "[267,     4] loss: 1.054\n",
            "[268,     4] loss: 1.042\n",
            "[269,     4] loss: 1.047\n",
            "[270,     4] loss: 1.049\n",
            "[271,     4] loss: 1.048\n",
            "[272,     4] loss: 1.046\n",
            "[273,     4] loss: 1.052\n",
            "[274,     4] loss: 1.049\n",
            "[275,     4] loss: 1.048\n",
            "[276,     4] loss: 1.049\n",
            "[277,     4] loss: 1.056\n",
            "[278,     4] loss: 1.039\n",
            "[279,     4] loss: 1.045\n",
            "[280,     4] loss: 1.058\n",
            "[281,     4] loss: 1.043\n",
            "[282,     4] loss: 1.057\n",
            "[283,     4] loss: 1.039\n",
            "[284,     4] loss: 1.043\n",
            "[285,     4] loss: 1.052\n",
            "[286,     4] loss: 1.042\n",
            "[287,     4] loss: 1.036\n",
            "[288,     4] loss: 1.044\n",
            "[289,     4] loss: 1.055\n",
            "[290,     4] loss: 1.050\n",
            "[291,     4] loss: 1.042\n",
            "[292,     4] loss: 1.054\n",
            "[293,     4] loss: 1.051\n",
            "[294,     4] loss: 1.055\n",
            "[295,     4] loss: 1.044\n",
            "[296,     4] loss: 1.058\n",
            "[297,     4] loss: 1.039\n",
            "[298,     4] loss: 1.047\n",
            "[299,     4] loss: 1.041\n",
            "[300,     4] loss: 1.042\n",
            "[301,     4] loss: 1.047\n",
            "[302,     4] loss: 1.043\n",
            "[303,     4] loss: 1.047\n",
            "[304,     4] loss: 1.049\n",
            "[305,     4] loss: 1.043\n",
            "[306,     4] loss: 1.045\n",
            "[307,     4] loss: 1.043\n",
            "[308,     4] loss: 1.044\n",
            "[309,     4] loss: 1.039\n",
            "[310,     4] loss: 1.043\n",
            "[311,     4] loss: 1.037\n",
            "[312,     4] loss: 1.046\n",
            "[313,     4] loss: 1.043\n",
            "[314,     4] loss: 1.049\n",
            "[315,     4] loss: 1.044\n",
            "[316,     4] loss: 1.048\n",
            "[317,     4] loss: 1.036\n",
            "[318,     4] loss: 1.048\n",
            "[319,     4] loss: 1.046\n",
            "[320,     4] loss: 1.046\n",
            "[321,     4] loss: 1.043\n",
            "[322,     4] loss: 1.042\n",
            "[323,     4] loss: 1.038\n",
            "[324,     4] loss: 1.038\n",
            "[325,     4] loss: 1.046\n",
            "[326,     4] loss: 1.041\n",
            "[327,     4] loss: 1.041\n",
            "[328,     4] loss: 1.044\n",
            "[329,     4] loss: 1.050\n",
            "[330,     4] loss: 1.036\n",
            "[331,     4] loss: 1.048\n",
            "[332,     4] loss: 1.065\n",
            "[333,     4] loss: 1.046\n",
            "[334,     4] loss: 1.051\n",
            "[335,     4] loss: 1.048\n",
            "[336,     4] loss: 1.043\n",
            "[337,     4] loss: 1.052\n",
            "[338,     4] loss: 1.040\n",
            "[339,     4] loss: 1.059\n",
            "[340,     4] loss: 1.049\n",
            "[341,     4] loss: 1.045\n",
            "[342,     4] loss: 1.052\n",
            "[343,     4] loss: 1.046\n",
            "[344,     4] loss: 1.050\n",
            "[345,     4] loss: 1.048\n",
            "[346,     4] loss: 1.044\n",
            "[347,     4] loss: 1.047\n",
            "[348,     4] loss: 1.044\n",
            "[349,     4] loss: 1.042\n",
            "[350,     4] loss: 1.048\n",
            "[351,     4] loss: 1.048\n",
            "[352,     4] loss: 1.054\n",
            "[353,     4] loss: 1.041\n",
            "[354,     4] loss: 1.037\n",
            "[355,     4] loss: 1.050\n",
            "[356,     4] loss: 1.042\n",
            "[357,     4] loss: 1.047\n",
            "[358,     4] loss: 1.048\n",
            "[359,     4] loss: 1.050\n",
            "[360,     4] loss: 1.041\n",
            "[361,     4] loss: 1.046\n",
            "[362,     4] loss: 1.038\n",
            "[363,     4] loss: 1.048\n",
            "[364,     4] loss: 1.040\n",
            "[365,     4] loss: 1.042\n",
            "[366,     4] loss: 1.049\n",
            "[367,     4] loss: 1.057\n",
            "[368,     4] loss: 1.044\n",
            "[369,     4] loss: 1.038\n",
            "[370,     4] loss: 1.052\n",
            "[371,     4] loss: 1.041\n",
            "[372,     4] loss: 1.051\n",
            "[373,     4] loss: 1.043\n",
            "[374,     4] loss: 1.048\n",
            "[375,     4] loss: 1.036\n",
            "[376,     4] loss: 1.050\n",
            "[377,     4] loss: 1.031\n",
            "[378,     4] loss: 1.046\n",
            "[379,     4] loss: 1.045\n",
            "[380,     4] loss: 1.043\n",
            "[381,     4] loss: 1.031\n",
            "[382,     4] loss: 1.046\n",
            "[383,     4] loss: 1.054\n",
            "[384,     4] loss: 1.043\n",
            "[385,     4] loss: 1.044\n",
            "[386,     4] loss: 1.042\n",
            "[387,     4] loss: 1.042\n",
            "[388,     4] loss: 1.037\n",
            "[389,     4] loss: 1.048\n",
            "[390,     4] loss: 1.043\n",
            "[391,     4] loss: 1.034\n",
            "[392,     4] loss: 1.040\n",
            "[393,     4] loss: 1.048\n",
            "[394,     4] loss: 1.035\n",
            "[395,     4] loss: 1.036\n",
            "[396,     4] loss: 1.034\n",
            "[397,     4] loss: 1.047\n",
            "[398,     4] loss: 1.032\n",
            "[399,     4] loss: 1.043\n",
            "[400,     4] loss: 1.042\n",
            "[401,     4] loss: 1.048\n",
            "[402,     4] loss: 1.041\n",
            "[403,     4] loss: 1.044\n",
            "[404,     4] loss: 1.036\n",
            "[405,     4] loss: 1.039\n",
            "[406,     4] loss: 1.043\n",
            "[407,     4] loss: 1.044\n",
            "[408,     4] loss: 1.042\n",
            "[409,     4] loss: 1.042\n",
            "[410,     4] loss: 1.043\n",
            "[411,     4] loss: 1.039\n",
            "[412,     4] loss: 1.041\n",
            "[413,     4] loss: 1.038\n",
            "[414,     4] loss: 1.035\n",
            "[415,     4] loss: 1.034\n",
            "[416,     4] loss: 1.043\n",
            "[417,     4] loss: 1.042\n",
            "[418,     4] loss: 1.044\n",
            "[419,     4] loss: 1.045\n",
            "[420,     4] loss: 1.057\n",
            "[421,     4] loss: 1.044\n",
            "[422,     4] loss: 1.043\n",
            "[423,     4] loss: 1.040\n",
            "[424,     4] loss: 1.043\n",
            "[425,     4] loss: 1.036\n",
            "[426,     4] loss: 1.039\n",
            "[427,     4] loss: 1.046\n",
            "[428,     4] loss: 1.037\n",
            "[429,     4] loss: 1.045\n",
            "[430,     4] loss: 1.047\n",
            "[431,     4] loss: 1.038\n",
            "[432,     4] loss: 1.042\n",
            "[433,     4] loss: 1.028\n",
            "[434,     4] loss: 1.041\n",
            "[435,     4] loss: 1.043\n",
            "[436,     4] loss: 1.037\n",
            "[437,     4] loss: 1.041\n",
            "[438,     4] loss: 1.043\n",
            "[439,     4] loss: 1.050\n",
            "[440,     4] loss: 1.041\n",
            "[441,     4] loss: 1.057\n",
            "[442,     4] loss: 1.045\n",
            "[443,     4] loss: 1.043\n",
            "[444,     4] loss: 1.048\n",
            "[445,     4] loss: 1.034\n",
            "[446,     4] loss: 1.041\n",
            "[447,     4] loss: 1.050\n",
            "[448,     4] loss: 1.045\n",
            "[449,     4] loss: 1.043\n",
            "[450,     4] loss: 1.050\n",
            "[451,     4] loss: 1.042\n",
            "[452,     4] loss: 1.038\n",
            "[453,     4] loss: 1.040\n",
            "[454,     4] loss: 1.047\n",
            "[455,     4] loss: 1.044\n",
            "[456,     4] loss: 1.044\n",
            "[457,     4] loss: 1.044\n",
            "[458,     4] loss: 1.040\n",
            "[459,     4] loss: 1.036\n",
            "[460,     4] loss: 1.042\n",
            "[461,     4] loss: 1.036\n",
            "[462,     4] loss: 1.042\n",
            "[463,     4] loss: 1.050\n",
            "[464,     4] loss: 1.038\n",
            "[465,     4] loss: 1.048\n",
            "[466,     4] loss: 1.043\n",
            "[467,     4] loss: 1.043\n",
            "[468,     4] loss: 1.038\n",
            "[469,     4] loss: 1.042\n",
            "[470,     4] loss: 1.037\n",
            "[471,     4] loss: 1.041\n",
            "[472,     4] loss: 1.046\n",
            "[473,     4] loss: 1.034\n",
            "[474,     4] loss: 1.040\n",
            "[475,     4] loss: 1.037\n",
            "[476,     4] loss: 1.053\n",
            "[477,     4] loss: 1.039\n",
            "[478,     4] loss: 1.052\n",
            "[479,     4] loss: 1.044\n",
            "[480,     4] loss: 1.032\n",
            "[481,     4] loss: 1.034\n",
            "[482,     4] loss: 1.042\n",
            "[483,     4] loss: 1.040\n",
            "[484,     4] loss: 1.040\n",
            "[485,     4] loss: 1.048\n",
            "[486,     4] loss: 1.039\n",
            "[487,     4] loss: 1.045\n",
            "[488,     4] loss: 1.048\n",
            "[489,     4] loss: 1.050\n",
            "[490,     4] loss: 1.041\n",
            "[491,     4] loss: 1.037\n",
            "[492,     4] loss: 1.042\n",
            "[493,     4] loss: 1.041\n",
            "[494,     4] loss: 1.033\n",
            "[495,     4] loss: 1.039\n",
            "[496,     4] loss: 1.029\n",
            "[497,     4] loss: 1.038\n",
            "[498,     4] loss: 1.040\n",
            "[499,     4] loss: 1.042\n",
            "[500,     4] loss: 1.043\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 52 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 54 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 55 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 54 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 52 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   3\n",
            "[1,     4] loss: 1.146\n",
            "[2,     4] loss: 1.030\n",
            "[3,     4] loss: 1.018\n",
            "[4,     4] loss: 1.037\n",
            "[5,     4] loss: 1.025\n",
            "[6,     4] loss: 1.028\n",
            "[7,     4] loss: 1.020\n",
            "[8,     4] loss: 1.021\n",
            "[9,     4] loss: 1.014\n",
            "[10,     4] loss: 1.015\n",
            "[11,     4] loss: 1.019\n",
            "[12,     4] loss: 1.016\n",
            "[13,     4] loss: 1.012\n",
            "[14,     4] loss: 1.017\n",
            "[15,     4] loss: 1.014\n",
            "[16,     4] loss: 1.017\n",
            "[17,     4] loss: 1.022\n",
            "[18,     4] loss: 1.023\n",
            "[19,     4] loss: 1.004\n",
            "[20,     4] loss: 1.019\n",
            "[21,     4] loss: 1.019\n",
            "[22,     4] loss: 1.021\n",
            "[23,     4] loss: 1.029\n",
            "[24,     4] loss: 1.016\n",
            "[25,     4] loss: 1.016\n",
            "[26,     4] loss: 1.015\n",
            "[27,     4] loss: 1.015\n",
            "[28,     4] loss: 1.023\n",
            "[29,     4] loss: 1.023\n",
            "[30,     4] loss: 1.019\n",
            "[31,     4] loss: 1.001\n",
            "[32,     4] loss: 1.012\n",
            "[33,     4] loss: 1.018\n",
            "[34,     4] loss: 1.017\n",
            "[35,     4] loss: 1.006\n",
            "[36,     4] loss: 1.004\n",
            "[37,     4] loss: 1.016\n",
            "[38,     4] loss: 1.010\n",
            "[39,     4] loss: 1.013\n",
            "[40,     4] loss: 1.006\n",
            "[41,     4] loss: 1.014\n",
            "[42,     4] loss: 1.006\n",
            "[43,     4] loss: 1.024\n",
            "[44,     4] loss: 1.009\n",
            "[45,     4] loss: 1.001\n",
            "[46,     4] loss: 1.003\n",
            "[47,     4] loss: 1.013\n",
            "[48,     4] loss: 1.013\n",
            "[49,     4] loss: 1.017\n",
            "[50,     4] loss: 1.015\n",
            "[51,     4] loss: 1.019\n",
            "[52,     4] loss: 1.014\n",
            "[53,     4] loss: 1.012\n",
            "[54,     4] loss: 1.014\n",
            "[55,     4] loss: 1.004\n",
            "[56,     4] loss: 1.006\n",
            "[57,     4] loss: 1.014\n",
            "[58,     4] loss: 1.007\n",
            "[59,     4] loss: 1.008\n",
            "[60,     4] loss: 1.018\n",
            "[61,     4] loss: 1.007\n",
            "[62,     4] loss: 1.022\n",
            "[63,     4] loss: 1.011\n",
            "[64,     4] loss: 1.002\n",
            "[65,     4] loss: 1.011\n",
            "[66,     4] loss: 1.008\n",
            "[67,     4] loss: 1.015\n",
            "[68,     4] loss: 1.007\n",
            "[69,     4] loss: 1.012\n",
            "[70,     4] loss: 1.000\n",
            "[71,     4] loss: 1.015\n",
            "[72,     4] loss: 1.012\n",
            "[73,     4] loss: 1.011\n",
            "[74,     4] loss: 1.015\n",
            "[75,     4] loss: 1.004\n",
            "[76,     4] loss: 1.020\n",
            "[77,     4] loss: 1.017\n",
            "[78,     4] loss: 1.015\n",
            "[79,     4] loss: 1.008\n",
            "[80,     4] loss: 1.015\n",
            "[81,     4] loss: 1.008\n",
            "[82,     4] loss: 1.015\n",
            "[83,     4] loss: 1.011\n",
            "[84,     4] loss: 1.015\n",
            "[85,     4] loss: 1.000\n",
            "[86,     4] loss: 1.021\n",
            "[87,     4] loss: 1.014\n",
            "[88,     4] loss: 1.011\n",
            "[89,     4] loss: 1.020\n",
            "[90,     4] loss: 1.015\n",
            "[91,     4] loss: 1.026\n",
            "[92,     4] loss: 0.998\n",
            "[93,     4] loss: 1.005\n",
            "[94,     4] loss: 0.993\n",
            "[95,     4] loss: 1.002\n",
            "[96,     4] loss: 1.015\n",
            "[97,     4] loss: 1.017\n",
            "[98,     4] loss: 1.019\n",
            "[99,     4] loss: 1.027\n",
            "[100,     4] loss: 1.010\n",
            "[101,     4] loss: 0.998\n",
            "[102,     4] loss: 1.004\n",
            "[103,     4] loss: 1.011\n",
            "[104,     4] loss: 1.009\n",
            "[105,     4] loss: 1.013\n",
            "[106,     4] loss: 1.013\n",
            "[107,     4] loss: 1.010\n",
            "[108,     4] loss: 1.010\n",
            "[109,     4] loss: 1.008\n",
            "[110,     4] loss: 1.012\n",
            "[111,     4] loss: 1.004\n",
            "[112,     4] loss: 1.004\n",
            "[113,     4] loss: 1.018\n",
            "[114,     4] loss: 1.026\n",
            "[115,     4] loss: 1.008\n",
            "[116,     4] loss: 1.002\n",
            "[117,     4] loss: 1.009\n",
            "[118,     4] loss: 1.010\n",
            "[119,     4] loss: 1.015\n",
            "[120,     4] loss: 1.010\n",
            "[121,     4] loss: 1.013\n",
            "[122,     4] loss: 0.993\n",
            "[123,     4] loss: 1.011\n",
            "[124,     4] loss: 1.008\n",
            "[125,     4] loss: 1.008\n",
            "[126,     4] loss: 1.004\n",
            "[127,     4] loss: 1.010\n",
            "[128,     4] loss: 1.021\n",
            "[129,     4] loss: 1.012\n",
            "[130,     4] loss: 1.007\n",
            "[131,     4] loss: 1.013\n",
            "[132,     4] loss: 1.011\n",
            "[133,     4] loss: 0.996\n",
            "[134,     4] loss: 1.011\n",
            "[135,     4] loss: 1.008\n",
            "[136,     4] loss: 1.017\n",
            "[137,     4] loss: 1.012\n",
            "[138,     4] loss: 1.005\n",
            "[139,     4] loss: 1.019\n",
            "[140,     4] loss: 1.018\n",
            "[141,     4] loss: 1.008\n",
            "[142,     4] loss: 1.015\n",
            "[143,     4] loss: 0.997\n",
            "[144,     4] loss: 1.004\n",
            "[145,     4] loss: 1.007\n",
            "[146,     4] loss: 1.020\n",
            "[147,     4] loss: 1.021\n",
            "[148,     4] loss: 1.011\n",
            "[149,     4] loss: 1.004\n",
            "[150,     4] loss: 1.010\n",
            "[151,     4] loss: 1.019\n",
            "[152,     4] loss: 1.015\n",
            "[153,     4] loss: 1.010\n",
            "[154,     4] loss: 1.017\n",
            "[155,     4] loss: 1.011\n",
            "[156,     4] loss: 1.012\n",
            "[157,     4] loss: 1.006\n",
            "[158,     4] loss: 1.017\n",
            "[159,     4] loss: 0.998\n",
            "[160,     4] loss: 1.011\n",
            "[161,     4] loss: 1.010\n",
            "[162,     4] loss: 1.002\n",
            "[163,     4] loss: 1.009\n",
            "[164,     4] loss: 1.005\n",
            "[165,     4] loss: 1.014\n",
            "[166,     4] loss: 1.013\n",
            "[167,     4] loss: 1.013\n",
            "[168,     4] loss: 1.002\n",
            "[169,     4] loss: 1.003\n",
            "[170,     4] loss: 1.000\n",
            "[171,     4] loss: 1.010\n",
            "[172,     4] loss: 1.004\n",
            "[173,     4] loss: 1.013\n",
            "[174,     4] loss: 1.006\n",
            "[175,     4] loss: 1.014\n",
            "[176,     4] loss: 1.010\n",
            "[177,     4] loss: 1.008\n",
            "[178,     4] loss: 1.008\n",
            "[179,     4] loss: 1.014\n",
            "[180,     4] loss: 1.006\n",
            "[181,     4] loss: 0.994\n",
            "[182,     4] loss: 1.010\n",
            "[183,     4] loss: 1.004\n",
            "[184,     4] loss: 1.007\n",
            "[185,     4] loss: 0.991\n",
            "[186,     4] loss: 1.007\n",
            "[187,     4] loss: 1.016\n",
            "[188,     4] loss: 1.013\n",
            "[189,     4] loss: 0.999\n",
            "[190,     4] loss: 1.006\n",
            "[191,     4] loss: 1.013\n",
            "[192,     4] loss: 1.004\n",
            "[193,     4] loss: 1.012\n",
            "[194,     4] loss: 0.998\n",
            "[195,     4] loss: 1.004\n",
            "[196,     4] loss: 1.009\n",
            "[197,     4] loss: 1.012\n",
            "[198,     4] loss: 0.998\n",
            "[199,     4] loss: 1.001\n",
            "[200,     4] loss: 1.011\n",
            "[201,     4] loss: 1.009\n",
            "[202,     4] loss: 1.010\n",
            "[203,     4] loss: 0.999\n",
            "[204,     4] loss: 1.000\n",
            "[205,     4] loss: 1.011\n",
            "[206,     4] loss: 1.016\n",
            "[207,     4] loss: 1.002\n",
            "[208,     4] loss: 1.015\n",
            "[209,     4] loss: 1.006\n",
            "[210,     4] loss: 1.004\n",
            "[211,     4] loss: 1.012\n",
            "[212,     4] loss: 1.018\n",
            "[213,     4] loss: 1.013\n",
            "[214,     4] loss: 1.001\n",
            "[215,     4] loss: 1.009\n",
            "[216,     4] loss: 1.009\n",
            "[217,     4] loss: 1.003\n",
            "[218,     4] loss: 1.005\n",
            "[219,     4] loss: 0.994\n",
            "[220,     4] loss: 0.989\n",
            "[221,     4] loss: 1.015\n",
            "[222,     4] loss: 1.010\n",
            "[223,     4] loss: 1.019\n",
            "[224,     4] loss: 1.011\n",
            "[225,     4] loss: 1.005\n",
            "[226,     4] loss: 1.020\n",
            "[227,     4] loss: 1.015\n",
            "[228,     4] loss: 1.014\n",
            "[229,     4] loss: 0.998\n",
            "[230,     4] loss: 1.001\n",
            "[231,     4] loss: 1.021\n",
            "[232,     4] loss: 1.010\n",
            "[233,     4] loss: 1.017\n",
            "[234,     4] loss: 1.012\n",
            "[235,     4] loss: 1.002\n",
            "[236,     4] loss: 1.013\n",
            "[237,     4] loss: 0.998\n",
            "[238,     4] loss: 1.001\n",
            "[239,     4] loss: 1.012\n",
            "[240,     4] loss: 1.010\n",
            "[241,     4] loss: 0.993\n",
            "[242,     4] loss: 1.011\n",
            "[243,     4] loss: 1.001\n",
            "[244,     4] loss: 0.988\n",
            "[245,     4] loss: 0.993\n",
            "[246,     4] loss: 1.007\n",
            "[247,     4] loss: 1.003\n",
            "[248,     4] loss: 0.993\n",
            "[249,     4] loss: 1.001\n",
            "[250,     4] loss: 1.012\n",
            "[251,     4] loss: 0.993\n",
            "[252,     4] loss: 1.007\n",
            "[253,     4] loss: 0.996\n",
            "[254,     4] loss: 1.008\n",
            "[255,     4] loss: 1.009\n",
            "[256,     4] loss: 1.006\n",
            "[257,     4] loss: 0.992\n",
            "[258,     4] loss: 1.006\n",
            "[259,     4] loss: 1.004\n",
            "[260,     4] loss: 1.007\n",
            "[261,     4] loss: 0.999\n",
            "[262,     4] loss: 0.999\n",
            "[263,     4] loss: 0.992\n",
            "[264,     4] loss: 1.004\n",
            "[265,     4] loss: 1.000\n",
            "[266,     4] loss: 1.004\n",
            "[267,     4] loss: 0.999\n",
            "[268,     4] loss: 1.007\n",
            "[269,     4] loss: 0.995\n",
            "[270,     4] loss: 1.010\n",
            "[271,     4] loss: 1.005\n",
            "[272,     4] loss: 0.999\n",
            "[273,     4] loss: 1.008\n",
            "[274,     4] loss: 0.995\n",
            "[275,     4] loss: 0.988\n",
            "[276,     4] loss: 1.010\n",
            "[277,     4] loss: 1.008\n",
            "[278,     4] loss: 0.997\n",
            "[279,     4] loss: 1.004\n",
            "[280,     4] loss: 0.999\n",
            "[281,     4] loss: 1.000\n",
            "[282,     4] loss: 1.010\n",
            "[283,     4] loss: 0.999\n",
            "[284,     4] loss: 1.006\n",
            "[285,     4] loss: 1.006\n",
            "[286,     4] loss: 0.996\n",
            "[287,     4] loss: 0.998\n",
            "[288,     4] loss: 1.006\n",
            "[289,     4] loss: 0.999\n",
            "[290,     4] loss: 0.995\n",
            "[291,     4] loss: 0.994\n",
            "[292,     4] loss: 1.012\n",
            "[293,     4] loss: 0.998\n",
            "[294,     4] loss: 1.007\n",
            "[295,     4] loss: 1.010\n",
            "[296,     4] loss: 1.001\n",
            "[297,     4] loss: 1.009\n",
            "[298,     4] loss: 0.998\n",
            "[299,     4] loss: 1.000\n",
            "[300,     4] loss: 1.000\n",
            "[301,     4] loss: 0.995\n",
            "[302,     4] loss: 1.009\n",
            "[303,     4] loss: 0.979\n",
            "[304,     4] loss: 1.013\n",
            "[305,     4] loss: 0.998\n",
            "[306,     4] loss: 0.996\n",
            "[307,     4] loss: 1.000\n",
            "[308,     4] loss: 1.002\n",
            "[309,     4] loss: 1.005\n",
            "[310,     4] loss: 0.998\n",
            "[311,     4] loss: 1.003\n",
            "[312,     4] loss: 1.004\n",
            "[313,     4] loss: 0.998\n",
            "[314,     4] loss: 0.999\n",
            "[315,     4] loss: 0.991\n",
            "[316,     4] loss: 1.001\n",
            "[317,     4] loss: 1.004\n",
            "[318,     4] loss: 1.005\n",
            "[319,     4] loss: 0.999\n",
            "[320,     4] loss: 1.003\n",
            "[321,     4] loss: 1.001\n",
            "[322,     4] loss: 1.002\n",
            "[323,     4] loss: 0.993\n",
            "[324,     4] loss: 0.996\n",
            "[325,     4] loss: 1.004\n",
            "[326,     4] loss: 1.002\n",
            "[327,     4] loss: 0.996\n",
            "[328,     4] loss: 0.999\n",
            "[329,     4] loss: 1.003\n",
            "[330,     4] loss: 1.009\n",
            "[331,     4] loss: 0.995\n",
            "[332,     4] loss: 1.002\n",
            "[333,     4] loss: 1.010\n",
            "[334,     4] loss: 0.983\n",
            "[335,     4] loss: 0.991\n",
            "[336,     4] loss: 0.993\n",
            "[337,     4] loss: 0.991\n",
            "[338,     4] loss: 0.994\n",
            "[339,     4] loss: 0.995\n",
            "[340,     4] loss: 0.995\n",
            "[341,     4] loss: 1.002\n",
            "[342,     4] loss: 0.993\n",
            "[343,     4] loss: 1.004\n",
            "[344,     4] loss: 1.002\n",
            "[345,     4] loss: 0.991\n",
            "[346,     4] loss: 0.998\n",
            "[347,     4] loss: 0.998\n",
            "[348,     4] loss: 1.005\n",
            "[349,     4] loss: 0.997\n",
            "[350,     4] loss: 1.005\n",
            "[351,     4] loss: 0.986\n",
            "[352,     4] loss: 1.004\n",
            "[353,     4] loss: 1.005\n",
            "[354,     4] loss: 0.992\n",
            "[355,     4] loss: 1.008\n",
            "[356,     4] loss: 1.004\n",
            "[357,     4] loss: 1.011\n",
            "[358,     4] loss: 1.000\n",
            "[359,     4] loss: 0.990\n",
            "[360,     4] loss: 1.009\n",
            "[361,     4] loss: 0.986\n",
            "[362,     4] loss: 0.998\n",
            "[363,     4] loss: 0.997\n",
            "[364,     4] loss: 0.993\n",
            "[365,     4] loss: 1.008\n",
            "[366,     4] loss: 0.997\n",
            "[367,     4] loss: 0.992\n",
            "[368,     4] loss: 0.995\n",
            "[369,     4] loss: 0.983\n",
            "[370,     4] loss: 0.996\n",
            "[371,     4] loss: 0.989\n",
            "[372,     4] loss: 0.987\n",
            "[373,     4] loss: 0.980\n",
            "[374,     4] loss: 1.001\n",
            "[375,     4] loss: 0.989\n",
            "[376,     4] loss: 1.002\n",
            "[377,     4] loss: 1.002\n",
            "[378,     4] loss: 0.989\n",
            "[379,     4] loss: 0.997\n",
            "[380,     4] loss: 0.990\n",
            "[381,     4] loss: 1.000\n",
            "[382,     4] loss: 0.996\n",
            "[383,     4] loss: 0.994\n",
            "[384,     4] loss: 0.996\n",
            "[385,     4] loss: 1.001\n",
            "[386,     4] loss: 0.988\n",
            "[387,     4] loss: 0.978\n",
            "[388,     4] loss: 0.999\n",
            "[389,     4] loss: 0.996\n",
            "[390,     4] loss: 1.002\n",
            "[391,     4] loss: 0.996\n",
            "[392,     4] loss: 0.988\n",
            "[393,     4] loss: 1.006\n",
            "[394,     4] loss: 0.997\n",
            "[395,     4] loss: 0.991\n",
            "[396,     4] loss: 1.006\n",
            "[397,     4] loss: 0.995\n",
            "[398,     4] loss: 0.997\n",
            "[399,     4] loss: 0.986\n",
            "[400,     4] loss: 0.999\n",
            "[401,     4] loss: 1.000\n",
            "[402,     4] loss: 0.991\n",
            "[403,     4] loss: 0.994\n",
            "[404,     4] loss: 1.003\n",
            "[405,     4] loss: 0.995\n",
            "[406,     4] loss: 0.995\n",
            "[407,     4] loss: 0.993\n",
            "[408,     4] loss: 1.000\n",
            "[409,     4] loss: 0.987\n",
            "[410,     4] loss: 0.992\n",
            "[411,     4] loss: 0.995\n",
            "[412,     4] loss: 0.992\n",
            "[413,     4] loss: 1.002\n",
            "[414,     4] loss: 0.997\n",
            "[415,     4] loss: 1.003\n",
            "[416,     4] loss: 0.996\n",
            "[417,     4] loss: 0.995\n",
            "[418,     4] loss: 0.996\n",
            "[419,     4] loss: 0.996\n",
            "[420,     4] loss: 0.989\n",
            "[421,     4] loss: 1.003\n",
            "[422,     4] loss: 0.990\n",
            "[423,     4] loss: 1.001\n",
            "[424,     4] loss: 0.988\n",
            "[425,     4] loss: 0.990\n",
            "[426,     4] loss: 0.986\n",
            "[427,     4] loss: 1.007\n",
            "[428,     4] loss: 0.991\n",
            "[429,     4] loss: 0.989\n",
            "[430,     4] loss: 1.001\n",
            "[431,     4] loss: 0.998\n",
            "[432,     4] loss: 0.994\n",
            "[433,     4] loss: 0.996\n",
            "[434,     4] loss: 0.995\n",
            "[435,     4] loss: 0.986\n",
            "[436,     4] loss: 0.982\n",
            "[437,     4] loss: 1.008\n",
            "[438,     4] loss: 0.999\n",
            "[439,     4] loss: 0.995\n",
            "[440,     4] loss: 1.001\n",
            "[441,     4] loss: 0.990\n",
            "[442,     4] loss: 0.986\n",
            "[443,     4] loss: 0.997\n",
            "[444,     4] loss: 1.000\n",
            "[445,     4] loss: 1.001\n",
            "[446,     4] loss: 0.981\n",
            "[447,     4] loss: 0.981\n",
            "[448,     4] loss: 0.992\n",
            "[449,     4] loss: 0.993\n",
            "[450,     4] loss: 0.985\n",
            "[451,     4] loss: 0.982\n",
            "[452,     4] loss: 0.996\n",
            "[453,     4] loss: 0.997\n",
            "[454,     4] loss: 0.981\n",
            "[455,     4] loss: 0.979\n",
            "[456,     4] loss: 0.992\n",
            "[457,     4] loss: 0.993\n",
            "[458,     4] loss: 0.988\n",
            "[459,     4] loss: 0.994\n",
            "[460,     4] loss: 0.992\n",
            "[461,     4] loss: 0.992\n",
            "[462,     4] loss: 0.991\n",
            "[463,     4] loss: 0.986\n",
            "[464,     4] loss: 0.996\n",
            "[465,     4] loss: 0.982\n",
            "[466,     4] loss: 0.986\n",
            "[467,     4] loss: 1.010\n",
            "[468,     4] loss: 1.005\n",
            "[469,     4] loss: 1.002\n",
            "[470,     4] loss: 0.994\n",
            "[471,     4] loss: 1.005\n",
            "[472,     4] loss: 0.985\n",
            "[473,     4] loss: 0.996\n",
            "[474,     4] loss: 0.995\n",
            "[475,     4] loss: 1.001\n",
            "[476,     4] loss: 0.992\n",
            "[477,     4] loss: 0.991\n",
            "[478,     4] loss: 0.993\n",
            "[479,     4] loss: 0.982\n",
            "[480,     4] loss: 0.985\n",
            "[481,     4] loss: 0.995\n",
            "[482,     4] loss: 0.995\n",
            "[483,     4] loss: 1.001\n",
            "[484,     4] loss: 0.993\n",
            "[485,     4] loss: 0.999\n",
            "[486,     4] loss: 0.984\n",
            "[487,     4] loss: 1.001\n",
            "[488,     4] loss: 0.994\n",
            "[489,     4] loss: 1.002\n",
            "[490,     4] loss: 0.989\n",
            "[491,     4] loss: 1.001\n",
            "[492,     4] loss: 0.992\n",
            "[493,     4] loss: 0.992\n",
            "[494,     4] loss: 0.998\n",
            "[495,     4] loss: 1.002\n",
            "[496,     4] loss: 0.994\n",
            "[497,     4] loss: 0.998\n",
            "[498,     4] loss: 1.000\n",
            "[499,     4] loss: 1.003\n",
            "[500,     4] loss: 0.979\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 49 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 42 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 49 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 51 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 53 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 57 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 61 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 61 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 58 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   4\n",
            "[1,     4] loss: 1.081\n",
            "[2,     4] loss: 0.985\n",
            "[3,     4] loss: 0.977\n",
            "[4,     4] loss: 0.940\n",
            "[5,     4] loss: 0.937\n",
            "[6,     4] loss: 0.939\n",
            "[7,     4] loss: 0.934\n",
            "[8,     4] loss: 0.926\n",
            "[9,     4] loss: 0.943\n",
            "[10,     4] loss: 0.918\n",
            "[11,     4] loss: 0.944\n",
            "[12,     4] loss: 0.938\n",
            "[13,     4] loss: 0.928\n",
            "[14,     4] loss: 0.933\n",
            "[15,     4] loss: 0.929\n",
            "[16,     4] loss: 0.911\n",
            "[17,     4] loss: 0.921\n",
            "[18,     4] loss: 0.919\n",
            "[19,     4] loss: 0.932\n",
            "[20,     4] loss: 0.917\n",
            "[21,     4] loss: 0.925\n",
            "[22,     4] loss: 0.938\n",
            "[23,     4] loss: 0.935\n",
            "[24,     4] loss: 0.914\n",
            "[25,     4] loss: 0.918\n",
            "[26,     4] loss: 0.926\n",
            "[27,     4] loss: 0.918\n",
            "[28,     4] loss: 0.934\n",
            "[29,     4] loss: 0.929\n",
            "[30,     4] loss: 0.916\n",
            "[31,     4] loss: 0.928\n",
            "[32,     4] loss: 0.922\n",
            "[33,     4] loss: 0.938\n",
            "[34,     4] loss: 0.932\n",
            "[35,     4] loss: 0.926\n",
            "[36,     4] loss: 0.917\n",
            "[37,     4] loss: 0.930\n",
            "[38,     4] loss: 0.928\n",
            "[39,     4] loss: 0.923\n",
            "[40,     4] loss: 0.940\n",
            "[41,     4] loss: 0.931\n",
            "[42,     4] loss: 0.939\n",
            "[43,     4] loss: 0.930\n",
            "[44,     4] loss: 0.933\n",
            "[45,     4] loss: 0.934\n",
            "[46,     4] loss: 0.916\n",
            "[47,     4] loss: 0.924\n",
            "[48,     4] loss: 0.915\n",
            "[49,     4] loss: 0.922\n",
            "[50,     4] loss: 0.898\n",
            "[51,     4] loss: 0.913\n",
            "[52,     4] loss: 0.927\n",
            "[53,     4] loss: 0.910\n",
            "[54,     4] loss: 0.934\n",
            "[55,     4] loss: 0.916\n",
            "[56,     4] loss: 0.912\n",
            "[57,     4] loss: 0.916\n",
            "[58,     4] loss: 0.923\n",
            "[59,     4] loss: 0.921\n",
            "[60,     4] loss: 0.939\n",
            "[61,     4] loss: 0.917\n",
            "[62,     4] loss: 0.926\n",
            "[63,     4] loss: 0.926\n",
            "[64,     4] loss: 0.934\n",
            "[65,     4] loss: 0.922\n",
            "[66,     4] loss: 0.907\n",
            "[67,     4] loss: 0.909\n",
            "[68,     4] loss: 0.940\n",
            "[69,     4] loss: 0.932\n",
            "[70,     4] loss: 0.927\n",
            "[71,     4] loss: 0.942\n",
            "[72,     4] loss: 0.934\n",
            "[73,     4] loss: 0.923\n",
            "[74,     4] loss: 0.926\n",
            "[75,     4] loss: 0.930\n",
            "[76,     4] loss: 0.921\n",
            "[77,     4] loss: 0.913\n",
            "[78,     4] loss: 0.927\n",
            "[79,     4] loss: 0.918\n",
            "[80,     4] loss: 0.922\n",
            "[81,     4] loss: 0.916\n",
            "[82,     4] loss: 0.926\n",
            "[83,     4] loss: 0.914\n",
            "[84,     4] loss: 0.910\n",
            "[85,     4] loss: 0.916\n",
            "[86,     4] loss: 0.909\n",
            "[87,     4] loss: 0.919\n",
            "[88,     4] loss: 0.924\n",
            "[89,     4] loss: 0.928\n",
            "[90,     4] loss: 0.913\n",
            "[91,     4] loss: 0.919\n",
            "[92,     4] loss: 0.910\n",
            "[93,     4] loss: 0.909\n",
            "[94,     4] loss: 0.915\n",
            "[95,     4] loss: 0.921\n",
            "[96,     4] loss: 0.925\n",
            "[97,     4] loss: 0.923\n",
            "[98,     4] loss: 0.929\n",
            "[99,     4] loss: 0.919\n",
            "[100,     4] loss: 0.930\n",
            "[101,     4] loss: 0.915\n",
            "[102,     4] loss: 0.914\n",
            "[103,     4] loss: 0.926\n",
            "[104,     4] loss: 0.916\n",
            "[105,     4] loss: 0.927\n",
            "[106,     4] loss: 0.931\n",
            "[107,     4] loss: 0.916\n",
            "[108,     4] loss: 0.925\n",
            "[109,     4] loss: 0.909\n",
            "[110,     4] loss: 0.911\n",
            "[111,     4] loss: 0.922\n",
            "[112,     4] loss: 0.912\n",
            "[113,     4] loss: 0.913\n",
            "[114,     4] loss: 0.910\n",
            "[115,     4] loss: 0.909\n",
            "[116,     4] loss: 0.926\n",
            "[117,     4] loss: 0.918\n",
            "[118,     4] loss: 0.910\n",
            "[119,     4] loss: 0.911\n",
            "[120,     4] loss: 0.934\n",
            "[121,     4] loss: 0.925\n",
            "[122,     4] loss: 0.922\n",
            "[123,     4] loss: 0.914\n",
            "[124,     4] loss: 0.923\n",
            "[125,     4] loss: 0.914\n",
            "[126,     4] loss: 0.905\n",
            "[127,     4] loss: 0.912\n",
            "[128,     4] loss: 0.906\n",
            "[129,     4] loss: 0.931\n",
            "[130,     4] loss: 0.911\n",
            "[131,     4] loss: 0.911\n",
            "[132,     4] loss: 0.917\n",
            "[133,     4] loss: 0.916\n",
            "[134,     4] loss: 0.921\n",
            "[135,     4] loss: 0.902\n",
            "[136,     4] loss: 0.894\n",
            "[137,     4] loss: 0.920\n",
            "[138,     4] loss: 0.911\n",
            "[139,     4] loss: 0.903\n",
            "[140,     4] loss: 0.915\n",
            "[141,     4] loss: 0.920\n",
            "[142,     4] loss: 0.900\n",
            "[143,     4] loss: 0.917\n",
            "[144,     4] loss: 0.904\n",
            "[145,     4] loss: 0.925\n",
            "[146,     4] loss: 0.914\n",
            "[147,     4] loss: 0.922\n",
            "[148,     4] loss: 0.922\n",
            "[149,     4] loss: 0.912\n",
            "[150,     4] loss: 0.917\n",
            "[151,     4] loss: 0.911\n",
            "[152,     4] loss: 0.922\n",
            "[153,     4] loss: 0.918\n",
            "[154,     4] loss: 0.918\n",
            "[155,     4] loss: 0.909\n",
            "[156,     4] loss: 0.917\n",
            "[157,     4] loss: 0.907\n",
            "[158,     4] loss: 0.910\n",
            "[159,     4] loss: 0.918\n",
            "[160,     4] loss: 0.907\n",
            "[161,     4] loss: 0.923\n",
            "[162,     4] loss: 0.907\n",
            "[163,     4] loss: 0.921\n",
            "[164,     4] loss: 0.911\n",
            "[165,     4] loss: 0.915\n",
            "[166,     4] loss: 0.908\n",
            "[167,     4] loss: 0.916\n",
            "[168,     4] loss: 0.922\n",
            "[169,     4] loss: 0.908\n",
            "[170,     4] loss: 0.917\n",
            "[171,     4] loss: 0.902\n",
            "[172,     4] loss: 0.908\n",
            "[173,     4] loss: 0.905\n",
            "[174,     4] loss: 0.907\n",
            "[175,     4] loss: 0.908\n",
            "[176,     4] loss: 0.917\n",
            "[177,     4] loss: 0.912\n",
            "[178,     4] loss: 0.914\n",
            "[179,     4] loss: 0.923\n",
            "[180,     4] loss: 0.903\n",
            "[181,     4] loss: 0.916\n",
            "[182,     4] loss: 0.912\n",
            "[183,     4] loss: 0.920\n",
            "[184,     4] loss: 0.905\n",
            "[185,     4] loss: 0.915\n",
            "[186,     4] loss: 0.911\n",
            "[187,     4] loss: 0.907\n",
            "[188,     4] loss: 0.908\n",
            "[189,     4] loss: 0.901\n",
            "[190,     4] loss: 0.894\n",
            "[191,     4] loss: 0.915\n",
            "[192,     4] loss: 0.900\n",
            "[193,     4] loss: 0.915\n",
            "[194,     4] loss: 0.921\n",
            "[195,     4] loss: 0.905\n",
            "[196,     4] loss: 0.920\n",
            "[197,     4] loss: 0.907\n",
            "[198,     4] loss: 0.910\n",
            "[199,     4] loss: 0.916\n",
            "[200,     4] loss: 0.918\n",
            "[201,     4] loss: 0.915\n",
            "[202,     4] loss: 0.895\n",
            "[203,     4] loss: 0.920\n",
            "[204,     4] loss: 0.907\n",
            "[205,     4] loss: 0.922\n",
            "[206,     4] loss: 0.917\n",
            "[207,     4] loss: 0.901\n",
            "[208,     4] loss: 0.929\n",
            "[209,     4] loss: 0.913\n",
            "[210,     4] loss: 0.915\n",
            "[211,     4] loss: 0.911\n",
            "[212,     4] loss: 0.910\n",
            "[213,     4] loss: 0.902\n",
            "[214,     4] loss: 0.912\n",
            "[215,     4] loss: 0.909\n",
            "[216,     4] loss: 0.902\n",
            "[217,     4] loss: 0.910\n",
            "[218,     4] loss: 0.916\n",
            "[219,     4] loss: 0.923\n",
            "[220,     4] loss: 0.928\n",
            "[221,     4] loss: 0.915\n",
            "[222,     4] loss: 0.913\n",
            "[223,     4] loss: 0.907\n",
            "[224,     4] loss: 0.896\n",
            "[225,     4] loss: 0.905\n",
            "[226,     4] loss: 0.909\n",
            "[227,     4] loss: 0.913\n",
            "[228,     4] loss: 0.901\n",
            "[229,     4] loss: 0.908\n",
            "[230,     4] loss: 0.917\n",
            "[231,     4] loss: 0.912\n",
            "[232,     4] loss: 0.906\n",
            "[233,     4] loss: 0.908\n",
            "[234,     4] loss: 0.898\n",
            "[235,     4] loss: 0.908\n",
            "[236,     4] loss: 0.921\n",
            "[237,     4] loss: 0.913\n",
            "[238,     4] loss: 0.912\n",
            "[239,     4] loss: 0.914\n",
            "[240,     4] loss: 0.906\n",
            "[241,     4] loss: 0.903\n",
            "[242,     4] loss: 0.901\n",
            "[243,     4] loss: 0.895\n",
            "[244,     4] loss: 0.909\n",
            "[245,     4] loss: 0.907\n",
            "[246,     4] loss: 0.906\n",
            "[247,     4] loss: 0.902\n",
            "[248,     4] loss: 0.920\n",
            "[249,     4] loss: 0.913\n",
            "[250,     4] loss: 0.923\n",
            "[251,     4] loss: 0.902\n",
            "[252,     4] loss: 0.906\n",
            "[253,     4] loss: 0.910\n",
            "[254,     4] loss: 0.906\n",
            "[255,     4] loss: 0.911\n",
            "[256,     4] loss: 0.904\n",
            "[257,     4] loss: 0.912\n",
            "[258,     4] loss: 0.902\n",
            "[259,     4] loss: 0.925\n",
            "[260,     4] loss: 0.899\n",
            "[261,     4] loss: 0.912\n",
            "[262,     4] loss: 0.901\n",
            "[263,     4] loss: 0.905\n",
            "[264,     4] loss: 0.898\n",
            "[265,     4] loss: 0.916\n",
            "[266,     4] loss: 0.896\n",
            "[267,     4] loss: 0.904\n",
            "[268,     4] loss: 0.908\n",
            "[269,     4] loss: 0.911\n",
            "[270,     4] loss: 0.912\n",
            "[271,     4] loss: 0.916\n",
            "[272,     4] loss: 0.908\n",
            "[273,     4] loss: 0.917\n",
            "[274,     4] loss: 0.905\n",
            "[275,     4] loss: 0.909\n",
            "[276,     4] loss: 0.920\n",
            "[277,     4] loss: 0.907\n",
            "[278,     4] loss: 0.902\n",
            "[279,     4] loss: 0.917\n",
            "[280,     4] loss: 0.916\n",
            "[281,     4] loss: 0.922\n",
            "[282,     4] loss: 0.910\n",
            "[283,     4] loss: 0.899\n",
            "[284,     4] loss: 0.911\n",
            "[285,     4] loss: 0.914\n",
            "[286,     4] loss: 0.912\n",
            "[287,     4] loss: 0.912\n",
            "[288,     4] loss: 0.896\n",
            "[289,     4] loss: 0.913\n",
            "[290,     4] loss: 0.912\n",
            "[291,     4] loss: 0.911\n",
            "[292,     4] loss: 0.903\n",
            "[293,     4] loss: 0.909\n",
            "[294,     4] loss: 0.901\n",
            "[295,     4] loss: 0.904\n",
            "[296,     4] loss: 0.904\n",
            "[297,     4] loss: 0.920\n",
            "[298,     4] loss: 0.914\n",
            "[299,     4] loss: 0.917\n",
            "[300,     4] loss: 0.903\n",
            "[301,     4] loss: 0.893\n",
            "[302,     4] loss: 0.907\n",
            "[303,     4] loss: 0.917\n",
            "[304,     4] loss: 0.914\n",
            "[305,     4] loss: 0.922\n",
            "[306,     4] loss: 0.907\n",
            "[307,     4] loss: 0.914\n",
            "[308,     4] loss: 0.892\n",
            "[309,     4] loss: 0.909\n",
            "[310,     4] loss: 0.907\n",
            "[311,     4] loss: 0.907\n",
            "[312,     4] loss: 0.903\n",
            "[313,     4] loss: 0.905\n",
            "[314,     4] loss: 0.922\n",
            "[315,     4] loss: 0.911\n",
            "[316,     4] loss: 0.900\n",
            "[317,     4] loss: 0.893\n",
            "[318,     4] loss: 0.891\n",
            "[319,     4] loss: 0.912\n",
            "[320,     4] loss: 0.901\n",
            "[321,     4] loss: 0.907\n",
            "[322,     4] loss: 0.903\n",
            "[323,     4] loss: 0.906\n",
            "[324,     4] loss: 0.902\n",
            "[325,     4] loss: 0.895\n",
            "[326,     4] loss: 0.926\n",
            "[327,     4] loss: 0.909\n",
            "[328,     4] loss: 0.927\n",
            "[329,     4] loss: 0.898\n",
            "[330,     4] loss: 0.900\n",
            "[331,     4] loss: 0.901\n",
            "[332,     4] loss: 0.897\n",
            "[333,     4] loss: 0.917\n",
            "[334,     4] loss: 0.899\n",
            "[335,     4] loss: 0.912\n",
            "[336,     4] loss: 0.893\n",
            "[337,     4] loss: 0.915\n",
            "[338,     4] loss: 0.916\n",
            "[339,     4] loss: 0.906\n",
            "[340,     4] loss: 0.919\n",
            "[341,     4] loss: 0.922\n",
            "[342,     4] loss: 0.906\n",
            "[343,     4] loss: 0.906\n",
            "[344,     4] loss: 0.905\n",
            "[345,     4] loss: 0.923\n",
            "[346,     4] loss: 0.926\n",
            "[347,     4] loss: 0.911\n",
            "[348,     4] loss: 0.902\n",
            "[349,     4] loss: 0.911\n",
            "[350,     4] loss: 0.905\n",
            "[351,     4] loss: 0.900\n",
            "[352,     4] loss: 0.904\n",
            "[353,     4] loss: 0.918\n",
            "[354,     4] loss: 0.903\n",
            "[355,     4] loss: 0.904\n",
            "[356,     4] loss: 0.908\n",
            "[357,     4] loss: 0.914\n",
            "[358,     4] loss: 0.919\n",
            "[359,     4] loss: 0.906\n",
            "[360,     4] loss: 0.919\n",
            "[361,     4] loss: 0.914\n",
            "[362,     4] loss: 0.906\n",
            "[363,     4] loss: 0.919\n",
            "[364,     4] loss: 0.903\n",
            "[365,     4] loss: 0.917\n",
            "[366,     4] loss: 0.884\n",
            "[367,     4] loss: 0.912\n",
            "[368,     4] loss: 0.909\n",
            "[369,     4] loss: 0.907\n",
            "[370,     4] loss: 0.912\n",
            "[371,     4] loss: 0.909\n",
            "[372,     4] loss: 0.902\n",
            "[373,     4] loss: 0.913\n",
            "[374,     4] loss: 0.904\n",
            "[375,     4] loss: 0.905\n",
            "[376,     4] loss: 0.901\n",
            "[377,     4] loss: 0.905\n",
            "[378,     4] loss: 0.905\n",
            "[379,     4] loss: 0.904\n",
            "[380,     4] loss: 0.910\n",
            "[381,     4] loss: 0.903\n",
            "[382,     4] loss: 0.906\n",
            "[383,     4] loss: 0.907\n",
            "[384,     4] loss: 0.900\n",
            "[385,     4] loss: 0.911\n",
            "[386,     4] loss: 0.900\n",
            "[387,     4] loss: 0.900\n",
            "[388,     4] loss: 0.908\n",
            "[389,     4] loss: 0.906\n",
            "[390,     4] loss: 0.896\n",
            "[391,     4] loss: 0.901\n",
            "[392,     4] loss: 0.913\n",
            "[393,     4] loss: 0.902\n",
            "[394,     4] loss: 0.892\n",
            "[395,     4] loss: 0.922\n",
            "[396,     4] loss: 0.914\n",
            "[397,     4] loss: 0.914\n",
            "[398,     4] loss: 0.888\n",
            "[399,     4] loss: 0.913\n",
            "[400,     4] loss: 0.901\n",
            "[401,     4] loss: 0.912\n",
            "[402,     4] loss: 0.899\n",
            "[403,     4] loss: 0.893\n",
            "[404,     4] loss: 0.896\n",
            "[405,     4] loss: 0.915\n",
            "[406,     4] loss: 0.895\n",
            "[407,     4] loss: 0.918\n",
            "[408,     4] loss: 0.908\n",
            "[409,     4] loss: 0.900\n",
            "[410,     4] loss: 0.906\n",
            "[411,     4] loss: 0.903\n",
            "[412,     4] loss: 0.908\n",
            "[413,     4] loss: 0.906\n",
            "[414,     4] loss: 0.897\n",
            "[415,     4] loss: 0.895\n",
            "[416,     4] loss: 0.919\n",
            "[417,     4] loss: 0.923\n",
            "[418,     4] loss: 0.917\n",
            "[419,     4] loss: 0.903\n",
            "[420,     4] loss: 0.911\n",
            "[421,     4] loss: 0.891\n",
            "[422,     4] loss: 0.897\n",
            "[423,     4] loss: 0.884\n",
            "[424,     4] loss: 0.905\n",
            "[425,     4] loss: 0.905\n",
            "[426,     4] loss: 0.898\n",
            "[427,     4] loss: 0.905\n",
            "[428,     4] loss: 0.913\n",
            "[429,     4] loss: 0.915\n",
            "[430,     4] loss: 0.916\n",
            "[431,     4] loss: 0.914\n",
            "[432,     4] loss: 0.908\n",
            "[433,     4] loss: 0.904\n",
            "[434,     4] loss: 0.905\n",
            "[435,     4] loss: 0.888\n",
            "[436,     4] loss: 0.903\n",
            "[437,     4] loss: 0.894\n",
            "[438,     4] loss: 0.882\n",
            "[439,     4] loss: 0.880\n",
            "[440,     4] loss: 0.897\n",
            "[441,     4] loss: 0.907\n",
            "[442,     4] loss: 0.907\n",
            "[443,     4] loss: 0.902\n",
            "[444,     4] loss: 0.896\n",
            "[445,     4] loss: 0.900\n",
            "[446,     4] loss: 0.882\n",
            "[447,     4] loss: 0.907\n",
            "[448,     4] loss: 0.907\n",
            "[449,     4] loss: 0.897\n",
            "[450,     4] loss: 0.915\n",
            "[451,     4] loss: 0.902\n",
            "[452,     4] loss: 0.913\n",
            "[453,     4] loss: 0.911\n",
            "[454,     4] loss: 0.910\n",
            "[455,     4] loss: 0.888\n",
            "[456,     4] loss: 0.896\n",
            "[457,     4] loss: 0.902\n",
            "[458,     4] loss: 0.889\n",
            "[459,     4] loss: 0.887\n",
            "[460,     4] loss: 0.897\n",
            "[461,     4] loss: 0.889\n",
            "[462,     4] loss: 0.899\n",
            "[463,     4] loss: 0.908\n",
            "[464,     4] loss: 0.902\n",
            "[465,     4] loss: 0.910\n",
            "[466,     4] loss: 0.906\n",
            "[467,     4] loss: 0.898\n",
            "[468,     4] loss: 0.902\n",
            "[469,     4] loss: 0.902\n",
            "[470,     4] loss: 0.908\n",
            "[471,     4] loss: 0.889\n",
            "[472,     4] loss: 0.898\n",
            "[473,     4] loss: 0.897\n",
            "[474,     4] loss: 0.914\n",
            "[475,     4] loss: 0.918\n",
            "[476,     4] loss: 0.895\n",
            "[477,     4] loss: 0.912\n",
            "[478,     4] loss: 0.898\n",
            "[479,     4] loss: 0.901\n",
            "[480,     4] loss: 0.906\n",
            "[481,     4] loss: 0.904\n",
            "[482,     4] loss: 0.895\n",
            "[483,     4] loss: 0.904\n",
            "[484,     4] loss: 0.902\n",
            "[485,     4] loss: 0.908\n",
            "[486,     4] loss: 0.888\n",
            "[487,     4] loss: 0.899\n",
            "[488,     4] loss: 0.894\n",
            "[489,     4] loss: 0.901\n",
            "[490,     4] loss: 0.900\n",
            "[491,     4] loss: 0.915\n",
            "[492,     4] loss: 0.890\n",
            "[493,     4] loss: 0.913\n",
            "[494,     4] loss: 0.907\n",
            "[495,     4] loss: 0.909\n",
            "[496,     4] loss: 0.895\n",
            "[497,     4] loss: 0.893\n",
            "[498,     4] loss: 0.906\n",
            "[499,     4] loss: 0.909\n",
            "[500,     4] loss: 0.916\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 53 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 34 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 39 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 53 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 55 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 57 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 59 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 56 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 62 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   5\n",
            "[1,     4] loss: 1.140\n",
            "[2,     4] loss: 0.915\n",
            "[3,     4] loss: 0.876\n",
            "[4,     4] loss: 0.869\n",
            "[5,     4] loss: 0.844\n",
            "[6,     4] loss: 0.831\n",
            "[7,     4] loss: 0.821\n",
            "[8,     4] loss: 0.804\n",
            "[9,     4] loss: 0.818\n",
            "[10,     4] loss: 0.800\n",
            "[11,     4] loss: 0.787\n",
            "[12,     4] loss: 0.795\n",
            "[13,     4] loss: 0.781\n",
            "[14,     4] loss: 0.809\n",
            "[15,     4] loss: 0.833\n",
            "[16,     4] loss: 0.812\n",
            "[17,     4] loss: 0.815\n",
            "[18,     4] loss: 0.810\n",
            "[19,     4] loss: 0.785\n",
            "[20,     4] loss: 0.779\n",
            "[21,     4] loss: 0.784\n",
            "[22,     4] loss: 0.768\n",
            "[23,     4] loss: 0.779\n",
            "[24,     4] loss: 0.783\n",
            "[25,     4] loss: 0.790\n",
            "[26,     4] loss: 0.787\n",
            "[27,     4] loss: 0.786\n",
            "[28,     4] loss: 0.789\n",
            "[29,     4] loss: 0.774\n",
            "[30,     4] loss: 0.772\n",
            "[31,     4] loss: 0.757\n",
            "[32,     4] loss: 0.769\n",
            "[33,     4] loss: 0.774\n",
            "[34,     4] loss: 0.801\n",
            "[35,     4] loss: 0.801\n",
            "[36,     4] loss: 0.809\n",
            "[37,     4] loss: 0.798\n",
            "[38,     4] loss: 0.776\n",
            "[39,     4] loss: 0.778\n",
            "[40,     4] loss: 0.771\n",
            "[41,     4] loss: 0.770\n",
            "[42,     4] loss: 0.740\n",
            "[43,     4] loss: 0.767\n",
            "[44,     4] loss: 0.762\n",
            "[45,     4] loss: 0.773\n",
            "[46,     4] loss: 0.773\n",
            "[47,     4] loss: 0.767\n",
            "[48,     4] loss: 0.758\n",
            "[49,     4] loss: 0.767\n",
            "[50,     4] loss: 0.767\n",
            "[51,     4] loss: 0.779\n",
            "[52,     4] loss: 0.774\n",
            "[53,     4] loss: 0.759\n",
            "[54,     4] loss: 0.763\n",
            "[55,     4] loss: 0.770\n",
            "[56,     4] loss: 0.773\n",
            "[57,     4] loss: 0.761\n",
            "[58,     4] loss: 0.775\n",
            "[59,     4] loss: 0.789\n",
            "[60,     4] loss: 0.783\n",
            "[61,     4] loss: 0.789\n",
            "[62,     4] loss: 0.772\n",
            "[63,     4] loss: 0.766\n",
            "[64,     4] loss: 0.786\n",
            "[65,     4] loss: 0.775\n",
            "[66,     4] loss: 0.779\n",
            "[67,     4] loss: 0.755\n",
            "[68,     4] loss: 0.743\n",
            "[69,     4] loss: 0.774\n",
            "[70,     4] loss: 0.768\n",
            "[71,     4] loss: 0.760\n",
            "[72,     4] loss: 0.757\n",
            "[73,     4] loss: 0.770\n",
            "[74,     4] loss: 0.779\n",
            "[75,     4] loss: 0.759\n",
            "[76,     4] loss: 0.758\n",
            "[77,     4] loss: 0.753\n",
            "[78,     4] loss: 0.768\n",
            "[79,     4] loss: 0.761\n",
            "[80,     4] loss: 0.778\n",
            "[81,     4] loss: 0.779\n",
            "[82,     4] loss: 0.779\n",
            "[83,     4] loss: 0.797\n",
            "[84,     4] loss: 0.782\n",
            "[85,     4] loss: 0.763\n",
            "[86,     4] loss: 0.768\n",
            "[87,     4] loss: 0.773\n",
            "[88,     4] loss: 0.771\n",
            "[89,     4] loss: 0.750\n",
            "[90,     4] loss: 0.765\n",
            "[91,     4] loss: 0.764\n",
            "[92,     4] loss: 0.766\n",
            "[93,     4] loss: 0.770\n",
            "[94,     4] loss: 0.763\n",
            "[95,     4] loss: 0.766\n",
            "[96,     4] loss: 0.764\n",
            "[97,     4] loss: 0.752\n",
            "[98,     4] loss: 0.742\n",
            "[99,     4] loss: 0.790\n",
            "[100,     4] loss: 0.760\n",
            "[101,     4] loss: 0.767\n",
            "[102,     4] loss: 0.757\n",
            "[103,     4] loss: 0.746\n",
            "[104,     4] loss: 0.768\n",
            "[105,     4] loss: 0.762\n",
            "[106,     4] loss: 0.751\n",
            "[107,     4] loss: 0.773\n",
            "[108,     4] loss: 0.764\n",
            "[109,     4] loss: 0.771\n",
            "[110,     4] loss: 0.774\n",
            "[111,     4] loss: 0.758\n",
            "[112,     4] loss: 0.752\n",
            "[113,     4] loss: 0.750\n",
            "[114,     4] loss: 0.743\n",
            "[115,     4] loss: 0.769\n",
            "[116,     4] loss: 0.768\n",
            "[117,     4] loss: 0.767\n",
            "[118,     4] loss: 0.757\n",
            "[119,     4] loss: 0.759\n",
            "[120,     4] loss: 0.761\n",
            "[121,     4] loss: 0.753\n",
            "[122,     4] loss: 0.746\n",
            "[123,     4] loss: 0.748\n",
            "[124,     4] loss: 0.751\n",
            "[125,     4] loss: 0.778\n",
            "[126,     4] loss: 0.746\n",
            "[127,     4] loss: 0.762\n",
            "[128,     4] loss: 0.776\n",
            "[129,     4] loss: 0.781\n",
            "[130,     4] loss: 0.761\n",
            "[131,     4] loss: 0.736\n",
            "[132,     4] loss: 0.744\n",
            "[133,     4] loss: 0.760\n",
            "[134,     4] loss: 0.759\n",
            "[135,     4] loss: 0.750\n",
            "[136,     4] loss: 0.743\n",
            "[137,     4] loss: 0.740\n",
            "[138,     4] loss: 0.752\n",
            "[139,     4] loss: 0.764\n",
            "[140,     4] loss: 0.752\n",
            "[141,     4] loss: 0.771\n",
            "[142,     4] loss: 0.774\n",
            "[143,     4] loss: 0.765\n",
            "[144,     4] loss: 0.783\n",
            "[145,     4] loss: 0.756\n",
            "[146,     4] loss: 0.766\n",
            "[147,     4] loss: 0.754\n",
            "[148,     4] loss: 0.751\n",
            "[149,     4] loss: 0.742\n",
            "[150,     4] loss: 0.737\n",
            "[151,     4] loss: 0.764\n",
            "[152,     4] loss: 0.761\n",
            "[153,     4] loss: 0.761\n",
            "[154,     4] loss: 0.733\n",
            "[155,     4] loss: 0.759\n",
            "[156,     4] loss: 0.733\n",
            "[157,     4] loss: 0.741\n",
            "[158,     4] loss: 0.759\n",
            "[159,     4] loss: 0.735\n",
            "[160,     4] loss: 0.743\n",
            "[161,     4] loss: 0.755\n",
            "[162,     4] loss: 0.750\n",
            "[163,     4] loss: 0.757\n",
            "[164,     4] loss: 0.753\n",
            "[165,     4] loss: 0.768\n",
            "[166,     4] loss: 0.767\n",
            "[167,     4] loss: 0.769\n",
            "[168,     4] loss: 0.754\n",
            "[169,     4] loss: 0.742\n",
            "[170,     4] loss: 0.746\n",
            "[171,     4] loss: 0.764\n",
            "[172,     4] loss: 0.756\n",
            "[173,     4] loss: 0.751\n",
            "[174,     4] loss: 0.764\n",
            "[175,     4] loss: 0.752\n",
            "[176,     4] loss: 0.756\n",
            "[177,     4] loss: 0.768\n",
            "[178,     4] loss: 0.786\n",
            "[179,     4] loss: 0.758\n",
            "[180,     4] loss: 0.768\n",
            "[181,     4] loss: 0.759\n",
            "[182,     4] loss: 0.783\n",
            "[183,     4] loss: 0.771\n",
            "[184,     4] loss: 0.763\n",
            "[185,     4] loss: 0.758\n",
            "[186,     4] loss: 0.748\n",
            "[187,     4] loss: 0.749\n",
            "[188,     4] loss: 0.759\n",
            "[189,     4] loss: 0.761\n",
            "[190,     4] loss: 0.753\n",
            "[191,     4] loss: 0.758\n",
            "[192,     4] loss: 0.771\n",
            "[193,     4] loss: 0.750\n",
            "[194,     4] loss: 0.747\n",
            "[195,     4] loss: 0.741\n",
            "[196,     4] loss: 0.763\n",
            "[197,     4] loss: 0.759\n",
            "[198,     4] loss: 0.765\n",
            "[199,     4] loss: 0.760\n",
            "[200,     4] loss: 0.767\n",
            "[201,     4] loss: 0.756\n",
            "[202,     4] loss: 0.754\n",
            "[203,     4] loss: 0.740\n",
            "[204,     4] loss: 0.753\n",
            "[205,     4] loss: 0.747\n",
            "[206,     4] loss: 0.731\n",
            "[207,     4] loss: 0.759\n",
            "[208,     4] loss: 0.765\n",
            "[209,     4] loss: 0.749\n",
            "[210,     4] loss: 0.771\n",
            "[211,     4] loss: 0.744\n",
            "[212,     4] loss: 0.753\n",
            "[213,     4] loss: 0.754\n",
            "[214,     4] loss: 0.754\n",
            "[215,     4] loss: 0.755\n",
            "[216,     4] loss: 0.758\n",
            "[217,     4] loss: 0.756\n",
            "[218,     4] loss: 0.758\n",
            "[219,     4] loss: 0.769\n",
            "[220,     4] loss: 0.754\n",
            "[221,     4] loss: 0.751\n",
            "[222,     4] loss: 0.770\n",
            "[223,     4] loss: 0.758\n",
            "[224,     4] loss: 0.746\n",
            "[225,     4] loss: 0.751\n",
            "[226,     4] loss: 0.733\n",
            "[227,     4] loss: 0.753\n",
            "[228,     4] loss: 0.735\n",
            "[229,     4] loss: 0.748\n",
            "[230,     4] loss: 0.745\n",
            "[231,     4] loss: 0.746\n",
            "[232,     4] loss: 0.743\n",
            "[233,     4] loss: 0.766\n",
            "[234,     4] loss: 0.740\n",
            "[235,     4] loss: 0.748\n",
            "[236,     4] loss: 0.766\n",
            "[237,     4] loss: 0.746\n",
            "[238,     4] loss: 0.765\n",
            "[239,     4] loss: 0.750\n",
            "[240,     4] loss: 0.741\n",
            "[241,     4] loss: 0.749\n",
            "[242,     4] loss: 0.756\n",
            "[243,     4] loss: 0.759\n",
            "[244,     4] loss: 0.751\n",
            "[245,     4] loss: 0.742\n",
            "[246,     4] loss: 0.749\n",
            "[247,     4] loss: 0.749\n",
            "[248,     4] loss: 0.742\n",
            "[249,     4] loss: 0.749\n",
            "[250,     4] loss: 0.777\n",
            "[251,     4] loss: 0.772\n",
            "[252,     4] loss: 0.756\n",
            "[253,     4] loss: 0.741\n",
            "[254,     4] loss: 0.758\n",
            "[255,     4] loss: 0.751\n",
            "[256,     4] loss: 0.764\n",
            "[257,     4] loss: 0.748\n",
            "[258,     4] loss: 0.750\n",
            "[259,     4] loss: 0.765\n",
            "[260,     4] loss: 0.738\n",
            "[261,     4] loss: 0.747\n",
            "[262,     4] loss: 0.742\n",
            "[263,     4] loss: 0.765\n",
            "[264,     4] loss: 0.744\n",
            "[265,     4] loss: 0.746\n",
            "[266,     4] loss: 0.749\n",
            "[267,     4] loss: 0.759\n",
            "[268,     4] loss: 0.738\n",
            "[269,     4] loss: 0.752\n",
            "[270,     4] loss: 0.758\n",
            "[271,     4] loss: 0.746\n",
            "[272,     4] loss: 0.761\n",
            "[273,     4] loss: 0.764\n",
            "[274,     4] loss: 0.747\n",
            "[275,     4] loss: 0.739\n",
            "[276,     4] loss: 0.755\n",
            "[277,     4] loss: 0.748\n",
            "[278,     4] loss: 0.765\n",
            "[279,     4] loss: 0.745\n",
            "[280,     4] loss: 0.755\n",
            "[281,     4] loss: 0.751\n",
            "[282,     4] loss: 0.744\n",
            "[283,     4] loss: 0.752\n",
            "[284,     4] loss: 0.743\n",
            "[285,     4] loss: 0.738\n",
            "[286,     4] loss: 0.755\n",
            "[287,     4] loss: 0.754\n",
            "[288,     4] loss: 0.754\n",
            "[289,     4] loss: 0.765\n",
            "[290,     4] loss: 0.769\n",
            "[291,     4] loss: 0.757\n",
            "[292,     4] loss: 0.742\n",
            "[293,     4] loss: 0.729\n",
            "[294,     4] loss: 0.763\n",
            "[295,     4] loss: 0.749\n",
            "[296,     4] loss: 0.752\n",
            "[297,     4] loss: 0.724\n",
            "[298,     4] loss: 0.732\n",
            "[299,     4] loss: 0.754\n",
            "[300,     4] loss: 0.749\n",
            "[301,     4] loss: 0.743\n",
            "[302,     4] loss: 0.741\n",
            "[303,     4] loss: 0.749\n",
            "[304,     4] loss: 0.736\n",
            "[305,     4] loss: 0.742\n",
            "[306,     4] loss: 0.746\n",
            "[307,     4] loss: 0.743\n",
            "[308,     4] loss: 0.744\n",
            "[309,     4] loss: 0.753\n",
            "[310,     4] loss: 0.744\n",
            "[311,     4] loss: 0.735\n",
            "[312,     4] loss: 0.727\n",
            "[313,     4] loss: 0.755\n",
            "[314,     4] loss: 0.751\n",
            "[315,     4] loss: 0.742\n",
            "[316,     4] loss: 0.750\n",
            "[317,     4] loss: 0.744\n",
            "[318,     4] loss: 0.731\n",
            "[319,     4] loss: 0.758\n",
            "[320,     4] loss: 0.742\n",
            "[321,     4] loss: 0.730\n",
            "[322,     4] loss: 0.754\n",
            "[323,     4] loss: 0.756\n",
            "[324,     4] loss: 0.756\n",
            "[325,     4] loss: 0.760\n",
            "[326,     4] loss: 0.736\n",
            "[327,     4] loss: 0.739\n",
            "[328,     4] loss: 0.745\n",
            "[329,     4] loss: 0.759\n",
            "[330,     4] loss: 0.767\n",
            "[331,     4] loss: 0.750\n",
            "[332,     4] loss: 0.758\n",
            "[333,     4] loss: 0.744\n",
            "[334,     4] loss: 0.763\n",
            "[335,     4] loss: 0.757\n",
            "[336,     4] loss: 0.759\n",
            "[337,     4] loss: 0.744\n",
            "[338,     4] loss: 0.762\n",
            "[339,     4] loss: 0.749\n",
            "[340,     4] loss: 0.759\n",
            "[341,     4] loss: 0.767\n",
            "[342,     4] loss: 0.741\n",
            "[343,     4] loss: 0.762\n",
            "[344,     4] loss: 0.745\n",
            "[345,     4] loss: 0.741\n",
            "[346,     4] loss: 0.727\n",
            "[347,     4] loss: 0.741\n",
            "[348,     4] loss: 0.750\n",
            "[349,     4] loss: 0.744\n",
            "[350,     4] loss: 0.752\n",
            "[351,     4] loss: 0.750\n",
            "[352,     4] loss: 0.731\n",
            "[353,     4] loss: 0.737\n",
            "[354,     4] loss: 0.736\n",
            "[355,     4] loss: 0.742\n",
            "[356,     4] loss: 0.757\n",
            "[357,     4] loss: 0.759\n",
            "[358,     4] loss: 0.759\n",
            "[359,     4] loss: 0.735\n",
            "[360,     4] loss: 0.743\n",
            "[361,     4] loss: 0.733\n",
            "[362,     4] loss: 0.734\n",
            "[363,     4] loss: 0.740\n",
            "[364,     4] loss: 0.716\n",
            "[365,     4] loss: 0.736\n",
            "[366,     4] loss: 0.752\n",
            "[367,     4] loss: 0.752\n",
            "[368,     4] loss: 0.758\n",
            "[369,     4] loss: 0.741\n",
            "[370,     4] loss: 0.752\n",
            "[371,     4] loss: 0.744\n",
            "[372,     4] loss: 0.750\n",
            "[373,     4] loss: 0.731\n",
            "[374,     4] loss: 0.742\n",
            "[375,     4] loss: 0.750\n",
            "[376,     4] loss: 0.767\n",
            "[377,     4] loss: 0.756\n",
            "[378,     4] loss: 0.745\n",
            "[379,     4] loss: 0.727\n",
            "[380,     4] loss: 0.747\n",
            "[381,     4] loss: 0.754\n",
            "[382,     4] loss: 0.747\n",
            "[383,     4] loss: 0.740\n",
            "[384,     4] loss: 0.762\n",
            "[385,     4] loss: 0.717\n",
            "[386,     4] loss: 0.728\n",
            "[387,     4] loss: 0.739\n",
            "[388,     4] loss: 0.749\n",
            "[389,     4] loss: 0.730\n",
            "[390,     4] loss: 0.752\n",
            "[391,     4] loss: 0.731\n",
            "[392,     4] loss: 0.744\n",
            "[393,     4] loss: 0.746\n",
            "[394,     4] loss: 0.735\n",
            "[395,     4] loss: 0.735\n",
            "[396,     4] loss: 0.749\n",
            "[397,     4] loss: 0.744\n",
            "[398,     4] loss: 0.748\n",
            "[399,     4] loss: 0.741\n",
            "[400,     4] loss: 0.748\n",
            "[401,     4] loss: 0.743\n",
            "[402,     4] loss: 0.763\n",
            "[403,     4] loss: 0.744\n",
            "[404,     4] loss: 0.740\n",
            "[405,     4] loss: 0.749\n",
            "[406,     4] loss: 0.736\n",
            "[407,     4] loss: 0.754\n",
            "[408,     4] loss: 0.745\n",
            "[409,     4] loss: 0.754\n",
            "[410,     4] loss: 0.745\n",
            "[411,     4] loss: 0.739\n",
            "[412,     4] loss: 0.759\n",
            "[413,     4] loss: 0.736\n",
            "[414,     4] loss: 0.749\n",
            "[415,     4] loss: 0.754\n",
            "[416,     4] loss: 0.751\n",
            "[417,     4] loss: 0.747\n",
            "[418,     4] loss: 0.748\n",
            "[419,     4] loss: 0.745\n",
            "[420,     4] loss: 0.718\n",
            "[421,     4] loss: 0.749\n",
            "[422,     4] loss: 0.759\n",
            "[423,     4] loss: 0.752\n",
            "[424,     4] loss: 0.744\n",
            "[425,     4] loss: 0.734\n",
            "[426,     4] loss: 0.745\n",
            "[427,     4] loss: 0.736\n",
            "[428,     4] loss: 0.758\n",
            "[429,     4] loss: 0.760\n",
            "[430,     4] loss: 0.743\n",
            "[431,     4] loss: 0.730\n",
            "[432,     4] loss: 0.761\n",
            "[433,     4] loss: 0.749\n",
            "[434,     4] loss: 0.741\n",
            "[435,     4] loss: 0.754\n",
            "[436,     4] loss: 0.745\n",
            "[437,     4] loss: 0.751\n",
            "[438,     4] loss: 0.758\n",
            "[439,     4] loss: 0.746\n",
            "[440,     4] loss: 0.739\n",
            "[441,     4] loss: 0.750\n",
            "[442,     4] loss: 0.753\n",
            "[443,     4] loss: 0.738\n",
            "[444,     4] loss: 0.739\n",
            "[445,     4] loss: 0.728\n",
            "[446,     4] loss: 0.756\n",
            "[447,     4] loss: 0.732\n",
            "[448,     4] loss: 0.759\n",
            "[449,     4] loss: 0.733\n",
            "[450,     4] loss: 0.749\n",
            "[451,     4] loss: 0.756\n",
            "[452,     4] loss: 0.745\n",
            "[453,     4] loss: 0.747\n",
            "[454,     4] loss: 0.763\n",
            "[455,     4] loss: 0.767\n",
            "[456,     4] loss: 0.767\n",
            "[457,     4] loss: 0.746\n",
            "[458,     4] loss: 0.741\n",
            "[459,     4] loss: 0.742\n",
            "[460,     4] loss: 0.753\n",
            "[461,     4] loss: 0.767\n",
            "[462,     4] loss: 0.746\n",
            "[463,     4] loss: 0.732\n",
            "[464,     4] loss: 0.724\n",
            "[465,     4] loss: 0.749\n",
            "[466,     4] loss: 0.734\n",
            "[467,     4] loss: 0.751\n",
            "[468,     4] loss: 0.741\n",
            "[469,     4] loss: 0.736\n",
            "[470,     4] loss: 0.738\n",
            "[471,     4] loss: 0.743\n",
            "[472,     4] loss: 0.759\n",
            "[473,     4] loss: 0.757\n",
            "[474,     4] loss: 0.738\n",
            "[475,     4] loss: 0.751\n",
            "[476,     4] loss: 0.743\n",
            "[477,     4] loss: 0.740\n",
            "[478,     4] loss: 0.741\n",
            "[479,     4] loss: 0.771\n",
            "[480,     4] loss: 0.756\n",
            "[481,     4] loss: 0.738\n",
            "[482,     4] loss: 0.730\n",
            "[483,     4] loss: 0.744\n",
            "[484,     4] loss: 0.757\n",
            "[485,     4] loss: 0.733\n",
            "[486,     4] loss: 0.744\n",
            "[487,     4] loss: 0.761\n",
            "[488,     4] loss: 0.729\n",
            "[489,     4] loss: 0.732\n",
            "[490,     4] loss: 0.738\n",
            "[491,     4] loss: 0.745\n",
            "[492,     4] loss: 0.737\n",
            "[493,     4] loss: 0.749\n",
            "[494,     4] loss: 0.756\n",
            "[495,     4] loss: 0.746\n",
            "[496,     4] loss: 0.740\n",
            "[497,     4] loss: 0.739\n",
            "[498,     4] loss: 0.740\n",
            "[499,     4] loss: 0.733\n",
            "[500,     4] loss: 0.722\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 38 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 42 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 48 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 63 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 70 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 69 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 65 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 62 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   6\n",
            "[1,     4] loss: 1.124\n",
            "[2,     4] loss: 0.807\n",
            "[3,     4] loss: 0.730\n",
            "[4,     4] loss: 0.678\n",
            "[5,     4] loss: 0.668\n",
            "[6,     4] loss: 0.660\n",
            "[7,     4] loss: 0.639\n",
            "[8,     4] loss: 0.631\n",
            "[9,     4] loss: 0.625\n",
            "[10,     4] loss: 0.632\n",
            "[11,     4] loss: 0.638\n",
            "[12,     4] loss: 0.621\n",
            "[13,     4] loss: 0.616\n",
            "[14,     4] loss: 0.591\n",
            "[15,     4] loss: 0.570\n",
            "[16,     4] loss: 0.565\n",
            "[17,     4] loss: 0.542\n",
            "[18,     4] loss: 0.552\n",
            "[19,     4] loss: 0.565\n",
            "[20,     4] loss: 0.564\n",
            "[21,     4] loss: 0.551\n",
            "[22,     4] loss: 0.569\n",
            "[23,     4] loss: 0.544\n",
            "[24,     4] loss: 0.498\n",
            "[25,     4] loss: 0.515\n",
            "[26,     4] loss: 0.526\n",
            "[27,     4] loss: 0.522\n",
            "[28,     4] loss: 0.571\n",
            "[29,     4] loss: 0.568\n",
            "[30,     4] loss: 0.528\n",
            "[31,     4] loss: 0.519\n",
            "[32,     4] loss: 0.496\n",
            "[33,     4] loss: 0.504\n",
            "[34,     4] loss: 0.527\n",
            "[35,     4] loss: 0.509\n",
            "[36,     4] loss: 0.495\n",
            "[37,     4] loss: 0.488\n",
            "[38,     4] loss: 0.495\n",
            "[39,     4] loss: 0.491\n",
            "[40,     4] loss: 0.492\n",
            "[41,     4] loss: 0.507\n",
            "[42,     4] loss: 0.506\n",
            "[43,     4] loss: 0.494\n",
            "[44,     4] loss: 0.511\n",
            "[45,     4] loss: 0.510\n",
            "[46,     4] loss: 0.580\n",
            "[47,     4] loss: 0.541\n",
            "[48,     4] loss: 0.531\n",
            "[49,     4] loss: 0.501\n",
            "[50,     4] loss: 0.481\n",
            "[51,     4] loss: 0.501\n",
            "[52,     4] loss: 0.495\n",
            "[53,     4] loss: 0.513\n",
            "[54,     4] loss: 0.511\n",
            "[55,     4] loss: 0.517\n",
            "[56,     4] loss: 0.508\n",
            "[57,     4] loss: 0.504\n",
            "[58,     4] loss: 0.504\n",
            "[59,     4] loss: 0.502\n",
            "[60,     4] loss: 0.495\n",
            "[61,     4] loss: 0.491\n",
            "[62,     4] loss: 0.489\n",
            "[63,     4] loss: 0.504\n",
            "[64,     4] loss: 0.524\n",
            "[65,     4] loss: 0.498\n",
            "[66,     4] loss: 0.508\n",
            "[67,     4] loss: 0.504\n",
            "[68,     4] loss: 0.516\n",
            "[69,     4] loss: 0.499\n",
            "[70,     4] loss: 0.490\n",
            "[71,     4] loss: 0.511\n",
            "[72,     4] loss: 0.520\n",
            "[73,     4] loss: 0.520\n",
            "[74,     4] loss: 0.503\n",
            "[75,     4] loss: 0.488\n",
            "[76,     4] loss: 0.493\n",
            "[77,     4] loss: 0.484\n",
            "[78,     4] loss: 0.495\n",
            "[79,     4] loss: 0.514\n",
            "[80,     4] loss: 0.512\n",
            "[81,     4] loss: 0.531\n",
            "[82,     4] loss: 0.498\n",
            "[83,     4] loss: 0.489\n",
            "[84,     4] loss: 0.510\n",
            "[85,     4] loss: 0.487\n",
            "[86,     4] loss: 0.500\n",
            "[87,     4] loss: 0.493\n",
            "[88,     4] loss: 0.499\n",
            "[89,     4] loss: 0.499\n",
            "[90,     4] loss: 0.501\n",
            "[91,     4] loss: 0.489\n",
            "[92,     4] loss: 0.507\n",
            "[93,     4] loss: 0.493\n",
            "[94,     4] loss: 0.485\n",
            "[95,     4] loss: 0.502\n",
            "[96,     4] loss: 0.503\n",
            "[97,     4] loss: 0.482\n",
            "[98,     4] loss: 0.483\n",
            "[99,     4] loss: 0.515\n",
            "[100,     4] loss: 0.499\n",
            "[101,     4] loss: 0.504\n",
            "[102,     4] loss: 0.497\n",
            "[103,     4] loss: 0.523\n",
            "[104,     4] loss: 0.492\n",
            "[105,     4] loss: 0.498\n",
            "[106,     4] loss: 0.504\n",
            "[107,     4] loss: 0.481\n",
            "[108,     4] loss: 0.505\n",
            "[109,     4] loss: 0.483\n",
            "[110,     4] loss: 0.497\n",
            "[111,     4] loss: 0.497\n",
            "[112,     4] loss: 0.494\n",
            "[113,     4] loss: 0.484\n",
            "[114,     4] loss: 0.493\n",
            "[115,     4] loss: 0.493\n",
            "[116,     4] loss: 0.491\n",
            "[117,     4] loss: 0.514\n",
            "[118,     4] loss: 0.494\n",
            "[119,     4] loss: 0.516\n",
            "[120,     4] loss: 0.487\n",
            "[121,     4] loss: 0.504\n",
            "[122,     4] loss: 0.488\n",
            "[123,     4] loss: 0.482\n",
            "[124,     4] loss: 0.507\n",
            "[125,     4] loss: 0.512\n",
            "[126,     4] loss: 0.515\n",
            "[127,     4] loss: 0.509\n",
            "[128,     4] loss: 0.519\n",
            "[129,     4] loss: 0.516\n",
            "[130,     4] loss: 0.493\n",
            "[131,     4] loss: 0.500\n",
            "[132,     4] loss: 0.500\n",
            "[133,     4] loss: 0.481\n",
            "[134,     4] loss: 0.498\n",
            "[135,     4] loss: 0.477\n",
            "[136,     4] loss: 0.496\n",
            "[137,     4] loss: 0.499\n",
            "[138,     4] loss: 0.494\n",
            "[139,     4] loss: 0.472\n",
            "[140,     4] loss: 0.473\n",
            "[141,     4] loss: 0.485\n",
            "[142,     4] loss: 0.487\n",
            "[143,     4] loss: 0.507\n",
            "[144,     4] loss: 0.501\n",
            "[145,     4] loss: 0.510\n",
            "[146,     4] loss: 0.481\n",
            "[147,     4] loss: 0.493\n",
            "[148,     4] loss: 0.496\n",
            "[149,     4] loss: 0.494\n",
            "[150,     4] loss: 0.486\n",
            "[151,     4] loss: 0.473\n",
            "[152,     4] loss: 0.512\n",
            "[153,     4] loss: 0.502\n",
            "[154,     4] loss: 0.490\n",
            "[155,     4] loss: 0.514\n",
            "[156,     4] loss: 0.488\n",
            "[157,     4] loss: 0.479\n",
            "[158,     4] loss: 0.497\n",
            "[159,     4] loss: 0.481\n",
            "[160,     4] loss: 0.491\n",
            "[161,     4] loss: 0.501\n",
            "[162,     4] loss: 0.483\n",
            "[163,     4] loss: 0.485\n",
            "[164,     4] loss: 0.489\n",
            "[165,     4] loss: 0.488\n",
            "[166,     4] loss: 0.482\n",
            "[167,     4] loss: 0.513\n",
            "[168,     4] loss: 0.483\n",
            "[169,     4] loss: 0.514\n",
            "[170,     4] loss: 0.489\n",
            "[171,     4] loss: 0.492\n",
            "[172,     4] loss: 0.496\n",
            "[173,     4] loss: 0.482\n",
            "[174,     4] loss: 0.481\n",
            "[175,     4] loss: 0.495\n",
            "[176,     4] loss: 0.502\n",
            "[177,     4] loss: 0.499\n",
            "[178,     4] loss: 0.503\n",
            "[179,     4] loss: 0.527\n",
            "[180,     4] loss: 0.502\n",
            "[181,     4] loss: 0.493\n",
            "[182,     4] loss: 0.500\n",
            "[183,     4] loss: 0.483\n",
            "[184,     4] loss: 0.499\n",
            "[185,     4] loss: 0.502\n",
            "[186,     4] loss: 0.497\n",
            "[187,     4] loss: 0.491\n",
            "[188,     4] loss: 0.497\n",
            "[189,     4] loss: 0.511\n",
            "[190,     4] loss: 0.526\n",
            "[191,     4] loss: 0.498\n",
            "[192,     4] loss: 0.503\n",
            "[193,     4] loss: 0.505\n",
            "[194,     4] loss: 0.481\n",
            "[195,     4] loss: 0.484\n",
            "[196,     4] loss: 0.470\n",
            "[197,     4] loss: 0.497\n",
            "[198,     4] loss: 0.478\n",
            "[199,     4] loss: 0.505\n",
            "[200,     4] loss: 0.504\n",
            "[201,     4] loss: 0.499\n",
            "[202,     4] loss: 0.488\n",
            "[203,     4] loss: 0.477\n",
            "[204,     4] loss: 0.499\n",
            "[205,     4] loss: 0.493\n",
            "[206,     4] loss: 0.481\n",
            "[207,     4] loss: 0.476\n",
            "[208,     4] loss: 0.478\n",
            "[209,     4] loss: 0.481\n",
            "[210,     4] loss: 0.501\n",
            "[211,     4] loss: 0.490\n",
            "[212,     4] loss: 0.474\n",
            "[213,     4] loss: 0.494\n",
            "[214,     4] loss: 0.471\n",
            "[215,     4] loss: 0.478\n",
            "[216,     4] loss: 0.472\n",
            "[217,     4] loss: 0.508\n",
            "[218,     4] loss: 0.488\n",
            "[219,     4] loss: 0.489\n",
            "[220,     4] loss: 0.487\n",
            "[221,     4] loss: 0.479\n",
            "[222,     4] loss: 0.491\n",
            "[223,     4] loss: 0.488\n",
            "[224,     4] loss: 0.485\n",
            "[225,     4] loss: 0.494\n",
            "[226,     4] loss: 0.480\n",
            "[227,     4] loss: 0.475\n",
            "[228,     4] loss: 0.475\n",
            "[229,     4] loss: 0.512\n",
            "[230,     4] loss: 0.487\n",
            "[231,     4] loss: 0.486\n",
            "[232,     4] loss: 0.479\n",
            "[233,     4] loss: 0.498\n",
            "[234,     4] loss: 0.481\n",
            "[235,     4] loss: 0.495\n",
            "[236,     4] loss: 0.465\n",
            "[237,     4] loss: 0.488\n",
            "[238,     4] loss: 0.505\n",
            "[239,     4] loss: 0.498\n",
            "[240,     4] loss: 0.481\n",
            "[241,     4] loss: 0.492\n",
            "[242,     4] loss: 0.492\n",
            "[243,     4] loss: 0.507\n",
            "[244,     4] loss: 0.496\n",
            "[245,     4] loss: 0.494\n",
            "[246,     4] loss: 0.492\n",
            "[247,     4] loss: 0.487\n",
            "[248,     4] loss: 0.489\n",
            "[249,     4] loss: 0.482\n",
            "[250,     4] loss: 0.497\n",
            "[251,     4] loss: 0.480\n",
            "[252,     4] loss: 0.486\n",
            "[253,     4] loss: 0.471\n",
            "[254,     4] loss: 0.468\n",
            "[255,     4] loss: 0.453\n",
            "[256,     4] loss: 0.473\n",
            "[257,     4] loss: 0.469\n",
            "[258,     4] loss: 0.474\n",
            "[259,     4] loss: 0.482\n",
            "[260,     4] loss: 0.465\n",
            "[261,     4] loss: 0.496\n",
            "[262,     4] loss: 0.478\n",
            "[263,     4] loss: 0.482\n",
            "[264,     4] loss: 0.487\n",
            "[265,     4] loss: 0.495\n",
            "[266,     4] loss: 0.497\n",
            "[267,     4] loss: 0.483\n",
            "[268,     4] loss: 0.490\n",
            "[269,     4] loss: 0.479\n",
            "[270,     4] loss: 0.492\n",
            "[271,     4] loss: 0.486\n",
            "[272,     4] loss: 0.493\n",
            "[273,     4] loss: 0.483\n",
            "[274,     4] loss: 0.490\n",
            "[275,     4] loss: 0.474\n",
            "[276,     4] loss: 0.485\n",
            "[277,     4] loss: 0.486\n",
            "[278,     4] loss: 0.478\n",
            "[279,     4] loss: 0.494\n",
            "[280,     4] loss: 0.486\n",
            "[281,     4] loss: 0.495\n",
            "[282,     4] loss: 0.488\n",
            "[283,     4] loss: 0.511\n",
            "[284,     4] loss: 0.482\n",
            "[285,     4] loss: 0.507\n",
            "[286,     4] loss: 0.497\n",
            "[287,     4] loss: 0.480\n",
            "[288,     4] loss: 0.486\n",
            "[289,     4] loss: 0.487\n",
            "[290,     4] loss: 0.495\n",
            "[291,     4] loss: 0.486\n",
            "[292,     4] loss: 0.485\n",
            "[293,     4] loss: 0.494\n",
            "[294,     4] loss: 0.496\n",
            "[295,     4] loss: 0.488\n",
            "[296,     4] loss: 0.491\n",
            "[297,     4] loss: 0.503\n",
            "[298,     4] loss: 0.490\n",
            "[299,     4] loss: 0.481\n",
            "[300,     4] loss: 0.476\n",
            "[301,     4] loss: 0.493\n",
            "[302,     4] loss: 0.481\n",
            "[303,     4] loss: 0.490\n",
            "[304,     4] loss: 0.466\n",
            "[305,     4] loss: 0.487\n",
            "[306,     4] loss: 0.472\n",
            "[307,     4] loss: 0.487\n",
            "[308,     4] loss: 0.486\n",
            "[309,     4] loss: 0.468\n",
            "[310,     4] loss: 0.488\n",
            "[311,     4] loss: 0.484\n",
            "[312,     4] loss: 0.490\n",
            "[313,     4] loss: 0.476\n",
            "[314,     4] loss: 0.483\n",
            "[315,     4] loss: 0.487\n",
            "[316,     4] loss: 0.484\n",
            "[317,     4] loss: 0.492\n",
            "[318,     4] loss: 0.474\n",
            "[319,     4] loss: 0.477\n",
            "[320,     4] loss: 0.496\n",
            "[321,     4] loss: 0.489\n",
            "[322,     4] loss: 0.493\n",
            "[323,     4] loss: 0.474\n",
            "[324,     4] loss: 0.483\n",
            "[325,     4] loss: 0.484\n",
            "[326,     4] loss: 0.480\n",
            "[327,     4] loss: 0.481\n",
            "[328,     4] loss: 0.466\n",
            "[329,     4] loss: 0.481\n",
            "[330,     4] loss: 0.482\n",
            "[331,     4] loss: 0.484\n",
            "[332,     4] loss: 0.470\n",
            "[333,     4] loss: 0.474\n",
            "[334,     4] loss: 0.490\n",
            "[335,     4] loss: 0.487\n",
            "[336,     4] loss: 0.480\n",
            "[337,     4] loss: 0.484\n",
            "[338,     4] loss: 0.470\n",
            "[339,     4] loss: 0.469\n",
            "[340,     4] loss: 0.470\n",
            "[341,     4] loss: 0.495\n",
            "[342,     4] loss: 0.490\n",
            "[343,     4] loss: 0.489\n",
            "[344,     4] loss: 0.496\n",
            "[345,     4] loss: 0.488\n",
            "[346,     4] loss: 0.501\n",
            "[347,     4] loss: 0.475\n",
            "[348,     4] loss: 0.472\n",
            "[349,     4] loss: 0.469\n",
            "[350,     4] loss: 0.485\n",
            "[351,     4] loss: 0.475\n",
            "[352,     4] loss: 0.472\n",
            "[353,     4] loss: 0.469\n",
            "[354,     4] loss: 0.486\n",
            "[355,     4] loss: 0.495\n",
            "[356,     4] loss: 0.497\n",
            "[357,     4] loss: 0.489\n",
            "[358,     4] loss: 0.467\n",
            "[359,     4] loss: 0.475\n",
            "[360,     4] loss: 0.485\n",
            "[361,     4] loss: 0.480\n",
            "[362,     4] loss: 0.482\n",
            "[363,     4] loss: 0.486\n",
            "[364,     4] loss: 0.487\n",
            "[365,     4] loss: 0.469\n",
            "[366,     4] loss: 0.465\n",
            "[367,     4] loss: 0.470\n",
            "[368,     4] loss: 0.474\n",
            "[369,     4] loss: 0.484\n",
            "[370,     4] loss: 0.484\n",
            "[371,     4] loss: 0.502\n",
            "[372,     4] loss: 0.489\n",
            "[373,     4] loss: 0.461\n",
            "[374,     4] loss: 0.487\n",
            "[375,     4] loss: 0.487\n",
            "[376,     4] loss: 0.478\n",
            "[377,     4] loss: 0.477\n",
            "[378,     4] loss: 0.479\n",
            "[379,     4] loss: 0.496\n",
            "[380,     4] loss: 0.488\n",
            "[381,     4] loss: 0.486\n",
            "[382,     4] loss: 0.466\n",
            "[383,     4] loss: 0.463\n",
            "[384,     4] loss: 0.485\n",
            "[385,     4] loss: 0.480\n",
            "[386,     4] loss: 0.488\n",
            "[387,     4] loss: 0.495\n",
            "[388,     4] loss: 0.472\n",
            "[389,     4] loss: 0.465\n",
            "[390,     4] loss: 0.459\n",
            "[391,     4] loss: 0.480\n",
            "[392,     4] loss: 0.468\n",
            "[393,     4] loss: 0.475\n",
            "[394,     4] loss: 0.487\n",
            "[395,     4] loss: 0.475\n",
            "[396,     4] loss: 0.482\n",
            "[397,     4] loss: 0.490\n",
            "[398,     4] loss: 0.486\n",
            "[399,     4] loss: 0.475\n",
            "[400,     4] loss: 0.491\n",
            "[401,     4] loss: 0.483\n",
            "[402,     4] loss: 0.488\n",
            "[403,     4] loss: 0.473\n",
            "[404,     4] loss: 0.490\n",
            "[405,     4] loss: 0.473\n",
            "[406,     4] loss: 0.472\n",
            "[407,     4] loss: 0.488\n",
            "[408,     4] loss: 0.477\n",
            "[409,     4] loss: 0.477\n",
            "[410,     4] loss: 0.481\n",
            "[411,     4] loss: 0.496\n",
            "[412,     4] loss: 0.482\n",
            "[413,     4] loss: 0.490\n",
            "[414,     4] loss: 0.494\n",
            "[415,     4] loss: 0.475\n",
            "[416,     4] loss: 0.488\n",
            "[417,     4] loss: 0.477\n",
            "[418,     4] loss: 0.497\n",
            "[419,     4] loss: 0.477\n",
            "[420,     4] loss: 0.471\n",
            "[421,     4] loss: 0.478\n",
            "[422,     4] loss: 0.474\n",
            "[423,     4] loss: 0.488\n",
            "[424,     4] loss: 0.480\n",
            "[425,     4] loss: 0.493\n",
            "[426,     4] loss: 0.479\n",
            "[427,     4] loss: 0.482\n",
            "[428,     4] loss: 0.472\n",
            "[429,     4] loss: 0.478\n",
            "[430,     4] loss: 0.483\n",
            "[431,     4] loss: 0.481\n",
            "[432,     4] loss: 0.475\n",
            "[433,     4] loss: 0.480\n",
            "[434,     4] loss: 0.479\n",
            "[435,     4] loss: 0.472\n",
            "[436,     4] loss: 0.483\n",
            "[437,     4] loss: 0.485\n",
            "[438,     4] loss: 0.478\n",
            "[439,     4] loss: 0.465\n",
            "[440,     4] loss: 0.472\n",
            "[441,     4] loss: 0.478\n",
            "[442,     4] loss: 0.477\n",
            "[443,     4] loss: 0.477\n",
            "[444,     4] loss: 0.480\n",
            "[445,     4] loss: 0.460\n",
            "[446,     4] loss: 0.495\n",
            "[447,     4] loss: 0.522\n",
            "[448,     4] loss: 0.508\n",
            "[449,     4] loss: 0.495\n",
            "[450,     4] loss: 0.471\n",
            "[451,     4] loss: 0.482\n",
            "[452,     4] loss: 0.477\n",
            "[453,     4] loss: 0.481\n",
            "[454,     4] loss: 0.468\n",
            "[455,     4] loss: 0.480\n",
            "[456,     4] loss: 0.467\n",
            "[457,     4] loss: 0.497\n",
            "[458,     4] loss: 0.466\n",
            "[459,     4] loss: 0.473\n",
            "[460,     4] loss: 0.487\n",
            "[461,     4] loss: 0.471\n",
            "[462,     4] loss: 0.461\n",
            "[463,     4] loss: 0.477\n",
            "[464,     4] loss: 0.462\n",
            "[465,     4] loss: 0.474\n",
            "[466,     4] loss: 0.468\n",
            "[467,     4] loss: 0.470\n",
            "[468,     4] loss: 0.499\n",
            "[469,     4] loss: 0.477\n",
            "[470,     4] loss: 0.472\n",
            "[471,     4] loss: 0.488\n",
            "[472,     4] loss: 0.480\n",
            "[473,     4] loss: 0.464\n",
            "[474,     4] loss: 0.479\n",
            "[475,     4] loss: 0.479\n",
            "[476,     4] loss: 0.465\n",
            "[477,     4] loss: 0.454\n",
            "[478,     4] loss: 0.488\n",
            "[479,     4] loss: 0.489\n",
            "[480,     4] loss: 0.482\n",
            "[481,     4] loss: 0.494\n",
            "[482,     4] loss: 0.469\n",
            "[483,     4] loss: 0.476\n",
            "[484,     4] loss: 0.484\n",
            "[485,     4] loss: 0.486\n",
            "[486,     4] loss: 0.469\n",
            "[487,     4] loss: 0.490\n",
            "[488,     4] loss: 0.474\n",
            "[489,     4] loss: 0.478\n",
            "[490,     4] loss: 0.491\n",
            "[491,     4] loss: 0.484\n",
            "[492,     4] loss: 0.488\n",
            "[493,     4] loss: 0.478\n",
            "[494,     4] loss: 0.481\n",
            "[495,     4] loss: 0.478\n",
            "[496,     4] loss: 0.482\n",
            "[497,     4] loss: 0.474\n",
            "[498,     4] loss: 0.472\n",
            "[499,     4] loss: 0.464\n",
            "[500,     4] loss: 0.500\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 76 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 37 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 41 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 58 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 76 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 86 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 86 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 67 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   7\n",
            "[1,     4] loss: 1.514\n",
            "[2,     4] loss: 0.792\n",
            "[3,     4] loss: 0.619\n",
            "[4,     4] loss: 0.584\n",
            "[5,     4] loss: 0.573\n",
            "[6,     4] loss: 0.533\n",
            "[7,     4] loss: 0.510\n",
            "[8,     4] loss: 0.486\n",
            "[9,     4] loss: 0.459\n",
            "[10,     4] loss: 0.449\n",
            "[11,     4] loss: 0.434\n",
            "[12,     4] loss: 0.440\n",
            "[13,     4] loss: 0.426\n",
            "[14,     4] loss: 0.416\n",
            "[15,     4] loss: 0.423\n",
            "[16,     4] loss: 0.386\n",
            "[17,     4] loss: 0.340\n",
            "[18,     4] loss: 0.314\n",
            "[19,     4] loss: 0.408\n",
            "[20,     4] loss: 0.363\n",
            "[21,     4] loss: 0.285\n",
            "[22,     4] loss: 0.294\n",
            "[23,     4] loss: 0.245\n",
            "[24,     4] loss: 0.249\n",
            "[25,     4] loss: 0.241\n",
            "[26,     4] loss: 0.242\n",
            "[27,     4] loss: 0.234\n",
            "[28,     4] loss: 0.241\n",
            "[29,     4] loss: 0.236\n",
            "[30,     4] loss: 0.234\n",
            "[31,     4] loss: 0.223\n",
            "[32,     4] loss: 0.242\n",
            "[33,     4] loss: 0.367\n",
            "[34,     4] loss: 0.257\n",
            "[35,     4] loss: 0.277\n",
            "[36,     4] loss: 0.246\n",
            "[37,     4] loss: 0.248\n",
            "[38,     4] loss: 0.228\n",
            "[39,     4] loss: 0.235\n",
            "[40,     4] loss: 0.211\n",
            "[41,     4] loss: 0.218\n",
            "[42,     4] loss: 0.218\n",
            "[43,     4] loss: 0.214\n",
            "[44,     4] loss: 0.204\n",
            "[45,     4] loss: 0.224\n",
            "[46,     4] loss: 0.206\n",
            "[47,     4] loss: 0.214\n",
            "[48,     4] loss: 0.215\n",
            "[49,     4] loss: 0.213\n",
            "[50,     4] loss: 0.229\n",
            "[51,     4] loss: 0.219\n",
            "[52,     4] loss: 0.244\n",
            "[53,     4] loss: 0.241\n",
            "[54,     4] loss: 0.230\n",
            "[55,     4] loss: 0.214\n",
            "[56,     4] loss: 0.202\n",
            "[57,     4] loss: 0.202\n",
            "[58,     4] loss: 0.217\n",
            "[59,     4] loss: 0.217\n",
            "[60,     4] loss: 0.210\n",
            "[61,     4] loss: 0.214\n",
            "[62,     4] loss: 0.219\n",
            "[63,     4] loss: 0.210\n",
            "[64,     4] loss: 0.215\n",
            "[65,     4] loss: 0.212\n",
            "[66,     4] loss: 0.202\n",
            "[67,     4] loss: 0.230\n",
            "[68,     4] loss: 0.232\n",
            "[69,     4] loss: 0.205\n",
            "[70,     4] loss: 0.229\n",
            "[71,     4] loss: 0.216\n",
            "[72,     4] loss: 0.210\n",
            "[73,     4] loss: 0.224\n",
            "[74,     4] loss: 0.214\n",
            "[75,     4] loss: 0.219\n",
            "[76,     4] loss: 0.229\n",
            "[77,     4] loss: 0.232\n",
            "[78,     4] loss: 0.241\n",
            "[79,     4] loss: 0.344\n",
            "[80,     4] loss: 0.277\n",
            "[81,     4] loss: 0.234\n",
            "[82,     4] loss: 0.253\n",
            "[83,     4] loss: 0.221\n",
            "[84,     4] loss: 0.209\n",
            "[85,     4] loss: 0.210\n",
            "[86,     4] loss: 0.220\n",
            "[87,     4] loss: 0.244\n",
            "[88,     4] loss: 0.238\n",
            "[89,     4] loss: 0.231\n",
            "[90,     4] loss: 0.240\n",
            "[91,     4] loss: 0.224\n",
            "[92,     4] loss: 0.232\n",
            "[93,     4] loss: 0.225\n",
            "[94,     4] loss: 0.212\n",
            "[95,     4] loss: 0.229\n",
            "[96,     4] loss: 0.225\n",
            "[97,     4] loss: 0.219\n",
            "[98,     4] loss: 0.216\n",
            "[99,     4] loss: 0.217\n",
            "[100,     4] loss: 0.210\n",
            "[101,     4] loss: 0.219\n",
            "[102,     4] loss: 0.215\n",
            "[103,     4] loss: 0.204\n",
            "[104,     4] loss: 0.205\n",
            "[105,     4] loss: 0.217\n",
            "[106,     4] loss: 0.231\n",
            "[107,     4] loss: 0.215\n",
            "[108,     4] loss: 0.217\n",
            "[109,     4] loss: 0.215\n",
            "[110,     4] loss: 0.229\n",
            "[111,     4] loss: 0.217\n",
            "[112,     4] loss: 0.216\n",
            "[113,     4] loss: 0.214\n",
            "[114,     4] loss: 0.233\n",
            "[115,     4] loss: 0.240\n",
            "[116,     4] loss: 0.219\n",
            "[117,     4] loss: 0.205\n",
            "[118,     4] loss: 0.201\n",
            "[119,     4] loss: 0.222\n",
            "[120,     4] loss: 0.216\n",
            "[121,     4] loss: 0.206\n",
            "[122,     4] loss: 0.210\n",
            "[123,     4] loss: 0.222\n",
            "[124,     4] loss: 0.228\n",
            "[125,     4] loss: 0.217\n",
            "[126,     4] loss: 0.225\n",
            "[127,     4] loss: 0.225\n",
            "[128,     4] loss: 0.226\n",
            "[129,     4] loss: 0.220\n",
            "[130,     4] loss: 0.208\n",
            "[131,     4] loss: 0.203\n",
            "[132,     4] loss: 0.212\n",
            "[133,     4] loss: 0.205\n",
            "[134,     4] loss: 0.210\n",
            "[135,     4] loss: 0.197\n",
            "[136,     4] loss: 0.207\n",
            "[137,     4] loss: 0.208\n",
            "[138,     4] loss: 0.208\n",
            "[139,     4] loss: 0.204\n",
            "[140,     4] loss: 0.197\n",
            "[141,     4] loss: 0.213\n",
            "[142,     4] loss: 0.209\n",
            "[143,     4] loss: 0.222\n",
            "[144,     4] loss: 0.224\n",
            "[145,     4] loss: 0.204\n",
            "[146,     4] loss: 0.225\n",
            "[147,     4] loss: 0.221\n",
            "[148,     4] loss: 0.222\n",
            "[149,     4] loss: 0.217\n",
            "[150,     4] loss: 0.226\n",
            "[151,     4] loss: 0.198\n",
            "[152,     4] loss: 0.230\n",
            "[153,     4] loss: 0.217\n",
            "[154,     4] loss: 0.214\n",
            "[155,     4] loss: 0.228\n",
            "[156,     4] loss: 0.222\n",
            "[157,     4] loss: 0.218\n",
            "[158,     4] loss: 0.205\n",
            "[159,     4] loss: 0.215\n",
            "[160,     4] loss: 0.235\n",
            "[161,     4] loss: 0.203\n",
            "[162,     4] loss: 0.216\n",
            "[163,     4] loss: 0.215\n",
            "[164,     4] loss: 0.220\n",
            "[165,     4] loss: 0.229\n",
            "[166,     4] loss: 0.206\n",
            "[167,     4] loss: 0.219\n",
            "[168,     4] loss: 0.196\n",
            "[169,     4] loss: 0.224\n",
            "[170,     4] loss: 0.205\n",
            "[171,     4] loss: 0.202\n",
            "[172,     4] loss: 0.205\n",
            "[173,     4] loss: 0.206\n",
            "[174,     4] loss: 0.210\n",
            "[175,     4] loss: 0.218\n",
            "[176,     4] loss: 0.201\n",
            "[177,     4] loss: 0.197\n",
            "[178,     4] loss: 0.214\n",
            "[179,     4] loss: 0.205\n",
            "[180,     4] loss: 0.211\n",
            "[181,     4] loss: 0.210\n",
            "[182,     4] loss: 0.209\n",
            "[183,     4] loss: 0.210\n",
            "[184,     4] loss: 0.217\n",
            "[185,     4] loss: 0.221\n",
            "[186,     4] loss: 0.195\n",
            "[187,     4] loss: 0.214\n",
            "[188,     4] loss: 0.210\n",
            "[189,     4] loss: 0.219\n",
            "[190,     4] loss: 0.213\n",
            "[191,     4] loss: 0.206\n",
            "[192,     4] loss: 0.211\n",
            "[193,     4] loss: 0.226\n",
            "[194,     4] loss: 0.224\n",
            "[195,     4] loss: 0.224\n",
            "[196,     4] loss: 0.206\n",
            "[197,     4] loss: 0.211\n",
            "[198,     4] loss: 0.211\n",
            "[199,     4] loss: 0.210\n",
            "[200,     4] loss: 0.211\n",
            "[201,     4] loss: 0.225\n",
            "[202,     4] loss: 0.214\n",
            "[203,     4] loss: 0.236\n",
            "[204,     4] loss: 0.220\n",
            "[205,     4] loss: 0.207\n",
            "[206,     4] loss: 0.213\n",
            "[207,     4] loss: 0.204\n",
            "[208,     4] loss: 0.230\n",
            "[209,     4] loss: 0.223\n",
            "[210,     4] loss: 0.218\n",
            "[211,     4] loss: 0.217\n",
            "[212,     4] loss: 0.217\n",
            "[213,     4] loss: 0.239\n",
            "[214,     4] loss: 0.227\n",
            "[215,     4] loss: 0.228\n",
            "[216,     4] loss: 0.213\n",
            "[217,     4] loss: 0.209\n",
            "[218,     4] loss: 0.207\n",
            "[219,     4] loss: 0.199\n",
            "[220,     4] loss: 0.224\n",
            "[221,     4] loss: 0.235\n",
            "[222,     4] loss: 0.204\n",
            "[223,     4] loss: 0.207\n",
            "[224,     4] loss: 0.206\n",
            "[225,     4] loss: 0.204\n",
            "[226,     4] loss: 0.215\n",
            "[227,     4] loss: 0.211\n",
            "[228,     4] loss: 0.201\n",
            "[229,     4] loss: 0.212\n",
            "[230,     4] loss: 0.198\n",
            "[231,     4] loss: 0.221\n",
            "[232,     4] loss: 0.219\n",
            "[233,     4] loss: 0.201\n",
            "[234,     4] loss: 0.205\n",
            "[235,     4] loss: 0.203\n",
            "[236,     4] loss: 0.220\n",
            "[237,     4] loss: 0.206\n",
            "[238,     4] loss: 0.209\n",
            "[239,     4] loss: 0.209\n",
            "[240,     4] loss: 0.185\n",
            "[241,     4] loss: 0.212\n",
            "[242,     4] loss: 0.217\n",
            "[243,     4] loss: 0.204\n",
            "[244,     4] loss: 0.209\n",
            "[245,     4] loss: 0.211\n",
            "[246,     4] loss: 0.209\n",
            "[247,     4] loss: 0.205\n",
            "[248,     4] loss: 0.215\n",
            "[249,     4] loss: 0.200\n",
            "[250,     4] loss: 0.208\n",
            "[251,     4] loss: 0.205\n",
            "[252,     4] loss: 0.212\n",
            "[253,     4] loss: 0.224\n",
            "[254,     4] loss: 0.211\n",
            "[255,     4] loss: 0.217\n",
            "[256,     4] loss: 0.222\n",
            "[257,     4] loss: 0.185\n",
            "[258,     4] loss: 0.208\n",
            "[259,     4] loss: 0.205\n",
            "[260,     4] loss: 0.205\n",
            "[261,     4] loss: 0.219\n",
            "[262,     4] loss: 0.228\n",
            "[263,     4] loss: 0.214\n",
            "[264,     4] loss: 0.219\n",
            "[265,     4] loss: 0.204\n",
            "[266,     4] loss: 0.241\n",
            "[267,     4] loss: 0.232\n",
            "[268,     4] loss: 0.234\n",
            "[269,     4] loss: 0.237\n",
            "[270,     4] loss: 0.220\n",
            "[271,     4] loss: 0.227\n",
            "[272,     4] loss: 0.210\n",
            "[273,     4] loss: 0.207\n",
            "[274,     4] loss: 0.223\n",
            "[275,     4] loss: 0.223\n",
            "[276,     4] loss: 0.223\n",
            "[277,     4] loss: 0.208\n",
            "[278,     4] loss: 0.207\n",
            "[279,     4] loss: 0.220\n",
            "[280,     4] loss: 0.220\n",
            "[281,     4] loss: 0.202\n",
            "[282,     4] loss: 0.217\n",
            "[283,     4] loss: 0.183\n",
            "[284,     4] loss: 0.206\n",
            "[285,     4] loss: 0.200\n",
            "[286,     4] loss: 0.207\n",
            "[287,     4] loss: 0.209\n",
            "[288,     4] loss: 0.208\n",
            "[289,     4] loss: 0.212\n",
            "[290,     4] loss: 0.221\n",
            "[291,     4] loss: 0.218\n",
            "[292,     4] loss: 0.215\n",
            "[293,     4] loss: 0.206\n",
            "[294,     4] loss: 0.210\n",
            "[295,     4] loss: 0.222\n",
            "[296,     4] loss: 0.215\n",
            "[297,     4] loss: 0.218\n",
            "[298,     4] loss: 0.204\n",
            "[299,     4] loss: 0.211\n",
            "[300,     4] loss: 0.204\n",
            "[301,     4] loss: 0.218\n",
            "[302,     4] loss: 0.216\n",
            "[303,     4] loss: 0.221\n",
            "[304,     4] loss: 0.217\n",
            "[305,     4] loss: 0.202\n",
            "[306,     4] loss: 0.200\n",
            "[307,     4] loss: 0.210\n",
            "[308,     4] loss: 0.199\n",
            "[309,     4] loss: 0.211\n",
            "[310,     4] loss: 0.227\n",
            "[311,     4] loss: 0.220\n",
            "[312,     4] loss: 0.201\n",
            "[313,     4] loss: 0.209\n",
            "[314,     4] loss: 0.219\n",
            "[315,     4] loss: 0.204\n",
            "[316,     4] loss: 0.192\n",
            "[317,     4] loss: 0.203\n",
            "[318,     4] loss: 0.220\n",
            "[319,     4] loss: 0.220\n",
            "[320,     4] loss: 0.217\n",
            "[321,     4] loss: 0.209\n",
            "[322,     4] loss: 0.206\n",
            "[323,     4] loss: 0.212\n",
            "[324,     4] loss: 0.203\n",
            "[325,     4] loss: 0.192\n",
            "[326,     4] loss: 0.194\n",
            "[327,     4] loss: 0.208\n",
            "[328,     4] loss: 0.212\n",
            "[329,     4] loss: 0.209\n",
            "[330,     4] loss: 0.185\n",
            "[331,     4] loss: 0.217\n",
            "[332,     4] loss: 0.209\n",
            "[333,     4] loss: 0.235\n",
            "[334,     4] loss: 0.208\n",
            "[335,     4] loss: 0.218\n",
            "[336,     4] loss: 0.215\n",
            "[337,     4] loss: 0.206\n",
            "[338,     4] loss: 0.189\n",
            "[339,     4] loss: 0.206\n",
            "[340,     4] loss: 0.206\n",
            "[341,     4] loss: 0.199\n",
            "[342,     4] loss: 0.202\n",
            "[343,     4] loss: 0.224\n",
            "[344,     4] loss: 0.206\n",
            "[345,     4] loss: 0.210\n",
            "[346,     4] loss: 0.222\n",
            "[347,     4] loss: 0.211\n",
            "[348,     4] loss: 0.200\n",
            "[349,     4] loss: 0.216\n",
            "[350,     4] loss: 0.215\n",
            "[351,     4] loss: 0.218\n",
            "[352,     4] loss: 0.212\n",
            "[353,     4] loss: 0.211\n",
            "[354,     4] loss: 0.212\n",
            "[355,     4] loss: 0.206\n",
            "[356,     4] loss: 0.209\n",
            "[357,     4] loss: 0.200\n",
            "[358,     4] loss: 0.197\n",
            "[359,     4] loss: 0.204\n",
            "[360,     4] loss: 0.221\n",
            "[361,     4] loss: 0.229\n",
            "[362,     4] loss: 0.229\n",
            "[363,     4] loss: 0.241\n",
            "[364,     4] loss: 0.225\n",
            "[365,     4] loss: 0.237\n",
            "[366,     4] loss: 0.233\n",
            "[367,     4] loss: 0.221\n",
            "[368,     4] loss: 0.229\n",
            "[369,     4] loss: 0.227\n",
            "[370,     4] loss: 0.224\n",
            "[371,     4] loss: 0.228\n",
            "[372,     4] loss: 0.234\n",
            "[373,     4] loss: 0.236\n",
            "[374,     4] loss: 0.203\n",
            "[375,     4] loss: 0.217\n",
            "[376,     4] loss: 0.206\n",
            "[377,     4] loss: 0.206\n",
            "[378,     4] loss: 0.215\n",
            "[379,     4] loss: 0.213\n",
            "[380,     4] loss: 0.205\n",
            "[381,     4] loss: 0.206\n",
            "[382,     4] loss: 0.206\n",
            "[383,     4] loss: 0.209\n",
            "[384,     4] loss: 0.207\n",
            "[385,     4] loss: 0.216\n",
            "[386,     4] loss: 0.209\n",
            "[387,     4] loss: 0.208\n",
            "[388,     4] loss: 0.203\n",
            "[389,     4] loss: 0.195\n",
            "[390,     4] loss: 0.207\n",
            "[391,     4] loss: 0.215\n",
            "[392,     4] loss: 0.199\n",
            "[393,     4] loss: 0.206\n",
            "[394,     4] loss: 0.213\n",
            "[395,     4] loss: 0.191\n",
            "[396,     4] loss: 0.203\n",
            "[397,     4] loss: 0.210\n",
            "[398,     4] loss: 0.197\n",
            "[399,     4] loss: 0.221\n",
            "[400,     4] loss: 0.203\n",
            "[401,     4] loss: 0.193\n",
            "[402,     4] loss: 0.214\n",
            "[403,     4] loss: 0.213\n",
            "[404,     4] loss: 0.214\n",
            "[405,     4] loss: 0.209\n",
            "[406,     4] loss: 0.214\n",
            "[407,     4] loss: 0.191\n",
            "[408,     4] loss: 0.200\n",
            "[409,     4] loss: 0.208\n",
            "[410,     4] loss: 0.205\n",
            "[411,     4] loss: 0.214\n",
            "[412,     4] loss: 0.221\n",
            "[413,     4] loss: 0.216\n",
            "[414,     4] loss: 0.215\n",
            "[415,     4] loss: 0.214\n",
            "[416,     4] loss: 0.199\n",
            "[417,     4] loss: 0.217\n",
            "[418,     4] loss: 0.197\n",
            "[419,     4] loss: 0.219\n",
            "[420,     4] loss: 0.202\n",
            "[421,     4] loss: 0.201\n",
            "[422,     4] loss: 0.206\n",
            "[423,     4] loss: 0.217\n",
            "[424,     4] loss: 0.208\n",
            "[425,     4] loss: 0.200\n",
            "[426,     4] loss: 0.210\n",
            "[427,     4] loss: 0.208\n",
            "[428,     4] loss: 0.194\n",
            "[429,     4] loss: 0.202\n",
            "[430,     4] loss: 0.211\n",
            "[431,     4] loss: 0.210\n",
            "[432,     4] loss: 0.204\n",
            "[433,     4] loss: 0.211\n",
            "[434,     4] loss: 0.197\n",
            "[435,     4] loss: 0.219\n",
            "[436,     4] loss: 0.211\n",
            "[437,     4] loss: 0.201\n",
            "[438,     4] loss: 0.198\n",
            "[439,     4] loss: 0.212\n",
            "[440,     4] loss: 0.194\n",
            "[441,     4] loss: 0.206\n",
            "[442,     4] loss: 0.191\n",
            "[443,     4] loss: 0.189\n",
            "[444,     4] loss: 0.210\n",
            "[445,     4] loss: 0.205\n",
            "[446,     4] loss: 0.195\n",
            "[447,     4] loss: 0.204\n",
            "[448,     4] loss: 0.204\n",
            "[449,     4] loss: 0.205\n",
            "[450,     4] loss: 0.202\n",
            "[451,     4] loss: 0.201\n",
            "[452,     4] loss: 0.231\n",
            "[453,     4] loss: 0.204\n",
            "[454,     4] loss: 0.220\n",
            "[455,     4] loss: 0.204\n",
            "[456,     4] loss: 0.189\n",
            "[457,     4] loss: 0.206\n",
            "[458,     4] loss: 0.195\n",
            "[459,     4] loss: 0.198\n",
            "[460,     4] loss: 0.204\n",
            "[461,     4] loss: 0.198\n",
            "[462,     4] loss: 0.204\n",
            "[463,     4] loss: 0.206\n",
            "[464,     4] loss: 0.212\n",
            "[465,     4] loss: 0.208\n",
            "[466,     4] loss: 0.193\n",
            "[467,     4] loss: 0.191\n",
            "[468,     4] loss: 0.203\n",
            "[469,     4] loss: 0.207\n",
            "[470,     4] loss: 0.210\n",
            "[471,     4] loss: 0.193\n",
            "[472,     4] loss: 0.203\n",
            "[473,     4] loss: 0.207\n",
            "[474,     4] loss: 0.204\n",
            "[475,     4] loss: 0.212\n",
            "[476,     4] loss: 0.197\n",
            "[477,     4] loss: 0.208\n",
            "[478,     4] loss: 0.195\n",
            "[479,     4] loss: 0.186\n",
            "[480,     4] loss: 0.189\n",
            "[481,     4] loss: 0.208\n",
            "[482,     4] loss: 0.233\n",
            "[483,     4] loss: 0.199\n",
            "[484,     4] loss: 0.215\n",
            "[485,     4] loss: 0.214\n",
            "[486,     4] loss: 0.202\n",
            "[487,     4] loss: 0.199\n",
            "[488,     4] loss: 0.214\n",
            "[489,     4] loss: 0.210\n",
            "[490,     4] loss: 0.207\n",
            "[491,     4] loss: 0.221\n",
            "[492,     4] loss: 0.211\n",
            "[493,     4] loss: 0.203\n",
            "[494,     4] loss: 0.199\n",
            "[495,     4] loss: 0.194\n",
            "[496,     4] loss: 0.213\n",
            "[497,     4] loss: 0.215\n",
            "[498,     4] loss: 0.215\n",
            "[499,     4] loss: 0.203\n",
            "[500,     4] loss: 0.207\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 90 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 36 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 38 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 42 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 54 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 72 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 90 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 95 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 83 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   8\n",
            "[1,     4] loss: 1.066\n",
            "[2,     4] loss: 0.726\n",
            "[3,     4] loss: 0.511\n",
            "[4,     4] loss: 0.404\n",
            "[5,     4] loss: 0.444\n",
            "[6,     4] loss: 0.397\n",
            "[7,     4] loss: 0.378\n",
            "[8,     4] loss: 0.332\n",
            "[9,     4] loss: 0.321\n",
            "[10,     4] loss: 0.291\n",
            "[11,     4] loss: 0.280\n",
            "[12,     4] loss: 0.259\n",
            "[13,     4] loss: 0.214\n",
            "[14,     4] loss: 0.231\n",
            "[15,     4] loss: 0.318\n",
            "[16,     4] loss: 0.263\n",
            "[17,     4] loss: 0.241\n",
            "[18,     4] loss: 0.218\n",
            "[19,     4] loss: 0.184\n",
            "[20,     4] loss: 0.134\n",
            "[21,     4] loss: 0.081\n",
            "[22,     4] loss: 0.053\n",
            "[23,     4] loss: 0.060\n",
            "[24,     4] loss: 0.051\n",
            "[25,     4] loss: 0.061\n",
            "[26,     4] loss: 0.046\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 98 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 38 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 42 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 45 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 49 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 62 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 87 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 98 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 100 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   9\n",
            "[1,     4] loss: 1.201\n",
            "[2,     4] loss: 0.759\n",
            "[3,     4] loss: 0.569\n",
            "[4,     4] loss: 0.378\n",
            "[5,     4] loss: 0.340\n",
            "[6,     4] loss: 0.326\n",
            "[7,     4] loss: 0.296\n",
            "[8,     4] loss: 0.317\n",
            "[9,     4] loss: 0.344\n",
            "[10,     4] loss: 0.260\n",
            "[11,     4] loss: 0.243\n",
            "[12,     4] loss: 0.243\n",
            "[13,     4] loss: 0.227\n",
            "[14,     4] loss: 0.205\n",
            "[15,     4] loss: 0.147\n",
            "[16,     4] loss: 0.110\n",
            "[17,     4] loss: 0.062\n",
            "[18,     4] loss: 0.476\n",
            "[19,     4] loss: 0.268\n",
            "[20,     4] loss: 0.273\n",
            "[21,     4] loss: 0.211\n",
            "[22,     4] loss: 0.212\n",
            "[23,     4] loss: 0.200\n",
            "[24,     4] loss: 0.176\n",
            "[25,     4] loss: 0.141\n",
            "[26,     4] loss: 0.115\n",
            "[27,     4] loss: 0.062\n",
            "[28,     4] loss: 0.298\n",
            "[29,     4] loss: 0.147\n",
            "[30,     4] loss: 0.065\n",
            "[31,     4] loss: 0.038\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 train images: 100 %\n",
            "Accuracy of the network on the 10000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 10000 test dataset 2: 38 %\n",
            "Accuracy of the network on the 10000 test dataset 3: 43 %\n",
            "Accuracy of the network on the 10000 test dataset 4: 45 %\n",
            "Accuracy of the network on the 10000 test dataset 5: 46 %\n",
            "Accuracy of the network on the 10000 test dataset 6: 51 %\n",
            "Accuracy of the network on the 10000 test dataset 7: 66 %\n",
            "Accuracy of the network on the 10000 test dataset 8: 97 %\n",
            "Accuracy of the network on the 10000 test dataset 9: 100 %\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In76SYH_zZHV"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "BS4HtOHEzZ0E",
        "outputId": "ed270e2c-1f78-4633-9b5a-ecc2801e0b56"
      },
      "source": [
        "for i,j in enumerate(train_loss_all):\n",
        "    plt.plot(j,label =\"dataset \"+str(i+1))\n",
        "    \n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1be0eb1940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS5D_SpOzj9n"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va4L2IZ1zj6o"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}