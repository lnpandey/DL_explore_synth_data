{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generalization_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6204da3afc814edf94b2659ac74d4a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49c25901c6e74f48ad090f3bcba68480",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a7701456fd34273bd95da58dfb3a0d5",
              "IPY_MODEL_a5fc4ee471d54e87a1195f3c24979334"
            ]
          }
        },
        "49c25901c6e74f48ad090f3bcba68480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a7701456fd34273bd95da58dfb3a0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b4fe38879f04349a5b203b531802f67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ae6cd6a66d847f1b878e24dfe058e8c"
          }
        },
        "a5fc4ee471d54e87a1195f3c24979334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52d64c0fcdca4bea8aeb4d8b4e369723",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 17517093.20it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b930804993a0415dbdaaffaea26a4b30"
          }
        },
        "5b4fe38879f04349a5b203b531802f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ae6cd6a66d847f1b878e24dfe058e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52d64c0fcdca4bea8aeb4d8b4e369723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b930804993a0415dbdaaffaea26a4b30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvhP2fR9tuc4"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AKOgwmmuDVr",
        "outputId": "86c54dd7-7279-4585-f6b3-293bd27a2d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "6204da3afc814edf94b2659ac74d4a7a",
            "49c25901c6e74f48ad090f3bcba68480",
            "3a7701456fd34273bd95da58dfb3a0d5",
            "a5fc4ee471d54e87a1195f3c24979334",
            "5b4fe38879f04349a5b203b531802f67",
            "6ae6cd6a66d847f1b878e24dfe058e8c",
            "52d64c0fcdca4bea8aeb4d8b4e369723",
            "b930804993a0415dbdaaffaea26a4b30"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6204da3afc814edf94b2659ac74d4a7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRNXNPHWxCT0"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nlXuo8mxHs1"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3bTKPpixLFs"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])#.type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])#.type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho0BsIqqxOj8"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "#fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  #fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tebDf0O3xSrp"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label )\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF9ggP3kz9Wv"
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  np.random.seed(i+30000)\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPEFFNfrz9Pf"
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU6nQ692xZHb"
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "    self.fc4 = nn.Linear(10,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    # print(x.shape)\n",
        "    x = (F.relu(self.conv3(x)))\n",
        "    x =  x.view(x.size(0), -1)\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTEbTBRXxajy"
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self,focus_net):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = focus_net\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "    self.fc4 = nn.Linear(10,3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "    \n",
        "    y1 = self.pool(F.relu(self.conv1(y)))\n",
        "    y1 = self.pool(F.relu(self.conv2(y1)))\n",
        "    # print(x.shape)\n",
        "    y1 = (F.relu(self.conv3(y1)))\n",
        "    y1 =  y1.view(y1.size(0), -1)\n",
        "    # print(x.shape)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_u8JyyLxy6G",
        "outputId": "dd9f6f3f-e153-4670-a99e-c7b526dc0df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# both trained\n",
        "focus_net = Focus().double()\n",
        "for params in focus_net.parameters():\n",
        "  params.requires_grad = True\n",
        "classify = Classification(focus_net).double()\n",
        "classify = classify.to(\"cuda\")\n",
        "classify.load_state_dict( torch.load(\"/content/brandom_btrain.pt\"))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqk_8LmyPHqg",
        "outputId": "29918003-d12d-4d48-a88a-6c8102c69274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#classify trained\n",
        "focus_ct = Focus().double()\n",
        "for params in focus_ct.parameters():\n",
        "  params.requires_grad = True\n",
        "classify_ct = Classification(focus_ct).double()\n",
        "classify_ct = classify_ct.to(\"cuda\")\n",
        "classify_ct.load_state_dict( torch.load(\"/content/brandom_ctrain.pt\"))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_bdCUU0Xmm3"
      },
      "source": [
        "# import torch.optim as optim\n",
        "# criterion_classify = nn.CrossEntropyLoss()\n",
        "# optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp9SRr_fVLAC"
      },
      "source": [
        "# nos_epochs =300\n",
        "# for epoch in range(nos_epochs):  # loop over the dataset multiple times  \n",
        "#   running_loss = 0.0\n",
        "#   epoch_loss = []\n",
        "#   cnt=0\n",
        "\n",
        "#   iteration = desired_num // batch\n",
        "  \n",
        "#   #training data set\n",
        "  \n",
        "#   for i, data in  enumerate(train_loader):\n",
        "#     inputs , labels = data\n",
        "#     inputs = inputs.double()\n",
        "#     inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "#     # zero the parameter gradients\n",
        "    \n",
        "#     optimizer_classify.zero_grad()\n",
        "#     outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "#     _, predicted = torch.max(outputs.data, 1)\n",
        "# #     print(outputs)\n",
        "# #     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "#     loss = criterion_classify(outputs, labels) \n",
        "#     loss.backward()\n",
        "#     optimizer_classify.step()\n",
        "\n",
        "#     running_loss += loss.item()\n",
        "#     mini = 60\n",
        "#     if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "#       print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "#       epoch_loss.append(running_loss/mini)\n",
        "#       running_loss = 0.0\n",
        "#     cnt=cnt+1\n",
        "#   if(np.mean(epoch_loss) <= 0.03):\n",
        "#       break;\n",
        "# print('Finished Training')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6R_j82EoJuX"
      },
      "source": [
        "# torch.save(classify.state_dict(),\"/content/brandom_ctrain.pt\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q5GJPPfyK1n"
      },
      "source": [
        "#classify.load_state_dict( torch.load(\"/content/brandom_ctrain.pt\"))\n",
        "#classify.load_state_dict( torch.load(\"/content/drive/My Drive/Cheating_data/16_experiments_on_cnn_3layers/4_focus_random_classify_random_train_classify.pt\"))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dqtbDtjzX4N"
      },
      "source": [
        "# classify.eval()\n",
        "# total = 0 \n",
        "# correct = 0\n",
        "# with torch.no_grad():\n",
        "#   for data in train_loader:\n",
        "#     inputs, labels  = data\n",
        "#     inputs = inputs.double()\n",
        "#     inputs, labels  = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "#     outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "#     _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "#     total += labels.size(0)\n",
        "#     correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
        "#     100 * correct / total))\n",
        "# print(\"total correct\", correct)\n",
        "# print(\"total train set images\", total)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-15xPM280v4N"
      },
      "source": [
        "# classify_ct.eval()\n",
        "# total = 0 \n",
        "# correct = 0\n",
        "# with torch.no_grad():\n",
        "#   for data in test_loader:\n",
        "#     inputs, labels  = data\n",
        "#     inputs = inputs.double() \n",
        "#     inputs, labels  = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "#     outputs, alphas, avg_images = classify_ct(inputs)\n",
        "\n",
        "#     _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "#     total += labels.size(0)\n",
        "#     correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "#     100 * correct / total))\n",
        "# print(\"total correct\", correct)\n",
        "# print(\"total train set images\", total)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKazVW7WHueg"
      },
      "source": [
        "# Analysis on both random train classify Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQB7lW6r16ZT"
      },
      "source": [
        "MIN = 100000\n",
        "MAX = -100000\n",
        "i=0\n",
        "for param in classify_ct.parameters():\n",
        "  if i %2 == 0:\n",
        "    min_value = np.min(param.cpu().detach().numpy())\n",
        "    max_value = np.max(param.cpu().detach().numpy())\n",
        "    if MIN > min_value:\n",
        "      MIN = min_value\n",
        "    if MAX < max_value:\n",
        "      MAX = max_value \n",
        "  i =i+1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_tDHGCaIGqz",
        "outputId": "4a01db1c-4069-4b45-9a01-b348893fdb45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MIN,MAX"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.2860045929276889, 1.7312222026163304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm8-wt7gIHif",
        "outputId": "02af02bf-f76b-4bd6-e102-f9ba2246e571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify_ct.eval()\n",
        "margin = []\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels  = data\n",
        "    inputs = inputs.double() \n",
        "    inputs  = inputs.to(\"cuda\")\n",
        "    output, alphas, avg_images = classify_ct(inputs)\n",
        "    output = output.cpu().detach().numpy()\n",
        "    indexes = np.arange(output.shape[0]), np.argsort(output, axis=1)[:, -2]\n",
        "    second_largest = output[indexes]\n",
        "    margin.append(np.diag(output[:,labels]) - second_largest)\n",
        "\n",
        "margin = np.concatenate(margin,axis=0)\n",
        "margin = np.percentile(margin[margin>0],5)\n",
        "print(margin)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.010290425296221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P78adR7jIHM4",
        "outputId": "d37fe7ad-4692-44a2-d3d3-90795a1be80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "max_alpha =[]\n",
        "for i, data in  enumerate(train_loader):\n",
        "  inputs , labels = data\n",
        "  inputs = inputs.double()\n",
        "  inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "  _, alphas, _ = classify_ct(inputs)\n",
        "  mx,_ = torch.max(alphas,1)\n",
        "  max_alpha.append(mx.cpu().detach().numpy())\n",
        "max_alpha = np.concatenate(max_alpha,axis=0)\n",
        "print(max_alpha.shape)\n",
        "plt.figure(figsize=(6,6))\n",
        "_,bins,_ = plt.hist(max_alpha,bins=50,color =\"c\")\n",
        "plt.title(\"alpha values histogram\")\n",
        "plt.savefig(\"attention_model_2_hist\")"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mb7_sQTQ2ms",
        "outputId": "ddf3959e-aa32-4154-bb2b-428ec61dd25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "norm_weight = 1\n",
        "i = 0\n",
        "for weights in classify_ct.parameters():\n",
        "  norm_weight *= np.linalg.norm(weights.cpu().detach().numpy())**2\n",
        "  i =i+1\n",
        "\n",
        "print(norm_weight)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255042257838873.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnW8tiwibTxb"
      },
      "source": [
        "with torch.no_grad():\n",
        "  for p in classify_ct.parameters():\n",
        "    p.data.copy_( (p*p).data)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV-trZd5c5eH",
        "outputId": "86b24612-7e04-42e9-f7df-eab5ce7d8196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs = torch.tensor(np.ones(next(iter(train_loader))[0].shape)).to(\"cuda\")\n",
        "outputs,_,_ = classify_ct(inputs)\n",
        "path_norm = np.sqrt(np.sum(outputs[0].cpu().detach().numpy()))\n",
        "print(path_norm)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110.62136599654703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyQK_2K2rGdK"
      },
      "source": [
        "# Sharpness\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OPRPgE9rFw_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFifHu-CrD6G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV082_iNIGMC"
      },
      "source": [
        "# Analysis on both random train both Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scFA7u5LILOR"
      },
      "source": [
        "MIN = 100000\n",
        "MAX = -100000\n",
        "i = 0\n",
        "for param in classify.parameters():\n",
        "  if i %2 == 0:\n",
        "    min_value = np.min(param.cpu().detach().numpy())\n",
        "    max_value = np.max(param.cpu().detach().numpy())\n",
        "    if MIN > min_value:\n",
        "      MIN = min_value\n",
        "    if MAX < max_value:\n",
        "      MAX = max_value \n",
        "  i = i+1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfy5-OToKK5L",
        "outputId": "17fcfb3c-7805-4a03-8475-f9a19036dc68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MIN,MAX"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.2381426818007577, 1.1129292140413958)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7FMmE3iKMha",
        "outputId": "117ffcce-8218-4b2e-e726-052724c3891e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify.eval()\n",
        "margin = []\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels  = data\n",
        "    inputs = inputs.double() \n",
        "    inputs  = inputs.to(\"cuda\")\n",
        "    output, alphas, avg_images = classify(inputs)\n",
        "    output = output.cpu().detach().numpy()\n",
        "    indexes = np.arange(output.shape[0]), np.argsort(output, axis=1)[:, -2]\n",
        "    second_largest = output[indexes]\n",
        "    margin.append(np.diag(output[:,labels]) - second_largest)\n",
        "\n",
        "margin = np.concatenate(margin,axis=0)\n",
        "margin = np.percentile(margin[margin>0],5)\n",
        "print(margin)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.628978227614205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1MVv2vIOsDD",
        "outputId": "1280b22e-2604-47a4-c159-a1acd208ecf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "norm_weight = 1\n",
        "i = 0 \n",
        "for weights in classify.parameters():\n",
        "  norm_weight *= np.linalg.norm(weights.cpu().detach().numpy())\n",
        "print(norm_weight)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66608444571.48307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQwrlxQdT-ow"
      },
      "source": [
        "with torch.no_grad():\n",
        "  for p in classify.parameters():\n",
        "    p.data.copy_( (p*p).data)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fyqK6iSU4tk",
        "outputId": "6372373c-9582-4a86-ad3f-a6e236c9a938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs = torch.tensor(np.ones(next(iter(train_loader))[0].shape)).to(\"cuda\")\n",
        "outputs,_,_ = classify(inputs)\n",
        "path_norm = np.sqrt(np.sum(outputs[0].cpu().detach().numpy()))\n",
        "print(path_norm)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.766916528253006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZk6kw73VrMz",
        "outputId": "402ce221-b21d-43ea-90e3-9f45f116125c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "max_alpha =[]\n",
        "for i, data in  enumerate(train_loader):\n",
        "  inputs , labels = data\n",
        "  inputs = inputs.double()\n",
        "  inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "  _, alphas, _ = classify(inputs)\n",
        "  mx,_ = torch.max(alphas,1)\n",
        "  max_alpha.append(mx.cpu().detach().numpy())\n",
        "max_alpha = np.concatenate(max_alpha,axis=0)\n",
        "print(max_alpha.shape)\n",
        "plt.figure(figsize=(6,6))\n",
        "_,bins,_ = plt.hist(max_alpha,bins=50,color =\"c\")\n",
        "plt.title(\"alpha values histogram\")\n",
        "plt.savefig(\"attention_model_1_hist\")"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkL5y3ITrMlF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMDAo3XTrLgu"
      },
      "source": [
        "# Sharpness\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTbNLYPDngm6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}