{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "15 focus_pretrained_classify_pretrained_train_focus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be5f8df5-e140-4f04-f3f1-628aea65fa49"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acRFqJNrZErV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3c9ad0ad-ec9b-48fb-fdd0-06e714018327"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V_JUhwCeZErk",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SadRzWBBZEsP",
        "colab": {}
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 2)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBQffkIzTOsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c5388e4-ccc8-4e74-fa78-6d51185a9571"
      },
      "source": [
        "focus_net.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Focus_net_weights/focus_net_6layer_cnn.pt\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZtcA4VOTVxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f99783d-c1ab-4706-cbce-b648150fd337"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=2, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMpRf9RETYRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "63d27e12-f9ec-44fa-f2de-4faa19d90353"
      },
      "source": [
        "print(focus_net.fc4)\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)\n",
        "temp = focus_net.fc4.weight.data\n",
        "temp2 = focus_net.fc4.bias.data\n",
        "focus_net.fc4 = nn.Linear(10,1).double()\n",
        "focus_net.fc4.weight.data = torch.unsqueeze(temp[1,:], 0)\n",
        "focus_net.fc4.bias.data = torch.unsqueeze(temp2[1], 0)\n",
        "focus_net = focus_net.to(\"cuda\")\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=10, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.3974,  0.2455,  0.2787, -0.4295, -0.5508,  0.8661, -0.2221, -0.6396,\n",
            "          0.5014,  0.1486],\n",
            "        [-0.1227,  0.1252, -0.0242,  0.3076,  0.7789, -0.7985, -0.2840,  0.6068,\n",
            "         -0.5138,  0.2816]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2738,  0.0337], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1227,  0.1252, -0.0242,  0.3076,  0.7789, -0.7985, -0.2840,  0.6068,\n",
            "         -0.5138,  0.2816]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0337], device='cuda:0', dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WFfxQ_3TYF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a70d017-3345-4fe9-8e49-059ee8c52a80"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=1, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6tBJqBaTnl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   params.requires_grad = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLhPEuVoUBC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "149f9b38-95ac-4e16-f079-d353faf935fa"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwcTiFhGThJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de42a681-67f9-4aa7-e11d-a7a6757525ac"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.0155e-01,  1.8843e-01, -3.7371e-01],\n",
            "          [ 1.3882e-01,  3.1465e-01, -2.3114e-01],\n",
            "          [-9.8712e-02,  1.7628e-01, -4.7682e-02]],\n",
            "\n",
            "         [[-1.7731e-01,  2.7669e-01, -1.6959e-02],\n",
            "          [-1.3041e-01,  1.1654e-01, -2.3628e-02],\n",
            "          [-1.8088e-01,  1.7182e-02,  2.2703e-01]],\n",
            "\n",
            "         [[ 2.6718e-01,  4.5371e-01, -1.1744e-02],\n",
            "          [ 1.3648e-01,  2.1359e-02, -3.3651e-01],\n",
            "          [-3.4207e-01, -2.8405e-01,  2.1965e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4553e-01, -3.1102e-01, -1.5143e-01],\n",
            "          [-7.8231e-02, -2.3423e-01, -1.1562e-01],\n",
            "          [ 4.3292e-03, -2.9985e-01, -1.6135e-01]],\n",
            "\n",
            "         [[ 2.3403e-01, -7.7107e-02,  2.3617e-01],\n",
            "          [ 7.9921e-03, -1.3719e-03, -1.2427e-01],\n",
            "          [-2.4708e-03, -1.7089e-01,  1.4559e-01]],\n",
            "\n",
            "         [[ 6.0008e-02,  2.2231e-01,  2.0222e-01],\n",
            "          [ 2.2929e-01, -5.4566e-03,  7.7658e-02],\n",
            "          [ 2.1009e-01, -2.0395e-02,  3.0434e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8955e-02, -8.9080e-02, -7.6312e-02],\n",
            "          [ 1.6654e-01,  9.1395e-02, -1.7210e-01],\n",
            "          [ 7.2608e-02,  3.6598e-02, -2.0946e-01]],\n",
            "\n",
            "         [[ 4.9694e-02,  3.4286e-02,  9.6677e-02],\n",
            "          [-9.4347e-02,  1.9066e-01, -1.7569e-01],\n",
            "          [ 2.2628e-01,  1.8944e-01,  1.0318e-01]],\n",
            "\n",
            "         [[-9.5871e-03,  2.3965e-02, -2.2961e-01],\n",
            "          [ 5.0691e-03, -1.2477e-03,  4.3030e-02],\n",
            "          [ 1.1552e-01,  5.2009e-02,  4.5297e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1273e-02,  1.1986e-01,  1.9651e-01],\n",
            "          [-1.0910e-01,  2.1594e-01,  2.3334e-01],\n",
            "          [-7.5300e-02, -1.2681e-01, -5.3049e-02]],\n",
            "\n",
            "         [[-4.8859e-02, -8.2950e-02, -1.8400e-01],\n",
            "          [-2.3791e-01, -8.6627e-02, -1.3185e-01],\n",
            "          [-1.8958e-02, -8.0871e-02, -1.0580e-01]],\n",
            "\n",
            "         [[-7.4944e-02, -1.2411e-01, -5.2474e-02],\n",
            "          [-2.0770e-02,  1.5161e-01, -1.6706e-01],\n",
            "          [-4.3331e-02,  1.3538e-01, -1.8715e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.3778e-03, -7.8674e-02,  1.9848e-01],\n",
            "          [-2.3493e-01,  1.7573e-01,  2.7151e-01],\n",
            "          [-2.2664e-02, -1.1002e-02, -6.5587e-02]],\n",
            "\n",
            "         [[ 1.9978e-01,  1.4815e-02,  1.0615e-02],\n",
            "          [ 2.0002e-01, -1.1983e-01,  1.5939e-01],\n",
            "          [-2.4128e-01, -1.4317e-01,  8.0474e-02]],\n",
            "\n",
            "         [[-1.4341e-01, -1.1064e-01, -2.6179e-01],\n",
            "          [ 2.1648e-01, -9.9564e-02,  1.6842e-02],\n",
            "          [ 1.1194e-01,  1.4890e-02,  1.9808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5718e-01,  6.6356e-03, -8.6083e-02],\n",
            "          [ 8.0345e-02, -1.1381e-01, -4.6426e-03],\n",
            "          [-1.2109e-01,  1.1055e-01,  2.1551e-01]],\n",
            "\n",
            "         [[ 1.5790e-01, -7.3243e-04, -1.1624e-01],\n",
            "          [ 2.9433e-01,  1.5650e-01, -2.7937e-01],\n",
            "          [ 1.0816e-01, -4.2703e-02,  1.1360e-01]],\n",
            "\n",
            "         [[-2.3966e-02, -1.7138e-01, -5.5875e-02],\n",
            "          [-1.1881e-01, -1.9345e-01, -3.4012e-01],\n",
            "          [ 7.5994e-02, -1.8580e-01,  5.1822e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5608e-01,  1.4220e-01, -1.9261e-01],\n",
            "          [ 2.8186e-01, -1.1467e-01, -3.0065e-02],\n",
            "          [-1.9499e-01, -8.0530e-04,  1.7978e-01]],\n",
            "\n",
            "         [[-2.9561e-01, -1.4465e-01, -3.8936e-02],\n",
            "          [ 2.7009e-01, -1.0709e-01,  1.9911e-01],\n",
            "          [-1.6047e-01,  1.9247e-01,  2.6052e-01]],\n",
            "\n",
            "         [[-1.3410e-01, -1.0264e-01, -2.3493e-01],\n",
            "          [ 3.7941e-01, -4.1826e-02, -2.3835e-01],\n",
            "          [ 1.5829e-01,  1.4479e-01, -7.7649e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4260e-02,  7.2909e-02, -4.9308e-01],\n",
            "          [ 1.9709e-01,  2.9608e-01,  4.4813e-02],\n",
            "          [ 1.8176e-01,  3.3937e-01,  1.7607e-01]],\n",
            "\n",
            "         [[-5.0911e-02,  2.4422e-01, -2.6483e-01],\n",
            "          [-2.5324e-01, -2.8686e-01, -1.1130e-01],\n",
            "          [-7.3526e-02, -1.8883e-01, -1.8568e-01]],\n",
            "\n",
            "         [[-3.3020e-02,  3.4905e-01,  9.6184e-02],\n",
            "          [ 9.3889e-02,  5.0457e-02, -4.1922e-02],\n",
            "          [-2.5109e-02, -1.0685e-01, -1.3722e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4828e-02,  9.2095e-04, -7.6290e-02],\n",
            "          [ 3.3454e-02,  3.7860e-01, -2.8654e-01],\n",
            "          [ 1.4552e-01,  7.2081e-02, -1.9682e-01]],\n",
            "\n",
            "         [[-3.7882e-02,  2.0972e-01, -2.3378e-01],\n",
            "          [-7.0486e-02,  4.0031e-01, -3.3082e-01],\n",
            "          [-2.2034e-01,  2.4179e-01, -7.7592e-02]],\n",
            "\n",
            "         [[-2.3171e-01,  2.7509e-01, -2.9406e-02],\n",
            "          [-2.5366e-01,  5.2276e-01, -3.5181e-01],\n",
            "          [ 4.7083e-02,  1.1258e-01, -2.4963e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2920e-02,  1.1366e-01, -1.0895e-01],\n",
            "          [-5.3343e-02,  1.6217e-02, -2.0651e-02],\n",
            "          [ 1.1660e-01,  9.8321e-02, -1.2359e-01]],\n",
            "\n",
            "         [[-3.4368e-02, -7.0742e-02, -2.5050e-01],\n",
            "          [-2.7087e-02,  1.4293e-01, -2.2920e-01],\n",
            "          [ 1.4525e-01,  1.4925e-02, -2.0972e-01]],\n",
            "\n",
            "         [[-2.4625e-01, -2.5307e-03, -2.1292e-02],\n",
            "          [ 2.9386e-02,  8.7204e-02,  1.4329e-01],\n",
            "          [ 2.4719e-01,  2.8453e-01,  9.2273e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.5100e-01, -1.5544e-01,  3.7412e-01],\n",
            "          [ 3.4293e-01, -6.4277e-02, -1.9676e-01],\n",
            "          [ 1.5227e-01, -4.3687e-02, -1.8680e-01]],\n",
            "\n",
            "         [[-3.5154e-01, -4.3465e-02,  7.8562e-02],\n",
            "          [ 3.2783e-01, -9.1473e-02, -7.4105e-02],\n",
            "          [ 1.5686e-01,  6.4711e-03,  4.9247e-02]],\n",
            "\n",
            "         [[ 1.0901e-01,  1.3724e-01,  1.4471e-01],\n",
            "          [ 3.8507e-01, -1.8206e-01, -9.0550e-02],\n",
            "          [ 1.8527e-02, -2.1300e-01, -2.1008e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.0009e-01,  5.2350e-02, -1.7434e-02],\n",
            "          [-1.3890e-01, -2.8554e-01,  1.3410e-01],\n",
            "          [-3.7519e-02, -5.1394e-01,  6.2113e-02]],\n",
            "\n",
            "         [[ 4.7610e-02,  1.4115e-01,  1.9123e-02],\n",
            "          [ 3.4660e-01,  1.0914e-01,  2.8330e-01],\n",
            "          [ 3.0530e-01, -1.6982e-01,  2.7858e-01]],\n",
            "\n",
            "         [[ 3.8899e-02, -4.2711e-03, -1.3205e-01],\n",
            "          [ 1.0196e-01, -2.7844e-01, -8.7242e-03],\n",
            "          [ 1.2730e-01, -2.8913e-01, -8.2701e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6047e-01,  3.1003e-01, -1.1233e-01],\n",
            "          [ 3.3223e-01,  2.9437e-01, -9.5160e-02],\n",
            "          [ 2.0716e-01, -2.9966e-01, -3.4367e-01]],\n",
            "\n",
            "         [[-2.8085e-01,  1.4637e-01, -3.4782e-02],\n",
            "          [ 1.6125e-03,  1.8891e-01,  2.3948e-01],\n",
            "          [-1.1145e-01, -1.3817e-01, -1.6709e-01]],\n",
            "\n",
            "         [[-4.5610e-01,  2.2247e-01,  2.1565e-01],\n",
            "          [-1.8045e-01, -1.5446e-01,  1.1526e-01],\n",
            "          [-1.5825e-01,  7.3281e-02,  3.5264e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1864e-01, -6.0254e-02,  9.2982e-02],\n",
            "          [ 1.4388e-01, -7.3523e-02, -2.0167e-01],\n",
            "          [-2.3147e-01,  1.1375e-01,  7.0444e-02]],\n",
            "\n",
            "         [[-4.4879e-02,  1.4091e-01, -1.9945e-01],\n",
            "          [ 2.1282e-01,  2.5781e-01,  1.0941e-01],\n",
            "          [-8.7437e-02,  1.2557e-01, -1.6704e-01]],\n",
            "\n",
            "         [[-8.5735e-02, -2.8465e-02, -7.9197e-02],\n",
            "          [ 5.6643e-02,  2.0363e-01,  4.2784e-02],\n",
            "          [ 8.6233e-03, -2.0354e-02, -3.6712e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.3492e-02, -1.5458e-01,  5.7564e-03],\n",
            "          [-3.7472e-02,  1.1123e-01, -2.3172e-01],\n",
            "          [ 1.0602e-01, -1.8604e-02, -1.4651e-01]],\n",
            "\n",
            "         [[-2.5336e-04, -5.2469e-03,  1.1831e-01],\n",
            "          [ 4.4008e-02, -9.3524e-02, -9.1982e-02],\n",
            "          [ 3.3203e-02, -1.1195e-01,  5.3600e-02]],\n",
            "\n",
            "         [[ 7.1521e-02,  3.1856e-02,  1.9880e-01],\n",
            "          [ 9.1581e-02, -6.5490e-02, -2.6157e-01],\n",
            "          [-6.2403e-02,  3.3127e-02, -9.8168e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4214e-01, -2.6254e-01, -2.4894e-01],\n",
            "          [ 6.0782e-02,  1.4442e-01, -4.1070e-02],\n",
            "          [ 2.3767e-01,  3.2218e-01,  1.7166e-01]],\n",
            "\n",
            "         [[ 6.9931e-02,  3.2418e-03,  5.9026e-02],\n",
            "          [ 9.8867e-02, -7.6754e-02, -1.1897e-01],\n",
            "          [-1.5324e-01,  2.3701e-01,  7.7406e-02]],\n",
            "\n",
            "         [[-1.8112e-02,  3.6124e-02,  8.8124e-02],\n",
            "          [ 5.1065e-03,  1.4502e-01, -1.0826e-01],\n",
            "          [-1.1482e-01,  1.5715e-01, -2.1675e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9496e-02, -2.3513e-01,  1.3399e-01],\n",
            "          [ 1.5434e-02,  1.2206e-01,  1.7543e-01],\n",
            "          [ 1.8777e-01,  6.9283e-02,  3.6612e-02]],\n",
            "\n",
            "         [[ 1.0813e-01, -9.1666e-02, -5.8822e-02],\n",
            "          [-1.7935e-01, -1.3325e-01, -9.2677e-02],\n",
            "          [ 1.5984e-02,  1.3427e-01, -1.9313e-01]],\n",
            "\n",
            "         [[-1.0145e-01, -1.7560e-01, -1.0277e-01],\n",
            "          [-4.1589e-02, -2.2296e-01, -2.0368e-02],\n",
            "          [-5.1968e-02, -9.4545e-02, -1.5786e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.8242e-01, -1.6982e-02,  1.2589e-01],\n",
            "          [-3.1782e-02, -1.3494e-02, -2.8895e-01],\n",
            "          [ 1.3941e-01, -1.0287e-01, -1.0379e-01]],\n",
            "\n",
            "         [[-2.7262e-01,  1.4852e-01,  1.4684e-01],\n",
            "          [ 7.8490e-02,  2.7467e-01,  1.6855e-02],\n",
            "          [ 3.8027e-01,  3.0940e-01,  1.7866e-02]],\n",
            "\n",
            "         [[-3.0519e-01,  2.7818e-02,  1.2216e-01],\n",
            "          [-2.1921e-01, -7.9760e-02, -2.0103e-04],\n",
            "          [ 1.7404e-01, -1.8248e-01, -1.4009e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0714e-01,  1.7765e-01, -3.0915e-01],\n",
            "          [-2.0353e-02, -1.6578e-01,  3.7074e-01],\n",
            "          [ 1.7386e-01, -2.7412e-01,  2.9055e-02]],\n",
            "\n",
            "         [[-1.2439e-01,  1.0872e-01, -1.7823e-01],\n",
            "          [-1.0632e-01, -2.9516e-01,  3.7788e-01],\n",
            "          [ 3.0583e-01, -4.0840e-01,  1.3042e-01]],\n",
            "\n",
            "         [[ 2.9924e-01,  8.6759e-02, -3.3583e-01],\n",
            "          [-1.1813e-02, -2.6363e-01,  4.2833e-01],\n",
            "          [-3.5804e-02, -3.3204e-01,  2.4581e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.5675e-02,  2.5866e-01,  1.2688e-01],\n",
            "          [-1.1888e-01,  2.3120e-01,  1.8862e-01],\n",
            "          [-1.0078e-01, -2.2704e-01, -3.4244e-01]],\n",
            "\n",
            "         [[ 2.7898e-02,  2.4486e-01,  1.8591e-01],\n",
            "          [ 2.0807e-01,  1.1544e-01,  4.7624e-03],\n",
            "          [ 3.2926e-02,  1.8853e-01, -1.2424e-01]],\n",
            "\n",
            "         [[-2.4558e-01, -1.8506e-01, -1.5971e-01],\n",
            "          [-2.0672e-01,  2.0476e-02, -1.1053e-01],\n",
            "          [ 2.1770e-01,  2.2833e-01, -8.8387e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.5205e-02,  1.5520e-01, -1.9695e-01],\n",
            "          [-7.9760e-02,  8.1679e-02, -6.8232e-02],\n",
            "          [ 1.6093e-03, -1.5213e-01, -1.2683e-01]],\n",
            "\n",
            "         [[ 1.8469e-01, -3.6921e-02, -1.7115e-01],\n",
            "          [ 8.1758e-02, -1.6792e-01, -6.7049e-02],\n",
            "          [ 1.6663e-01, -6.6594e-02,  1.2634e-01]],\n",
            "\n",
            "         [[-3.6184e-01, -6.5170e-02, -1.0652e-01],\n",
            "          [-4.7971e-01,  1.4482e-01,  4.2907e-01],\n",
            "          [-2.5983e-01,  2.9876e-01,  5.4646e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8698e-02, -1.1509e-01,  3.1465e-01],\n",
            "          [-2.2665e-01,  1.1842e-01, -1.0207e-01],\n",
            "          [-2.1049e-01, -7.1634e-02,  2.3764e-01]],\n",
            "\n",
            "         [[ 1.5028e-01, -1.8738e-01,  1.2004e-01],\n",
            "          [ 1.6371e-01, -1.7511e-03, -2.4908e-01],\n",
            "          [-5.7438e-02,  2.1253e-01,  4.7965e-02]],\n",
            "\n",
            "         [[ 2.8607e-01, -1.4524e-01, -2.5859e-01],\n",
            "          [ 2.9987e-01,  5.0431e-02, -5.1815e-01],\n",
            "          [ 2.1397e-01,  2.9649e-01, -3.1808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8467e-02, -9.7171e-02, -6.5884e-02],\n",
            "          [ 4.7044e-03, -1.2399e-01,  1.3729e-01],\n",
            "          [-1.0409e-01,  1.7758e-01,  1.4271e-01]],\n",
            "\n",
            "         [[ 1.8816e-01,  7.7143e-02, -1.2912e-02],\n",
            "          [ 1.1297e-01, -2.5210e-01, -2.2299e-01],\n",
            "          [-2.8796e-01,  8.2649e-02, -8.7493e-02]],\n",
            "\n",
            "         [[ 2.1926e-01,  2.2060e-01,  1.7361e-01],\n",
            "          [-2.0023e-02,  1.5427e-01,  6.1582e-02],\n",
            "          [-2.0668e-01, -1.0826e-01,  1.1648e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5940e-01,  1.1073e-01, -1.7217e-02],\n",
            "          [-1.0682e-01,  6.4494e-02,  1.4025e-01],\n",
            "          [-8.2975e-02, -1.8486e-01, -2.2712e-01]],\n",
            "\n",
            "         [[-8.8423e-02,  1.4320e-01, -2.0304e-02],\n",
            "          [-5.0818e-03,  1.7296e-01, -8.4649e-02],\n",
            "          [ 6.2910e-03, -1.7587e-01, -2.0314e-02]],\n",
            "\n",
            "         [[-8.5325e-02, -1.5731e-01, -1.0675e-01],\n",
            "          [ 1.9048e-01,  1.6936e-01,  6.7662e-03],\n",
            "          [-2.7817e-05,  9.5952e-02, -2.4236e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1579e-01,  1.7570e-01, -1.1779e-01],\n",
            "          [ 2.0060e-03, -1.0404e-01,  1.3824e-01],\n",
            "          [-1.1473e-01,  3.1071e-02,  1.7744e-01]],\n",
            "\n",
            "         [[ 6.9442e-02, -1.5036e-02,  5.4487e-02],\n",
            "          [-5.8634e-02, -1.4846e-01,  9.5080e-02],\n",
            "          [ 1.6324e-01, -1.5676e-02, -8.4563e-02]],\n",
            "\n",
            "         [[ 1.1528e-01, -1.1609e-01,  2.9263e-03],\n",
            "          [ 5.4937e-02, -1.5815e-01,  1.8128e-01],\n",
            "          [ 1.5560e-01,  1.3262e-01,  1.8461e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1694e-01, -2.9142e-01, -2.6329e-01],\n",
            "          [-1.2755e-01, -1.9556e-01,  3.8795e-02],\n",
            "          [ 3.4141e-01,  3.4313e-01,  1.9673e-01]],\n",
            "\n",
            "         [[-1.2067e-01, -2.4652e-01,  3.6027e-03],\n",
            "          [-1.8045e-01,  1.0407e-01, -1.6403e-01],\n",
            "          [ 5.5994e-02,  2.2146e-01, -1.2961e-01]],\n",
            "\n",
            "         [[ 1.9381e-01, -3.1823e-02,  2.0926e-01],\n",
            "          [ 7.3488e-02, -8.3086e-02,  2.8715e-02],\n",
            "          [-1.1377e-01,  2.3878e-01, -1.3486e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6004e-02,  2.2558e-01,  1.3777e-01],\n",
            "          [ 1.4699e-01, -1.7660e-01, -9.6174e-02],\n",
            "          [-8.1804e-02, -1.1437e-01, -6.4043e-02]],\n",
            "\n",
            "         [[-1.8785e-01,  1.2662e-01,  1.1054e-01],\n",
            "          [ 6.8984e-02, -1.8815e-01, -4.3549e-02],\n",
            "          [ 2.6759e-01, -7.3002e-02, -8.8331e-02]],\n",
            "\n",
            "         [[-2.2460e-01, -8.1323e-02,  2.9143e-01],\n",
            "          [-2.5683e-01, -9.4635e-02,  2.5643e-01],\n",
            "          [-1.2625e-02, -2.2122e-01,  4.7715e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.8392e-02, -2.1575e-01, -2.8500e-02],\n",
            "          [-2.5681e-01, -2.5748e-01,  1.5143e-01],\n",
            "          [ 2.5797e-01,  3.1017e-01,  5.0137e-03]],\n",
            "\n",
            "         [[ 8.3711e-02, -2.3980e-01, -7.0890e-02],\n",
            "          [-9.5829e-02, -1.9823e-01,  2.7156e-01],\n",
            "          [-2.6914e-02,  2.7501e-01, -3.1315e-02]],\n",
            "\n",
            "         [[-1.3819e-01,  4.2787e-02,  3.4596e-02],\n",
            "          [-1.1717e-01, -1.7322e-01,  1.3440e-01],\n",
            "          [ 4.9149e-02, -5.2634e-02, -1.1780e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1362e-01,  4.8102e-02,  3.4139e-01],\n",
            "          [ 3.4290e-02, -2.4965e-01,  2.7953e-01],\n",
            "          [-1.6447e-01,  9.0822e-04,  2.3792e-01]],\n",
            "\n",
            "         [[-4.8142e-02, -1.0798e-01,  3.7232e-01],\n",
            "          [-1.0745e-02, -4.9819e-01,  8.5103e-02],\n",
            "          [ 1.1553e-01, -2.4784e-01,  1.5701e-01]],\n",
            "\n",
            "         [[-1.1495e-01, -2.1601e-01,  1.0106e-01],\n",
            "          [ 2.3005e-01, -3.2803e-01, -8.3869e-02],\n",
            "          [ 2.2454e-01, -1.0049e-02,  2.0753e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3836e-01,  3.2456e-01,  3.3695e-01],\n",
            "          [-2.4138e-01, -2.9768e-01, -1.5685e-01],\n",
            "          [-9.5723e-02, -7.9013e-02, -1.9312e-01]],\n",
            "\n",
            "         [[ 1.3153e-01,  6.7787e-02,  2.1433e-01],\n",
            "          [-2.6171e-01, -2.9836e-01, -2.0850e-01],\n",
            "          [ 1.0682e-01,  1.0624e-01, -1.6899e-01]],\n",
            "\n",
            "         [[ 1.7010e-01, -3.2429e-02, -1.2887e-02],\n",
            "          [-3.4082e-02, -2.3638e-01, -8.2708e-02],\n",
            "          [ 8.6260e-02,  2.9735e-01, -1.4077e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4088e-01,  2.0552e-01, -6.8858e-02],\n",
            "          [-1.4319e-02, -1.5148e-01, -2.4972e-01],\n",
            "          [ 2.8147e-01, -1.4573e-01, -1.2848e-01]],\n",
            "\n",
            "         [[-1.1730e-01, -4.3468e-02, -1.5309e-01],\n",
            "          [ 6.0057e-02, -1.9846e-01, -1.4349e-02],\n",
            "          [ 2.6214e-01,  1.4849e-01, -1.9905e-01]],\n",
            "\n",
            "         [[-1.7688e-01,  2.2597e-01, -1.7985e-01],\n",
            "          [ 1.3996e-01, -6.4199e-02, -1.3442e-01],\n",
            "          [ 2.9831e-01, -8.8765e-04,  5.7207e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.3738e-02, -6.5191e-02,  1.1433e-01],\n",
            "          [-5.4104e-02,  1.0246e-01,  1.1657e-01],\n",
            "          [-2.1356e-01, -1.6824e-01,  6.3947e-02]],\n",
            "\n",
            "         [[-9.3507e-02, -3.5852e-02,  4.9805e-02],\n",
            "          [ 1.4713e-01, -1.3346e-01, -1.2432e-01],\n",
            "          [-2.2472e-01, -1.8936e-01,  1.7751e-01]],\n",
            "\n",
            "         [[-7.8939e-02,  4.8241e-02, -1.3442e-01],\n",
            "          [ 1.6475e-02, -3.7413e-02,  2.9886e-01],\n",
            "          [-2.3843e-01, -1.1041e-02,  1.7069e-01]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9554ce5f-d03d-44c7-9527-56eb261dd3fd"
      },
      "source": [
        "classify.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Classify_net_weights/classify_net_6layer_cnn.pt\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJSnUYJyS0Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for params in classify.parameters():\n",
        "  params.requires_grad = False"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JM19FiENmBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04ad3733-63b5-483e-f53e-67da1e0ce864"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break\n",
        "  "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0rkwoqLpya8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc8d91f4-d527-41ed-91d5-1616975492df"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0309,  0.1087,  0.1955],\n",
            "          [ 0.2209,  0.0076,  0.0348],\n",
            "          [-0.0854,  0.0774, -0.0973]],\n",
            "\n",
            "         [[ 0.0616, -0.1282,  0.2080],\n",
            "          [ 0.0332, -0.1826, -0.1365],\n",
            "          [-0.1557, -0.0844, -0.1973]],\n",
            "\n",
            "         [[-0.0722,  0.0364,  0.1260],\n",
            "          [ 0.0611, -0.0341,  0.1729],\n",
            "          [ 0.0427,  0.0797,  0.0223]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1835,  0.0366, -0.1656],\n",
            "          [-0.0834,  0.1659,  0.0364],\n",
            "          [ 0.1062,  0.2152,  0.1314]],\n",
            "\n",
            "         [[ 0.0086,  0.2094,  0.2249],\n",
            "          [-0.1404, -0.1745,  0.0035],\n",
            "          [-0.2156,  0.0847,  0.0851]],\n",
            "\n",
            "         [[-0.1070,  0.1605, -0.1541],\n",
            "          [-0.0419, -0.0417,  0.0718],\n",
            "          [-0.0668, -0.2273, -0.2890]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1013,  0.0165, -0.0829],\n",
            "          [-0.1709,  0.1888, -0.0619],\n",
            "          [-0.0676,  0.2545,  0.2560]],\n",
            "\n",
            "         [[-0.0495, -0.0233, -0.0692],\n",
            "          [ 0.0196, -0.1944, -0.2639],\n",
            "          [-0.2429,  0.0565,  0.1495]],\n",
            "\n",
            "         [[ 0.2412, -0.1480, -0.1188],\n",
            "          [ 0.0755,  0.0533, -0.1636],\n",
            "          [ 0.1195,  0.0296, -0.0620]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2049,  0.1405, -0.0744],\n",
            "          [ 0.0715,  0.0253,  0.0548],\n",
            "          [-0.0363, -0.0603, -0.0169]],\n",
            "\n",
            "         [[ 0.1719, -0.0024,  0.1642],\n",
            "          [ 0.0824, -0.1403,  0.0444],\n",
            "          [ 0.1660, -0.0140, -0.0213]],\n",
            "\n",
            "         [[-0.1377,  0.0023,  0.0830],\n",
            "          [-0.0201,  0.0463, -0.1071],\n",
            "          [-0.0089, -0.0475,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1722, -0.1703,  0.0900],\n",
            "          [-0.0026, -0.1981, -0.0808],\n",
            "          [-0.0556, -0.0525, -0.0903]],\n",
            "\n",
            "         [[ 0.0469,  0.1535,  0.1791],\n",
            "          [ 0.0031, -0.1002,  0.1474],\n",
            "          [-0.2295,  0.1191,  0.0080]],\n",
            "\n",
            "         [[ 0.1878,  0.0110,  0.1277],\n",
            "          [ 0.0146,  0.1758,  0.1353],\n",
            "          [-0.1670,  0.1439, -0.0813]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1690,  0.1051, -0.0433],\n",
            "          [-0.2494,  0.0010,  0.0629],\n",
            "          [-0.0552,  0.0004,  0.0097]],\n",
            "\n",
            "         [[ 0.1635,  0.3134,  0.0763],\n",
            "          [-0.1233,  0.0560, -0.2310],\n",
            "          [-0.1199, -0.2663, -0.0928]],\n",
            "\n",
            "         [[ 0.0838,  0.1768,  0.0256],\n",
            "          [-0.2400,  0.1630, -0.2009],\n",
            "          [ 0.0774, -0.0150,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1059,  0.0585, -0.1707],\n",
            "          [ 0.1078, -0.0531, -0.0276],\n",
            "          [ 0.1118, -0.0519, -0.1506]],\n",
            "\n",
            "         [[-0.1614,  0.1542, -0.1130],\n",
            "          [ 0.1823,  0.1833,  0.1834],\n",
            "          [ 0.0840, -0.0238,  0.0096]],\n",
            "\n",
            "         [[ 0.1863,  0.0509, -0.1148],\n",
            "          [-0.0720,  0.1801, -0.0417],\n",
            "          [ 0.0088,  0.0210, -0.0527]]],\n",
            "\n",
            "\n",
            "        [[[-0.0021, -0.1920, -0.1925],\n",
            "          [-0.0794, -0.1094, -0.1952],\n",
            "          [ 0.0640, -0.1527, -0.1590]],\n",
            "\n",
            "         [[ 0.0023, -0.0093,  0.0917],\n",
            "          [ 0.1893,  0.1771, -0.0419],\n",
            "          [ 0.1959,  0.0765, -0.1216]],\n",
            "\n",
            "         [[ 0.1127, -0.0509, -0.0890],\n",
            "          [ 0.0425, -0.0004,  0.0970],\n",
            "          [ 0.1725, -0.0294,  0.2238]]],\n",
            "\n",
            "\n",
            "        [[[-0.1533,  0.2030, -0.1170],\n",
            "          [ 0.0515, -0.0504, -0.1635],\n",
            "          [-0.1322, -0.1429,  0.1475]],\n",
            "\n",
            "         [[ 0.0555, -0.0411,  0.2137],\n",
            "          [-0.0274, -0.0902,  0.0513],\n",
            "          [ 0.0085, -0.1591,  0.1483]],\n",
            "\n",
            "         [[ 0.1163, -0.1371,  0.0318],\n",
            "          [ 0.0841, -0.2464, -0.2148],\n",
            "          [ 0.0637,  0.1322,  0.0676]]],\n",
            "\n",
            "\n",
            "        [[[-0.0227,  0.0487,  0.2023],\n",
            "          [-0.1330,  0.1492, -0.0169],\n",
            "          [ 0.1584,  0.1524, -0.0456]],\n",
            "\n",
            "         [[-0.0525, -0.1646, -0.0814],\n",
            "          [-0.2456, -0.1350,  0.0154],\n",
            "          [ 0.2309, -0.1780, -0.0720]],\n",
            "\n",
            "         [[-0.0142,  0.0480,  0.2516],\n",
            "          [-0.1593,  0.1562,  0.1928],\n",
            "          [-0.1119, -0.2044, -0.1976]]],\n",
            "\n",
            "\n",
            "        [[[-0.0355,  0.1166, -0.0631],\n",
            "          [-0.0836, -0.1515,  0.1577],\n",
            "          [ 0.0235,  0.1110, -0.0250]],\n",
            "\n",
            "         [[-0.2114,  0.1654,  0.2484],\n",
            "          [ 0.0525,  0.2583,  0.0362],\n",
            "          [-0.0713,  0.1357, -0.0152]],\n",
            "\n",
            "         [[-0.0821, -0.0350, -0.1481],\n",
            "          [-0.2171,  0.0489,  0.2106],\n",
            "          [ 0.1037, -0.1230,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.1625,  0.1384],\n",
            "          [-0.1124, -0.1412,  0.2642],\n",
            "          [ 0.0284, -0.0494, -0.0447]],\n",
            "\n",
            "         [[ 0.0205, -0.2302,  0.1754],\n",
            "          [ 0.0924, -0.2460,  0.2219],\n",
            "          [ 0.0863, -0.1062,  0.1210]],\n",
            "\n",
            "         [[ 0.2537, -0.2292, -0.1540],\n",
            "          [ 0.2104, -0.2362,  0.1700],\n",
            "          [ 0.2093, -0.2085, -0.0309]]],\n",
            "\n",
            "\n",
            "        [[[-0.1426,  0.1824, -0.2160],\n",
            "          [ 0.0009, -0.0087,  0.0207],\n",
            "          [ 0.0911, -0.2336, -0.1702]],\n",
            "\n",
            "         [[ 0.2153,  0.1894,  0.0243],\n",
            "          [-0.2433,  0.2294,  0.2479],\n",
            "          [-0.0595, -0.1203,  0.1227]],\n",
            "\n",
            "         [[-0.1597,  0.1976, -0.1576],\n",
            "          [-0.1258, -0.0205, -0.1531],\n",
            "          [ 0.1347,  0.0364, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[-0.0633, -0.0466, -0.0325],\n",
            "          [-0.0601,  0.0621, -0.0215],\n",
            "          [-0.0044, -0.0534,  0.0422]],\n",
            "\n",
            "         [[-0.1383, -0.1374, -0.1793],\n",
            "          [-0.0877, -0.1327,  0.0918],\n",
            "          [-0.0787,  0.0740, -0.0112]],\n",
            "\n",
            "         [[ 0.0814,  0.0275, -0.1438],\n",
            "          [-0.0439,  0.1876,  0.1383],\n",
            "          [-0.0834,  0.1108,  0.0304]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0447,  0.0499, -0.1449],\n",
            "          [-0.1171, -0.0733,  0.0182],\n",
            "          [-0.0587, -0.1367, -0.1931]],\n",
            "\n",
            "         [[ 0.0961,  0.0888, -0.0784],\n",
            "          [ 0.0504, -0.1259,  0.0890],\n",
            "          [-0.1473,  0.0371,  0.1020]],\n",
            "\n",
            "         [[ 0.0476, -0.1709, -0.0371],\n",
            "          [ 0.2308,  0.1298,  0.0326],\n",
            "          [-0.0171, -0.0634, -0.1609]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2378, -0.1200, -0.2246],\n",
            "          [ 0.2465,  0.0634, -0.1682],\n",
            "          [-0.0573, -0.1788,  0.0856]],\n",
            "\n",
            "         [[ 0.2020,  0.1478, -0.0181],\n",
            "          [ 0.1683,  0.0819, -0.0775],\n",
            "          [ 0.1869, -0.2327, -0.2108]],\n",
            "\n",
            "         [[-0.0383, -0.1762, -0.0893],\n",
            "          [-0.1869,  0.0115,  0.0917],\n",
            "          [ 0.0562, -0.0899,  0.1009]]],\n",
            "\n",
            "\n",
            "        [[[-0.0911, -0.2512,  0.0277],\n",
            "          [-0.0324,  0.1520,  0.2214],\n",
            "          [ 0.1329, -0.0946,  0.1157]],\n",
            "\n",
            "         [[ 0.1063, -0.1710,  0.0471],\n",
            "          [-0.1126,  0.1777,  0.2435],\n",
            "          [-0.1798,  0.0235,  0.1735]],\n",
            "\n",
            "         [[ 0.0092, -0.1809,  0.0974],\n",
            "          [ 0.1691, -0.1317,  0.1264],\n",
            "          [-0.1224, -0.1659, -0.2023]]],\n",
            "\n",
            "\n",
            "        [[[-0.2336,  0.2346,  0.0983],\n",
            "          [-0.1950, -0.1840,  0.1690],\n",
            "          [-0.2168,  0.0477,  0.0916]],\n",
            "\n",
            "         [[-0.0561,  0.1103,  0.0033],\n",
            "          [-0.0990, -0.2062, -0.0978],\n",
            "          [ 0.1411, -0.0397,  0.0443]],\n",
            "\n",
            "         [[ 0.1579,  0.1184, -0.1102],\n",
            "          [ 0.1775,  0.0325, -0.1486],\n",
            "          [-0.0702,  0.2019,  0.1233]]],\n",
            "\n",
            "\n",
            "        [[[-0.0797,  0.1350,  0.1679],\n",
            "          [-0.0473,  0.2595,  0.1358],\n",
            "          [-0.2849, -0.0974, -0.0081]],\n",
            "\n",
            "         [[-0.1065, -0.1424, -0.1542],\n",
            "          [-0.2096,  0.1828,  0.1126],\n",
            "          [ 0.0174,  0.0576, -0.0152]],\n",
            "\n",
            "         [[-0.2226,  0.0298, -0.1312],\n",
            "          [-0.1327,  0.2087,  0.1935],\n",
            "          [-0.0249,  0.0243, -0.0377]]],\n",
            "\n",
            "\n",
            "        [[[-0.0588,  0.1742,  0.2010],\n",
            "          [ 0.1427, -0.0923,  0.0899],\n",
            "          [-0.1261, -0.1139, -0.0786]],\n",
            "\n",
            "         [[-0.1481,  0.0529,  0.0481],\n",
            "          [ 0.0126, -0.0323,  0.1211],\n",
            "          [-0.0912, -0.0420, -0.1293]],\n",
            "\n",
            "         [[-0.2270, -0.2813, -0.1512],\n",
            "          [ 0.0183, -0.0734, -0.0467],\n",
            "          [ 0.1668,  0.1287,  0.1416]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1385,  0.0580,  0.3274],\n",
            "          [-0.0714, -0.0263,  0.2946],\n",
            "          [-0.2355, -0.3553,  0.0437]],\n",
            "\n",
            "         [[ 0.0762, -0.1933, -0.1612],\n",
            "          [-0.1279,  0.0055, -0.0561],\n",
            "          [ 0.2241, -0.0410,  0.1810]],\n",
            "\n",
            "         [[ 0.1535, -0.1441, -0.1855],\n",
            "          [ 0.2696, -0.1765,  0.0269],\n",
            "          [ 0.2909, -0.1872, -0.1417]]],\n",
            "\n",
            "\n",
            "        [[[-0.1353, -0.0778,  0.2160],\n",
            "          [-0.2453,  0.0684,  0.2713],\n",
            "          [ 0.0924,  0.0206,  0.2311]],\n",
            "\n",
            "         [[-0.1599,  0.0515, -0.0479],\n",
            "          [-0.1464, -0.0211,  0.0214],\n",
            "          [-0.1591, -0.0081, -0.1259]],\n",
            "\n",
            "         [[-0.0057,  0.1981, -0.0700],\n",
            "          [-0.1581,  0.2080,  0.0793],\n",
            "          [-0.2191,  0.0567,  0.0142]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2331, -0.0791, -0.0360],\n",
            "          [ 0.0551, -0.1573, -0.1605],\n",
            "          [ 0.1258, -0.0884, -0.2061]],\n",
            "\n",
            "         [[-0.2222,  0.1591,  0.1350],\n",
            "          [-0.1694, -0.0935,  0.0388],\n",
            "          [-0.0330,  0.1814,  0.0005]],\n",
            "\n",
            "         [[-0.1377, -0.0267,  0.1763],\n",
            "          [-0.2532,  0.2026,  0.1464],\n",
            "          [-0.0366,  0.2414, -0.1755]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0655, -0.1766, -0.2965],\n",
            "          [ 0.0635, -0.1370,  0.2211],\n",
            "          [ 0.0251, -0.0315,  0.2027]],\n",
            "\n",
            "         [[ 0.2559, -0.1553, -0.1362],\n",
            "          [ 0.2658, -0.1706,  0.1501],\n",
            "          [-0.1731, -0.0166, -0.0638]],\n",
            "\n",
            "         [[-0.1674,  0.0792,  0.1900],\n",
            "          [-0.0342, -0.2272,  0.2679],\n",
            "          [-0.0845, -0.0639,  0.0261]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0958,  0.0557, -0.0319],\n",
            "          [ 0.1302, -0.0530, -0.2087],\n",
            "          [ 0.0320,  0.1967, -0.1969]],\n",
            "\n",
            "         [[ 0.1327, -0.1589,  0.1865],\n",
            "          [-0.0338, -0.2036, -0.2538],\n",
            "          [ 0.1661,  0.1607,  0.1042]],\n",
            "\n",
            "         [[-0.2442, -0.0128, -0.1746],\n",
            "          [-0.0988,  0.0191, -0.2384],\n",
            "          [-0.1124,  0.2998,  0.2225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1305, -0.0375, -0.0713],\n",
            "          [-0.0881,  0.0315, -0.0487],\n",
            "          [-0.1159, -0.0198, -0.0042]],\n",
            "\n",
            "         [[-0.1895,  0.1779, -0.0391],\n",
            "          [ 0.1096, -0.0229,  0.0431],\n",
            "          [ 0.1912, -0.0880,  0.1516]],\n",
            "\n",
            "         [[ 0.1237,  0.1648,  0.0864],\n",
            "          [ 0.1106, -0.1358, -0.0593],\n",
            "          [ 0.0834,  0.1760, -0.1148]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0261,  0.0946, -0.2135],\n",
            "          [-0.0508, -0.2134, -0.0804],\n",
            "          [ 0.2161,  0.1251,  0.1160]],\n",
            "\n",
            "         [[ 0.2439,  0.1499,  0.0541],\n",
            "          [-0.1242, -0.3017, -0.1642],\n",
            "          [ 0.1484,  0.0228, -0.0532]],\n",
            "\n",
            "         [[ 0.2827,  0.0027,  0.2216],\n",
            "          [-0.2123, -0.1097, -0.0140],\n",
            "          [-0.1472, -0.1401,  0.1451]]],\n",
            "\n",
            "\n",
            "        [[[-0.0668, -0.0305, -0.1276],\n",
            "          [-0.0389,  0.0897,  0.0144],\n",
            "          [ 0.0437, -0.0369,  0.2345]],\n",
            "\n",
            "         [[ 0.0160, -0.0964, -0.1077],\n",
            "          [ 0.1918,  0.2170,  0.1363],\n",
            "          [-0.1928, -0.0407,  0.0342]],\n",
            "\n",
            "         [[-0.0021, -0.0420,  0.0836],\n",
            "          [ 0.0767,  0.0022,  0.0412],\n",
            "          [-0.1141, -0.0197,  0.0672]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1341, -0.0483, -0.1076],\n",
            "          [-0.1852, -0.0061,  0.0918],\n",
            "          [-0.1238,  0.0374, -0.0902]],\n",
            "\n",
            "         [[ 0.1261, -0.0141, -0.0833],\n",
            "          [-0.1273, -0.2019, -0.1387],\n",
            "          [-0.0098,  0.2122, -0.0161]],\n",
            "\n",
            "         [[ 0.1478,  0.0007, -0.0934],\n",
            "          [-0.1233,  0.0490,  0.0353],\n",
            "          [ 0.2064, -0.1164,  0.1303]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0583, -0.1114,  0.2957],\n",
            "          [ 0.1703, -0.0507,  0.0694],\n",
            "          [-0.1846,  0.1098, -0.1668]],\n",
            "\n",
            "         [[-0.2051, -0.2725, -0.0990],\n",
            "          [-0.1666,  0.0620, -0.0992],\n",
            "          [ 0.1796,  0.0437, -0.2720]],\n",
            "\n",
            "         [[ 0.1627, -0.1647, -0.0541],\n",
            "          [ 0.0633,  0.2490, -0.1993],\n",
            "          [ 0.1262,  0.2773,  0.0247]]],\n",
            "\n",
            "\n",
            "        [[[-0.2300, -0.1971, -0.0127],\n",
            "          [ 0.0639,  0.0679, -0.0152],\n",
            "          [ 0.2227, -0.0215, -0.0974]],\n",
            "\n",
            "         [[-0.2116, -0.0484,  0.1070],\n",
            "          [ 0.1198, -0.1068, -0.0113],\n",
            "          [ 0.1952,  0.0198,  0.0825]],\n",
            "\n",
            "         [[-0.3352,  0.1302,  0.0801],\n",
            "          [ 0.1699,  0.1231,  0.0742],\n",
            "          [ 0.0210, -0.1424,  0.0352]]],\n",
            "\n",
            "\n",
            "        [[[-0.0857,  0.1421,  0.1182],\n",
            "          [ 0.1262,  0.2026,  0.1068],\n",
            "          [ 0.0704, -0.0585, -0.0306]],\n",
            "\n",
            "         [[ 0.1038, -0.1139,  0.0915],\n",
            "          [ 0.1529,  0.1774, -0.1306],\n",
            "          [-0.2282, -0.2159,  0.0512]],\n",
            "\n",
            "         [[-0.1076, -0.1626,  0.0314],\n",
            "          [-0.1577,  0.1472,  0.1330],\n",
            "          [ 0.1294, -0.0155, -0.0551]]]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSjKBRG_t-2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IleJ3J0Bt-yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "185fef17-7713-4e90-fb10-fa28f18c5d10"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29980\n",
            "total train set images 30000\n",
            "focus_true_pred_true 29975 =============> FTPT : 99 %\n",
            "focus_false_pred_true 5 =============> FFPT : 0 %\n",
            "focus_true_pred_false 16 =============> FTPF : 0 %\n",
            "focus_false_pred_false 4 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  30000\n",
            "argmax_less_than_half ==================>  0\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tra3SCft-t_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "9e7d3bc7-b055-44ea-d21d-758442712eff"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n",
            "total correct 9991\n",
            "total train set images 10000\n",
            "focus_true_pred_true 9990 =============> FTPT : 99 %\n",
            "focus_false_pred_true 1 =============> FFPT : 0 %\n",
            "focus_true_pred_false 8 =============> FTPF : 0 %\n",
            "focus_false_pred_false 1 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  10000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tFfAJZkcZEsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "39713207-9347-4666-8d04-f8cca5a0f428"
      },
      "source": [
        "nos_epochs = 500\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    # optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_focus.step()\n",
        "    # optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    col1.append(epoch + 1)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    focus_net.eval()\n",
        "    classify.eval()\n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 0.001\n",
            "[1,   120] loss: 0.002\n",
            "[1,   180] loss: 0.001\n",
            "[1,   240] loss: 0.003\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfZ2k3hXy85T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05010e86-dc8b-4f83-d874-924246ad65c9"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYD8ohJ8fkBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab585e8d-bdcb-492d-8684-dd6b1a65efeb"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0omdiVCzBhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0deb895-313d-4305-82d3-d94d9378f388"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.0051e-01,  1.8984e-01, -3.7233e-01],\n",
            "          [ 1.4016e-01,  3.1619e-01, -2.2997e-01],\n",
            "          [-9.7726e-02,  1.7741e-01, -4.6579e-02]],\n",
            "\n",
            "         [[-1.7615e-01,  2.7823e-01, -1.5446e-02],\n",
            "          [-1.2895e-01,  1.1830e-01, -2.2278e-02],\n",
            "          [-1.7972e-01,  1.8557e-02,  2.2831e-01]],\n",
            "\n",
            "         [[ 2.6824e-01,  4.5527e-01, -1.0437e-02],\n",
            "          [ 1.3806e-01,  2.3478e-02, -3.3491e-01],\n",
            "          [-3.4046e-01, -2.8203e-01,  2.3956e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4526e-01, -3.1090e-01, -1.5127e-01],\n",
            "          [-7.7936e-02, -2.3403e-01, -1.1527e-01],\n",
            "          [ 4.8266e-03, -2.9947e-01, -1.6091e-01]],\n",
            "\n",
            "         [[ 2.3443e-01, -7.6824e-02,  2.3652e-01],\n",
            "          [ 8.4555e-03, -9.8106e-04, -1.2372e-01],\n",
            "          [-1.8125e-03, -1.7034e-01,  1.4621e-01]],\n",
            "\n",
            "         [[ 6.0126e-02,  2.2235e-01,  2.0238e-01],\n",
            "          [ 2.2940e-01, -5.3290e-03,  7.8018e-02],\n",
            "          [ 2.1041e-01, -2.0085e-02,  3.0482e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9050e-02, -8.8824e-02, -7.5899e-02],\n",
            "          [ 1.6669e-01,  9.1660e-02, -1.7178e-01],\n",
            "          [ 7.2792e-02,  3.6914e-02, -2.0914e-01]],\n",
            "\n",
            "         [[ 4.9713e-02,  3.4472e-02,  9.7003e-02],\n",
            "          [-9.4314e-02,  1.9086e-01, -1.7542e-01],\n",
            "          [ 2.2630e-01,  1.8963e-01,  1.0343e-01]],\n",
            "\n",
            "         [[-9.1982e-03,  2.4509e-02, -2.2901e-01],\n",
            "          [ 5.6362e-03, -5.7004e-04,  4.3627e-02],\n",
            "          [ 1.1612e-01,  5.2742e-02,  5.1435e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1911e-02,  1.2072e-01,  1.9750e-01],\n",
            "          [-1.0849e-01,  2.1680e-01,  2.3443e-01],\n",
            "          [-7.4846e-02, -1.2621e-01, -5.2231e-02]],\n",
            "\n",
            "         [[-4.8566e-02, -8.2459e-02, -1.8335e-01],\n",
            "          [-2.3759e-01, -8.6089e-02, -1.3109e-01],\n",
            "          [-1.8730e-02, -8.0507e-02, -1.0523e-01]],\n",
            "\n",
            "         [[-7.4849e-02, -1.2389e-01, -5.2242e-02],\n",
            "          [-2.0603e-02,  1.5190e-01, -1.6670e-01],\n",
            "          [-4.3289e-02,  1.3546e-01, -1.8542e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.9975e-03, -7.9348e-02,  1.9800e-01],\n",
            "          [-2.3559e-01,  1.7524e-01,  2.7141e-01],\n",
            "          [-2.2994e-02, -1.1190e-02, -6.5633e-02]],\n",
            "\n",
            "         [[ 1.9923e-01,  1.4225e-02,  1.0240e-02],\n",
            "          [ 1.9940e-01, -1.2031e-01,  1.5928e-01],\n",
            "          [-2.4160e-01, -1.4336e-01,  8.0383e-02]],\n",
            "\n",
            "         [[-1.4401e-01, -1.1111e-01, -2.6202e-01],\n",
            "          [ 2.1580e-01, -9.9961e-02,  1.6918e-02],\n",
            "          [ 1.1164e-01,  1.4863e-02,  1.9828e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5716e-01,  6.6011e-03, -8.6023e-02],\n",
            "          [ 8.0573e-02, -1.1356e-01, -4.4232e-03],\n",
            "          [-1.2092e-01,  1.1080e-01,  2.1566e-01]],\n",
            "\n",
            "         [[ 1.5799e-01, -6.9980e-04, -1.1617e-01],\n",
            "          [ 2.9460e-01,  1.5677e-01, -2.7916e-01],\n",
            "          [ 1.0835e-01, -4.2454e-02,  1.1372e-01]],\n",
            "\n",
            "         [[-2.3911e-02, -1.7137e-01, -5.5798e-02],\n",
            "          [-1.1859e-01, -1.9328e-01, -3.4004e-01],\n",
            "          [ 7.6202e-02, -1.8563e-01,  5.1784e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5690e-01,  1.4143e-01, -1.9355e-01],\n",
            "          [ 2.8132e-01, -1.1518e-01, -3.0632e-02],\n",
            "          [-1.9514e-01, -1.3569e-03,  1.7865e-01]],\n",
            "\n",
            "         [[-2.9618e-01, -1.4517e-01, -3.9645e-02],\n",
            "          [ 2.6997e-01, -1.0730e-01,  1.9878e-01],\n",
            "          [-1.6018e-01,  1.9232e-01,  2.5977e-01]],\n",
            "\n",
            "         [[-1.3427e-01, -1.0275e-01, -2.3501e-01],\n",
            "          [ 3.7951e-01, -4.1749e-02, -2.3819e-01],\n",
            "          [ 1.5864e-01,  1.4478e-01, -7.8022e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3438e-02,  7.2007e-02, -4.9375e-01],\n",
            "          [ 1.9690e-01,  2.9613e-01,  4.4686e-02],\n",
            "          [ 1.8178e-01,  3.3961e-01,  1.7620e-01]],\n",
            "\n",
            "         [[-5.1787e-02,  2.4330e-01, -2.6553e-01],\n",
            "          [-2.5352e-01, -2.8687e-01, -1.1149e-01],\n",
            "          [-7.3568e-02, -1.8864e-01, -1.8564e-01]],\n",
            "\n",
            "         [[-3.3885e-02,  3.4814e-01,  9.5419e-02],\n",
            "          [ 9.3532e-02,  5.0325e-02, -4.2231e-02],\n",
            "          [-2.5299e-02, -1.0682e-01, -1.3735e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3602e-02,  2.8877e-04, -7.6645e-02],\n",
            "          [ 3.2735e-02,  3.7807e-01, -2.8662e-01],\n",
            "          [ 1.4549e-01,  7.2144e-02, -1.9638e-01]],\n",
            "\n",
            "         [[-3.8824e-02,  2.0932e-01, -2.3404e-01],\n",
            "          [-7.1075e-02,  3.9994e-01, -3.3078e-01],\n",
            "          [-2.2028e-01,  2.4208e-01, -7.6985e-02]],\n",
            "\n",
            "         [[-2.3231e-01,  2.7513e-01, -2.9361e-02],\n",
            "          [-2.5398e-01,  5.2297e-01, -3.5168e-01],\n",
            "          [ 4.7497e-02,  1.1332e-01, -2.4284e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2792e-02,  1.1350e-01, -1.0912e-01],\n",
            "          [-5.3371e-02,  1.6168e-02, -2.0766e-02],\n",
            "          [ 1.1669e-01,  9.8533e-02, -1.2338e-01]],\n",
            "\n",
            "         [[-3.4397e-02, -7.0763e-02, -2.5059e-01],\n",
            "          [-2.7082e-02,  1.4297e-01, -2.2924e-01],\n",
            "          [ 1.4533e-01,  1.5184e-02, -2.0947e-01]],\n",
            "\n",
            "         [[-2.4611e-01, -2.4856e-03, -2.1378e-02],\n",
            "          [ 2.9515e-02,  8.7221e-02,  1.4311e-01],\n",
            "          [ 2.4726e-01,  2.8463e-01,  9.2279e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.5027e-01, -1.5512e-01,  3.7415e-01],\n",
            "          [ 3.4338e-01, -6.4085e-02, -1.9667e-01],\n",
            "          [ 1.5256e-01, -4.3712e-02, -1.8661e-01]],\n",
            "\n",
            "         [[-3.5034e-01, -4.2723e-02,  7.8919e-02],\n",
            "          [ 3.2874e-01, -9.0835e-02, -7.3532e-02],\n",
            "          [ 1.5756e-01,  6.8671e-03,  4.9895e-02]],\n",
            "\n",
            "         [[ 1.1031e-01,  1.3804e-01,  1.4544e-01],\n",
            "          [ 3.8623e-01, -1.8127e-01, -8.9667e-02],\n",
            "          [ 1.9543e-02, -2.1235e-01, -2.0910e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.0089e-01,  5.1278e-02, -1.8742e-02],\n",
            "          [-1.3929e-01, -2.8618e-01,  1.3304e-01],\n",
            "          [-3.7628e-02, -5.1431e-01,  6.1249e-02]],\n",
            "\n",
            "         [[ 4.7328e-02,  1.4067e-01,  1.8531e-02],\n",
            "          [ 3.4660e-01,  1.0900e-01,  2.8284e-01],\n",
            "          [ 3.0542e-01, -1.6993e-01,  2.7800e-01]],\n",
            "\n",
            "         [[ 3.8946e-02, -4.2385e-03, -1.3220e-01],\n",
            "          [ 1.0240e-01, -2.7818e-01, -8.7733e-03],\n",
            "          [ 1.2798e-01, -2.8876e-01, -8.2760e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5954e-01,  3.1072e-01, -1.1171e-01],\n",
            "          [ 3.3269e-01,  2.9502e-01, -9.4760e-02],\n",
            "          [ 2.0752e-01, -2.9879e-01, -3.4285e-01]],\n",
            "\n",
            "         [[-2.8028e-01,  1.4677e-01, -3.4466e-02],\n",
            "          [ 1.7749e-03,  1.8927e-01,  2.3959e-01],\n",
            "          [-1.1123e-01, -1.3743e-01, -1.6641e-01]],\n",
            "\n",
            "         [[-4.5621e-01,  2.2228e-01,  2.1557e-01],\n",
            "          [-1.8089e-01, -1.5440e-01,  1.1529e-01],\n",
            "          [-1.5852e-01,  7.3922e-02,  3.5340e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1898e-01, -5.9837e-02,  9.3436e-02],\n",
            "          [ 1.4396e-01, -7.3363e-02, -2.0134e-01],\n",
            "          [-2.3156e-01,  1.1377e-01,  7.0665e-02]],\n",
            "\n",
            "         [[-4.4621e-02,  1.4129e-01, -1.9901e-01],\n",
            "          [ 2.1280e-01,  2.5790e-01,  1.0970e-01],\n",
            "          [-8.7623e-02,  1.2553e-01, -1.6685e-01]],\n",
            "\n",
            "         [[-8.4904e-02, -2.7524e-02, -7.8310e-02],\n",
            "          [ 5.7143e-02,  2.0424e-01,  4.3514e-02],\n",
            "          [ 8.8651e-03, -1.9955e-02, -3.6092e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.3609e-02, -1.5478e-01,  5.5370e-03],\n",
            "          [-3.7492e-02,  1.1104e-01, -2.3177e-01],\n",
            "          [ 1.0625e-01, -1.8619e-02, -1.4661e-01]],\n",
            "\n",
            "         [[-5.0138e-04, -5.5892e-03,  1.1795e-01],\n",
            "          [ 4.3822e-02, -9.3852e-02, -9.2157e-02],\n",
            "          [ 3.3246e-02, -1.1209e-01,  5.3377e-02]],\n",
            "\n",
            "         [[ 7.1154e-02,  3.1431e-02,  1.9830e-01],\n",
            "          [ 9.1329e-02, -6.5818e-02, -2.6176e-01],\n",
            "          [-6.2475e-02,  3.2931e-02, -9.8393e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4231e-01, -2.6266e-01, -2.4909e-01],\n",
            "          [ 6.0565e-02,  1.4417e-01, -4.1332e-02],\n",
            "          [ 2.3759e-01,  3.2207e-01,  1.7140e-01]],\n",
            "\n",
            "         [[ 6.9795e-02,  3.1409e-03,  5.8925e-02],\n",
            "          [ 9.8683e-02, -7.6970e-02, -1.1916e-01],\n",
            "          [-1.5326e-01,  2.3701e-01,  7.7267e-02]],\n",
            "\n",
            "         [[-1.7969e-02,  3.6303e-02,  8.8207e-02],\n",
            "          [ 5.2759e-03,  1.4512e-01, -1.0826e-01],\n",
            "          [-1.1450e-01,  1.5742e-01, -2.1674e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9621e-02, -2.3496e-01,  1.3421e-01],\n",
            "          [ 1.5609e-02,  1.2234e-01,  1.7568e-01],\n",
            "          [ 1.8786e-01,  6.9490e-02,  3.6811e-02]],\n",
            "\n",
            "         [[ 1.0813e-01, -9.1668e-02, -5.8791e-02],\n",
            "          [-1.7928e-01, -1.3311e-01, -9.2602e-02],\n",
            "          [ 1.5981e-02,  1.3437e-01, -1.9305e-01]],\n",
            "\n",
            "         [[-1.0140e-01, -1.7555e-01, -1.0272e-01],\n",
            "          [-4.1486e-02, -2.2281e-01, -2.0316e-02],\n",
            "          [-5.1936e-02, -9.4453e-02, -1.5784e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.8202e-01, -1.6552e-02,  1.2602e-01],\n",
            "          [-3.1384e-02, -1.3072e-02, -2.8875e-01],\n",
            "          [ 1.3964e-01, -1.0256e-01, -1.0329e-01]],\n",
            "\n",
            "         [[-2.7192e-01,  1.4932e-01,  1.4744e-01],\n",
            "          [ 7.9146e-02,  2.7542e-01,  1.7495e-02],\n",
            "          [ 3.8085e-01,  3.1007e-01,  1.8758e-02]],\n",
            "\n",
            "         [[-3.0441e-01,  2.8578e-02,  1.2259e-01],\n",
            "          [-2.1840e-01, -7.9002e-02,  2.6889e-04],\n",
            "          [ 1.7485e-01, -1.8175e-01, -1.3939e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0708e-01,  1.7778e-01, -3.0821e-01],\n",
            "          [-2.0211e-02, -1.6567e-01,  3.7099e-01],\n",
            "          [ 1.7360e-01, -2.7475e-01,  2.8639e-02]],\n",
            "\n",
            "         [[-1.2407e-01,  1.0929e-01, -1.7669e-01],\n",
            "          [-1.0583e-01, -2.9456e-01,  3.7871e-01],\n",
            "          [ 3.0580e-01, -4.0862e-01,  1.3054e-01]],\n",
            "\n",
            "         [[ 3.0034e-01,  8.8234e-02, -3.3364e-01],\n",
            "          [-1.0673e-02, -2.6247e-01,  4.2974e-01],\n",
            "          [-3.5439e-02, -3.3190e-01,  2.4669e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.6045e-02,  2.5847e-01,  1.2668e-01],\n",
            "          [-1.1898e-01,  2.3110e-01,  1.8880e-01],\n",
            "          [-1.0075e-01, -2.2702e-01, -3.4213e-01]],\n",
            "\n",
            "         [[ 2.7486e-02,  2.4465e-01,  1.8574e-01],\n",
            "          [ 2.0781e-01,  1.1525e-01,  4.9233e-03],\n",
            "          [ 3.2775e-02,  1.8849e-01, -1.2392e-01]],\n",
            "\n",
            "         [[-2.4631e-01, -1.8551e-01, -1.6005e-01],\n",
            "          [-2.0715e-01,  2.0188e-02, -1.1038e-01],\n",
            "          [ 2.1770e-01,  2.2843e-01, -8.7877e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.4959e-02,  1.5491e-01, -1.9735e-01],\n",
            "          [-8.0138e-02,  8.1252e-02, -6.8676e-02],\n",
            "          [ 1.1562e-03, -1.5239e-01, -1.2707e-01]],\n",
            "\n",
            "         [[ 1.8446e-01, -3.7184e-02, -1.7159e-01],\n",
            "          [ 8.1401e-02, -1.6839e-01, -6.7580e-02],\n",
            "          [ 1.6613e-01, -6.6919e-02,  1.2605e-01]],\n",
            "\n",
            "         [[-3.6244e-01, -6.5720e-02, -1.0713e-01],\n",
            "          [-4.8062e-01,  1.4385e-01,  4.2815e-01],\n",
            "          [-2.6108e-01,  2.9784e-01,  5.4571e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7824e-02, -1.1585e-01,  3.1408e-01],\n",
            "          [-2.2708e-01,  1.1793e-01, -1.0233e-01],\n",
            "          [-2.1068e-01, -7.1905e-02,  2.3713e-01]],\n",
            "\n",
            "         [[ 1.4981e-01, -1.8781e-01,  1.1986e-01],\n",
            "          [ 1.6380e-01, -1.8086e-03, -2.4884e-01],\n",
            "          [-5.7163e-02,  2.1272e-01,  4.7885e-02]],\n",
            "\n",
            "         [[ 2.8568e-01, -1.4566e-01, -2.5873e-01],\n",
            "          [ 3.0009e-01,  5.0512e-02, -5.1791e-01],\n",
            "          [ 2.1463e-01,  2.9690e-01, -3.1796e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8543e-02, -9.7065e-02, -6.5640e-02],\n",
            "          [ 4.7713e-03, -1.2381e-01,  1.3768e-01],\n",
            "          [-1.0419e-01,  1.7768e-01,  1.4307e-01]],\n",
            "\n",
            "         [[ 1.8805e-01,  7.7124e-02, -1.2787e-02],\n",
            "          [ 1.1291e-01, -2.5205e-01, -2.2273e-01],\n",
            "          [-2.8816e-01,  8.2630e-02, -8.7277e-02]],\n",
            "\n",
            "         [[ 2.1896e-01,  2.2036e-01,  1.7348e-01],\n",
            "          [-2.0314e-02,  1.5416e-01,  6.1725e-02],\n",
            "          [-2.0707e-01, -1.0835e-01,  1.1674e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5928e-01,  1.1086e-01, -1.7144e-02],\n",
            "          [-1.0678e-01,  6.4557e-02,  1.4034e-01],\n",
            "          [-8.3051e-02, -1.8485e-01, -2.2697e-01]],\n",
            "\n",
            "         [[-8.8430e-02,  1.4320e-01, -2.0369e-02],\n",
            "          [-5.0887e-03,  1.7297e-01, -8.4629e-02],\n",
            "          [ 6.1929e-03, -1.7587e-01, -2.0172e-02]],\n",
            "\n",
            "         [[-8.5378e-02, -1.5739e-01, -1.0691e-01],\n",
            "          [ 1.9052e-01,  1.6939e-01,  6.7312e-03],\n",
            "          [-1.7727e-05,  9.6003e-02, -2.4226e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1602e-01,  1.7596e-01, -1.1747e-01],\n",
            "          [ 1.9191e-03, -1.0415e-01,  1.3824e-01],\n",
            "          [-1.1501e-01,  3.0761e-02,  1.7716e-01]],\n",
            "\n",
            "         [[ 6.9661e-02, -1.4801e-02,  5.4767e-02],\n",
            "          [-5.8721e-02, -1.4858e-01,  9.5057e-02],\n",
            "          [ 1.6297e-01, -1.5975e-02, -8.4821e-02]],\n",
            "\n",
            "         [[ 1.1565e-01, -1.1573e-01,  3.2887e-03],\n",
            "          [ 5.5008e-02, -1.5812e-01,  1.8138e-01],\n",
            "          [ 1.5544e-01,  1.3245e-01,  1.8450e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1722e-01, -2.9164e-01, -2.6391e-01],\n",
            "          [-1.2771e-01, -1.9582e-01,  3.7865e-02],\n",
            "          [ 3.4119e-01,  3.4266e-01,  1.9574e-01]],\n",
            "\n",
            "         [[-1.2079e-01, -2.4656e-01,  3.1329e-03],\n",
            "          [-1.8048e-01,  1.0398e-01, -1.6477e-01],\n",
            "          [ 5.5959e-02,  2.2123e-01, -1.3039e-01]],\n",
            "\n",
            "         [[ 1.9376e-01, -3.1826e-02,  2.0875e-01],\n",
            "          [ 7.3405e-02, -8.3303e-02,  2.7799e-02],\n",
            "          [-1.1398e-01,  2.3832e-01, -1.3592e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6534e-02,  2.2621e-01,  1.3836e-01],\n",
            "          [ 1.4710e-01, -1.7610e-01, -9.5342e-02],\n",
            "          [-8.2022e-02, -1.1425e-01, -6.3408e-02]],\n",
            "\n",
            "         [[-1.8744e-01,  1.2714e-01,  1.1103e-01],\n",
            "          [ 6.8995e-02, -1.8774e-01, -4.2885e-02],\n",
            "          [ 2.6734e-01, -7.2939e-02, -8.7842e-02]],\n",
            "\n",
            "         [[-2.2400e-01, -8.0535e-02,  2.9223e-01],\n",
            "          [-2.5657e-01, -9.3939e-02,  2.5748e-01],\n",
            "          [-1.2637e-02, -2.2084e-01,  4.8705e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.8788e-02, -2.1571e-01, -2.8328e-02],\n",
            "          [-2.5711e-01, -2.5757e-01,  1.5140e-01],\n",
            "          [ 2.5782e-01,  3.0987e-01,  4.9096e-03]],\n",
            "\n",
            "         [[ 8.3303e-02, -2.3979e-01, -7.0754e-02],\n",
            "          [-9.6159e-02, -1.9839e-01,  2.7148e-01],\n",
            "          [-2.7090e-02,  2.7468e-01, -3.1446e-02]],\n",
            "\n",
            "         [[-1.3850e-01,  4.2891e-02,  3.4675e-02],\n",
            "          [-1.1751e-01, -1.7348e-01,  1.3410e-01],\n",
            "          [ 4.8781e-02, -5.3255e-02, -1.2233e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1532e-01,  4.6545e-02,  3.3985e-01],\n",
            "          [ 3.2517e-02, -2.5074e-01,  2.7891e-01],\n",
            "          [-1.6625e-01, -5.5018e-04,  2.3734e-01]],\n",
            "\n",
            "         [[-4.9509e-02, -1.0914e-01,  3.7122e-01],\n",
            "          [-1.2231e-02, -4.9889e-01,  8.4841e-02],\n",
            "          [ 1.1402e-01, -2.4897e-01,  1.5672e-01]],\n",
            "\n",
            "         [[-1.1567e-01, -2.1633e-01,  1.0093e-01],\n",
            "          [ 2.2899e-01, -3.2828e-01, -8.3511e-02],\n",
            "          [ 2.2327e-01, -1.0915e-02,  2.0764e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3835e-01,  3.2442e-01,  3.3676e-01],\n",
            "          [-2.4133e-01, -2.9780e-01, -1.5716e-01],\n",
            "          [-9.6007e-02, -7.9505e-02, -1.9379e-01]],\n",
            "\n",
            "         [[ 1.3157e-01,  6.7614e-02,  2.1408e-01],\n",
            "          [-2.6146e-01, -2.9828e-01, -2.0860e-01],\n",
            "          [ 1.0673e-01,  1.0598e-01, -1.6945e-01]],\n",
            "\n",
            "         [[ 1.7002e-01, -3.2601e-02, -1.2885e-02],\n",
            "          [-3.3831e-02, -2.3624e-01, -8.2555e-02],\n",
            "          [ 8.6386e-02,  2.9729e-01, -1.4267e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4063e-01,  2.0501e-01, -6.8982e-02],\n",
            "          [-1.4300e-02, -1.5175e-01, -2.4982e-01],\n",
            "          [ 2.8149e-01, -1.4588e-01, -1.2855e-01]],\n",
            "\n",
            "         [[-1.1759e-01, -4.4010e-02, -1.5330e-01],\n",
            "          [ 6.0012e-02, -1.9879e-01, -1.4504e-02],\n",
            "          [ 2.6214e-01,  1.4830e-01, -1.9918e-01]],\n",
            "\n",
            "         [[-1.7726e-01,  2.2535e-01, -1.8009e-01],\n",
            "          [ 1.3966e-01, -6.4832e-02, -1.3483e-01],\n",
            "          [ 2.9792e-01, -1.5429e-03,  5.6673e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.4368e-02, -6.4365e-02,  1.1521e-01],\n",
            "          [-5.3523e-02,  1.0317e-01,  1.1749e-01],\n",
            "          [-2.1297e-01, -1.6768e-01,  6.4850e-02]],\n",
            "\n",
            "         [[-9.2998e-02, -3.5160e-02,  5.0560e-02],\n",
            "          [ 1.4762e-01, -1.3285e-01, -1.2349e-01],\n",
            "          [-2.2421e-01, -1.8886e-01,  1.7837e-01]],\n",
            "\n",
            "         [[-7.8760e-02,  4.8531e-02, -1.3412e-01],\n",
            "          [ 1.6663e-02, -3.7177e-02,  2.9930e-01],\n",
            "          [-2.3824e-01, -1.0860e-02,  1.7124e-01]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToKa651tMtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b6afb40-28c9-4151-e63d-c3a1f1ce805e"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0309,  0.1087,  0.1955],\n",
            "          [ 0.2209,  0.0076,  0.0348],\n",
            "          [-0.0854,  0.0774, -0.0973]],\n",
            "\n",
            "         [[ 0.0616, -0.1282,  0.2080],\n",
            "          [ 0.0332, -0.1826, -0.1365],\n",
            "          [-0.1557, -0.0844, -0.1973]],\n",
            "\n",
            "         [[-0.0722,  0.0364,  0.1260],\n",
            "          [ 0.0611, -0.0341,  0.1729],\n",
            "          [ 0.0427,  0.0797,  0.0223]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1835,  0.0366, -0.1656],\n",
            "          [-0.0834,  0.1659,  0.0364],\n",
            "          [ 0.1062,  0.2152,  0.1314]],\n",
            "\n",
            "         [[ 0.0086,  0.2094,  0.2249],\n",
            "          [-0.1404, -0.1745,  0.0035],\n",
            "          [-0.2156,  0.0847,  0.0851]],\n",
            "\n",
            "         [[-0.1070,  0.1605, -0.1541],\n",
            "          [-0.0419, -0.0417,  0.0718],\n",
            "          [-0.0668, -0.2273, -0.2890]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1013,  0.0165, -0.0829],\n",
            "          [-0.1709,  0.1888, -0.0619],\n",
            "          [-0.0676,  0.2545,  0.2560]],\n",
            "\n",
            "         [[-0.0495, -0.0233, -0.0692],\n",
            "          [ 0.0196, -0.1944, -0.2639],\n",
            "          [-0.2429,  0.0565,  0.1495]],\n",
            "\n",
            "         [[ 0.2412, -0.1480, -0.1188],\n",
            "          [ 0.0755,  0.0533, -0.1636],\n",
            "          [ 0.1195,  0.0296, -0.0620]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2049,  0.1405, -0.0744],\n",
            "          [ 0.0715,  0.0253,  0.0548],\n",
            "          [-0.0363, -0.0603, -0.0169]],\n",
            "\n",
            "         [[ 0.1719, -0.0024,  0.1642],\n",
            "          [ 0.0824, -0.1403,  0.0444],\n",
            "          [ 0.1660, -0.0140, -0.0213]],\n",
            "\n",
            "         [[-0.1377,  0.0023,  0.0830],\n",
            "          [-0.0201,  0.0463, -0.1071],\n",
            "          [-0.0089, -0.0475,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1722, -0.1703,  0.0900],\n",
            "          [-0.0026, -0.1981, -0.0808],\n",
            "          [-0.0556, -0.0525, -0.0903]],\n",
            "\n",
            "         [[ 0.0469,  0.1535,  0.1791],\n",
            "          [ 0.0031, -0.1002,  0.1474],\n",
            "          [-0.2295,  0.1191,  0.0080]],\n",
            "\n",
            "         [[ 0.1878,  0.0110,  0.1277],\n",
            "          [ 0.0146,  0.1758,  0.1353],\n",
            "          [-0.1670,  0.1439, -0.0813]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1690,  0.1051, -0.0433],\n",
            "          [-0.2494,  0.0010,  0.0629],\n",
            "          [-0.0552,  0.0004,  0.0097]],\n",
            "\n",
            "         [[ 0.1635,  0.3134,  0.0763],\n",
            "          [-0.1233,  0.0560, -0.2310],\n",
            "          [-0.1199, -0.2663, -0.0928]],\n",
            "\n",
            "         [[ 0.0838,  0.1768,  0.0256],\n",
            "          [-0.2400,  0.1630, -0.2009],\n",
            "          [ 0.0774, -0.0150,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1059,  0.0585, -0.1707],\n",
            "          [ 0.1078, -0.0531, -0.0276],\n",
            "          [ 0.1118, -0.0519, -0.1506]],\n",
            "\n",
            "         [[-0.1614,  0.1542, -0.1130],\n",
            "          [ 0.1823,  0.1833,  0.1834],\n",
            "          [ 0.0840, -0.0238,  0.0096]],\n",
            "\n",
            "         [[ 0.1863,  0.0509, -0.1148],\n",
            "          [-0.0720,  0.1801, -0.0417],\n",
            "          [ 0.0088,  0.0210, -0.0527]]],\n",
            "\n",
            "\n",
            "        [[[-0.0021, -0.1920, -0.1925],\n",
            "          [-0.0794, -0.1094, -0.1952],\n",
            "          [ 0.0640, -0.1527, -0.1590]],\n",
            "\n",
            "         [[ 0.0023, -0.0093,  0.0917],\n",
            "          [ 0.1893,  0.1771, -0.0419],\n",
            "          [ 0.1959,  0.0765, -0.1216]],\n",
            "\n",
            "         [[ 0.1127, -0.0509, -0.0890],\n",
            "          [ 0.0425, -0.0004,  0.0970],\n",
            "          [ 0.1725, -0.0294,  0.2238]]],\n",
            "\n",
            "\n",
            "        [[[-0.1533,  0.2030, -0.1170],\n",
            "          [ 0.0515, -0.0504, -0.1635],\n",
            "          [-0.1322, -0.1429,  0.1475]],\n",
            "\n",
            "         [[ 0.0555, -0.0411,  0.2137],\n",
            "          [-0.0274, -0.0902,  0.0513],\n",
            "          [ 0.0085, -0.1591,  0.1483]],\n",
            "\n",
            "         [[ 0.1163, -0.1371,  0.0318],\n",
            "          [ 0.0841, -0.2464, -0.2148],\n",
            "          [ 0.0637,  0.1322,  0.0676]]],\n",
            "\n",
            "\n",
            "        [[[-0.0227,  0.0487,  0.2023],\n",
            "          [-0.1330,  0.1492, -0.0169],\n",
            "          [ 0.1584,  0.1524, -0.0456]],\n",
            "\n",
            "         [[-0.0525, -0.1646, -0.0814],\n",
            "          [-0.2456, -0.1350,  0.0154],\n",
            "          [ 0.2309, -0.1780, -0.0720]],\n",
            "\n",
            "         [[-0.0142,  0.0480,  0.2516],\n",
            "          [-0.1593,  0.1562,  0.1928],\n",
            "          [-0.1119, -0.2044, -0.1976]]],\n",
            "\n",
            "\n",
            "        [[[-0.0355,  0.1166, -0.0631],\n",
            "          [-0.0836, -0.1515,  0.1577],\n",
            "          [ 0.0235,  0.1110, -0.0250]],\n",
            "\n",
            "         [[-0.2114,  0.1654,  0.2484],\n",
            "          [ 0.0525,  0.2583,  0.0362],\n",
            "          [-0.0713,  0.1357, -0.0152]],\n",
            "\n",
            "         [[-0.0821, -0.0350, -0.1481],\n",
            "          [-0.2171,  0.0489,  0.2106],\n",
            "          [ 0.1037, -0.1230,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.1625,  0.1384],\n",
            "          [-0.1124, -0.1412,  0.2642],\n",
            "          [ 0.0284, -0.0494, -0.0447]],\n",
            "\n",
            "         [[ 0.0205, -0.2302,  0.1754],\n",
            "          [ 0.0924, -0.2460,  0.2219],\n",
            "          [ 0.0863, -0.1062,  0.1210]],\n",
            "\n",
            "         [[ 0.2537, -0.2292, -0.1540],\n",
            "          [ 0.2104, -0.2362,  0.1700],\n",
            "          [ 0.2093, -0.2085, -0.0309]]],\n",
            "\n",
            "\n",
            "        [[[-0.1426,  0.1824, -0.2160],\n",
            "          [ 0.0009, -0.0087,  0.0207],\n",
            "          [ 0.0911, -0.2336, -0.1702]],\n",
            "\n",
            "         [[ 0.2153,  0.1894,  0.0243],\n",
            "          [-0.2433,  0.2294,  0.2479],\n",
            "          [-0.0595, -0.1203,  0.1227]],\n",
            "\n",
            "         [[-0.1597,  0.1976, -0.1576],\n",
            "          [-0.1258, -0.0205, -0.1531],\n",
            "          [ 0.1347,  0.0364, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[-0.0633, -0.0466, -0.0325],\n",
            "          [-0.0601,  0.0621, -0.0215],\n",
            "          [-0.0044, -0.0534,  0.0422]],\n",
            "\n",
            "         [[-0.1383, -0.1374, -0.1793],\n",
            "          [-0.0877, -0.1327,  0.0918],\n",
            "          [-0.0787,  0.0740, -0.0112]],\n",
            "\n",
            "         [[ 0.0814,  0.0275, -0.1438],\n",
            "          [-0.0439,  0.1876,  0.1383],\n",
            "          [-0.0834,  0.1108,  0.0304]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0447,  0.0499, -0.1449],\n",
            "          [-0.1171, -0.0733,  0.0182],\n",
            "          [-0.0587, -0.1367, -0.1931]],\n",
            "\n",
            "         [[ 0.0961,  0.0888, -0.0784],\n",
            "          [ 0.0504, -0.1259,  0.0890],\n",
            "          [-0.1473,  0.0371,  0.1020]],\n",
            "\n",
            "         [[ 0.0476, -0.1709, -0.0371],\n",
            "          [ 0.2308,  0.1298,  0.0326],\n",
            "          [-0.0171, -0.0634, -0.1609]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2378, -0.1200, -0.2246],\n",
            "          [ 0.2465,  0.0634, -0.1682],\n",
            "          [-0.0573, -0.1788,  0.0856]],\n",
            "\n",
            "         [[ 0.2020,  0.1478, -0.0181],\n",
            "          [ 0.1683,  0.0819, -0.0775],\n",
            "          [ 0.1869, -0.2327, -0.2108]],\n",
            "\n",
            "         [[-0.0383, -0.1762, -0.0893],\n",
            "          [-0.1869,  0.0115,  0.0917],\n",
            "          [ 0.0562, -0.0899,  0.1009]]],\n",
            "\n",
            "\n",
            "        [[[-0.0911, -0.2512,  0.0277],\n",
            "          [-0.0324,  0.1520,  0.2214],\n",
            "          [ 0.1329, -0.0946,  0.1157]],\n",
            "\n",
            "         [[ 0.1063, -0.1710,  0.0471],\n",
            "          [-0.1126,  0.1777,  0.2435],\n",
            "          [-0.1798,  0.0235,  0.1735]],\n",
            "\n",
            "         [[ 0.0092, -0.1809,  0.0974],\n",
            "          [ 0.1691, -0.1317,  0.1264],\n",
            "          [-0.1224, -0.1659, -0.2023]]],\n",
            "\n",
            "\n",
            "        [[[-0.2336,  0.2346,  0.0983],\n",
            "          [-0.1950, -0.1840,  0.1690],\n",
            "          [-0.2168,  0.0477,  0.0916]],\n",
            "\n",
            "         [[-0.0561,  0.1103,  0.0033],\n",
            "          [-0.0990, -0.2062, -0.0978],\n",
            "          [ 0.1411, -0.0397,  0.0443]],\n",
            "\n",
            "         [[ 0.1579,  0.1184, -0.1102],\n",
            "          [ 0.1775,  0.0325, -0.1486],\n",
            "          [-0.0702,  0.2019,  0.1233]]],\n",
            "\n",
            "\n",
            "        [[[-0.0797,  0.1350,  0.1679],\n",
            "          [-0.0473,  0.2595,  0.1358],\n",
            "          [-0.2849, -0.0974, -0.0081]],\n",
            "\n",
            "         [[-0.1065, -0.1424, -0.1542],\n",
            "          [-0.2096,  0.1828,  0.1126],\n",
            "          [ 0.0174,  0.0576, -0.0152]],\n",
            "\n",
            "         [[-0.2226,  0.0298, -0.1312],\n",
            "          [-0.1327,  0.2087,  0.1935],\n",
            "          [-0.0249,  0.0243, -0.0377]]],\n",
            "\n",
            "\n",
            "        [[[-0.0588,  0.1742,  0.2010],\n",
            "          [ 0.1427, -0.0923,  0.0899],\n",
            "          [-0.1261, -0.1139, -0.0786]],\n",
            "\n",
            "         [[-0.1481,  0.0529,  0.0481],\n",
            "          [ 0.0126, -0.0323,  0.1211],\n",
            "          [-0.0912, -0.0420, -0.1293]],\n",
            "\n",
            "         [[-0.2270, -0.2813, -0.1512],\n",
            "          [ 0.0183, -0.0734, -0.0467],\n",
            "          [ 0.1668,  0.1287,  0.1416]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1385,  0.0580,  0.3274],\n",
            "          [-0.0714, -0.0263,  0.2946],\n",
            "          [-0.2355, -0.3553,  0.0437]],\n",
            "\n",
            "         [[ 0.0762, -0.1933, -0.1612],\n",
            "          [-0.1279,  0.0055, -0.0561],\n",
            "          [ 0.2241, -0.0410,  0.1810]],\n",
            "\n",
            "         [[ 0.1535, -0.1441, -0.1855],\n",
            "          [ 0.2696, -0.1765,  0.0269],\n",
            "          [ 0.2909, -0.1872, -0.1417]]],\n",
            "\n",
            "\n",
            "        [[[-0.1353, -0.0778,  0.2160],\n",
            "          [-0.2453,  0.0684,  0.2713],\n",
            "          [ 0.0924,  0.0206,  0.2311]],\n",
            "\n",
            "         [[-0.1599,  0.0515, -0.0479],\n",
            "          [-0.1464, -0.0211,  0.0214],\n",
            "          [-0.1591, -0.0081, -0.1259]],\n",
            "\n",
            "         [[-0.0057,  0.1981, -0.0700],\n",
            "          [-0.1581,  0.2080,  0.0793],\n",
            "          [-0.2191,  0.0567,  0.0142]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2331, -0.0791, -0.0360],\n",
            "          [ 0.0551, -0.1573, -0.1605],\n",
            "          [ 0.1258, -0.0884, -0.2061]],\n",
            "\n",
            "         [[-0.2222,  0.1591,  0.1350],\n",
            "          [-0.1694, -0.0935,  0.0388],\n",
            "          [-0.0330,  0.1814,  0.0005]],\n",
            "\n",
            "         [[-0.1377, -0.0267,  0.1763],\n",
            "          [-0.2532,  0.2026,  0.1464],\n",
            "          [-0.0366,  0.2414, -0.1755]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0655, -0.1766, -0.2965],\n",
            "          [ 0.0635, -0.1370,  0.2211],\n",
            "          [ 0.0251, -0.0315,  0.2027]],\n",
            "\n",
            "         [[ 0.2559, -0.1553, -0.1362],\n",
            "          [ 0.2658, -0.1706,  0.1501],\n",
            "          [-0.1731, -0.0166, -0.0638]],\n",
            "\n",
            "         [[-0.1674,  0.0792,  0.1900],\n",
            "          [-0.0342, -0.2272,  0.2679],\n",
            "          [-0.0845, -0.0639,  0.0261]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0958,  0.0557, -0.0319],\n",
            "          [ 0.1302, -0.0530, -0.2087],\n",
            "          [ 0.0320,  0.1967, -0.1969]],\n",
            "\n",
            "         [[ 0.1327, -0.1589,  0.1865],\n",
            "          [-0.0338, -0.2036, -0.2538],\n",
            "          [ 0.1661,  0.1607,  0.1042]],\n",
            "\n",
            "         [[-0.2442, -0.0128, -0.1746],\n",
            "          [-0.0988,  0.0191, -0.2384],\n",
            "          [-0.1124,  0.2998,  0.2225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1305, -0.0375, -0.0713],\n",
            "          [-0.0881,  0.0315, -0.0487],\n",
            "          [-0.1159, -0.0198, -0.0042]],\n",
            "\n",
            "         [[-0.1895,  0.1779, -0.0391],\n",
            "          [ 0.1096, -0.0229,  0.0431],\n",
            "          [ 0.1912, -0.0880,  0.1516]],\n",
            "\n",
            "         [[ 0.1237,  0.1648,  0.0864],\n",
            "          [ 0.1106, -0.1358, -0.0593],\n",
            "          [ 0.0834,  0.1760, -0.1148]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0261,  0.0946, -0.2135],\n",
            "          [-0.0508, -0.2134, -0.0804],\n",
            "          [ 0.2161,  0.1251,  0.1160]],\n",
            "\n",
            "         [[ 0.2439,  0.1499,  0.0541],\n",
            "          [-0.1242, -0.3017, -0.1642],\n",
            "          [ 0.1484,  0.0228, -0.0532]],\n",
            "\n",
            "         [[ 0.2827,  0.0027,  0.2216],\n",
            "          [-0.2123, -0.1097, -0.0140],\n",
            "          [-0.1472, -0.1401,  0.1451]]],\n",
            "\n",
            "\n",
            "        [[[-0.0668, -0.0305, -0.1276],\n",
            "          [-0.0389,  0.0897,  0.0144],\n",
            "          [ 0.0437, -0.0369,  0.2345]],\n",
            "\n",
            "         [[ 0.0160, -0.0964, -0.1077],\n",
            "          [ 0.1918,  0.2170,  0.1363],\n",
            "          [-0.1928, -0.0407,  0.0342]],\n",
            "\n",
            "         [[-0.0021, -0.0420,  0.0836],\n",
            "          [ 0.0767,  0.0022,  0.0412],\n",
            "          [-0.1141, -0.0197,  0.0672]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1341, -0.0483, -0.1076],\n",
            "          [-0.1852, -0.0061,  0.0918],\n",
            "          [-0.1238,  0.0374, -0.0902]],\n",
            "\n",
            "         [[ 0.1261, -0.0141, -0.0833],\n",
            "          [-0.1273, -0.2019, -0.1387],\n",
            "          [-0.0098,  0.2122, -0.0161]],\n",
            "\n",
            "         [[ 0.1478,  0.0007, -0.0934],\n",
            "          [-0.1233,  0.0490,  0.0353],\n",
            "          [ 0.2064, -0.1164,  0.1303]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0583, -0.1114,  0.2957],\n",
            "          [ 0.1703, -0.0507,  0.0694],\n",
            "          [-0.1846,  0.1098, -0.1668]],\n",
            "\n",
            "         [[-0.2051, -0.2725, -0.0990],\n",
            "          [-0.1666,  0.0620, -0.0992],\n",
            "          [ 0.1796,  0.0437, -0.2720]],\n",
            "\n",
            "         [[ 0.1627, -0.1647, -0.0541],\n",
            "          [ 0.0633,  0.2490, -0.1993],\n",
            "          [ 0.1262,  0.2773,  0.0247]]],\n",
            "\n",
            "\n",
            "        [[[-0.2300, -0.1971, -0.0127],\n",
            "          [ 0.0639,  0.0679, -0.0152],\n",
            "          [ 0.2227, -0.0215, -0.0974]],\n",
            "\n",
            "         [[-0.2116, -0.0484,  0.1070],\n",
            "          [ 0.1198, -0.1068, -0.0113],\n",
            "          [ 0.1952,  0.0198,  0.0825]],\n",
            "\n",
            "         [[-0.3352,  0.1302,  0.0801],\n",
            "          [ 0.1699,  0.1231,  0.0742],\n",
            "          [ 0.0210, -0.1424,  0.0352]]],\n",
            "\n",
            "\n",
            "        [[[-0.0857,  0.1421,  0.1182],\n",
            "          [ 0.1262,  0.2026,  0.1068],\n",
            "          [ 0.0704, -0.0585, -0.0306]],\n",
            "\n",
            "         [[ 0.1038, -0.1139,  0.0915],\n",
            "          [ 0.1529,  0.1774, -0.1306],\n",
            "          [-0.2282, -0.2159,  0.0512]],\n",
            "\n",
            "         [[-0.1076, -0.1626,  0.0314],\n",
            "          [-0.1577,  0.1472,  0.1330],\n",
            "          [ 0.1294, -0.0155, -0.0551]]]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"15_focus_pretrained_classify_pretrained_train_focus\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0zuujPPzLHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(focus_net.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn/\"+name+\"_focus_net.pt\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn/\"+name+\"_classify.pt\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "2fbda671-416c-4854-adf1-d3e2854dcc9c"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>29975</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0       0         30000  ...                     16                       4\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "06066f6e-5445-4471-e77e-c769d6e31213"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "1b3453db-4e6c-492d-ed7b-9f0a1c800110"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>9990</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0       0         10000  ...                      8                       1\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "0c4b1918-ed90-4dcd-c60d-9bd45e5795be"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLtaUpOmLF5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "69ea43e3-5fe4-469d-ab45-0feb10dd73e9"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29972\n",
            "total train set images 30000\n",
            "focus_true_pred_true 29968 =============> FTPT : 99 %\n",
            "focus_false_pred_true 4 =============> FFPT : 0 %\n",
            "focus_true_pred_false 23 =============> FTPF : 0 %\n",
            "focus_false_pred_false 5 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  30000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqF-4UYSLHBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "5c9d5c03-d488-4ced-f85d-8ae2d818441b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n",
            "total correct 9993\n",
            "total train set images 10000\n",
            "focus_true_pred_true 9989 =============> FTPT : 99 %\n",
            "focus_false_pred_true 4 =============> FFPT : 0 %\n",
            "focus_true_pred_false 5 =============> FTPF : 0 %\n",
            "focus_false_pred_false 2 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  10000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "665bf578-d168-42f3-b410-3ebfd5770289"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29970\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "05eabb71-b4d8-4dd3-a845-a7b2724ec489"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n",
            "total correct 9996\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}