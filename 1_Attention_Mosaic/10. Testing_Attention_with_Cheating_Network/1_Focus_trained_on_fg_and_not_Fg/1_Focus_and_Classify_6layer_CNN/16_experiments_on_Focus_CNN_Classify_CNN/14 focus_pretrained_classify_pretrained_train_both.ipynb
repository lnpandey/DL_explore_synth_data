{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "14 focus_pretrained_classify_pretrained_train_both.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84db1799-82af-4b6c-adb8-b785ec66678c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acRFqJNrZErV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a8778b3b-ef5c-41a7-9a1b-7edd5313d3d8"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V_JUhwCeZErk",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SadRzWBBZEsP",
        "colab": {}
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 2)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBQffkIzTOsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04648ffd-e873-4630-f9e3-58a738405e38"
      },
      "source": [
        "focus_net.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Focus_net_weights/focus_net_6layer_cnn.pt\"))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZtcA4VOTVxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbae06f5-f955-45cd-b2a0-17a34e30a4fb"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=2, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMpRf9RETYRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "7e139e41-0876-4c6c-c58e-62303ce02c6a"
      },
      "source": [
        "print(focus_net.fc4)\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)\n",
        "temp = focus_net.fc4.weight.data\n",
        "temp2 = focus_net.fc4.bias.data\n",
        "focus_net.fc4 = nn.Linear(10,1).double()\n",
        "focus_net.fc4.weight.data = torch.unsqueeze(temp[1,:], 0)\n",
        "focus_net.fc4.bias.data = torch.unsqueeze(temp2[1], 0)\n",
        "focus_net = focus_net.to(\"cuda\")\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=10, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.3974,  0.2455,  0.2787, -0.4295, -0.5508,  0.8661, -0.2221, -0.6396,\n",
            "          0.5014,  0.1486],\n",
            "        [-0.1227,  0.1252, -0.0242,  0.3076,  0.7789, -0.7985, -0.2840,  0.6068,\n",
            "         -0.5138,  0.2816]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2738,  0.0337], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1227,  0.1252, -0.0242,  0.3076,  0.7789, -0.7985, -0.2840,  0.6068,\n",
            "         -0.5138,  0.2816]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0337], device='cuda:0', dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WFfxQ_3TYF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48d9d910-652f-4d24-a8b6-4c84a5403de4"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=1, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6tBJqBaTnl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   params.requires_grad = False"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLhPEuVoUBC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9a793ca-0a49-4ea8-99bf-cbdedf8716c2"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwcTiFhGThJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fce0a02e-7586-49db-cf2f-855b5b7fe514"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.0155e-01,  1.8843e-01, -3.7371e-01],\n",
            "          [ 1.3882e-01,  3.1465e-01, -2.3114e-01],\n",
            "          [-9.8712e-02,  1.7628e-01, -4.7682e-02]],\n",
            "\n",
            "         [[-1.7731e-01,  2.7669e-01, -1.6959e-02],\n",
            "          [-1.3041e-01,  1.1654e-01, -2.3628e-02],\n",
            "          [-1.8088e-01,  1.7182e-02,  2.2703e-01]],\n",
            "\n",
            "         [[ 2.6718e-01,  4.5371e-01, -1.1744e-02],\n",
            "          [ 1.3648e-01,  2.1359e-02, -3.3651e-01],\n",
            "          [-3.4207e-01, -2.8405e-01,  2.1965e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4553e-01, -3.1102e-01, -1.5143e-01],\n",
            "          [-7.8231e-02, -2.3423e-01, -1.1562e-01],\n",
            "          [ 4.3292e-03, -2.9985e-01, -1.6135e-01]],\n",
            "\n",
            "         [[ 2.3403e-01, -7.7107e-02,  2.3617e-01],\n",
            "          [ 7.9921e-03, -1.3719e-03, -1.2427e-01],\n",
            "          [-2.4708e-03, -1.7089e-01,  1.4559e-01]],\n",
            "\n",
            "         [[ 6.0008e-02,  2.2231e-01,  2.0222e-01],\n",
            "          [ 2.2929e-01, -5.4566e-03,  7.7658e-02],\n",
            "          [ 2.1009e-01, -2.0395e-02,  3.0434e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8955e-02, -8.9080e-02, -7.6312e-02],\n",
            "          [ 1.6654e-01,  9.1395e-02, -1.7210e-01],\n",
            "          [ 7.2608e-02,  3.6598e-02, -2.0946e-01]],\n",
            "\n",
            "         [[ 4.9694e-02,  3.4286e-02,  9.6677e-02],\n",
            "          [-9.4347e-02,  1.9066e-01, -1.7569e-01],\n",
            "          [ 2.2628e-01,  1.8944e-01,  1.0318e-01]],\n",
            "\n",
            "         [[-9.5871e-03,  2.3965e-02, -2.2961e-01],\n",
            "          [ 5.0691e-03, -1.2477e-03,  4.3030e-02],\n",
            "          [ 1.1552e-01,  5.2009e-02,  4.5297e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1273e-02,  1.1986e-01,  1.9651e-01],\n",
            "          [-1.0910e-01,  2.1594e-01,  2.3334e-01],\n",
            "          [-7.5300e-02, -1.2681e-01, -5.3049e-02]],\n",
            "\n",
            "         [[-4.8859e-02, -8.2950e-02, -1.8400e-01],\n",
            "          [-2.3791e-01, -8.6627e-02, -1.3185e-01],\n",
            "          [-1.8958e-02, -8.0871e-02, -1.0580e-01]],\n",
            "\n",
            "         [[-7.4944e-02, -1.2411e-01, -5.2474e-02],\n",
            "          [-2.0770e-02,  1.5161e-01, -1.6706e-01],\n",
            "          [-4.3331e-02,  1.3538e-01, -1.8715e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.3778e-03, -7.8674e-02,  1.9848e-01],\n",
            "          [-2.3493e-01,  1.7573e-01,  2.7151e-01],\n",
            "          [-2.2664e-02, -1.1002e-02, -6.5587e-02]],\n",
            "\n",
            "         [[ 1.9978e-01,  1.4815e-02,  1.0615e-02],\n",
            "          [ 2.0002e-01, -1.1983e-01,  1.5939e-01],\n",
            "          [-2.4128e-01, -1.4317e-01,  8.0474e-02]],\n",
            "\n",
            "         [[-1.4341e-01, -1.1064e-01, -2.6179e-01],\n",
            "          [ 2.1648e-01, -9.9564e-02,  1.6842e-02],\n",
            "          [ 1.1194e-01,  1.4890e-02,  1.9808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5718e-01,  6.6356e-03, -8.6083e-02],\n",
            "          [ 8.0345e-02, -1.1381e-01, -4.6426e-03],\n",
            "          [-1.2109e-01,  1.1055e-01,  2.1551e-01]],\n",
            "\n",
            "         [[ 1.5790e-01, -7.3243e-04, -1.1624e-01],\n",
            "          [ 2.9433e-01,  1.5650e-01, -2.7937e-01],\n",
            "          [ 1.0816e-01, -4.2703e-02,  1.1360e-01]],\n",
            "\n",
            "         [[-2.3966e-02, -1.7138e-01, -5.5875e-02],\n",
            "          [-1.1881e-01, -1.9345e-01, -3.4012e-01],\n",
            "          [ 7.5994e-02, -1.8580e-01,  5.1822e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5608e-01,  1.4220e-01, -1.9261e-01],\n",
            "          [ 2.8186e-01, -1.1467e-01, -3.0065e-02],\n",
            "          [-1.9499e-01, -8.0530e-04,  1.7978e-01]],\n",
            "\n",
            "         [[-2.9561e-01, -1.4465e-01, -3.8936e-02],\n",
            "          [ 2.7009e-01, -1.0709e-01,  1.9911e-01],\n",
            "          [-1.6047e-01,  1.9247e-01,  2.6052e-01]],\n",
            "\n",
            "         [[-1.3410e-01, -1.0264e-01, -2.3493e-01],\n",
            "          [ 3.7941e-01, -4.1826e-02, -2.3835e-01],\n",
            "          [ 1.5829e-01,  1.4479e-01, -7.7649e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4260e-02,  7.2909e-02, -4.9308e-01],\n",
            "          [ 1.9709e-01,  2.9608e-01,  4.4813e-02],\n",
            "          [ 1.8176e-01,  3.3937e-01,  1.7607e-01]],\n",
            "\n",
            "         [[-5.0911e-02,  2.4422e-01, -2.6483e-01],\n",
            "          [-2.5324e-01, -2.8686e-01, -1.1130e-01],\n",
            "          [-7.3526e-02, -1.8883e-01, -1.8568e-01]],\n",
            "\n",
            "         [[-3.3020e-02,  3.4905e-01,  9.6184e-02],\n",
            "          [ 9.3889e-02,  5.0457e-02, -4.1922e-02],\n",
            "          [-2.5109e-02, -1.0685e-01, -1.3722e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4828e-02,  9.2095e-04, -7.6290e-02],\n",
            "          [ 3.3454e-02,  3.7860e-01, -2.8654e-01],\n",
            "          [ 1.4552e-01,  7.2081e-02, -1.9682e-01]],\n",
            "\n",
            "         [[-3.7882e-02,  2.0972e-01, -2.3378e-01],\n",
            "          [-7.0486e-02,  4.0031e-01, -3.3082e-01],\n",
            "          [-2.2034e-01,  2.4179e-01, -7.7592e-02]],\n",
            "\n",
            "         [[-2.3171e-01,  2.7509e-01, -2.9406e-02],\n",
            "          [-2.5366e-01,  5.2276e-01, -3.5181e-01],\n",
            "          [ 4.7083e-02,  1.1258e-01, -2.4963e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2920e-02,  1.1366e-01, -1.0895e-01],\n",
            "          [-5.3343e-02,  1.6217e-02, -2.0651e-02],\n",
            "          [ 1.1660e-01,  9.8321e-02, -1.2359e-01]],\n",
            "\n",
            "         [[-3.4368e-02, -7.0742e-02, -2.5050e-01],\n",
            "          [-2.7087e-02,  1.4293e-01, -2.2920e-01],\n",
            "          [ 1.4525e-01,  1.4925e-02, -2.0972e-01]],\n",
            "\n",
            "         [[-2.4625e-01, -2.5307e-03, -2.1292e-02],\n",
            "          [ 2.9386e-02,  8.7204e-02,  1.4329e-01],\n",
            "          [ 2.4719e-01,  2.8453e-01,  9.2273e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.5100e-01, -1.5544e-01,  3.7412e-01],\n",
            "          [ 3.4293e-01, -6.4277e-02, -1.9676e-01],\n",
            "          [ 1.5227e-01, -4.3687e-02, -1.8680e-01]],\n",
            "\n",
            "         [[-3.5154e-01, -4.3465e-02,  7.8562e-02],\n",
            "          [ 3.2783e-01, -9.1473e-02, -7.4105e-02],\n",
            "          [ 1.5686e-01,  6.4711e-03,  4.9247e-02]],\n",
            "\n",
            "         [[ 1.0901e-01,  1.3724e-01,  1.4471e-01],\n",
            "          [ 3.8507e-01, -1.8206e-01, -9.0550e-02],\n",
            "          [ 1.8527e-02, -2.1300e-01, -2.1008e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.0009e-01,  5.2350e-02, -1.7434e-02],\n",
            "          [-1.3890e-01, -2.8554e-01,  1.3410e-01],\n",
            "          [-3.7519e-02, -5.1394e-01,  6.2113e-02]],\n",
            "\n",
            "         [[ 4.7610e-02,  1.4115e-01,  1.9123e-02],\n",
            "          [ 3.4660e-01,  1.0914e-01,  2.8330e-01],\n",
            "          [ 3.0530e-01, -1.6982e-01,  2.7858e-01]],\n",
            "\n",
            "         [[ 3.8899e-02, -4.2711e-03, -1.3205e-01],\n",
            "          [ 1.0196e-01, -2.7844e-01, -8.7242e-03],\n",
            "          [ 1.2730e-01, -2.8913e-01, -8.2701e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6047e-01,  3.1003e-01, -1.1233e-01],\n",
            "          [ 3.3223e-01,  2.9437e-01, -9.5160e-02],\n",
            "          [ 2.0716e-01, -2.9966e-01, -3.4367e-01]],\n",
            "\n",
            "         [[-2.8085e-01,  1.4637e-01, -3.4782e-02],\n",
            "          [ 1.6125e-03,  1.8891e-01,  2.3948e-01],\n",
            "          [-1.1145e-01, -1.3817e-01, -1.6709e-01]],\n",
            "\n",
            "         [[-4.5610e-01,  2.2247e-01,  2.1565e-01],\n",
            "          [-1.8045e-01, -1.5446e-01,  1.1526e-01],\n",
            "          [-1.5825e-01,  7.3281e-02,  3.5264e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1864e-01, -6.0254e-02,  9.2982e-02],\n",
            "          [ 1.4388e-01, -7.3523e-02, -2.0167e-01],\n",
            "          [-2.3147e-01,  1.1375e-01,  7.0444e-02]],\n",
            "\n",
            "         [[-4.4879e-02,  1.4091e-01, -1.9945e-01],\n",
            "          [ 2.1282e-01,  2.5781e-01,  1.0941e-01],\n",
            "          [-8.7437e-02,  1.2557e-01, -1.6704e-01]],\n",
            "\n",
            "         [[-8.5735e-02, -2.8465e-02, -7.9197e-02],\n",
            "          [ 5.6643e-02,  2.0363e-01,  4.2784e-02],\n",
            "          [ 8.6233e-03, -2.0354e-02, -3.6712e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.3492e-02, -1.5458e-01,  5.7564e-03],\n",
            "          [-3.7472e-02,  1.1123e-01, -2.3172e-01],\n",
            "          [ 1.0602e-01, -1.8604e-02, -1.4651e-01]],\n",
            "\n",
            "         [[-2.5336e-04, -5.2469e-03,  1.1831e-01],\n",
            "          [ 4.4008e-02, -9.3524e-02, -9.1982e-02],\n",
            "          [ 3.3203e-02, -1.1195e-01,  5.3600e-02]],\n",
            "\n",
            "         [[ 7.1521e-02,  3.1856e-02,  1.9880e-01],\n",
            "          [ 9.1581e-02, -6.5490e-02, -2.6157e-01],\n",
            "          [-6.2403e-02,  3.3127e-02, -9.8168e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4214e-01, -2.6254e-01, -2.4894e-01],\n",
            "          [ 6.0782e-02,  1.4442e-01, -4.1070e-02],\n",
            "          [ 2.3767e-01,  3.2218e-01,  1.7166e-01]],\n",
            "\n",
            "         [[ 6.9931e-02,  3.2418e-03,  5.9026e-02],\n",
            "          [ 9.8867e-02, -7.6754e-02, -1.1897e-01],\n",
            "          [-1.5324e-01,  2.3701e-01,  7.7406e-02]],\n",
            "\n",
            "         [[-1.8112e-02,  3.6124e-02,  8.8124e-02],\n",
            "          [ 5.1065e-03,  1.4502e-01, -1.0826e-01],\n",
            "          [-1.1482e-01,  1.5715e-01, -2.1675e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9496e-02, -2.3513e-01,  1.3399e-01],\n",
            "          [ 1.5434e-02,  1.2206e-01,  1.7543e-01],\n",
            "          [ 1.8777e-01,  6.9283e-02,  3.6612e-02]],\n",
            "\n",
            "         [[ 1.0813e-01, -9.1666e-02, -5.8822e-02],\n",
            "          [-1.7935e-01, -1.3325e-01, -9.2677e-02],\n",
            "          [ 1.5984e-02,  1.3427e-01, -1.9313e-01]],\n",
            "\n",
            "         [[-1.0145e-01, -1.7560e-01, -1.0277e-01],\n",
            "          [-4.1589e-02, -2.2296e-01, -2.0368e-02],\n",
            "          [-5.1968e-02, -9.4545e-02, -1.5786e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.8242e-01, -1.6982e-02,  1.2589e-01],\n",
            "          [-3.1782e-02, -1.3494e-02, -2.8895e-01],\n",
            "          [ 1.3941e-01, -1.0287e-01, -1.0379e-01]],\n",
            "\n",
            "         [[-2.7262e-01,  1.4852e-01,  1.4684e-01],\n",
            "          [ 7.8490e-02,  2.7467e-01,  1.6855e-02],\n",
            "          [ 3.8027e-01,  3.0940e-01,  1.7866e-02]],\n",
            "\n",
            "         [[-3.0519e-01,  2.7818e-02,  1.2216e-01],\n",
            "          [-2.1921e-01, -7.9760e-02, -2.0103e-04],\n",
            "          [ 1.7404e-01, -1.8248e-01, -1.4009e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0714e-01,  1.7765e-01, -3.0915e-01],\n",
            "          [-2.0353e-02, -1.6578e-01,  3.7074e-01],\n",
            "          [ 1.7386e-01, -2.7412e-01,  2.9055e-02]],\n",
            "\n",
            "         [[-1.2439e-01,  1.0872e-01, -1.7823e-01],\n",
            "          [-1.0632e-01, -2.9516e-01,  3.7788e-01],\n",
            "          [ 3.0583e-01, -4.0840e-01,  1.3042e-01]],\n",
            "\n",
            "         [[ 2.9924e-01,  8.6759e-02, -3.3583e-01],\n",
            "          [-1.1813e-02, -2.6363e-01,  4.2833e-01],\n",
            "          [-3.5804e-02, -3.3204e-01,  2.4581e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.5675e-02,  2.5866e-01,  1.2688e-01],\n",
            "          [-1.1888e-01,  2.3120e-01,  1.8862e-01],\n",
            "          [-1.0078e-01, -2.2704e-01, -3.4244e-01]],\n",
            "\n",
            "         [[ 2.7898e-02,  2.4486e-01,  1.8591e-01],\n",
            "          [ 2.0807e-01,  1.1544e-01,  4.7624e-03],\n",
            "          [ 3.2926e-02,  1.8853e-01, -1.2424e-01]],\n",
            "\n",
            "         [[-2.4558e-01, -1.8506e-01, -1.5971e-01],\n",
            "          [-2.0672e-01,  2.0476e-02, -1.1053e-01],\n",
            "          [ 2.1770e-01,  2.2833e-01, -8.8387e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.5205e-02,  1.5520e-01, -1.9695e-01],\n",
            "          [-7.9760e-02,  8.1679e-02, -6.8232e-02],\n",
            "          [ 1.6093e-03, -1.5213e-01, -1.2683e-01]],\n",
            "\n",
            "         [[ 1.8469e-01, -3.6921e-02, -1.7115e-01],\n",
            "          [ 8.1758e-02, -1.6792e-01, -6.7049e-02],\n",
            "          [ 1.6663e-01, -6.6594e-02,  1.2634e-01]],\n",
            "\n",
            "         [[-3.6184e-01, -6.5170e-02, -1.0652e-01],\n",
            "          [-4.7971e-01,  1.4482e-01,  4.2907e-01],\n",
            "          [-2.5983e-01,  2.9876e-01,  5.4646e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8698e-02, -1.1509e-01,  3.1465e-01],\n",
            "          [-2.2665e-01,  1.1842e-01, -1.0207e-01],\n",
            "          [-2.1049e-01, -7.1634e-02,  2.3764e-01]],\n",
            "\n",
            "         [[ 1.5028e-01, -1.8738e-01,  1.2004e-01],\n",
            "          [ 1.6371e-01, -1.7511e-03, -2.4908e-01],\n",
            "          [-5.7438e-02,  2.1253e-01,  4.7965e-02]],\n",
            "\n",
            "         [[ 2.8607e-01, -1.4524e-01, -2.5859e-01],\n",
            "          [ 2.9987e-01,  5.0431e-02, -5.1815e-01],\n",
            "          [ 2.1397e-01,  2.9649e-01, -3.1808e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8467e-02, -9.7171e-02, -6.5884e-02],\n",
            "          [ 4.7044e-03, -1.2399e-01,  1.3729e-01],\n",
            "          [-1.0409e-01,  1.7758e-01,  1.4271e-01]],\n",
            "\n",
            "         [[ 1.8816e-01,  7.7143e-02, -1.2912e-02],\n",
            "          [ 1.1297e-01, -2.5210e-01, -2.2299e-01],\n",
            "          [-2.8796e-01,  8.2649e-02, -8.7493e-02]],\n",
            "\n",
            "         [[ 2.1926e-01,  2.2060e-01,  1.7361e-01],\n",
            "          [-2.0023e-02,  1.5427e-01,  6.1582e-02],\n",
            "          [-2.0668e-01, -1.0826e-01,  1.1648e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5940e-01,  1.1073e-01, -1.7217e-02],\n",
            "          [-1.0682e-01,  6.4494e-02,  1.4025e-01],\n",
            "          [-8.2975e-02, -1.8486e-01, -2.2712e-01]],\n",
            "\n",
            "         [[-8.8423e-02,  1.4320e-01, -2.0304e-02],\n",
            "          [-5.0818e-03,  1.7296e-01, -8.4649e-02],\n",
            "          [ 6.2910e-03, -1.7587e-01, -2.0314e-02]],\n",
            "\n",
            "         [[-8.5325e-02, -1.5731e-01, -1.0675e-01],\n",
            "          [ 1.9048e-01,  1.6936e-01,  6.7662e-03],\n",
            "          [-2.7817e-05,  9.5952e-02, -2.4236e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1579e-01,  1.7570e-01, -1.1779e-01],\n",
            "          [ 2.0060e-03, -1.0404e-01,  1.3824e-01],\n",
            "          [-1.1473e-01,  3.1071e-02,  1.7744e-01]],\n",
            "\n",
            "         [[ 6.9442e-02, -1.5036e-02,  5.4487e-02],\n",
            "          [-5.8634e-02, -1.4846e-01,  9.5080e-02],\n",
            "          [ 1.6324e-01, -1.5676e-02, -8.4563e-02]],\n",
            "\n",
            "         [[ 1.1528e-01, -1.1609e-01,  2.9263e-03],\n",
            "          [ 5.4937e-02, -1.5815e-01,  1.8128e-01],\n",
            "          [ 1.5560e-01,  1.3262e-01,  1.8461e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1694e-01, -2.9142e-01, -2.6329e-01],\n",
            "          [-1.2755e-01, -1.9556e-01,  3.8795e-02],\n",
            "          [ 3.4141e-01,  3.4313e-01,  1.9673e-01]],\n",
            "\n",
            "         [[-1.2067e-01, -2.4652e-01,  3.6027e-03],\n",
            "          [-1.8045e-01,  1.0407e-01, -1.6403e-01],\n",
            "          [ 5.5994e-02,  2.2146e-01, -1.2961e-01]],\n",
            "\n",
            "         [[ 1.9381e-01, -3.1823e-02,  2.0926e-01],\n",
            "          [ 7.3488e-02, -8.3086e-02,  2.8715e-02],\n",
            "          [-1.1377e-01,  2.3878e-01, -1.3486e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6004e-02,  2.2558e-01,  1.3777e-01],\n",
            "          [ 1.4699e-01, -1.7660e-01, -9.6174e-02],\n",
            "          [-8.1804e-02, -1.1437e-01, -6.4043e-02]],\n",
            "\n",
            "         [[-1.8785e-01,  1.2662e-01,  1.1054e-01],\n",
            "          [ 6.8984e-02, -1.8815e-01, -4.3549e-02],\n",
            "          [ 2.6759e-01, -7.3002e-02, -8.8331e-02]],\n",
            "\n",
            "         [[-2.2460e-01, -8.1323e-02,  2.9143e-01],\n",
            "          [-2.5683e-01, -9.4635e-02,  2.5643e-01],\n",
            "          [-1.2625e-02, -2.2122e-01,  4.7715e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.8392e-02, -2.1575e-01, -2.8500e-02],\n",
            "          [-2.5681e-01, -2.5748e-01,  1.5143e-01],\n",
            "          [ 2.5797e-01,  3.1017e-01,  5.0137e-03]],\n",
            "\n",
            "         [[ 8.3711e-02, -2.3980e-01, -7.0890e-02],\n",
            "          [-9.5829e-02, -1.9823e-01,  2.7156e-01],\n",
            "          [-2.6914e-02,  2.7501e-01, -3.1315e-02]],\n",
            "\n",
            "         [[-1.3819e-01,  4.2787e-02,  3.4596e-02],\n",
            "          [-1.1717e-01, -1.7322e-01,  1.3440e-01],\n",
            "          [ 4.9149e-02, -5.2634e-02, -1.1780e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1362e-01,  4.8102e-02,  3.4139e-01],\n",
            "          [ 3.4290e-02, -2.4965e-01,  2.7953e-01],\n",
            "          [-1.6447e-01,  9.0822e-04,  2.3792e-01]],\n",
            "\n",
            "         [[-4.8142e-02, -1.0798e-01,  3.7232e-01],\n",
            "          [-1.0745e-02, -4.9819e-01,  8.5103e-02],\n",
            "          [ 1.1553e-01, -2.4784e-01,  1.5701e-01]],\n",
            "\n",
            "         [[-1.1495e-01, -2.1601e-01,  1.0106e-01],\n",
            "          [ 2.3005e-01, -3.2803e-01, -8.3869e-02],\n",
            "          [ 2.2454e-01, -1.0049e-02,  2.0753e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3836e-01,  3.2456e-01,  3.3695e-01],\n",
            "          [-2.4138e-01, -2.9768e-01, -1.5685e-01],\n",
            "          [-9.5723e-02, -7.9013e-02, -1.9312e-01]],\n",
            "\n",
            "         [[ 1.3153e-01,  6.7787e-02,  2.1433e-01],\n",
            "          [-2.6171e-01, -2.9836e-01, -2.0850e-01],\n",
            "          [ 1.0682e-01,  1.0624e-01, -1.6899e-01]],\n",
            "\n",
            "         [[ 1.7010e-01, -3.2429e-02, -1.2887e-02],\n",
            "          [-3.4082e-02, -2.3638e-01, -8.2708e-02],\n",
            "          [ 8.6260e-02,  2.9735e-01, -1.4077e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4088e-01,  2.0552e-01, -6.8858e-02],\n",
            "          [-1.4319e-02, -1.5148e-01, -2.4972e-01],\n",
            "          [ 2.8147e-01, -1.4573e-01, -1.2848e-01]],\n",
            "\n",
            "         [[-1.1730e-01, -4.3468e-02, -1.5309e-01],\n",
            "          [ 6.0057e-02, -1.9846e-01, -1.4349e-02],\n",
            "          [ 2.6214e-01,  1.4849e-01, -1.9905e-01]],\n",
            "\n",
            "         [[-1.7688e-01,  2.2597e-01, -1.7985e-01],\n",
            "          [ 1.3996e-01, -6.4199e-02, -1.3442e-01],\n",
            "          [ 2.9831e-01, -8.8765e-04,  5.7207e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.3738e-02, -6.5191e-02,  1.1433e-01],\n",
            "          [-5.4104e-02,  1.0246e-01,  1.1657e-01],\n",
            "          [-2.1356e-01, -1.6824e-01,  6.3947e-02]],\n",
            "\n",
            "         [[-9.3507e-02, -3.5852e-02,  4.9805e-02],\n",
            "          [ 1.4713e-01, -1.3346e-01, -1.2432e-01],\n",
            "          [-2.2472e-01, -1.8936e-01,  1.7751e-01]],\n",
            "\n",
            "         [[-7.8939e-02,  4.8241e-02, -1.3442e-01],\n",
            "          [ 1.6475e-02, -3.7413e-02,  2.9886e-01],\n",
            "          [-2.3843e-01, -1.1041e-02,  1.7069e-01]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1cc29246-d1bb-46a4-e4c3-22186df5b3e3"
      },
      "source": [
        "classify.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Classify_net_weights/classify_net_6layer_cnn.pt\"))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JM19FiENmBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88311db3-5279-4acb-e24f-6e516919b6d9"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break\n",
        "  "
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0rkwoqLpya8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af46c7a2-2359-493f-c4f9-2ffe9bae767c"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0309,  0.1087,  0.1955],\n",
            "          [ 0.2209,  0.0076,  0.0348],\n",
            "          [-0.0854,  0.0774, -0.0973]],\n",
            "\n",
            "         [[ 0.0616, -0.1282,  0.2080],\n",
            "          [ 0.0332, -0.1826, -0.1365],\n",
            "          [-0.1557, -0.0844, -0.1973]],\n",
            "\n",
            "         [[-0.0722,  0.0364,  0.1260],\n",
            "          [ 0.0611, -0.0341,  0.1729],\n",
            "          [ 0.0427,  0.0797,  0.0223]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1835,  0.0366, -0.1656],\n",
            "          [-0.0834,  0.1659,  0.0364],\n",
            "          [ 0.1062,  0.2152,  0.1314]],\n",
            "\n",
            "         [[ 0.0086,  0.2094,  0.2249],\n",
            "          [-0.1404, -0.1745,  0.0035],\n",
            "          [-0.2156,  0.0847,  0.0851]],\n",
            "\n",
            "         [[-0.1070,  0.1605, -0.1541],\n",
            "          [-0.0419, -0.0417,  0.0718],\n",
            "          [-0.0668, -0.2273, -0.2890]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1013,  0.0165, -0.0829],\n",
            "          [-0.1709,  0.1888, -0.0619],\n",
            "          [-0.0676,  0.2545,  0.2560]],\n",
            "\n",
            "         [[-0.0495, -0.0233, -0.0692],\n",
            "          [ 0.0196, -0.1944, -0.2639],\n",
            "          [-0.2429,  0.0565,  0.1495]],\n",
            "\n",
            "         [[ 0.2412, -0.1480, -0.1188],\n",
            "          [ 0.0755,  0.0533, -0.1636],\n",
            "          [ 0.1195,  0.0296, -0.0620]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2049,  0.1405, -0.0744],\n",
            "          [ 0.0715,  0.0253,  0.0548],\n",
            "          [-0.0363, -0.0603, -0.0169]],\n",
            "\n",
            "         [[ 0.1719, -0.0024,  0.1642],\n",
            "          [ 0.0824, -0.1403,  0.0444],\n",
            "          [ 0.1660, -0.0140, -0.0213]],\n",
            "\n",
            "         [[-0.1377,  0.0023,  0.0830],\n",
            "          [-0.0201,  0.0463, -0.1071],\n",
            "          [-0.0089, -0.0475,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1722, -0.1703,  0.0900],\n",
            "          [-0.0026, -0.1981, -0.0808],\n",
            "          [-0.0556, -0.0525, -0.0903]],\n",
            "\n",
            "         [[ 0.0469,  0.1535,  0.1791],\n",
            "          [ 0.0031, -0.1002,  0.1474],\n",
            "          [-0.2295,  0.1191,  0.0080]],\n",
            "\n",
            "         [[ 0.1878,  0.0110,  0.1277],\n",
            "          [ 0.0146,  0.1758,  0.1353],\n",
            "          [-0.1670,  0.1439, -0.0813]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1690,  0.1051, -0.0433],\n",
            "          [-0.2494,  0.0010,  0.0629],\n",
            "          [-0.0552,  0.0004,  0.0097]],\n",
            "\n",
            "         [[ 0.1635,  0.3134,  0.0763],\n",
            "          [-0.1233,  0.0560, -0.2310],\n",
            "          [-0.1199, -0.2663, -0.0928]],\n",
            "\n",
            "         [[ 0.0838,  0.1768,  0.0256],\n",
            "          [-0.2400,  0.1630, -0.2009],\n",
            "          [ 0.0774, -0.0150,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1059,  0.0585, -0.1707],\n",
            "          [ 0.1078, -0.0531, -0.0276],\n",
            "          [ 0.1118, -0.0519, -0.1506]],\n",
            "\n",
            "         [[-0.1614,  0.1542, -0.1130],\n",
            "          [ 0.1823,  0.1833,  0.1834],\n",
            "          [ 0.0840, -0.0238,  0.0096]],\n",
            "\n",
            "         [[ 0.1863,  0.0509, -0.1148],\n",
            "          [-0.0720,  0.1801, -0.0417],\n",
            "          [ 0.0088,  0.0210, -0.0527]]],\n",
            "\n",
            "\n",
            "        [[[-0.0021, -0.1920, -0.1925],\n",
            "          [-0.0794, -0.1094, -0.1952],\n",
            "          [ 0.0640, -0.1527, -0.1590]],\n",
            "\n",
            "         [[ 0.0023, -0.0093,  0.0917],\n",
            "          [ 0.1893,  0.1771, -0.0419],\n",
            "          [ 0.1959,  0.0765, -0.1216]],\n",
            "\n",
            "         [[ 0.1127, -0.0509, -0.0890],\n",
            "          [ 0.0425, -0.0004,  0.0970],\n",
            "          [ 0.1725, -0.0294,  0.2238]]],\n",
            "\n",
            "\n",
            "        [[[-0.1533,  0.2030, -0.1170],\n",
            "          [ 0.0515, -0.0504, -0.1635],\n",
            "          [-0.1322, -0.1429,  0.1475]],\n",
            "\n",
            "         [[ 0.0555, -0.0411,  0.2137],\n",
            "          [-0.0274, -0.0902,  0.0513],\n",
            "          [ 0.0085, -0.1591,  0.1483]],\n",
            "\n",
            "         [[ 0.1163, -0.1371,  0.0318],\n",
            "          [ 0.0841, -0.2464, -0.2148],\n",
            "          [ 0.0637,  0.1322,  0.0676]]],\n",
            "\n",
            "\n",
            "        [[[-0.0227,  0.0487,  0.2023],\n",
            "          [-0.1330,  0.1492, -0.0169],\n",
            "          [ 0.1584,  0.1524, -0.0456]],\n",
            "\n",
            "         [[-0.0525, -0.1646, -0.0814],\n",
            "          [-0.2456, -0.1350,  0.0154],\n",
            "          [ 0.2309, -0.1780, -0.0720]],\n",
            "\n",
            "         [[-0.0142,  0.0480,  0.2516],\n",
            "          [-0.1593,  0.1562,  0.1928],\n",
            "          [-0.1119, -0.2044, -0.1976]]],\n",
            "\n",
            "\n",
            "        [[[-0.0355,  0.1166, -0.0631],\n",
            "          [-0.0836, -0.1515,  0.1577],\n",
            "          [ 0.0235,  0.1110, -0.0250]],\n",
            "\n",
            "         [[-0.2114,  0.1654,  0.2484],\n",
            "          [ 0.0525,  0.2583,  0.0362],\n",
            "          [-0.0713,  0.1357, -0.0152]],\n",
            "\n",
            "         [[-0.0821, -0.0350, -0.1481],\n",
            "          [-0.2171,  0.0489,  0.2106],\n",
            "          [ 0.1037, -0.1230,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.1625,  0.1384],\n",
            "          [-0.1124, -0.1412,  0.2642],\n",
            "          [ 0.0284, -0.0494, -0.0447]],\n",
            "\n",
            "         [[ 0.0205, -0.2302,  0.1754],\n",
            "          [ 0.0924, -0.2460,  0.2219],\n",
            "          [ 0.0863, -0.1062,  0.1210]],\n",
            "\n",
            "         [[ 0.2537, -0.2292, -0.1540],\n",
            "          [ 0.2104, -0.2362,  0.1700],\n",
            "          [ 0.2093, -0.2085, -0.0309]]],\n",
            "\n",
            "\n",
            "        [[[-0.1426,  0.1824, -0.2160],\n",
            "          [ 0.0009, -0.0087,  0.0207],\n",
            "          [ 0.0911, -0.2336, -0.1702]],\n",
            "\n",
            "         [[ 0.2153,  0.1894,  0.0243],\n",
            "          [-0.2433,  0.2294,  0.2479],\n",
            "          [-0.0595, -0.1203,  0.1227]],\n",
            "\n",
            "         [[-0.1597,  0.1976, -0.1576],\n",
            "          [-0.1258, -0.0205, -0.1531],\n",
            "          [ 0.1347,  0.0364, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[-0.0633, -0.0466, -0.0325],\n",
            "          [-0.0601,  0.0621, -0.0215],\n",
            "          [-0.0044, -0.0534,  0.0422]],\n",
            "\n",
            "         [[-0.1383, -0.1374, -0.1793],\n",
            "          [-0.0877, -0.1327,  0.0918],\n",
            "          [-0.0787,  0.0740, -0.0112]],\n",
            "\n",
            "         [[ 0.0814,  0.0275, -0.1438],\n",
            "          [-0.0439,  0.1876,  0.1383],\n",
            "          [-0.0834,  0.1108,  0.0304]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0447,  0.0499, -0.1449],\n",
            "          [-0.1171, -0.0733,  0.0182],\n",
            "          [-0.0587, -0.1367, -0.1931]],\n",
            "\n",
            "         [[ 0.0961,  0.0888, -0.0784],\n",
            "          [ 0.0504, -0.1259,  0.0890],\n",
            "          [-0.1473,  0.0371,  0.1020]],\n",
            "\n",
            "         [[ 0.0476, -0.1709, -0.0371],\n",
            "          [ 0.2308,  0.1298,  0.0326],\n",
            "          [-0.0171, -0.0634, -0.1609]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2378, -0.1200, -0.2246],\n",
            "          [ 0.2465,  0.0634, -0.1682],\n",
            "          [-0.0573, -0.1788,  0.0856]],\n",
            "\n",
            "         [[ 0.2020,  0.1478, -0.0181],\n",
            "          [ 0.1683,  0.0819, -0.0775],\n",
            "          [ 0.1869, -0.2327, -0.2108]],\n",
            "\n",
            "         [[-0.0383, -0.1762, -0.0893],\n",
            "          [-0.1869,  0.0115,  0.0917],\n",
            "          [ 0.0562, -0.0899,  0.1009]]],\n",
            "\n",
            "\n",
            "        [[[-0.0911, -0.2512,  0.0277],\n",
            "          [-0.0324,  0.1520,  0.2214],\n",
            "          [ 0.1329, -0.0946,  0.1157]],\n",
            "\n",
            "         [[ 0.1063, -0.1710,  0.0471],\n",
            "          [-0.1126,  0.1777,  0.2435],\n",
            "          [-0.1798,  0.0235,  0.1735]],\n",
            "\n",
            "         [[ 0.0092, -0.1809,  0.0974],\n",
            "          [ 0.1691, -0.1317,  0.1264],\n",
            "          [-0.1224, -0.1659, -0.2023]]],\n",
            "\n",
            "\n",
            "        [[[-0.2336,  0.2346,  0.0983],\n",
            "          [-0.1950, -0.1840,  0.1690],\n",
            "          [-0.2168,  0.0477,  0.0916]],\n",
            "\n",
            "         [[-0.0561,  0.1103,  0.0033],\n",
            "          [-0.0990, -0.2062, -0.0978],\n",
            "          [ 0.1411, -0.0397,  0.0443]],\n",
            "\n",
            "         [[ 0.1579,  0.1184, -0.1102],\n",
            "          [ 0.1775,  0.0325, -0.1486],\n",
            "          [-0.0702,  0.2019,  0.1233]]],\n",
            "\n",
            "\n",
            "        [[[-0.0797,  0.1350,  0.1679],\n",
            "          [-0.0473,  0.2595,  0.1358],\n",
            "          [-0.2849, -0.0974, -0.0081]],\n",
            "\n",
            "         [[-0.1065, -0.1424, -0.1542],\n",
            "          [-0.2096,  0.1828,  0.1126],\n",
            "          [ 0.0174,  0.0576, -0.0152]],\n",
            "\n",
            "         [[-0.2226,  0.0298, -0.1312],\n",
            "          [-0.1327,  0.2087,  0.1935],\n",
            "          [-0.0249,  0.0243, -0.0377]]],\n",
            "\n",
            "\n",
            "        [[[-0.0588,  0.1742,  0.2010],\n",
            "          [ 0.1427, -0.0923,  0.0899],\n",
            "          [-0.1261, -0.1139, -0.0786]],\n",
            "\n",
            "         [[-0.1481,  0.0529,  0.0481],\n",
            "          [ 0.0126, -0.0323,  0.1211],\n",
            "          [-0.0912, -0.0420, -0.1293]],\n",
            "\n",
            "         [[-0.2270, -0.2813, -0.1512],\n",
            "          [ 0.0183, -0.0734, -0.0467],\n",
            "          [ 0.1668,  0.1287,  0.1416]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1385,  0.0580,  0.3274],\n",
            "          [-0.0714, -0.0263,  0.2946],\n",
            "          [-0.2355, -0.3553,  0.0437]],\n",
            "\n",
            "         [[ 0.0762, -0.1933, -0.1612],\n",
            "          [-0.1279,  0.0055, -0.0561],\n",
            "          [ 0.2241, -0.0410,  0.1810]],\n",
            "\n",
            "         [[ 0.1535, -0.1441, -0.1855],\n",
            "          [ 0.2696, -0.1765,  0.0269],\n",
            "          [ 0.2909, -0.1872, -0.1417]]],\n",
            "\n",
            "\n",
            "        [[[-0.1353, -0.0778,  0.2160],\n",
            "          [-0.2453,  0.0684,  0.2713],\n",
            "          [ 0.0924,  0.0206,  0.2311]],\n",
            "\n",
            "         [[-0.1599,  0.0515, -0.0479],\n",
            "          [-0.1464, -0.0211,  0.0214],\n",
            "          [-0.1591, -0.0081, -0.1259]],\n",
            "\n",
            "         [[-0.0057,  0.1981, -0.0700],\n",
            "          [-0.1581,  0.2080,  0.0793],\n",
            "          [-0.2191,  0.0567,  0.0142]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2331, -0.0791, -0.0360],\n",
            "          [ 0.0551, -0.1573, -0.1605],\n",
            "          [ 0.1258, -0.0884, -0.2061]],\n",
            "\n",
            "         [[-0.2222,  0.1591,  0.1350],\n",
            "          [-0.1694, -0.0935,  0.0388],\n",
            "          [-0.0330,  0.1814,  0.0005]],\n",
            "\n",
            "         [[-0.1377, -0.0267,  0.1763],\n",
            "          [-0.2532,  0.2026,  0.1464],\n",
            "          [-0.0366,  0.2414, -0.1755]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0655, -0.1766, -0.2965],\n",
            "          [ 0.0635, -0.1370,  0.2211],\n",
            "          [ 0.0251, -0.0315,  0.2027]],\n",
            "\n",
            "         [[ 0.2559, -0.1553, -0.1362],\n",
            "          [ 0.2658, -0.1706,  0.1501],\n",
            "          [-0.1731, -0.0166, -0.0638]],\n",
            "\n",
            "         [[-0.1674,  0.0792,  0.1900],\n",
            "          [-0.0342, -0.2272,  0.2679],\n",
            "          [-0.0845, -0.0639,  0.0261]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0958,  0.0557, -0.0319],\n",
            "          [ 0.1302, -0.0530, -0.2087],\n",
            "          [ 0.0320,  0.1967, -0.1969]],\n",
            "\n",
            "         [[ 0.1327, -0.1589,  0.1865],\n",
            "          [-0.0338, -0.2036, -0.2538],\n",
            "          [ 0.1661,  0.1607,  0.1042]],\n",
            "\n",
            "         [[-0.2442, -0.0128, -0.1746],\n",
            "          [-0.0988,  0.0191, -0.2384],\n",
            "          [-0.1124,  0.2998,  0.2225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1305, -0.0375, -0.0713],\n",
            "          [-0.0881,  0.0315, -0.0487],\n",
            "          [-0.1159, -0.0198, -0.0042]],\n",
            "\n",
            "         [[-0.1895,  0.1779, -0.0391],\n",
            "          [ 0.1096, -0.0229,  0.0431],\n",
            "          [ 0.1912, -0.0880,  0.1516]],\n",
            "\n",
            "         [[ 0.1237,  0.1648,  0.0864],\n",
            "          [ 0.1106, -0.1358, -0.0593],\n",
            "          [ 0.0834,  0.1760, -0.1148]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0261,  0.0946, -0.2135],\n",
            "          [-0.0508, -0.2134, -0.0804],\n",
            "          [ 0.2161,  0.1251,  0.1160]],\n",
            "\n",
            "         [[ 0.2439,  0.1499,  0.0541],\n",
            "          [-0.1242, -0.3017, -0.1642],\n",
            "          [ 0.1484,  0.0228, -0.0532]],\n",
            "\n",
            "         [[ 0.2827,  0.0027,  0.2216],\n",
            "          [-0.2123, -0.1097, -0.0140],\n",
            "          [-0.1472, -0.1401,  0.1451]]],\n",
            "\n",
            "\n",
            "        [[[-0.0668, -0.0305, -0.1276],\n",
            "          [-0.0389,  0.0897,  0.0144],\n",
            "          [ 0.0437, -0.0369,  0.2345]],\n",
            "\n",
            "         [[ 0.0160, -0.0964, -0.1077],\n",
            "          [ 0.1918,  0.2170,  0.1363],\n",
            "          [-0.1928, -0.0407,  0.0342]],\n",
            "\n",
            "         [[-0.0021, -0.0420,  0.0836],\n",
            "          [ 0.0767,  0.0022,  0.0412],\n",
            "          [-0.1141, -0.0197,  0.0672]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1341, -0.0483, -0.1076],\n",
            "          [-0.1852, -0.0061,  0.0918],\n",
            "          [-0.1238,  0.0374, -0.0902]],\n",
            "\n",
            "         [[ 0.1261, -0.0141, -0.0833],\n",
            "          [-0.1273, -0.2019, -0.1387],\n",
            "          [-0.0098,  0.2122, -0.0161]],\n",
            "\n",
            "         [[ 0.1478,  0.0007, -0.0934],\n",
            "          [-0.1233,  0.0490,  0.0353],\n",
            "          [ 0.2064, -0.1164,  0.1303]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0583, -0.1114,  0.2957],\n",
            "          [ 0.1703, -0.0507,  0.0694],\n",
            "          [-0.1846,  0.1098, -0.1668]],\n",
            "\n",
            "         [[-0.2051, -0.2725, -0.0990],\n",
            "          [-0.1666,  0.0620, -0.0992],\n",
            "          [ 0.1796,  0.0437, -0.2720]],\n",
            "\n",
            "         [[ 0.1627, -0.1647, -0.0541],\n",
            "          [ 0.0633,  0.2490, -0.1993],\n",
            "          [ 0.1262,  0.2773,  0.0247]]],\n",
            "\n",
            "\n",
            "        [[[-0.2300, -0.1971, -0.0127],\n",
            "          [ 0.0639,  0.0679, -0.0152],\n",
            "          [ 0.2227, -0.0215, -0.0974]],\n",
            "\n",
            "         [[-0.2116, -0.0484,  0.1070],\n",
            "          [ 0.1198, -0.1068, -0.0113],\n",
            "          [ 0.1952,  0.0198,  0.0825]],\n",
            "\n",
            "         [[-0.3352,  0.1302,  0.0801],\n",
            "          [ 0.1699,  0.1231,  0.0742],\n",
            "          [ 0.0210, -0.1424,  0.0352]]],\n",
            "\n",
            "\n",
            "        [[[-0.0857,  0.1421,  0.1182],\n",
            "          [ 0.1262,  0.2026,  0.1068],\n",
            "          [ 0.0704, -0.0585, -0.0306]],\n",
            "\n",
            "         [[ 0.1038, -0.1139,  0.0915],\n",
            "          [ 0.1529,  0.1774, -0.1306],\n",
            "          [-0.2282, -0.2159,  0.0512]],\n",
            "\n",
            "         [[-0.1076, -0.1626,  0.0314],\n",
            "          [-0.1577,  0.1472,  0.1330],\n",
            "          [ 0.1294, -0.0155, -0.0551]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWKhNgh6tSik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4fhhuP9tYNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "070b15a7-d42e-49bd-af7c-4a65bf263ac9"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29978\n",
            "total train set images 30000\n",
            "focus_true_pred_true 29976 =============> FTPT : 99 %\n",
            "focus_false_pred_true 2 =============> FFPT : 0 %\n",
            "focus_true_pred_false 19 =============> FTPF : 0 %\n",
            "focus_false_pred_false 3 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  30000\n",
            "argmax_less_than_half ==================>  0\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NIm2739tYEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "219a41a8-b9f5-4270-db1a-da88f781b73e"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n",
            "total correct 9997\n",
            "total train set images 10000\n",
            "focus_true_pred_true 9997 =============> FTPT : 99 %\n",
            "focus_false_pred_true 0 =============> FFPT : 0 %\n",
            "focus_true_pred_false 3 =============> FTPF : 0 %\n",
            "focus_false_pred_false 0 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  10000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tFfAJZkcZEsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "c636bc2f-9276-48a5-b447-8a688f5df4f0"
      },
      "source": [
        "nos_epochs = 200\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_focus.step()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    focus_net.eval()\n",
        "    classify.eval()\n",
        "    col1.append(epoch + 1 )\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 0.049\n",
            "[1,   120] loss: 0.080\n",
            "[1,   180] loss: 0.023\n",
            "[1,   240] loss: 0.028\n",
            "[2,    60] loss: 0.118\n",
            "[2,   120] loss: 0.057\n",
            "[2,   180] loss: 0.034\n",
            "[2,   240] loss: 0.067\n",
            "[3,    60] loss: 0.039\n",
            "[3,   120] loss: 0.023\n",
            "[3,   180] loss: 0.023\n",
            "[3,   240] loss: 0.030\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfZ2k3hXy85T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69feeab8-c8cd-4eba-fab5-c351d8b73525"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYD8ohJ8fkBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "966e14e9-01c8-4b97-a067-48fefcd0dcdd"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0omdiVCzBhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0a00834-fb79-40ee-93fa-a9971f0a92df"
      },
      "source": [
        "for params in focus_net.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-1.0769e-01,  1.8356e-01, -3.7659e-01],\n",
            "          [ 1.3221e-01,  3.0923e-01, -2.3317e-01],\n",
            "          [-1.0439e-01,  1.7067e-01, -4.9822e-02]],\n",
            "\n",
            "         [[-1.8005e-01,  2.7539e-01, -1.6436e-02],\n",
            "          [-1.3343e-01,  1.1521e-01, -2.1972e-02],\n",
            "          [-1.8378e-01,  1.5336e-02,  2.2860e-01]],\n",
            "\n",
            "         [[ 2.6595e-01,  4.5332e-01, -9.9903e-03],\n",
            "          [ 1.3499e-01,  2.0803e-02, -3.3403e-01],\n",
            "          [-3.4306e-01, -2.8441e-01,  2.4925e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4483e-01, -3.0952e-01, -1.4938e-01],\n",
            "          [-7.8588e-02, -2.3472e-01, -1.1498e-01],\n",
            "          [ 3.6368e-03, -3.0023e-01, -1.6048e-01]],\n",
            "\n",
            "         [[ 2.3338e-01, -7.6699e-02,  2.3733e-01],\n",
            "          [ 6.8080e-03, -2.3074e-03, -1.2374e-01],\n",
            "          [-3.5954e-03, -1.7141e-01,  1.4663e-01]],\n",
            "\n",
            "         [[ 6.0099e-02,  2.2344e-01,  2.0325e-01],\n",
            "          [ 2.2871e-01, -5.8040e-03,  7.8011e-02],\n",
            "          [ 2.0915e-01, -2.0690e-02,  3.0517e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4680e-02, -9.2363e-02, -7.9017e-02],\n",
            "          [ 1.6373e-01,  8.8736e-02, -1.7425e-01],\n",
            "          [ 7.2686e-02,  3.6367e-02, -2.0956e-01]],\n",
            "\n",
            "         [[ 4.8083e-02,  3.3362e-02,  9.6050e-02],\n",
            "          [-9.3957e-02,  1.9101e-01, -1.7500e-01],\n",
            "          [ 2.2922e-01,  1.9201e-01,  1.0556e-01]],\n",
            "\n",
            "         [[-9.5749e-03,  2.4667e-02, -2.2867e-01],\n",
            "          [ 6.8979e-03,  7.8902e-04,  4.5540e-02],\n",
            "          [ 1.1947e-01,  5.6076e-02,  8.7866e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.6032e-02,  1.2267e-01,  1.9676e-01],\n",
            "          [-1.0651e-01,  2.1748e-01,  2.3152e-01],\n",
            "          [-7.3141e-02, -1.2564e-01, -5.6165e-02]],\n",
            "\n",
            "         [[-4.7266e-02, -8.2944e-02, -1.8609e-01],\n",
            "          [-2.3849e-01, -8.7790e-02, -1.3592e-01],\n",
            "          [-1.9414e-02, -8.2041e-02, -1.1066e-01]],\n",
            "\n",
            "         [[-7.1174e-02, -1.2165e-01, -5.1284e-02],\n",
            "          [-1.8999e-02,  1.5316e-01, -1.6746e-01],\n",
            "          [-4.0941e-02,  1.3744e-01, -1.9457e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.1729e-03, -7.4519e-02,  2.0361e-01],\n",
            "          [-2.3655e-01,  1.7618e-01,  2.7426e-01],\n",
            "          [-2.5133e-02, -9.6533e-03, -6.1291e-02]],\n",
            "\n",
            "         [[ 1.9866e-01,  1.4884e-02,  1.1294e-02],\n",
            "          [ 1.9401e-01, -1.2367e-01,  1.5703e-01],\n",
            "          [-2.4785e-01, -1.4590e-01,  7.9839e-02]],\n",
            "\n",
            "         [[-1.4497e-01, -1.1140e-01, -2.6250e-01],\n",
            "          [ 2.0914e-01, -1.0474e-01,  1.2643e-02],\n",
            "          [ 1.0343e-01,  1.0261e-02,  1.9507e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5883e-01,  6.7333e-03, -8.7967e-02],\n",
            "          [ 8.2236e-02, -1.1274e-01, -4.0347e-03],\n",
            "          [-1.2070e-01,  1.1159e-01,  2.1643e-01]],\n",
            "\n",
            "         [[ 1.5919e-01, -1.4935e-03, -1.1914e-01],\n",
            "          [ 2.9556e-01,  1.5615e-01, -2.8046e-01],\n",
            "          [ 1.0822e-01, -4.2953e-02,  1.1277e-01]],\n",
            "\n",
            "         [[-2.2931e-02, -1.7275e-01, -5.9330e-02],\n",
            "          [-1.1743e-01, -1.9430e-01, -3.4193e-01],\n",
            "          [ 7.6466e-02, -1.8654e-01,  5.0012e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5497e-01,  1.4377e-01, -1.9147e-01],\n",
            "          [ 2.7927e-01, -1.1629e-01, -3.1095e-02],\n",
            "          [-1.9929e-01, -4.6042e-03,  1.7891e-01]],\n",
            "\n",
            "         [[-2.9788e-01, -1.4576e-01, -3.9615e-02],\n",
            "          [ 2.6479e-01, -1.1143e-01,  1.9551e-01],\n",
            "          [-1.6674e-01,  1.8671e-01,  2.5764e-01]],\n",
            "\n",
            "         [[-1.3726e-01, -1.0546e-01, -2.3758e-01],\n",
            "          [ 3.7311e-01, -4.7823e-02, -2.4374e-01],\n",
            "          [ 1.5021e-01,  1.3687e-01, -8.2633e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8498e-02,  7.7289e-02, -4.8996e-01],\n",
            "          [ 2.0115e-01,  2.9953e-01,  4.6336e-02],\n",
            "          [ 1.8899e-01,  3.4566e-01,  1.8002e-01]],\n",
            "\n",
            "         [[-4.6238e-02,  2.4768e-01, -2.6361e-01],\n",
            "          [-2.4951e-01, -2.8494e-01, -1.1163e-01],\n",
            "          [-6.7311e-02, -1.8417e-01, -1.8251e-01]],\n",
            "\n",
            "         [[-2.6635e-02,  3.5448e-01,  9.9475e-02],\n",
            "          [ 9.8598e-02,  5.3847e-02, -4.0364e-02],\n",
            "          [-1.8440e-02, -1.0100e-01, -1.3214e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5540e-02,  3.1344e-03, -7.4411e-02],\n",
            "          [ 3.1257e-02,  3.7525e-01, -2.8885e-01],\n",
            "          [ 1.4881e-01,  7.1584e-02, -1.9749e-01]],\n",
            "\n",
            "         [[-4.2197e-02,  2.0810e-01, -2.3403e-01],\n",
            "          [-7.6562e-02,  3.9363e-01, -3.3567e-01],\n",
            "          [-2.2039e-01,  2.3914e-01, -7.9954e-02]],\n",
            "\n",
            "         [[-2.3628e-01,  2.7403e-01, -2.8155e-02],\n",
            "          [-2.5925e-01,  5.1707e-01, -3.5511e-01],\n",
            "          [ 4.7447e-02,  1.1014e-01, -2.7141e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.6965e-02,  1.1711e-01, -1.0611e-01],\n",
            "          [-5.1167e-02,  1.7151e-02, -2.1161e-02],\n",
            "          [ 1.1745e-01,  9.8205e-02, -1.2449e-01]],\n",
            "\n",
            "         [[-3.0465e-02, -6.7950e-02, -2.4881e-01],\n",
            "          [-2.4590e-02,  1.4363e-01, -2.3065e-01],\n",
            "          [ 1.4624e-01,  1.4313e-02, -2.1216e-01]],\n",
            "\n",
            "         [[-2.4121e-01,  1.1167e-03, -1.9308e-02],\n",
            "          [ 3.2923e-02,  8.8971e-02,  1.4258e-01],\n",
            "          [ 2.4892e-01,  2.8496e-01,  9.0534e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.6011e-01, -1.6080e-01,  3.6873e-01],\n",
            "          [ 3.3696e-01, -6.5754e-02, -1.9986e-01],\n",
            "          [ 1.4193e-01, -5.2087e-02, -1.9412e-01]],\n",
            "\n",
            "         [[-3.5830e-01, -4.5661e-02,  7.7556e-02],\n",
            "          [ 3.2389e-01, -9.1093e-02, -7.5572e-02],\n",
            "          [ 1.4875e-01, -4.4108e-04,  4.1802e-02]],\n",
            "\n",
            "         [[ 1.0345e-01,  1.3666e-01,  1.4416e-01],\n",
            "          [ 3.8129e-01, -1.8065e-01, -9.1839e-02],\n",
            "          [ 1.0273e-02, -2.1911e-01, -2.1736e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.0017e-01,  4.8219e-02, -2.5277e-02],\n",
            "          [-1.3934e-01, -2.8919e-01,  1.3023e-01],\n",
            "          [-4.0510e-02, -5.1866e-01,  5.9149e-02]],\n",
            "\n",
            "         [[ 4.5933e-02,  1.3701e-01,  1.2324e-02],\n",
            "          [ 3.4354e-01,  1.0419e-01,  2.7914e-01],\n",
            "          [ 2.9974e-01, -1.7624e-01,  2.7393e-01]],\n",
            "\n",
            "         [[ 3.9011e-02, -6.2318e-03, -1.3690e-01],\n",
            "          [ 1.0112e-01, -2.8065e-01, -1.0546e-02],\n",
            "          [ 1.2338e-01, -2.9291e-01, -8.5622e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6286e-01,  3.0664e-01, -1.1427e-01],\n",
            "          [ 3.3261e-01,  2.9190e-01, -9.8579e-02],\n",
            "          [ 2.0801e-01, -3.0196e-01, -3.4839e-01]],\n",
            "\n",
            "         [[-2.8055e-01,  1.4507e-01, -3.5984e-02],\n",
            "          [ 3.5261e-03,  1.8703e-01,  2.3620e-01],\n",
            "          [-1.1097e-01, -1.4144e-01, -1.7231e-01]],\n",
            "\n",
            "         [[-4.5323e-01,  2.2415e-01,  2.1746e-01],\n",
            "          [-1.7709e-01, -1.5442e-01,  1.1381e-01],\n",
            "          [-1.5768e-01,  7.1121e-02,  3.4839e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1685e-01, -6.1496e-02,  9.0907e-02],\n",
            "          [ 1.4313e-01, -7.2928e-02, -2.0152e-01],\n",
            "          [-2.2971e-01,  1.1589e-01,  7.2558e-02]],\n",
            "\n",
            "         [[-4.4851e-02,  1.4140e-01, -1.9971e-01],\n",
            "          [ 2.1401e-01,  2.6033e-01,  1.1162e-01],\n",
            "          [-8.4134e-02,  1.2971e-01, -1.6303e-01]],\n",
            "\n",
            "         [[-8.3191e-02, -2.5180e-02, -7.6454e-02],\n",
            "          [ 5.9689e-02,  2.0850e-01,  4.7650e-02],\n",
            "          [ 1.3050e-02, -1.4485e-02, -3.0674e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.0482e-02, -1.5016e-01,  9.3550e-03],\n",
            "          [-3.5127e-02,  1.1374e-01, -2.3033e-01],\n",
            "          [ 1.0704e-01, -1.7623e-02, -1.4583e-01]],\n",
            "\n",
            "         [[ 3.2017e-03, -5.6597e-04,  1.2178e-01],\n",
            "          [ 4.7208e-02, -9.0300e-02, -9.0113e-02],\n",
            "          [ 3.5792e-02, -1.0950e-01,  5.5532e-02]],\n",
            "\n",
            "         [[ 7.5112e-02,  3.6825e-02,  2.0251e-01],\n",
            "          [ 9.5351e-02, -6.1305e-02, -2.5843e-01],\n",
            "          [-5.8277e-02,  3.7261e-02, -9.4183e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4161e-01, -2.6359e-01, -2.5259e-01],\n",
            "          [ 6.0269e-02,  1.4273e-01, -4.3753e-02],\n",
            "          [ 2.3789e-01,  3.2331e-01,  1.7414e-01]],\n",
            "\n",
            "         [[ 7.1531e-02,  4.1220e-03,  5.8398e-02],\n",
            "          [ 9.9747e-02, -7.6450e-02, -1.1895e-01],\n",
            "          [-1.5179e-01,  2.3993e-01,  8.2341e-02]],\n",
            "\n",
            "         [[-1.4116e-02,  3.9121e-02,  8.9716e-02],\n",
            "          [ 8.5412e-03,  1.4751e-01, -1.0623e-01],\n",
            "          [-1.1160e-01,  1.6206e-01, -2.0944e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3448e-02, -2.3314e-01,  1.3415e-01],\n",
            "          [ 1.7860e-02,  1.2388e-01,  1.7533e-01],\n",
            "          [ 1.8939e-01,  7.0848e-02,  3.7050e-02]],\n",
            "\n",
            "         [[ 1.1120e-01, -9.0728e-02, -5.9791e-02],\n",
            "          [-1.7824e-01, -1.3300e-01, -9.4337e-02],\n",
            "          [ 1.6193e-02,  1.3412e-01, -1.9443e-01]],\n",
            "\n",
            "         [[-9.6587e-02, -1.7294e-01, -1.0187e-01],\n",
            "          [-3.8786e-02, -2.2104e-01, -2.0167e-02],\n",
            "          [-5.0104e-02, -9.3155e-02, -1.5746e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.8509e-01, -2.0321e-02,  1.2271e-01],\n",
            "          [-3.0404e-02, -1.3310e-02, -2.9102e-01],\n",
            "          [ 1.4355e-01, -9.9654e-02, -1.0196e-01]],\n",
            "\n",
            "         [[-2.7754e-01,  1.4355e-01,  1.4241e-01],\n",
            "          [ 7.6881e-02,  2.7208e-01,  1.2145e-02],\n",
            "          [ 3.8132e-01,  3.0938e-01,  1.6206e-02]],\n",
            "\n",
            "         [[-3.1481e-01,  1.8337e-02,  1.1339e-01],\n",
            "          [-2.2585e-01, -8.6926e-02, -9.0698e-03],\n",
            "          [ 1.6941e-01, -1.8769e-01, -1.4676e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1602e-01,  1.8494e-01, -3.0058e-01],\n",
            "          [-1.4485e-02, -1.5961e-01,  3.7448e-01],\n",
            "          [ 1.7208e-01, -2.7276e-01,  2.3607e-02]],\n",
            "\n",
            "         [[-1.1907e-01,  1.1406e-01, -1.7039e-01],\n",
            "          [-1.0205e-01, -2.8877e-01,  3.8248e-01],\n",
            "          [ 3.0254e-01, -4.0740e-01,  1.2432e-01]],\n",
            "\n",
            "         [[ 3.0265e-01,  9.0971e-02, -3.2835e-01],\n",
            "          [-9.9403e-03, -2.5906e-01,  4.3212e-01],\n",
            "          [-4.1743e-02, -3.3378e-01,  2.3736e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.7076e-02,  2.5792e-01,  1.2483e-01],\n",
            "          [-1.1928e-01,  2.3080e-01,  1.8799e-01],\n",
            "          [-1.0215e-01, -2.2872e-01, -3.4250e-01]],\n",
            "\n",
            "         [[ 2.5086e-02,  2.4273e-01,  1.8241e-01],\n",
            "          [ 2.0621e-01,  1.1367e-01,  2.7420e-03],\n",
            "          [ 2.8808e-02,  1.8461e-01, -1.2600e-01]],\n",
            "\n",
            "         [[-2.4939e-01, -1.8809e-01, -1.6503e-01],\n",
            "          [-2.0854e-01,  1.8140e-02, -1.1359e-01],\n",
            "          [ 2.1374e-01,  2.2396e-01, -9.1311e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.6561e-02,  1.5631e-01, -1.9418e-01],\n",
            "          [-7.9856e-02,  8.2205e-02, -6.8288e-02],\n",
            "          [-1.1667e-03, -1.5521e-01, -1.3030e-01]],\n",
            "\n",
            "         [[ 1.8892e-01, -3.4990e-02, -1.6962e-01],\n",
            "          [ 8.4642e-02, -1.6624e-01, -6.7802e-02],\n",
            "          [ 1.6533e-01, -6.9629e-02,  1.2179e-01]],\n",
            "\n",
            "         [[-3.6111e-01, -6.6770e-02, -1.0720e-01],\n",
            "          [-4.8070e-01,  1.4294e-01,  4.2594e-01],\n",
            "          [-2.6573e-01,  2.9155e-01,  5.3840e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4769e-02, -1.1644e-01,  3.1171e-01],\n",
            "          [-2.3414e-01,  1.1348e-01, -1.0819e-01],\n",
            "          [-2.1822e-01, -7.8807e-02,  2.3001e-01]],\n",
            "\n",
            "         [[ 1.4633e-01, -1.8928e-01,  1.1668e-01],\n",
            "          [ 1.5574e-01, -7.5111e-03, -2.5659e-01],\n",
            "          [-6.5804e-02,  2.0462e-01,  3.8890e-02]],\n",
            "\n",
            "         [[ 2.8540e-01, -1.4469e-01, -2.5970e-01],\n",
            "          [ 2.9553e-01,  4.7761e-02, -5.2258e-01],\n",
            "          [ 2.0984e-01,  2.9204e-01, -3.2375e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8571e-02, -9.5253e-02, -6.2847e-02],\n",
            "          [ 4.8673e-03, -1.2284e-01,  1.3928e-01],\n",
            "          [-1.0439e-01,  1.7835e-01,  1.4416e-01]],\n",
            "\n",
            "         [[ 1.8710e-01,  7.7911e-02, -1.0473e-02],\n",
            "          [ 1.1163e-01, -2.5208e-01, -2.2144e-01],\n",
            "          [-2.8987e-01,  8.2245e-02, -8.6725e-02]],\n",
            "\n",
            "         [[ 2.1866e-01,  2.2169e-01,  1.7629e-01],\n",
            "          [-2.1533e-02,  1.5435e-01,  6.3226e-02],\n",
            "          [-2.0906e-01, -1.0889e-01,  1.1716e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5927e-01,  1.1108e-01, -1.6693e-02],\n",
            "          [-1.0502e-01,  6.5915e-02,  1.4069e-01],\n",
            "          [-8.0832e-02, -1.8373e-01, -2.2689e-01]],\n",
            "\n",
            "         [[-8.9386e-02,  1.4246e-01, -2.0715e-02],\n",
            "          [-4.3278e-03,  1.7356e-01, -8.4610e-02],\n",
            "          [ 8.2210e-03, -1.7462e-01, -1.9573e-02]],\n",
            "\n",
            "         [[-8.4880e-02, -1.5696e-01, -1.0643e-01],\n",
            "          [ 1.9216e-01,  1.7072e-01,  7.4136e-03],\n",
            "          [ 2.8831e-03,  9.8336e-02, -2.4041e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0955e-01,  1.6950e-01, -1.2465e-01],\n",
            "          [-3.5059e-03, -1.0940e-01,  1.3268e-01],\n",
            "          [-1.1944e-01,  2.7144e-02,  1.7336e-01]],\n",
            "\n",
            "         [[ 6.4321e-02, -1.9941e-02,  4.9005e-02],\n",
            "          [-6.2961e-02, -1.5233e-01,  9.1081e-02],\n",
            "          [ 1.5950e-01, -1.8289e-02, -8.7344e-02]],\n",
            "\n",
            "         [[ 1.1085e-01, -1.2032e-01, -2.0338e-03],\n",
            "          [ 5.0850e-02, -1.6158e-01,  1.7776e-01],\n",
            "          [ 1.5156e-01,  1.3005e-01,  1.8195e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1251e-01, -2.8671e-01, -2.5920e-01],\n",
            "          [-1.2509e-01, -1.9208e-01,  4.2088e-02],\n",
            "          [ 3.4451e-01,  3.4714e-01,  2.0171e-01]],\n",
            "\n",
            "         [[-1.2055e-01, -2.4566e-01,  4.9481e-03],\n",
            "          [-1.8181e-01,  1.0386e-01, -1.6411e-01],\n",
            "          [ 5.5717e-02,  2.2253e-01, -1.2769e-01]],\n",
            "\n",
            "         [[ 1.9327e-01, -3.1707e-02,  2.1018e-01],\n",
            "          [ 7.1785e-02, -8.3987e-02,  2.7993e-02],\n",
            "          [-1.1460e-01,  2.3946e-01, -1.3326e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2486e-02,  2.1981e-01,  1.3206e-01],\n",
            "          [ 1.4298e-01, -1.8137e-01, -1.0039e-01],\n",
            "          [-8.5878e-02, -1.1925e-01, -6.7497e-02]],\n",
            "\n",
            "         [[-1.9127e-01,  1.2048e-01,  1.0375e-01],\n",
            "          [ 6.5285e-02, -1.9340e-01, -4.8996e-02],\n",
            "          [ 2.6384e-01, -7.8742e-02, -9.3372e-02]],\n",
            "\n",
            "         [[-2.3230e-01, -9.2368e-02,  2.7912e-01],\n",
            "          [-2.6514e-01, -1.0523e-01,  2.4567e-01],\n",
            "          [-2.1037e-02, -2.3204e-01,  3.7883e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.1461e-02, -2.1783e-01, -3.2475e-02],\n",
            "          [-2.5571e-01, -2.5592e-01,  1.5214e-01],\n",
            "          [ 2.5938e-01,  3.1307e-01,  8.0224e-03]],\n",
            "\n",
            "         [[ 8.0401e-02, -2.4186e-01, -7.4119e-02],\n",
            "          [-9.4991e-02, -1.9686e-01,  2.7214e-01],\n",
            "          [-2.6364e-02,  2.7700e-01, -2.9236e-02]],\n",
            "\n",
            "         [[-1.4356e-01,  3.8507e-02,  2.9956e-02],\n",
            "          [-1.1810e-01, -1.7402e-01,  1.3347e-01],\n",
            "          [ 4.7254e-02, -5.3388e-02, -1.1621e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1680e-01,  4.7302e-02,  3.4212e-01],\n",
            "          [ 2.8994e-02, -2.5036e-01,  2.7890e-01],\n",
            "          [-1.7147e-01, -1.0075e-03,  2.3587e-01]],\n",
            "\n",
            "         [[-5.0737e-02, -1.0702e-01,  3.7432e-01],\n",
            "          [-1.5636e-02, -4.9779e-01,  8.5359e-02],\n",
            "          [ 1.0947e-01, -2.4879e-01,  1.5512e-01]],\n",
            "\n",
            "         [[-1.1923e-01, -2.1590e-01,  1.0254e-01],\n",
            "          [ 2.2339e-01, -3.2857e-01, -8.4111e-02],\n",
            "          [ 2.1631e-01, -1.2709e-02,  2.0438e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4505e-01,  3.3147e-01,  3.4339e-01],\n",
            "          [-2.3707e-01, -2.9320e-01, -1.5422e-01],\n",
            "          [-9.3757e-02, -7.7874e-02, -1.9374e-01]],\n",
            "\n",
            "         [[ 1.4027e-01,  7.6593e-02,  2.2188e-01],\n",
            "          [-2.5654e-01, -2.9287e-01, -2.0528e-01],\n",
            "          [ 1.0965e-01,  1.0841e-01, -1.6867e-01]],\n",
            "\n",
            "         [[ 1.7756e-01, -2.5551e-02, -7.1732e-03],\n",
            "          [-2.9995e-02, -2.3231e-01, -8.0683e-02],\n",
            "          [ 8.9179e-02,  2.9947e-01, -1.3957e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3897e-01,  2.0410e-01, -7.1323e-02],\n",
            "          [-1.8068e-02, -1.5581e-01, -2.5401e-01],\n",
            "          [ 2.7559e-01, -1.5300e-01, -1.3297e-01]],\n",
            "\n",
            "         [[-1.1738e-01, -4.3482e-02, -1.5472e-01],\n",
            "          [ 5.8557e-02, -2.0096e-01, -1.7676e-02],\n",
            "          [ 2.5907e-01,  1.4378e-01, -2.0210e-01]],\n",
            "\n",
            "         [[-1.7691e-01,  2.2613e-01, -1.8158e-01],\n",
            "          [ 1.3873e-01, -6.6176e-02, -1.3773e-01],\n",
            "          [ 2.9589e-01, -4.7510e-03,  5.4412e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.2470e-02, -6.5438e-02,  1.1492e-01],\n",
            "          [-5.5843e-02,  1.0220e-01,  1.1748e-01],\n",
            "          [-2.1532e-01, -1.6941e-01,  6.1695e-02]],\n",
            "\n",
            "         [[-9.4803e-02, -3.6098e-02,  4.9681e-02],\n",
            "          [ 1.4604e-01, -1.3326e-01, -1.2374e-01],\n",
            "          [-2.2568e-01, -1.9021e-01,  1.7529e-01]],\n",
            "\n",
            "         [[-8.2380e-02,  4.5602e-02, -1.3632e-01],\n",
            "          [ 1.4105e-02, -3.8835e-02,  2.9841e-01],\n",
            "          [-2.4062e-01, -1.3158e-02,  1.6791e-01]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToKa651tMtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c6e59de-fe9a-4bcf-a4fc-b3703a9dce5f"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0608,  0.1241,  0.2178],\n",
            "          [ 0.2544, -0.0005,  0.0279],\n",
            "          [-0.0894,  0.0466, -0.1346]],\n",
            "\n",
            "         [[ 0.0796, -0.1312,  0.2094],\n",
            "          [ 0.0579, -0.2026, -0.1578],\n",
            "          [-0.1472, -0.1016, -0.2254]],\n",
            "\n",
            "         [[-0.0475,  0.0467,  0.1432],\n",
            "          [ 0.0953, -0.0304,  0.1807],\n",
            "          [ 0.0728,  0.0986,  0.0312]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1824,  0.0462, -0.1711],\n",
            "          [-0.0844,  0.1844,  0.0568],\n",
            "          [ 0.1108,  0.2393,  0.1652]],\n",
            "\n",
            "         [[ 0.0145,  0.2230,  0.2240],\n",
            "          [-0.1623, -0.1783,  0.0041],\n",
            "          [-0.2329,  0.0858,  0.1000]],\n",
            "\n",
            "         [[-0.1069,  0.1630, -0.1680],\n",
            "          [-0.0730, -0.0682,  0.0449],\n",
            "          [-0.0917, -0.2486, -0.3023]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1042,  0.0246, -0.0877],\n",
            "          [-0.1738,  0.2121, -0.0366],\n",
            "          [-0.0684,  0.2997,  0.3040]],\n",
            "\n",
            "         [[-0.0571, -0.0355, -0.0853],\n",
            "          [-0.0079, -0.2055, -0.2648],\n",
            "          [-0.2577,  0.0791,  0.1765]],\n",
            "\n",
            "         [[ 0.2507, -0.1626, -0.1530],\n",
            "          [ 0.0669,  0.0388, -0.1894],\n",
            "          [ 0.1088,  0.0437, -0.0557]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2245,  0.1634, -0.0498],\n",
            "          [ 0.0864,  0.0371,  0.0731],\n",
            "          [-0.0451, -0.0750, -0.0121]],\n",
            "\n",
            "         [[ 0.1688, -0.0070,  0.1625],\n",
            "          [ 0.0848, -0.1439,  0.0497],\n",
            "          [ 0.1600, -0.0267, -0.0152]],\n",
            "\n",
            "         [[-0.1538, -0.0211,  0.0618],\n",
            "          [-0.0191,  0.0367, -0.1102],\n",
            "          [-0.0060, -0.0525,  0.0794]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1705, -0.1840,  0.0820],\n",
            "          [-0.0242, -0.2221, -0.0962],\n",
            "          [-0.0927, -0.0842, -0.1065]],\n",
            "\n",
            "         [[ 0.0399,  0.1378,  0.1651],\n",
            "          [-0.0184, -0.1210,  0.1311],\n",
            "          [-0.2650,  0.0877, -0.0153]],\n",
            "\n",
            "         [[ 0.1999,  0.0154,  0.1286],\n",
            "          [ 0.0145,  0.1775,  0.1330],\n",
            "          [-0.1827,  0.1316, -0.0950]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1710,  0.1335, -0.0459],\n",
            "          [-0.2650,  0.0074,  0.0466],\n",
            "          [-0.0734, -0.0164, -0.0052]],\n",
            "\n",
            "         [[ 0.1942,  0.3573,  0.0754],\n",
            "          [-0.1313,  0.0585, -0.2562],\n",
            "          [-0.1383, -0.2863, -0.1098]],\n",
            "\n",
            "         [[ 0.1160,  0.2190,  0.0255],\n",
            "          [-0.2364,  0.1794, -0.2128],\n",
            "          [ 0.0779, -0.0110,  0.0412]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1041,  0.0623, -0.1747],\n",
            "          [ 0.1135, -0.0486, -0.0289],\n",
            "          [ 0.1044, -0.0669, -0.1725]],\n",
            "\n",
            "         [[-0.1583,  0.1633, -0.1159],\n",
            "          [ 0.1884,  0.1913,  0.1839],\n",
            "          [ 0.0789, -0.0335, -0.0074]],\n",
            "\n",
            "         [[ 0.2062,  0.0769, -0.1038],\n",
            "          [-0.0566,  0.1944, -0.0359],\n",
            "          [ 0.0125,  0.0157, -0.0708]]],\n",
            "\n",
            "\n",
            "        [[[-0.0196, -0.2338, -0.2337],\n",
            "          [-0.0833, -0.1360, -0.2177],\n",
            "          [ 0.0613, -0.1664, -0.1617]],\n",
            "\n",
            "         [[ 0.0027, -0.0243,  0.0755],\n",
            "          [ 0.2088,  0.1828, -0.0350],\n",
            "          [ 0.2104,  0.0871, -0.1009]],\n",
            "\n",
            "         [[ 0.1189, -0.0548, -0.0975],\n",
            "          [ 0.0729,  0.0176,  0.1111],\n",
            "          [ 0.1920, -0.0149,  0.2453]]],\n",
            "\n",
            "\n",
            "        [[[-0.1719,  0.1921, -0.1354],\n",
            "          [ 0.0418, -0.0775, -0.1700],\n",
            "          [-0.1466, -0.1617,  0.1571]],\n",
            "\n",
            "         [[ 0.0464, -0.0389,  0.2091],\n",
            "          [-0.0291, -0.1031,  0.0630],\n",
            "          [-0.0019, -0.1659,  0.1766]],\n",
            "\n",
            "         [[ 0.1098, -0.1414,  0.0147],\n",
            "          [ 0.0901, -0.2584, -0.2079],\n",
            "          [ 0.0460,  0.1185,  0.0887]]],\n",
            "\n",
            "\n",
            "        [[[-0.0505,  0.0351,  0.1891],\n",
            "          [-0.1442,  0.1547, -0.0163],\n",
            "          [ 0.1675,  0.1456, -0.0672]],\n",
            "\n",
            "         [[-0.0789, -0.1736, -0.0900],\n",
            "          [-0.2739, -0.1438,  0.0011],\n",
            "          [ 0.2234, -0.1936, -0.0948]],\n",
            "\n",
            "         [[-0.0046,  0.0755,  0.2782],\n",
            "          [-0.1679,  0.1687,  0.2034],\n",
            "          [-0.1167, -0.2165, -0.2090]]],\n",
            "\n",
            "\n",
            "        [[[-0.0322,  0.1147, -0.0623],\n",
            "          [-0.0812, -0.1506,  0.1640],\n",
            "          [ 0.0179,  0.0998, -0.0381]],\n",
            "\n",
            "         [[-0.2147,  0.1664,  0.2577],\n",
            "          [ 0.0496,  0.2654,  0.0572],\n",
            "          [-0.0761,  0.1344, -0.0103]],\n",
            "\n",
            "         [[-0.1031, -0.0554, -0.1651],\n",
            "          [-0.2419,  0.0317,  0.2080],\n",
            "          [ 0.0787, -0.1417,  0.0169]]],\n",
            "\n",
            "\n",
            "        [[[-0.0052, -0.1901,  0.1523],\n",
            "          [-0.1433, -0.1817,  0.2809],\n",
            "          [ 0.0095, -0.0690, -0.0541]],\n",
            "\n",
            "         [[ 0.0158, -0.2594,  0.1828],\n",
            "          [ 0.0808, -0.2699,  0.2440],\n",
            "          [ 0.0914, -0.1074,  0.1161]],\n",
            "\n",
            "         [[ 0.2717, -0.2614, -0.1678],\n",
            "          [ 0.2060, -0.2710,  0.1707],\n",
            "          [ 0.2083, -0.2222, -0.0477]]],\n",
            "\n",
            "\n",
            "        [[[-0.1353,  0.2059, -0.2203],\n",
            "          [-0.0167, -0.0048,  0.0253],\n",
            "          [ 0.0796, -0.2397, -0.1547]],\n",
            "\n",
            "         [[ 0.2441,  0.2376,  0.0421],\n",
            "          [-0.2440,  0.2526,  0.2682],\n",
            "          [-0.0543, -0.1099,  0.1503]],\n",
            "\n",
            "         [[-0.1498,  0.2088, -0.1936],\n",
            "          [-0.1359, -0.0345, -0.1978],\n",
            "          [ 0.1456,  0.0174, -0.1259]]],\n",
            "\n",
            "\n",
            "        [[[-0.0717, -0.0583, -0.0444],\n",
            "          [-0.0768,  0.0532, -0.0271],\n",
            "          [-0.0136, -0.0615,  0.0298]],\n",
            "\n",
            "         [[-0.1537, -0.1562, -0.1972],\n",
            "          [-0.1145, -0.1506,  0.0827],\n",
            "          [-0.0975,  0.0555, -0.0286]],\n",
            "\n",
            "         [[ 0.0774,  0.0205, -0.1503],\n",
            "          [-0.0580,  0.1814,  0.1385],\n",
            "          [-0.0907,  0.1018,  0.0195]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0305,  0.0324, -0.1596],\n",
            "          [-0.1281, -0.0857,  0.0062],\n",
            "          [-0.0694, -0.1578, -0.2166]],\n",
            "\n",
            "         [[ 0.0891,  0.0799, -0.0838],\n",
            "          [ 0.0467, -0.1275,  0.0893],\n",
            "          [-0.1579,  0.0204,  0.0847]],\n",
            "\n",
            "         [[ 0.0515, -0.1701, -0.0348],\n",
            "          [ 0.2365,  0.1364,  0.0380],\n",
            "          [-0.0223, -0.0782, -0.1826]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2683, -0.1090, -0.2405],\n",
            "          [ 0.2684,  0.0637, -0.1871],\n",
            "          [-0.0505, -0.1982,  0.0877]],\n",
            "\n",
            "         [[ 0.2379,  0.1652, -0.0219],\n",
            "          [ 0.2034,  0.0951, -0.0778],\n",
            "          [ 0.2104, -0.2417, -0.1980]],\n",
            "\n",
            "         [[-0.0517, -0.2049, -0.1198],\n",
            "          [-0.2026, -0.0182,  0.0685],\n",
            "          [ 0.0487, -0.1203,  0.0997]]],\n",
            "\n",
            "\n",
            "        [[[-0.1073, -0.2846,  0.0159],\n",
            "          [-0.0208,  0.1719,  0.2490],\n",
            "          [ 0.1372, -0.0749,  0.1558]],\n",
            "\n",
            "         [[ 0.1114, -0.1837,  0.0492],\n",
            "          [-0.0953,  0.2057,  0.2774],\n",
            "          [-0.1801,  0.0414,  0.2130]],\n",
            "\n",
            "         [[-0.0071, -0.2138,  0.0876],\n",
            "          [ 0.1594, -0.1319,  0.1354],\n",
            "          [-0.1542, -0.1837, -0.1958]]],\n",
            "\n",
            "\n",
            "        [[[-0.2507,  0.2465,  0.1336],\n",
            "          [-0.2511, -0.2257,  0.1697],\n",
            "          [-0.2659,  0.0153,  0.0964]],\n",
            "\n",
            "         [[-0.0494,  0.1345,  0.0287],\n",
            "          [-0.1238, -0.2326, -0.1084],\n",
            "          [ 0.1161, -0.0626,  0.0388]],\n",
            "\n",
            "         [[ 0.2098,  0.1728, -0.0716],\n",
            "          [ 0.2067,  0.0447, -0.1428],\n",
            "          [-0.0518,  0.2152,  0.1411]]],\n",
            "\n",
            "\n",
            "        [[[-0.0591,  0.1536,  0.1970],\n",
            "          [-0.0547,  0.2851,  0.1468],\n",
            "          [-0.3019, -0.1033, -0.0256]],\n",
            "\n",
            "         [[-0.1153, -0.1533, -0.1478],\n",
            "          [-0.2222,  0.2018,  0.1239],\n",
            "          [ 0.0163,  0.0653, -0.0153]],\n",
            "\n",
            "         [[-0.2292,  0.0267, -0.1071],\n",
            "          [-0.1538,  0.2295,  0.2164],\n",
            "          [-0.0380,  0.0301, -0.0328]]],\n",
            "\n",
            "\n",
            "        [[[-0.0310,  0.2093,  0.2197],\n",
            "          [ 0.1624, -0.0846,  0.0883],\n",
            "          [-0.1125, -0.1170, -0.0903]],\n",
            "\n",
            "         [[-0.1474,  0.0615,  0.0443],\n",
            "          [ 0.0169, -0.0355,  0.1129],\n",
            "          [-0.0785, -0.0378, -0.1265]],\n",
            "\n",
            "         [[-0.2544, -0.3127, -0.1973],\n",
            "          [ 0.0118, -0.0955, -0.0718],\n",
            "          [ 0.1840,  0.1362,  0.1538]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1636,  0.1009,  0.3619],\n",
            "          [-0.0922, -0.0476,  0.3195],\n",
            "          [-0.2725, -0.4048,  0.0304]],\n",
            "\n",
            "         [[ 0.0876, -0.2008, -0.1687],\n",
            "          [-0.1244, -0.0241, -0.0545],\n",
            "          [ 0.2394, -0.0623,  0.1720]],\n",
            "\n",
            "         [[ 0.1935, -0.1601, -0.2321],\n",
            "          [ 0.2990, -0.2066,  0.0020],\n",
            "          [ 0.3324, -0.2075, -0.1657]]],\n",
            "\n",
            "\n",
            "        [[[-0.1670, -0.0926,  0.2069],\n",
            "          [-0.2652,  0.0663,  0.2808],\n",
            "          [ 0.1048,  0.0325,  0.2498]],\n",
            "\n",
            "         [[-0.1861,  0.0379, -0.0614],\n",
            "          [-0.1744, -0.0310,  0.0156],\n",
            "          [-0.1586, -0.0065, -0.1215]],\n",
            "\n",
            "         [[-0.0103,  0.2048, -0.0667],\n",
            "          [-0.1688,  0.2196,  0.0908],\n",
            "          [-0.2128,  0.0695,  0.0337]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2470, -0.0930, -0.0416],\n",
            "          [ 0.0406, -0.1786, -0.1875],\n",
            "          [ 0.1430, -0.0936, -0.2440]],\n",
            "\n",
            "         [[-0.2171,  0.1538,  0.1454],\n",
            "          [-0.1885, -0.0967,  0.0380],\n",
            "          [-0.0272,  0.1860, -0.0212]],\n",
            "\n",
            "         [[-0.1413, -0.0186,  0.2023],\n",
            "          [-0.2751,  0.2226,  0.1687],\n",
            "          [-0.0370,  0.2572, -0.1846]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0770, -0.2222, -0.3468],\n",
            "          [ 0.0882, -0.1602,  0.2281],\n",
            "          [ 0.0331, -0.0305,  0.2037]],\n",
            "\n",
            "         [[ 0.2845, -0.1757, -0.1569],\n",
            "          [ 0.2931, -0.1873,  0.1620],\n",
            "          [-0.1733, -0.0218, -0.0771]],\n",
            "\n",
            "         [[-0.1521,  0.0833,  0.2119],\n",
            "          [-0.0280, -0.2305,  0.3177],\n",
            "          [-0.0951, -0.0618,  0.0370]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1256,  0.0898, -0.0073],\n",
            "          [ 0.1526, -0.0403, -0.2205],\n",
            "          [ 0.0525,  0.2276, -0.2145]],\n",
            "\n",
            "         [[ 0.1245, -0.1533,  0.1920],\n",
            "          [-0.0486, -0.2135, -0.2724],\n",
            "          [ 0.1628,  0.1795,  0.0924]],\n",
            "\n",
            "         [[-0.2771, -0.0323, -0.1947],\n",
            "          [-0.1163,  0.0026, -0.2643],\n",
            "          [-0.1031,  0.3302,  0.2251]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1227, -0.0408, -0.0602],\n",
            "          [-0.0917,  0.0242, -0.0464],\n",
            "          [-0.1131, -0.0251, -0.0100]],\n",
            "\n",
            "         [[-0.1928,  0.1737, -0.0350],\n",
            "          [ 0.1123, -0.0293,  0.0401],\n",
            "          [ 0.1966, -0.0956,  0.1381]],\n",
            "\n",
            "         [[ 0.1350,  0.1693,  0.0924],\n",
            "          [ 0.1292, -0.1318, -0.0604],\n",
            "          [ 0.1045,  0.1792, -0.1266]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0448,  0.1001, -0.2423],\n",
            "          [-0.0297, -0.2443, -0.1006],\n",
            "          [ 0.2517,  0.1323,  0.1131]],\n",
            "\n",
            "         [[ 0.2788,  0.1817,  0.0688],\n",
            "          [-0.1170, -0.3358, -0.1695],\n",
            "          [ 0.1480,  0.0027, -0.0677]],\n",
            "\n",
            "         [[ 0.3231,  0.0605,  0.2632],\n",
            "          [-0.2149, -0.1323, -0.0033],\n",
            "          [-0.1661, -0.1731,  0.1263]]],\n",
            "\n",
            "\n",
            "        [[[-0.0739, -0.0457, -0.1419],\n",
            "          [-0.0282,  0.1075,  0.0440],\n",
            "          [ 0.0315, -0.0317,  0.2639]],\n",
            "\n",
            "         [[ 0.0185, -0.1037, -0.1164],\n",
            "          [ 0.1975,  0.2283,  0.1605],\n",
            "          [-0.2208, -0.0524,  0.0512]],\n",
            "\n",
            "         [[ 0.0067, -0.0433,  0.0777],\n",
            "          [ 0.0794,  0.0116,  0.0658],\n",
            "          [-0.1490, -0.0331,  0.0833]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1343, -0.0559, -0.1224],\n",
            "          [-0.1929, -0.0169,  0.0942],\n",
            "          [-0.1090,  0.0416, -0.0816]],\n",
            "\n",
            "         [[ 0.1141, -0.0327, -0.1094],\n",
            "          [-0.1422, -0.2190, -0.1395],\n",
            "          [-0.0016,  0.2154, -0.0045]],\n",
            "\n",
            "         [[ 0.1331, -0.0194, -0.1195],\n",
            "          [-0.1323,  0.0384,  0.0421],\n",
            "          [ 0.2250, -0.1021,  0.1496]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0546, -0.1169,  0.3267],\n",
            "          [ 0.1780, -0.0358,  0.0679],\n",
            "          [-0.1916,  0.1268, -0.1874]],\n",
            "\n",
            "         [[-0.2380, -0.3122, -0.1156],\n",
            "          [-0.1749,  0.0665, -0.1211],\n",
            "          [ 0.1792,  0.0674, -0.2908]],\n",
            "\n",
            "         [[ 0.1706, -0.1736, -0.0665],\n",
            "          [ 0.0927,  0.2855, -0.2061],\n",
            "          [ 0.1607,  0.3342,  0.0326]]],\n",
            "\n",
            "\n",
            "        [[[-0.2705, -0.2225, -0.0179],\n",
            "          [ 0.0909,  0.0727, -0.0323],\n",
            "          [ 0.2541, -0.0255, -0.1221]],\n",
            "\n",
            "         [[-0.2399, -0.0522,  0.1283],\n",
            "          [ 0.1439, -0.0951, -0.0130],\n",
            "          [ 0.2143,  0.0163,  0.0689]],\n",
            "\n",
            "         [[-0.3643,  0.1398,  0.1157],\n",
            "          [ 0.1880,  0.1441,  0.0912],\n",
            "          [ 0.0387, -0.1338,  0.0387]]],\n",
            "\n",
            "\n",
            "        [[[-0.0846,  0.1564,  0.1343],\n",
            "          [ 0.1386,  0.2196,  0.1104],\n",
            "          [ 0.0690, -0.0864, -0.0589]],\n",
            "\n",
            "         [[ 0.0986, -0.1091,  0.0954],\n",
            "          [ 0.1544,  0.1834, -0.1361],\n",
            "          [-0.2339, -0.2419,  0.0269]],\n",
            "\n",
            "         [[-0.1356, -0.1786,  0.0168],\n",
            "          [-0.1740,  0.1396,  0.1196],\n",
            "          [ 0.1241, -0.0344, -0.0683]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"14_focus_pretrained_classify_pretrained_train_both\""
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0zuujPPzLHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(focus_net.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn/\"+name+\"_focus_net.pt\")"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn/\"+name+\"_classify.pt\")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "f9323468-8ca1-4d7d-c66f-cc6bdbd4eff6"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>29976</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29998</td>\n",
              "      <td>2</td>\n",
              "      <td>29550</td>\n",
              "      <td>2</td>\n",
              "      <td>444</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0       0         30000  ...                     19                       3\n",
              "1       1         29998  ...                    444                       4\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "11b3f086-fc0c-4df3-e0f4-840c89ca0116"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAEWCAYAAABoup70AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZhVdbn/8fdnGGF8QB5kQuRpQB4HFJUJkDRKTclSI8zoaGIqVub5lZnm6Xd+R7KHkx2L66rUDimCHk3IVDhKGgdN7ZjokIJCCISQEMgoTyqIDHP//thragczwx6cPXtm1ud1Xeuave/1XWvd3xm47r3W+u71VURgZmZm6VFU6ATMzMysebn4m5mZpYyLv5mZWcq4+JuZmaWMi7+ZmVnKuPibmZmljIu/WQFIWibpI03d1swsFy7+1qZJukTSS5J2Stok6TZJnQ9iP30kvZ21hKR3st6f2pj9RcSwiPhdU7dtDpJmSvpuofMws4Pn4m9tlqRrgJuAa4FOwBigL7BAUvvG7Csi/hIRR9QuSXhEVuzprOMWN1EXzMzywsXf2iRJRwLfBv45Ih6NiD0RsRa4ACgDLkraTZU0R9Jdkt5KLrFXNPJYl0j6X0nTJL0JTJV0rKTHJb0p6Q1J92RfcZC0VtIZueTQyLYnSXohWfcrSbPrO0uXNEDSk5K2JznOzlo3RNICSVskvSLpgiR+BXAhcF1yxeO/G/O7MrOWwcXf2qqxQAnwQHYwIt4G5gMfywqfC9wHdAbmAT87iOONBtYA3YHvAQL+HTgGGAr0BqY2sH1jcqizbXI140FgJtAV+CUwoYH9fAf4LdAF6AX8NNnP4cAC4F7gA8Ak4FZJ5RExHbgH+GFyxeOcBvZvZi2Ui7+1Vd2ANyKiuo51G5P1tX4fEfMjYi9wNzDiII7314j4aURUR8SuiFgdEQsiYndEVAE/BsY1sH1jcqiv7RigGPhJcqXjAeC5Bvazh8xtkGMi4t2I+H0S/ySwNiLuTPrzAvBr4DMH+B2YWSvh4m9t1RtAt3ruv/dI1tfalPV6J1ByEPftX8t+I6m7pPskbZC0A/gv/vEDx74ak0N9bY8BNsQ/ztb1D3nt4zoyVyieS24fXJrE+wKjJW2rXchc6j+6gX2ZWSvi4m9t1R+A3cCns4OSjgA+Dixs4uPtOz3m95PYcRFxJJkxBmriY+5rI9BTUvZxetfXOCI2RcSUiDgG+CKZS/sDyHxgeDIiOmctR0TEl2s3zVsPzKxZuPhbmxQR28kM+PuppPGSDpFUBswB1pO5XJ5PHYG3ge2SepL5xkG+/QHYC1wlqVjSecCo+hpL+oykXsnbrWSKeg3wMDBI0ueT39shkj4oaWjS9nWgf/66YWb55uJvbVZE/BD4FnAzsANYROas9vSI2J3nw38bOAnYDjzCPgMP8yEi3iNzpeMyYBuZqw0Pk7kCUpcPAoskvU1m4OBXI2JNRLwFnElmoN9fydxmuAnokGx3B1Ce3BJ4KF/9MbP80T/eHjSztkTSIuDnEXFnoXMxs5bDZ/5mbYikcZKOTi77TwaOBx4tdF5m1rL4SWRmbctgMuMaDifz3IHzI2JjYVMys5bGl/3NzMxSxpf9zczMUiZ1l/27desWZWVlhU7DzKxVWbx48RsRUVroPKxppK74l5WVUVlZWeg0zMxaFUnrCp2DNR1f9jczM0sZF38zM7OUcfE3MzNLGRd/MzOzlHHxNzMzS5m8FX9JJZKek7QkmSv820m8n6RFklZLmi2pfRLvkLxfnawvy9rXvyTxVySdlRUfn8RWS7o+X30xMzNrS/J55r8bOC0iRgAnAOMljSEzO9i0iBhAZhrRy5L2lwFbk/i0pB2SysnMLjYMGE9mzvF2ktoBt5CZm70c+FzS1szMzBqQt+/5R+a5wW8nbw9JlgBOA/4pic8CpgK3AeclrwHuB34mSUn8vmQK1lclrebvc5Svjog1AJLuS9ouz0d/Zv7vq2x557187LrtkgqdQavj31jj+J9Y41z10QEUt/PdXsvzQ36Ss/PFwAAyZ+l/BrZFRHXSZD3QM3ndk8xc60REtaTtwFFJ/Nms3WZv89o+8dH15HEFcAVAnz59Dqov9z73F1ZtfvvADQ0ATxlh1vJ8adyxFLcrdBbWEuS1+EfEXuAESZ2BB4Eh+TxeA3lMB6YDVFRUHFRZ+u3V45o0JzN7fzwpmdnBa5bH+0bENklPACcDnSUVJ2f/vYANSbMNQG9gvaRioBPwZla8VvY29cXNrI2Tr/mbHbR8jvYvTc74kXQo8DHgT8ATwPlJs8nA3OT1vOQ9yfrHk3ED84BJybcB+gEDgeeA54GBybcH2pMZFDgvX/0xMzNrK/J55t8DmJXc9y8C5kTEw5KWA/dJ+i7wAnBH0v4O4O5kQN8WMsWciFgmaQ6ZgXzVwFeS2wlIugp4DGgHzIiIZXnsj5mZWZugtN03q6ioCM/qZ2bWOJIWR0RFofOwpuHvfJiZmaWMi7+ZmVnKuPibmZmljIu/mZlZyrj4m5mZpYyLv5mZWcq4+JuZmaWMi7+ZmVnKuPibmZmljIu/mZlZyrj4m5mZpYyLv5mZWcq4+JuZmaWMi7+ZmVnKuPibmZmljIu/mZlZyrj4m5mZpYyLv5mZWcq4+JuZmaWMi7+ZmVnKuPibmZmljIu/mZlZyrj4m5mZpYyLv5mZWcrkrfhL6i3pCUnLJS2T9NUkPlXSBkkvJsvZWdv8i6TVkl6RdFZWfHwSWy3p+qx4P0mLkvhsSe3z1R8zM7O2Ip9n/tXANRFRDowBviKpPFk3LSJOSJb5AMm6ScAwYDxwq6R2ktoBtwAfB8qBz2Xt56ZkXwOArcBleeyPmZlZm5C34h8RGyPij8nrt4A/AT0b2OQ84L6I2B0RrwKrgVHJsjoi1kTEe8B9wHmSBJwG3J9sPwv4VH56Y2Zm1nY0yz1/SWXAicCiJHSVpKWSZkjqksR6Aq9lbbY+idUXPwrYFhHV+8TrOv4VkiolVVZVVTVBj8zMzFqvvBd/SUcAvwa+FhE7gNuAY4ETgI3Aj/KdQ0RMj4iKiKgoLS3N9+HMzMxatOJ87lzSIWQK/z0R8QBARLyetf4XwMPJ2w1A76zNeyUx6om/CXSWVJyc/We3NzMzs3rkc7S/gDuAP0XEj7PiPbKaTQBeTl7PAyZJ6iCpHzAQeA54HhiYjOxvT2ZQ4LyICOAJ4Pxk+8nA3Hz1x8zMrK3I55n/h4DPAy9JejGJfYvMaP0TgADWAl8EiIhlkuYAy8l8U+ArEbEXQNJVwGNAO2BGRCxL9vdN4D5J3wVeIPNhw8zMzBqgzAl0elRUVERlZWWh0zAza1UkLY6IikLnYU3DT/gzMzNLGRd/MzOzlHHxNzMzSxkXfzMzs5Rx8TczM0sZF38zM7OUcfE3MzNLGRd/MzOzlHHxNzMzSxkXfzMzs5Rx8TczM0sZF38zM7OUcfE3MzNLGRd/MzOzlHHxNzMzSxkXfzMzs5Rx8TczM0sZF38zM7OUcfE3MzNLGRd/MzOzlHHxNzMzSxkXfzMzs5Rx8TczM0sZF38zM7OUyVvxl9Rb0hOSlktaJumrSbyrpAWSViU/uyRxSfqJpNWSlko6KWtfk5P2qyRNzoqPlPRSss1PJClf/TEzM2sr8nnmXw1cExHlwBjgK5LKgeuBhRExEFiYvAf4ODAwWa4AboPMhwXgBmA0MAq4ofYDQ9JmStZ24/PYHzMzszYhb8U/IjZGxB+T128BfwJ6AucBs5Jms4BPJa/PA+6KjGeBzpJ6AGcBCyJiS0RsBRYA45N1R0bEsxERwF1Z+zIzM7N6NMs9f0llwInAIqB7RGxMVm0CuievewKvZW22Pok1FF9fR7yu418hqVJSZVVV1fvqi5mZWWuX9+Iv6Qjg18DXImJH9rrkjD3ynUNETI+IioioKC0tzffhzMzMWrS8Fn9Jh5Ap/PdExANJ+PXkkj3Jz81JfAPQO2vzXkmsoXivOuJmZmbWgAMWf0mlkm6WNF/S47VLDtsJuAP4U0T8OGvVPKB2xP5kYG5W/OJk1P8YYHtye+Ax4ExJXZKBfmcCjyXrdkgakxzr4qx9mZmZWT2Kc2hzDzAb+ATwJTIFO5cb5x8CPg+8JOnFJPYt4AfAHEmXAeuAC5J184GzgdXATuALABGxRdJ3gOeTdjdGxJbk9ZXATOBQ4DfJYmZmZg1Q5rZ7Aw2kxRExUtLSiDg+iT0fER9slgybWEVFRVRWVhY6DTOzViWpBRWFzsOaRi5n/nuSnxslfQL4K9A1fymZmZlZPuVS/L8rqRNwDfBT4Ejga3nNyszMzPIml+K/NSK2A9uBjwJI+lBeszIzM7O8yeWrfj/NMWZmZmatQL1n/pJOBsYCpZK+nrXqSKBdvhMzMzOz/Gjosn974IikTces+A7g/HwmZWZmZvlTb/GPiCeBJyXNjIh1zZiTmZmZ5VEuA/52SvoPYBhQUhuMiNPylpWZmZnlTS4D/u4BVgD9gG8Da/n70/bMzMyslcml+B8VEXcAeyLiyYi4FPBZv5mZWSvlJ/yZmZmlzME+4e/qvGZlZmYt3uLFiz9QXFx8OzCcPE8Rb41SA7xcXV19+ciRIzfX1eCAxT8iHk5e/u0Jf2ZmZsXFxbcfffTRQ0tLS7cWFRU1PEucNZuamhpVVVWVb9q06Xbg3LraNPSQn58C9f4xI+L/vP8UzcysFRvuwt/yFBUVRWlp6fZNmzYNr7dNA9tXAovJfL3vJGBVspxA5gFAZmaWbkUu/C1T8nept8Y39JCfWQCSvgycEhHVyfufA083cZ5mZmapV1NTw6WXXtr78ccf71RSUlIzY8aMtaeccsrOfduNGjVq8ObNmw8pKSmpAVi4cOHKnj17Vud6nFwG/HUhM8hvS/L+iCRmZmbW4lVXV1NcnEu5y4+qqqp2paWle3Np+6tf/arTmjVrStauXfvyE088cfiVV17ZZ+nSpSvqanvXXXet+fCHP7zfB4Nc5DI68wfAC5JmSpoF/BH4/sEczMzMrCmdccYZxw4bNmzogAEDht18883dauOHHXbYiVOmTOk1ePDg8oULFx4xbdq0bmVlZcOPO+64oZMmTep78cUX9wGYOHFi2YUXXthnxIgRQ3r16nXcww8/3PEzn/lMWf/+/YdNnDixrHZ/F154YZ/hw4cPHTBgwLCrr776GIA333yzXVlZ2fAlS5Z0ADjnnHP6/ehHP+q2T4pcfvnlfcaMGTPotttu67pz50411J+5c+d2vvDCC98sKiri9NNPf2fHjh3F69atO6SJfl1/k8to/zsl/QYYnYS+GRGbmjoRMzNrva69f0nvlZveOqwp9zno6I47/+P8Ea811Oaee+5Z2717971vv/22TjzxxPKLLrpo69FHH713165dRaNHj37nF7/4xfq1a9cecumll/b74x//uLxz5841Y8eOHTRs2LBdtfvYvn178QsvvLDi3nvv7Txp0qQBjz/++IqRI0fuOv7444c+88wzh44dO3bXj3/84w3du3ffW11dzdixYwcvWrTo0NGjR++aNm3aXyZPntzvyiuvfH3btm3F11xzzRv75jh37txXn3766cOmT5/e7fvf//4xp5122vYvfelLb5x88sm79m27cePGQ8rKyt6rfd+jR4/31q1bd0jfvn337Nv28ssvLysqKuKcc87ZetNNN20sKsr925Y5tYyITRExN1lc+M3MrEW46aabug8ePLh85MiRQzdt2nTIsmXLSgDatWvHJZdcshXg6aefPnz06NFvde/efW+HDh1iwoQJW7P38YlPfGJbUVERJ5100s6jjjpqz6hRo3a1a9eOQYMG7frzn//cAWDWrFldy8vLh5aXl5evWrWqZMmSJSUAEyZM2DF06NBd1113Xd+ZM2eurS/PU089defdd9/9l1deeWXZgAEDdo8bN27o1KlTux9sv2fPnr1m5cqVy//whz+seOaZZ4649dZbj2rM9oW7CWJmZm3Ggc7Q8+Hhhx/u+OSTT3asrKxc0bFjx5pRo0YN3rVrVxFA+/bta3K9z19SUhKQ+cDQvn37v317oaioiOrqaq1YsaL9z372s+6LFy/+U2lp6d6JEyeWvfvuu0UAe/fuZeXKlSUlJSU1b775ZvGxxx673xk6wJ49e5gzZ06nO++8s9u6detKrr322r9OmTLlzX3b9ejRY8/atWv/9o26jRs3tq/rrL9fv357ALp06VLz2c9+dstzzz13OLDf/urjJzKZmVmrtG3btnadOnXa27Fjx5oXXnihZMmSJYfX1e6UU055Z9GiRR2rqqra7dmzh7lz5zZq0PrWrVvbHXrooTVdu3bd+9prrxX/7ne/61S77sYbb+w+aNCgd2fOnLnm0ksvLdu9e/d+9/SnTp3avV+/fsf9+te/7vKNb3zj9VWrVi373ve+t6mu0fnnnnvutnvuueeompoaFi5ceHjHjh337lv89+zZw8aNG4sBdu/erfnz53caPnz4frcQGnLAj0WS6nqO/1sRUeenGzMzs+YwceLE7dOnTy/t37//sP79+787YsSId+pq169fvz1XX331xoqKiqGdOnWqHjBgwLudOnXKafQ9wMknn7xr+PDhO4899tjhPXr0eG/kyJFvAyxZsqTD3Xff3W3x4sV/6tKlS83999//1vXXX99j2rRpf83e/oQTTti5dOnSZV27dq050LEuuOCC7Y888kinvn37Dj/00ENrbr/99rW164YMGVK+YsWK5bt27So644wzBu7Zs0c1NTU69dRTd3z961+vyrU/AIpo+PkMktYCvYGtgIDOwCbgdWBKRCxuzAELraKiIiorKwudhplZqyJpcURUZMeWLFmydsSIEfsNcGuJtm/fXtSpU6eaPXv2cNZZZw245JJL3rj44ou3FTqvfFqyZEm3ESNGlNW1LpfL/guAsyOiW0QcBXwceBi4Eri1vo0kzZC0WdLLWbGpkjZIejFZzs5a9y+SVkt6RdJZWfHxSWy1pOuz4v0kLUrisyX5qYNmZlana6+99pghQ4aUDxo0aFifPn12X3TRRW268B9ILqMhxkTElNo3EfFbSTdHxBcldWhgu5nAz4C79olPi4ibswOSyoFJwDDgGOB/JA1KVt8CfAxYDzwvaV5ELAduSvZ1X/LUwcuA23Loj5mZpcz06dPXFzqHliSXM/+Nkr4pqW+yXAe8LqkdmWkD6xQRT/H3pwIeyHnAfRGxOyJeBVYDo5JldUSsiYj3gPuA8yQJOA24P9l+FvCpHI9lZmaWarkU/38CegEPJUufJNYOuOAgjnmVpKXJbYHaEZc9geyviaxPYvXFjwK21c43kBWvk6QrJFVKqqyqatSYCDMzszbngMU/It6IiH+OiBOT5aqIqIqI9yJidSOPdxtwLJmZATcCPzqInBstIqZHREVEVJSWljbHIc3MzFqsXL7qNwj4BlCW3T4iTmvswSLi9az9/oLMwEGADWS+UVCrVxKjnvibQGdJxcnZf3Z7MzMza0Aul/1/BbwA/CtwbdbSaJJ6ZL2dANR+E2AeMElSB0n9gIHAc8DzwMBkZH97MoMC50Xm+4lPAOcn208G5h5MTmZmZi1FTU0Nl1xySe8+ffoMHzRoUPnvf//7OudLGDVq1OCysrLhQ4YMKR8yZEj5hg0bGvXE3lwaV0dEo0fRS/ol8BGgm6T1wA3ARySdAASwFvgiQEQskzQHWA5UA1+JiL3Jfq4CHiMzxmBGRCxLDvFN4D5J3yXz4eSOxuZoZmZtX6Gn9K1PXVP9tqQpff9b0pWSekjqWrscaKOI+FxE9IiIQyKiV0TcERGfj4jjIuL4iDg3IjZmtf9eRBwbEYMj4jdZ8fkRMShZ972s+JqIGBURAyLiMxGxu9G9NzOzVq01TOmbbcOGDcX/9m//1n3gwIHD7rzzzv1qaYuZ0pfMJXX4x0v9AfRv6mTMzKyVeugrvdm8vEmn9OUD5Tv51C2tfkrfvXv38uCDDx55++23d1u1atWhEydO3PLoo4+urGsSoOaa0veAxT8i+uW8NzMzs2Z00003dX/kkUc6A9RO6Xv00Ue/U9+UvgATJkzYunLlypLafdQ1pS/wtyl9x44du2vWrFldZ86c2a26ulpVVVWHLFmypGT06NG7JkyYsGPOnDldrrvuur6LFy9eVleOH/vYxwYsW7bssFtuuWXtpz/96R2NKdL1mT179pp+/frt2bp1a9EnP/nJY2+99dajrrrqqpxn9au3+Es6LSIel/TputZHxAMHk7CZmbVBBzhDz4fWMqXvD3/4w/W33npr6TXXXNPnoYce2jFlypQ3xo0bV+e9+pYwpe+45Oc5dSyfzPUAZmZm+dBapvStqKh4d8aMGa+98sory8aNG/fWt771rZ6DBg0qf+CBB47ct23Bp/SNiBuSn19ozA7NzMyaQ2uZ0rdWSUlJTJkyZeuUKVO2rly5sv3rr7++Xw1uSVP6dgAmsv9Dfm5szIFaCk/pa2bWeJ7St/VpaErfXG6IzAW2A4sBf53OzMxanWuvvfaYp5566sjdu3dr3LhxOzyl74H1iojxec/EzMwsTzyl7z/K5fsGz0g6Lu+ZmJmZWbPI5cz/FOASSa+SuewvICLi+LxmZmZmLV1NTU2NioqKGh48Zs2upqZGQE1963Mp/h9vunTMzKwNebmqqqq8tLR0uz8AtBw1NTWqqqrqxN8nz9tPQw/5OTIidgBv5SM5MzNr3aqrqy/ftGnT7Zs2bRpObreRrXnUAC9XV1dfXl+Dhs787yXzMJ/FZJ7ln/3gAj/b38ws5UaOHLkZOLfQeVjjNfSQn08mP/1sfzMzszYkpwcfS+oCDAT+NhFCRDyVr6TMzMwsfw5Y/CVdDnwV6AW8CIwB/gCclt/UzMzMLB9yGaDxVeCDwLqI+ChwIpDqJyOZmZm1ZrkU/3cj4l3IPOc/IlYAg/OblpmZmeVLLvf810vqDDwELJC0FViX37TMzMwsXw5Y/CNiQvJyqqQngE7Ao3nNyszMzPKmweIvqR2wLCKGAETEk82SlZmZmeVNg/f8I2Iv8IqkPs2Uj5mZmeVZLvf8uwDLJD0HvFMbjAg/1cnMzKwVyqX4/7+8Z2FmZmbNJpev+p0dEU9mL8DZB9pI0gxJmyW9nBXrKmmBpFXJzy5JXJJ+Imm1pKWSTsraZnLSfpWkyVnxkZJeSrb5iSRhZmZmB5RL8f9YHbFcpvmdCYzfJ3Y9sDAiBgILk/e1+xuYLFcAt0HmwwJwAzAaGAXcUPuBIWkzJWu7fY9lZmZmdai3+Ev6sqSXgMHJ2Xjt8iqw9EA7Tp79v2Wf8HnArOT1LOBTWfG7IuNZoLOkHsBZwIKI2BIRW4EFwPhk3ZER8WxEBHBX1r7MzMysAQea0vc3wL/z9zN0gLciYt+inqvuEbExeb0J6J687gm8ltVufRJrKL6+jnidJF1B5ooCffr4iwtmZpZuDU3pux3YDnwuHweOiJAU+dh3HceaDkwHqKioaJZjmpmZtVS53PNvSq8nl+xJfm5O4huA3lnteiWxhuK96oibmZnZATR38Z8H1I7YnwzMzYpfnIz6HwNsT24PPAacKalLMtDvTOCxZN0OSWOSUf4XZ+3LzMzMGpDL9/wPiqRfAh8BuklaT2bU/g+AOZIuIzM50AVJ8/lkvj64GtgJfAEgIrZI+g7wfNLuxqzxBleS+UbBoWTGJvwmX30xMzNrS5QZLJ8eFRUVUVlZWeg0zMxaFUmLI6Ki0HlY02juy/5mZmZWYC7+ZmZmKePib2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMi7+ZmZmKePib2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMi7+ZmZmKePib2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMi7+ZmZmKePib2ZmljIu/mZmZinj4m9mZpYyLv5mZmYpU5DiL2mtpJckvSipMol1lbRA0qrkZ5ckLkk/kbRa0lJJJ2XtZ3LSfpWkyYXoi5mZWWtTyDP/j0bECRFRkby/HlgYEQOBhcl7gI8DA5PlCuA2yHxYAG4ARgOjgBtqPzCYmZlZ/VrSZf/zgFnJ61nAp7Lid0XGs0BnST2As4AFEbElIrYCC4DxzZ20mZlZa1Oo4h/AbyUtlnRFEuseERuT15uA7snrnsBrWduuT2L1xfcj6QpJlZIqq6qqmqoPZmZmrVJxgY57SkRskPQBYIGkFdkrIyIkRVMdLCKmA9MBKioqmmy/ZmZmrVFBzvwjYkPyczPwIJl79q8nl/NJfm5Omm8Aemdt3iuJ1Rc3MzOzBjR78Zd0uKSOta+BM4GXgXlA7Yj9ycDc5PU84OJk1P8YYHtye+Ax4ExJXZKBfmcmMTMzM2tAIS77dwcelFR7/Hsj4lFJzwNzJF0GrAMuSNrPB84GVgM7gS8ARMQWSd8Bnk/a3RgRW5qvG2ZmZq2TItJ1C7yioiIqKysLnYaZWasiaXHWV7OtlWtJX/UzMzOzZuDib2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMi7+ZmZmKePib2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMi7+ZmZmKePib2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMi7+ZmZmKePib2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMq2++EsaL+kVSaslXV/ofMzMzFq6Vl38JbUDbgE+DpQDn5NUXtiszMzMWrbiQifwPo0CVkfEGgBJ9wHnAcub/Ej3ToIta5p8t21XFDqB1if8O2sc/74a7cvPQHGHQmdhLUBrL/49gdey3q8HRu/bSNIVwBUAffr0Obgjde3v/zSNJRU6g1bIv7NG8b+xRvLvyzJae/HPSURMB6YDVFRUHNzpwvjvN2VKZmZmBdOq7/kDG4DeWe97JTEzMzOrR2sv/s8DAyX1k9QemATMK3BOZmZmLVqrvuwfEdWSrgIeA9oBMyJiWYHTMjMza9FadfEHiIj5wPxC52FmZtZatPbL/mZmZtZILv5mZmYp4+JvZmaWMi7+ZmZmKaNI2SNFJVUB6w5y827AG02YTmvgPqdD2pUrwPwAAAXZSURBVPqctv7C++9z34gobapkrLBSV/zfD0mVEVFR6Dyak/ucDmnrc9r6C+nss9XPl/3NzMxSxsXfzMwsZVz8G2d6oRMoAPc5HdLW57T1F9LZZ6uH7/mbmZmljM/8zczMUsbF38zMLGVc/OsgabykVyStlnR9Hes7SJqdrF8kqaz5s2w6OfT365KWS1oqaaGkvoXIsykdqM9Z7SZKCkmt/itSufRZ0gXJ33qZpHubO8emlsO/7T6SnpD0QvLv++xC5NlUJM2QtFnSy/Wsl6SfJL+PpZJOau4crYWICC9ZC5mpgf8M9AfaA0uA8n3aXAn8PHk9CZhd6Lzz3N+PAoclr7/cmvuba5+Tdh2Bp4BngYpC590Mf+eBwAtAl+T9BwqddzP0eTrw5eR1ObC20Hm/zz5/GDgJeLme9WcDvwEEjAEWFTpnL4VZfOa/v1HA6ohYExHvAfcB5+3T5jxgVvL6fuB0SWrGHJvSAfsbEU9ExM7k7bNAr2bOsanl8jcG+A5wE/BucyaXJ7n0eQpwS0RsBYiIzc2cY1PLpc8BHJm87gT8tRnza3IR8RSwpYEm5wF3RcazQGdJPZonO2tJXPz31xN4Lev9+iRWZ5uIqAa2A0c1S3ZNL5f+ZruMzJlDa3bAPieXQ3tHxCPNmVge5fJ3HgQMkvS/kp6VNL7ZssuPXPo8FbhI0npgPvDPzZNawTT2/7u1UcWFTsBaD0kXARXAuELnkk+SioAfA5cUOJXmVkzm0v9HyFzdeUrScRGxraBZ5dfngJkR8SNJJwN3SxoeETWFTswsn3zmv78NQO+s972SWJ1tJBWTuVz4ZrNk1/Ry6S+SzgD+L3BuROxuptzy5UB97ggMB34naS2Ze6PzWvmgv1z+zuuBeRGxJyJeBVaS+TDQWuXS58uAOQAR8QeghMwEOG1VTv/fre1z8d/f88BASf0ktSczoG/ePm3mAZOT1+cDj0dEa31a0gH7K+lE4D/JFP7Wfh8YDtDniNgeEd0ioiwiysiMczg3IioLk26TyOXf9UNkzvqR1I3MbYA1zZlkE8ulz38BTgeQNJRM8a9q1iyb1zzg4mTU/xhge0RsLHRS1vx82X8fEVEt6SrgMTKjhWdExDJJNwKVETEPuIPM5cHVZAbXTCpcxu9Pjv39D+AI4FfJuMa/RMS5BUv6fcqxz21Kjn1+DDhT0nJgL3BtRLTWK1q59vka4BeSriYz+O+SVvxBHkm/JPMBrlsyjuEG4BCAiPg5mXENZwOrgZ3AFwqTqRWaH+9rZmaWMr7sb2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMi7+Zi2cpI9IerjQeZhZ2+Hib2ZmljIu/mZNRNJFkp6T9KKk/5TUTtLbkqZJWiZpoaTSpO0JyeQ5SyU9KKlLEh8g6X8kLZH0R0nHJrs/QtL9klZIuqd2FklJP5C0PNnPzQXqupm1Mi7+Zk0geTTsZ4EPRcQJZJ6QdyFwOJmnyQ0DniTzxDWAu4BvRsTxwEtZ8XvITKs7AhgL1D569UTga2TmnO8PfEjSUcAEYFiyn+/mt5dm1la4+Js1jdOBkcDzkl5M3vcHaoDZSZv/Ak6R1AnoHBFPJvFZwIcldQR6RsSDABHxbkTsTNo8FxHrk9nmXgTKyEwl/S5wh6RPk3lcq5nZAbn4mzUNAbMi4oRkGRwRU+tod7DP086eSXEvUBwR1cAo4H7gk8CjB7lvM0sZF3+zprEQOF/SBwAkdZXUl8z/sfOTNv8E/D4itgNbJZ2axD8PPBkRbwHrJX0q2UcHSYfVd0BJRwCdImI+cDUwIh8dM7O2x7P6mTWBiFgu6V+B30oqAvYAXwHeAUYl6zaTGRcAmSmhf54U9zX8fXa1zwP/mcw8twf4TAOH7QjMlVRC5srD15u4W2bWRnlWP7M8kvR2RBxR6DzMzLL5sr+ZmVnK+MzfzMwsZXzmb2ZmljIu/mZmZinj4m9mZpYyLv5mZmYp4+JvZmaWMv8fSqYVEQZsHlgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "bf950d0c-5544-4890-df83-9d504b9a36f1"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>9997</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9743</td>\n",
              "      <td>257</td>\n",
              "      <td>9165</td>\n",
              "      <td>209</td>\n",
              "      <td>455</td>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0       0         10000  ...                      3                       0\n",
              "1       1          9743  ...                    455                     171\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "79984755-82b4-4980-ae20-f2525dc99a66"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTmdoz9L--GB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "44fa531d-7584-4d02-c408-a3ffaca89023"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29944\n",
            "total train set images 30000\n",
            "focus_true_pred_true 29932 =============> FTPT : 99 %\n",
            "focus_false_pred_true 12 =============> FFPT : 0 %\n",
            "focus_true_pred_false 52 =============> FTPF : 0 %\n",
            "focus_false_pred_false 4 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  29995\n",
            "argmax_less_than_half ==================>  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40RP4DzU_A2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "8cb41736-dd25-41d6-b879-376a2cb8fa1b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n",
            "total correct 9967\n",
            "total train set images 10000\n",
            "focus_true_pred_true 9959 =============> FTPT : 99 %\n",
            "focus_false_pred_true 8 =============> FFPT : 0 %\n",
            "focus_true_pred_false 31 =============> FTPF : 0 %\n",
            "focus_false_pred_false 2 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  9993\n",
            "argmax_less_than_half ==================>  7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "85e6af33-2dcc-4fb2-df63-c13580a35c40"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29944\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f0b752f8-4a99-4f96-c9c2-79408e87473a"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n",
            "total correct 9967\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}