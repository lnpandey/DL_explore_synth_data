{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "11 focus_random_classify_pretrained_train_focus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "982d8f41953d44f2b3dcd821059486e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6791b3b447004f798ba58d2ca6c9feaa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa7a63a18c134008a9335d0a2fde9183",
              "IPY_MODEL_2eb401dfcd284106b15eea61d076196b"
            ]
          }
        },
        "6791b3b447004f798ba58d2ca6c9feaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa7a63a18c134008a9335d0a2fde9183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da576cb033a34fdc849bc06f59d22c83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_284f380c165549c695031a82c6303644"
          }
        },
        "2eb401dfcd284106b15eea61d076196b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91d44753931a46b3829217a8143b7151",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:05&lt;00:00, 29918623.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_014cadb183d34d92964e089e24726860"
          }
        },
        "da576cb033a34fdc849bc06f59d22c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "284f380c165549c695031a82c6303644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91d44753931a46b3829217a8143b7151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "014cadb183d34d92964e089e24726860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acRFqJNrZErV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "982d8f41953d44f2b3dcd821059486e8",
            "6791b3b447004f798ba58d2ca6c9feaa",
            "fa7a63a18c134008a9335d0a2fde9183",
            "2eb401dfcd284106b15eea61d076196b",
            "da576cb033a34fdc849bc06f59d22c83",
            "284f380c165549c695031a82c6303644",
            "91d44753931a46b3829217a8143b7151",
            "014cadb183d34d92964e089e24726860"
          ]
        },
        "outputId": "8f6e8af4-9f4a-41b4-f015-1390dcd6da65"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "982d8f41953d44f2b3dcd821059486e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V_JUhwCeZErk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26f230b4-99b7-4a0d-88a2-4e9c884e54dc"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SadRzWBBZEsP",
        "colab": {}
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX82H_9UnSny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(focus_net.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/Focus_net_weights/focus_net_11_exp_initialisation_1.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBQffkIzTOsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# focus_net.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Focus_net_weights/focus_net_6layer_cnn.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZtcA4VOTVxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# focus_net.fc4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMpRf9RETYRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# focus_net.fc4 = nn.Linear(10,1).double()\n",
        "# focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WFfxQ_3TYF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# focus_net.fc4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6tBJqBaTnl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   params.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLhPEuVoUBC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   print(params.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwcTiFhGThJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   print(params)\n",
        "#   break;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8b801dd-4444-4ee8-fa04-bb99bd3001c6"
      },
      "source": [
        "classify.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Classify_net_weights/classify_net_6layer_cnn.pt\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JM19FiENmBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for params in classify.parameters():\n",
        "  params.requires_grad = False\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL1DYUWuV5Jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de4b2856-729c-40c5-f4dd-cc324bdc79c8"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0rkwoqLpya8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e08bdcbd-6c35-4428-9f1e-ca6abcf7eefd"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0309,  0.1087,  0.1955],\n",
            "          [ 0.2209,  0.0076,  0.0348],\n",
            "          [-0.0854,  0.0774, -0.0973]],\n",
            "\n",
            "         [[ 0.0616, -0.1282,  0.2080],\n",
            "          [ 0.0332, -0.1826, -0.1365],\n",
            "          [-0.1557, -0.0844, -0.1973]],\n",
            "\n",
            "         [[-0.0722,  0.0364,  0.1260],\n",
            "          [ 0.0611, -0.0341,  0.1729],\n",
            "          [ 0.0427,  0.0797,  0.0223]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1835,  0.0366, -0.1656],\n",
            "          [-0.0834,  0.1659,  0.0364],\n",
            "          [ 0.1062,  0.2152,  0.1314]],\n",
            "\n",
            "         [[ 0.0086,  0.2094,  0.2249],\n",
            "          [-0.1404, -0.1745,  0.0035],\n",
            "          [-0.2156,  0.0847,  0.0851]],\n",
            "\n",
            "         [[-0.1070,  0.1605, -0.1541],\n",
            "          [-0.0419, -0.0417,  0.0718],\n",
            "          [-0.0668, -0.2273, -0.2890]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1013,  0.0165, -0.0829],\n",
            "          [-0.1709,  0.1888, -0.0619],\n",
            "          [-0.0676,  0.2545,  0.2560]],\n",
            "\n",
            "         [[-0.0495, -0.0233, -0.0692],\n",
            "          [ 0.0196, -0.1944, -0.2639],\n",
            "          [-0.2429,  0.0565,  0.1495]],\n",
            "\n",
            "         [[ 0.2412, -0.1480, -0.1188],\n",
            "          [ 0.0755,  0.0533, -0.1636],\n",
            "          [ 0.1195,  0.0296, -0.0620]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2049,  0.1405, -0.0744],\n",
            "          [ 0.0715,  0.0253,  0.0548],\n",
            "          [-0.0363, -0.0603, -0.0169]],\n",
            "\n",
            "         [[ 0.1719, -0.0024,  0.1642],\n",
            "          [ 0.0824, -0.1403,  0.0444],\n",
            "          [ 0.1660, -0.0140, -0.0213]],\n",
            "\n",
            "         [[-0.1377,  0.0023,  0.0830],\n",
            "          [-0.0201,  0.0463, -0.1071],\n",
            "          [-0.0089, -0.0475,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1722, -0.1703,  0.0900],\n",
            "          [-0.0026, -0.1981, -0.0808],\n",
            "          [-0.0556, -0.0525, -0.0903]],\n",
            "\n",
            "         [[ 0.0469,  0.1535,  0.1791],\n",
            "          [ 0.0031, -0.1002,  0.1474],\n",
            "          [-0.2295,  0.1191,  0.0080]],\n",
            "\n",
            "         [[ 0.1878,  0.0110,  0.1277],\n",
            "          [ 0.0146,  0.1758,  0.1353],\n",
            "          [-0.1670,  0.1439, -0.0813]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1690,  0.1051, -0.0433],\n",
            "          [-0.2494,  0.0010,  0.0629],\n",
            "          [-0.0552,  0.0004,  0.0097]],\n",
            "\n",
            "         [[ 0.1635,  0.3134,  0.0763],\n",
            "          [-0.1233,  0.0560, -0.2310],\n",
            "          [-0.1199, -0.2663, -0.0928]],\n",
            "\n",
            "         [[ 0.0838,  0.1768,  0.0256],\n",
            "          [-0.2400,  0.1630, -0.2009],\n",
            "          [ 0.0774, -0.0150,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1059,  0.0585, -0.1707],\n",
            "          [ 0.1078, -0.0531, -0.0276],\n",
            "          [ 0.1118, -0.0519, -0.1506]],\n",
            "\n",
            "         [[-0.1614,  0.1542, -0.1130],\n",
            "          [ 0.1823,  0.1833,  0.1834],\n",
            "          [ 0.0840, -0.0238,  0.0096]],\n",
            "\n",
            "         [[ 0.1863,  0.0509, -0.1148],\n",
            "          [-0.0720,  0.1801, -0.0417],\n",
            "          [ 0.0088,  0.0210, -0.0527]]],\n",
            "\n",
            "\n",
            "        [[[-0.0021, -0.1920, -0.1925],\n",
            "          [-0.0794, -0.1094, -0.1952],\n",
            "          [ 0.0640, -0.1527, -0.1590]],\n",
            "\n",
            "         [[ 0.0023, -0.0093,  0.0917],\n",
            "          [ 0.1893,  0.1771, -0.0419],\n",
            "          [ 0.1959,  0.0765, -0.1216]],\n",
            "\n",
            "         [[ 0.1127, -0.0509, -0.0890],\n",
            "          [ 0.0425, -0.0004,  0.0970],\n",
            "          [ 0.1725, -0.0294,  0.2238]]],\n",
            "\n",
            "\n",
            "        [[[-0.1533,  0.2030, -0.1170],\n",
            "          [ 0.0515, -0.0504, -0.1635],\n",
            "          [-0.1322, -0.1429,  0.1475]],\n",
            "\n",
            "         [[ 0.0555, -0.0411,  0.2137],\n",
            "          [-0.0274, -0.0902,  0.0513],\n",
            "          [ 0.0085, -0.1591,  0.1483]],\n",
            "\n",
            "         [[ 0.1163, -0.1371,  0.0318],\n",
            "          [ 0.0841, -0.2464, -0.2148],\n",
            "          [ 0.0637,  0.1322,  0.0676]]],\n",
            "\n",
            "\n",
            "        [[[-0.0227,  0.0487,  0.2023],\n",
            "          [-0.1330,  0.1492, -0.0169],\n",
            "          [ 0.1584,  0.1524, -0.0456]],\n",
            "\n",
            "         [[-0.0525, -0.1646, -0.0814],\n",
            "          [-0.2456, -0.1350,  0.0154],\n",
            "          [ 0.2309, -0.1780, -0.0720]],\n",
            "\n",
            "         [[-0.0142,  0.0480,  0.2516],\n",
            "          [-0.1593,  0.1562,  0.1928],\n",
            "          [-0.1119, -0.2044, -0.1976]]],\n",
            "\n",
            "\n",
            "        [[[-0.0355,  0.1166, -0.0631],\n",
            "          [-0.0836, -0.1515,  0.1577],\n",
            "          [ 0.0235,  0.1110, -0.0250]],\n",
            "\n",
            "         [[-0.2114,  0.1654,  0.2484],\n",
            "          [ 0.0525,  0.2583,  0.0362],\n",
            "          [-0.0713,  0.1357, -0.0152]],\n",
            "\n",
            "         [[-0.0821, -0.0350, -0.1481],\n",
            "          [-0.2171,  0.0489,  0.2106],\n",
            "          [ 0.1037, -0.1230,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.1625,  0.1384],\n",
            "          [-0.1124, -0.1412,  0.2642],\n",
            "          [ 0.0284, -0.0494, -0.0447]],\n",
            "\n",
            "         [[ 0.0205, -0.2302,  0.1754],\n",
            "          [ 0.0924, -0.2460,  0.2219],\n",
            "          [ 0.0863, -0.1062,  0.1210]],\n",
            "\n",
            "         [[ 0.2537, -0.2292, -0.1540],\n",
            "          [ 0.2104, -0.2362,  0.1700],\n",
            "          [ 0.2093, -0.2085, -0.0309]]],\n",
            "\n",
            "\n",
            "        [[[-0.1426,  0.1824, -0.2160],\n",
            "          [ 0.0009, -0.0087,  0.0207],\n",
            "          [ 0.0911, -0.2336, -0.1702]],\n",
            "\n",
            "         [[ 0.2153,  0.1894,  0.0243],\n",
            "          [-0.2433,  0.2294,  0.2479],\n",
            "          [-0.0595, -0.1203,  0.1227]],\n",
            "\n",
            "         [[-0.1597,  0.1976, -0.1576],\n",
            "          [-0.1258, -0.0205, -0.1531],\n",
            "          [ 0.1347,  0.0364, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[-0.0633, -0.0466, -0.0325],\n",
            "          [-0.0601,  0.0621, -0.0215],\n",
            "          [-0.0044, -0.0534,  0.0422]],\n",
            "\n",
            "         [[-0.1383, -0.1374, -0.1793],\n",
            "          [-0.0877, -0.1327,  0.0918],\n",
            "          [-0.0787,  0.0740, -0.0112]],\n",
            "\n",
            "         [[ 0.0814,  0.0275, -0.1438],\n",
            "          [-0.0439,  0.1876,  0.1383],\n",
            "          [-0.0834,  0.1108,  0.0304]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0447,  0.0499, -0.1449],\n",
            "          [-0.1171, -0.0733,  0.0182],\n",
            "          [-0.0587, -0.1367, -0.1931]],\n",
            "\n",
            "         [[ 0.0961,  0.0888, -0.0784],\n",
            "          [ 0.0504, -0.1259,  0.0890],\n",
            "          [-0.1473,  0.0371,  0.1020]],\n",
            "\n",
            "         [[ 0.0476, -0.1709, -0.0371],\n",
            "          [ 0.2308,  0.1298,  0.0326],\n",
            "          [-0.0171, -0.0634, -0.1609]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2378, -0.1200, -0.2246],\n",
            "          [ 0.2465,  0.0634, -0.1682],\n",
            "          [-0.0573, -0.1788,  0.0856]],\n",
            "\n",
            "         [[ 0.2020,  0.1478, -0.0181],\n",
            "          [ 0.1683,  0.0819, -0.0775],\n",
            "          [ 0.1869, -0.2327, -0.2108]],\n",
            "\n",
            "         [[-0.0383, -0.1762, -0.0893],\n",
            "          [-0.1869,  0.0115,  0.0917],\n",
            "          [ 0.0562, -0.0899,  0.1009]]],\n",
            "\n",
            "\n",
            "        [[[-0.0911, -0.2512,  0.0277],\n",
            "          [-0.0324,  0.1520,  0.2214],\n",
            "          [ 0.1329, -0.0946,  0.1157]],\n",
            "\n",
            "         [[ 0.1063, -0.1710,  0.0471],\n",
            "          [-0.1126,  0.1777,  0.2435],\n",
            "          [-0.1798,  0.0235,  0.1735]],\n",
            "\n",
            "         [[ 0.0092, -0.1809,  0.0974],\n",
            "          [ 0.1691, -0.1317,  0.1264],\n",
            "          [-0.1224, -0.1659, -0.2023]]],\n",
            "\n",
            "\n",
            "        [[[-0.2336,  0.2346,  0.0983],\n",
            "          [-0.1950, -0.1840,  0.1690],\n",
            "          [-0.2168,  0.0477,  0.0916]],\n",
            "\n",
            "         [[-0.0561,  0.1103,  0.0033],\n",
            "          [-0.0990, -0.2062, -0.0978],\n",
            "          [ 0.1411, -0.0397,  0.0443]],\n",
            "\n",
            "         [[ 0.1579,  0.1184, -0.1102],\n",
            "          [ 0.1775,  0.0325, -0.1486],\n",
            "          [-0.0702,  0.2019,  0.1233]]],\n",
            "\n",
            "\n",
            "        [[[-0.0797,  0.1350,  0.1679],\n",
            "          [-0.0473,  0.2595,  0.1358],\n",
            "          [-0.2849, -0.0974, -0.0081]],\n",
            "\n",
            "         [[-0.1065, -0.1424, -0.1542],\n",
            "          [-0.2096,  0.1828,  0.1126],\n",
            "          [ 0.0174,  0.0576, -0.0152]],\n",
            "\n",
            "         [[-0.2226,  0.0298, -0.1312],\n",
            "          [-0.1327,  0.2087,  0.1935],\n",
            "          [-0.0249,  0.0243, -0.0377]]],\n",
            "\n",
            "\n",
            "        [[[-0.0588,  0.1742,  0.2010],\n",
            "          [ 0.1427, -0.0923,  0.0899],\n",
            "          [-0.1261, -0.1139, -0.0786]],\n",
            "\n",
            "         [[-0.1481,  0.0529,  0.0481],\n",
            "          [ 0.0126, -0.0323,  0.1211],\n",
            "          [-0.0912, -0.0420, -0.1293]],\n",
            "\n",
            "         [[-0.2270, -0.2813, -0.1512],\n",
            "          [ 0.0183, -0.0734, -0.0467],\n",
            "          [ 0.1668,  0.1287,  0.1416]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1385,  0.0580,  0.3274],\n",
            "          [-0.0714, -0.0263,  0.2946],\n",
            "          [-0.2355, -0.3553,  0.0437]],\n",
            "\n",
            "         [[ 0.0762, -0.1933, -0.1612],\n",
            "          [-0.1279,  0.0055, -0.0561],\n",
            "          [ 0.2241, -0.0410,  0.1810]],\n",
            "\n",
            "         [[ 0.1535, -0.1441, -0.1855],\n",
            "          [ 0.2696, -0.1765,  0.0269],\n",
            "          [ 0.2909, -0.1872, -0.1417]]],\n",
            "\n",
            "\n",
            "        [[[-0.1353, -0.0778,  0.2160],\n",
            "          [-0.2453,  0.0684,  0.2713],\n",
            "          [ 0.0924,  0.0206,  0.2311]],\n",
            "\n",
            "         [[-0.1599,  0.0515, -0.0479],\n",
            "          [-0.1464, -0.0211,  0.0214],\n",
            "          [-0.1591, -0.0081, -0.1259]],\n",
            "\n",
            "         [[-0.0057,  0.1981, -0.0700],\n",
            "          [-0.1581,  0.2080,  0.0793],\n",
            "          [-0.2191,  0.0567,  0.0142]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2331, -0.0791, -0.0360],\n",
            "          [ 0.0551, -0.1573, -0.1605],\n",
            "          [ 0.1258, -0.0884, -0.2061]],\n",
            "\n",
            "         [[-0.2222,  0.1591,  0.1350],\n",
            "          [-0.1694, -0.0935,  0.0388],\n",
            "          [-0.0330,  0.1814,  0.0005]],\n",
            "\n",
            "         [[-0.1377, -0.0267,  0.1763],\n",
            "          [-0.2532,  0.2026,  0.1464],\n",
            "          [-0.0366,  0.2414, -0.1755]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0655, -0.1766, -0.2965],\n",
            "          [ 0.0635, -0.1370,  0.2211],\n",
            "          [ 0.0251, -0.0315,  0.2027]],\n",
            "\n",
            "         [[ 0.2559, -0.1553, -0.1362],\n",
            "          [ 0.2658, -0.1706,  0.1501],\n",
            "          [-0.1731, -0.0166, -0.0638]],\n",
            "\n",
            "         [[-0.1674,  0.0792,  0.1900],\n",
            "          [-0.0342, -0.2272,  0.2679],\n",
            "          [-0.0845, -0.0639,  0.0261]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0958,  0.0557, -0.0319],\n",
            "          [ 0.1302, -0.0530, -0.2087],\n",
            "          [ 0.0320,  0.1967, -0.1969]],\n",
            "\n",
            "         [[ 0.1327, -0.1589,  0.1865],\n",
            "          [-0.0338, -0.2036, -0.2538],\n",
            "          [ 0.1661,  0.1607,  0.1042]],\n",
            "\n",
            "         [[-0.2442, -0.0128, -0.1746],\n",
            "          [-0.0988,  0.0191, -0.2384],\n",
            "          [-0.1124,  0.2998,  0.2225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1305, -0.0375, -0.0713],\n",
            "          [-0.0881,  0.0315, -0.0487],\n",
            "          [-0.1159, -0.0198, -0.0042]],\n",
            "\n",
            "         [[-0.1895,  0.1779, -0.0391],\n",
            "          [ 0.1096, -0.0229,  0.0431],\n",
            "          [ 0.1912, -0.0880,  0.1516]],\n",
            "\n",
            "         [[ 0.1237,  0.1648,  0.0864],\n",
            "          [ 0.1106, -0.1358, -0.0593],\n",
            "          [ 0.0834,  0.1760, -0.1148]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0261,  0.0946, -0.2135],\n",
            "          [-0.0508, -0.2134, -0.0804],\n",
            "          [ 0.2161,  0.1251,  0.1160]],\n",
            "\n",
            "         [[ 0.2439,  0.1499,  0.0541],\n",
            "          [-0.1242, -0.3017, -0.1642],\n",
            "          [ 0.1484,  0.0228, -0.0532]],\n",
            "\n",
            "         [[ 0.2827,  0.0027,  0.2216],\n",
            "          [-0.2123, -0.1097, -0.0140],\n",
            "          [-0.1472, -0.1401,  0.1451]]],\n",
            "\n",
            "\n",
            "        [[[-0.0668, -0.0305, -0.1276],\n",
            "          [-0.0389,  0.0897,  0.0144],\n",
            "          [ 0.0437, -0.0369,  0.2345]],\n",
            "\n",
            "         [[ 0.0160, -0.0964, -0.1077],\n",
            "          [ 0.1918,  0.2170,  0.1363],\n",
            "          [-0.1928, -0.0407,  0.0342]],\n",
            "\n",
            "         [[-0.0021, -0.0420,  0.0836],\n",
            "          [ 0.0767,  0.0022,  0.0412],\n",
            "          [-0.1141, -0.0197,  0.0672]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1341, -0.0483, -0.1076],\n",
            "          [-0.1852, -0.0061,  0.0918],\n",
            "          [-0.1238,  0.0374, -0.0902]],\n",
            "\n",
            "         [[ 0.1261, -0.0141, -0.0833],\n",
            "          [-0.1273, -0.2019, -0.1387],\n",
            "          [-0.0098,  0.2122, -0.0161]],\n",
            "\n",
            "         [[ 0.1478,  0.0007, -0.0934],\n",
            "          [-0.1233,  0.0490,  0.0353],\n",
            "          [ 0.2064, -0.1164,  0.1303]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0583, -0.1114,  0.2957],\n",
            "          [ 0.1703, -0.0507,  0.0694],\n",
            "          [-0.1846,  0.1098, -0.1668]],\n",
            "\n",
            "         [[-0.2051, -0.2725, -0.0990],\n",
            "          [-0.1666,  0.0620, -0.0992],\n",
            "          [ 0.1796,  0.0437, -0.2720]],\n",
            "\n",
            "         [[ 0.1627, -0.1647, -0.0541],\n",
            "          [ 0.0633,  0.2490, -0.1993],\n",
            "          [ 0.1262,  0.2773,  0.0247]]],\n",
            "\n",
            "\n",
            "        [[[-0.2300, -0.1971, -0.0127],\n",
            "          [ 0.0639,  0.0679, -0.0152],\n",
            "          [ 0.2227, -0.0215, -0.0974]],\n",
            "\n",
            "         [[-0.2116, -0.0484,  0.1070],\n",
            "          [ 0.1198, -0.1068, -0.0113],\n",
            "          [ 0.1952,  0.0198,  0.0825]],\n",
            "\n",
            "         [[-0.3352,  0.1302,  0.0801],\n",
            "          [ 0.1699,  0.1231,  0.0742],\n",
            "          [ 0.0210, -0.1424,  0.0352]]],\n",
            "\n",
            "\n",
            "        [[[-0.0857,  0.1421,  0.1182],\n",
            "          [ 0.1262,  0.2026,  0.1068],\n",
            "          [ 0.0704, -0.0585, -0.0306]],\n",
            "\n",
            "         [[ 0.1038, -0.1139,  0.0915],\n",
            "          [ 0.1529,  0.1774, -0.1306],\n",
            "          [-0.2282, -0.2159,  0.0512]],\n",
            "\n",
            "         [[-0.1076, -0.1626,  0.0314],\n",
            "          [-0.1577,  0.1472,  0.1330],\n",
            "          [ 0.1294, -0.0155, -0.0551]]]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "068JnKOn249E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPm79Bdg2665",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "bf33100c-9c82-4503-c500-ea12e62b4218"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 47 %\n",
            "total correct 14123\n",
            "total train set images 30000\n",
            "focus_true_pred_true 1698 =============> FTPT : 5 %\n",
            "focus_false_pred_true 12425 =============> FFPT : 41 %\n",
            "focus_true_pred_false 1832 =============> FTPF : 6 %\n",
            "focus_false_pred_false 14045 =============> FFPF : 46 %\n",
            "argmax_more_than_half ==================>  0\n",
            "argmax_less_than_half ==================>  30000\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r3eJ9ax26wP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "51d3e1be-fed2-465a-e8cd-dc3fd208b712"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 47 %\n",
            "total correct 4778\n",
            "total train set images 10000\n",
            "focus_true_pred_true 555 =============> FTPT : 5 %\n",
            "focus_false_pred_true 4223 =============> FFPT : 42 %\n",
            "focus_true_pred_false 581 =============> FTPF : 5 %\n",
            "focus_false_pred_false 4641 =============> FFPF : 46 %\n",
            "argmax_more_than_half ==================>  0\n",
            "argmax_less_than_half ==================>  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tFfAJZkcZEsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5d6bbb6-2867-4f94-aaaa-447bf1af4e63"
      },
      "source": [
        "nos_epochs = 1000\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    # optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_focus.step()\n",
        "    # optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    # focus_net.eval()\n",
        "    col1.append(epoch+1)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "    print(\"=\"*20)\n",
        "    print(\"Train FTPT : \", col4)\n",
        "    print(\"Train FFPT : \", col5)\n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    print(\"Test FTPT : \", col10)\n",
        "    print(\"Test FFPT : \", col11)\n",
        "    print(\"=\"*20)\n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 5.161\n",
            "[1,   120] loss: 5.014\n",
            "[1,   180] loss: 5.223\n",
            "[1,   240] loss: 5.088\n",
            "====================\n",
            "Train FTPT :  [1698, 3350]\n",
            "Train FFPT :  [12425, 11229]\n",
            "Test FTPT :  [555, 1482]\n",
            "Test FFPT :  [4223, 3520]\n",
            "====================\n",
            "[2,    60] loss: 5.036\n",
            "[2,   120] loss: 4.983\n",
            "[2,   180] loss: 5.239\n",
            "[2,   240] loss: 4.979\n",
            "[3,    60] loss: 5.073\n",
            "[3,   120] loss: 4.905\n",
            "[3,   180] loss: 4.829\n",
            "[3,   240] loss: 4.938\n",
            "[4,    60] loss: 4.731\n",
            "[4,   120] loss: 4.985\n",
            "[4,   180] loss: 4.807\n",
            "[4,   240] loss: 4.596\n",
            "[5,    60] loss: 4.405\n",
            "[5,   120] loss: 4.576\n",
            "[5,   180] loss: 4.438\n",
            "[5,   240] loss: 4.640\n",
            "[6,    60] loss: 4.502\n",
            "[6,   120] loss: 4.268\n",
            "[6,   180] loss: 4.251\n",
            "[6,   240] loss: 4.307\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642]\n",
            "Train FFPT :  [12425, 11229, 9430]\n",
            "Test FTPT :  [555, 1482, 1676]\n",
            "Test FFPT :  [4223, 3520, 3539]\n",
            "====================\n",
            "[7,    60] loss: 4.277\n",
            "[7,   120] loss: 4.290\n",
            "[7,   180] loss: 3.973\n",
            "[7,   240] loss: 3.690\n",
            "[8,    60] loss: 3.606\n",
            "[8,   120] loss: 3.704\n",
            "[8,   180] loss: 3.491\n",
            "[8,   240] loss: 3.458\n",
            "[9,    60] loss: 3.200\n",
            "[9,   120] loss: 3.144\n",
            "[9,   180] loss: 3.081\n",
            "[9,   240] loss: 2.953\n",
            "[10,    60] loss: 2.907\n",
            "[10,   120] loss: 2.734\n",
            "[10,   180] loss: 2.779\n",
            "[10,   240] loss: 2.679\n",
            "[11,    60] loss: 2.637\n",
            "[11,   120] loss: 2.473\n",
            "[11,   180] loss: 2.473\n",
            "[11,   240] loss: 2.637\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698]\n",
            "Test FTPT :  [555, 1482, 1676, 5002]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251]\n",
            "====================\n",
            "[12,    60] loss: 2.204\n",
            "[12,   120] loss: 2.421\n",
            "[12,   180] loss: 2.370\n",
            "[12,   240] loss: 2.383\n",
            "[13,    60] loss: 2.269\n",
            "[13,   120] loss: 2.409\n",
            "[13,   180] loss: 2.282\n",
            "[13,   240] loss: 2.269\n",
            "[14,    60] loss: 2.262\n",
            "[14,   120] loss: 2.277\n",
            "[14,   180] loss: 2.121\n",
            "[14,   240] loss: 1.964\n",
            "[15,    60] loss: 1.960\n",
            "[15,   120] loss: 2.101\n",
            "[15,   180] loss: 2.102\n",
            "[15,   240] loss: 1.974\n",
            "[16,    60] loss: 1.897\n",
            "[16,   120] loss: 1.854\n",
            "[16,   180] loss: 1.944\n",
            "[16,   240] loss: 1.832\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935]\n",
            "====================\n",
            "[17,    60] loss: 1.788\n",
            "[17,   120] loss: 1.889\n",
            "[17,   180] loss: 1.893\n",
            "[17,   240] loss: 1.792\n",
            "[18,    60] loss: 1.890\n",
            "[18,   120] loss: 1.739\n",
            "[18,   180] loss: 1.718\n",
            "[18,   240] loss: 1.778\n",
            "[19,    60] loss: 1.679\n",
            "[19,   120] loss: 1.661\n",
            "[19,   180] loss: 1.625\n",
            "[19,   240] loss: 1.652\n",
            "[20,    60] loss: 1.614\n",
            "[20,   120] loss: 1.681\n",
            "[20,   180] loss: 1.574\n",
            "[20,   240] loss: 1.617\n",
            "[21,    60] loss: 1.592\n",
            "[21,   120] loss: 1.333\n",
            "[21,   180] loss: 1.441\n",
            "[21,   240] loss: 1.500\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735]\n",
            "====================\n",
            "[22,    60] loss: 1.309\n",
            "[22,   120] loss: 1.406\n",
            "[22,   180] loss: 1.471\n",
            "[22,   240] loss: 1.419\n",
            "[23,    60] loss: 1.397\n",
            "[23,   120] loss: 1.456\n",
            "[23,   180] loss: 1.366\n",
            "[23,   240] loss: 1.409\n",
            "[24,    60] loss: 1.375\n",
            "[24,   120] loss: 1.270\n",
            "[24,   180] loss: 1.301\n",
            "[24,   240] loss: 1.332\n",
            "[25,    60] loss: 1.245\n",
            "[25,   120] loss: 1.285\n",
            "[25,   180] loss: 1.313\n",
            "[25,   240] loss: 1.265\n",
            "[26,    60] loss: 1.179\n",
            "[26,   120] loss: 1.251\n",
            "[26,   180] loss: 1.179\n",
            "[26,   240] loss: 1.265\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536]\n",
            "====================\n",
            "[27,    60] loss: 1.117\n",
            "[27,   120] loss: 1.099\n",
            "[27,   180] loss: 1.243\n",
            "[27,   240] loss: 1.124\n",
            "[28,    60] loss: 1.121\n",
            "[28,   120] loss: 1.077\n",
            "[28,   180] loss: 1.137\n",
            "[28,   240] loss: 1.027\n",
            "[29,    60] loss: 1.071\n",
            "[29,   120] loss: 1.019\n",
            "[29,   180] loss: 1.006\n",
            "[29,   240] loss: 1.160\n",
            "[30,    60] loss: 1.153\n",
            "[30,   120] loss: 1.051\n",
            "[30,   180] loss: 1.002\n",
            "[30,   240] loss: 1.036\n",
            "[31,    60] loss: 0.973\n",
            "[31,   120] loss: 0.948\n",
            "[31,   180] loss: 1.056\n",
            "[31,   240] loss: 1.084\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658]\n",
            "====================\n",
            "[32,    60] loss: 0.896\n",
            "[32,   120] loss: 0.941\n",
            "[32,   180] loss: 0.932\n",
            "[32,   240] loss: 0.957\n",
            "[33,    60] loss: 0.810\n",
            "[33,   120] loss: 0.966\n",
            "[33,   180] loss: 0.867\n",
            "[33,   240] loss: 0.887\n",
            "[34,    60] loss: 0.863\n",
            "[34,   120] loss: 0.918\n",
            "[34,   180] loss: 0.836\n",
            "[34,   240] loss: 0.930\n",
            "[35,    60] loss: 0.754\n",
            "[35,   120] loss: 0.827\n",
            "[35,   180] loss: 0.891\n",
            "[35,   240] loss: 0.842\n",
            "[36,    60] loss: 0.725\n",
            "[36,   120] loss: 0.753\n",
            "[36,   180] loss: 0.732\n",
            "[36,   240] loss: 0.753\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414]\n",
            "====================\n",
            "[37,    60] loss: 0.727\n",
            "[37,   120] loss: 0.701\n",
            "[37,   180] loss: 0.718\n",
            "[37,   240] loss: 0.758\n",
            "[38,    60] loss: 0.779\n",
            "[38,   120] loss: 0.786\n",
            "[38,   180] loss: 0.774\n",
            "[38,   240] loss: 0.763\n",
            "[39,    60] loss: 0.707\n",
            "[39,   120] loss: 0.678\n",
            "[39,   180] loss: 0.688\n",
            "[39,   240] loss: 0.684\n",
            "[40,    60] loss: 0.625\n",
            "[40,   120] loss: 0.638\n",
            "[40,   180] loss: 0.714\n",
            "[40,   240] loss: 0.618\n",
            "[41,    60] loss: 0.670\n",
            "[41,   120] loss: 0.643\n",
            "[41,   180] loss: 0.613\n",
            "[41,   240] loss: 0.691\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346]\n",
            "====================\n",
            "[42,    60] loss: 0.561\n",
            "[42,   120] loss: 0.572\n",
            "[42,   180] loss: 0.572\n",
            "[42,   240] loss: 0.600\n",
            "[43,    60] loss: 0.541\n",
            "[43,   120] loss: 0.548\n",
            "[43,   180] loss: 0.541\n",
            "[43,   240] loss: 0.593\n",
            "[44,    60] loss: 0.551\n",
            "[44,   120] loss: 0.570\n",
            "[44,   180] loss: 0.621\n",
            "[44,   240] loss: 0.652\n",
            "[45,    60] loss: 0.558\n",
            "[45,   120] loss: 0.565\n",
            "[45,   180] loss: 0.601\n",
            "[45,   240] loss: 0.497\n",
            "[46,    60] loss: 0.476\n",
            "[46,   120] loss: 0.596\n",
            "[46,   180] loss: 0.541\n",
            "[46,   240] loss: 0.497\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332]\n",
            "====================\n",
            "[47,    60] loss: 0.547\n",
            "[47,   120] loss: 0.460\n",
            "[47,   180] loss: 0.622\n",
            "[47,   240] loss: 0.497\n",
            "[48,    60] loss: 0.458\n",
            "[48,   120] loss: 0.416\n",
            "[48,   180] loss: 0.503\n",
            "[48,   240] loss: 0.459\n",
            "[49,    60] loss: 0.401\n",
            "[49,   120] loss: 0.480\n",
            "[49,   180] loss: 0.497\n",
            "[49,   240] loss: 0.512\n",
            "[50,    60] loss: 0.457\n",
            "[50,   120] loss: 0.540\n",
            "[50,   180] loss: 0.405\n",
            "[50,   240] loss: 0.404\n",
            "[51,    60] loss: 0.349\n",
            "[51,   120] loss: 0.422\n",
            "[51,   180] loss: 0.394\n",
            "[51,   240] loss: 0.376\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148]\n",
            "====================\n",
            "[52,    60] loss: 0.461\n",
            "[52,   120] loss: 0.433\n",
            "[52,   180] loss: 0.399\n",
            "[52,   240] loss: 0.379\n",
            "[53,    60] loss: 0.334\n",
            "[53,   120] loss: 0.369\n",
            "[53,   180] loss: 0.389\n",
            "[53,   240] loss: 0.390\n",
            "[54,    60] loss: 0.406\n",
            "[54,   120] loss: 0.437\n",
            "[54,   180] loss: 0.450\n",
            "[54,   240] loss: 0.526\n",
            "[55,    60] loss: 0.448\n",
            "[55,   120] loss: 0.441\n",
            "[55,   180] loss: 0.391\n",
            "[55,   240] loss: 0.349\n",
            "[56,    60] loss: 0.354\n",
            "[56,   120] loss: 0.317\n",
            "[56,   180] loss: 0.380\n",
            "[56,   240] loss: 0.378\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108]\n",
            "====================\n",
            "[57,    60] loss: 0.316\n",
            "[57,   120] loss: 0.319\n",
            "[57,   180] loss: 0.397\n",
            "[57,   240] loss: 0.373\n",
            "[58,    60] loss: 0.292\n",
            "[58,   120] loss: 0.400\n",
            "[58,   180] loss: 0.334\n",
            "[58,   240] loss: 0.367\n",
            "[59,    60] loss: 0.259\n",
            "[59,   120] loss: 0.283\n",
            "[59,   180] loss: 0.322\n",
            "[59,   240] loss: 0.293\n",
            "[60,    60] loss: 0.286\n",
            "[60,   120] loss: 0.293\n",
            "[60,   180] loss: 0.357\n",
            "[60,   240] loss: 0.309\n",
            "[61,    60] loss: 0.306\n",
            "[61,   120] loss: 0.311\n",
            "[61,   180] loss: 0.286\n",
            "[61,   240] loss: 0.300\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131]\n",
            "====================\n",
            "[62,    60] loss: 0.289\n",
            "[62,   120] loss: 0.308\n",
            "[62,   180] loss: 0.348\n",
            "[62,   240] loss: 0.365\n",
            "[63,    60] loss: 0.329\n",
            "[63,   120] loss: 0.263\n",
            "[63,   180] loss: 0.285\n",
            "[63,   240] loss: 0.360\n",
            "[64,    60] loss: 0.335\n",
            "[64,   120] loss: 0.280\n",
            "[64,   180] loss: 0.290\n",
            "[64,   240] loss: 0.309\n",
            "[65,    60] loss: 0.243\n",
            "[65,   120] loss: 0.251\n",
            "[65,   180] loss: 0.241\n",
            "[65,   240] loss: 0.209\n",
            "[66,    60] loss: 0.232\n",
            "[66,   120] loss: 0.231\n",
            "[66,   180] loss: 0.253\n",
            "[66,   240] loss: 0.255\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096]\n",
            "====================\n",
            "[67,    60] loss: 0.296\n",
            "[67,   120] loss: 0.258\n",
            "[67,   180] loss: 0.238\n",
            "[67,   240] loss: 0.278\n",
            "[68,    60] loss: 0.278\n",
            "[68,   120] loss: 0.229\n",
            "[68,   180] loss: 0.203\n",
            "[68,   240] loss: 0.248\n",
            "[69,    60] loss: 0.263\n",
            "[69,   120] loss: 0.249\n",
            "[69,   180] loss: 0.263\n",
            "[69,   240] loss: 0.296\n",
            "[70,    60] loss: 0.324\n",
            "[70,   120] loss: 0.276\n",
            "[70,   180] loss: 0.324\n",
            "[70,   240] loss: 0.295\n",
            "[71,    60] loss: 0.277\n",
            "[71,   120] loss: 0.246\n",
            "[71,   180] loss: 0.246\n",
            "[71,   240] loss: 0.311\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113]\n",
            "====================\n",
            "[72,    60] loss: 0.221\n",
            "[72,   120] loss: 0.237\n",
            "[72,   180] loss: 0.228\n",
            "[72,   240] loss: 0.211\n",
            "[73,    60] loss: 0.158\n",
            "[73,   120] loss: 0.196\n",
            "[73,   180] loss: 0.193\n",
            "[73,   240] loss: 0.233\n",
            "[74,    60] loss: 0.173\n",
            "[74,   120] loss: 0.229\n",
            "[74,   180] loss: 0.185\n",
            "[74,   240] loss: 0.232\n",
            "[75,    60] loss: 0.217\n",
            "[75,   120] loss: 0.197\n",
            "[75,   180] loss: 0.206\n",
            "[75,   240] loss: 0.192\n",
            "[76,    60] loss: 0.197\n",
            "[76,   120] loss: 0.180\n",
            "[76,   180] loss: 0.207\n",
            "[76,   240] loss: 0.198\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066]\n",
            "====================\n",
            "[77,    60] loss: 0.184\n",
            "[77,   120] loss: 0.189\n",
            "[77,   180] loss: 0.176\n",
            "[77,   240] loss: 0.190\n",
            "[78,    60] loss: 0.223\n",
            "[78,   120] loss: 0.180\n",
            "[78,   180] loss: 0.186\n",
            "[78,   240] loss: 0.136\n",
            "[79,    60] loss: 0.197\n",
            "[79,   120] loss: 0.186\n",
            "[79,   180] loss: 0.151\n",
            "[79,   240] loss: 0.145\n",
            "[80,    60] loss: 0.178\n",
            "[80,   120] loss: 0.165\n",
            "[80,   180] loss: 0.160\n",
            "[80,   240] loss: 0.131\n",
            "[81,    60] loss: 0.135\n",
            "[81,   120] loss: 0.131\n",
            "[81,   180] loss: 0.129\n",
            "[81,   240] loss: 0.160\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028]\n",
            "====================\n",
            "[82,    60] loss: 0.141\n",
            "[82,   120] loss: 0.106\n",
            "[82,   180] loss: 0.139\n",
            "[82,   240] loss: 0.119\n",
            "[83,    60] loss: 0.151\n",
            "[83,   120] loss: 0.159\n",
            "[83,   180] loss: 0.158\n",
            "[83,   240] loss: 0.137\n",
            "[84,    60] loss: 0.110\n",
            "[84,   120] loss: 0.140\n",
            "[84,   180] loss: 0.171\n",
            "[84,   240] loss: 0.140\n",
            "[85,    60] loss: 0.130\n",
            "[85,   120] loss: 0.121\n",
            "[85,   180] loss: 0.089\n",
            "[85,   240] loss: 0.125\n",
            "[86,    60] loss: 0.105\n",
            "[86,   120] loss: 0.131\n",
            "[86,   180] loss: 0.115\n",
            "[86,   240] loss: 0.126\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939]\n",
            "====================\n",
            "[87,    60] loss: 0.111\n",
            "[87,   120] loss: 0.185\n",
            "[87,   180] loss: 0.128\n",
            "[87,   240] loss: 0.142\n",
            "[88,    60] loss: 0.157\n",
            "[88,   120] loss: 0.134\n",
            "[88,   180] loss: 0.137\n",
            "[88,   240] loss: 0.126\n",
            "[89,    60] loss: 0.110\n",
            "[89,   120] loss: 0.119\n",
            "[89,   180] loss: 0.157\n",
            "[89,   240] loss: 0.138\n",
            "[90,    60] loss: 0.132\n",
            "[90,   120] loss: 0.125\n",
            "[90,   180] loss: 0.165\n",
            "[90,   240] loss: 0.129\n",
            "[91,    60] loss: 0.114\n",
            "[91,   120] loss: 0.115\n",
            "[91,   180] loss: 0.092\n",
            "[91,   240] loss: 0.106\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922]\n",
            "====================\n",
            "[92,    60] loss: 0.082\n",
            "[92,   120] loss: 0.084\n",
            "[92,   180] loss: 0.108\n",
            "[92,   240] loss: 0.150\n",
            "[93,    60] loss: 0.090\n",
            "[93,   120] loss: 0.091\n",
            "[93,   180] loss: 0.094\n",
            "[93,   240] loss: 0.106\n",
            "[94,    60] loss: 0.116\n",
            "[94,   120] loss: 0.129\n",
            "[94,   180] loss: 0.123\n",
            "[94,   240] loss: 0.112\n",
            "[95,    60] loss: 0.116\n",
            "[95,   120] loss: 0.095\n",
            "[95,   180] loss: 0.134\n",
            "[95,   240] loss: 0.114\n",
            "[96,    60] loss: 0.105\n",
            "[96,   120] loss: 0.120\n",
            "[96,   180] loss: 0.148\n",
            "[96,   240] loss: 0.101\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965]\n",
            "====================\n",
            "[97,    60] loss: 0.142\n",
            "[97,   120] loss: 0.124\n",
            "[97,   180] loss: 0.131\n",
            "[97,   240] loss: 0.131\n",
            "[98,    60] loss: 0.099\n",
            "[98,   120] loss: 0.117\n",
            "[98,   180] loss: 0.114\n",
            "[98,   240] loss: 0.127\n",
            "[99,    60] loss: 0.103\n",
            "[99,   120] loss: 0.095\n",
            "[99,   180] loss: 0.130\n",
            "[99,   240] loss: 0.097\n",
            "[100,    60] loss: 0.117\n",
            "[100,   120] loss: 0.110\n",
            "[100,   180] loss: 0.132\n",
            "[100,   240] loss: 0.105\n",
            "[101,    60] loss: 0.106\n",
            "[101,   120] loss: 0.097\n",
            "[101,   180] loss: 0.092\n",
            "[101,   240] loss: 0.096\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924]\n",
            "====================\n",
            "[102,    60] loss: 0.100\n",
            "[102,   120] loss: 0.107\n",
            "[102,   180] loss: 0.106\n",
            "[102,   240] loss: 0.091\n",
            "[103,    60] loss: 0.091\n",
            "[103,   120] loss: 0.085\n",
            "[103,   180] loss: 0.114\n",
            "[103,   240] loss: 0.108\n",
            "[104,    60] loss: 0.113\n",
            "[104,   120] loss: 0.077\n",
            "[104,   180] loss: 0.084\n",
            "[104,   240] loss: 0.078\n",
            "[105,    60] loss: 0.099\n",
            "[105,   120] loss: 0.088\n",
            "[105,   180] loss: 0.087\n",
            "[105,   240] loss: 0.084\n",
            "[106,    60] loss: 0.086\n",
            "[106,   120] loss: 0.080\n",
            "[106,   180] loss: 0.106\n",
            "[106,   240] loss: 0.114\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943]\n",
            "====================\n",
            "[107,    60] loss: 0.108\n",
            "[107,   120] loss: 0.101\n",
            "[107,   180] loss: 0.087\n",
            "[107,   240] loss: 0.107\n",
            "[108,    60] loss: 0.087\n",
            "[108,   120] loss: 0.090\n",
            "[108,   180] loss: 0.072\n",
            "[108,   240] loss: 0.091\n",
            "[109,    60] loss: 0.110\n",
            "[109,   120] loss: 0.090\n",
            "[109,   180] loss: 0.094\n",
            "[109,   240] loss: 0.109\n",
            "[110,    60] loss: 0.084\n",
            "[110,   120] loss: 0.085\n",
            "[110,   180] loss: 0.110\n",
            "[110,   240] loss: 0.094\n",
            "[111,    60] loss: 0.103\n",
            "[111,   120] loss: 0.094\n",
            "[111,   180] loss: 0.080\n",
            "[111,   240] loss: 0.108\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993]\n",
            "====================\n",
            "[112,    60] loss: 0.097\n",
            "[112,   120] loss: 0.096\n",
            "[112,   180] loss: 0.079\n",
            "[112,   240] loss: 0.090\n",
            "[113,    60] loss: 0.081\n",
            "[113,   120] loss: 0.082\n",
            "[113,   180] loss: 0.110\n",
            "[113,   240] loss: 0.105\n",
            "[114,    60] loss: 0.078\n",
            "[114,   120] loss: 0.084\n",
            "[114,   180] loss: 0.088\n",
            "[114,   240] loss: 0.081\n",
            "[115,    60] loss: 0.071\n",
            "[115,   120] loss: 0.084\n",
            "[115,   180] loss: 0.145\n",
            "[115,   240] loss: 0.110\n",
            "[116,    60] loss: 0.132\n",
            "[116,   120] loss: 0.092\n",
            "[116,   180] loss: 0.118\n",
            "[116,   240] loss: 0.115\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966]\n",
            "====================\n",
            "[117,    60] loss: 0.074\n",
            "[117,   120] loss: 0.081\n",
            "[117,   180] loss: 0.084\n",
            "[117,   240] loss: 0.118\n",
            "[118,    60] loss: 0.092\n",
            "[118,   120] loss: 0.086\n",
            "[118,   180] loss: 0.096\n",
            "[118,   240] loss: 0.071\n",
            "[119,    60] loss: 0.081\n",
            "[119,   120] loss: 0.067\n",
            "[119,   180] loss: 0.070\n",
            "[119,   240] loss: 0.087\n",
            "[120,    60] loss: 0.065\n",
            "[120,   120] loss: 0.064\n",
            "[120,   180] loss: 0.085\n",
            "[120,   240] loss: 0.091\n",
            "[121,    60] loss: 0.064\n",
            "[121,   120] loss: 0.077\n",
            "[121,   180] loss: 0.059\n",
            "[121,   240] loss: 0.070\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886]\n",
            "====================\n",
            "[122,    60] loss: 0.052\n",
            "[122,   120] loss: 0.064\n",
            "[122,   180] loss: 0.081\n",
            "[122,   240] loss: 0.069\n",
            "[123,    60] loss: 0.070\n",
            "[123,   120] loss: 0.048\n",
            "[123,   180] loss: 0.066\n",
            "[123,   240] loss: 0.076\n",
            "[124,    60] loss: 0.057\n",
            "[124,   120] loss: 0.078\n",
            "[124,   180] loss: 0.063\n",
            "[124,   240] loss: 0.062\n",
            "[125,    60] loss: 0.067\n",
            "[125,   120] loss: 0.090\n",
            "[125,   180] loss: 0.062\n",
            "[125,   240] loss: 0.048\n",
            "[126,    60] loss: 0.059\n",
            "[126,   120] loss: 0.073\n",
            "[126,   180] loss: 0.070\n",
            "[126,   240] loss: 0.048\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872]\n",
            "====================\n",
            "[127,    60] loss: 0.062\n",
            "[127,   120] loss: 0.074\n",
            "[127,   180] loss: 0.052\n",
            "[127,   240] loss: 0.056\n",
            "[128,    60] loss: 0.059\n",
            "[128,   120] loss: 0.055\n",
            "[128,   180] loss: 0.061\n",
            "[128,   240] loss: 0.062\n",
            "[129,    60] loss: 0.055\n",
            "[129,   120] loss: 0.055\n",
            "[129,   180] loss: 0.046\n",
            "[129,   240] loss: 0.075\n",
            "[130,    60] loss: 0.065\n",
            "[130,   120] loss: 0.045\n",
            "[130,   180] loss: 0.054\n",
            "[130,   240] loss: 0.062\n",
            "[131,    60] loss: 0.045\n",
            "[131,   120] loss: 0.049\n",
            "[131,   180] loss: 0.058\n",
            "[131,   240] loss: 0.063\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925]\n",
            "====================\n",
            "[132,    60] loss: 0.057\n",
            "[132,   120] loss: 0.046\n",
            "[132,   180] loss: 0.099\n",
            "[132,   240] loss: 0.070\n",
            "[133,    60] loss: 0.064\n",
            "[133,   120] loss: 0.059\n",
            "[133,   180] loss: 0.070\n",
            "[133,   240] loss: 0.060\n",
            "[134,    60] loss: 0.057\n",
            "[134,   120] loss: 0.042\n",
            "[134,   180] loss: 0.067\n",
            "[134,   240] loss: 0.099\n",
            "[135,    60] loss: 0.093\n",
            "[135,   120] loss: 0.083\n",
            "[135,   180] loss: 0.063\n",
            "[135,   240] loss: 0.064\n",
            "[136,    60] loss: 0.069\n",
            "[136,   120] loss: 0.064\n",
            "[136,   180] loss: 0.074\n",
            "[136,   240] loss: 0.061\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861]\n",
            "====================\n",
            "[137,    60] loss: 0.041\n",
            "[137,   120] loss: 0.066\n",
            "[137,   180] loss: 0.056\n",
            "[137,   240] loss: 0.050\n",
            "[138,    60] loss: 0.040\n",
            "[138,   120] loss: 0.047\n",
            "[138,   180] loss: 0.054\n",
            "[138,   240] loss: 0.057\n",
            "[139,    60] loss: 0.050\n",
            "[139,   120] loss: 0.041\n",
            "[139,   180] loss: 0.112\n",
            "[139,   240] loss: 0.098\n",
            "[140,    60] loss: 0.055\n",
            "[140,   120] loss: 0.074\n",
            "[140,   180] loss: 0.047\n",
            "[140,   240] loss: 0.081\n",
            "[141,    60] loss: 0.060\n",
            "[141,   120] loss: 0.063\n",
            "[141,   180] loss: 0.056\n",
            "[141,   240] loss: 0.055\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882]\n",
            "====================\n",
            "[142,    60] loss: 0.051\n",
            "[142,   120] loss: 0.056\n",
            "[142,   180] loss: 0.066\n",
            "[142,   240] loss: 0.059\n",
            "[143,    60] loss: 0.065\n",
            "[143,   120] loss: 0.064\n",
            "[143,   180] loss: 0.091\n",
            "[143,   240] loss: 0.087\n",
            "[144,    60] loss: 0.099\n",
            "[144,   120] loss: 0.096\n",
            "[144,   180] loss: 0.075\n",
            "[144,   240] loss: 0.083\n",
            "[145,    60] loss: 0.071\n",
            "[145,   120] loss: 0.061\n",
            "[145,   180] loss: 0.074\n",
            "[145,   240] loss: 0.097\n",
            "[146,    60] loss: 0.068\n",
            "[146,   120] loss: 0.089\n",
            "[146,   180] loss: 0.072\n",
            "[146,   240] loss: 0.058\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881]\n",
            "====================\n",
            "[147,    60] loss: 0.060\n",
            "[147,   120] loss: 0.056\n",
            "[147,   180] loss: 0.060\n",
            "[147,   240] loss: 0.061\n",
            "[148,    60] loss: 0.071\n",
            "[148,   120] loss: 0.073\n",
            "[148,   180] loss: 0.069\n",
            "[148,   240] loss: 0.072\n",
            "[149,    60] loss: 0.073\n",
            "[149,   120] loss: 0.069\n",
            "[149,   180] loss: 0.092\n",
            "[149,   240] loss: 0.092\n",
            "[150,    60] loss: 0.067\n",
            "[150,   120] loss: 0.071\n",
            "[150,   180] loss: 0.079\n",
            "[150,   240] loss: 0.065\n",
            "[151,    60] loss: 0.062\n",
            "[151,   120] loss: 0.080\n",
            "[151,   180] loss: 0.060\n",
            "[151,   240] loss: 0.067\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892]\n",
            "====================\n",
            "[152,    60] loss: 0.048\n",
            "[152,   120] loss: 0.057\n",
            "[152,   180] loss: 0.060\n",
            "[152,   240] loss: 0.050\n",
            "[153,    60] loss: 0.052\n",
            "[153,   120] loss: 0.060\n",
            "[153,   180] loss: 0.072\n",
            "[153,   240] loss: 0.054\n",
            "[154,    60] loss: 0.045\n",
            "[154,   120] loss: 0.053\n",
            "[154,   180] loss: 0.061\n",
            "[154,   240] loss: 0.057\n",
            "[155,    60] loss: 0.065\n",
            "[155,   120] loss: 0.065\n",
            "[155,   180] loss: 0.054\n",
            "[155,   240] loss: 0.049\n",
            "[156,    60] loss: 0.051\n",
            "[156,   120] loss: 0.051\n",
            "[156,   180] loss: 0.065\n",
            "[156,   240] loss: 0.047\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867]\n",
            "====================\n",
            "[157,    60] loss: 0.039\n",
            "[157,   120] loss: 0.054\n",
            "[157,   180] loss: 0.040\n",
            "[157,   240] loss: 0.041\n",
            "[158,    60] loss: 0.053\n",
            "[158,   120] loss: 0.053\n",
            "[158,   180] loss: 0.045\n",
            "[158,   240] loss: 0.054\n",
            "[159,    60] loss: 0.063\n",
            "[159,   120] loss: 0.063\n",
            "[159,   180] loss: 0.040\n",
            "[159,   240] loss: 0.061\n",
            "[160,    60] loss: 0.049\n",
            "[160,   120] loss: 0.040\n",
            "[160,   180] loss: 0.046\n",
            "[160,   240] loss: 0.049\n",
            "[161,    60] loss: 0.050\n",
            "[161,   120] loss: 0.051\n",
            "[161,   180] loss: 0.052\n",
            "[161,   240] loss: 0.051\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887]\n",
            "====================\n",
            "[162,    60] loss: 0.045\n",
            "[162,   120] loss: 0.042\n",
            "[162,   180] loss: 0.045\n",
            "[162,   240] loss: 0.040\n",
            "[163,    60] loss: 0.060\n",
            "[163,   120] loss: 0.034\n",
            "[163,   180] loss: 0.042\n",
            "[163,   240] loss: 0.045\n",
            "[164,    60] loss: 0.040\n",
            "[164,   120] loss: 0.037\n",
            "[164,   180] loss: 0.053\n",
            "[164,   240] loss: 0.032\n",
            "[165,    60] loss: 0.045\n",
            "[165,   120] loss: 0.060\n",
            "[165,   180] loss: 0.052\n",
            "[165,   240] loss: 0.044\n",
            "[166,    60] loss: 0.045\n",
            "[166,   120] loss: 0.038\n",
            "[166,   180] loss: 0.057\n",
            "[166,   240] loss: 0.045\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878]\n",
            "====================\n",
            "[167,    60] loss: 0.047\n",
            "[167,   120] loss: 0.039\n",
            "[167,   180] loss: 0.047\n",
            "[167,   240] loss: 0.046\n",
            "[168,    60] loss: 0.055\n",
            "[168,   120] loss: 0.051\n",
            "[168,   180] loss: 0.038\n",
            "[168,   240] loss: 0.055\n",
            "[169,    60] loss: 0.062\n",
            "[169,   120] loss: 0.043\n",
            "[169,   180] loss: 0.047\n",
            "[169,   240] loss: 0.052\n",
            "[170,    60] loss: 0.032\n",
            "[170,   120] loss: 0.049\n",
            "[170,   180] loss: 0.047\n",
            "[170,   240] loss: 0.054\n",
            "[171,    60] loss: 0.032\n",
            "[171,   120] loss: 0.057\n",
            "[171,   180] loss: 0.040\n",
            "[171,   240] loss: 0.046\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020, 27156]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716, 2601]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651, 8680]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878, 865]\n",
            "====================\n",
            "[172,    60] loss: 0.034\n",
            "[172,   120] loss: 0.043\n",
            "[172,   180] loss: 0.033\n",
            "[172,   240] loss: 0.043\n",
            "[173,    60] loss: 0.037\n",
            "[173,   120] loss: 0.041\n",
            "[173,   180] loss: 0.032\n",
            "[173,   240] loss: 0.053\n",
            "[174,    60] loss: 0.031\n",
            "[174,   120] loss: 0.041\n",
            "[174,   180] loss: 0.041\n",
            "[174,   240] loss: 0.041\n",
            "[175,    60] loss: 0.040\n",
            "[175,   120] loss: 0.044\n",
            "[175,   180] loss: 0.035\n",
            "[175,   240] loss: 0.036\n",
            "[176,    60] loss: 0.035\n",
            "[176,   120] loss: 0.035\n",
            "[176,   180] loss: 0.043\n",
            "[176,   240] loss: 0.045\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020, 27156, 27159]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716, 2601, 2627]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651, 8680, 8677]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878, 865, 876]\n",
            "====================\n",
            "[177,    60] loss: 0.038\n",
            "[177,   120] loss: 0.036\n",
            "[177,   180] loss: 0.033\n",
            "[177,   240] loss: 0.039\n",
            "[178,    60] loss: 0.035\n",
            "[178,   120] loss: 0.041\n",
            "[178,   180] loss: 0.040\n",
            "[178,   240] loss: 0.036\n",
            "[179,    60] loss: 0.037\n",
            "[179,   120] loss: 0.030\n",
            "[179,   180] loss: 0.048\n",
            "[179,   240] loss: 0.053\n",
            "[180,    60] loss: 0.042\n",
            "[180,   120] loss: 0.038\n",
            "[180,   180] loss: 0.047\n",
            "[180,   240] loss: 0.057\n",
            "[181,    60] loss: 0.043\n",
            "[181,   120] loss: 0.047\n",
            "[181,   180] loss: 0.045\n",
            "[181,   240] loss: 0.051\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020, 27156, 27159, 27149]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716, 2601, 2627, 2616]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651, 8680, 8677, 8699]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878, 865, 876, 844]\n",
            "====================\n",
            "[182,    60] loss: 0.050\n",
            "[182,   120] loss: 0.039\n",
            "[182,   180] loss: 0.039\n",
            "[182,   240] loss: 0.034\n",
            "[183,    60] loss: 0.049\n",
            "[183,   120] loss: 0.044\n",
            "[183,   180] loss: 0.039\n",
            "[183,   240] loss: 0.044\n",
            "[184,    60] loss: 0.042\n",
            "[184,   120] loss: 0.038\n",
            "[184,   180] loss: 0.041\n",
            "[184,   240] loss: 0.053\n",
            "[185,    60] loss: 0.044\n",
            "[185,   120] loss: 0.052\n",
            "[185,   180] loss: 0.039\n",
            "[185,   240] loss: 0.034\n",
            "[186,    60] loss: 0.047\n",
            "[186,   120] loss: 0.038\n",
            "[186,   180] loss: 0.031\n",
            "[186,   240] loss: 0.035\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020, 27156, 27159, 27149, 27272]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716, 2601, 2627, 2616, 2528]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651, 8680, 8677, 8699, 8770]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878, 865, 876, 844, 795]\n",
            "====================\n",
            "[187,    60] loss: 0.037\n",
            "[187,   120] loss: 0.033\n",
            "[187,   180] loss: 0.038\n",
            "[187,   240] loss: 0.035\n",
            "[188,    60] loss: 0.038\n",
            "[188,   120] loss: 0.021\n",
            "[188,   180] loss: 0.036\n",
            "[188,   240] loss: 0.031\n",
            "[189,    60] loss: 0.026\n",
            "[189,   120] loss: 0.040\n",
            "[189,   180] loss: 0.035\n",
            "[189,   240] loss: 0.036\n",
            "[190,    60] loss: 0.026\n",
            "[190,   120] loss: 0.028\n",
            "[190,   180] loss: 0.041\n",
            "[190,   240] loss: 0.035\n",
            "[191,    60] loss: 0.035\n",
            "[191,   120] loss: 0.032\n",
            "[191,   180] loss: 0.043\n",
            "[191,   240] loss: 0.028\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020, 27156, 27159, 27149, 27272, 27230]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716, 2601, 2627, 2616, 2528, 2582]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651, 8680, 8677, 8699, 8770, 8704]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878, 865, 876, 844, 795, 843]\n",
            "====================\n",
            "[192,    60] loss: 0.042\n",
            "[192,   120] loss: 0.051\n",
            "[192,   180] loss: 0.036\n",
            "[192,   240] loss: 0.033\n",
            "[193,    60] loss: 0.032\n",
            "[193,   120] loss: 0.044\n",
            "[193,   180] loss: 0.043\n",
            "[193,   240] loss: 0.035\n",
            "[194,    60] loss: 0.035\n",
            "[194,   120] loss: 0.025\n",
            "[194,   180] loss: 0.049\n",
            "[194,   240] loss: 0.030\n",
            "[195,    60] loss: 0.029\n",
            "[195,   120] loss: 0.029\n",
            "[195,   180] loss: 0.040\n",
            "[195,   240] loss: 0.038\n",
            "[196,    60] loss: 0.041\n",
            "[196,   120] loss: 0.022\n",
            "[196,   180] loss: 0.034\n",
            "[196,   240] loss: 0.035\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020, 27156, 27159, 27149, 27272, 27230, 27197]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716, 2601, 2627, 2616, 2528, 2582, 2625]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651, 8680, 8677, 8699, 8770, 8704, 8680]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878, 865, 876, 844, 795, 843, 854]\n",
            "====================\n",
            "[197,    60] loss: 0.044\n",
            "[197,   120] loss: 0.033\n",
            "[197,   180] loss: 0.037\n",
            "[197,   240] loss: 0.030\n",
            "[198,    60] loss: 0.028\n",
            "[198,   120] loss: 0.038\n",
            "[198,   180] loss: 0.036\n",
            "[198,   240] loss: 0.037\n",
            "[199,    60] loss: 0.050\n",
            "[199,   120] loss: 0.041\n",
            "[199,   180] loss: 0.034\n",
            "[199,   240] loss: 0.026\n",
            "[200,    60] loss: 0.030\n",
            "[200,   120] loss: 0.040\n",
            "[200,   180] loss: 0.040\n",
            "[200,   240] loss: 0.049\n",
            "[201,    60] loss: 0.051\n",
            "[201,   120] loss: 0.042\n",
            "[201,   180] loss: 0.053\n",
            "[201,   240] loss: 0.053\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020, 27156, 27159, 27149, 27272, 27230, 27197, 27053]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716, 2601, 2627, 2616, 2528, 2582, 2625, 2673]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651, 8680, 8677, 8699, 8770, 8704, 8680, 8613]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878, 865, 876, 844, 795, 843, 854, 910]\n",
            "====================\n",
            "[202,    60] loss: 0.047\n",
            "[202,   120] loss: 0.048\n",
            "[202,   180] loss: 0.040\n",
            "[202,   240] loss: 0.061\n",
            "[203,    60] loss: 0.049\n",
            "[203,   120] loss: 0.048\n",
            "[203,   180] loss: 0.043\n",
            "[203,   240] loss: 0.047\n",
            "[204,    60] loss: 0.035\n",
            "[204,   120] loss: 0.042\n",
            "[204,   180] loss: 0.042\n",
            "[204,   240] loss: 0.033\n",
            "[205,    60] loss: 0.030\n",
            "[205,   120] loss: 0.038\n",
            "[205,   180] loss: 0.022\n",
            "[205,   240] loss: 0.044\n",
            "[206,    60] loss: 0.046\n",
            "[206,   120] loss: 0.034\n",
            "[206,   180] loss: 0.036\n",
            "[206,   240] loss: 0.038\n",
            "====================\n",
            "Train FTPT :  [1698, 3350, 7642, 14596, 17279, 19102, 20403, 21549, 22674, 23204, 23751, 24517, 24607, 25018, 25469, 25303, 25837, 26096, 26262, 26355, 26255, 26523, 26486, 26565, 26436, 26750, 26869, 26929, 26801, 26906, 26811, 26841, 26987, 26955, 27020, 27156, 27159, 27149, 27272, 27230, 27197, 27053, 27224]\n",
            "Train FFPT :  [12425, 11229, 9430, 6698, 5949, 5492, 5108, 4631, 4400, 4167, 4126, 3847, 3857, 3663, 3431, 3520, 3284, 3241, 3162, 3123, 3142, 3005, 3036, 2968, 3017, 2889, 2819, 2787, 2859, 2795, 2833, 2814, 2725, 2767, 2716, 2601, 2627, 2616, 2528, 2582, 2625, 2673, 2565]\n",
            "Test FTPT :  [555, 1482, 1676, 5002, 5641, 6420, 6715, 6799, 7282, 7473, 7636, 7957, 8051, 8043, 8060, 8129, 8243, 8339, 8447, 8490, 8434, 8497, 8486, 8444, 8477, 8605, 8651, 8596, 8663, 8659, 8652, 8601, 8657, 8642, 8651, 8680, 8677, 8699, 8770, 8704, 8680, 8613, 8739]\n",
            "Test FFPT :  [4223, 3520, 3539, 2251, 1935, 1735, 1536, 1658, 1414, 1346, 1332, 1148, 1108, 1131, 1096, 1113, 1066, 1028, 939, 922, 965, 924, 943, 993, 966, 886, 872, 925, 861, 882, 881, 892, 867, 887, 878, 865, 876, 844, 795, 843, 854, 910, 801]\n",
            "====================\n",
            "[207,    60] loss: 0.032\n",
            "[207,   120] loss: 0.034\n",
            "[207,   180] loss: 0.033\n",
            "[207,   240] loss: 0.027\n",
            "[208,    60] loss: 0.031\n",
            "[208,   120] loss: 0.024\n",
            "[208,   180] loss: 0.037\n",
            "[208,   240] loss: 0.035\n",
            "[209,    60] loss: 0.039\n",
            "[209,   120] loss: 0.025\n",
            "[209,   180] loss: 0.037\n",
            "[209,   240] loss: 0.026\n",
            "[210,    60] loss: 0.034\n",
            "[210,   120] loss: 0.026\n",
            "[210,   180] loss: 0.038\n",
            "[210,   240] loss: 0.036\n",
            "[211,    60] loss: 0.026\n",
            "[211,   120] loss: 0.030\n",
            "[211,   180] loss: 0.027\n",
            "[211,   240] loss: 0.036\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYD8ohJ8fkBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7392312d-2b26-402c-b987-e99760669ec2"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)\n",
        "  break"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToKa651tMtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14e06828-3a9e-459a-bc6b-5146fd64718d"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0309,  0.1087,  0.1955],\n",
            "          [ 0.2209,  0.0076,  0.0348],\n",
            "          [-0.0854,  0.0774, -0.0973]],\n",
            "\n",
            "         [[ 0.0616, -0.1282,  0.2080],\n",
            "          [ 0.0332, -0.1826, -0.1365],\n",
            "          [-0.1557, -0.0844, -0.1973]],\n",
            "\n",
            "         [[-0.0722,  0.0364,  0.1260],\n",
            "          [ 0.0611, -0.0341,  0.1729],\n",
            "          [ 0.0427,  0.0797,  0.0223]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1835,  0.0366, -0.1656],\n",
            "          [-0.0834,  0.1659,  0.0364],\n",
            "          [ 0.1062,  0.2152,  0.1314]],\n",
            "\n",
            "         [[ 0.0086,  0.2094,  0.2249],\n",
            "          [-0.1404, -0.1745,  0.0035],\n",
            "          [-0.2156,  0.0847,  0.0851]],\n",
            "\n",
            "         [[-0.1070,  0.1605, -0.1541],\n",
            "          [-0.0419, -0.0417,  0.0718],\n",
            "          [-0.0668, -0.2273, -0.2890]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1013,  0.0165, -0.0829],\n",
            "          [-0.1709,  0.1888, -0.0619],\n",
            "          [-0.0676,  0.2545,  0.2560]],\n",
            "\n",
            "         [[-0.0495, -0.0233, -0.0692],\n",
            "          [ 0.0196, -0.1944, -0.2639],\n",
            "          [-0.2429,  0.0565,  0.1495]],\n",
            "\n",
            "         [[ 0.2412, -0.1480, -0.1188],\n",
            "          [ 0.0755,  0.0533, -0.1636],\n",
            "          [ 0.1195,  0.0296, -0.0620]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2049,  0.1405, -0.0744],\n",
            "          [ 0.0715,  0.0253,  0.0548],\n",
            "          [-0.0363, -0.0603, -0.0169]],\n",
            "\n",
            "         [[ 0.1719, -0.0024,  0.1642],\n",
            "          [ 0.0824, -0.1403,  0.0444],\n",
            "          [ 0.1660, -0.0140, -0.0213]],\n",
            "\n",
            "         [[-0.1377,  0.0023,  0.0830],\n",
            "          [-0.0201,  0.0463, -0.1071],\n",
            "          [-0.0089, -0.0475,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1722, -0.1703,  0.0900],\n",
            "          [-0.0026, -0.1981, -0.0808],\n",
            "          [-0.0556, -0.0525, -0.0903]],\n",
            "\n",
            "         [[ 0.0469,  0.1535,  0.1791],\n",
            "          [ 0.0031, -0.1002,  0.1474],\n",
            "          [-0.2295,  0.1191,  0.0080]],\n",
            "\n",
            "         [[ 0.1878,  0.0110,  0.1277],\n",
            "          [ 0.0146,  0.1758,  0.1353],\n",
            "          [-0.1670,  0.1439, -0.0813]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1690,  0.1051, -0.0433],\n",
            "          [-0.2494,  0.0010,  0.0629],\n",
            "          [-0.0552,  0.0004,  0.0097]],\n",
            "\n",
            "         [[ 0.1635,  0.3134,  0.0763],\n",
            "          [-0.1233,  0.0560, -0.2310],\n",
            "          [-0.1199, -0.2663, -0.0928]],\n",
            "\n",
            "         [[ 0.0838,  0.1768,  0.0256],\n",
            "          [-0.2400,  0.1630, -0.2009],\n",
            "          [ 0.0774, -0.0150,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1059,  0.0585, -0.1707],\n",
            "          [ 0.1078, -0.0531, -0.0276],\n",
            "          [ 0.1118, -0.0519, -0.1506]],\n",
            "\n",
            "         [[-0.1614,  0.1542, -0.1130],\n",
            "          [ 0.1823,  0.1833,  0.1834],\n",
            "          [ 0.0840, -0.0238,  0.0096]],\n",
            "\n",
            "         [[ 0.1863,  0.0509, -0.1148],\n",
            "          [-0.0720,  0.1801, -0.0417],\n",
            "          [ 0.0088,  0.0210, -0.0527]]],\n",
            "\n",
            "\n",
            "        [[[-0.0021, -0.1920, -0.1925],\n",
            "          [-0.0794, -0.1094, -0.1952],\n",
            "          [ 0.0640, -0.1527, -0.1590]],\n",
            "\n",
            "         [[ 0.0023, -0.0093,  0.0917],\n",
            "          [ 0.1893,  0.1771, -0.0419],\n",
            "          [ 0.1959,  0.0765, -0.1216]],\n",
            "\n",
            "         [[ 0.1127, -0.0509, -0.0890],\n",
            "          [ 0.0425, -0.0004,  0.0970],\n",
            "          [ 0.1725, -0.0294,  0.2238]]],\n",
            "\n",
            "\n",
            "        [[[-0.1533,  0.2030, -0.1170],\n",
            "          [ 0.0515, -0.0504, -0.1635],\n",
            "          [-0.1322, -0.1429,  0.1475]],\n",
            "\n",
            "         [[ 0.0555, -0.0411,  0.2137],\n",
            "          [-0.0274, -0.0902,  0.0513],\n",
            "          [ 0.0085, -0.1591,  0.1483]],\n",
            "\n",
            "         [[ 0.1163, -0.1371,  0.0318],\n",
            "          [ 0.0841, -0.2464, -0.2148],\n",
            "          [ 0.0637,  0.1322,  0.0676]]],\n",
            "\n",
            "\n",
            "        [[[-0.0227,  0.0487,  0.2023],\n",
            "          [-0.1330,  0.1492, -0.0169],\n",
            "          [ 0.1584,  0.1524, -0.0456]],\n",
            "\n",
            "         [[-0.0525, -0.1646, -0.0814],\n",
            "          [-0.2456, -0.1350,  0.0154],\n",
            "          [ 0.2309, -0.1780, -0.0720]],\n",
            "\n",
            "         [[-0.0142,  0.0480,  0.2516],\n",
            "          [-0.1593,  0.1562,  0.1928],\n",
            "          [-0.1119, -0.2044, -0.1976]]],\n",
            "\n",
            "\n",
            "        [[[-0.0355,  0.1166, -0.0631],\n",
            "          [-0.0836, -0.1515,  0.1577],\n",
            "          [ 0.0235,  0.1110, -0.0250]],\n",
            "\n",
            "         [[-0.2114,  0.1654,  0.2484],\n",
            "          [ 0.0525,  0.2583,  0.0362],\n",
            "          [-0.0713,  0.1357, -0.0152]],\n",
            "\n",
            "         [[-0.0821, -0.0350, -0.1481],\n",
            "          [-0.2171,  0.0489,  0.2106],\n",
            "          [ 0.1037, -0.1230,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.1625,  0.1384],\n",
            "          [-0.1124, -0.1412,  0.2642],\n",
            "          [ 0.0284, -0.0494, -0.0447]],\n",
            "\n",
            "         [[ 0.0205, -0.2302,  0.1754],\n",
            "          [ 0.0924, -0.2460,  0.2219],\n",
            "          [ 0.0863, -0.1062,  0.1210]],\n",
            "\n",
            "         [[ 0.2537, -0.2292, -0.1540],\n",
            "          [ 0.2104, -0.2362,  0.1700],\n",
            "          [ 0.2093, -0.2085, -0.0309]]],\n",
            "\n",
            "\n",
            "        [[[-0.1426,  0.1824, -0.2160],\n",
            "          [ 0.0009, -0.0087,  0.0207],\n",
            "          [ 0.0911, -0.2336, -0.1702]],\n",
            "\n",
            "         [[ 0.2153,  0.1894,  0.0243],\n",
            "          [-0.2433,  0.2294,  0.2479],\n",
            "          [-0.0595, -0.1203,  0.1227]],\n",
            "\n",
            "         [[-0.1597,  0.1976, -0.1576],\n",
            "          [-0.1258, -0.0205, -0.1531],\n",
            "          [ 0.1347,  0.0364, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[-0.0633, -0.0466, -0.0325],\n",
            "          [-0.0601,  0.0621, -0.0215],\n",
            "          [-0.0044, -0.0534,  0.0422]],\n",
            "\n",
            "         [[-0.1383, -0.1374, -0.1793],\n",
            "          [-0.0877, -0.1327,  0.0918],\n",
            "          [-0.0787,  0.0740, -0.0112]],\n",
            "\n",
            "         [[ 0.0814,  0.0275, -0.1438],\n",
            "          [-0.0439,  0.1876,  0.1383],\n",
            "          [-0.0834,  0.1108,  0.0304]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0447,  0.0499, -0.1449],\n",
            "          [-0.1171, -0.0733,  0.0182],\n",
            "          [-0.0587, -0.1367, -0.1931]],\n",
            "\n",
            "         [[ 0.0961,  0.0888, -0.0784],\n",
            "          [ 0.0504, -0.1259,  0.0890],\n",
            "          [-0.1473,  0.0371,  0.1020]],\n",
            "\n",
            "         [[ 0.0476, -0.1709, -0.0371],\n",
            "          [ 0.2308,  0.1298,  0.0326],\n",
            "          [-0.0171, -0.0634, -0.1609]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2378, -0.1200, -0.2246],\n",
            "          [ 0.2465,  0.0634, -0.1682],\n",
            "          [-0.0573, -0.1788,  0.0856]],\n",
            "\n",
            "         [[ 0.2020,  0.1478, -0.0181],\n",
            "          [ 0.1683,  0.0819, -0.0775],\n",
            "          [ 0.1869, -0.2327, -0.2108]],\n",
            "\n",
            "         [[-0.0383, -0.1762, -0.0893],\n",
            "          [-0.1869,  0.0115,  0.0917],\n",
            "          [ 0.0562, -0.0899,  0.1009]]],\n",
            "\n",
            "\n",
            "        [[[-0.0911, -0.2512,  0.0277],\n",
            "          [-0.0324,  0.1520,  0.2214],\n",
            "          [ 0.1329, -0.0946,  0.1157]],\n",
            "\n",
            "         [[ 0.1063, -0.1710,  0.0471],\n",
            "          [-0.1126,  0.1777,  0.2435],\n",
            "          [-0.1798,  0.0235,  0.1735]],\n",
            "\n",
            "         [[ 0.0092, -0.1809,  0.0974],\n",
            "          [ 0.1691, -0.1317,  0.1264],\n",
            "          [-0.1224, -0.1659, -0.2023]]],\n",
            "\n",
            "\n",
            "        [[[-0.2336,  0.2346,  0.0983],\n",
            "          [-0.1950, -0.1840,  0.1690],\n",
            "          [-0.2168,  0.0477,  0.0916]],\n",
            "\n",
            "         [[-0.0561,  0.1103,  0.0033],\n",
            "          [-0.0990, -0.2062, -0.0978],\n",
            "          [ 0.1411, -0.0397,  0.0443]],\n",
            "\n",
            "         [[ 0.1579,  0.1184, -0.1102],\n",
            "          [ 0.1775,  0.0325, -0.1486],\n",
            "          [-0.0702,  0.2019,  0.1233]]],\n",
            "\n",
            "\n",
            "        [[[-0.0797,  0.1350,  0.1679],\n",
            "          [-0.0473,  0.2595,  0.1358],\n",
            "          [-0.2849, -0.0974, -0.0081]],\n",
            "\n",
            "         [[-0.1065, -0.1424, -0.1542],\n",
            "          [-0.2096,  0.1828,  0.1126],\n",
            "          [ 0.0174,  0.0576, -0.0152]],\n",
            "\n",
            "         [[-0.2226,  0.0298, -0.1312],\n",
            "          [-0.1327,  0.2087,  0.1935],\n",
            "          [-0.0249,  0.0243, -0.0377]]],\n",
            "\n",
            "\n",
            "        [[[-0.0588,  0.1742,  0.2010],\n",
            "          [ 0.1427, -0.0923,  0.0899],\n",
            "          [-0.1261, -0.1139, -0.0786]],\n",
            "\n",
            "         [[-0.1481,  0.0529,  0.0481],\n",
            "          [ 0.0126, -0.0323,  0.1211],\n",
            "          [-0.0912, -0.0420, -0.1293]],\n",
            "\n",
            "         [[-0.2270, -0.2813, -0.1512],\n",
            "          [ 0.0183, -0.0734, -0.0467],\n",
            "          [ 0.1668,  0.1287,  0.1416]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1385,  0.0580,  0.3274],\n",
            "          [-0.0714, -0.0263,  0.2946],\n",
            "          [-0.2355, -0.3553,  0.0437]],\n",
            "\n",
            "         [[ 0.0762, -0.1933, -0.1612],\n",
            "          [-0.1279,  0.0055, -0.0561],\n",
            "          [ 0.2241, -0.0410,  0.1810]],\n",
            "\n",
            "         [[ 0.1535, -0.1441, -0.1855],\n",
            "          [ 0.2696, -0.1765,  0.0269],\n",
            "          [ 0.2909, -0.1872, -0.1417]]],\n",
            "\n",
            "\n",
            "        [[[-0.1353, -0.0778,  0.2160],\n",
            "          [-0.2453,  0.0684,  0.2713],\n",
            "          [ 0.0924,  0.0206,  0.2311]],\n",
            "\n",
            "         [[-0.1599,  0.0515, -0.0479],\n",
            "          [-0.1464, -0.0211,  0.0214],\n",
            "          [-0.1591, -0.0081, -0.1259]],\n",
            "\n",
            "         [[-0.0057,  0.1981, -0.0700],\n",
            "          [-0.1581,  0.2080,  0.0793],\n",
            "          [-0.2191,  0.0567,  0.0142]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2331, -0.0791, -0.0360],\n",
            "          [ 0.0551, -0.1573, -0.1605],\n",
            "          [ 0.1258, -0.0884, -0.2061]],\n",
            "\n",
            "         [[-0.2222,  0.1591,  0.1350],\n",
            "          [-0.1694, -0.0935,  0.0388],\n",
            "          [-0.0330,  0.1814,  0.0005]],\n",
            "\n",
            "         [[-0.1377, -0.0267,  0.1763],\n",
            "          [-0.2532,  0.2026,  0.1464],\n",
            "          [-0.0366,  0.2414, -0.1755]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0655, -0.1766, -0.2965],\n",
            "          [ 0.0635, -0.1370,  0.2211],\n",
            "          [ 0.0251, -0.0315,  0.2027]],\n",
            "\n",
            "         [[ 0.2559, -0.1553, -0.1362],\n",
            "          [ 0.2658, -0.1706,  0.1501],\n",
            "          [-0.1731, -0.0166, -0.0638]],\n",
            "\n",
            "         [[-0.1674,  0.0792,  0.1900],\n",
            "          [-0.0342, -0.2272,  0.2679],\n",
            "          [-0.0845, -0.0639,  0.0261]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0958,  0.0557, -0.0319],\n",
            "          [ 0.1302, -0.0530, -0.2087],\n",
            "          [ 0.0320,  0.1967, -0.1969]],\n",
            "\n",
            "         [[ 0.1327, -0.1589,  0.1865],\n",
            "          [-0.0338, -0.2036, -0.2538],\n",
            "          [ 0.1661,  0.1607,  0.1042]],\n",
            "\n",
            "         [[-0.2442, -0.0128, -0.1746],\n",
            "          [-0.0988,  0.0191, -0.2384],\n",
            "          [-0.1124,  0.2998,  0.2225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1305, -0.0375, -0.0713],\n",
            "          [-0.0881,  0.0315, -0.0487],\n",
            "          [-0.1159, -0.0198, -0.0042]],\n",
            "\n",
            "         [[-0.1895,  0.1779, -0.0391],\n",
            "          [ 0.1096, -0.0229,  0.0431],\n",
            "          [ 0.1912, -0.0880,  0.1516]],\n",
            "\n",
            "         [[ 0.1237,  0.1648,  0.0864],\n",
            "          [ 0.1106, -0.1358, -0.0593],\n",
            "          [ 0.0834,  0.1760, -0.1148]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0261,  0.0946, -0.2135],\n",
            "          [-0.0508, -0.2134, -0.0804],\n",
            "          [ 0.2161,  0.1251,  0.1160]],\n",
            "\n",
            "         [[ 0.2439,  0.1499,  0.0541],\n",
            "          [-0.1242, -0.3017, -0.1642],\n",
            "          [ 0.1484,  0.0228, -0.0532]],\n",
            "\n",
            "         [[ 0.2827,  0.0027,  0.2216],\n",
            "          [-0.2123, -0.1097, -0.0140],\n",
            "          [-0.1472, -0.1401,  0.1451]]],\n",
            "\n",
            "\n",
            "        [[[-0.0668, -0.0305, -0.1276],\n",
            "          [-0.0389,  0.0897,  0.0144],\n",
            "          [ 0.0437, -0.0369,  0.2345]],\n",
            "\n",
            "         [[ 0.0160, -0.0964, -0.1077],\n",
            "          [ 0.1918,  0.2170,  0.1363],\n",
            "          [-0.1928, -0.0407,  0.0342]],\n",
            "\n",
            "         [[-0.0021, -0.0420,  0.0836],\n",
            "          [ 0.0767,  0.0022,  0.0412],\n",
            "          [-0.1141, -0.0197,  0.0672]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1341, -0.0483, -0.1076],\n",
            "          [-0.1852, -0.0061,  0.0918],\n",
            "          [-0.1238,  0.0374, -0.0902]],\n",
            "\n",
            "         [[ 0.1261, -0.0141, -0.0833],\n",
            "          [-0.1273, -0.2019, -0.1387],\n",
            "          [-0.0098,  0.2122, -0.0161]],\n",
            "\n",
            "         [[ 0.1478,  0.0007, -0.0934],\n",
            "          [-0.1233,  0.0490,  0.0353],\n",
            "          [ 0.2064, -0.1164,  0.1303]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0583, -0.1114,  0.2957],\n",
            "          [ 0.1703, -0.0507,  0.0694],\n",
            "          [-0.1846,  0.1098, -0.1668]],\n",
            "\n",
            "         [[-0.2051, -0.2725, -0.0990],\n",
            "          [-0.1666,  0.0620, -0.0992],\n",
            "          [ 0.1796,  0.0437, -0.2720]],\n",
            "\n",
            "         [[ 0.1627, -0.1647, -0.0541],\n",
            "          [ 0.0633,  0.2490, -0.1993],\n",
            "          [ 0.1262,  0.2773,  0.0247]]],\n",
            "\n",
            "\n",
            "        [[[-0.2300, -0.1971, -0.0127],\n",
            "          [ 0.0639,  0.0679, -0.0152],\n",
            "          [ 0.2227, -0.0215, -0.0974]],\n",
            "\n",
            "         [[-0.2116, -0.0484,  0.1070],\n",
            "          [ 0.1198, -0.1068, -0.0113],\n",
            "          [ 0.1952,  0.0198,  0.0825]],\n",
            "\n",
            "         [[-0.3352,  0.1302,  0.0801],\n",
            "          [ 0.1699,  0.1231,  0.0742],\n",
            "          [ 0.0210, -0.1424,  0.0352]]],\n",
            "\n",
            "\n",
            "        [[[-0.0857,  0.1421,  0.1182],\n",
            "          [ 0.1262,  0.2026,  0.1068],\n",
            "          [ 0.0704, -0.0585, -0.0306]],\n",
            "\n",
            "         [[ 0.1038, -0.1139,  0.0915],\n",
            "          [ 0.1529,  0.1774, -0.1306],\n",
            "          [-0.2282, -0.2159,  0.0512]],\n",
            "\n",
            "         [[-0.1076, -0.1626,  0.0314],\n",
            "          [-0.1577,  0.1472,  0.1330],\n",
            "          [ 0.1294, -0.0155, -0.0551]]]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"11_focus_random_classify_pretrained_train_focus\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn/\"+name+\".pt\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea3e0ff3-0270-430c-be5b-59b2d9f58011"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>1698</td>\n",
              "      <td>12425</td>\n",
              "      <td>1832</td>\n",
              "      <td>14045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>29969</td>\n",
              "      <td>3350</td>\n",
              "      <td>11229</td>\n",
              "      <td>2639</td>\n",
              "      <td>12782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>4808</td>\n",
              "      <td>25192</td>\n",
              "      <td>7642</td>\n",
              "      <td>9430</td>\n",
              "      <td>1968</td>\n",
              "      <td>10960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>11569</td>\n",
              "      <td>18431</td>\n",
              "      <td>14596</td>\n",
              "      <td>6698</td>\n",
              "      <td>1712</td>\n",
              "      <td>6994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>14522</td>\n",
              "      <td>15478</td>\n",
              "      <td>17279</td>\n",
              "      <td>5949</td>\n",
              "      <td>1560</td>\n",
              "      <td>5212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>18297</td>\n",
              "      <td>11703</td>\n",
              "      <td>19102</td>\n",
              "      <td>5492</td>\n",
              "      <td>1247</td>\n",
              "      <td>4159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>21240</td>\n",
              "      <td>8760</td>\n",
              "      <td>20403</td>\n",
              "      <td>5108</td>\n",
              "      <td>982</td>\n",
              "      <td>3507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>22961</td>\n",
              "      <td>7039</td>\n",
              "      <td>21549</td>\n",
              "      <td>4631</td>\n",
              "      <td>851</td>\n",
              "      <td>2969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>23791</td>\n",
              "      <td>6209</td>\n",
              "      <td>22674</td>\n",
              "      <td>4400</td>\n",
              "      <td>677</td>\n",
              "      <td>2249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>25400</td>\n",
              "      <td>4600</td>\n",
              "      <td>23204</td>\n",
              "      <td>4167</td>\n",
              "      <td>496</td>\n",
              "      <td>2133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>25028</td>\n",
              "      <td>4972</td>\n",
              "      <td>23751</td>\n",
              "      <td>4126</td>\n",
              "      <td>464</td>\n",
              "      <td>1659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>51</td>\n",
              "      <td>25653</td>\n",
              "      <td>4347</td>\n",
              "      <td>24517</td>\n",
              "      <td>3847</td>\n",
              "      <td>342</td>\n",
              "      <td>1294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>56</td>\n",
              "      <td>25806</td>\n",
              "      <td>4194</td>\n",
              "      <td>24607</td>\n",
              "      <td>3857</td>\n",
              "      <td>342</td>\n",
              "      <td>1194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>61</td>\n",
              "      <td>26282</td>\n",
              "      <td>3718</td>\n",
              "      <td>25018</td>\n",
              "      <td>3663</td>\n",
              "      <td>270</td>\n",
              "      <td>1049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>66</td>\n",
              "      <td>26548</td>\n",
              "      <td>3452</td>\n",
              "      <td>25469</td>\n",
              "      <td>3431</td>\n",
              "      <td>220</td>\n",
              "      <td>880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>71</td>\n",
              "      <td>26491</td>\n",
              "      <td>3509</td>\n",
              "      <td>25303</td>\n",
              "      <td>3520</td>\n",
              "      <td>240</td>\n",
              "      <td>937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>76</td>\n",
              "      <td>27151</td>\n",
              "      <td>2849</td>\n",
              "      <td>25837</td>\n",
              "      <td>3284</td>\n",
              "      <td>167</td>\n",
              "      <td>712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>81</td>\n",
              "      <td>26970</td>\n",
              "      <td>3030</td>\n",
              "      <td>26096</td>\n",
              "      <td>3241</td>\n",
              "      <td>121</td>\n",
              "      <td>542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>86</td>\n",
              "      <td>27197</td>\n",
              "      <td>2803</td>\n",
              "      <td>26262</td>\n",
              "      <td>3162</td>\n",
              "      <td>102</td>\n",
              "      <td>474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>91</td>\n",
              "      <td>27005</td>\n",
              "      <td>2995</td>\n",
              "      <td>26355</td>\n",
              "      <td>3123</td>\n",
              "      <td>102</td>\n",
              "      <td>420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>96</td>\n",
              "      <td>27205</td>\n",
              "      <td>2795</td>\n",
              "      <td>26255</td>\n",
              "      <td>3142</td>\n",
              "      <td>124</td>\n",
              "      <td>479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>101</td>\n",
              "      <td>27263</td>\n",
              "      <td>2737</td>\n",
              "      <td>26523</td>\n",
              "      <td>3005</td>\n",
              "      <td>88</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>106</td>\n",
              "      <td>27473</td>\n",
              "      <td>2527</td>\n",
              "      <td>26486</td>\n",
              "      <td>3036</td>\n",
              "      <td>107</td>\n",
              "      <td>371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>111</td>\n",
              "      <td>27603</td>\n",
              "      <td>2397</td>\n",
              "      <td>26565</td>\n",
              "      <td>2968</td>\n",
              "      <td>78</td>\n",
              "      <td>389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>116</td>\n",
              "      <td>27391</td>\n",
              "      <td>2609</td>\n",
              "      <td>26436</td>\n",
              "      <td>3017</td>\n",
              "      <td>95</td>\n",
              "      <td>452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>121</td>\n",
              "      <td>27488</td>\n",
              "      <td>2512</td>\n",
              "      <td>26750</td>\n",
              "      <td>2889</td>\n",
              "      <td>65</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>126</td>\n",
              "      <td>27656</td>\n",
              "      <td>2344</td>\n",
              "      <td>26869</td>\n",
              "      <td>2819</td>\n",
              "      <td>60</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>131</td>\n",
              "      <td>27800</td>\n",
              "      <td>2200</td>\n",
              "      <td>26929</td>\n",
              "      <td>2787</td>\n",
              "      <td>55</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>136</td>\n",
              "      <td>27712</td>\n",
              "      <td>2288</td>\n",
              "      <td>26801</td>\n",
              "      <td>2859</td>\n",
              "      <td>71</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>141</td>\n",
              "      <td>27820</td>\n",
              "      <td>2180</td>\n",
              "      <td>26906</td>\n",
              "      <td>2795</td>\n",
              "      <td>60</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>146</td>\n",
              "      <td>27658</td>\n",
              "      <td>2342</td>\n",
              "      <td>26811</td>\n",
              "      <td>2833</td>\n",
              "      <td>69</td>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>151</td>\n",
              "      <td>27506</td>\n",
              "      <td>2494</td>\n",
              "      <td>26841</td>\n",
              "      <td>2814</td>\n",
              "      <td>72</td>\n",
              "      <td>273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>156</td>\n",
              "      <td>27725</td>\n",
              "      <td>2275</td>\n",
              "      <td>26987</td>\n",
              "      <td>2725</td>\n",
              "      <td>60</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>161</td>\n",
              "      <td>27665</td>\n",
              "      <td>2335</td>\n",
              "      <td>26955</td>\n",
              "      <td>2767</td>\n",
              "      <td>51</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>166</td>\n",
              "      <td>27689</td>\n",
              "      <td>2311</td>\n",
              "      <td>27020</td>\n",
              "      <td>2716</td>\n",
              "      <td>57</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>171</td>\n",
              "      <td>27563</td>\n",
              "      <td>2437</td>\n",
              "      <td>27156</td>\n",
              "      <td>2601</td>\n",
              "      <td>51</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>176</td>\n",
              "      <td>27953</td>\n",
              "      <td>2047</td>\n",
              "      <td>27159</td>\n",
              "      <td>2627</td>\n",
              "      <td>36</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>181</td>\n",
              "      <td>27787</td>\n",
              "      <td>2213</td>\n",
              "      <td>27149</td>\n",
              "      <td>2616</td>\n",
              "      <td>45</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>186</td>\n",
              "      <td>28052</td>\n",
              "      <td>1948</td>\n",
              "      <td>27272</td>\n",
              "      <td>2528</td>\n",
              "      <td>31</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>191</td>\n",
              "      <td>27748</td>\n",
              "      <td>2252</td>\n",
              "      <td>27230</td>\n",
              "      <td>2582</td>\n",
              "      <td>35</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>196</td>\n",
              "      <td>27644</td>\n",
              "      <td>2356</td>\n",
              "      <td>27197</td>\n",
              "      <td>2625</td>\n",
              "      <td>33</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>201</td>\n",
              "      <td>27600</td>\n",
              "      <td>2400</td>\n",
              "      <td>27053</td>\n",
              "      <td>2673</td>\n",
              "      <td>47</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>206</td>\n",
              "      <td>27695</td>\n",
              "      <td>2305</td>\n",
              "      <td>27224</td>\n",
              "      <td>2565</td>\n",
              "      <td>38</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0             0  ...                   1832                   14045\n",
              "1        1            31  ...                   2639                   12782\n",
              "2        6          4808  ...                   1968                   10960\n",
              "3       11         11569  ...                   1712                    6994\n",
              "4       16         14522  ...                   1560                    5212\n",
              "5       21         18297  ...                   1247                    4159\n",
              "6       26         21240  ...                    982                    3507\n",
              "7       31         22961  ...                    851                    2969\n",
              "8       36         23791  ...                    677                    2249\n",
              "9       41         25400  ...                    496                    2133\n",
              "10      46         25028  ...                    464                    1659\n",
              "11      51         25653  ...                    342                    1294\n",
              "12      56         25806  ...                    342                    1194\n",
              "13      61         26282  ...                    270                    1049\n",
              "14      66         26548  ...                    220                     880\n",
              "15      71         26491  ...                    240                     937\n",
              "16      76         27151  ...                    167                     712\n",
              "17      81         26970  ...                    121                     542\n",
              "18      86         27197  ...                    102                     474\n",
              "19      91         27005  ...                    102                     420\n",
              "20      96         27205  ...                    124                     479\n",
              "21     101         27263  ...                     88                     384\n",
              "22     106         27473  ...                    107                     371\n",
              "23     111         27603  ...                     78                     389\n",
              "24     116         27391  ...                     95                     452\n",
              "25     121         27488  ...                     65                     296\n",
              "26     126         27656  ...                     60                     252\n",
              "27     131         27800  ...                     55                     229\n",
              "28     136         27712  ...                     71                     269\n",
              "29     141         27820  ...                     60                     239\n",
              "30     146         27658  ...                     69                     287\n",
              "31     151         27506  ...                     72                     273\n",
              "32     156         27725  ...                     60                     228\n",
              "33     161         27665  ...                     51                     227\n",
              "34     166         27689  ...                     57                     207\n",
              "35     171         27563  ...                     51                     192\n",
              "36     176         27953  ...                     36                     178\n",
              "37     181         27787  ...                     45                     190\n",
              "38     186         28052  ...                     31                     169\n",
              "39     191         27748  ...                     35                     153\n",
              "40     196         27644  ...                     33                     145\n",
              "41     201         27600  ...                     47                     227\n",
              "42     206         27695  ...                     38                     173\n",
              "\n",
              "[43 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "8aff373d-d855-4477-e1f2-a675d5c32125"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bc6c918-c262-470c-a121-9edcee8cc69c"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>555</td>\n",
              "      <td>4223</td>\n",
              "      <td>581</td>\n",
              "      <td>4641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>1482</td>\n",
              "      <td>3520</td>\n",
              "      <td>1226</td>\n",
              "      <td>3772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>1676</td>\n",
              "      <td>3539</td>\n",
              "      <td>1102</td>\n",
              "      <td>3683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>3264</td>\n",
              "      <td>6736</td>\n",
              "      <td>5002</td>\n",
              "      <td>2251</td>\n",
              "      <td>620</td>\n",
              "      <td>2127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>4025</td>\n",
              "      <td>5975</td>\n",
              "      <td>5641</td>\n",
              "      <td>1935</td>\n",
              "      <td>654</td>\n",
              "      <td>1770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>6429</td>\n",
              "      <td>3571</td>\n",
              "      <td>6420</td>\n",
              "      <td>1735</td>\n",
              "      <td>393</td>\n",
              "      <td>1452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>6867</td>\n",
              "      <td>3133</td>\n",
              "      <td>6715</td>\n",
              "      <td>1536</td>\n",
              "      <td>382</td>\n",
              "      <td>1367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>6749</td>\n",
              "      <td>3251</td>\n",
              "      <td>6799</td>\n",
              "      <td>1658</td>\n",
              "      <td>450</td>\n",
              "      <td>1093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>8191</td>\n",
              "      <td>1809</td>\n",
              "      <td>7282</td>\n",
              "      <td>1414</td>\n",
              "      <td>263</td>\n",
              "      <td>1041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>7848</td>\n",
              "      <td>2152</td>\n",
              "      <td>7473</td>\n",
              "      <td>1346</td>\n",
              "      <td>293</td>\n",
              "      <td>888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>8211</td>\n",
              "      <td>1789</td>\n",
              "      <td>7636</td>\n",
              "      <td>1332</td>\n",
              "      <td>212</td>\n",
              "      <td>820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>51</td>\n",
              "      <td>8632</td>\n",
              "      <td>1368</td>\n",
              "      <td>7957</td>\n",
              "      <td>1148</td>\n",
              "      <td>179</td>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>56</td>\n",
              "      <td>8805</td>\n",
              "      <td>1195</td>\n",
              "      <td>8051</td>\n",
              "      <td>1108</td>\n",
              "      <td>158</td>\n",
              "      <td>683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>61</td>\n",
              "      <td>8346</td>\n",
              "      <td>1654</td>\n",
              "      <td>8043</td>\n",
              "      <td>1131</td>\n",
              "      <td>175</td>\n",
              "      <td>651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>66</td>\n",
              "      <td>8682</td>\n",
              "      <td>1318</td>\n",
              "      <td>8060</td>\n",
              "      <td>1096</td>\n",
              "      <td>156</td>\n",
              "      <td>688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>71</td>\n",
              "      <td>8634</td>\n",
              "      <td>1366</td>\n",
              "      <td>8129</td>\n",
              "      <td>1113</td>\n",
              "      <td>158</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>76</td>\n",
              "      <td>8722</td>\n",
              "      <td>1278</td>\n",
              "      <td>8243</td>\n",
              "      <td>1066</td>\n",
              "      <td>141</td>\n",
              "      <td>550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>81</td>\n",
              "      <td>8675</td>\n",
              "      <td>1325</td>\n",
              "      <td>8339</td>\n",
              "      <td>1028</td>\n",
              "      <td>142</td>\n",
              "      <td>491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>86</td>\n",
              "      <td>8955</td>\n",
              "      <td>1045</td>\n",
              "      <td>8447</td>\n",
              "      <td>939</td>\n",
              "      <td>120</td>\n",
              "      <td>494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>91</td>\n",
              "      <td>9089</td>\n",
              "      <td>911</td>\n",
              "      <td>8490</td>\n",
              "      <td>922</td>\n",
              "      <td>90</td>\n",
              "      <td>498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>96</td>\n",
              "      <td>9085</td>\n",
              "      <td>915</td>\n",
              "      <td>8434</td>\n",
              "      <td>965</td>\n",
              "      <td>113</td>\n",
              "      <td>488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>101</td>\n",
              "      <td>9106</td>\n",
              "      <td>894</td>\n",
              "      <td>8497</td>\n",
              "      <td>924</td>\n",
              "      <td>112</td>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>106</td>\n",
              "      <td>9203</td>\n",
              "      <td>797</td>\n",
              "      <td>8486</td>\n",
              "      <td>943</td>\n",
              "      <td>65</td>\n",
              "      <td>506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>111</td>\n",
              "      <td>8989</td>\n",
              "      <td>1011</td>\n",
              "      <td>8444</td>\n",
              "      <td>993</td>\n",
              "      <td>118</td>\n",
              "      <td>445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>116</td>\n",
              "      <td>8819</td>\n",
              "      <td>1181</td>\n",
              "      <td>8477</td>\n",
              "      <td>966</td>\n",
              "      <td>148</td>\n",
              "      <td>409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>121</td>\n",
              "      <td>9271</td>\n",
              "      <td>729</td>\n",
              "      <td>8605</td>\n",
              "      <td>886</td>\n",
              "      <td>99</td>\n",
              "      <td>410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>126</td>\n",
              "      <td>9253</td>\n",
              "      <td>747</td>\n",
              "      <td>8651</td>\n",
              "      <td>872</td>\n",
              "      <td>92</td>\n",
              "      <td>385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>131</td>\n",
              "      <td>9088</td>\n",
              "      <td>912</td>\n",
              "      <td>8596</td>\n",
              "      <td>925</td>\n",
              "      <td>92</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>136</td>\n",
              "      <td>9127</td>\n",
              "      <td>873</td>\n",
              "      <td>8663</td>\n",
              "      <td>861</td>\n",
              "      <td>113</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>141</td>\n",
              "      <td>9077</td>\n",
              "      <td>923</td>\n",
              "      <td>8659</td>\n",
              "      <td>882</td>\n",
              "      <td>81</td>\n",
              "      <td>378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>146</td>\n",
              "      <td>9236</td>\n",
              "      <td>764</td>\n",
              "      <td>8652</td>\n",
              "      <td>881</td>\n",
              "      <td>74</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>151</td>\n",
              "      <td>9250</td>\n",
              "      <td>750</td>\n",
              "      <td>8601</td>\n",
              "      <td>892</td>\n",
              "      <td>76</td>\n",
              "      <td>431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>156</td>\n",
              "      <td>9193</td>\n",
              "      <td>807</td>\n",
              "      <td>8657</td>\n",
              "      <td>867</td>\n",
              "      <td>94</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>161</td>\n",
              "      <td>8972</td>\n",
              "      <td>1028</td>\n",
              "      <td>8642</td>\n",
              "      <td>887</td>\n",
              "      <td>97</td>\n",
              "      <td>374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>166</td>\n",
              "      <td>8980</td>\n",
              "      <td>1020</td>\n",
              "      <td>8651</td>\n",
              "      <td>878</td>\n",
              "      <td>99</td>\n",
              "      <td>372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>171</td>\n",
              "      <td>9129</td>\n",
              "      <td>871</td>\n",
              "      <td>8680</td>\n",
              "      <td>865</td>\n",
              "      <td>79</td>\n",
              "      <td>376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>176</td>\n",
              "      <td>9115</td>\n",
              "      <td>885</td>\n",
              "      <td>8677</td>\n",
              "      <td>876</td>\n",
              "      <td>76</td>\n",
              "      <td>371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>181</td>\n",
              "      <td>9276</td>\n",
              "      <td>724</td>\n",
              "      <td>8699</td>\n",
              "      <td>844</td>\n",
              "      <td>81</td>\n",
              "      <td>376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>186</td>\n",
              "      <td>9298</td>\n",
              "      <td>702</td>\n",
              "      <td>8770</td>\n",
              "      <td>795</td>\n",
              "      <td>86</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>191</td>\n",
              "      <td>9161</td>\n",
              "      <td>839</td>\n",
              "      <td>8704</td>\n",
              "      <td>843</td>\n",
              "      <td>92</td>\n",
              "      <td>361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>196</td>\n",
              "      <td>8957</td>\n",
              "      <td>1043</td>\n",
              "      <td>8680</td>\n",
              "      <td>854</td>\n",
              "      <td>91</td>\n",
              "      <td>375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>201</td>\n",
              "      <td>8939</td>\n",
              "      <td>1061</td>\n",
              "      <td>8613</td>\n",
              "      <td>910</td>\n",
              "      <td>122</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>206</td>\n",
              "      <td>9167</td>\n",
              "      <td>833</td>\n",
              "      <td>8739</td>\n",
              "      <td>801</td>\n",
              "      <td>100</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0             0  ...                    581                    4641\n",
              "1        1             0  ...                   1226                    3772\n",
              "2        6             0  ...                   1102                    3683\n",
              "3       11          3264  ...                    620                    2127\n",
              "4       16          4025  ...                    654                    1770\n",
              "5       21          6429  ...                    393                    1452\n",
              "6       26          6867  ...                    382                    1367\n",
              "7       31          6749  ...                    450                    1093\n",
              "8       36          8191  ...                    263                    1041\n",
              "9       41          7848  ...                    293                     888\n",
              "10      46          8211  ...                    212                     820\n",
              "11      51          8632  ...                    179                     716\n",
              "12      56          8805  ...                    158                     683\n",
              "13      61          8346  ...                    175                     651\n",
              "14      66          8682  ...                    156                     688\n",
              "15      71          8634  ...                    158                     600\n",
              "16      76          8722  ...                    141                     550\n",
              "17      81          8675  ...                    142                     491\n",
              "18      86          8955  ...                    120                     494\n",
              "19      91          9089  ...                     90                     498\n",
              "20      96          9085  ...                    113                     488\n",
              "21     101          9106  ...                    112                     467\n",
              "22     106          9203  ...                     65                     506\n",
              "23     111          8989  ...                    118                     445\n",
              "24     116          8819  ...                    148                     409\n",
              "25     121          9271  ...                     99                     410\n",
              "26     126          9253  ...                     92                     385\n",
              "27     131          9088  ...                     92                     387\n",
              "28     136          9127  ...                    113                     363\n",
              "29     141          9077  ...                     81                     378\n",
              "30     146          9236  ...                     74                     393\n",
              "31     151          9250  ...                     76                     431\n",
              "32     156          9193  ...                     94                     382\n",
              "33     161          8972  ...                     97                     374\n",
              "34     166          8980  ...                     99                     372\n",
              "35     171          9129  ...                     79                     376\n",
              "36     176          9115  ...                     76                     371\n",
              "37     181          9276  ...                     81                     376\n",
              "38     186          9298  ...                     86                     349\n",
              "39     191          9161  ...                     92                     361\n",
              "40     196          8957  ...                     91                     375\n",
              "41     201          8939  ...                    122                     355\n",
              "42     206          9167  ...                    100                     360\n",
              "\n",
              "[43 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "bb946205-9fad-463c-a335-63f1f7a8cc24"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoV2bwMki5h9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "9a860d44-6285-40f4-9166-d891dbd36a84"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29835\n",
            "total train set images 30000\n",
            "focus_true_pred_true 27236 =============> FTPT : 90 %\n",
            "focus_false_pred_true 2599 =============> FFPT : 8 %\n",
            "focus_true_pred_false 27 =============> FTPF : 0 %\n",
            "focus_false_pred_false 138 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  27751\n",
            "argmax_less_than_half ==================>  2249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjt9XLf6jF50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "70810b39-8d7f-4f5b-8496-8010fe6a9226"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 95 %\n",
            "total correct 9552\n",
            "total train set images 10000\n",
            "focus_true_pred_true 8757 =============> FTPT : 87 %\n",
            "focus_false_pred_true 795 =============> FFPT : 7 %\n",
            "focus_true_pred_false 82 =============> FTPF : 0 %\n",
            "focus_false_pred_false 366 =============> FFPF : 3 %\n",
            "argmax_more_than_half ==================>  9066\n",
            "argmax_less_than_half ==================>  934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "bce457ae-8c06-4505-9e1b-c89060edf698"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29835\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ab5f15be-01fa-418c-8d43-1096f86ad579"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 95 %\n",
            "total correct 9566\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "725MVVfLS3et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}