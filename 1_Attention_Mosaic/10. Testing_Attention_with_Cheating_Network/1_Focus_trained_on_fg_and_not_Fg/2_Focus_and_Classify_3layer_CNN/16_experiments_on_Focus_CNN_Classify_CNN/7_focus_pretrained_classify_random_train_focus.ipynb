{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "7_focus_pretrained_classify_random_train_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c20fe8ff-9660-4090-fdb9-b8f2f7d87dd2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acRFqJNrZErV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "645fd26b-c73a-4733-a35f-0ed8b038432c"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V_JUhwCeZErk",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SadRzWBBZEsP",
        "colab": {}
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "    self.fc4 = nn.Linear(10,2)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    # print(x.shape)\n",
        "    x = (F.relu(self.conv3(x)))\n",
        "    x =  x.view(x.size(0), -1)\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90e2413b-d8f1-4ba2-f90e-56ca30af2255"
      },
      "source": [
        "focus_net.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Focus_net_weights/focus_net_3layer_cnn.pt\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuvh8egty-M8",
        "colab_type": "text"
      },
      "source": [
        "Changing the last layer of Focus net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF-WJw9Da0MM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac7ce057-f954-43d2-f0eb-9beb021f7844"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=2, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugYLSgCpyv2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "f19796be-94ec-4c41-d42b-f79f022cedfa"
      },
      "source": [
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)\n",
        "temp = focus_net.fc4.weight.data\n",
        "temp2 = focus_net.fc4.bias.data\n",
        "focus_net.fc4 = nn.Linear(10,1).double()\n",
        "focus_net.fc4.weight.data = torch.unsqueeze(temp[1,:], 0)\n",
        "focus_net.fc4.bias.data = torch.unsqueeze(temp2[1], 0)\n",
        "focus_net = focus_net.to(\"cuda\")\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3198, -0.1404,  1.5384,  0.7315, -0.1772,  0.1583, -0.2523, -0.2352,\n",
            "         -1.7105, -0.1908],\n",
            "        [ 0.3026,  0.1300, -1.6173, -0.8441,  0.0563,  0.0410,  0.1276, -0.0125,\n",
            "          1.3969, -0.2657]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1808,  0.1159], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.3026,  0.1300, -1.6173, -0.8441,  0.0563,  0.0410,  0.1276, -0.0125,\n",
            "          1.3969, -0.2657]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1159], device='cuda:0', dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnE-DYdAa4LL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87cf577c-ee3e-4158-ae12-62aff95a06ce"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=1, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uE2ecgApdwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   params.requires_grad = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0rkwoqLpya8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   print(params)\n",
        "#   break;"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "    self.fc4 = nn.Linear(10,3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    # print(x.shape)\n",
        "    x = (F.relu(self.conv3(x)))\n",
        "    x =  x.view(x.size(0), -1)\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjK7sLtEouXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for params in classify.parameters():\n",
        "  params.requires_grad = False"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWqPec7aoynC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ada7b86-8f98-478f-c43d-252bf14cc517"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-0.0767, -0.1167, -0.1786],\n",
            "          [ 0.0845,  0.0740,  0.0724],\n",
            "          [ 0.1830,  0.1433,  0.1361]],\n",
            "\n",
            "         [[ 0.0795, -0.1849, -0.0115],\n",
            "          [ 0.0375,  0.1197, -0.1259],\n",
            "          [ 0.1882, -0.1456, -0.1450]],\n",
            "\n",
            "         [[ 0.0137, -0.0685, -0.0291],\n",
            "          [ 0.0293,  0.0182, -0.1025],\n",
            "          [-0.0206, -0.0970,  0.1143]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0067, -0.0057,  0.1570],\n",
            "          [ 0.1101,  0.0524, -0.0900],\n",
            "          [ 0.1122, -0.1392, -0.0868]],\n",
            "\n",
            "         [[-0.1291, -0.1660, -0.1731],\n",
            "          [-0.0749, -0.0017, -0.0162],\n",
            "          [-0.0656,  0.0766,  0.1224]],\n",
            "\n",
            "         [[ 0.0884, -0.0457, -0.1225],\n",
            "          [ 0.0090, -0.0917, -0.0510],\n",
            "          [-0.0979, -0.0951, -0.0878]]],\n",
            "\n",
            "\n",
            "        [[[-0.1204,  0.1765,  0.0156],\n",
            "          [ 0.0790, -0.1805,  0.0856],\n",
            "          [ 0.0881,  0.1273, -0.0795]],\n",
            "\n",
            "         [[ 0.0159, -0.1554,  0.1770],\n",
            "          [-0.1891, -0.0219,  0.0270],\n",
            "          [-0.0111,  0.0171, -0.0621]],\n",
            "\n",
            "         [[ 0.0207,  0.0763,  0.0747],\n",
            "          [-0.0644,  0.1493,  0.1329],\n",
            "          [-0.1816, -0.0640,  0.1794]]],\n",
            "\n",
            "\n",
            "        [[[-0.1524,  0.0172,  0.0274],\n",
            "          [ 0.0982, -0.0972, -0.1674],\n",
            "          [-0.1571,  0.0451,  0.1385]],\n",
            "\n",
            "         [[-0.0103, -0.0953,  0.1810],\n",
            "          [-0.1566,  0.0045,  0.0375],\n",
            "          [-0.0174, -0.0983,  0.1681]],\n",
            "\n",
            "         [[ 0.1803,  0.1817, -0.0720],\n",
            "          [ 0.0527, -0.0455, -0.0123],\n",
            "          [ 0.0144,  0.0420, -0.1591]]],\n",
            "\n",
            "\n",
            "        [[[-0.1184, -0.1595,  0.0232],\n",
            "          [ 0.1290,  0.1356,  0.0422],\n",
            "          [-0.1865, -0.0548, -0.1197]],\n",
            "\n",
            "         [[ 0.1551,  0.1854,  0.1287],\n",
            "          [-0.0265, -0.0829,  0.1450],\n",
            "          [-0.1746, -0.0701,  0.1438]],\n",
            "\n",
            "         [[-0.0228, -0.1391, -0.0158],\n",
            "          [ 0.0927, -0.0417,  0.1887],\n",
            "          [-0.0741,  0.1167, -0.0644]]],\n",
            "\n",
            "\n",
            "        [[[-0.0172, -0.0920,  0.0177],\n",
            "          [-0.0254, -0.1658, -0.0880],\n",
            "          [-0.0173, -0.0478,  0.0148]],\n",
            "\n",
            "         [[ 0.0095, -0.1369,  0.0795],\n",
            "          [ 0.0050, -0.1191, -0.0455],\n",
            "          [ 0.0136,  0.0528, -0.0232]],\n",
            "\n",
            "         [[ 0.0695,  0.0464,  0.0718],\n",
            "          [ 0.0658, -0.0004, -0.1644],\n",
            "          [ 0.1710, -0.0935, -0.1307]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1727, -0.1820,  0.1059],\n",
            "          [-0.1406,  0.0315,  0.0891],\n",
            "          [-0.0412, -0.1839, -0.0042]],\n",
            "\n",
            "         [[-0.1506, -0.0517, -0.0385],\n",
            "          [-0.0830,  0.0814,  0.1830],\n",
            "          [-0.0485,  0.1200, -0.0454]],\n",
            "\n",
            "         [[ 0.0949,  0.1181,  0.0160],\n",
            "          [-0.1173, -0.0451,  0.1188],\n",
            "          [-0.1020, -0.0287, -0.1899]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0358, -0.1423, -0.1143],\n",
            "          [-0.0973, -0.0596,  0.1742],\n",
            "          [ 0.1452,  0.0285,  0.0324]],\n",
            "\n",
            "         [[ 0.0876, -0.1459, -0.0188],\n",
            "          [ 0.0948,  0.0629,  0.0110],\n",
            "          [ 0.1069, -0.0341, -0.0367]],\n",
            "\n",
            "         [[-0.0554,  0.0466,  0.0186],\n",
            "          [ 0.1878, -0.0946,  0.1298],\n",
            "          [ 0.0427, -0.1870, -0.0826]]],\n",
            "\n",
            "\n",
            "        [[[-0.1503, -0.0113, -0.0135],\n",
            "          [ 0.0526,  0.0870, -0.0912],\n",
            "          [-0.1061,  0.1669, -0.0904]],\n",
            "\n",
            "         [[ 0.1041,  0.1253,  0.1253],\n",
            "          [-0.0150, -0.0141, -0.1046],\n",
            "          [ 0.1066, -0.1691, -0.1529]],\n",
            "\n",
            "         [[-0.1391, -0.0833,  0.0025],\n",
            "          [-0.0123, -0.0129,  0.1465],\n",
            "          [-0.0933, -0.1588,  0.1752]]],\n",
            "\n",
            "\n",
            "        [[[-0.0998, -0.1527,  0.0075],\n",
            "          [ 0.0206, -0.0256, -0.0009],\n",
            "          [ 0.0654, -0.0716, -0.0699]],\n",
            "\n",
            "         [[-0.0139, -0.0170, -0.1053],\n",
            "          [-0.1710, -0.0996, -0.1460],\n",
            "          [ 0.0896,  0.0143, -0.1828]],\n",
            "\n",
            "         [[-0.0118,  0.1357,  0.1521],\n",
            "          [ 0.1330, -0.0807, -0.0352],\n",
            "          [ 0.1351,  0.0484, -0.1040]]],\n",
            "\n",
            "\n",
            "        [[[-0.0077, -0.1250,  0.0431],\n",
            "          [ 0.0111,  0.0378, -0.0421],\n",
            "          [ 0.1187, -0.0584, -0.0190]],\n",
            "\n",
            "         [[ 0.1718, -0.1291, -0.0898],\n",
            "          [-0.0950,  0.1752, -0.1899],\n",
            "          [ 0.0264,  0.1344,  0.0217]],\n",
            "\n",
            "         [[-0.0383,  0.0959, -0.1372],\n",
            "          [ 0.1546, -0.1646, -0.0818],\n",
            "          [ 0.0964,  0.1295,  0.0015]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1083,  0.0173,  0.1594],\n",
            "          [-0.1068,  0.0818, -0.1608],\n",
            "          [-0.0411,  0.1322,  0.1614]],\n",
            "\n",
            "         [[ 0.1733,  0.0258, -0.1410],\n",
            "          [ 0.0570, -0.1002, -0.1426],\n",
            "          [-0.0794, -0.1362,  0.0498]],\n",
            "\n",
            "         [[-0.1732,  0.1867, -0.1906],\n",
            "          [-0.0891, -0.0367, -0.1565],\n",
            "          [ 0.1361,  0.0943, -0.1090]]],\n",
            "\n",
            "\n",
            "        [[[-0.0896, -0.1185, -0.1618],\n",
            "          [-0.0546, -0.0797, -0.0158],\n",
            "          [ 0.1106,  0.0100,  0.0689]],\n",
            "\n",
            "         [[ 0.0269,  0.1701,  0.0041],\n",
            "          [ 0.0492,  0.0415, -0.0721],\n",
            "          [-0.1306, -0.1085,  0.0746]],\n",
            "\n",
            "         [[ 0.1911,  0.0917, -0.1444],\n",
            "          [-0.1092, -0.1088, -0.1258],\n",
            "          [ 0.0418, -0.1371,  0.1871]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1547, -0.0755, -0.0494],\n",
            "          [-0.1719,  0.0090, -0.0362],\n",
            "          [ 0.0774,  0.1391, -0.0827]],\n",
            "\n",
            "         [[-0.1401, -0.0831, -0.0355],\n",
            "          [-0.0833, -0.1071, -0.1108],\n",
            "          [ 0.0810,  0.1336,  0.0984]],\n",
            "\n",
            "         [[ 0.0533,  0.0322, -0.1054],\n",
            "          [-0.1077, -0.0211,  0.1437],\n",
            "          [ 0.0410,  0.1030,  0.0174]]],\n",
            "\n",
            "\n",
            "        [[[-0.1522,  0.0502,  0.0500],\n",
            "          [-0.0118,  0.0422, -0.0785],\n",
            "          [-0.1627,  0.0736, -0.0526]],\n",
            "\n",
            "         [[-0.1404,  0.1916, -0.0529],\n",
            "          [-0.0796,  0.1329,  0.0025],\n",
            "          [-0.0298,  0.0971, -0.1017]],\n",
            "\n",
            "         [[-0.1862, -0.1798, -0.0369],\n",
            "          [-0.0116, -0.0423,  0.0353],\n",
            "          [-0.1198,  0.1788, -0.1192]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0556,  0.0709, -0.0082],\n",
            "          [-0.0031, -0.1088, -0.0318],\n",
            "          [-0.1624, -0.1903, -0.0773]],\n",
            "\n",
            "         [[ 0.0051, -0.0879,  0.0107],\n",
            "          [ 0.0566, -0.1839, -0.1852],\n",
            "          [-0.0970,  0.1455, -0.1905]],\n",
            "\n",
            "         [[ 0.0622,  0.0545, -0.0540],\n",
            "          [ 0.0374, -0.0077,  0.0976],\n",
            "          [-0.0031,  0.0983, -0.0446]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1781,  0.1395,  0.1818],\n",
            "          [ 0.1178, -0.0300, -0.1879],\n",
            "          [-0.1119, -0.1723,  0.1428]],\n",
            "\n",
            "         [[-0.0617, -0.1857,  0.1003],\n",
            "          [-0.0054, -0.0995, -0.0820],\n",
            "          [-0.0416, -0.1805, -0.0353]],\n",
            "\n",
            "         [[ 0.0073, -0.1677,  0.0252],\n",
            "          [-0.0848, -0.1895,  0.1106],\n",
            "          [-0.1707, -0.1329, -0.1183]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1111,  0.0635, -0.1917],\n",
            "          [-0.0490,  0.1761,  0.0526],\n",
            "          [ 0.1133, -0.0209, -0.1005]],\n",
            "\n",
            "         [[ 0.1372,  0.0435,  0.1680],\n",
            "          [-0.0353,  0.0711,  0.0643],\n",
            "          [-0.0298,  0.1663,  0.1554]],\n",
            "\n",
            "         [[-0.1712, -0.1788, -0.1129],\n",
            "          [-0.1887,  0.1519,  0.0479],\n",
            "          [ 0.0582, -0.0827, -0.1517]]],\n",
            "\n",
            "\n",
            "        [[[-0.0794, -0.1430,  0.0231],\n",
            "          [-0.0932, -0.0326,  0.0803],\n",
            "          [ 0.0642,  0.1007, -0.1419]],\n",
            "\n",
            "         [[-0.1314,  0.0982, -0.1829],\n",
            "          [ 0.1207, -0.0606,  0.0452],\n",
            "          [-0.0131,  0.0785, -0.0017]],\n",
            "\n",
            "         [[-0.0445,  0.1713, -0.1560],\n",
            "          [-0.1855, -0.0245, -0.0387],\n",
            "          [ 0.0238,  0.0061,  0.1499]]],\n",
            "\n",
            "\n",
            "        [[[-0.0728,  0.1902,  0.0347],\n",
            "          [-0.1417,  0.1087, -0.0441],\n",
            "          [-0.1035,  0.1910,  0.1532]],\n",
            "\n",
            "         [[ 0.0419,  0.1414, -0.0654],\n",
            "          [ 0.0534, -0.0348,  0.1718],\n",
            "          [ 0.0253, -0.1780,  0.0536]],\n",
            "\n",
            "         [[ 0.1726,  0.0737,  0.0732],\n",
            "          [-0.1145,  0.1718,  0.1619],\n",
            "          [ 0.0610,  0.1324,  0.0064]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1191,  0.0812,  0.0864],\n",
            "          [-0.0517, -0.0416,  0.1507],\n",
            "          [-0.0182,  0.0219, -0.1198]],\n",
            "\n",
            "         [[-0.1091, -0.0812, -0.1542],\n",
            "          [-0.0052, -0.1502,  0.0379],\n",
            "          [-0.0988, -0.1861,  0.1235]],\n",
            "\n",
            "         [[ 0.0490, -0.1461, -0.1308],\n",
            "          [-0.1583, -0.1381,  0.0902],\n",
            "          [ 0.1557, -0.1130, -0.1034]]],\n",
            "\n",
            "\n",
            "        [[[-0.0473,  0.1882,  0.0249],\n",
            "          [-0.0107, -0.1163, -0.1368],\n",
            "          [ 0.1388,  0.1445,  0.1666]],\n",
            "\n",
            "         [[ 0.1496, -0.1664, -0.1665],\n",
            "          [ 0.0433,  0.1917,  0.0454],\n",
            "          [-0.0131,  0.0185,  0.1130]],\n",
            "\n",
            "         [[ 0.0697,  0.1251, -0.1581],\n",
            "          [ 0.1898,  0.0958,  0.1726],\n",
            "          [-0.0163,  0.0418,  0.1218]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1056, -0.1557,  0.1110],\n",
            "          [-0.1125, -0.1493, -0.1156],\n",
            "          [-0.0611,  0.1344, -0.0548]],\n",
            "\n",
            "         [[ 0.0467, -0.0040, -0.1587],\n",
            "          [-0.0180,  0.1350, -0.0296],\n",
            "          [-0.0997,  0.1432,  0.0253]],\n",
            "\n",
            "         [[-0.0973,  0.0249, -0.0673],\n",
            "          [ 0.1656, -0.0366, -0.1017],\n",
            "          [ 0.0310,  0.1559,  0.0300]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0404, -0.0540,  0.0529],\n",
            "          [-0.0744,  0.0450,  0.1287],\n",
            "          [ 0.0793,  0.0567, -0.0693]],\n",
            "\n",
            "         [[-0.1523,  0.1706, -0.1320],\n",
            "          [-0.0927, -0.1107, -0.0940],\n",
            "          [ 0.1877,  0.1400, -0.1145]],\n",
            "\n",
            "         [[-0.1512, -0.0059, -0.0262],\n",
            "          [ 0.1539,  0.0539,  0.0550],\n",
            "          [-0.0962,  0.0481,  0.0898]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0358,  0.1414,  0.1484],\n",
            "          [-0.1669,  0.1561, -0.0957],\n",
            "          [-0.1698, -0.1665, -0.0752]],\n",
            "\n",
            "         [[ 0.1655,  0.1800,  0.1599],\n",
            "          [-0.1832,  0.1622, -0.1431],\n",
            "          [-0.0339,  0.1050,  0.0151]],\n",
            "\n",
            "         [[-0.0405, -0.1164,  0.1865],\n",
            "          [ 0.1423, -0.0128,  0.1164],\n",
            "          [ 0.1139, -0.0108, -0.1126]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1538, -0.0958, -0.0681],\n",
            "          [-0.1495, -0.1546, -0.0495],\n",
            "          [ 0.0485, -0.0470, -0.1343]],\n",
            "\n",
            "         [[ 0.0873,  0.0627,  0.1689],\n",
            "          [-0.0313, -0.0012,  0.0163],\n",
            "          [ 0.0109, -0.1555,  0.0143]],\n",
            "\n",
            "         [[-0.0207,  0.0957, -0.0692],\n",
            "          [ 0.1046, -0.1653,  0.0894],\n",
            "          [ 0.1458,  0.1789, -0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1757,  0.1346,  0.0168],\n",
            "          [-0.1224,  0.0330,  0.0796],\n",
            "          [ 0.0067, -0.1142,  0.1537]],\n",
            "\n",
            "         [[ 0.0219, -0.1845,  0.1544],\n",
            "          [-0.0427, -0.1589, -0.0650],\n",
            "          [ 0.0044, -0.1536,  0.1252]],\n",
            "\n",
            "         [[-0.1909,  0.0264, -0.1318],\n",
            "          [-0.1024, -0.1600, -0.1428],\n",
            "          [-0.0414, -0.0984,  0.0212]]],\n",
            "\n",
            "\n",
            "        [[[-0.1435, -0.0897, -0.0504],\n",
            "          [-0.0876,  0.0481, -0.0289],\n",
            "          [-0.1393, -0.0613, -0.1307]],\n",
            "\n",
            "         [[-0.0378,  0.1127, -0.1798],\n",
            "          [ 0.1913,  0.0090, -0.0450],\n",
            "          [ 0.0060,  0.0011, -0.0569]],\n",
            "\n",
            "         [[ 0.0361,  0.1631, -0.1517],\n",
            "          [-0.1558, -0.0748,  0.1526],\n",
            "          [ 0.1047,  0.0827,  0.0022]]],\n",
            "\n",
            "\n",
            "        [[[-0.1845,  0.0823, -0.1341],\n",
            "          [-0.0909, -0.1797,  0.0677],\n",
            "          [ 0.1366, -0.0843,  0.0296]],\n",
            "\n",
            "         [[-0.1183,  0.0327, -0.0891],\n",
            "          [ 0.0780, -0.0168, -0.0901],\n",
            "          [ 0.1617,  0.0862,  0.0830]],\n",
            "\n",
            "         [[-0.1247,  0.0243, -0.0465],\n",
            "          [ 0.0146,  0.0660, -0.0081],\n",
            "          [ 0.0297,  0.0836, -0.1087]]],\n",
            "\n",
            "\n",
            "        [[[-0.1639, -0.0972,  0.0869],\n",
            "          [-0.0663, -0.0839, -0.0080],\n",
            "          [ 0.1293,  0.0434, -0.1294]],\n",
            "\n",
            "         [[-0.1737, -0.1424, -0.0197],\n",
            "          [ 0.0563,  0.0254,  0.1411],\n",
            "          [-0.1545,  0.0530, -0.1551]],\n",
            "\n",
            "         [[ 0.1040,  0.1890,  0.0914],\n",
            "          [-0.1212,  0.1821, -0.1795],\n",
            "          [ 0.0323,  0.1260,  0.1291]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1299, -0.0634,  0.1211],\n",
            "          [ 0.0799, -0.0534, -0.0650],\n",
            "          [-0.1852, -0.0656,  0.1808]],\n",
            "\n",
            "         [[ 0.1729,  0.1894, -0.0316],\n",
            "          [ 0.1107, -0.0377, -0.1797],\n",
            "          [ 0.0552,  0.0672,  0.0766]],\n",
            "\n",
            "         [[-0.1913, -0.0869, -0.0228],\n",
            "          [ 0.1863, -0.1404, -0.0313],\n",
            "          [ 0.1354, -0.1199,  0.1026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0861,  0.1733,  0.1421],\n",
            "          [-0.0202, -0.0693,  0.0959],\n",
            "          [-0.0430,  0.1066, -0.0865]],\n",
            "\n",
            "         [[-0.0306, -0.0762,  0.1133],\n",
            "          [-0.0629,  0.1901, -0.0911],\n",
            "          [ 0.0527,  0.1757,  0.1323]],\n",
            "\n",
            "         [[ 0.0381, -0.1165, -0.0552],\n",
            "          [-0.0036,  0.0097,  0.0773],\n",
            "          [-0.1408,  0.1242, -0.1229]]]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_focus = nn.CrossEntropyLoss()\n",
        "optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRRGIUjGG_Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjmFfZ4nHCkX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "b7352417-4a00-42ff-ad26-b8b3fa180e98"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 32 %\n",
            "total correct 9865\n",
            "total train set images 30000\n",
            "focus_true_pred_true 9865 =============> FTPT : 32 %\n",
            "focus_false_pred_true 0 =============> FFPT : 0 %\n",
            "focus_true_pred_false 20135 =============> FTPF : 67 %\n",
            "focus_false_pred_false 0 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  30000\n",
            "argmax_less_than_half ==================>  0\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CRJ3nOHEYe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "78335b66-0464-44e4-c0d9-27472700e542"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 33 %\n",
            "total correct 3305\n",
            "total train set images 10000\n",
            "focus_true_pred_true 3305 =============> FTPT : 33 %\n",
            "focus_false_pred_true 0 =============> FFPT : 0 %\n",
            "focus_true_pred_false 6695 =============> FTPF : 66 %\n",
            "focus_false_pred_false 0 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  10000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tFfAJZkcZEsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "158b02de-3705-470b-d663-b606bcef3551"
      },
      "source": [
        "nos_epochs = 50\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_focus(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_focus.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    col1.append(epoch + 1 )\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 1.119\n",
            "[1,   120] loss: 1.118\n",
            "[1,   180] loss: 1.118\n",
            "[1,   240] loss: 1.117\n",
            "[2,    60] loss: 1.118\n",
            "[2,   120] loss: 1.119\n",
            "[2,   180] loss: 1.118\n",
            "[2,   240] loss: 1.116\n",
            "[3,    60] loss: 1.118\n",
            "[3,   120] loss: 1.116\n",
            "[3,   180] loss: 1.117\n",
            "[3,   240] loss: 1.120\n",
            "[4,    60] loss: 1.117\n",
            "[4,   120] loss: 1.117\n",
            "[4,   180] loss: 1.119\n",
            "[4,   240] loss: 1.118\n",
            "[5,    60] loss: 1.119\n",
            "[5,   120] loss: 1.120\n",
            "[5,   180] loss: 1.115\n",
            "[5,   240] loss: 1.116\n",
            "[6,    60] loss: 1.118\n",
            "[6,   120] loss: 1.114\n",
            "[6,   180] loss: 1.118\n",
            "[6,   240] loss: 1.120\n",
            "[7,    60] loss: 1.121\n",
            "[7,   120] loss: 1.118\n",
            "[7,   180] loss: 1.116\n",
            "[7,   240] loss: 1.116\n",
            "[8,    60] loss: 1.115\n",
            "[8,   120] loss: 1.119\n",
            "[8,   180] loss: 1.117\n",
            "[8,   240] loss: 1.120\n",
            "[9,    60] loss: 1.118\n",
            "[9,   120] loss: 1.117\n",
            "[9,   180] loss: 1.116\n",
            "[9,   240] loss: 1.120\n",
            "[10,    60] loss: 1.120\n",
            "[10,   120] loss: 1.116\n",
            "[10,   180] loss: 1.120\n",
            "[10,   240] loss: 1.115\n",
            "[11,    60] loss: 1.117\n",
            "[11,   120] loss: 1.118\n",
            "[11,   180] loss: 1.121\n",
            "[11,   240] loss: 1.115\n",
            "[12,    60] loss: 1.119\n",
            "[12,   120] loss: 1.118\n",
            "[12,   180] loss: 1.120\n",
            "[12,   240] loss: 1.114\n",
            "[13,    60] loss: 1.119\n",
            "[13,   120] loss: 1.119\n",
            "[13,   180] loss: 1.119\n",
            "[13,   240] loss: 1.114\n",
            "[14,    60] loss: 1.116\n",
            "[14,   120] loss: 1.121\n",
            "[14,   180] loss: 1.115\n",
            "[14,   240] loss: 1.119\n",
            "[15,    60] loss: 1.117\n",
            "[15,   120] loss: 1.120\n",
            "[15,   180] loss: 1.116\n",
            "[15,   240] loss: 1.118\n",
            "[16,    60] loss: 1.118\n",
            "[16,   120] loss: 1.115\n",
            "[16,   180] loss: 1.118\n",
            "[16,   240] loss: 1.120\n",
            "[17,    60] loss: 1.121\n",
            "[17,   120] loss: 1.116\n",
            "[17,   180] loss: 1.119\n",
            "[17,   240] loss: 1.115\n",
            "[18,    60] loss: 1.118\n",
            "[18,   120] loss: 1.119\n",
            "[18,   180] loss: 1.118\n",
            "[18,   240] loss: 1.116\n",
            "[19,    60] loss: 1.119\n",
            "[19,   120] loss: 1.118\n",
            "[19,   180] loss: 1.116\n",
            "[19,   240] loss: 1.118\n",
            "[20,    60] loss: 1.119\n",
            "[20,   120] loss: 1.115\n",
            "[20,   180] loss: 1.116\n",
            "[20,   240] loss: 1.121\n",
            "[21,    60] loss: 1.116\n",
            "[21,   120] loss: 1.120\n",
            "[21,   180] loss: 1.118\n",
            "[21,   240] loss: 1.117\n",
            "[22,    60] loss: 1.117\n",
            "[22,   120] loss: 1.120\n",
            "[22,   180] loss: 1.118\n",
            "[22,   240] loss: 1.116\n",
            "[23,    60] loss: 1.118\n",
            "[23,   120] loss: 1.119\n",
            "[23,   180] loss: 1.118\n",
            "[23,   240] loss: 1.116\n",
            "[24,    60] loss: 1.115\n",
            "[24,   120] loss: 1.119\n",
            "[24,   180] loss: 1.118\n",
            "[24,   240] loss: 1.119\n",
            "[25,    60] loss: 1.119\n",
            "[25,   120] loss: 1.120\n",
            "[25,   180] loss: 1.117\n",
            "[25,   240] loss: 1.115\n",
            "[26,    60] loss: 1.118\n",
            "[26,   120] loss: 1.116\n",
            "[26,   180] loss: 1.116\n",
            "[26,   240] loss: 1.120\n",
            "[27,    60] loss: 1.117\n",
            "[27,   120] loss: 1.118\n",
            "[27,   180] loss: 1.118\n",
            "[27,   240] loss: 1.118\n",
            "[28,    60] loss: 1.117\n",
            "[28,   120] loss: 1.120\n",
            "[28,   180] loss: 1.115\n",
            "[28,   240] loss: 1.119\n",
            "[29,    60] loss: 1.121\n",
            "[29,   120] loss: 1.117\n",
            "[29,   180] loss: 1.114\n",
            "[29,   240] loss: 1.119\n",
            "[30,    60] loss: 1.119\n",
            "[30,   120] loss: 1.115\n",
            "[30,   180] loss: 1.119\n",
            "[30,   240] loss: 1.118\n",
            "[31,    60] loss: 1.120\n",
            "[31,   120] loss: 1.115\n",
            "[31,   180] loss: 1.116\n",
            "[31,   240] loss: 1.120\n",
            "[32,    60] loss: 1.113\n",
            "[32,   120] loss: 1.123\n",
            "[32,   180] loss: 1.120\n",
            "[32,   240] loss: 1.116\n",
            "[33,    60] loss: 1.119\n",
            "[33,   120] loss: 1.118\n",
            "[33,   180] loss: 1.118\n",
            "[33,   240] loss: 1.116\n",
            "[34,    60] loss: 1.117\n",
            "[34,   120] loss: 1.116\n",
            "[34,   180] loss: 1.119\n",
            "[34,   240] loss: 1.119\n",
            "[35,    60] loss: 1.120\n",
            "[35,   120] loss: 1.114\n",
            "[35,   180] loss: 1.122\n",
            "[35,   240] loss: 1.116\n",
            "[36,    60] loss: 1.118\n",
            "[36,   120] loss: 1.120\n",
            "[36,   180] loss: 1.116\n",
            "[36,   240] loss: 1.117\n",
            "[37,    60] loss: 1.119\n",
            "[37,   120] loss: 1.119\n",
            "[37,   180] loss: 1.117\n",
            "[37,   240] loss: 1.115\n",
            "[38,    60] loss: 1.119\n",
            "[38,   120] loss: 1.119\n",
            "[38,   180] loss: 1.117\n",
            "[38,   240] loss: 1.116\n",
            "[39,    60] loss: 1.119\n",
            "[39,   120] loss: 1.115\n",
            "[39,   180] loss: 1.115\n",
            "[39,   240] loss: 1.122\n",
            "[40,    60] loss: 1.116\n",
            "[40,   120] loss: 1.118\n",
            "[40,   180] loss: 1.121\n",
            "[40,   240] loss: 1.116\n",
            "[41,    60] loss: 1.118\n",
            "[41,   120] loss: 1.115\n",
            "[41,   180] loss: 1.117\n",
            "[41,   240] loss: 1.121\n",
            "[42,    60] loss: 1.118\n",
            "[42,   120] loss: 1.119\n",
            "[42,   180] loss: 1.118\n",
            "[42,   240] loss: 1.116\n",
            "[43,    60] loss: 1.116\n",
            "[43,   120] loss: 1.122\n",
            "[43,   180] loss: 1.117\n",
            "[43,   240] loss: 1.117\n",
            "[44,    60] loss: 1.116\n",
            "[44,   120] loss: 1.119\n",
            "[44,   180] loss: 1.120\n",
            "[44,   240] loss: 1.116\n",
            "[45,    60] loss: 1.118\n",
            "[45,   120] loss: 1.114\n",
            "[45,   180] loss: 1.120\n",
            "[45,   240] loss: 1.119\n",
            "[46,    60] loss: 1.119\n",
            "[46,   120] loss: 1.117\n",
            "[46,   180] loss: 1.118\n",
            "[46,   240] loss: 1.117\n",
            "[47,    60] loss: 1.115\n",
            "[47,   120] loss: 1.121\n",
            "[47,   180] loss: 1.117\n",
            "[47,   240] loss: 1.118\n",
            "[48,    60] loss: 1.121\n",
            "[48,   120] loss: 1.119\n",
            "[48,   180] loss: 1.115\n",
            "[48,   240] loss: 1.116\n",
            "[49,    60] loss: 1.116\n",
            "[49,   120] loss: 1.119\n",
            "[49,   180] loss: 1.118\n",
            "[49,   240] loss: 1.117\n",
            "[50,    60] loss: 1.116\n",
            "[50,   120] loss: 1.116\n",
            "[50,   180] loss: 1.119\n",
            "[50,   240] loss: 1.120\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urwhyQWLbXFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "f07d583c-667f-4e64-ddb7-adf004824487"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToKa651tMtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8aca5f8-02a6-49db-8249-1b19510f7153"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-0.0767, -0.1167, -0.1786],\n",
            "          [ 0.0845,  0.0740,  0.0724],\n",
            "          [ 0.1830,  0.1433,  0.1361]],\n",
            "\n",
            "         [[ 0.0795, -0.1849, -0.0115],\n",
            "          [ 0.0375,  0.1197, -0.1259],\n",
            "          [ 0.1882, -0.1456, -0.1450]],\n",
            "\n",
            "         [[ 0.0137, -0.0685, -0.0291],\n",
            "          [ 0.0293,  0.0182, -0.1025],\n",
            "          [-0.0206, -0.0970,  0.1143]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0067, -0.0057,  0.1570],\n",
            "          [ 0.1101,  0.0524, -0.0900],\n",
            "          [ 0.1122, -0.1392, -0.0868]],\n",
            "\n",
            "         [[-0.1291, -0.1660, -0.1731],\n",
            "          [-0.0749, -0.0017, -0.0162],\n",
            "          [-0.0656,  0.0766,  0.1224]],\n",
            "\n",
            "         [[ 0.0884, -0.0457, -0.1225],\n",
            "          [ 0.0090, -0.0917, -0.0510],\n",
            "          [-0.0979, -0.0951, -0.0878]]],\n",
            "\n",
            "\n",
            "        [[[-0.1204,  0.1765,  0.0156],\n",
            "          [ 0.0790, -0.1805,  0.0856],\n",
            "          [ 0.0881,  0.1273, -0.0795]],\n",
            "\n",
            "         [[ 0.0159, -0.1554,  0.1770],\n",
            "          [-0.1891, -0.0219,  0.0270],\n",
            "          [-0.0111,  0.0171, -0.0621]],\n",
            "\n",
            "         [[ 0.0207,  0.0763,  0.0747],\n",
            "          [-0.0644,  0.1493,  0.1329],\n",
            "          [-0.1816, -0.0640,  0.1794]]],\n",
            "\n",
            "\n",
            "        [[[-0.1524,  0.0172,  0.0274],\n",
            "          [ 0.0982, -0.0972, -0.1674],\n",
            "          [-0.1571,  0.0451,  0.1385]],\n",
            "\n",
            "         [[-0.0103, -0.0953,  0.1810],\n",
            "          [-0.1566,  0.0045,  0.0375],\n",
            "          [-0.0174, -0.0983,  0.1681]],\n",
            "\n",
            "         [[ 0.1803,  0.1817, -0.0720],\n",
            "          [ 0.0527, -0.0455, -0.0123],\n",
            "          [ 0.0144,  0.0420, -0.1591]]],\n",
            "\n",
            "\n",
            "        [[[-0.1184, -0.1595,  0.0232],\n",
            "          [ 0.1290,  0.1356,  0.0422],\n",
            "          [-0.1865, -0.0548, -0.1197]],\n",
            "\n",
            "         [[ 0.1551,  0.1854,  0.1287],\n",
            "          [-0.0265, -0.0829,  0.1450],\n",
            "          [-0.1746, -0.0701,  0.1438]],\n",
            "\n",
            "         [[-0.0228, -0.1391, -0.0158],\n",
            "          [ 0.0927, -0.0417,  0.1887],\n",
            "          [-0.0741,  0.1167, -0.0644]]],\n",
            "\n",
            "\n",
            "        [[[-0.0172, -0.0920,  0.0177],\n",
            "          [-0.0254, -0.1658, -0.0880],\n",
            "          [-0.0173, -0.0478,  0.0148]],\n",
            "\n",
            "         [[ 0.0095, -0.1369,  0.0795],\n",
            "          [ 0.0050, -0.1191, -0.0455],\n",
            "          [ 0.0136,  0.0528, -0.0232]],\n",
            "\n",
            "         [[ 0.0695,  0.0464,  0.0718],\n",
            "          [ 0.0658, -0.0004, -0.1644],\n",
            "          [ 0.1710, -0.0935, -0.1307]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1727, -0.1820,  0.1059],\n",
            "          [-0.1406,  0.0315,  0.0891],\n",
            "          [-0.0412, -0.1839, -0.0042]],\n",
            "\n",
            "         [[-0.1506, -0.0517, -0.0385],\n",
            "          [-0.0830,  0.0814,  0.1830],\n",
            "          [-0.0485,  0.1200, -0.0454]],\n",
            "\n",
            "         [[ 0.0949,  0.1181,  0.0160],\n",
            "          [-0.1173, -0.0451,  0.1188],\n",
            "          [-0.1020, -0.0287, -0.1899]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0358, -0.1423, -0.1143],\n",
            "          [-0.0973, -0.0596,  0.1742],\n",
            "          [ 0.1452,  0.0285,  0.0324]],\n",
            "\n",
            "         [[ 0.0876, -0.1459, -0.0188],\n",
            "          [ 0.0948,  0.0629,  0.0110],\n",
            "          [ 0.1069, -0.0341, -0.0367]],\n",
            "\n",
            "         [[-0.0554,  0.0466,  0.0186],\n",
            "          [ 0.1878, -0.0946,  0.1298],\n",
            "          [ 0.0427, -0.1870, -0.0826]]],\n",
            "\n",
            "\n",
            "        [[[-0.1503, -0.0113, -0.0135],\n",
            "          [ 0.0526,  0.0870, -0.0912],\n",
            "          [-0.1061,  0.1669, -0.0904]],\n",
            "\n",
            "         [[ 0.1041,  0.1253,  0.1253],\n",
            "          [-0.0150, -0.0141, -0.1046],\n",
            "          [ 0.1066, -0.1691, -0.1529]],\n",
            "\n",
            "         [[-0.1391, -0.0833,  0.0025],\n",
            "          [-0.0123, -0.0129,  0.1465],\n",
            "          [-0.0933, -0.1588,  0.1752]]],\n",
            "\n",
            "\n",
            "        [[[-0.0998, -0.1527,  0.0075],\n",
            "          [ 0.0206, -0.0256, -0.0009],\n",
            "          [ 0.0654, -0.0716, -0.0699]],\n",
            "\n",
            "         [[-0.0139, -0.0170, -0.1053],\n",
            "          [-0.1710, -0.0996, -0.1460],\n",
            "          [ 0.0896,  0.0143, -0.1828]],\n",
            "\n",
            "         [[-0.0118,  0.1357,  0.1521],\n",
            "          [ 0.1330, -0.0807, -0.0352],\n",
            "          [ 0.1351,  0.0484, -0.1040]]],\n",
            "\n",
            "\n",
            "        [[[-0.0077, -0.1250,  0.0431],\n",
            "          [ 0.0111,  0.0378, -0.0421],\n",
            "          [ 0.1187, -0.0584, -0.0190]],\n",
            "\n",
            "         [[ 0.1718, -0.1291, -0.0898],\n",
            "          [-0.0950,  0.1752, -0.1899],\n",
            "          [ 0.0264,  0.1344,  0.0217]],\n",
            "\n",
            "         [[-0.0383,  0.0959, -0.1372],\n",
            "          [ 0.1546, -0.1646, -0.0818],\n",
            "          [ 0.0964,  0.1295,  0.0015]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1083,  0.0173,  0.1594],\n",
            "          [-0.1068,  0.0818, -0.1608],\n",
            "          [-0.0411,  0.1322,  0.1614]],\n",
            "\n",
            "         [[ 0.1733,  0.0258, -0.1410],\n",
            "          [ 0.0570, -0.1002, -0.1426],\n",
            "          [-0.0794, -0.1362,  0.0498]],\n",
            "\n",
            "         [[-0.1732,  0.1867, -0.1906],\n",
            "          [-0.0891, -0.0367, -0.1565],\n",
            "          [ 0.1361,  0.0943, -0.1090]]],\n",
            "\n",
            "\n",
            "        [[[-0.0896, -0.1185, -0.1618],\n",
            "          [-0.0546, -0.0797, -0.0158],\n",
            "          [ 0.1106,  0.0100,  0.0689]],\n",
            "\n",
            "         [[ 0.0269,  0.1701,  0.0041],\n",
            "          [ 0.0492,  0.0415, -0.0721],\n",
            "          [-0.1306, -0.1085,  0.0746]],\n",
            "\n",
            "         [[ 0.1911,  0.0917, -0.1444],\n",
            "          [-0.1092, -0.1088, -0.1258],\n",
            "          [ 0.0418, -0.1371,  0.1871]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1547, -0.0755, -0.0494],\n",
            "          [-0.1719,  0.0090, -0.0362],\n",
            "          [ 0.0774,  0.1391, -0.0827]],\n",
            "\n",
            "         [[-0.1401, -0.0831, -0.0355],\n",
            "          [-0.0833, -0.1071, -0.1108],\n",
            "          [ 0.0810,  0.1336,  0.0984]],\n",
            "\n",
            "         [[ 0.0533,  0.0322, -0.1054],\n",
            "          [-0.1077, -0.0211,  0.1437],\n",
            "          [ 0.0410,  0.1030,  0.0174]]],\n",
            "\n",
            "\n",
            "        [[[-0.1522,  0.0502,  0.0500],\n",
            "          [-0.0118,  0.0422, -0.0785],\n",
            "          [-0.1627,  0.0736, -0.0526]],\n",
            "\n",
            "         [[-0.1404,  0.1916, -0.0529],\n",
            "          [-0.0796,  0.1329,  0.0025],\n",
            "          [-0.0298,  0.0971, -0.1017]],\n",
            "\n",
            "         [[-0.1862, -0.1798, -0.0369],\n",
            "          [-0.0116, -0.0423,  0.0353],\n",
            "          [-0.1198,  0.1788, -0.1192]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0556,  0.0709, -0.0082],\n",
            "          [-0.0031, -0.1088, -0.0318],\n",
            "          [-0.1624, -0.1903, -0.0773]],\n",
            "\n",
            "         [[ 0.0051, -0.0879,  0.0107],\n",
            "          [ 0.0566, -0.1839, -0.1852],\n",
            "          [-0.0970,  0.1455, -0.1905]],\n",
            "\n",
            "         [[ 0.0622,  0.0545, -0.0540],\n",
            "          [ 0.0374, -0.0077,  0.0976],\n",
            "          [-0.0031,  0.0983, -0.0446]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1781,  0.1395,  0.1818],\n",
            "          [ 0.1178, -0.0300, -0.1879],\n",
            "          [-0.1119, -0.1723,  0.1428]],\n",
            "\n",
            "         [[-0.0617, -0.1857,  0.1003],\n",
            "          [-0.0054, -0.0995, -0.0820],\n",
            "          [-0.0416, -0.1805, -0.0353]],\n",
            "\n",
            "         [[ 0.0073, -0.1677,  0.0252],\n",
            "          [-0.0848, -0.1895,  0.1106],\n",
            "          [-0.1707, -0.1329, -0.1183]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1111,  0.0635, -0.1917],\n",
            "          [-0.0490,  0.1761,  0.0526],\n",
            "          [ 0.1133, -0.0209, -0.1005]],\n",
            "\n",
            "         [[ 0.1372,  0.0435,  0.1680],\n",
            "          [-0.0353,  0.0711,  0.0643],\n",
            "          [-0.0298,  0.1663,  0.1554]],\n",
            "\n",
            "         [[-0.1712, -0.1788, -0.1129],\n",
            "          [-0.1887,  0.1519,  0.0479],\n",
            "          [ 0.0582, -0.0827, -0.1517]]],\n",
            "\n",
            "\n",
            "        [[[-0.0794, -0.1430,  0.0231],\n",
            "          [-0.0932, -0.0326,  0.0803],\n",
            "          [ 0.0642,  0.1007, -0.1419]],\n",
            "\n",
            "         [[-0.1314,  0.0982, -0.1829],\n",
            "          [ 0.1207, -0.0606,  0.0452],\n",
            "          [-0.0131,  0.0785, -0.0017]],\n",
            "\n",
            "         [[-0.0445,  0.1713, -0.1560],\n",
            "          [-0.1855, -0.0245, -0.0387],\n",
            "          [ 0.0238,  0.0061,  0.1499]]],\n",
            "\n",
            "\n",
            "        [[[-0.0728,  0.1902,  0.0347],\n",
            "          [-0.1417,  0.1087, -0.0441],\n",
            "          [-0.1035,  0.1910,  0.1532]],\n",
            "\n",
            "         [[ 0.0419,  0.1414, -0.0654],\n",
            "          [ 0.0534, -0.0348,  0.1718],\n",
            "          [ 0.0253, -0.1780,  0.0536]],\n",
            "\n",
            "         [[ 0.1726,  0.0737,  0.0732],\n",
            "          [-0.1145,  0.1718,  0.1619],\n",
            "          [ 0.0610,  0.1324,  0.0064]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1191,  0.0812,  0.0864],\n",
            "          [-0.0517, -0.0416,  0.1507],\n",
            "          [-0.0182,  0.0219, -0.1198]],\n",
            "\n",
            "         [[-0.1091, -0.0812, -0.1542],\n",
            "          [-0.0052, -0.1502,  0.0379],\n",
            "          [-0.0988, -0.1861,  0.1235]],\n",
            "\n",
            "         [[ 0.0490, -0.1461, -0.1308],\n",
            "          [-0.1583, -0.1381,  0.0902],\n",
            "          [ 0.1557, -0.1130, -0.1034]]],\n",
            "\n",
            "\n",
            "        [[[-0.0473,  0.1882,  0.0249],\n",
            "          [-0.0107, -0.1163, -0.1368],\n",
            "          [ 0.1388,  0.1445,  0.1666]],\n",
            "\n",
            "         [[ 0.1496, -0.1664, -0.1665],\n",
            "          [ 0.0433,  0.1917,  0.0454],\n",
            "          [-0.0131,  0.0185,  0.1130]],\n",
            "\n",
            "         [[ 0.0697,  0.1251, -0.1581],\n",
            "          [ 0.1898,  0.0958,  0.1726],\n",
            "          [-0.0163,  0.0418,  0.1218]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1056, -0.1557,  0.1110],\n",
            "          [-0.1125, -0.1493, -0.1156],\n",
            "          [-0.0611,  0.1344, -0.0548]],\n",
            "\n",
            "         [[ 0.0467, -0.0040, -0.1587],\n",
            "          [-0.0180,  0.1350, -0.0296],\n",
            "          [-0.0997,  0.1432,  0.0253]],\n",
            "\n",
            "         [[-0.0973,  0.0249, -0.0673],\n",
            "          [ 0.1656, -0.0366, -0.1017],\n",
            "          [ 0.0310,  0.1559,  0.0300]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0404, -0.0540,  0.0529],\n",
            "          [-0.0744,  0.0450,  0.1287],\n",
            "          [ 0.0793,  0.0567, -0.0693]],\n",
            "\n",
            "         [[-0.1523,  0.1706, -0.1320],\n",
            "          [-0.0927, -0.1107, -0.0940],\n",
            "          [ 0.1877,  0.1400, -0.1145]],\n",
            "\n",
            "         [[-0.1512, -0.0059, -0.0262],\n",
            "          [ 0.1539,  0.0539,  0.0550],\n",
            "          [-0.0962,  0.0481,  0.0898]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0358,  0.1414,  0.1484],\n",
            "          [-0.1669,  0.1561, -0.0957],\n",
            "          [-0.1698, -0.1665, -0.0752]],\n",
            "\n",
            "         [[ 0.1655,  0.1800,  0.1599],\n",
            "          [-0.1832,  0.1622, -0.1431],\n",
            "          [-0.0339,  0.1050,  0.0151]],\n",
            "\n",
            "         [[-0.0405, -0.1164,  0.1865],\n",
            "          [ 0.1423, -0.0128,  0.1164],\n",
            "          [ 0.1139, -0.0108, -0.1126]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1538, -0.0958, -0.0681],\n",
            "          [-0.1495, -0.1546, -0.0495],\n",
            "          [ 0.0485, -0.0470, -0.1343]],\n",
            "\n",
            "         [[ 0.0873,  0.0627,  0.1689],\n",
            "          [-0.0313, -0.0012,  0.0163],\n",
            "          [ 0.0109, -0.1555,  0.0143]],\n",
            "\n",
            "         [[-0.0207,  0.0957, -0.0692],\n",
            "          [ 0.1046, -0.1653,  0.0894],\n",
            "          [ 0.1458,  0.1789, -0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1757,  0.1346,  0.0168],\n",
            "          [-0.1224,  0.0330,  0.0796],\n",
            "          [ 0.0067, -0.1142,  0.1537]],\n",
            "\n",
            "         [[ 0.0219, -0.1845,  0.1544],\n",
            "          [-0.0427, -0.1589, -0.0650],\n",
            "          [ 0.0044, -0.1536,  0.1252]],\n",
            "\n",
            "         [[-0.1909,  0.0264, -0.1318],\n",
            "          [-0.1024, -0.1600, -0.1428],\n",
            "          [-0.0414, -0.0984,  0.0212]]],\n",
            "\n",
            "\n",
            "        [[[-0.1435, -0.0897, -0.0504],\n",
            "          [-0.0876,  0.0481, -0.0289],\n",
            "          [-0.1393, -0.0613, -0.1307]],\n",
            "\n",
            "         [[-0.0378,  0.1127, -0.1798],\n",
            "          [ 0.1913,  0.0090, -0.0450],\n",
            "          [ 0.0060,  0.0011, -0.0569]],\n",
            "\n",
            "         [[ 0.0361,  0.1631, -0.1517],\n",
            "          [-0.1558, -0.0748,  0.1526],\n",
            "          [ 0.1047,  0.0827,  0.0022]]],\n",
            "\n",
            "\n",
            "        [[[-0.1845,  0.0823, -0.1341],\n",
            "          [-0.0909, -0.1797,  0.0677],\n",
            "          [ 0.1366, -0.0843,  0.0296]],\n",
            "\n",
            "         [[-0.1183,  0.0327, -0.0891],\n",
            "          [ 0.0780, -0.0168, -0.0901],\n",
            "          [ 0.1617,  0.0862,  0.0830]],\n",
            "\n",
            "         [[-0.1247,  0.0243, -0.0465],\n",
            "          [ 0.0146,  0.0660, -0.0081],\n",
            "          [ 0.0297,  0.0836, -0.1087]]],\n",
            "\n",
            "\n",
            "        [[[-0.1639, -0.0972,  0.0869],\n",
            "          [-0.0663, -0.0839, -0.0080],\n",
            "          [ 0.1293,  0.0434, -0.1294]],\n",
            "\n",
            "         [[-0.1737, -0.1424, -0.0197],\n",
            "          [ 0.0563,  0.0254,  0.1411],\n",
            "          [-0.1545,  0.0530, -0.1551]],\n",
            "\n",
            "         [[ 0.1040,  0.1890,  0.0914],\n",
            "          [-0.1212,  0.1821, -0.1795],\n",
            "          [ 0.0323,  0.1260,  0.1291]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1299, -0.0634,  0.1211],\n",
            "          [ 0.0799, -0.0534, -0.0650],\n",
            "          [-0.1852, -0.0656,  0.1808]],\n",
            "\n",
            "         [[ 0.1729,  0.1894, -0.0316],\n",
            "          [ 0.1107, -0.0377, -0.1797],\n",
            "          [ 0.0552,  0.0672,  0.0766]],\n",
            "\n",
            "         [[-0.1913, -0.0869, -0.0228],\n",
            "          [ 0.1863, -0.1404, -0.0313],\n",
            "          [ 0.1354, -0.1199,  0.1026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0861,  0.1733,  0.1421],\n",
            "          [-0.0202, -0.0693,  0.0959],\n",
            "          [-0.0430,  0.1066, -0.0865]],\n",
            "\n",
            "         [[-0.0306, -0.0762,  0.1133],\n",
            "          [-0.0629,  0.1901, -0.0911],\n",
            "          [ 0.0527,  0.1757,  0.1323]],\n",
            "\n",
            "         [[ 0.0381, -0.1165, -0.0552],\n",
            "          [-0.0036,  0.0097,  0.0773],\n",
            "          [-0.1408,  0.1242, -0.1229]]]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBkrx7vTnEJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"7_focus_pretrained_classify_random_train_focus\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5kPCVrwpM3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cacde61c-f53d-400d-8574-798133acb087"
      },
      "source": [
        "print(name)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7_focus_pretrained_classify_random_train_focus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn_3layers/\"+name+\".pt\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "eb585665-7d57-4e5a-d321-fa4d9122cd65"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9865</td>\n",
              "      <td>0</td>\n",
              "      <td>20135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0         30000  ...                  20135                       0\n",
              "1        1         30000  ...                  20135                       0\n",
              "2        6         30000  ...                  20135                       0\n",
              "3       11         30000  ...                  20135                       0\n",
              "4       16         30000  ...                  20135                       0\n",
              "5       21         30000  ...                  20135                       0\n",
              "6       26         30000  ...                  20135                       0\n",
              "7       31         30000  ...                  20135                       0\n",
              "8       36         30000  ...                  20135                       0\n",
              "9       41         30000  ...                  20135                       0\n",
              "10      46         30000  ...                  20135                       0\n",
              "\n",
              "[11 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "26543e58-eaa2-40d0-c3e7-12ab3672df00"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAEWCAYAAABBixyCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde1xVVfo/8M8DKBe5CEiKXPIGEqaI4qUZJ9O0tBIrnTQpqa9p2sVKazKZqdFs1Pnp6JeZakZTzL6althIhJWk4tSUelBDMVRUJBFvgVwEkcvz++Ns7EiAqMDp6Of9ep0X+zx77b3W3pPDw1pr7yWqCiIiIiJbYGftBhARERE1FBMXIiIishlMXIiIiMhmMHEhIiIim8HEhYiIiGwGExciIiKyGUxciKxARNJF5K7GLktEdKNj4kI3NBF5QkT2ikiJiJwUkXdFpPU1nCdQRIotPioi5y2+/+5qzqeq3VR1a2OXbQ4iskJE5li7HUR0c2LiQjcsEZkOYD6AVwB4AOgP4FYAm0Sk5dWcS1WzVdW1+mOEwyxi/7Go16GRLoGIiGpg4kI3JBFxBzALwPOq+rmqlqtqFoBHAHQA8JhR7s8i8pGIrBSRImNYJuIq63pCRL4RkUUi8hOAP4tIZxHZLCI/ichZEVll2dMjIlkiMqQhbbjKsr1EZLex72MRWVtX74iIdBGRFBEpMNq41mJfiIhsEpE8ETkgIo8Y8UkAogD8wehp+vRq7hUR0fVi4kI3qt8AcAKw3jKoqsUAkgAMtQhHAlgDoDWABAD/uIb6+gE4AqAtgLcACIC5ANoDuA1AAIA/13P81bSh1rJGL9InAFYA8ALwIYCH6jnPmwC+BOAJwB/A343ztAKwCcBqALcAGAvgHREJVdUlAFYB+KvR0zSinvMTETU6Ji50o2oD4KyqVtSyL9fYX+1rVU1S1UoAHwAIu4b6Tqjq31W1QlVLVTVTVTepapmqngHwNwAD6zn+atpQV9n+ABwAxBo9TOsB7KjnPOUwD521V9ULqvq1EX8AQJaqxhnXsxtAPIDfX+EeEBE1OSYudKM6C6BNHfNNfI391U5abJcAcLqGeSo/Wn4RkbYiskZEckSkEMD/4fJkqaaraUNdZdsDyNHLV069rF01/AHmnqEdxpDT/xjxWwH0E5Fz1R+Yh4fa1XMuIqJmwcSFblTfAigD8LBlUERcAQwH8FUj11dzmfW/GLHuquoO85waaeQ6a8oF4CcilvUE1FVYVU+q6kRVbQ/gaZiHg7rAnOykqGpri4+rqk6pPrTJroCI6AqYuNANSVULYJ6c+3cRGSYiLUSkA4CPAByHeYilKbkBKAZQICJ+MD/Z1NS+BVAJ4DkRcRCRkQD61lVYRH4vIv7G13yYE5IqAIkAgkXkceO+tRCRPiJym1H2FIBOTXcZRER1Y+JCNyxV/SuAmQAWACgEsB3m3oS7VbWsiaufBaAXgAIAn6HGJOGmoKoXYe5hmgDgHMy9PIkw9zzVpg+A7SJSDPMk3xdU9YiqFgG4B+ZJuSdgHpqaD8DROG4ZgFBjGOnfTXU9RES1kcuHw4noRiIi2wH8U1XjrN0WIqLGwB4XohuIiAwUkXbGUFE0gB4APrd2u4iIGgvf8El0Y+kK8zyeVjC/V2a0quZat0lERI2HQ0VERERkMzhURERERDbjphsqatOmjXbo0MHazSAisimpqalnVdXH2u0guukSlw4dOsBkMlm7GURENkVEjlm7DUQAh4qIiIjIhjBxISIiIpvBxIWIiIhsBhMXIiIishlMXIiIiMhmMHEhIiIim9FkiYuIBIjIFhHZLyLpIvKCEfcSkU0icsj46WnERURiRSRTRNJEpJfFuaKN8oeM9Veq471FZK9xTKyISFNdDxEREVlfU77HpQLAdFXdJSJuAFJFZBOAJwB8parzRGQGgBkAXgUwHECQ8ekH4F0A/UTEC8AbACIAqHGeBFXNN8pMBLAdQBKAYQA2NsXFzN8xHxl5GU1xaiKiJhfiFYJX+75q7WYQXbcm63FR1VxV3WVsFwH4AYAfgJEA3jeKvQ/gQWN7JICVavYdgNYi4gvgXgCbVDXPSFY2ARhm7HNX1e/UvODSSotzERER0Q2oWd6cKyIdAITD3DPS1mK12pMA2hrbfgB+tDjsuBGrL368lniT4F8qRERE1tfkk3NFxBVAPIAXVbXQcp/RU9Lky1OLyCQRMYmI6cyZM01dHRERETWRJk1cRKQFzEnLKlVdb4RPGcM8MH6eNuI5AAIsDvc3YvXF/WuJ/4KqLlHVCFWN8PHhGmFERES2qimfKhIAywD8oKp/s9iVAKD6yaBoABss4uONp4v6AygwhpS+AHCPiHgaTyDdA+ALY1+hiPQ36hpvcS4iIiK6ATXlHJffAngcwF4R2WPEZgKYB+AjEZkA4BiAR4x9SQDuA5AJoATAkwCgqnki8iaAnUa52aqaZ2w/A2AFAGeYnyZqkieKiIiI6NdBzNNMbh4RERFqMpms3QwiIpsiIqmqGmHtdhDxzblERERkM5i4EBERkc1g4kJEREQ2g4kLERER2QwmLkRERGQzmLgQERGRzWDiQkRERDaDiQsRERHZDCYuREREZDOYuBAREZHNYOJCRERENoOJCxEREdkMJi5ERERkM5i4EBERkc1g4kJEREQ2g4kLERER2YwmS1xEZLmInBaRfRaxtSKyx/hkicgeI95BREot9v3T4pjeIrJXRDJFJFZExIh7icgmETlk/PRsqmshIiKiX4em7HFZAWCYZUBVx6hqT1XtCSAewHqL3Yer96nqZIv4uwAmAggyPtXnnAHgK1UNAvCV8Z2IiIhuYE2WuKjqNgB5te0zek0eAfBhfecQEV8A7qr6naoqgJUAHjR2jwTwvrH9vkWciIiIblDWmuPyOwCnVPWQRayjiOwWkRQR+Z0R8wNw3KLMcSMGAG1VNdfYPgmgbV2VicgkETGJiOnMmTONdAlERETU3KyVuDyKy3tbcgEEqmo4gGkAVouIe0NPZvTGaD37l6hqhKpG+Pj4XGubiYiIyMocmrtCEXEA8DCA3tUxVS0DUGZsp4rIYQDBAHIA+Fsc7m/EAOCUiPiqaq4xpHS6OdpPRERE1mONHpchADJU9dIQkIj4iIi9sd0J5km4R4yhoEIR6W/MixkPYINxWAKAaGM72iJOREREN6imfBz6QwDfAugqIsdFZIKxayx+OSn3TgBpxuPR6wBMVtXqib3PAHgPQCaAwwA2GvF5AIaKyCGYk6F5TXUtRERE9Osg5ukhN4+IiAg1mUzWbgYRkU0RkVRVjbB2O4j45lwiIiKyGUxciIiIyGYwcSEiIiKbwcSFiIiIbAYTFyIiIrIZTFyIiIjIZjBxISIiIpvBxIWIiIhsBhMXIiIishlMXIiIiMhmMHEhIiIim8HEhYiIiGwGExciIiKyGUxciIiIyGYwcSEiIiKb0WSJi4gsF5HTIrLPIvZnEckRkT3G5z6Lfa+JSKaIHBCRey3iw4xYpojMsIh3FJHtRnytiLRsqmshIiKiX4em7HFZAWBYLfFFqtrT+CQBgIiEAhgLoJtxzDsiYi8i9gDeBjAcQCiAR42yADDfOFcXAPkAJjThtRAREdGvQJMlLqq6DUBeA4uPBLBGVctU9SiATAB9jU+mqh5R1YsA1gAYKSICYDCAdcbx7wN4sFEvgIiIiH51rDHH5TkRSTOGkjyNmB+AHy3KHDdidcW9AZxT1YoacSIiIrqBNXfi8i6AzgB6AsgFsLA5KhWRSSJiEhHTmTNnmqNKIiIiagLNmrio6ilVrVTVKgBLYR4KAoAcAAEWRf2NWF3xnwC0FhGHGvG66l2iqhGqGuHj49M4F0NERETNrlkTFxHxtfj6EIDqJ44SAIwVEUcR6QggCMAOADsBBBlPELWEeQJvgqoqgC0ARhvHRwPY0BzXQERERNbjcOUi10ZEPgRwF4A2InIcwBsA7hKRngAUQBaApwFAVdNF5CMA+wFUAHhWVSuN8zwH4AsA9gCWq2q6UcWrANaIyBwAuwEsa6prISIiol8HMXde3DwiIiLUZDJZuxlERDZFRFJVNcLa7SDim3OJiIjIZjBxISIiIpvBxIWIiIhsBhMXIiIishlMXIiIiMhmMHEhIiIim8HEhYiIiGwGExciIiKyGUxciIiIyGYwcSEiIiKb0WRrFRER0Y0tNTX1FgcHh/cA3A7+IUyNowrAvoqKiqd69+59urYCTFyIiOiaODg4vNeuXbvbfHx88u3s7G6uhe+oSVRVVcmZM2dCT548+R6AyNrKMEMmIqJrdbuPj08hkxZqLHZ2durj41MAcy9era7Y4yIiPgBeBRAKwKk6rqqDG6ORRERks+yYtFBjM/6bqrNjpSE9LqsA/ACgI4BZALIA7GyMxhERERFdjYYkLt6qugxAuaqmqOr/AGBvCxERETW7hiQu5cbPXBG5X0TCAXhd6SARWS4ip0Vkn0Xs/4lIhoikicgnItLaiHcQkVIR2WN8/mlxTG8R2SsimSISKyJixL1EZJOIHDJ+el7VlRMRkc2bM2fOLZ06deoWGRnZsbnr/u9//+u8du1aj+au93q5uLiE17XvwIEDLf/5z39e8Xe8NTXkqaI5IuIBYDqAvwNwB/BiA45bAeAfAFZaxDYBeE1VK0RkPoDXYJ4/AwCHVbVnLed5F8BEANsBJAEYBmAjgBkAvlLVeSIyw/j+ai3HExFRE3tl3fcBB08WuTTmOYPbuZX8v9FhP9ZXZtmyZT7JyckHO3fuXF5fuaZgMplcTCZTqzFjxhTU3FdeXo4WLVo0W1saq75Dhw45rl271mvy5Ml5TVXH9WpIj0u+qhao6j5VHaSqvQH84oJqUtVtNcup6peqWmF8/Q6Af33nEBFfAO6q+p2qKsxJ0IPG7pEA3je237eIExHRTWDcuHGBx48fdxw+fHjQrFmzbjl16pT9kCFDOgcHB4eGhYWFbN++3RkACgoK7EaPHt0hODg4NDg4OHTFihWtgct7HuLi4jxHjRrVAQCWL1/uGRQU1K1r166hERERXWur+8KFCzJ37tz2n376qWdISEjo0qVLPadNm9b+wQcf7NirV6+Qhx9+uGNsbKz3+PHjA6uPGTRoUJfExEQ3AFi/fr17z549Q0JDQ28bPnx4p4KCgjp/H/v5+XWfPHmyf3BwcGj37t1v27dvnyMAjBo1qsO4ceMCe/ToETJlyhT/9PR0x9/97ndB3bp1u613795dd+/e7QQAGRkZLXv27BkSHBwcOnXq1Pb13dOYmBg/k8nkGhISEjpr1qxbYmNjvQcPHtylf//+wb/5zW+6JiYmug0aNKhLdfnx48cHxsbGegPAf/7zH5c+ffp07dat220DBgwIOnbsWJNkOQ3pcfk7gF4NiF2t/wGw1uJ7RxHZDaAQwB9V9T8A/AActyhz3IgBQFtVzTW2TwJoW1dFIjIJwCQACAwMrKsYERFdoyv1jDSF1atXZ6ekpHikpKQc9PX1rYiOjg4ICwsrSU5OPpyQkOAWHR3dMSMjY/+MGTN83d3dKw8ePLgfAM6cOWNf33nnzZvn++WXXx7s2LFj+dmzZ2st6+TkpK+99toJk8nUauXKldkAMG3aNOdDhw45bd++PcPV1VWrf6HXlJub6/CXv/zFd9u2bQfd3d2rYmJi2r355pttFyxYkFtbeQDw8PCoOHjw4P5//OMf3s8//3zAli1bMo1ztdy1a1eGg4MD7rjjjuAlS5Yc6969e9nmzZtbTZkyJfC77747+MwzzwQ+9dRTZ5577rmf5s6d61Pftb/11ls5CxcubFt9/tjYWO/09HSXtLS09LZt21ZWJ141lZWVydSpUwM/++yzzPbt21csXbrU8+WXX/b7+OOPs+qr71rUmbiIyB0AfgPAR0SmWexyB1Dv/+hXIiIxACpgfmIJAHIBBKrqTyLSG8C/RaRbQ8+nqioidT6Sp6pLACwBgIiICD66R0R0A9qxY4dbfHx8JgBERkYWTZo0ySEvL89u27Zt7mvWrDlSXc7Hx6eyvvNEREQUR0VFdRg1alR+VFRU/tW0YdiwYedcXV3r/T2zdevWVocPH3bq27dvCACUl5dL7969i+s7Jjo6Og8AJk6cmPfHP/4xoDr+8MMP5zs4OKCgoMBu9+7drr///e87V++7ePGiAMCuXbtcN27ceBgAnn766Z/efPPNekc7avrd735X2LZt23rvWVpamuOhQ4ecBw8eHAwAVVVV8PHxaZLhu/p6XFoCcDXKWGZYhQBGX2uFIvIEgAcA3G0M/0BVywCUGdupInIYQDCAHFw+nORvxADglIj4qmquMaRU66uBiYiIamM86wEAKC0tvfRl9erV2Zs3b26VkJDg0bt379DU1NT97dq1q/cXd7VWrVpVVW87ODhoVdWlrygrK7MDAFXFgAEDCj/99NOjDW2rnd3PI0mWf6i7urpWAUBlZSXc3NwqMjIy9tdx/DX/0e7i4nLpIlq0aFHzmgQAVFW6dOlSumfPnoxrraeh6hxTMx59ngWgv6rOsvj8TVUPXUtlIjIMwB8ARKpqiUXcR0Tsje1OAIIAHDGGggpFpL/xNNF4ABuMwxIARBvb0RZxIiK6CfXr168oLi7OGwASExPdPD09K7y8vKoGDhxYuGjRoluqy1UPFXl7e5fv2rXLqbKyEhs2bLj0ZGp6errj4MGDzy9evPiEp6dnxZEjR1rWVp+7u3tlcXFxnb9HO3fufDE9Pd2lsrISmZmZLdLS0loBwF133XXeZDK5Vs9VKSwstEtLS3Os79pWrlzpBQDLli3zDA8PP19zv5eXV5W/v//F5cuXewLmHo9vv/3WGQB69epVvHTpUi8AWLp0aa3DV9U8PDwqi4uL6xxV6dy5c1lmZqZzaWmpnD171v7rr792B4AePXpcyMvLc0hOTm4FmBMak8nkVNd5rkdDJueWGI8xJ4nI5urPlQ4SkQ8BfAugq4gcF5EJMD9l5AZgU43Hnu8EkCYiewCsAzBZVasn9j4D4D0AmQAOw/xEEQDMAzBURA4BGGJ8JyKim9T8+fNP7N692yU4ODg0JibGb8WKFUcBYO7cubnnzp2zr55wm5SU5AYAs2bNyhk5cmSXXr16hbRt2/bSsMZLL73kHxwcHBoUFNStT58+xf379y+trb7hw4cXHTx40Ll6cm7N/UOHDi0OCAgo69KlS7cpU6YEhoaGlgBA+/btK/71r39ljR07tlNwcHBoREREyN69e+v9JZ+fn28fHBwc+s4777SNjY2tdT7Rhx9+eCQuLq5N165dQ4OCgrrFx8e3BoB33nkne8mSJbcEBweH5uTk1Dthtm/fvqX29vbatWvX0FmzZt1Sc3+XLl3KR4wYkR8SEtJt5MiRnbp161YCmOf8rFmz5vCMGTP8u3btGtqtW7fQlJQU1/rqulZijNbUXUDkS5gn0b4MYDLMvRtnVNUmHz2OiIhQk8lk7WYQEdkUEUlV1QjL2Pfff58VFhZ21lptuln4+fl1N5lMP/j6+lZcufSN4fvvv28TFhbWobZ9fHMuERER2YyGPA592ZtzAZxAA96cS0REdCOIj493j4mJuexJnICAgLJNmzYdbsx6hg4d2vnHH3+8bK7LW2+9dTwnJ2dvY9YDADt27HAeP378ZW8bbtmyZVVaWlqTT669Xg0ZKnoAwH8ABODnN+fOUtWEpm9e4+NQERHR1eNQETWn+oaKrtjjoqqJxmYBgEGN2C4iIiKiq1LfC+j+DqC+l7pNbZIWEREREdWhvsm5JgCpAJxgfr3/IePTE+aX0xERERE1q/peQPe+qr4PoAeAu1T176r6dwB3w5y8EBERWdWcOXNu6dSpU7fIyMiOVy7d+EaMGNExODi41neeVJs2bVr7119/vc719KzpSm2LjY31zsrKsv6S0BYa8lSRJ8wTcqtfCOdqxIiIiKxq2bJlPsnJyQc7d+7cJOvi1Cc7O9vh+++/b5Wdnb2vueuuT1VVFVQV9vbXtawgAOD//u//2vTs2bO0Q4cOv7i/FRUVcHBoSBrRuBpS4zwAu0VkCwCB+S23f27KRhERkY3597MBOL3fpVHPeUtoCR58u85Vp8eNGxd4/Phxx+HDhwdFRUWdnTx58k9RUVEdsrOzHZ2dnauWLFlyrF+/fqUFBQV2EyZMCExLS3MBgJkzZ5544oknzrm4uISXlJTsBoC4uDjPxMREj/j4+Kzly5d7zp07t72dnZ26ublVmkymA7XVP2TIkODTp0+3DAkJCV28eHF2enq6U1xcnE95ebl06NChbN26dUfd3NyqLI+ZM2fOLXFxcT729vYaHBx8ITEx8UhhYaHdhAkTAjMyMpwrKiokJibmxGOPPXautjpjY2O9N2zY0LqoqMjh1KlTLUaPHv3TwoULcw8cONDy3nvvDQ4PDy/eu3dvq6SkpEMffPCB5yeffOJ18eJFuf/++88tWrToBAC8+uqr7dauXdvG29u7vH379hfDw8NLaqsrLi7Oc9++fS7jx4/v5OTkVGUymX7o2rXr7ZGRkXkpKSnuL7744sn33nvvlgULFvx45513luTm5jpERETclpOTs7eiogLPPvus/zfffON28eJFmThx4ulXXnmlUZ5Aa8hTRXEishFAPyP0qqqebIzKiYiIrtXq1auzU1JSPFJSUg76+vpWREdHB4SFhZUkJycfTkhIcIuOju6YkZGxf8aMGb7u7u6VBw8e3A/8vFZRXebNm+f75ZdfHuzYsWP52bNn6yz76aefZj7wwANB1Qsb9uzZs3T69OlnAWDq1KntY2Nj28TExFy2AHBsbGy7Y8eO7XV2dtbqc8+cOdN30KBBhR9//HHW2bNn7SMiIm6LjIwsdHd3r/plrUBaWlqrvXv3pru6ulaFh4eHjhw5sqBt27YV2dnZjsuWLTt69913Z61fv949MzPTKS0t7QdVxZAhQ7ps3LjR1dXVteqTTz7x2rt37/7y8nL07NkztK7E5cknn8x/9913LyUm1XFvb++K/fv3/wAA7733Xq1DZIsXL27j4eFRuW/fvh9KS0ulT58+ISNGjCgMCQm5WN+9b4gG9fEYiQoXMSQiotrV0zPSXHbs2OEWHx+fCQCRkZFFkyZNcsjLy7Pbtm2b+5o1a45Ul/Px8al3peeIiIjiqKioDqNGjcqPiorKb2j9qampzq+//rpfUVGR/fnz5+0HDhxYULNM165dSx966KGOkZGR56Kios4BwNatW92/+OKL1rGxse0A8wKFmZmZLXv16nWhtnoGDBhQWL1a9f3335+/detW1zFjxpzz9fW9ePfdd58HgM8//9x927Zt7qGhoaEAUFJSYpeRkeFUVFRkd999952r7gm65557au3Zqc/48eOveE+Sk5PdMzIyXBISEjwBoKioyH7//v1OzZa4EBER3WhE5NJ2aWnppS+rV6/O3rx5c6uEhASP3r17h6ampu6vThTqM2nSpI7r1q3LvOOOO0pjY2O9U1JS3GqW2bJly6GNGze6bdiwwWPBggW+Bw4cSFdVrFu3LjMsLKzsattt+d3FxeVSD42q4sUXX8ytOTwze/bsOicRN5Tl8JeDg4NWVppvTUlJyaWGqaosXLgwe9SoUYXXW19NDVmriIiI6FevX79+RXFxcd4AkJiY6Obp6Vnh5eVVNXDgwMJFixZd+oVdPVTk7e1dvmvXLqfKykps2LDh0kMn6enpjoMHDz6/ePHiE56enhVHjhxp0CtASkpK7AIDA8vLyspkzZo1v1gap7KyEocPH245YsSIorfffjunuLjYvqCgwH7QoEGFCxcubFtVZc4HvvnmG+f66vn666/dT506ZV9cXCxJSUmtBw4cWFyzzPDhwws/+OCDNgUFBXYAcPTo0RY5OTkOgwcPLk5KSmpdXFws+fn5dps2bWpdX12urq6VBQUFdQ6XBQQElO3YsaMVAKxaterSPRw6dGjBu+++61NWViYAkJaW5lhYWNgoOccVe1xEpLZ1iYpUtdlncBMREdVl/vz5J6KiojoEBweHOjs7V61YseIoAMydOzf3ySefDAwKCupmZ2enM2fOPBEdHX1u1qxZOSNHjuzi5eVVERYWVnL+/Hk7AHjppZf8s7KyHFVVBgwYUNi/f//ShtQ/Y8aME3379r3Ny8urolevXsXFxcWX/cKvqKiQcePGdSwqKrJXVXnqqadOt2nTpnLevHknJk2aFBgSEhJaVVUlAQEBZVu2bMmsq54ePXqcj4yM7Hzy5MmWo0eP/unOO+8sOXDgwGXJ1cMPP1yYnp7u1KdPnxDA3BuzatWqowMGDCh56KGH8m6//fZu3t7e5T169Dhf3zWNHz/+7PPPP3/rK6+8UmUymX6o5ZpPjRkzptOKFSt8hg4demnY6aWXXjqblZXl2L1799tUVby8vMqTkpIaZW2nhqxVlAXzOkX5MD9V1BrASQCnAExU1dTGaEhz4VpFRERXj2sV/TrExsZ6m0ymVitXrsy2dluaUn1rFTWk22YTgPtUtY2qegMYDiARwDMA3mm0VhIRERFdQUMm5/ZX1YnVX1T1SxFZoKpPi4hjfQeKyHIADwA4raq3GzEvAGsBdACQBeARVc0X8+yi/wVwH4ASAE+o6i7jmGgAfzROO8d4oy9EpDeAFQCcASQBeEGv1IVERER0FeLj491jYmL8LWMBAQFlmzZtapShj2uo86fGru/xxx8P3Llzp6tlbMqUKadeeOGFRq/rejVkqOhLAF8BWGOExgAYCmAYgJ2q2queY+8EUAxgpUXi8lcAeao6T0RmAPBU1VdF5D4Az8OcuPQD8L+q2s9IdEwAImBe9DEVQG8j2dkBYCqA7TAnLrGqurG+6+FQERHR1eNQETWn6x0qGgfAH8C/jU+gEbMH8Eh9B6rqNvy8VEC1kQDeN7bfB/CgRXylmn0HoLWI+AK4F8AmVc1T1XyYh66GGfvcVfU7o5dlpcW5iIiI6AbUkDfnnoW5J6Q2dc56rkdbVc01tk8CqF7cyQ+A5QuMjhux+uLHa4n/gohMAjAJAAIDA6+hycCsT9Ox/0SjP45ORNQsQtu7440R3azdDKLr1pDHoYMBvAzznJRL5VV18PVWrqoqIk0+J0VVlwBYApiHipq6PnK7H+cAAB+aSURBVCIiImoaDZmc+zGAfwJ4D8AV3xzYAKdExFdVc43hnup1HHJgfuy6mr8RywFwV434ViPuX0v5JsG/VIiIiKyvIXNcKlT1XVXdoaqp1Z/rqDMBQLSxHY2f10BKADBezPoDKDCGlL4AcI+IeIqIJ4B7AHxh7CsUkf7GE0njwfWUiIhuKnPmzLmlU6dO3SIjIzs2d93//e9/ndeuXevR3PVeLxcXl/D69j/99NP+Xbp06fb000/711UmNjbWe/z48dc29+I6NaTH5VMReQbAJwAuraOgqjUn3f6CiHwIc29JGxE5DuANAPMAfCQiEwAcw88TfJNgfqIoE+bHoZ+srkdE3gSw0yg326LuZ/Dz49AbjQ8REd0kli1b5pOcnHywc+fOzf42d5PJ5GIymVqNGTPmF4splpeXo0WLFs3Wlsasb/Xq1W3y8/P3ODj8OpczbEirqntHXrGIKYBOVzpQVR+tY9fdtZRVAM/WcZ7lAJbXEjcBuP1K7SAioqb1p2/+FJCZn+nSmOfs4tml5M3fvlnnqtPjxo0LPH78uOPw4cODoqKizk6ePPmnqKioDtnZ2Y7Ozs5VS5YsOdavX7/SgoICuwkTJgSmpaW5AMDMmTNPPPHEE+dcXFzCS0pKdgNAXFycZ2Jiokd8fHzW8uXLPefOndvezs5O3dzcKk0m04GadV+4cEHmzp3b/sKFC3YhISGu06dPz/3hhx+cjxw54pidne3o5+dXNnTo0ELLt9wOGjSoy/Tp00898MADRevXr3efPXt2+4sXL8qtt95atmbNmiwPD4+qmvUAgJ+fX/cRI0bkb9682d3R0VE//PDDI7fffnvZqFGjOjg6Olbt27fPpW/fvsUvvfTSmcmTJwfm5eU5ODk5Vb333nvHwsPDL2RkZLQcO3Zsp5KSErthw4bVuxr04MGDu5SUlNjffvvtodOnT89t1apV1bx583zLy8vtPD09K9auXXskICCgwvKY2u5XRUUFnn32Wf9vvvnG7eLFizJx4sTTNRd8vFYNeaqo2bvfiIiIrmT16tXZKSkpHikpKQd9fX0roqOjA8LCwkqSk5MPJyQkuEVHR3fMyMjYP2PGDF93d/fKgwcP7gd+XmSxLvPmzfP98ssvD3bs2LH87NmztZZ1cnLS11577YRlYjJt2jTnQ4cOOW3fvj3D1dVVY2NjvWs7Njc31+Evf/mL77Zt2w66u7tXxcTEtHvzzTfbLliwILe28gDg4eFRcfDgwf3/+Mc/vJ9//vmA6rWMcnNzW+7atSvDwcEBd9xxR/CSJUuOde/evWzz5s2tpkyZEvjdd98dfOaZZwKfeuqpM88999xPc+fO9anv2jdv3pzp4uISnpGRcelejR07NsPOzg5/+9vf2syePbvd0qVLLZ/orfV+LV68uI2Hh0flvn37figtLZU+ffqEjBgxojAkJORiffU3RJ2Ji4gMVtXNIvJwbftVdf31Vk5ERDeG+npGmsuOHTvc4uPjMwEgMjKyaNKkSQ55eXl227Ztc1+zZs2R6nI+Pj71PmgSERFRHBUV1WHUqFH5UVFR+VfThmHDhp1zdXWt9+nVrVu3tjp8+LBT3759QwCgvLxcevfu/YsVni1FR0fnAcDEiRPz/vjHP156kOXhhx/Od3BwQEFBgd3u3btdf//733eu3nfx4kUBgF27drlu3LjxMAA8/fTTP7355pt1zl2p6ejRoy0ffPBB/zNnzrS4ePGiXUBAQFnNMrXdr+TkZPeMjAyXhIQETwAoKiqy379/v1OTJi4ABgLYDGBELfsUABMXIiKyWebnOsxKS0svfVm9enX25s2bWyUkJHj07t07NDU1dX+7du0a9FRtq1atLg33ODg4aFXVz6M/ZWVldgCgqhgwYEDhp59+erShbbWz+/lZGsvXiLi6ulYBQGVlJdzc3Cqqe0pqOf6aXgXy3HPPBb7wwgsno6KiChITE91mz57dvmaZ2u6XqsrChQuzR40a1egvQKvzqSJVfcP4+WQtn/9p7IYQERFdj379+hXFxcV5A0BiYqKbp6dnhZeXV9XAgQMLFy1adEt1ueqhIm9v7/Jdu3Y5VVZWYsOGDZ7V+9PT0x0HDx58fvHixSc8PT0rjhw50rK2+tzd3SuLi4vr/D3auXPni+np6S6VlZXIzMxskZaW1goA7rrrrvMmk8l13759jgBQWFhol5aWVu/afytXrvQCgGXLlnmGh4efr7nfy8uryt/f/+Ly5cs9AaCqqgrffvutMwD06tWreOnSpV4AsHTp0lqHr+pSVFRkHxgYWA4AK1asqPXY2u7X0KFDC959912fsrIyAYC0tDTHwsLChjzJfEUNeQGdI4BR+OUL6GY3RgOIiIgaw/z5809ERUV1CA4ODnV2dq5asWLFUQCYO3du7pNPPhkYFBTUzc7OTmfOnHkiOjr63KxZs3JGjhzZxcvLqyIsLKzk/PnzdgDw0ksv+WdlZTmqqgwYMKCwf//+pbXVN3z48KIFCxb4hoSEhE6fPv0X81OGDh1a/Pbbb5d16dKlW5cuXS6EhoaWAED79u0r/vWvf2WNHTu2U/VwzhtvvJHTo0ePXwzDVMvPz7cPDg4ObdmypVoOe1n68MMPj0ycOPHW+fPn+1ZUVMhDDz2Ud8cdd5S+88472WPHju20ePHidleanFtTTEzMiUcffbSzh4dHxYABA4qys7N/kWDVdr/69etXmpWV5di9e/fbVFW8vLzKk5KSGmVRyoYssvg5gAKYFze81FWmqgsbowHNjYssEhFdPS6yaD1+fn7dTSbTD76+vhVXLn1jqG+RxYY8Du2vqsMat0lEREREV68hict/RaS7qu5t8tYQERH9ysTHx7vHxMRc9iROQEBA2aZNmxpl6KPa0KFDO//444+XDcW89dZbx3Nychr99++OHTucx48ff9nrTlq2bFmVlpaW0dh1NbaGDBXtB9AFwFGY35wrML8vrkfTN6/xcaiIiOjqcaiImtP1DhUNb9zmEBEREV2b+l5A566qhQCKmrE9RERERHWqr8dlNYAHYH6aSGEeIqrWoLWKiIiIiBpTnYmLqj5g/ORaRURERPSr0KC32ImIp4j0FZE7qz9N3TAiIqIrmTNnzi2dOnXqFhkZaZU/skeMGNExODg4dNasWbfUVWbatGntX3/99bbN2a6GulLbdu/e7RQSEhJ62223haanp9f5dl8/P7/uubm5DZk3e90a8ubcpwC8AMAfwB4A/QF8C2Bw0zaNiIiofsuWLfNJTk4+2Llz5/Lmrjs7O9vh+++/b5Wdnb2vueuuT1VVFVQV9vb1LoLdIB9//HHryMjI/L/+9a91rlzd3BqSHb0AoA+A71R1kIiEAPjLtVYoIl0BrLUIdQLwOoDWACYCOGPEZ6pqknHMawAmwPzm3qmq+oURHwbgfwHYA3hPVedda7uIiOjanZgZE1B26JBLY57TMSiopP1f3qpz1elx48YFHj9+3HH48OFBUVFRZydPnvxTVFRUh+zsbEdnZ+eqJUuWHOvXr19pQUGB3YQJEwLT0tJcAGDmzJknnnjiiXMuLi7hJSUluwEgLi7OMzEx0SM+Pj5r+fLlnnPnzm1vZ2enbm5ulSaT6UBt9Q8ZMiT49OnTLUNCQkIXL16cnZ6e7hQXF+dTXl4uHTp0KFu3bt1RNze3Kstj5syZc0tcXJyPvb29BgcHX0hMTDxSWFhoN2HChMCMjAzniooKiYmJOfHYY4/V+mr+2NhY7w0bNrQuKipyOHXqVIvRo0f/tHDhwtwDBw60vPfee4PDw8OL9+7d2yopKenQBx984PnJJ594Xbx4Ue6///5zixYtOgEAr776aru1a9e28fb2Lm/fvv3F8PDwktrqWrt2rceSJUva2tnZaUpKitv27dsPDhkypHNubm7LsrIyu8mTJ596+eWXL3scvrCw0C4yMrJTbm5uy6qqKvnDH/5wYuLEifn/+c9/XKZNmxZQUlJi5+npWbFq1aqsW2+99ZqSzYYkLhdU9YKIQEQcVTXDSD6uiaoeANATAETEHkAOgE8APAlgkaousCwvIqEAxgLoBqA9gGQRCTZ2vw1gKIDjAHaKSIKq1royJhER3VhWr16dnZKS4pGSknLQ19e3Ijo6OiAsLKwkOTn5cEJCglt0dHTHjIyM/TNmzPB1d3evPHjw4H7g50UW6zJv3jzfL7/88mDHjh3Lz549W2fZTz/9NPOBBx4Iql6RuWfPnqXTp08/CwBTp05tHxsb2yYmJua05TGxsbHtjh07ttfZ2Vmrzz1z5kzfQYMGFX788cdZZ8+etY+IiLgtMjKy0N3dveqXtQJpaWmt9u7dm+7q6loVHh4eOnLkyIK2bdtWZGdnOy5btuzo3XffnbV+/Xr3zMxMp7S0tB9UFUOGDOmyceNGV1dX16pPPvnEa+/evfvLy8vRs2fP0LoSlzFjxhRs3779jKura+Xs2bNPAcCqVauy2rZtW1lcXCzh4eGhjz32WL7lytnr1693b9euXfnWrVszAeCnn36yLysrk6lTpwZ+9tlnme3bt69YunSp58svv+z38ccfZ9X3v0NdGpK4HBeR1gD+DWCTiOQDOHYtldXibgCHVfWY5fLiNYwEsEZVywAcFZFMAH2NfZmqegQARGSNUZaJCxFRM6uvZ6S57Nixwy0+Pj4TACIjI4smTZrkkJeXZ7dt2zZ3y4UJfXx8Kus+CxAREVEcFRXVYdSoUflRUVH5Da0/NTXV+fXXX/crKiqyP3/+vP3AgQMLapbp2rVr6UMPPdQxMjLyXFRU1DkA2Lp1q/sXX3zROjY2th0AlJWVSWZmZstevXpdqK2eAQMGFFYnC/fff3/+1q1bXceMGXPO19f34t13330eAD7//HP3bdu2uYeGhoYCQElJiV1GRoZTUVGR3X333XeuuifonnvuuapFF+fPn9/2s88+aw0AJ0+ebJGenu7Url27S6tV9+rVqzQmJiZgypQpfiNHjiwYNmxY8c6dO50OHTrkPHjw4GDAPJTl4+NzzUN7V0xcVPUhY/PPIrIFgAeAz6+1whrGAvjQ4vtzIjIegAnAdFXNB+AH4DuLMseNGAD8WCPer7ZKRGQSgEkAEBgY2DgtJyIim2b5B3NpaemlL6tXr87evHlzq4SEBI/evXuHpqam7rfsVajLpEmTOq5bty7zjjvuKI2NjfVOSUlxq1lmy5YthzZu3Oi2YcMGjwULFvgeOHAgXVWxbt26zLCwsDpXh66r3ZbfXVxcLvXQqCpefPHF3FdeeeWyoZzZs2fXOYn4ShITE91SUlLcTCZThpubW1Xfvn27lpaWXvaQT48ePcp27dq1Pz4+3uNPf/qTX3JycuEjjzxyrkuXLqV79uxplOUE6n2qSETsReRSRaqaoqoJqnrxeisWkZYAIgF8bITeBdAZ5mGkXACNtvq0qi5R1QhVjfDx8Wms0xIR0a9Iv379iuLi4rwB8y9ZT0/PCi8vr6qBAwcWLlq06NIv7OqhIm9v7/Jdu3Y5VVZWYsOGDZ7V+9PT0x0HDx58fvHixSc8PT0rjhw50rIh9ZeUlNgFBgaWl5WVyZo1a7xq7q+srMThw4dbjhgxoujtt9/OKS4uti8oKLAfNGhQ4cKFC9tWVZnzjm+++ca5vnq+/vpr91OnTtkXFxdLUlJS64EDBxbXLDN8+PDCDz74oE1BQYEdABw9erRFTk6Ow+DBg4uTkpJaFxcXS35+vt2mTZtaN+TaAODcuXP2Hh4elW5ublW7d+92+v7771vVLJOVldXCzc2t6plnnsmbNm3ayT179rj06NHjQl5enkNycnIrwNyjZDKZnBpab0319rioaqWIHBCRQFXNvtZK6jAcwC5VPWXUdap6h4gsBZBofM0BEGBxnL8RQz1xIiK6ycyfP/9EVFRUh+Dg4FBnZ+eqFStWHAWAuXPn5j755JOBQUFB3ezs7HTmzJknoqOjz82aNStn5MiRXby8vCrCwsJKzp8/bwcAL730kn9WVpajqsqAAQMK+/fvX9qQ+mfMmHGib9++t3l5eVX06tWruLi4+LL5MRUVFTJu3LiORUVF9qoqTz311Ok2bdpUzps378SkSZMCQ0JCQquqqiQgIKBsy5YtmXXV06NHj/ORkZGdT5482XL06NE/3XnnnSUHDhy4LLl6+OGHC9PT05369OkTAph7Y1atWnV0wIABJQ899FDe7bff3s3b27u8R48e52uv5ZdGjRpVsGTJEp9OnTp169Sp04WwsLBfHJuamur82muv+dvZ2cHBwUHfeeedY05OTrpmzZrDU6dODSwqKrKvrKyUKVOmnIqIiKh1KOxKGrLI4jYA4QB2ALjUSFWNvJYKLc67BsAXqhpnfPdV1Vxj+yUA/VR1rIh0g/ktvn1hnpz7FYAgmN/kexDmeTI5AHYCGKeq6fXVy0UWiYiuHhdZ/HWIjY31NplMrVauXNnYnQm/Kte7yOKfGrc5gIi0gvlpoKctwn8VkZ4wLyeQVb1PVdNF5COYJ91WAHhWVSuN8zwH4AuYH4defqWkhYiIiGxbQxKX+1T1VcuAiMwHkHKtlarqeQDeNWKP11P+LQBv1RJPApB0re0gIiK6kvj4ePeYmBh/y1hAQEDZpk2bDlupzp8au77HH388cOfOna6WsSlTppx64YUXGr2u69WQoaJdqtqrRixNVXs0acuaCIeKiIiuXh1DRUe6d++eb2dnV/8vEqKrUFVVJXv37vUMCwurdTHnOp8qEpEpIrIXQFcRSbP4HAWQ1lQNJiIim7HvzJkzHlVVVXW+iIvoalRVVcmZM2c8ANS5jEJ9Q0WrAWwEMBfADIt4karmNU4TiYjIVlVUVDx18uTJ906ePHk7GrhoL9EVVAHYV1FR8VRdBepMXFS1AEABgEeboGFERGTjevfufRrm93ERNRtmyERERGQzmLgQERGRzWDiQkRERDaDiQsRERHZDCYuREREZDOYuBAREZHNYOJCRERENoOJCxEREdkMJi5ERERkM5i4EBERkc1g4kJEREQ2g4kLERER2QyrJS4ikiUie0Vkj4iYjJiXiGwSkUPGT08jLiISKyKZIpImIr0szhNtlD8kItHWuh4iIiJqetbucRmkqj1VNcL4PgPAV6oaBOAr4zsADAcQZHwmAXgXMCc6AN4A0A9AXwBvVCc7REREdOOxduJS00gA7xvb7wN40CK+Us2+A9BaRHwB3Atgk6rmqWo+gE0AhjV3o4mIiKh5WDNxUQBfikiqiEwyYm1VNdfYPgmgrbHtB+BHi2OPG7G64pcRkUkiYhIR05kzZxrzGoiIiKgZOVix7gGqmiMitwDYJCIZljtVVUVEG6MiVV0CYAkARERENMo5iYiIqPlZrcdFVXOMn6cBfALzHJVTxhAQjJ+njeI5AAIsDvc3YnXFiYiI6AZklcRFRFqJiFv1NoB7AOwDkACg+smgaAAbjO0EAOONp4v6AygwhpS+AHCPiHgak3LvMWJERER0A7LWUFFbAJ+ISHUbVqvq5yKyE8BHIjIBwDEAjxjlkwDcByATQAmAJwFAVfNE5E0AO41ys1U1r/kug4iIiJqTqN5cUz4iIiLUZDJZuxlERDZFRFItXl1BZDW/tsehiYiIiOrExIWIiIhsBhMXIiIishlMXIiIiMhmMHEhIiIim8HEhYiIiGwGExciIiKyGUxciIiIyGYwcSEiIiKbwcSFiIiIbAYTFyIiIrIZTFyIiIjIZjBxISIiIpvBxIWIiIhsBhMXIiIishnNnriISICIbBGR/SKSLiIvGPE/i0iOiOwxPvdZHPOaiGSKyAERudciPsyIZYrIjOa+FiIiImpeDlaoswLAdFXdJSJuAFJFZJOxb5GqLrAsLCKhAMYC6AagPYBkEQk2dr8NYCiA4wB2ikiCqu5vlqsgIiKiZtfsiYuq5gLINbaLROQHAH71HDISwBpVLQNwVEQyAfQ19mWq6hEAEJE1RlkmLkRERDcoq85xEZEOAMIBbDdCz4lImogsFxFPI+YH4EeLw44bsbritdUzSURMImI6c+ZMI14BERERNSerJS4i4gogHsCLqloI4F0AnQH0hLlHZmFj1aWqS1Q1QlUjfHx8Guu0RERE1MysMccFItIC5qRllaquBwBVPWWxfymARONrDoAAi8P9jRjqiRMREdENyBpPFQmAZQB+UNW/WcR9LYo9BGCfsZ0AYKyIOIpIRwBBAHYA2AkgSEQ6ikhLmCfwJjTHNRAREZF1WKPH5bcAHgewV0T2GLGZAB4VkZ4AFEAWgKcBQFXTReQjmCfdVgB4VlUrAUBEngPwBQB7AMtVNb05L4SIiIial6iqtdvQrCIiItRkMlm7GURENkVEUlU1wtrtIOKbc4mIiMhmMHEhIiIim8HEhYiIiGwGExciIiKyGUxciIiIyGYwcSEiIiKbwcSFiIiIbAYTFyIiIrIZTFyIiIjIZjBxISIiIpvBxIWIiIhsBhMXIiIishlMXIiIiMhmMHEhIiIim8HEhYiIiGwGExciIiKyGTafuIjIMBE5ICKZIjLD2u0hIiKipmPTiYuI2AN4G8BwAKEAHhWRUOu2ioiIiJqKg7UbcJ36AshU1SMAICJrAIwEsL+xKzo56X6UHT3R2KclImoWjh3bo92Sz6zdDKLrZtM9LgD8APxo8f24EbuMiEwSEZOImM6cOdNsjSMiIqLGZes9Lg2iqksALAGAiIgIvZZz8C8VIiIi67P1HpccAAEW3/2NGBEREd2AbD1x2QkgSEQ6ikhLAGMBJFi5TURERNREbHqoSFUrROQ5AF8AsAewXFXTrdwsIiIiaiI2nbgAgKomAUiydjuIiIio6dn6UBERERHdRJi4EBERkc1g4kJEREQ2g4kLERER2QxRvab3sdksETkD4Ng1Ht4GwNlGbI6t4n0w4334Ge+F2Y18H25VVR9rN4LopktcroeImFQ1wtrtsDbeBzPeh5/xXpjxPhA1PQ4VERERkc1g4kJEREQ2g4nL1Vli7Qb8SvA+mPE+/Iz3woz3gaiJcY4LERER2Qz2uBAREZHNYOJCRERENoOJSwOJyDAROSAimSIyw9rtaS4islxETovIPouYl4hsEpFDxk9Pa7axOYhIgIhsEZH9IpIuIi8Y8ZvqXoiIk4jsEJHvjfswy4h3FJHtxr+PtSLS0tptbQ4iYi8iu0Uk0fh+U94HoubExKUBRMQewNsAhgMIBfCoiIRat1XNZgWAYTViMwB8papBAL4yvt/oKgBMV9VQAP0BPGv8N3Cz3YsyAINVNQxATwDDRKQ/gPkAFqlqFwD5ACZYsY3N6QUAP1h8v1nvA1GzYeLSMH0BZKrqEVW9CGANgJFWblOzUNVtAPJqhEcCeN/Yfh/Ag83aKCtQ1VxV3WVsF8H8y8oPN9m9ULNi42sL46MABgNYZ8Rv+PsAACLiD+B+AO8Z3wU34X0gam5MXBrGD8CPFt+PG7GbVVtVzTW2TwJoa83GNDcR6QAgHMB23IT3whge2QPgNIBNAA4DOKeqFUaRm+Xfx2IAfwBQZXz3xs15H4iaFRMXui5qfp7+pnmmXkRcAcQDeFFVCy333Sz3QlUrVbUnAH+YeyNDrNykZiciDwA4raqp1m4L0c3GwdoNsBE5AAIsvvsbsZvVKRHxVdVcEfGF+S/vG56ItIA5aVmlquuN8E15LwBAVc+JyBYAdwBoLSIORm/DzfDv47cAIkXkPgBOANwB/C9uvvtA1OzY49IwOwEEGU8MtAQwFkCCldtkTQkAoo3taAAbrNiWZmHMX1gG4AdV/ZvFrpvqXoiIj4i0NradAQyFeb7PFgCjjWI3/H1Q1ddU1V9VO8D8/webVTUKN9l9ILIGvjm3gYy/rBYDsAewXFXfsnKTmoWIfAjgLgBtAJwC8AaAfwP4CEAggGMAHlHVmhN4bygiMgDAfwDsxc9zGmbCPM/lprkXItID5kmn9jD/4fORqs4WkU4wT1r3ArAbwGOqWma9ljYfEbkLwMuq+sDNfB+ImgsTFyIiIrIZHCoiIiIim8HEhYiIiGwGExciIiKyGUxciIiIyGYwcSEiIiKbwcSF6FdORO6qXn2YiOhmx8SFiIiIbAYTF6JGIiKPicgOEdkjIv8yFiMsFpFFIpIuIl+JiI9RtqeIfCciaSLyiYh4GvEuIpIsIt+LyC4R6Wyc3lVE1olIhoisMt7kCxGZJyL7jfMssNKlExE1GyYuRI1ARG4DMAbAb40FCCsBRAFoBcCkqt0ApMD85mEAWAngVVXtAfPbeKvjqwC8raphAH4DoHrl6XAALwIIBdAJwG9FxBvAQwC6GeeZ07RXSURkfUxciBrH3QB6A9gpInuM751gXh5grVHm/wAMEBEPAK1VNcWIvw/gThFxA+Cnqp8AgKpeUNUSo8wOVT2uqlUA9gDoAKAAwAUAy0TkYQDVZYmIblhMXIgahwB4X1V7Gp+uqvrnWspd6xobluvdVAKoXoG4L4B1AB4A8Pk1npuIyGYwcSFqHF8BGC0itwCAiHiJyK0w/xurXi14HICvVf9/e3eo0wAMRWH4P4RkCxnZo+BwewcMciHTKKZRPAU8xswEjpdAoqYwhMAU4iJWOxTL1uX/ZJvctu7ktknrE/hIMmnjU+Clqr6AVZKrVmOQ5GzbgklGwLiqlsAdcLGLg0nSITnd9wakY1BVr0nugeckJ8APcAusgcs2987mHQzADfDYgskbMGvjU+ApyUOrcf3HsufAIsmQTcdn/s/HkqSD4+/Q0g4l+a6q0b73IUnHwqsiSZLUDTsukiSpG3ZcJElSNwwukiSpGwYXSZLUDYOLJEnqhsFFkiR14xfctHKShcRDuQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "b1c8e0ec-c751-4461-c393-e2afdd8c2805"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3305</td>\n",
              "      <td>0</td>\n",
              "      <td>6695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0         10000  ...                   6695                       0\n",
              "1        1         10000  ...                   6695                       0\n",
              "2        6         10000  ...                   6695                       0\n",
              "3       11         10000  ...                   6695                       0\n",
              "4       16         10000  ...                   6695                       0\n",
              "5       21         10000  ...                   6695                       0\n",
              "6       26         10000  ...                   6695                       0\n",
              "7       31         10000  ...                   6695                       0\n",
              "8       36         10000  ...                   6695                       0\n",
              "9       41         10000  ...                   6695                       0\n",
              "10      46         10000  ...                   6695                       0\n",
              "\n",
              "[11 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "94628a51-0957-4d7e-f103-d27a8cbc05d3"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ANVZc6AB6Sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "92a3436f-2efd-4e10-b560-95c99c2e0d0a"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 32 %\n",
            "total correct 9865\n",
            "total train set images 30000\n",
            "focus_true_pred_true 9865 =============> FTPT : 32 %\n",
            "focus_false_pred_true 0 =============> FFPT : 0 %\n",
            "focus_true_pred_false 20135 =============> FTPF : 67 %\n",
            "focus_false_pred_false 0 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  30000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIkxwKHWB9kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "983ced43-42cd-4dfb-f027-fab38d2957be"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 33 %\n",
            "total correct 3305\n",
            "total train set images 10000\n",
            "focus_true_pred_true 3305 =============> FTPT : 33 %\n",
            "focus_false_pred_true 0 =============> FFPT : 0 %\n",
            "focus_true_pred_false 6695 =============> FTPF : 66 %\n",
            "focus_false_pred_false 0 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  10000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "15e7042d-bea6-4cc3-bd57-199681364497"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 32 %\n",
            "total correct 9865\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cee69db1-9930-406a-caf7-4af9c01d364b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 33 %\n",
            "total correct 3305\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}