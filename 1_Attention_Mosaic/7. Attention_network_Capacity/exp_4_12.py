# -*- coding: utf-8 -*-
"""exp_4_12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AB6P-iE5bTqZrM7_wFA-at6sXio-yVse
"""

import torch.nn as nn
import torch.nn.functional as F

import pandas as pd
import numpy as np

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
import torch.optim as optim
#from matplotlib import pyplot as plt

import copy
import pickle
# Ignore warnings
import warnings
warnings.filterwarnings("ignore")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)


testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)


classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

foreground_classes = {'horse','ship', 'truck'}

background_classes = {'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog'}

images ,labels = iter(trainloader).next()

images.shape

dataiter = iter(trainloader)
background_data=[]
background_label=[]
foreground_data=[]
foreground_label=[]
batch_size=10

for i in range(5000):   #5000*batch_size = 50000 data points
    images, labels = dataiter.next()
    for j in range(batch_size):
        if(classes[labels[j]] in background_classes):
            img = images[j].tolist()
            background_data.append(img)
            background_label.append(labels[j])
        else:
            img = images[j].tolist()
            foreground_data.append(img)
            foreground_label.append(labels[j])
            
foreground_data = torch.tensor(foreground_data)
foreground_label = torch.tensor(foreground_label)
background_data = torch.tensor(background_data)
background_label = torch.tensor(background_label)

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img#.numpy()
    plt.imshow(np.transpose(npimg, axes = (1, 2, 0)))
    plt.show()

def create_mosaic_img(bg_idx,fg_idx,fg): 
    """
      bg_idx : list of indexes of background_data[] to be used as background images in mosaic
      fg_idx : index of image to be used as foreground image from foreground data
      fg : at what position/index foreground image has to be stored out of 0-8
    """
    image_list=[]
    j=0
    for i in range(9):
        if i != fg:
            image_list.append(background_data[bg_idx[j]].type("torch.DoubleTensor"))
            j+=1
        else: 
            image_list.append(foreground_data[fg_idx].type("torch.DoubleTensor"))
            label = foreground_label[fg_idx] -7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2
    #image_list = np.concatenate(image_list ,axis=0)
    image_list = torch.stack(image_list) 
    return image_list,label

desired_num = 30000
mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images
fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               
mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic
for i in range(desired_num):
    bg_idx = np.random.randint(0,35000,8)
    fg_idx = np.random.randint(0,15000)
    fg = np.random.randint(0,9)
    fore_idx.append(fg)
    image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)
    mosaic_list_of_images.append(image_list)
    mosaic_label.append(label)

np.shape(fore_idx)

class MosaicDataset(Dataset):
    """MosaicDataset dataset."""

    def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):
        """
          Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.mosaic = mosaic_list_of_images
        self.label = mosaic_label
        self.fore_idx = fore_idx

    def __len__(self):
        return len(self.label)

    def __getitem__(self, idx):
      #print(len(self.mosaic),len(self.label))
      return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]

batch = 50
msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)
train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)

class Conv_module(nn.Module):
    def __init__(self,inp_ch,f,s,k,pad):
        super(Conv_module,self).__init__()
        self.inp_ch = inp_ch
        self.f = f
        self.s = s 
        self.k = k 
        self.pad = pad
        
        
        self.conv = nn.Conv2d(self.inp_ch,self.f,k,stride=s,padding=self.pad)
        self.bn = nn.BatchNorm2d(self.f)
        self.act = nn.ReLU()
    def forward(self,x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.act(x)
        return x

class inception_module(nn.Module):
    def __init__(self,inp_ch,f0,f1):
        super(inception_module, self).__init__()
        self.inp_ch = inp_ch
        self.f0 = f0
        self.f1 = f1
        
        
        
        self.conv1 = Conv_module(self.inp_ch,self.f0,1,1,pad=0)
        self.conv3 = Conv_module(self.inp_ch,self.f1,1,3,pad=1)
        #self.conv1 = nn.Conv2d(3,self.f0,1)
        #self.conv3 = nn.Conv2d(3,self.f1,3,padding=1)
    def forward(self,x):
        x1 = self.conv1.forward(x)
        x3 = self.conv3.forward(x)
        #print(x1.shape,x3.shape)
        
        x = torch.cat((x1,x3),dim=1)
        
    
        return x

class downsample_module(nn.Module):
    def __init__(self,inp_ch,f):
        super(downsample_module,self).__init__()
        self.inp_ch = inp_ch
        self.f = f
        self.conv = Conv_module(self.inp_ch,self.f,1,3,pad=1)
        self.pool = nn.MaxPool2d(3,stride=1,padding=1)
    def forward(self,x):
        x1 = self.conv(x)
        #print(x1.shape)
        x2 = self.pool(x)
        #print(x2.shape)
        x = torch.cat((x1,x2),dim=1)
        
        return x

class focus_inception_net(nn.Module):
    def __init__(self):
        super(focus_inception_net,self).__init__()
        self.conv1 = Conv_module(3,64,1,3,0)
        
        self.incept1 = inception_module(64,16,16)
        self.incept2 = inception_module(32,16,56)
        
        self.downsample1 = downsample_module(72,72)
        
        self.incept3 = inception_module(144,32,32)

        self.incept4 = inception_module(64,32,32)

        self.pool = nn.AvgPool2d(5)


        self.linear = nn.Linear(64*6*6,1)
    def helper(self,x):
        x = self.conv1.forward(x)
        
        x = self.incept1.forward(x)

        x = self.incept2.forward(x)

        
        x = self.downsample1.forward(x)
        #print(x.shape)
        
        x = self.incept3.forward(x)

        x = self.incept4.forward(x)

        x = self.pool(x)
        #print(x.shape)

        x = x.view(-1,6*6*64)

        x = self.linear(x) 

        return x
    
    def forward(self, z):
        x = torch.zeros([batch,9],dtype=torch.float64)
        y = torch.zeros([batch,3, 32,32], dtype=torch.float64)
        x,y = x.to(device),y.to(device)
        z = z.to(device)
        for i in range(9):
            # print(z[:,i].shape)
            x[:,i] = self.helper(z[:,i])[:,0]
        x = F.softmax(x,dim=1)   # alphas
    
        x1 = x[:,0]
        torch.mul(x1[:,None,None,None],z[:,0])

        for i in range(9):            
            x1 = x[:,i]          
            y = y + torch.mul(x1[:,None,None,None],z[:,i])
        return y , x

images ,labels,foreground_indices = iter(train_loader).next()

Where = focus_inception_net().double()

Where = Where.to(device)

# batch =10
# avg_img ,alpha_values = Where(images[:10])
# avg_img.shape,alpha_values.shape

class classy_inception_net(nn.Module):
    def __init__(self):
        super(classy_inception_net,self).__init__()
        self.conv1 = Conv_module(3,64,1,3,0)
        
        self.incept1 = inception_module(64,16,16)
        self.incept2 = inception_module(32,16,56)
        
        self.downsample1 = downsample_module(72,72)
        
        self.incept3 = inception_module(144,32,32)
        self.incept4 = inception_module(64,48,32)
        self.incept5 = inception_module(80,40,40)
        self.incept6 = inception_module(80,32,48)
        
        self.downsample2 = downsample_module(80,64)
        
        self.incept7 = inception_module(144,128,64)
        self.incept8 = inception_module(192,48,32)
        
        self.incept9 = inception_module(80,64,64)
        self.incept10 = inception_module(128,64,32)

        self.incept11 = inception_module(96,32,64)
        self.incept12 = inception_module(96,32,48)




        self.pool = nn.AvgPool2d(7)
        
        
        
        self.linear = nn.Linear(4*4*80,3)
    def forward(self,x):
        x = self.conv1.forward(x)
        x = self.incept1.forward(x)
        x = self.incept2.forward(x)
        x = self.downsample1.forward(x)
        
        x = self.incept3.forward(x)
        x = self.incept4.forward(x)
        x = self.incept5.forward(x)
        x = self.incept6.forward(x)
        x = self.downsample2.forward(x) 
        x = self.incept7.forward(x)
        x = self.incept8.forward(x)
        
        x = self.incept9.forward(x)
        x = self.incept10.forward(x)
        x = self.incept11.forward(x)
        x = self.incept12.forward(x)
        # print(x.shape)
        x = self.pool(x)
        # print(x.shape)
        x = x.view(-1,4*4*80)
        x = self.linear(x) 
        #activatn = {"act1":act1,"act2":act2,"act3":act3,"act4":act4,"act5":act5,"act6":act6,
         #           "act7":act7,"act8":act8,"act9":act9,"act10":act10,"act11":act11}
        return x

What = classy_inception_net().double()
What = What.to(device)

# y = What(avg_img.to(device))
# y

test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images
fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                
test_label=[]                # label of mosaic image = foreground class present in that mosaic
for i in range(10000):
  bg_idx = np.random.randint(0,35000,8)
  fg_idx = np.random.randint(0,15000)
  fg = np.random.randint(0,9)
  fore_idx_test.append(fg)
  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)
  test_images.append(image_list)
  test_label.append(label)

test_data = MosaicDataset(test_images,test_label,fore_idx_test)
test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)

criterion = nn.CrossEntropyLoss()
optimizer_where = optim.SGD(Where.parameters(), lr=0.01, momentum=0.9)
optimizer_what = optim.SGD(What.parameters(), lr=0.01, momentum=0.9)
nos_epochs = 35
for epoch in range(nos_epochs):  # loop over the dataset multiple times

  running_loss = 0.0
  cnt=0

  iteration = desired_num // batch
  
  for i, data in  enumerate(train_loader):
    inputs , labels , fgrnd_idx = data
    inputs,labels = inputs.to("cuda"),labels.to("cuda")
    # zero the parameter gradients
    
    optimizer_where.zero_grad()
    optimizer_what.zero_grad()
    
    avg_images , alphas = Where(inputs)
    outputs = What(avg_images)
    # print("ot", outputs)
    # print("labels", labels)
      
    _, predicted = torch.max(outputs.data, 1)
      

    loss = criterion(outputs, labels) 
    # print(loss)
    # print(outputs)
    loss.backward()

    optimizer_where.step()
    optimizer_what.step()

    running_loss += loss.item()
    mini = 200
    if cnt % mini == mini-1:    # print every 40 mini-batches
      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))
      running_loss = 0.0
    cnt=cnt+1
#     print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt , running_loss/cnt))
#     print(running_loss)
print('Finished Training')
torch.save(What.state_dict(),"weights/What_4_12_epoch"+str(nos_epochs)+".pt")
torch.save(Where.state_dict(),"weights/Where_4_12_epoch"+str(nos_epochs)+".pt")

full_train_acc = 0 
for data in train_loader:
    inputs,labels,_ = data
    inputs,labels = inputs.to(device), labels.to(device)
    avg_inp,alphas = Where(inputs)
    outputs = What(avg_inp)
    _,predicted = torch.max(outputs.data,1)
    #print(predicted.cpu().numpy(),"labels",labels.cpu().numpy())
    full_train_acc+=sum(predicted.cpu().numpy()== labels.cpu().numpy())
print("mosaic_data_training_accuracy :",full_train_acc/desired_num)

full_test_acc = 0 
for data in test_loader:
    inputs,labels,_ = data
    inputs,labels = inputs.to(device), labels.to(device)
    avg_inp,alphas = Where(inputs)
    outputs = What(avg_inp)
    _,predicted = torch.max(outputs.data,1)
    #print(predicted.cpu().numpy(),"labels",labels.cpu().numpy())
    full_test_acc+=sum(predicted.cpu().numpy()== labels.cpu().numpy())
print("mosaic_data_test_accuracy :",full_test_acc/10000)

