{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom matplotlib import pyplot as plt\nimport copy\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\nforeground_classes = {'plane', 'car', 'bird'}\n#foreground_classes = {'bird', 'cat', 'deer'}\nbackground_classes = {'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n#background_classes = {'plane', 'car', 'dog', 'frog', 'horse','ship', 'truck'}\n\nfg1,fg2,fg3 = 0,1,2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(trainloader)\nbackground_data=[]\nbackground_label=[]\nforeground_data=[]\nforeground_label=[]\nbatch_size=10\n\nfor i in range(5000):\n  images, labels = dataiter.next()\n  for j in range(batch_size):\n    if(classes[labels[j]] in background_classes):\n      img = images[j].tolist()\n      background_data.append(img)\n      background_label.append(labels[j])\n    else:\n      img = images[j].tolist()\n      foreground_data.append(img)\n      foreground_label.append(labels[j])\n            \nforeground_data = torch.tensor(foreground_data)\nforeground_label = torch.tensor(foreground_label)\nbackground_data = torch.tensor(background_data)\nbackground_label = torch.tensor(background_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mosaic_img(bg_idx,fg_idx,fg): \n  \"\"\"\n  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n  fg_idx : index of image to be used as foreground image from foreground data\n  fg : at what position/index foreground image has to be stored out of 0-8\n  \"\"\"\n  image_list=[]\n  j=0\n  for i in range(9):\n    if i != fg:\n      image_list.append(background_data[bg_idx[j]])#.type(\"torch.DoubleTensor\"))\n      j+=1\n    else: \n      image_list.append(foreground_data[fg_idx])#.type(\"torch.DoubleTensor\"))\n      label = foreground_label[fg_idx]- fg1  # minus fg1 because our fore ground classes are fg1,fg2,fg3 but we have to store it as 0,1,2\n  #image_list = np.concatenate(image_list ,axis=0)\n  image_list = torch.stack(image_list) \n  return image_list,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desired_num = 30000\nmosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\nfore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \nmosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\nfor i in range(desired_num):\n  np.random.seed(i)\n  bg_idx = np.random.randint(0,35000,8)\n  fg_idx = np.random.randint(0,15000)\n  fg = np.random.randint(0,9)\n  fore_idx.append(fg)\n  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n  mosaic_list_of_images.append(image_list)\n  mosaic_label.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MosaicDataset(Dataset):\n  \"\"\"MosaicDataset dataset.\"\"\"\n\n  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n    \"\"\"\n      Args:\n        csv_file (string): Path to the csv file with annotations.\n        root_dir (string): Directory with all the images.\n        transform (callable, optional): Optional transform to be applied\n            on a sample.\n    \"\"\"\n    self.mosaic = mosaic_list_of_images\n    self.label = mosaic_label\n    self.fore_idx = fore_idx\n\n  def __len__(self):\n    return len(self.label)\n\n  def __getitem__(self, idx):\n    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n\nbatch = 250\nmsd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\ntrain_loader = DataLoader( msd,batch_size= batch ,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Focus(nn.Module):\n  def __init__(self,pretrained =True):\n    super(Focus, self).__init__()\n    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n    self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=0)\n    self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n    self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=0)\n    self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n    self.batch_norm1 = nn.BatchNorm2d(32,track_running_stats=False)\n    self.batch_norm2 = nn.BatchNorm2d(64,track_running_stats=False)\n    self.batch_norm3 = nn.BatchNorm2d(256,track_running_stats=False)\n    self.dropout1 = nn.Dropout2d(p=0.05)\n    self.dropout2 = nn.Dropout2d(p=0.1)\n    self.fc1 = nn.Linear(256,64)\n    self.fc2 = nn.Linear(64, 32)\n    self.fc3 = nn.Linear(32, 10)\n    self.fc4 = nn.Linear(10, 2)\n    self.pretrained = pretrained\n\n  def forward(self,z):  #y is avg image #z batch of list of 9 images\n    y = torch.zeros([batch,256, 3,3], dtype=torch.float64)\n    x = torch.zeros([batch,9],dtype=torch.float64)\n    ftr = torch.zeros([batch,9,256,3,3])\n    y = y.to(\"cuda\")\n    x = x.to(\"cuda\")\n    ftr = ftr.to(\"cuda\")\n    \n    for i in range(9):\n        out,ftrs = self.helper(z[:,i])\n        #print(out.shape)\n        x[:,i] = out\n        ftr[:,i] = ftrs\n    log_x = F.log_softmax(x,dim=1)\n    x = F.softmax(x,dim=1)\n\n    # x1 = x[:,0]\n    # torch.mul(x1[:,None,None,None],z[:,0])\n\n    for i in range(9):            \n      x1 = x[:,i]          \n      y = y + torch.mul(x1[:,None,None,None],ftr[:,i])\n\n    return x, log_x, y #alpha,avg_data\n    \n  def helper(self, x):\n    #x1 = x\n    #x1 =x\n    x = self.conv1(x)\n    x = F.relu(self.batch_norm1(x))\n\n    x = (F.relu(self.conv2(x)))\n    x = self.pool(x)\n    \n    x = self.conv3(x)\n    x = F.relu(self.batch_norm2(x))\n\n    x = (F.relu(self.conv4(x)))\n    x = self.pool(x)\n    x = self.dropout1(x)\n\n    x = self.conv5(x)\n    \n    x = F.relu(self.batch_norm3(x))\n\n    x = self.conv6(x)\n    x1 = F.tanh(x)\n    x = F.relu(x)\n    x = self.pool(x)\n\n    x = x.view(x.size(0), -1)\n\n    x = self.dropout2(x)\n    x = F.relu(self.fc1(x))\n    x = F.relu(self.fc2(x))\n    x = self.dropout2(x)\n    x = F.relu(self.fc3(x))\n    if self.pretrained==True:\n      x = self.fc4(x)\n      x = x[:,1] -x[:,0]\n    else:\n      x = self.fc4(x)\n      x = x[:,0]\n    return x,x1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(1234)\nfocus_net = Focus(False).double()\nfocus_net = focus_net.to(\"cuda\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Classification(nn.Module):\n  def __init__(self):\n    super(Classification, self).__init__()\n    self.conv1 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1)\n    self.conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n    self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n    self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n    self.conv6 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n    self.pool = nn.MaxPool2d(kernel_size=2, stride=2,padding=1)\n    self.batch_norm1 = nn.BatchNorm2d(128,track_running_stats=False)\n    self.batch_norm2 = nn.BatchNorm2d(256,track_running_stats=False)\n    self.batch_norm3 = nn.BatchNorm2d(512,track_running_stats=False)\n    self.dropout1 = nn.Dropout2d(p=0.05)\n    self.dropout2 = nn.Dropout2d(p=0.1)\n    self.global_average_pooling = nn.AvgPool2d(kernel_size=2)\n    self.fc1 = nn.Linear(512,128)\n    # self.fc2 = nn.Linear(128, 64)\n    # self.fc3 = nn.Linear(64, 10)\n    self.fc2 = nn.Linear(128, 3)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = F.relu(self.batch_norm1(x))\n\n    x = (F.relu(self.conv2(x)))\n    x = self.pool(x)\n    \n    x = self.conv3(x)\n    x = F.relu(self.batch_norm2(x))\n\n    x = (F.relu(self.conv4(x)))\n    x = self.pool(x)\n    x = self.dropout1(x)\n\n    x = self.conv5(x)\n    x = F.relu(self.batch_norm3(x))\n\n    x = (F.relu(self.conv6(x)))\n    x = self.pool(x)\n    #print(x.shape)\n    x = self.global_average_pooling(x)\n    x = x.squeeze()\n    #x = x.view(x.size(0), -1)\n    #print(x.shape)\n    x = self.dropout2(x)\n    x = F.relu(self.fc1(x))\n    #x = F.relu(self.fc2(x))\n    #x = self.dropout2(x)\n    #x = F.relu(self.fc3(x))\n    x = self.fc2(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(1234)\nclassify = Classification().double()\nclassify = classify.to(\"cuda\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\nfore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \ntest_label=[]                # label of mosaic image = foreground class present in that mosaic\nfor i in range(10000):\n  np.random.seed(i+30000)\n  bg_idx = np.random.randint(0,35000,8)\n  fg_idx = np.random.randint(0,15000)\n  fg = np.random.randint(0,9)\n  fore_idx_test.append(fg)\n  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n  test_images.append(image_list)\n  test_label.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = MosaicDataset(test_images,test_label,fore_idx_test)\ntest_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n#criterion_classify = nn.CrossEntropyLoss()\noptimizer_focus = optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)\noptimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\ndef my_cross_entropy(x, y,alpha,log_alpha,k):\n    loss = criterion(x,y)\n    b = -1.0* alpha * log_alpha\n    b =  torch.mean(torch.sum(b,dim=1))\n    closs = loss\n    entropy = b \n    loss = (1-k)*loss + ((k)*b)\n    return loss,closs,entropy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col1=[]\ncol2=[]\ncol3=[]\ncol4=[]\ncol5=[]\ncol6=[]\ncol7=[]\ncol8=[]\ncol9=[]\ncol10=[]\ncol11=[]\ncol12=[]\ncol13=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\ncount = 0\nflag = 1\nfocus_true_pred_true =0\nfocus_false_pred_true =0\nfocus_true_pred_false =0\nfocus_false_pred_false =0\n\nargmax_more_than_half = 0\nargmax_less_than_half =0\n\nwith torch.no_grad():\n  for data in train_loader:\n    inputs, labels , fore_idx = data\n    inputs = inputs.double()\n    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n    alphas, _,avg_images = focus_net(inputs)\n    outputs = classify(avg_images)\n\n    _, predicted = torch.max(outputs.data, 1)\n\n    for j in range(labels.size(0)):\n      count += 1\n      focus = torch.argmax(alphas[j])\n      if alphas[j][focus] >= 0.5 :\n        argmax_more_than_half += 1\n      else:\n        argmax_less_than_half += 1\n\n      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n          focus_true_pred_true += 1\n      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n        focus_false_pred_true += 1\n      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n        focus_true_pred_false += 1\n      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n        focus_false_pred_false += 1\n\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\nprint(\"total correct\", correct)\nprint(\"total train set images\", total)\n\nprint(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\nprint(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\nprint(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\nprint(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n\nprint(\"argmax_more_than_half ==================> \",argmax_more_than_half)\nprint(\"argmax_less_than_half ==================> \",argmax_less_than_half)\nprint(count)\n\nprint(\"=\"*100)\n\ncol1.append(0)\ncol2.append(argmax_more_than_half)\ncol3.append(argmax_less_than_half)\ncol4.append(focus_true_pred_true)\ncol5.append(focus_false_pred_true)\ncol6.append(focus_true_pred_false)\ncol7.append(focus_false_pred_false)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\ncount = 0\nflag = 1\nfocus_true_pred_true =0\nfocus_false_pred_true =0\nfocus_true_pred_false =0\nfocus_false_pred_false =0\n\nargmax_more_than_half = 0\nargmax_less_than_half =0\n\nwith torch.no_grad():\n  for data in test_loader:\n    inputs, labels , fore_idx = data\n    inputs = inputs.double()\n    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n    alphas,_,avg_images = focus_net(inputs)\n    outputs = classify(avg_images)\n\n    _, predicted = torch.max(outputs.data, 1)\n\n    for j in range(labels.size(0)):\n      focus = torch.argmax(alphas[j])\n      if alphas[j][focus] >= 0.5 :\n        argmax_more_than_half += 1\n      else:\n        argmax_less_than_half += 1\n\n      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n          focus_true_pred_true += 1\n      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n        focus_false_pred_true += 1\n      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n        focus_true_pred_false += 1\n      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n        focus_false_pred_false += 1\n\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))\nprint(\"total correct\", correct)\nprint(\"total train set images\", total)\n\nprint(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\nprint(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\nprint(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\nprint(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n\nprint(\"argmax_more_than_half ==================> \",argmax_more_than_half)\nprint(\"argmax_less_than_half ==================> \",argmax_less_than_half)\ncol8.append(argmax_more_than_half)\ncol9.append(argmax_less_than_half)\ncol10.append(focus_true_pred_true)\ncol11.append(focus_false_pred_true)\ncol12.append(focus_true_pred_false)\ncol13.append(focus_false_pred_false)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nos_epochs = 60\nk =0.01\nfocus_true_pred_true =0\nfocus_false_pred_true =0\nfocus_true_pred_false =0\nfocus_false_pred_false =0\n\nargmax_more_than_half = 0\nargmax_less_than_half =0\n\n\nfor epoch in range(nos_epochs):  # loop over the dataset multiple times\n\n  focus_true_pred_true =0\n  focus_false_pred_true =0\n  focus_true_pred_false =0\n  focus_false_pred_false =0\n  \n  argmax_more_than_half = 0\n  argmax_less_than_half =0\n  \n  running_loss = 0.0\n  running_cross_entropy = 0.0\n  running_entropy = 0.0\n\n  epoch_loss = []\n  epoch_ce = []\n  epoch_entropy = []\n  cnt=0\n\n  iteration = desired_num // batch\n  \n  #training data set\n  \n  for i, data in  enumerate(train_loader):\n    inputs , labels , fore_idx = data\n    inputs = inputs.double()\n    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n    # zero the parameter gradients\n    optimizer_focus.zero_grad()\n    optimizer_classify.zero_grad()\n    alphas, log_alpha,avg_images = focus_net(inputs)\n    outputs = classify(avg_images)\n    \n    # outputs, alphas, avg_images = classify(inputs)\n\n    _, predicted = torch.max(outputs.data, 1)\n#     print(outputs)\n#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n\n    #loss = criterion_classify(outputs, labels) \n    loss,c_e,entropy = my_cross_entropy(outputs, labels,alphas,log_alpha,k)\n    loss.backward()\n    optimizer_focus.step()\n    optimizer_classify.step()\n\n    running_loss += loss.item()\n    running_cross_entropy += c_e.item()\n    running_entropy += entropy.item()\n    mini = 60\n    if cnt % mini == mini-1:    # print every 40 mini-batches\n      print('[%d, %5d] loss: %.3f  cross_entropy: %.3f  entropy: %.3f' %(epoch + 1, cnt + 1, running_loss / mini,running_cross_entropy/mini,running_entropy/mini))\n      epoch_loss.append(running_loss/mini)\n      epoch_ce.append(running_cross_entropy/mini)\n      epoch_entropy.append(running_entropy/mini)\n      running_loss = 0.0\n      running_cross_entropy = 0.0\n      running_entropy = 0.0\n    cnt=cnt+1\n    \n    if epoch % 5 == 0:\n      for j in range (batch):\n        focus = torch.argmax(alphas[j])\n\n        if(alphas[j][focus] >= 0.5):\n          argmax_more_than_half +=1\n        else:\n          argmax_less_than_half +=1\n\n        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n          focus_true_pred_true += 1\n\n        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n          focus_false_pred_true +=1\n\n        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n          focus_true_pred_false +=1\n\n        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n          focus_false_pred_false +=1\n\n\n\n  if epoch % 5 == 0:\n    col1.append(epoch+1)\n    col2.append(argmax_more_than_half)\n    col3.append(argmax_less_than_half)\n    col4.append(focus_true_pred_true)\n    col5.append(focus_false_pred_true)\n    col6.append(focus_true_pred_false)\n    col7.append(focus_false_pred_false)\n  \n    #************************************************************************\n    #testing data set  \n    with torch.no_grad():\n      focus_true_pred_true =0\n      focus_false_pred_true =0\n      focus_true_pred_false =0\n      focus_false_pred_false =0\n\n      argmax_more_than_half = 0\n      argmax_less_than_half =0\n      for data in test_loader:\n        inputs, labels , fore_idx = data\n        inputs = inputs.double()\n        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n        alphas, _,avg_images = focus_net(inputs)\n        outputs = classify(avg_images)\n        #outputs, alphas, avg_images = classify(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n\n        for j in range (batch):\n          focus = torch.argmax(alphas[j])\n\n          if(alphas[j][focus] >= 0.5):\n            argmax_more_than_half +=1\n          else:\n            argmax_less_than_half +=1\n\n          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n            focus_true_pred_true += 1\n\n          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n            focus_false_pred_true +=1\n\n          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n            focus_true_pred_false +=1\n\n          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n            focus_false_pred_false +=1\n      \n    col8.append(argmax_more_than_half)\n    col9.append(argmax_less_than_half)\n    col10.append(focus_true_pred_true)\n    col11.append(focus_false_pred_true)\n    col12.append(focus_true_pred_false)\n    col13.append(focus_false_pred_false)\n  if(np.mean(epoch_loss) <= 0.02):\n    break;\nprint('Finished Training') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(focus_net.state_dict(),\"weights_focus_entropy_6.pt\")\ntorch.save(classify.state_dict(),\"weights_classify_entropy_6.pt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.DataFrame()\ndf_test = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[columns[0]] = col1\ndf_train[columns[1]] = col2\ndf_train[columns[2]] = col3\ndf_train[columns[3]] = col4\ndf_train[columns[4]] = col5\ndf_train[columns[5]] = col6\ndf_train[columns[6]] = col7\n\ndf_test[columns[0]] = col1\ndf_test[columns[1]] = col8\ndf_test[columns[2]] = col9\ndf_test[columns[3]] = col10\ndf_test[columns[4]] = col11\ndf_test[columns[5]] = col12\ndf_test[columns[6]] = col13","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(12,12)\nplt.plot(col1,col2, label='argmax > 0.5')\nplt.plot(col1,col3, label='argmax < 0.5')\n\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.xlabel(\"epochs\")\nplt.ylabel(\"training data\")\nplt.title(\"On Training set\")\nplt.show()\n\nplt.plot(col1,col4, label =\"focus_true_pred_true \")\nplt.plot(col1,col5, label =\"focus_false_pred_true \")\nplt.plot(col1,col6, label =\"focus_true_pred_false \")\nplt.plot(col1,col7, label =\"focus_false_pred_false \")\nplt.title(\"On Training set\")\n#plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.xlabel(\"epochs\")\nplt.ylabel(\"training data\")\nplt.savefig(\"train_entropy_6.png\",bbox_inches=\"tight\")\nplt.savefig(\"train_entropy_6.pdf\",bbox_inches=\"tight\")\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(12,12)\nplt.plot(col1,col8, label='argmax > 0.5')\nplt.plot(col1,col9, label='argmax < 0.5')\n\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Testing data\")\nplt.title(\"On Testing set\")\nplt.show()\n\nplt.plot(col1,col10, label =\"focus_true_pred_true \")\nplt.plot(col1,col11, label =\"focus_false_pred_true \")\nplt.plot(col1,col12, label =\"focus_true_pred_false \")\nplt.plot(col1,col13, label =\"focus_false_pred_false \")\nplt.title(\"On Testing set\")\n#plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Testing data\")\nplt.savefig(\"test_entropy_6.png\",bbox_inches=\"tight\")\nplt.savefig(\"test_entropy_6.pdf\",bbox_inches=\"tight\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\ncount = 0\nflag = 1\nfocus_true_pred_true =0\nfocus_false_pred_true =0\nfocus_true_pred_false =0\nfocus_false_pred_false =0\n\nargmax_more_than_half = 0\nargmax_less_than_half =0\nfocus_net.eval()\nclassify.eval()\nwith torch.no_grad():\n  for data in train_loader:\n    inputs, labels , fore_idx = data\n    inputs = inputs.double()\n    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n    alphas,_, avg_images = focus_net(inputs)\n    outputs = classify(avg_images)\n\n    _, predicted = torch.max(outputs.data, 1)\n\n    for j in range(labels.size(0)):\n      count += 1\n      focus = torch.argmax(alphas[j])\n      if alphas[j][focus] >= 0.5 :\n        argmax_more_than_half += 1\n      else:\n        argmax_less_than_half += 1\n\n      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n          focus_true_pred_true += 1\n      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n        focus_false_pred_true += 1\n      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n        focus_true_pred_false += 1\n      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n        focus_false_pred_false += 1\n\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\nprint(\"total correct\", correct)\nprint(\"total train set images\", total)\n\nprint(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\nprint(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\nprint(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\nprint(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n\nprint(\"argmax_more_than_half ==================> \",argmax_more_than_half)\nprint(\"argmax_less_than_half ==================> \",argmax_less_than_half)\nprint(count)\n\nprint(\"=\"*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\ncount = 0\nflag = 1\nfocus_true_pred_true =0\nfocus_false_pred_true =0\nfocus_true_pred_false =0\nfocus_false_pred_false =0\n\nargmax_more_than_half = 0\nargmax_less_than_half =0\nfocus_net.eval()\nclassify.eval()\nwith torch.no_grad():\n  for data in test_loader:\n    inputs, labels , fore_idx = data\n    inputs = inputs.double()\n    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n    alphas, _,avg_images = focus_net(inputs)\n    outputs = classify(avg_images)\n\n    _, predicted = torch.max(outputs.data, 1)\n\n    for j in range(labels.size(0)):\n      focus = torch.argmax(alphas[j])\n      if alphas[j][focus] >= 0.5 :\n        argmax_more_than_half += 1\n      else:\n        argmax_less_than_half += 1\n\n      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n          focus_true_pred_true += 1\n      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n        focus_false_pred_true += 1\n      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n        focus_true_pred_false += 1\n      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n        focus_false_pred_false += 1\n\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))\nprint(\"total correct\", correct)\nprint(\"total train set images\", total)\n\nprint(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\nprint(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\nprint(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\nprint(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n\nprint(\"argmax_more_than_half ==================> \",argmax_more_than_half)\nprint(\"argmax_less_than_half ==================> \",argmax_less_than_half)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\nfocus_net.eval()\nclassify.eval()\nwith torch.no_grad():\n  for data in train_loader:\n    inputs, labels , fore_idx = data\n    inputs = inputs.double()\n    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n    alphas, _,avg_images = focus_net(inputs)\n    outputs = classify(avg_images)\n\n    _, predicted = torch.max(outputs.data, 1)\n\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\nprint(\"total correct\", correct)\nprint(\"total train set images\", total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\nfocus_net.eval()\nclassify.eval()\nwith torch.no_grad():\n  for data in test_loader:\n    inputs, labels , fore_idx = data\n    inputs = inputs.double()\n    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n    alphas,_, avg_images = focus_net(inputs)\n    outputs = classify(avg_images)\n\n    _, predicted = torch.max(outputs.data, 1)\n\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\nprint(\"total correct\", correct)\nprint(\"total train set images\", total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}