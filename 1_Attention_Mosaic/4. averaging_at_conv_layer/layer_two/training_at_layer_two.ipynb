{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R2j0wT2NxUG",
        "colab_type": "code",
        "outputId": "9390799e-e5a6-4a58-d0a0-909ac16a1bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Models import Classification_Module3 as Classification_Module\n",
        "from Models import Focus_Module3 as Focus_Module\n",
        "from Mosaic import mosaic_data, MosaicDataset,split_foreground_background\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SblUamycPE7O",
        "colab_type": "code",
        "outputId": "ef6229b6-cf4d-45b5-f715-d96676263d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsd9DNgUPMBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = split_foreground_background(trainloader,total = 50000)\n",
        "mosaic_list_of_images,mosaic_label,fore_idx = mosaic_data(data,desired_num=30000,total=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC1dUctdPgmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "train_dataset  = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "mosaic_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCm_yFatRxib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mimages_val,mlabel_val,fidx_val = mosaic_data(data,desired_num=10000,total=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RccSHk3DU3jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "test_dataset  = MosaicDataset(mimages_val,mlabel_val,fidx_val)\n",
        "test_loader = DataLoader( test_dataset,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di1vx00TVFgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net =  Focus_Module(3,1).double()\n",
        "focus_net = focus_net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0wsFjYFVPfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classification_net  = Classification_Module(12,3).double()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz6llbjujOm8",
        "colab_type": "code",
        "outputId": "0fb5f223-a67d-4e0b-f54c-d676a5cdb084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "classification_net = classification_net.to(device)\n",
        "classification_net"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification_Module3(\n",
              "  (conv1): Conv2d(12, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=720, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emZvvTp0VbIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_focus = optim.SGD(focus_net.parameters(),lr = 0.01,momentum=0.9)\n",
        "optimizer_classification = optim.SGD(classification_net.parameters(),lr =0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cClaMnSRVfS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8iOl6JEVjJJ",
        "colab_type": "code",
        "outputId": "afb1cab8-217b-4270-9464-8f728915b766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tr_loss = []\n",
        "for epoch in range(110):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    cnt=0\n",
        "    iteration = 30000 // batch\n",
        "    ep_loss = []\n",
        "    for i, data in  enumerate(mosaic_loader):\n",
        "        inputs , labels , fgrnd_idx = data\n",
        "        inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "        optimizer_focus.zero_grad()\n",
        "        optimizer_classification.zero_grad()\n",
        "        avg_data , alphas = focus_net(inputs)\n",
        "        outputs = classification_net(avg_data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_focus.step()\n",
        "        optimizer_classification.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        mini = 40\n",
        "        if cnt % mini == mini-1:    # print every mini mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "            ep_loss.append(running_loss/mini)\n",
        "            running_loss = 0.0  \n",
        "        cnt=cnt+1\n",
        "    tr_loss.append(np.mean(ep_loss))      \n",
        "print('Finished Training')    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.103\n",
            "[1,    80] loss: 1.099\n",
            "[1,   120] loss: 1.099\n",
            "[2,    40] loss: 1.099\n",
            "[2,    80] loss: 1.099\n",
            "[2,   120] loss: 1.099\n",
            "[3,    40] loss: 1.099\n",
            "[3,    80] loss: 1.099\n",
            "[3,   120] loss: 1.099\n",
            "[4,    40] loss: 1.099\n",
            "[4,    80] loss: 1.099\n",
            "[4,   120] loss: 1.099\n",
            "[5,    40] loss: 1.099\n",
            "[5,    80] loss: 1.098\n",
            "[5,   120] loss: 1.098\n",
            "[6,    40] loss: 1.098\n",
            "[6,    80] loss: 1.098\n",
            "[6,   120] loss: 1.099\n",
            "[7,    40] loss: 1.098\n",
            "[7,    80] loss: 1.098\n",
            "[7,   120] loss: 1.098\n",
            "[8,    40] loss: 1.098\n",
            "[8,    80] loss: 1.098\n",
            "[8,   120] loss: 1.098\n",
            "[9,    40] loss: 1.097\n",
            "[9,    80] loss: 1.097\n",
            "[9,   120] loss: 1.096\n",
            "[10,    40] loss: 1.096\n",
            "[10,    80] loss: 1.095\n",
            "[10,   120] loss: 1.094\n",
            "[11,    40] loss: 1.094\n",
            "[11,    80] loss: 1.093\n",
            "[11,   120] loss: 1.092\n",
            "[12,    40] loss: 1.091\n",
            "[12,    80] loss: 1.090\n",
            "[12,   120] loss: 1.090\n",
            "[13,    40] loss: 1.085\n",
            "[13,    80] loss: 1.080\n",
            "[13,   120] loss: 1.080\n",
            "[14,    40] loss: 1.072\n",
            "[14,    80] loss: 1.073\n",
            "[14,   120] loss: 1.073\n",
            "[15,    40] loss: 1.067\n",
            "[15,    80] loss: 1.060\n",
            "[15,   120] loss: 1.060\n",
            "[16,    40] loss: 1.061\n",
            "[16,    80] loss: 1.057\n",
            "[16,   120] loss: 1.055\n",
            "[17,    40] loss: 1.048\n",
            "[17,    80] loss: 1.052\n",
            "[17,   120] loss: 1.045\n",
            "[18,    40] loss: 1.045\n",
            "[18,    80] loss: 1.045\n",
            "[18,   120] loss: 1.039\n",
            "[19,    40] loss: 1.037\n",
            "[19,    80] loss: 1.026\n",
            "[19,   120] loss: 1.026\n",
            "[20,    40] loss: 1.024\n",
            "[20,    80] loss: 1.021\n",
            "[20,   120] loss: 1.023\n",
            "[21,    40] loss: 1.020\n",
            "[21,    80] loss: 1.017\n",
            "[21,   120] loss: 1.003\n",
            "[22,    40] loss: 1.006\n",
            "[22,    80] loss: 1.001\n",
            "[22,   120] loss: 0.999\n",
            "[23,    40] loss: 0.982\n",
            "[23,    80] loss: 0.981\n",
            "[23,   120] loss: 0.959\n",
            "[24,    40] loss: 0.956\n",
            "[24,    80] loss: 0.936\n",
            "[24,   120] loss: 0.910\n",
            "[25,    40] loss: 0.884\n",
            "[25,    80] loss: 0.895\n",
            "[25,   120] loss: 0.862\n",
            "[26,    40] loss: 0.823\n",
            "[26,    80] loss: 0.825\n",
            "[26,   120] loss: 0.798\n",
            "[27,    40] loss: 0.790\n",
            "[27,    80] loss: 0.813\n",
            "[27,   120] loss: 0.761\n",
            "[28,    40] loss: 0.771\n",
            "[28,    80] loss: 0.769\n",
            "[28,   120] loss: 0.759\n",
            "[29,    40] loss: 0.733\n",
            "[29,    80] loss: 0.721\n",
            "[29,   120] loss: 0.718\n",
            "[30,    40] loss: 0.685\n",
            "[30,    80] loss: 0.688\n",
            "[30,   120] loss: 0.679\n",
            "[31,    40] loss: 0.685\n",
            "[31,    80] loss: 0.679\n",
            "[31,   120] loss: 0.656\n",
            "[32,    40] loss: 0.651\n",
            "[32,    80] loss: 0.656\n",
            "[32,   120] loss: 0.649\n",
            "[33,    40] loss: 0.628\n",
            "[33,    80] loss: 0.610\n",
            "[33,   120] loss: 0.614\n",
            "[34,    40] loss: 0.583\n",
            "[34,    80] loss: 0.588\n",
            "[34,   120] loss: 0.599\n",
            "[35,    40] loss: 0.551\n",
            "[35,    80] loss: 0.566\n",
            "[35,   120] loss: 0.570\n",
            "[36,    40] loss: 0.534\n",
            "[36,    80] loss: 0.540\n",
            "[36,   120] loss: 0.536\n",
            "[37,    40] loss: 0.512\n",
            "[37,    80] loss: 0.508\n",
            "[37,   120] loss: 0.530\n",
            "[38,    40] loss: 0.486\n",
            "[38,    80] loss: 0.486\n",
            "[38,   120] loss: 0.523\n",
            "[39,    40] loss: 0.469\n",
            "[39,    80] loss: 0.489\n",
            "[39,   120] loss: 0.492\n",
            "[40,    40] loss: 0.470\n",
            "[40,    80] loss: 0.468\n",
            "[40,   120] loss: 0.468\n",
            "[41,    40] loss: 0.430\n",
            "[41,    80] loss: 0.449\n",
            "[41,   120] loss: 0.456\n",
            "[42,    40] loss: 0.414\n",
            "[42,    80] loss: 0.425\n",
            "[42,   120] loss: 0.434\n",
            "[43,    40] loss: 0.404\n",
            "[43,    80] loss: 0.397\n",
            "[43,   120] loss: 0.382\n",
            "[44,    40] loss: 0.361\n",
            "[44,    80] loss: 0.385\n",
            "[44,   120] loss: 0.389\n",
            "[45,    40] loss: 0.363\n",
            "[45,    80] loss: 0.352\n",
            "[45,   120] loss: 0.376\n",
            "[46,    40] loss: 0.344\n",
            "[46,    80] loss: 0.333\n",
            "[46,   120] loss: 0.347\n",
            "[47,    40] loss: 0.313\n",
            "[47,    80] loss: 0.359\n",
            "[47,   120] loss: 0.345\n",
            "[48,    40] loss: 0.318\n",
            "[48,    80] loss: 0.305\n",
            "[48,   120] loss: 0.344\n",
            "[49,    40] loss: 0.323\n",
            "[49,    80] loss: 0.316\n",
            "[49,   120] loss: 0.307\n",
            "[50,    40] loss: 0.275\n",
            "[50,    80] loss: 0.306\n",
            "[50,   120] loss: 0.306\n",
            "[51,    40] loss: 0.285\n",
            "[51,    80] loss: 0.291\n",
            "[51,   120] loss: 0.269\n",
            "[52,    40] loss: 0.269\n",
            "[52,    80] loss: 0.257\n",
            "[52,   120] loss: 0.291\n",
            "[53,    40] loss: 0.259\n",
            "[53,    80] loss: 0.252\n",
            "[53,   120] loss: 0.254\n",
            "[54,    40] loss: 0.213\n",
            "[54,    80] loss: 0.250\n",
            "[54,   120] loss: 0.243\n",
            "[55,    40] loss: 0.238\n",
            "[55,    80] loss: 0.275\n",
            "[55,   120] loss: 0.243\n",
            "[56,    40] loss: 0.225\n",
            "[56,    80] loss: 0.207\n",
            "[56,   120] loss: 0.217\n",
            "[57,    40] loss: 0.210\n",
            "[57,    80] loss: 0.242\n",
            "[57,   120] loss: 0.241\n",
            "[58,    40] loss: 0.211\n",
            "[58,    80] loss: 0.213\n",
            "[58,   120] loss: 0.204\n",
            "[59,    40] loss: 0.187\n",
            "[59,    80] loss: 0.192\n",
            "[59,   120] loss: 0.220\n",
            "[60,    40] loss: 0.177\n",
            "[60,    80] loss: 0.226\n",
            "[60,   120] loss: 0.204\n",
            "[61,    40] loss: 0.160\n",
            "[61,    80] loss: 0.180\n",
            "[61,   120] loss: 0.197\n",
            "[62,    40] loss: 0.164\n",
            "[62,    80] loss: 0.207\n",
            "[62,   120] loss: 0.163\n",
            "[63,    40] loss: 0.139\n",
            "[63,    80] loss: 0.142\n",
            "[63,   120] loss: 0.152\n",
            "[64,    40] loss: 0.160\n",
            "[64,    80] loss: 0.209\n",
            "[64,   120] loss: 0.196\n",
            "[65,    40] loss: 0.162\n",
            "[65,    80] loss: 0.156\n",
            "[65,   120] loss: 0.183\n",
            "[66,    40] loss: 0.152\n",
            "[66,    80] loss: 0.150\n",
            "[66,   120] loss: 0.167\n",
            "[67,    40] loss: 0.138\n",
            "[67,    80] loss: 0.151\n",
            "[67,   120] loss: 0.140\n",
            "[68,    40] loss: 0.109\n",
            "[68,    80] loss: 0.138\n",
            "[68,   120] loss: 0.127\n",
            "[69,    40] loss: 0.116\n",
            "[69,    80] loss: 0.118\n",
            "[69,   120] loss: 0.123\n",
            "[70,    40] loss: 0.135\n",
            "[70,    80] loss: 0.154\n",
            "[70,   120] loss: 0.122\n",
            "[71,    40] loss: 0.100\n",
            "[71,    80] loss: 0.108\n",
            "[71,   120] loss: 0.130\n",
            "[72,    40] loss: 0.128\n",
            "[72,    80] loss: 0.160\n",
            "[72,   120] loss: 0.156\n",
            "[73,    40] loss: 0.120\n",
            "[73,    80] loss: 0.119\n",
            "[73,   120] loss: 0.111\n",
            "[74,    40] loss: 0.112\n",
            "[74,    80] loss: 0.103\n",
            "[74,   120] loss: 0.100\n",
            "[75,    40] loss: 0.093\n",
            "[75,    80] loss: 0.103\n",
            "[75,   120] loss: 0.094\n",
            "[76,    40] loss: 0.084\n",
            "[76,    80] loss: 0.094\n",
            "[76,   120] loss: 0.097\n",
            "[77,    40] loss: 0.074\n",
            "[77,    80] loss: 0.077\n",
            "[77,   120] loss: 0.100\n",
            "[78,    40] loss: 0.079\n",
            "[78,    80] loss: 0.084\n",
            "[78,   120] loss: 0.088\n",
            "[79,    40] loss: 0.088\n",
            "[79,    80] loss: 0.099\n",
            "[79,   120] loss: 0.093\n",
            "[80,    40] loss: 0.073\n",
            "[80,    80] loss: 0.107\n",
            "[80,   120] loss: 0.094\n",
            "[81,    40] loss: 0.078\n",
            "[81,    80] loss: 0.086\n",
            "[81,   120] loss: 0.089\n",
            "[82,    40] loss: 0.076\n",
            "[82,    80] loss: 0.065\n",
            "[82,   120] loss: 0.071\n",
            "[83,    40] loss: 0.066\n",
            "[83,    80] loss: 0.058\n",
            "[83,   120] loss: 0.081\n",
            "[84,    40] loss: 0.085\n",
            "[84,    80] loss: 0.094\n",
            "[84,   120] loss: 0.072\n",
            "[85,    40] loss: 0.058\n",
            "[85,    80] loss: 0.076\n",
            "[85,   120] loss: 0.066\n",
            "[86,    40] loss: 0.061\n",
            "[86,    80] loss: 0.068\n",
            "[86,   120] loss: 0.075\n",
            "[87,    40] loss: 0.063\n",
            "[87,    80] loss: 0.059\n",
            "[87,   120] loss: 0.064\n",
            "[88,    40] loss: 0.054\n",
            "[88,    80] loss: 0.057\n",
            "[88,   120] loss: 0.054\n",
            "[89,    40] loss: 0.060\n",
            "[89,    80] loss: 0.069\n",
            "[89,   120] loss: 0.079\n",
            "[90,    40] loss: 0.068\n",
            "[90,    80] loss: 0.070\n",
            "[90,   120] loss: 0.109\n",
            "[91,    40] loss: 0.062\n",
            "[91,    80] loss: 0.047\n",
            "[91,   120] loss: 0.062\n",
            "[92,    40] loss: 0.035\n",
            "[92,    80] loss: 0.062\n",
            "[92,   120] loss: 0.069\n",
            "[93,    40] loss: 0.043\n",
            "[93,    80] loss: 0.059\n",
            "[93,   120] loss: 0.052\n",
            "[94,    40] loss: 0.049\n",
            "[94,    80] loss: 0.068\n",
            "[94,   120] loss: 0.068\n",
            "[95,    40] loss: 0.041\n",
            "[95,    80] loss: 0.074\n",
            "[95,   120] loss: 0.059\n",
            "[96,    40] loss: 0.041\n",
            "[96,    80] loss: 0.042\n",
            "[96,   120] loss: 0.048\n",
            "[97,    40] loss: 0.056\n",
            "[97,    80] loss: 0.070\n",
            "[97,   120] loss: 0.068\n",
            "[98,    40] loss: 0.037\n",
            "[98,    80] loss: 0.037\n",
            "[98,   120] loss: 0.042\n",
            "[99,    40] loss: 0.065\n",
            "[99,    80] loss: 0.054\n",
            "[99,   120] loss: 0.051\n",
            "[100,    40] loss: 0.041\n",
            "[100,    80] loss: 0.033\n",
            "[100,   120] loss: 0.032\n",
            "[101,    40] loss: 0.019\n",
            "[101,    80] loss: 0.030\n",
            "[101,   120] loss: 0.042\n",
            "[102,    40] loss: 0.037\n",
            "[102,    80] loss: 0.045\n",
            "[102,   120] loss: 0.040\n",
            "[103,    40] loss: 0.041\n",
            "[103,    80] loss: 0.029\n",
            "[103,   120] loss: 0.053\n",
            "[104,    40] loss: 0.038\n",
            "[104,    80] loss: 0.037\n",
            "[104,   120] loss: 0.042\n",
            "[105,    40] loss: 0.039\n",
            "[105,    80] loss: 0.029\n",
            "[105,   120] loss: 0.022\n",
            "[106,    40] loss: 0.039\n",
            "[106,    80] loss: 0.036\n",
            "[106,   120] loss: 0.029\n",
            "[107,    40] loss: 0.029\n",
            "[107,    80] loss: 0.021\n",
            "[107,   120] loss: 0.041\n",
            "[108,    40] loss: 0.041\n",
            "[108,    80] loss: 0.031\n",
            "[108,   120] loss: 0.037\n",
            "[109,    40] loss: 0.021\n",
            "[109,    80] loss: 0.026\n",
            "[109,   120] loss: 0.030\n",
            "[110,    40] loss: 0.020\n",
            "[110,    80] loss: 0.037\n",
            "[110,   120] loss: 0.035\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lB7KlwGVpmd",
        "colab_type": "code",
        "outputId": "f24a5344-8c7e-48ae-d11c-f9572b6cfbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "  train_acc = 0\n",
        "for i, data in enumerate(mosaic_loader):\n",
        "    inputs,labels,_ = data\n",
        "    inputs,labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    avg_data,alphas = focus_net(inputs)\n",
        "    outputs = classification_net(avg_data)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    # print(predicted.detach().cpu().numpy())\n",
        "    train_acc += sum(predicted.cpu().numpy() == labels.cpu().numpy())\n",
        "print(\"percentage train accuracy: \",train_acc/300) \n",
        "\n",
        "torch.save(focus_net.state_dict(),\"focus_net_at_two.pt\")\n",
        "torch.save(classification_net.state_dict(),\"classification_net_at_two.pt\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "percentage train accuracy:  99.41333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEdCv9Lfd6Pf",
        "colab_type": "code",
        "outputId": "2a090d2f-8602-4e69-fb60-4d52809ec538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "val_acc = 0\n",
        "for i, data in enumerate(test_loader):\n",
        "    inputs,labels,_ = data\n",
        "    inputs,labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    avg_data,alphas = focus_net(inputs)\n",
        "    outputs = classification_net(avg_data)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "\n",
        "    val_acc +=sum(predicted.cpu().numpy() == labels.cpu().numpy())\n",
        "print(\"percentage validation accuracy: \",val_acc/100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "percentage validation accuracy:  88.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5MIz98beE2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "4d57528e-e293-4f32-b023-3356db10ec5d"
      },
      "source": [
        "plt.figure(figsize = (5,4))\n",
        "plt.plot(tr_loss,label= \"training loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"cross entropy loss\")\n",
        "plt.savefig(\"training_loss_at_two.png\")\n",
        "plt.savefig(\"training_loss_at_two.pdf\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDF5iDVwYCZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}