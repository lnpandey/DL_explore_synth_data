{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eba951e4-6056-4433-81d3-dd26de83caea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98ab3307-0c6a-435e-ef3a-efd5915b09e2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f68a1f6e-fde6-453a-d356-36660dfd0e8b"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fc40e5c1-b6b6-4146-c2c1-9e4068478f85"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 30000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4WPsAzBcgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05127df0-62a7-4c30-9053-e7bfaa846454"
      },
      "source": [
        "print(len(mosaic_list_of_images),len(mosaic_label))"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d55b8b0b-a3fa-4035-bbeb-9b892a177b25"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.107\n",
            "[1,    80] loss: 1.099\n",
            "[1,   120] loss: 1.098\n",
            "[2,    40] loss: 1.098\n",
            "[2,    80] loss: 1.096\n",
            "[2,   120] loss: 1.091\n",
            "[3,    40] loss: 1.085\n",
            "[3,    80] loss: 1.074\n",
            "[3,   120] loss: 1.065\n",
            "[4,    40] loss: 1.056\n",
            "[4,    80] loss: 1.044\n",
            "[4,   120] loss: 1.028\n",
            "[5,    40] loss: 0.999\n",
            "[5,    80] loss: 0.959\n",
            "[5,   120] loss: 0.881\n",
            "[6,    40] loss: 0.765\n",
            "[6,    80] loss: 0.681\n",
            "[6,   120] loss: 0.603\n",
            "[7,    40] loss: 0.536\n",
            "[7,    80] loss: 0.463\n",
            "[7,   120] loss: 0.422\n",
            "[8,    40] loss: 0.371\n",
            "[8,    80] loss: 0.345\n",
            "[8,   120] loss: 0.306\n",
            "[9,    40] loss: 0.305\n",
            "[9,    80] loss: 0.251\n",
            "[9,   120] loss: 0.247\n",
            "[10,    40] loss: 0.209\n",
            "[10,    80] loss: 0.180\n",
            "[10,   120] loss: 0.172\n",
            "[11,    40] loss: 0.152\n",
            "[11,    80] loss: 0.161\n",
            "[11,   120] loss: 0.159\n",
            "[12,    40] loss: 0.146\n",
            "[12,    80] loss: 0.176\n",
            "[12,   120] loss: 0.131\n",
            "[13,    40] loss: 0.133\n",
            "[13,    80] loss: 0.113\n",
            "[13,   120] loss: 0.106\n",
            "[14,    40] loss: 0.103\n",
            "[14,    80] loss: 0.075\n",
            "[14,   120] loss: 0.092\n",
            "[15,    40] loss: 0.089\n",
            "[15,    80] loss: 0.079\n",
            "[15,   120] loss: 0.081\n",
            "[16,    40] loss: 0.141\n",
            "[16,    80] loss: 0.111\n",
            "[16,   120] loss: 0.097\n",
            "[17,    40] loss: 0.083\n",
            "[17,    80] loss: 0.073\n",
            "[17,   120] loss: 0.075\n",
            "[18,    40] loss: 0.072\n",
            "[18,    80] loss: 0.064\n",
            "[18,   120] loss: 0.066\n",
            "[19,    40] loss: 0.068\n",
            "[19,    80] loss: 0.096\n",
            "[19,   120] loss: 0.075\n",
            "[20,    40] loss: 0.065\n",
            "[20,    80] loss: 0.066\n",
            "[20,   120] loss: 0.062\n",
            "[21,    40] loss: 0.062\n",
            "[21,    80] loss: 0.056\n",
            "[21,   120] loss: 0.056\n",
            "[22,    40] loss: 0.056\n",
            "[22,    80] loss: 0.052\n",
            "[22,   120] loss: 0.086\n",
            "[23,    40] loss: 0.060\n",
            "[23,    80] loss: 0.046\n",
            "[23,   120] loss: 0.044\n",
            "[24,    40] loss: 0.050\n",
            "[24,    80] loss: 0.070\n",
            "[24,   120] loss: 0.064\n",
            "[25,    40] loss: 0.043\n",
            "[25,    80] loss: 0.051\n",
            "[25,   120] loss: 0.055\n",
            "[26,    40] loss: 0.049\n",
            "[26,    80] loss: 0.044\n",
            "[26,   120] loss: 0.038\n",
            "[27,    40] loss: 0.036\n",
            "[27,    80] loss: 0.043\n",
            "[27,   120] loss: 0.029\n",
            "[28,    40] loss: 0.025\n",
            "[28,    80] loss: 0.031\n",
            "[28,   120] loss: 0.030\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds5\""
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "67cf8cb7-ab5d-42b6-8e8f-34c0d9d78f78"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29773\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c2af7e8d-27b8-4b58-c778-14f3858ed246"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 66 %\n",
            "total correct 6625\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1dda9dec-5a80-43eb-ee1a-7b5d0a588464"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "total correct 7723\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d8f0d03c-d736-44e5-ca9d-a1b0e1b8b613"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 67 %\n",
            "total correct 6781\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "667a9df6-3d39-4805-bb8f-90d186738fad"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 90 %\n",
            "total correct 9017\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cd31957c-f9d0-4cd8-ce4e-96bdb01310b5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 98 %\n",
            "total correct 9896\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5b54dd26-5c15-46b5-e518-eb5bbbb1eab6"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 90 %\n",
            "total correct 9041\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8f61788d-a9c3-4c1f-c293-8f0c74271d6b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 70 %\n",
            "total correct 7066\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "80ce2046-be40-4569-9cea-ad6d603d1523"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "total correct 8086\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f4be3a10-5120-4cdc-e0be-3ef7e5aa93f4"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "total correct 7163\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "9953b5d2-0b5f-4353-82f1-bb358eebeeba"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 300
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 300,
      "outputs": []
    }
  ]
}