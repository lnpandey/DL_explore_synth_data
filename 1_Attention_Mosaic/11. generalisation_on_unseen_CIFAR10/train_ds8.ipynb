{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eba951e4-6056-4433-81d3-dd26de83caea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98ab3307-0c6a-435e-ef3a-efd5915b09e2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f68a1f6e-fde6-453a-d356-36660dfd0e8b"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fc40e5c1-b6b6-4146-c2c1-9e4068478f85"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 30000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4WPsAzBcgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89bd1fbe-e2bf-47e8-f641-eb10884673fb"
      },
      "source": [
        "print(len(mosaic_list_of_images),len(mosaic_label))"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edc3b4fb-05f4-4137-cbe0-c381ea0ab7de"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.102\n",
            "[1,    80] loss: 1.098\n",
            "[1,   120] loss: 1.097\n",
            "[2,    40] loss: 1.096\n",
            "[2,    80] loss: 1.094\n",
            "[2,   120] loss: 1.092\n",
            "[3,    40] loss: 1.086\n",
            "[3,    80] loss: 1.079\n",
            "[3,   120] loss: 1.075\n",
            "[4,    40] loss: 1.066\n",
            "[4,    80] loss: 1.062\n",
            "[4,   120] loss: 1.052\n",
            "[5,    40] loss: 1.035\n",
            "[5,    80] loss: 1.006\n",
            "[5,   120] loss: 0.942\n",
            "[6,    40] loss: 0.877\n",
            "[6,    80] loss: 0.829\n",
            "[6,   120] loss: 0.780\n",
            "[7,    40] loss: 0.704\n",
            "[7,    80] loss: 0.668\n",
            "[7,   120] loss: 0.632\n",
            "[8,    40] loss: 0.560\n",
            "[8,    80] loss: 0.556\n",
            "[8,   120] loss: 0.541\n",
            "[9,    40] loss: 0.456\n",
            "[9,    80] loss: 0.462\n",
            "[9,   120] loss: 0.452\n",
            "[10,    40] loss: 0.420\n",
            "[10,    80] loss: 0.412\n",
            "[10,   120] loss: 0.391\n",
            "[11,    40] loss: 0.335\n",
            "[11,    80] loss: 0.339\n",
            "[11,   120] loss: 0.374\n",
            "[12,    40] loss: 0.307\n",
            "[12,    80] loss: 0.311\n",
            "[12,   120] loss: 0.294\n",
            "[13,    40] loss: 0.290\n",
            "[13,    80] loss: 0.275\n",
            "[13,   120] loss: 0.259\n",
            "[14,    40] loss: 0.217\n",
            "[14,    80] loss: 0.263\n",
            "[14,   120] loss: 0.239\n",
            "[15,    40] loss: 0.234\n",
            "[15,    80] loss: 0.201\n",
            "[15,   120] loss: 0.224\n",
            "[16,    40] loss: 0.213\n",
            "[16,    80] loss: 0.210\n",
            "[16,   120] loss: 0.195\n",
            "[17,    40] loss: 0.158\n",
            "[17,    80] loss: 0.173\n",
            "[17,   120] loss: 0.164\n",
            "[18,    40] loss: 0.169\n",
            "[18,    80] loss: 0.158\n",
            "[18,   120] loss: 0.169\n",
            "[19,    40] loss: 0.145\n",
            "[19,    80] loss: 0.162\n",
            "[19,   120] loss: 0.143\n",
            "[20,    40] loss: 0.136\n",
            "[20,    80] loss: 0.135\n",
            "[20,   120] loss: 0.147\n",
            "[21,    40] loss: 0.123\n",
            "[21,    80] loss: 0.107\n",
            "[21,   120] loss: 0.111\n",
            "[22,    40] loss: 0.100\n",
            "[22,    80] loss: 0.123\n",
            "[22,   120] loss: 0.122\n",
            "[23,    40] loss: 0.100\n",
            "[23,    80] loss: 0.106\n",
            "[23,   120] loss: 0.128\n",
            "[24,    40] loss: 0.092\n",
            "[24,    80] loss: 0.093\n",
            "[24,   120] loss: 0.090\n",
            "[25,    40] loss: 0.085\n",
            "[25,    80] loss: 0.085\n",
            "[25,   120] loss: 0.108\n",
            "[26,    40] loss: 0.085\n",
            "[26,    80] loss: 0.086\n",
            "[26,   120] loss: 0.101\n",
            "[27,    40] loss: 0.068\n",
            "[27,    80] loss: 0.075\n",
            "[27,   120] loss: 0.087\n",
            "[28,    40] loss: 0.064\n",
            "[28,    80] loss: 0.066\n",
            "[28,   120] loss: 0.067\n",
            "[29,    40] loss: 0.056\n",
            "[29,    80] loss: 0.065\n",
            "[29,   120] loss: 0.076\n",
            "[30,    40] loss: 0.070\n",
            "[30,    80] loss: 0.079\n",
            "[30,   120] loss: 0.089\n",
            "[31,    40] loss: 0.077\n",
            "[31,    80] loss: 0.068\n",
            "[31,   120] loss: 0.068\n",
            "[32,    40] loss: 0.061\n",
            "[32,    80] loss: 0.063\n",
            "[32,   120] loss: 0.052\n",
            "[33,    40] loss: 0.039\n",
            "[33,    80] loss: 0.052\n",
            "[33,   120] loss: 0.069\n",
            "[34,    40] loss: 0.059\n",
            "[34,    80] loss: 0.052\n",
            "[34,   120] loss: 0.050\n",
            "[35,    40] loss: 0.044\n",
            "[35,    80] loss: 0.042\n",
            "[35,   120] loss: 0.051\n",
            "[36,    40] loss: 0.037\n",
            "[36,    80] loss: 0.046\n",
            "[36,   120] loss: 0.039\n",
            "[37,    40] loss: 0.037\n",
            "[37,    80] loss: 0.046\n",
            "[37,   120] loss: 0.053\n",
            "[38,    40] loss: 0.038\n",
            "[38,    80] loss: 0.037\n",
            "[38,   120] loss: 0.041\n",
            "[39,    40] loss: 0.042\n",
            "[39,    80] loss: 0.062\n",
            "[39,   120] loss: 0.047\n",
            "[40,    40] loss: 0.038\n",
            "[40,    80] loss: 0.036\n",
            "[40,   120] loss: 0.036\n",
            "[41,    40] loss: 0.029\n",
            "[41,    80] loss: 0.042\n",
            "[41,   120] loss: 0.038\n",
            "[42,    40] loss: 0.038\n",
            "[42,    80] loss: 0.033\n",
            "[42,   120] loss: 0.055\n",
            "[43,    40] loss: 0.042\n",
            "[43,    80] loss: 0.028\n",
            "[43,   120] loss: 0.032\n",
            "[44,    40] loss: 0.021\n",
            "[44,    80] loss: 0.033\n",
            "[44,   120] loss: 0.038\n",
            "[45,    40] loss: 0.031\n",
            "[45,    80] loss: 0.031\n",
            "[45,   120] loss: 0.042\n",
            "[46,    40] loss: 0.032\n",
            "[46,    80] loss: 0.029\n",
            "[46,   120] loss: 0.055\n",
            "[47,    40] loss: 0.026\n",
            "[47,    80] loss: 0.022\n",
            "[47,   120] loss: 0.023\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds8\""
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "264f0434-eff9-42ef-ca68-a5c6b31e2e22"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29867\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "37df3a1e-6a97-40e4-c34d-39c725b0d26c"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 82 %\n",
            "total correct 8258\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cfb4fc5a-ff12-48f9-def8-c6ca05f6bed4"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "total correct 9680\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0889df5b-07de-4c54-c5cf-6ad192932a7f"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 84 %\n",
            "total correct 8429\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e28f7cbb-4a32-4349-a918-fe53518521d8"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 83 %\n",
            "total correct 8319\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "46185055-5491-4ced-d6d3-a052027ef1f8"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "total correct 9664\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3b657db7-18e9-44fa-c443-535cb1d4d822"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 85 %\n",
            "total correct 8510\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a6c37c0c-c793-48ef-ad0c-80bb3887ef22"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 83 %\n",
            "total correct 8322\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7a7989b8-b05f-4c13-ba71-7712308c0af9"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 417,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "total correct 9636\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d6153b96-8a2e-44d0-8692-785b8fb668af"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 84 %\n",
            "total correct 8449\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "18427470-a669-4714-a34b-383a407aa835"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 423,
      "outputs": []
    }
  ]
}