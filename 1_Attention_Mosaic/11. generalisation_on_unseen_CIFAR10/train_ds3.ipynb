{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eba951e4-6056-4433-81d3-dd26de83caea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98ab3307-0c6a-435e-ef3a-efd5915b09e2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f68a1f6e-fde6-453a-d356-36660dfd0e8b"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fc40e5c1-b6b6-4146-c2c1-9e4068478f85"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                    fg_size = 15000, \n",
        "                                                                    desired_num = 30000, \n",
        "                                                                    background_data = background_data_combined, \n",
        "                                                                    foreground_data = foreground_data_train, \n",
        "                                                                    foreground_label = foreground_label_train)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4WPsAzBcgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11f89b3d-28d6-423a-c897-2a735da9e68d"
      },
      "source": [
        "print(len(mosaic_list_of_images),len(mosaic_label))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ff35dbd-d17a-4797-91ac-d5d93b825d6e"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.099\n",
            "[1,    80] loss: 1.097\n",
            "[1,   120] loss: 1.096\n",
            "[2,    40] loss: 1.092\n",
            "[2,    80] loss: 1.087\n",
            "[2,   120] loss: 1.082\n",
            "[3,    40] loss: 1.077\n",
            "[3,    80] loss: 1.065\n",
            "[3,   120] loss: 1.054\n",
            "[4,    40] loss: 1.046\n",
            "[4,    80] loss: 1.037\n",
            "[4,   120] loss: 1.033\n",
            "[5,    40] loss: 1.003\n",
            "[5,    80] loss: 0.965\n",
            "[5,   120] loss: 0.915\n",
            "[6,    40] loss: 0.864\n",
            "[6,    80] loss: 0.804\n",
            "[6,   120] loss: 0.766\n",
            "[7,    40] loss: 0.713\n",
            "[7,    80] loss: 0.683\n",
            "[7,   120] loss: 0.641\n",
            "[8,    40] loss: 0.598\n",
            "[8,    80] loss: 0.581\n",
            "[8,   120] loss: 0.563\n",
            "[9,    40] loss: 0.519\n",
            "[9,    80] loss: 0.491\n",
            "[9,   120] loss: 0.499\n",
            "[10,    40] loss: 0.447\n",
            "[10,    80] loss: 0.452\n",
            "[10,   120] loss: 0.428\n",
            "[11,    40] loss: 0.379\n",
            "[11,    80] loss: 0.419\n",
            "[11,   120] loss: 0.406\n",
            "[12,    40] loss: 0.359\n",
            "[12,    80] loss: 0.365\n",
            "[12,   120] loss: 0.345\n",
            "[13,    40] loss: 0.311\n",
            "[13,    80] loss: 0.326\n",
            "[13,   120] loss: 0.341\n",
            "[14,    40] loss: 0.289\n",
            "[14,    80] loss: 0.290\n",
            "[14,   120] loss: 0.303\n",
            "[15,    40] loss: 0.269\n",
            "[15,    80] loss: 0.257\n",
            "[15,   120] loss: 0.269\n",
            "[16,    40] loss: 0.214\n",
            "[16,    80] loss: 0.220\n",
            "[16,   120] loss: 0.237\n",
            "[17,    40] loss: 0.199\n",
            "[17,    80] loss: 0.217\n",
            "[17,   120] loss: 0.232\n",
            "[18,    40] loss: 0.180\n",
            "[18,    80] loss: 0.197\n",
            "[18,   120] loss: 0.214\n",
            "[19,    40] loss: 0.168\n",
            "[19,    80] loss: 0.185\n",
            "[19,   120] loss: 0.201\n",
            "[20,    40] loss: 0.161\n",
            "[20,    80] loss: 0.165\n",
            "[20,   120] loss: 0.198\n",
            "[21,    40] loss: 0.169\n",
            "[21,    80] loss: 0.170\n",
            "[21,   120] loss: 0.146\n",
            "[22,    40] loss: 0.117\n",
            "[22,    80] loss: 0.155\n",
            "[22,   120] loss: 0.151\n",
            "[23,    40] loss: 0.128\n",
            "[23,    80] loss: 0.142\n",
            "[23,   120] loss: 0.136\n",
            "[24,    40] loss: 0.132\n",
            "[24,    80] loss: 0.124\n",
            "[24,   120] loss: 0.125\n",
            "[25,    40] loss: 0.103\n",
            "[25,    80] loss: 0.110\n",
            "[25,   120] loss: 0.108\n",
            "[26,    40] loss: 0.106\n",
            "[26,    80] loss: 0.107\n",
            "[26,   120] loss: 0.107\n",
            "[27,    40] loss: 0.093\n",
            "[27,    80] loss: 0.090\n",
            "[27,   120] loss: 0.105\n",
            "[28,    40] loss: 0.087\n",
            "[28,    80] loss: 0.091\n",
            "[28,   120] loss: 0.105\n",
            "[29,    40] loss: 0.087\n",
            "[29,    80] loss: 0.079\n",
            "[29,   120] loss: 0.092\n",
            "[30,    40] loss: 0.061\n",
            "[30,    80] loss: 0.071\n",
            "[30,   120] loss: 0.088\n",
            "[31,    40] loss: 0.065\n",
            "[31,    80] loss: 0.057\n",
            "[31,   120] loss: 0.062\n",
            "[32,    40] loss: 0.058\n",
            "[32,    80] loss: 0.070\n",
            "[32,   120] loss: 0.092\n",
            "[33,    40] loss: 0.057\n",
            "[33,    80] loss: 0.070\n",
            "[33,   120] loss: 0.062\n",
            "[34,    40] loss: 0.063\n",
            "[34,    80] loss: 0.079\n",
            "[34,   120] loss: 0.060\n",
            "[35,    40] loss: 0.051\n",
            "[35,    80] loss: 0.053\n",
            "[35,   120] loss: 0.059\n",
            "[36,    40] loss: 0.045\n",
            "[36,    80] loss: 0.070\n",
            "[36,   120] loss: 0.087\n",
            "[37,    40] loss: 0.068\n",
            "[37,    80] loss: 0.067\n",
            "[37,   120] loss: 0.066\n",
            "[38,    40] loss: 0.044\n",
            "[38,    80] loss: 0.042\n",
            "[38,   120] loss: 0.044\n",
            "[39,    40] loss: 0.041\n",
            "[39,    80] loss: 0.052\n",
            "[39,   120] loss: 0.043\n",
            "[40,    40] loss: 0.037\n",
            "[40,    80] loss: 0.033\n",
            "[40,   120] loss: 0.055\n",
            "[41,    40] loss: 0.033\n",
            "[41,    80] loss: 0.039\n",
            "[41,   120] loss: 0.045\n",
            "[42,    40] loss: 0.044\n",
            "[42,    80] loss: 0.038\n",
            "[42,   120] loss: 0.053\n",
            "[43,    40] loss: 0.038\n",
            "[43,    80] loss: 0.036\n",
            "[43,   120] loss: 0.043\n",
            "[44,    40] loss: 0.033\n",
            "[44,    80] loss: 0.040\n",
            "[44,   120] loss: 0.036\n",
            "[45,    40] loss: 0.027\n",
            "[45,    80] loss: 0.043\n",
            "[45,   120] loss: 0.040\n",
            "[46,    40] loss: 0.021\n",
            "[46,    80] loss: 0.027\n",
            "[46,   120] loss: 0.038\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds3\""
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2c98ca47-03a1-4386-d734-bafe80f78b4f"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 98 %\n",
            "total correct 29611\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d7d26450-3730-495f-a632-5a5fab39fbf3"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 93 %\n",
            "total correct 9304\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d0ff2313-cd58-422f-8d1f-ebc7a06ecd09"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "total correct 9256\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "24f2f936-1595-4170-bce6-b79958ab8d74"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "total correct 9293\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0b2e3ecb-7592-46b7-8b83-d35cececfbe1"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "total correct 8114\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d89a58a2-69fb-4146-f074-dc51cb3a1f7b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "total correct 8090\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3d2981a2-f98a-44b8-c89a-12f9ec475bc2"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "total correct 8104\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e9c04a20-ea42-453b-e921-384307f49372"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9113\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d31f3c11-603e-465d-cfe9-1ac3342bc12c"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 90 %\n",
            "total correct 9019\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c863af78-f3fd-4528-91b0-765b7edf3066"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9107\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "3d5e89ef-cf22-4549-eaf1-75b6eb0efab1"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 214,
      "outputs": []
    }
  ]
}