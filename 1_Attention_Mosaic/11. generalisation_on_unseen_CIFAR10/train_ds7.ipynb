{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eba951e4-6056-4433-81d3-dd26de83caea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98ab3307-0c6a-435e-ef3a-efd5915b09e2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f68a1f6e-fde6-453a-d356-36660dfd0e8b"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fc40e5c1-b6b6-4146-c2c1-9e4068478f85"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 30000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n"
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4WPsAzBcgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "375a78e1-dc00-4568-8eb7-30c1738ba885"
      },
      "source": [
        "print(len(mosaic_list_of_images),len(mosaic_label))"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b72e109f-8b11-4784-956c-9d21a71655c9"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.103\n",
            "[1,    80] loss: 1.098\n",
            "[1,   120] loss: 1.097\n",
            "[2,    40] loss: 1.094\n",
            "[2,    80] loss: 1.089\n",
            "[2,   120] loss: 1.087\n",
            "[3,    40] loss: 1.084\n",
            "[3,    80] loss: 1.084\n",
            "[3,   120] loss: 1.077\n",
            "[4,    40] loss: 1.072\n",
            "[4,    80] loss: 1.065\n",
            "[4,   120] loss: 1.058\n",
            "[5,    40] loss: 1.033\n",
            "[5,    80] loss: 1.022\n",
            "[5,   120] loss: 0.970\n",
            "[6,    40] loss: 0.922\n",
            "[6,    80] loss: 0.876\n",
            "[6,   120] loss: 0.818\n",
            "[7,    40] loss: 0.763\n",
            "[7,    80] loss: 0.726\n",
            "[7,   120] loss: 0.682\n",
            "[8,    40] loss: 0.629\n",
            "[8,    80] loss: 0.601\n",
            "[8,   120] loss: 0.597\n",
            "[9,    40] loss: 0.531\n",
            "[9,    80] loss: 0.527\n",
            "[9,   120] loss: 0.528\n",
            "[10,    40] loss: 0.477\n",
            "[10,    80] loss: 0.452\n",
            "[10,   120] loss: 0.454\n",
            "[11,    40] loss: 0.406\n",
            "[11,    80] loss: 0.413\n",
            "[11,   120] loss: 0.422\n",
            "[12,    40] loss: 0.392\n",
            "[12,    80] loss: 0.386\n",
            "[12,   120] loss: 0.367\n",
            "[13,    40] loss: 0.319\n",
            "[13,    80] loss: 0.342\n",
            "[13,   120] loss: 0.344\n",
            "[14,    40] loss: 0.284\n",
            "[14,    80] loss: 0.297\n",
            "[14,   120] loss: 0.315\n",
            "[15,    40] loss: 0.255\n",
            "[15,    80] loss: 0.264\n",
            "[15,   120] loss: 0.274\n",
            "[16,    40] loss: 0.234\n",
            "[16,    80] loss: 0.249\n",
            "[16,   120] loss: 0.250\n",
            "[17,    40] loss: 0.217\n",
            "[17,    80] loss: 0.234\n",
            "[17,   120] loss: 0.237\n",
            "[18,    40] loss: 0.217\n",
            "[18,    80] loss: 0.220\n",
            "[18,   120] loss: 0.212\n",
            "[19,    40] loss: 0.173\n",
            "[19,    80] loss: 0.190\n",
            "[19,   120] loss: 0.199\n",
            "[20,    40] loss: 0.168\n",
            "[20,    80] loss: 0.156\n",
            "[20,   120] loss: 0.196\n",
            "[21,    40] loss: 0.151\n",
            "[21,    80] loss: 0.182\n",
            "[21,   120] loss: 0.174\n",
            "[22,    40] loss: 0.151\n",
            "[22,    80] loss: 0.155\n",
            "[22,   120] loss: 0.163\n",
            "[23,    40] loss: 0.130\n",
            "[23,    80] loss: 0.155\n",
            "[23,   120] loss: 0.165\n",
            "[24,    40] loss: 0.118\n",
            "[24,    80] loss: 0.131\n",
            "[24,   120] loss: 0.131\n",
            "[25,    40] loss: 0.117\n",
            "[25,    80] loss: 0.131\n",
            "[25,   120] loss: 0.121\n",
            "[26,    40] loss: 0.095\n",
            "[26,    80] loss: 0.105\n",
            "[26,   120] loss: 0.111\n",
            "[27,    40] loss: 0.099\n",
            "[27,    80] loss: 0.106\n",
            "[27,   120] loss: 0.106\n",
            "[28,    40] loss: 0.085\n",
            "[28,    80] loss: 0.102\n",
            "[28,   120] loss: 0.097\n",
            "[29,    40] loss: 0.089\n",
            "[29,    80] loss: 0.089\n",
            "[29,   120] loss: 0.094\n",
            "[30,    40] loss: 0.075\n",
            "[30,    80] loss: 0.098\n",
            "[30,   120] loss: 0.104\n",
            "[31,    40] loss: 0.066\n",
            "[31,    80] loss: 0.076\n",
            "[31,   120] loss: 0.095\n",
            "[32,    40] loss: 0.080\n",
            "[32,    80] loss: 0.083\n",
            "[32,   120] loss: 0.078\n",
            "[33,    40] loss: 0.058\n",
            "[33,    80] loss: 0.073\n",
            "[33,   120] loss: 0.079\n",
            "[34,    40] loss: 0.067\n",
            "[34,    80] loss: 0.064\n",
            "[34,   120] loss: 0.065\n",
            "[35,    40] loss: 0.058\n",
            "[35,    80] loss: 0.059\n",
            "[35,   120] loss: 0.081\n",
            "[36,    40] loss: 0.068\n",
            "[36,    80] loss: 0.067\n",
            "[36,   120] loss: 0.065\n",
            "[37,    40] loss: 0.057\n",
            "[37,    80] loss: 0.068\n",
            "[37,   120] loss: 0.088\n",
            "[38,    40] loss: 0.055\n",
            "[38,    80] loss: 0.050\n",
            "[38,   120] loss: 0.052\n",
            "[39,    40] loss: 0.045\n",
            "[39,    80] loss: 0.047\n",
            "[39,   120] loss: 0.056\n",
            "[40,    40] loss: 0.045\n",
            "[40,    80] loss: 0.050\n",
            "[40,   120] loss: 0.047\n",
            "[41,    40] loss: 0.045\n",
            "[41,    80] loss: 0.042\n",
            "[41,   120] loss: 0.051\n",
            "[42,    40] loss: 0.041\n",
            "[42,    80] loss: 0.035\n",
            "[42,   120] loss: 0.044\n",
            "[43,    40] loss: 0.030\n",
            "[43,    80] loss: 0.035\n",
            "[43,   120] loss: 0.044\n",
            "[44,    40] loss: 0.047\n",
            "[44,    80] loss: 0.046\n",
            "[44,   120] loss: 0.044\n",
            "[45,    40] loss: 0.035\n",
            "[45,    80] loss: 0.027\n",
            "[45,   120] loss: 0.039\n",
            "[46,    40] loss: 0.037\n",
            "[46,    80] loss: 0.031\n",
            "[46,   120] loss: 0.038\n",
            "[47,    40] loss: 0.026\n",
            "[47,    80] loss: 0.026\n",
            "[47,   120] loss: 0.040\n",
            "[48,    40] loss: 0.041\n",
            "[48,    80] loss: 0.028\n",
            "[48,   120] loss: 0.032\n",
            "[49,    40] loss: 0.030\n",
            "[49,    80] loss: 0.033\n",
            "[49,   120] loss: 0.032\n",
            "[50,    40] loss: 0.026\n",
            "[50,    80] loss: 0.028\n",
            "[50,   120] loss: 0.030\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds7\""
      ],
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b727d990-7d25-4dcf-9d69-6ead6c1d39ce"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 98 %\n",
            "total correct 29675\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7adfd5eb-3f31-4c70-dffd-71312f15c19d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "total correct 9260\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f57707c5-4d70-49db-802d-eed478009bdf"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 88 %\n",
            "total correct 8866\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8ba98b2c-8fcf-4ab3-9381-b1ad57b3f8a5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "total correct 9205\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d66d4243-5050-4e30-abd3-b181a1adf618"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 93 %\n",
            "total correct 9308\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "441f5710-3662-4139-e2ad-ee244e425b79"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 87 %\n",
            "total correct 8790\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6e08a851-351e-4d67-9d82-4c7d9ffa6475"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9195\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6c27d45f-0e52-44c5-e2b4-7614c8d1ce4b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "total correct 9282\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1f1fcebe-74a0-4aa8-978d-5bba350bd79a"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 87 %\n",
            "total correct 8786\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4cb0a96f-8111-4297-c15e-06cc4cc1a29c"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9185\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "904ccf20-d658-4aeb-a872-86f9d92af833"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 382
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 382,
      "outputs": []
    }
  ]
}