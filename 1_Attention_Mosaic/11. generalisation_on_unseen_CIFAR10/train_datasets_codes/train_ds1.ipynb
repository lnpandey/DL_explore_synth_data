{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "434ae3aa-3cb6-43f0-efdd-7acd7e962b2a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5e5bdfa6-db41-4a72-9c9b-1d40671e53b8"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "99aa8b65-d32d-4184-b1da-429c87c79522"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "999a5307-cffc-483c-bd6d-07448adfce2d"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                     fg_size = 15000, \n",
        "                                                                     desired_num = 30000, \n",
        "                                                                     background_data = background_data_train, \n",
        "                                                                     foreground_data = foreground_data_train, \n",
        "                                                                     foreground_label = foreground_label_train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f915638-30d2-474f-f2cc-1b28b2d82487"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.108\n",
            "[1,    80] loss: 1.098\n",
            "[1,   120] loss: 1.095\n",
            "[2,    40] loss: 1.089\n",
            "[2,    80] loss: 1.082\n",
            "[2,   120] loss: 1.078\n",
            "[3,    40] loss: 1.072\n",
            "[3,    80] loss: 1.065\n",
            "[3,   120] loss: 1.060\n",
            "[4,    40] loss: 1.043\n",
            "[4,    80] loss: 1.031\n",
            "[4,   120] loss: 0.990\n",
            "[5,    40] loss: 0.945\n",
            "[5,    80] loss: 0.897\n",
            "[5,   120] loss: 0.840\n",
            "[6,    40] loss: 0.778\n",
            "[6,    80] loss: 0.728\n",
            "[6,   120] loss: 0.692\n",
            "[7,    40] loss: 0.629\n",
            "[7,    80] loss: 0.623\n",
            "[7,   120] loss: 0.583\n",
            "[8,    40] loss: 0.522\n",
            "[8,    80] loss: 0.529\n",
            "[8,   120] loss: 0.507\n",
            "[9,    40] loss: 0.456\n",
            "[9,    80] loss: 0.467\n",
            "[9,   120] loss: 0.439\n",
            "[10,    40] loss: 0.413\n",
            "[10,    80] loss: 0.393\n",
            "[10,   120] loss: 0.410\n",
            "[11,    40] loss: 0.370\n",
            "[11,    80] loss: 0.364\n",
            "[11,   120] loss: 0.368\n",
            "[12,    40] loss: 0.315\n",
            "[12,    80] loss: 0.314\n",
            "[12,   120] loss: 0.301\n",
            "[13,    40] loss: 0.305\n",
            "[13,    80] loss: 0.286\n",
            "[13,   120] loss: 0.279\n",
            "[14,    40] loss: 0.252\n",
            "[14,    80] loss: 0.289\n",
            "[14,   120] loss: 0.248\n",
            "[15,    40] loss: 0.227\n",
            "[15,    80] loss: 0.268\n",
            "[15,   120] loss: 0.244\n",
            "[16,    40] loss: 0.204\n",
            "[16,    80] loss: 0.220\n",
            "[16,   120] loss: 0.221\n",
            "[17,    40] loss: 0.186\n",
            "[17,    80] loss: 0.199\n",
            "[17,   120] loss: 0.206\n",
            "[18,    40] loss: 0.172\n",
            "[18,    80] loss: 0.192\n",
            "[18,   120] loss: 0.174\n",
            "[19,    40] loss: 0.158\n",
            "[19,    80] loss: 0.151\n",
            "[19,   120] loss: 0.159\n",
            "[20,    40] loss: 0.148\n",
            "[20,    80] loss: 0.148\n",
            "[20,   120] loss: 0.148\n",
            "[21,    40] loss: 0.123\n",
            "[21,    80] loss: 0.148\n",
            "[21,   120] loss: 0.141\n",
            "[22,    40] loss: 0.109\n",
            "[22,    80] loss: 0.112\n",
            "[22,   120] loss: 0.131\n",
            "[23,    40] loss: 0.108\n",
            "[23,    80] loss: 0.130\n",
            "[23,   120] loss: 0.123\n",
            "[24,    40] loss: 0.105\n",
            "[24,    80] loss: 0.110\n",
            "[24,   120] loss: 0.111\n",
            "[25,    40] loss: 0.090\n",
            "[25,    80] loss: 0.094\n",
            "[25,   120] loss: 0.109\n",
            "[26,    40] loss: 0.078\n",
            "[26,    80] loss: 0.095\n",
            "[26,   120] loss: 0.115\n",
            "[27,    40] loss: 0.109\n",
            "[27,    80] loss: 0.101\n",
            "[27,   120] loss: 0.101\n",
            "[28,    40] loss: 0.080\n",
            "[28,    80] loss: 0.084\n",
            "[28,   120] loss: 0.083\n",
            "[29,    40] loss: 0.065\n",
            "[29,    80] loss: 0.077\n",
            "[29,   120] loss: 0.078\n",
            "[30,    40] loss: 0.070\n",
            "[30,    80] loss: 0.068\n",
            "[30,   120] loss: 0.059\n",
            "[31,    40] loss: 0.059\n",
            "[31,    80] loss: 0.066\n",
            "[31,   120] loss: 0.074\n",
            "[32,    40] loss: 0.059\n",
            "[32,    80] loss: 0.060\n",
            "[32,   120] loss: 0.067\n",
            "[33,    40] loss: 0.055\n",
            "[33,    80] loss: 0.059\n",
            "[33,   120] loss: 0.059\n",
            "[34,    40] loss: 0.048\n",
            "[34,    80] loss: 0.053\n",
            "[34,   120] loss: 0.072\n",
            "[35,    40] loss: 0.049\n",
            "[35,    80] loss: 0.049\n",
            "[35,   120] loss: 0.051\n",
            "[36,    40] loss: 0.060\n",
            "[36,    80] loss: 0.075\n",
            "[36,   120] loss: 0.063\n",
            "[37,    40] loss: 0.038\n",
            "[37,    80] loss: 0.041\n",
            "[37,   120] loss: 0.045\n",
            "[38,    40] loss: 0.035\n",
            "[38,    80] loss: 0.044\n",
            "[38,   120] loss: 0.049\n",
            "[39,    40] loss: 0.041\n",
            "[39,    80] loss: 0.048\n",
            "[39,   120] loss: 0.036\n",
            "[40,    40] loss: 0.028\n",
            "[40,    80] loss: 0.029\n",
            "[40,   120] loss: 0.040\n",
            "[41,    40] loss: 0.035\n",
            "[41,    80] loss: 0.035\n",
            "[41,   120] loss: 0.046\n",
            "[42,    40] loss: 0.031\n",
            "[42,    80] loss: 0.026\n",
            "[42,   120] loss: 0.032\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds1\""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4219f210-0b89-4a3e-f33c-37f5939a397c"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29805\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6de72b1d-bdff-4d35-81b6-46b0435d5f77"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 93 %\n",
            "total correct 9387\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b95d8df7-7585-4eda-8875-ff780c283260"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 89 %\n",
            "total correct 8972\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "68027765-d8b1-4ac3-eb84-6c1bff716e47"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 93 %\n",
            "total correct 9324\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8dd065d9-8213-4657-d5c5-72a0c8691d3f"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 83 %\n",
            "total correct 8345\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e3dd18ce-5c87-4cea-8aea-9d4ca65f3de5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "total correct 7903\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b5440860-3a38-402c-dab0-924dd4f56059"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 82 %\n",
            "total correct 8241\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "da91d4c0-f42f-45c1-c317-8199d94a0607"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "total correct 9217\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "37826fbc-ecc5-4f60-c65a-a4c9be3baf0f"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 87 %\n",
            "total correct 8791\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "568f3fbc-8a39-40b3-d00b-e0427e787c70"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 90 %\n",
            "total correct 9083\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fe483ca5-fcbf-4de9-ab59-30391a40cc24"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}