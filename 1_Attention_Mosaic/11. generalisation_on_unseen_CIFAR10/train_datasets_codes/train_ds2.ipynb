{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eba951e4-6056-4433-81d3-dd26de83caea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98ab3307-0c6a-435e-ef3a-efd5915b09e2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f68a1f6e-fde6-453a-d356-36660dfd0e8b"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fc40e5c1-b6b6-4146-c2c1-9e4068478f85"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 30000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4WPsAzBcgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46cc37ad-0a38-42b4-d677-10b506322995"
      },
      "source": [
        "print(len(mosaic_list_of_images),len(mosaic_label))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3c9430e-dc21-4619-c140-82e5b4089f1a"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.099\n",
            "[1,    80] loss: 1.095\n",
            "[1,   120] loss: 1.089\n",
            "[2,    40] loss: 1.084\n",
            "[2,    80] loss: 1.079\n",
            "[2,   120] loss: 1.069\n",
            "[3,    40] loss: 1.057\n",
            "[3,    80] loss: 1.047\n",
            "[3,   120] loss: 1.038\n",
            "[4,    40] loss: 1.012\n",
            "[4,    80] loss: 0.971\n",
            "[4,   120] loss: 0.891\n",
            "[5,    40] loss: 0.789\n",
            "[5,    80] loss: 0.730\n",
            "[5,   120] loss: 0.674\n",
            "[6,    40] loss: 0.600\n",
            "[6,    80] loss: 0.575\n",
            "[6,   120] loss: 0.543\n",
            "[7,    40] loss: 0.478\n",
            "[7,    80] loss: 0.466\n",
            "[7,   120] loss: 0.447\n",
            "[8,    40] loss: 0.406\n",
            "[8,    80] loss: 0.400\n",
            "[8,   120] loss: 0.378\n",
            "[9,    40] loss: 0.344\n",
            "[9,    80] loss: 0.336\n",
            "[9,   120] loss: 0.323\n",
            "[10,    40] loss: 0.289\n",
            "[10,    80] loss: 0.276\n",
            "[10,   120] loss: 0.292\n",
            "[11,    40] loss: 0.251\n",
            "[11,    80] loss: 0.258\n",
            "[11,   120] loss: 0.247\n",
            "[12,    40] loss: 0.240\n",
            "[12,    80] loss: 0.208\n",
            "[12,   120] loss: 0.240\n",
            "[13,    40] loss: 0.184\n",
            "[13,    80] loss: 0.194\n",
            "[13,   120] loss: 0.204\n",
            "[14,    40] loss: 0.191\n",
            "[14,    80] loss: 0.177\n",
            "[14,   120] loss: 0.186\n",
            "[15,    40] loss: 0.177\n",
            "[15,    80] loss: 0.151\n",
            "[15,   120] loss: 0.172\n",
            "[16,    40] loss: 0.162\n",
            "[16,    80] loss: 0.153\n",
            "[16,   120] loss: 0.152\n",
            "[17,    40] loss: 0.124\n",
            "[17,    80] loss: 0.130\n",
            "[17,   120] loss: 0.121\n",
            "[18,    40] loss: 0.125\n",
            "[18,    80] loss: 0.120\n",
            "[18,   120] loss: 0.123\n",
            "[19,    40] loss: 0.104\n",
            "[19,    80] loss: 0.118\n",
            "[19,   120] loss: 0.121\n",
            "[20,    40] loss: 0.101\n",
            "[20,    80] loss: 0.090\n",
            "[20,   120] loss: 0.109\n",
            "[21,    40] loss: 0.090\n",
            "[21,    80] loss: 0.089\n",
            "[21,   120] loss: 0.084\n",
            "[22,    40] loss: 0.070\n",
            "[22,    80] loss: 0.072\n",
            "[22,   120] loss: 0.084\n",
            "[23,    40] loss: 0.096\n",
            "[23,    80] loss: 0.100\n",
            "[23,   120] loss: 0.091\n",
            "[24,    40] loss: 0.060\n",
            "[24,    80] loss: 0.079\n",
            "[24,   120] loss: 0.081\n",
            "[25,    40] loss: 0.089\n",
            "[25,    80] loss: 0.075\n",
            "[25,   120] loss: 0.071\n",
            "[26,    40] loss: 0.060\n",
            "[26,    80] loss: 0.053\n",
            "[26,   120] loss: 0.069\n",
            "[27,    40] loss: 0.053\n",
            "[27,    80] loss: 0.052\n",
            "[27,   120] loss: 0.059\n",
            "[28,    40] loss: 0.056\n",
            "[28,    80] loss: 0.047\n",
            "[28,   120] loss: 0.047\n",
            "[29,    40] loss: 0.043\n",
            "[29,    80] loss: 0.054\n",
            "[29,   120] loss: 0.043\n",
            "[30,    40] loss: 0.045\n",
            "[30,    80] loss: 0.051\n",
            "[30,   120] loss: 0.056\n",
            "[31,    40] loss: 0.050\n",
            "[31,    80] loss: 0.046\n",
            "[31,   120] loss: 0.060\n",
            "[32,    40] loss: 0.056\n",
            "[32,    80] loss: 0.063\n",
            "[32,   120] loss: 0.050\n",
            "[33,    40] loss: 0.048\n",
            "[33,    80] loss: 0.036\n",
            "[33,   120] loss: 0.042\n",
            "[34,    40] loss: 0.032\n",
            "[34,    80] loss: 0.044\n",
            "[34,   120] loss: 0.052\n",
            "[35,    40] loss: 0.042\n",
            "[35,    80] loss: 0.070\n",
            "[35,   120] loss: 0.063\n",
            "[36,    40] loss: 0.039\n",
            "[36,    80] loss: 0.050\n",
            "[36,   120] loss: 0.051\n",
            "[37,    40] loss: 0.033\n",
            "[37,    80] loss: 0.049\n",
            "[37,   120] loss: 0.035\n",
            "[38,    40] loss: 0.030\n",
            "[38,    80] loss: 0.041\n",
            "[38,   120] loss: 0.031\n",
            "[39,    40] loss: 0.029\n",
            "[39,    80] loss: 0.025\n",
            "[39,   120] loss: 0.028\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds2\""
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "989eced0-095e-4926-cd18-4dba4810d30d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29761\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "111cf60e-a604-4fa2-d1b5-e93d46302848"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 82 %\n",
            "total correct 8230\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "342b3536-bd71-49e1-9df4-d0fe1450112c"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "total correct 9601\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "24778db2-26ed-4350-8788-264865d45728"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 84 %\n",
            "total correct 8403\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3d0c1b57-e483-45be-9cfb-5399a3c0ae07"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "total correct 7304\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8caf6cac-6ef3-4fb0-da88-4a84b5911611"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 86 %\n",
            "total correct 8644\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d258adb6-48fe-48ce-a353-893a1ca21eda"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 74 %\n",
            "total correct 7419\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "16dcc42b-eec7-48c4-eadb-3dc78ba01baf"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "total correct 8042\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "18fe461b-fb4b-4aac-d210-2ca5e320fc63"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 95 %\n",
            "total correct 9500\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1eff8024-6b5b-4ba9-cbca-a4d67cc7cf1b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 83 %\n",
            "total correct 8317\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "14e9da7a-7ff5-4e54-8bfc-850b4a6c5832"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 173,
      "outputs": []
    }
  ]
}