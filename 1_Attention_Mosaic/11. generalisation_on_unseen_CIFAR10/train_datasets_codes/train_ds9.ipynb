{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generalisation_on_unseen_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eba951e4-6056-4433-81d3-dd26de83caea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZo88NV5ZUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98ab3307-0c6a-435e-ef3a-efd5915b09e2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSGIGxk5ZUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdsP4Lq5ZUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data_train=[]\n",
        "background_label_train=[]\n",
        "foreground_data_train=[]\n",
        "foreground_label_train=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):   #5000*batch_size = 50000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_train.append(img)\n",
        "      background_label_train.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_train.append(img)\n",
        "      foreground_label_train.append(labels[j])\n",
        "            \n",
        "foreground_data_train = torch.tensor(foreground_data_train)\n",
        "foreground_label_train = torch.tensor(foreground_label_train)\n",
        "background_data_train = torch.tensor(background_data_train)\n",
        "background_label_train = torch.tensor(background_label_train)\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7eYWwWUTnS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "background_data_test=[]\n",
        "background_label_test=[]\n",
        "foreground_data_test=[]\n",
        "foreground_label_test=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(1000):   #1000*batch_size = 10000 data points\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data_test.append(img)\n",
        "      background_label_test.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data_test.append(img)\n",
        "      foreground_label_test.append(labels[j])\n",
        "            \n",
        "foreground_data_test = torch.tensor(foreground_data_test)\n",
        "foreground_label_test = torch.tensor(foreground_label_test)\n",
        "background_data_test = torch.tensor(background_data_test)\n",
        "background_label_test = torch.tensor(background_label_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sasFFybUPOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f68a1f6e-fde6-453a-d356-36660dfd0e8b"
      },
      "source": [
        "print(foreground_data_train.size())\n",
        "print(foreground_data_test.size())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32])\n",
            "torch.Size([3000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLR6EvK5DqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foreground_data_combined = torch.cat([foreground_data_train , foreground_data_test], dim=0)\n",
        "foreground_label_combined = torch.cat([foreground_label_train , foreground_label_test], dim=0) \n",
        "background_data_combined = torch.cat([background_data_train , background_data_test], dim=0) \n",
        "background_label_combined = torch.cat([background_label_train , background_label_test], dim=0) "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8KV_9g_SY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fc40e5c1-b6b6-4146-c2c1-9e4068478f85"
      },
      "source": [
        "print(foreground_data_train.size() , foreground_data_test.size() , foreground_data_combined.size())\n",
        "print(foreground_label_train.size() , foreground_label_test.size() , foreground_label_combined.size())\n",
        "print(background_data_train.size() , background_data_test.size() , background_data_combined.size())\n",
        "print(background_label_train.size() , background_label_test.size() , background_label_combined.size())"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15000, 3, 32, 32]) torch.Size([3000, 3, 32, 32]) torch.Size([18000, 3, 32, 32])\n",
            "torch.Size([15000]) torch.Size([3000]) torch.Size([18000])\n",
            "torch.Size([35000, 3, 32, 32]) torch.Size([7000, 3, 32, 32]) torch.Size([42000, 3, 32, 32])\n",
            "torch.Size([35000]) torch.Size([7000]) torch.Size([42000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa2mMli5ZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(background_data, foreground_data, foreground_label, bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSidmeagYPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mosaic_creation(bg_size, fg_size, desired_num, background_data, foreground_data, foreground_label):\n",
        "  # bg_size = 35000\n",
        "  # fg_size = 15000\n",
        "  # desired_num = 30000\n",
        "  mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "  fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "  mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "  for i in range(desired_num):\n",
        "    bg_idx = np.random.randint(0,bg_size,8)\n",
        "    fg_idx = np.random.randint(0,fg_size)\n",
        "    fg = np.random.randint(0,9)\n",
        "    fore_idx.append(fg)\n",
        "    image_list,label = create_mosaic_img(background_data, foreground_data, foreground_label ,bg_idx,fg_idx,fg)\n",
        "    mosaic_list_of_images.append(image_list)\n",
        "    mosaic_label.append(label)\n",
        "  \n",
        "  return mosaic_list_of_images, mosaic_label, fore_idx\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBymhsvlhstt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images, mosaic_label, fore_idx = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 30000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n"
      ],
      "execution_count": 424,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4WPsAzBcgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e39d3a2-2fe6-4752-b06f-d603b054fdcc"
      },
      "source": [
        "print(len(mosaic_list_of_images),len(mosaic_label))"
      ],
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSO9SFE25Lrk",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n"
      ],
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71gWrhugFUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSYzkDitY9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model initialisation\n",
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 428,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexGRZ2svm-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.module1 = Focus().double()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,z):  #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    x = x.to(\"cuda\")\n",
        "    y = y.to(\"cuda\")\n",
        "\n",
        "    for i in range(9):\n",
        "        x[:,i] = self.module1.forward(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    y1 = self.conv1(y)\n",
        "    y1 = F.relu(self.batch_norm1(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv2(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    \n",
        "    y1 = self.conv3(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv4(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "    y1 = self.dropout1(y1)\n",
        "\n",
        "    y1 = self.conv5(y1)\n",
        "    y1 = F.relu(self.batch_norm2(y1))\n",
        "\n",
        "    y1 = (F.relu(self.conv6(y1)))\n",
        "    y1 = self.pool(y1)\n",
        "\n",
        "    y1 = y1.view(y1.size(0), -1)\n",
        "\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = self.dropout2(y1)\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "\n",
        "    return y1 , x, y"
      ],
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXAyn9NvqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 430,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaPbDFsvsZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_classify = nn.CrossEntropyLoss()\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 431,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZqomaQtUU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b04f49ae-fd52-4f39-847a-ba252344018c"
      },
      "source": [
        "# train\n",
        "nos_epochs = 300\n",
        "loss_list = []\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_classify(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 40\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "\n",
        "  loss_list.append(np.mean(epoch_loss))\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "        \n",
        "print('Finished Training')"
      ],
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.108\n",
            "[1,    80] loss: 1.096\n",
            "[1,   120] loss: 1.089\n",
            "[2,    40] loss: 1.080\n",
            "[2,    80] loss: 1.076\n",
            "[2,   120] loss: 1.068\n",
            "[3,    40] loss: 1.054\n",
            "[3,    80] loss: 1.056\n",
            "[3,   120] loss: 1.041\n",
            "[4,    40] loss: 1.027\n",
            "[4,    80] loss: 1.025\n",
            "[4,   120] loss: 1.016\n",
            "[5,    40] loss: 0.975\n",
            "[5,    80] loss: 0.941\n",
            "[5,   120] loss: 0.904\n",
            "[6,    40] loss: 0.844\n",
            "[6,    80] loss: 0.795\n",
            "[6,   120] loss: 0.788\n",
            "[7,    40] loss: 0.706\n",
            "[7,    80] loss: 0.698\n",
            "[7,   120] loss: 0.673\n",
            "[8,    40] loss: 0.598\n",
            "[8,    80] loss: 0.615\n",
            "[8,   120] loss: 0.587\n",
            "[9,    40] loss: 0.514\n",
            "[9,    80] loss: 0.523\n",
            "[9,   120] loss: 0.503\n",
            "[10,    40] loss: 0.456\n",
            "[10,    80] loss: 0.450\n",
            "[10,   120] loss: 0.445\n",
            "[11,    40] loss: 0.397\n",
            "[11,    80] loss: 0.387\n",
            "[11,   120] loss: 0.407\n",
            "[12,    40] loss: 0.359\n",
            "[12,    80] loss: 0.360\n",
            "[12,   120] loss: 0.357\n",
            "[13,    40] loss: 0.299\n",
            "[13,    80] loss: 0.306\n",
            "[13,   120] loss: 0.315\n",
            "[14,    40] loss: 0.282\n",
            "[14,    80] loss: 0.282\n",
            "[14,   120] loss: 0.271\n",
            "[15,    40] loss: 0.265\n",
            "[15,    80] loss: 0.263\n",
            "[15,   120] loss: 0.269\n",
            "[16,    40] loss: 0.225\n",
            "[16,    80] loss: 0.234\n",
            "[16,   120] loss: 0.264\n",
            "[17,    40] loss: 0.212\n",
            "[17,    80] loss: 0.226\n",
            "[17,   120] loss: 0.223\n",
            "[18,    40] loss: 0.191\n",
            "[18,    80] loss: 0.194\n",
            "[18,   120] loss: 0.200\n",
            "[19,    40] loss: 0.173\n",
            "[19,    80] loss: 0.187\n",
            "[19,   120] loss: 0.163\n",
            "[20,    40] loss: 0.148\n",
            "[20,    80] loss: 0.165\n",
            "[20,   120] loss: 0.161\n",
            "[21,    40] loss: 0.126\n",
            "[21,    80] loss: 0.142\n",
            "[21,   120] loss: 0.175\n",
            "[22,    40] loss: 0.140\n",
            "[22,    80] loss: 0.130\n",
            "[22,   120] loss: 0.144\n",
            "[23,    40] loss: 0.126\n",
            "[23,    80] loss: 0.131\n",
            "[23,   120] loss: 0.132\n",
            "[24,    40] loss: 0.120\n",
            "[24,    80] loss: 0.112\n",
            "[24,   120] loss: 0.113\n",
            "[25,    40] loss: 0.095\n",
            "[25,    80] loss: 0.121\n",
            "[25,   120] loss: 0.123\n",
            "[26,    40] loss: 0.093\n",
            "[26,    80] loss: 0.098\n",
            "[26,   120] loss: 0.110\n",
            "[27,    40] loss: 0.076\n",
            "[27,    80] loss: 0.089\n",
            "[27,   120] loss: 0.108\n",
            "[28,    40] loss: 0.088\n",
            "[28,    80] loss: 0.089\n",
            "[28,   120] loss: 0.091\n",
            "[29,    40] loss: 0.072\n",
            "[29,    80] loss: 0.082\n",
            "[29,   120] loss: 0.093\n",
            "[30,    40] loss: 0.073\n",
            "[30,    80] loss: 0.081\n",
            "[30,   120] loss: 0.075\n",
            "[31,    40] loss: 0.065\n",
            "[31,    80] loss: 0.064\n",
            "[31,   120] loss: 0.084\n",
            "[32,    40] loss: 0.059\n",
            "[32,    80] loss: 0.067\n",
            "[32,   120] loss: 0.084\n",
            "[33,    40] loss: 0.065\n",
            "[33,    80] loss: 0.060\n",
            "[33,   120] loss: 0.073\n",
            "[34,    40] loss: 0.050\n",
            "[34,    80] loss: 0.053\n",
            "[34,   120] loss: 0.071\n",
            "[35,    40] loss: 0.052\n",
            "[35,    80] loss: 0.054\n",
            "[35,   120] loss: 0.070\n",
            "[36,    40] loss: 0.059\n",
            "[36,    80] loss: 0.057\n",
            "[36,   120] loss: 0.067\n",
            "[37,    40] loss: 0.051\n",
            "[37,    80] loss: 0.052\n",
            "[37,   120] loss: 0.047\n",
            "[38,    40] loss: 0.035\n",
            "[38,    80] loss: 0.042\n",
            "[38,   120] loss: 0.040\n",
            "[39,    40] loss: 0.034\n",
            "[39,    80] loss: 0.070\n",
            "[39,   120] loss: 0.062\n",
            "[40,    40] loss: 0.034\n",
            "[40,    80] loss: 0.044\n",
            "[40,   120] loss: 0.043\n",
            "[41,    40] loss: 0.034\n",
            "[41,    80] loss: 0.041\n",
            "[41,   120] loss: 0.041\n",
            "[42,    40] loss: 0.031\n",
            "[42,    80] loss: 0.033\n",
            "[42,   120] loss: 0.055\n",
            "[43,    40] loss: 0.033\n",
            "[43,    80] loss: 0.024\n",
            "[43,   120] loss: 0.027\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQIyZlgyvqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"train_ds9\""
      ],
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDugMRftUyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/genralisation_on_unseen_CIFAR/\"+name+\".pt\")"
      ],
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVcTZ1RQzTqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "46497659-29f4-4070-af57-1cd52683e3d6"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29788\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSntUxwSgHNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_1, mosaic_label_1, fore_idx_1 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd1 = MosaicDataset(mosaic_list_of_images_1, mosaic_label_1 , fore_idx_1)\n",
        "test_loader_1 = DataLoader( msd1, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRII_ZuzjvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6a239f47-aac6-4c11-91ed-28da9437ad00"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_1:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9192\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBGlzdRugSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_1\n",
        "del msd1\n",
        "del mosaic_list_of_images_1\n",
        "del mosaic_label_1\n",
        "del fore_idx_1"
      ],
      "execution_count": 438,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsXLEKBjyLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_2, mosaic_label_2, fore_idx_2 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd2 = MosaicDataset(mosaic_list_of_images_2, mosaic_label_2 , fore_idx_2)\n",
        "test_loader_2 = DataLoader( msd2, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 439,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z7CSKM0VBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "543b1f01-f2fb-44bf-9fb6-e0207e0cf51a"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_2:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 440,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9106\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFJhvNR0tT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_2\n",
        "del msd2\n",
        "del mosaic_list_of_images_2\n",
        "del mosaic_label_2\n",
        "del fore_idx_2"
      ],
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb3FD-4Sohhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_3, mosaic_label_3, fore_idx_3 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 15000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_train, \n",
        "                                                                          foreground_label = foreground_label_train)\n",
        "\n",
        "msd3 = MosaicDataset(mosaic_list_of_images_3, mosaic_label_3 , fore_idx_3)\n",
        "test_loader_3 = DataLoader( msd3, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7CPi2wT0Xd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "52cbe52d-21b4-4511-86db-6dd6ebb390e5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_3:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9193\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfZgbTR00w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_3\n",
        "del msd3\n",
        "del mosaic_list_of_images_3\n",
        "del mosaic_label_3\n",
        "del fore_idx_3"
      ],
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywQU0yG2o3T_",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_4, mosaic_label_4, fore_idx_4 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd4 = MosaicDataset(mosaic_list_of_images_4, mosaic_label_4 , fore_idx_4)\n",
        "test_loader_4 = DataLoader( msd4, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLeW4vdv0Y7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "52503887-230c-4020-fc70-7008d1a0a473"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_4:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 90 %\n",
            "total correct 9088\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFYNQc104dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_4\n",
        "del msd4\n",
        "del mosaic_list_of_images_4\n",
        "del mosaic_label_4\n",
        "del fore_idx_4"
      ],
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK2aYdLdo3UK",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_5, mosaic_label_5, fore_idx_5 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd5 = MosaicDataset(mosaic_list_of_images_5, mosaic_label_5 , fore_idx_5)\n",
        "test_loader_5 = DataLoader( msd5, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gcb6dgr0bzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "931e3381-8450-41d4-c65b-3f2f4da34eb5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_5:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9106\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHtjoe808QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_5\n",
        "del msd5\n",
        "del mosaic_list_of_images_5\n",
        "del mosaic_label_5\n",
        "del fore_idx_5"
      ],
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACIcvFpso3UT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_6, mosaic_label_6, fore_idx_6 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 3000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_test, \n",
        "                                                                          foreground_label = foreground_label_test)\n",
        "\n",
        "msd6 = MosaicDataset(mosaic_list_of_images_6, mosaic_label_6 , fore_idx_6)\n",
        "test_loader_6 = DataLoader( msd6, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rozEI40dbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b8f4c3cc-2d51-4dcb-debb-f99dc6ad48ac"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_6:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9157\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX4uG3Sn1A5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_6\n",
        "del msd6\n",
        "del mosaic_list_of_images_6\n",
        "del mosaic_label_6\n",
        "del fore_idx_6"
      ],
      "execution_count": 453,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLt4xNT_q_Y2",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_7, mosaic_label_7, fore_idx_7 = init_mosaic_creation(bg_size = 35000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_train, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd7 = MosaicDataset(mosaic_list_of_images_7, mosaic_label_7 , fore_idx_7)\n",
        "test_loader_7 = DataLoader( msd7, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brH70rlP0hWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cbf8dab9-ed5a-476b-d56c-10da2a686a74"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_7:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 455,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9169\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6owhcwU1HVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_7\n",
        "del msd7\n",
        "del mosaic_list_of_images_7\n",
        "del mosaic_label_7\n",
        "del fore_idx_7"
      ],
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfnNbZqfq_ZT",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_8, mosaic_label_8, fore_idx_8 = init_mosaic_creation(bg_size = 7000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_test, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd8 = MosaicDataset(mosaic_list_of_images_8, mosaic_label_8 , fore_idx_8)\n",
        "test_loader_8 = DataLoader( msd8, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzFo1vH30k_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8053e6c1-8468-4ee2-eea4-5c102ed0fbfa"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_8:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9102\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEneUJNd1LQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_8\n",
        "del msd8\n",
        "del mosaic_list_of_images_8\n",
        "del mosaic_label_8\n",
        "del fore_idx_8"
      ],
      "execution_count": 459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBLBjzAJq_Zc",
        "colab": {}
      },
      "source": [
        "mosaic_list_of_images_9, mosaic_label_9, fore_idx_9 = init_mosaic_creation(bg_size = 42000, \n",
        "                                                                          fg_size = 18000, \n",
        "                                                                          desired_num = 10000, \n",
        "                                                                          background_data = background_data_combined, \n",
        "                                                                          foreground_data = foreground_data_combined, \n",
        "                                                                          foreground_label = foreground_label_combined)\n",
        "\n",
        "msd9 = MosaicDataset(mosaic_list_of_images_9, mosaic_label_9 , fore_idx_9)\n",
        "test_loader_9 = DataLoader( msd9, batch_size= batch ,shuffle = False)"
      ],
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "626PTbsW0moI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a63190a9-21db-4384-b0bf-c64949dcb432"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader_9:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    outputs, alphas, avg_images = classify(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "total correct 9134\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlKwKma1PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del test_loader_9\n",
        "del msd9\n",
        "del mosaic_list_of_images_9\n",
        "del mosaic_label_9\n",
        "del fore_idx_9"
      ],
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcMFWrB5ZWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nivyY0qX5ZWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "4d8fe9a2-a001-4f23-f474-00b6a01db3cb"
      },
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Training_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 464
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5d338c9vJnvIBlkIJASQXUSWaEFREbRFpWKLDy2tS3vb+thF7aNdfO4ud2vb+27v9rFq622rrbW1rWhta92tRQF3CaLIbtjBAGENa9bf88cMNrKEATI5k8z3/Xqd18ycOTP55bzEb851neu6zN0REZHkFQq6ABERCZaCQEQkySkIRESSnIJARCTJKQhERJJcStAFnIjCwkLv27dv0GWIiHQq8+fP3+ruRYfu75RB0LdvX6qqqoIuQ0SkUzGztUfar6YhEZEkpyAQEUlyCgIRkSSnIBARSXIKAhGRJKcgEBFJcgoCEZEkl1RBMG/Ndu6Zu5KGppagSxERSRhJFQTPLtrEfz61jMl3zGXuitqgyxERSQhJFQTfmjKM+z5TSUuLc9V9b3Dt76tYv31f0GWJiAQqqYIAYOKQEp79P+fytY8M5sV3t3LBbXO47bkV7G9oDro0EZFAJF0QAKSnhPnS+QN4/qvn8eFTe3LnrHe54LY5PLOoBi3dKSLJJimD4KDSvEx+PmMUM68dS05GCtf94U0+e/881m1Tc5GIJI+kDoKDxvbvwRPXj+c7U4Yxb/V2LvzZHO56oVp3F4lIUlAQRKWEQ/zb+H788+bzOH9wMT95djmX3Pkib6zeHnRpIiJxpSA4RGleJr+8cgy/ubqSfQ3NTP/Vq3z9kbfZsbch6NJEROJCQXAUk4aW8NxN53Ldeafw1zc3MvH/zeaxt98LuiwRkXanIGhDVloKt1w0hCduGE9Fj2xueHABN85cwK59jUGXJiLSbhQEMRjSM5dHrhvHTRcO4omFNUy+Yy6vVG8NuiwRkXahIIhRSjjEDZMG8tcvnEVmWphP/fp1vv/EEg40aiCaiHRuCoLjdHp5Pk9efw5XjavgNy+t5tJfvMSS9+qCLktE5IQpCE5AZlqYW6cO5/7PnsHOfY1Mvesl/jJ/Q9BliYicEAXBSZgwuJhnv3IuI8vzufWJJeytbwq6JBGR4xbXIDCz+8xsi5ktOsr7ZmZ3mlm1mS00s9HxrCceCrLT+PeLh7JrfyMPvrEu6HJERI5bvK8I7gcmt/H+RcDA6HYtcHec64mLUX0KGNe/B/e+uIr6JnUei0jnEtcgcPe5QFtzNEwFfu8RrwH5ZlYaz5ri5Yvnn8LmunoeXbAx6FJERI5L0H0EvYH1rV5viO47jJlda2ZVZlZVW5t4q4uNH1DI8N65/HLOKppbNJW1iHQeQQdBzNz9HnevdPfKoqKioMs5jJnxxQkDWL11L88s2hR0OSIiMQs6CDYC5a1el0X3dUofObUn/QuzuXtOtRa4EZFOI+ggeAy4Knr30Fhgl7vXBFzTCQuHjOvOO4VFG+t48V1NQSEinUO8bx99EHgVGGxmG8zsGjO7zsyuix7yFLAKqAbuBb4Yz3o6wmWjetMzN4P/mV0ddCkiIjFJieeXu/uMY7zvwJfiWUNHS0sJ8blz+vGDJ5fy5rodjO5TEHRJIiJtCrppqEuacWYf8rNSuXv2yqBLERE5JgVBHGSnp3D1uL48t2QzKzbvDrocEZE2KQji5DNn9SUrLcwv5+iqQEQSm4IgTgqy05hxZh8ee+s9NuzYF3Q5IiJHpSCIo8+d0w8zuHfuqqBLERE5KgVBHJXmZTJ1ZG8ertqglcxEJGEpCOLso6f3Yn9jM6+s1AAzEUlMCoI4G9u/O1lpYf65dEvQpYiIHJGCIM7SU8KcM7CQ55du0fxDIpKQFAQdYNLQEjbVHWCxFrkXkQSkIOgAE4cUYwaz1DwkIglIQdABCrulM7I8n1nLNgddiojIYRQEHeSCoSUs3LCLzXUHgi5FROQDFAQdZNLQYgCeX6bmIRFJLAqCDjK4JIfe+ZnMWqrmIRFJLAqCDmJmXDC0mJeqt2qUsYgkFAVBB5o0tIQDjS28XK1RxiKSOBQEHehD/buTrVHGIpJgFAQdKDLKuIjnl23WKGMRSRgKgg42aWgxm+vqNcpYRBKGgqCDnR8dZfxP3T0kIglCQdDBCrulM6o8X9NNiEjCUBAEYNLQEt7ZqFHGIpIYFAQBuGBoCaBJ6EQkMSgIAjCopBtlBRplLCKJQUEQgMgo4xJeqt7K/gaNMhaRYCkIAjJpaDH1TRplLCLBUxAE5EP9etAtPUVrFIhI4OIeBGY22cyWm1m1md1yhPf7mNkLZrbAzBaa2cXxrikRpKWEOHdQIbOWbqGlRaOMRSQ4cQ0CMwsDdwEXAcOAGWY27JDDvgU87O6jgE8C/xPPmhLJpCElbNldz8KNu4IuRUSSWLyvCM4Eqt19lbs3ADOBqYcc40Bu9Hke8F6ca0oYFwwtITVsPPVOTdCliEgSi3cQ9AbWt3q9Ibqvte8CV5jZBuAp4PojfZGZXWtmVWZWVVtbG49aO1xeVirjBxTy5MIaTUInIoFJhM7iGcD97l4GXAw8YGaH1eXu97h7pbtXFhUVdXiR8XLJiF5s3Lmft9bvDLoUEUlS8Q6CjUB5q9dl0X2tXQM8DODurwIZQGGc60oYFw6LNA89uVDNQyISjHgHwTxgoJn1M7M0Ip3Bjx1yzDpgEoCZDSUSBF2j7ScGeZmpnDuwiKfeqdHdQyISiLgGgbs3AV8GngWWErk7aLGZ3Wpml0YPuxn4vJm9DTwIfMaTrMH8khGlvLfrAAvUPCQiAUiJ9w9w96eIdAK33vedVs+XAGfHu45EdsGwEtLCIZ5cWMOYioKgyxGRJJMIncVJLzcjlXMHqXlIRIKhIEgQU0aUsqnuAG+u2xF0KSKSZBQECWLS0GLSUkI8obuHRKSDKQgSRE5GKhPUPCQiAVAQJJBLRpSyZXc9VWvVPCQiHUdBkEAmDS0hPSXEkwuTZrolEUkACoIE0i09hfMHF/PUok00q3lIRDqIgiDBXDKilNrd9cxbsz3oUkQkScQUBGZ2ipmlR59PMLMbzCw/vqUlp4lDislIDWnuIRHpMLFeEfwFaDazAcA9RCaS+1Pcqkpi2ekpTBxSzNOLatQ8JCIdItYgaInOG/Qx4Ofu/jWgNH5lJbdLTuvF1j0NvL56W9CliEgSiDUIGs1sBnA18ER0X2p8SpLzhxSRmRpW85CIdIhYg+CzwDjgh+6+2sz6AQ/Er6zklpWWwsShxTyzaBNNzS1BlyMiXVxMQeDuS9z9Bnd/0MwKgBx3/3Gca0tqU04rZdveBl5bpbuHRCS+Yr1raLaZ5ZpZd+BN4F4zuy2+pSW3CYOLyclIYea8dUGXIiJdXKxNQ3nuXgd8HPi9u38IuCB+ZUlmWpjpleU8s2gTm+sOBF2OiHRhsQZBipmVAtP5V2exxNlV4ypoduePr60NuhQR6cJiDYJbiSw3udLd55lZf+Dd+JUlABU9sjl/cDF/emMd9U3NQZcjIl1UrJ3Ff3b3Ee7+hejrVe4+Lb6lCUSuCrbuaeDpdzYFXYqIdFGxdhaXmdnfzGxLdPuLmZXFuziBcwcW0a8wm/tfWRN0KSLSRcXaNPRb4DGgV3R7PLpP4iwUMq4aV8Fb63fy9vqdQZcjIl1QrEFQ5O6/dfem6HY/UBTHuqSVaWPKyEoL87tX1wRdioh0QbEGwTYzu8LMwtHtCkAT4XSQ3IxUpo0u44m3a9i6pz7ockSki4k1CP6NyK2jm4Aa4HIi005IB7n6rAoamlt4aN76oEsRkS4m1ruG1rr7pe5e5O7F7n6Zu2vIawcaUJzD2QN68IfX1mr+IRFpVyltvWlmPweOOim+u9/Q7hXJUV09ri/XPjCffyzZzMWnaRZwEWkfbQYBUNUhVUhMJg0toXd+Jr97ZY2CQETaTZtB4O6/i+VLzOzn7n59+5QkRxMOGVeOq+BHTy9jaU0dQ0tzgy5JRLqA9lq8/uyjvWFmk81suZlVm9ktRzlmupktMbPFZqYlMNvwicpy0lNC/P5VzT8kIu2jvYLgiMwsDNwFXAQMA2aY2bBDjhkI/F/gbHc/FfhKPGvq7Aqy07hsZG8eXbCRXfsagy5HRLqAuAYBcCZQHZ2bqAGYCUw95JjPA3e5+w4Ad98S55o6vavOqmB/YzMPV+lWUhE5ee0VBHaU/b2B1v+32hDd19ogYJCZvWxmr5nZ5CP+ALNrzazKzKpqa2tPvuJO7NReeZzZtzv3v7JGt5KKyElrryC44yQ+mwIMBCYAM4isfpZ/6EHufo+7V7p7ZVGRZrf43Dn92LhzP08v0qykInJyjnX7KABm9jiHjyfYReT20l9F5x46ko1AeavXZdF9rW0AXnf3RmC1ma0gEgzzYqktWV0wtIR+hdncM3cVU0aUYna0izIRkbbFekWwCtgD3Bvd6oDdRJp17m3jc/OAgWbWz8zSgE8SmcW0tUeJXA1gZoXR71wVY11JKxQyPndOP97ZuIvXV2uBexE5cbEGwVnu/il3fzy6XQGc4e5fAkYf7UPu3gR8mcjqZkuBh919sZndamaXRg97lsikdkuAF4CvubsmtIvBtNFldM9O4965yk0ROXExNQ0B3cysz8H5hcysD9At+l5DWx9096eApw7Z951Wzx24KbrJcchIDXPl2ArumPUu1Vv2MKC427E/JCJyiFivCG4GXjKzF8xsNvAi8FUzywZiGn0s8XHluArSU0L85iVdFYjIiYnpisDdn4oO/BoS3bXc3Q9En98el8okJoXd0pk2poxH5m/gpgsHU5STHnRJItLJHM/to2OAU4HTgelmdlV8SpLjdc34fjQ0tfDAa5p2QkSOX6yL1z8A/BQYD5wR3SrjWJcch1OKunHB0BIeeHUN+xuagy5HRDqZWDuLK4Fh0Y5dSUDXntuf6b/azCNvbuDKsRVBlyMinUisTUOLgJ7xLEROzhl9Czi9PJ/fvLiK5hbltYjELtYgKASWmNmzZvbYwS2ehcnxMTOuPac/a7bt459LNwddjoh0IrE2DX03nkVI+/jIqSWUFWRy79xVfORUXcCJSGxivX10TrwLkZOXEg5xzfh+fO/xJcxfu4MxFQVBlyQinUCbTUNm9lL0cbeZ1bXadptZXceUKMdjemU5uRkpmnZCRGLWZhC4+/joY46757bactxdC+YmoOz0FD5zVl+eWbyJeWs0GZ2IHFvMA8rMLGxmvcysz8EtnoXJibtuwin0zs/km397h0YtXCMixxDrgLLrgc3Ac8CT0e2JONYlJyErLYXvXXoqKzbv4dcvrg66HBFJcLHeNXQjMFjTQ3ceFwwr4cPDSrhj1gqmjCilvHtW0CWJSIKKtWloPZEVyaQT+e6lpxIy4z8eW4wGhYvI0cR6RbAKmG1mTwL1B3e6+21xqUraRa/8TG66cBA/eHIpzy7ezOThGlsgIoeL9YpgHZH+gTQgp9UmCe4zZ/VlaGku33t8MXvqm4IuR0QSUKwDyr4X70IkPlLCIX74seFMu/sVfvbcCr49ZVjQJYlIgmkzCMzsdnf/ipk9DhzWyOzulx7hY5JgRvcpYMaZffjty6v52KjeDO+dF3RJIpJAjnVF8ED08afxLkTi6xsfGcKzizbxzUcX8dcvnEU4ZEGXJCIJ4lgji+dHH+ccaeuYEqU95GWl8q0pQ3l7/U4efGNd0OWISAKJdUDZQDN7xMyWmNmqg1u8i5P2ddnI3ozr34MfP7OMTbsOHPsDIpIUYr1r6LfA3UATcD7we+AP8SpK4sPM+OHHhtPc4tw4c4EWsBERIPYgyHT3WYC5+1p3/y5wSfzKknjpX9SN708dzuurt3PnrHeDLkdEEkCsQVBvZiHgXTP7spl9DOgWx7okjqaNKePjo3tz5/Pv8srKrUGXIyIBizUIbgSygBuAMcAVwNXxKkri7/tTh9OvMJuvzHyLrXvqj/0BEemyjhkEZhYGPuHue9x9g7t/1t2nuftrHVCfxEl2egq/mDGanfsbufnht2lRf4FI0jrWCmUp7t4MjO+geqQDDeuVy7enDGPOilrufVE3gYkkq2NdEbwRfVxgZo+Z2ZVm9vGDWyw/wMwmm9lyM6s2s1vaOG6ambmZVcZavJy8Kz7Uh4uG9+Qnzy7nzXU7gi5HRAIQax9BBrANmAhMAT4afWxTtFnpLuAiYBgww8wOm+zGzHKI9EO8HmM90k7MjB9NG0HPvAyu/9MCdu1rDLokEelgxwqCYjO7CVgEvBN9XBx9XBTD958JVLv7KndvAGYCU49w3PeBHwMa5RSAvMxUfj5jFJvrDvCNvyzU2gUiSeZYQRAmcptoNyLTTnc7ZDuW3kQWtTloQ3Tf+8xsNFDu7k+29UVmdq2ZVZlZVW1tbQw/Wo7HqD4FfH3yYJ5ZvIk7NL5AJKkca9K5Gne/NV4/PDo24TbgM8c61t3vAe4BqKys1J+scfC58f1ZvmkPt//zXZpbnJsuHISZJqcT6eqOFQQn+3+BjUB5q9dl0X0H5QDDiax+BtATeMzMLnX3qpP82XKcQiHjJ5ePIDVs/Pz5ahqaW7hl8hCFgUgXd6wgmHSS3z8PGGhm/YgEwCeBTx180913AYUHX5vZbOCrCoHghELGf37sNFLCxq/mrKKxyfn2lKEKA5EurM0gcPftJ/Pl7t5kZl8GniXS33Cfuy82s1uBKnd/7GS+X+IjFDK+P3U4qeEQ9728msbmFr536amEtIaBSJcU6+L1J8zdnwKeOmTfd45y7IR41yOxMTO+M2UYaSkhfjVnFU0tLfzwstMUBiJdUNyDQDovM+OWyUNIC4cifQZNzn9fPkKrm4l0MQoCaZOZcfOHB5MaDnHbcytISwnxXx8/LeiyRKQdKQgkJjdMGsj+xmbunr2SMRUFXD6mLOiSRKSdxDrFhAhf/fBgxvXvwbcefYflm3YHXY6ItBMFgcQsHDLumDGSbumpfPGP89lb3xR0SSLSDhQEclyKczK4c8ZIVm/dy7//7R3NSyTSBSgI5LiddUohN104iL+/9R4PvrH+2B8QkYSmIJAT8sUJAzh3UBHffXwxizbuCrocETkJCgI5IaGQcfsnRtI9K40v/elN6g5oHQORzkpBICese3Yav/jUKDbs2M/X/6x1DEQ6KwWBnJTKvt35RnQdg9+8tDrockTkBCgI5KR9/pz+XDishB88uZTv/H0RBxqbgy5JRI6DgkBOmpnxi0+N4prx/fj9q2uZ+ouXNeBMpBNREEi7SE8J8+0pw7j/s2ewbW89l/7iJR54dY36DUQ6AQWBtKsJg4t5+sZzGdu/B9/++2I+//v5bN/bEHRZItIGBYG0u6KcdH77mTP49pRhzF1Ry0V3zOXl6q1BlyUiR6HZRyUuQiHjmvH9+FC/7twwcwGf/vXrDCrpxuThpVw0vCdDeuZo+UuRBGGdsQ23srLSq6q0rHFnsa+hiYfmreeZRZuYt2Y7LQ59e2TxkeE9uWh4KaeX5SkURDqAmc1398rD9isIpCNt3VPPPxZv5pnFm3ileitNLU6vvAy+PHEgnzyjXEthisSRgkASzq59jcxatpmZb6znjTXb+VC/7vxo2gj6FWYHXZpIl3S0IFBnsQQmLyuVj48u46H/PZYfTzuNJTV1TL59LnfPXkljc0vQ5YkkDQWBBM7M+MQZfZh103lMHFLMj59ZxmV3vaxZTUU6iIJAEkZxbgZ3XzGGX14xhi2765l618v819NL2d+gKStE4klBIAln8vCe/POm8/hfY8r41ZxVnP/T2Tzw2loamtRcJBIPCgJJSHmZqfxo2ggeunYsZQWZfPvRRZz/09nMfGOd+g9E2pnuGpKE5+7MfXcrt/1jOW9v2EVFjyxumDiQy0b1JqzbTUVipruGpNMyM84bVMSjXzqbX19VSXZaCjf/+W0u/NkcnnqnRhPbiZwkBYF0GmbGBcNKeOL68fzyitGkhkJ88Y9vcu0D89lSdyDo8kQ6rbgHgZlNNrPlZlZtZrcc4f2bzGyJmS00s1lmVhHvmqRzC4WMycNLeerGc/jmxUOZu6KWC382l7/M36CrA5ETENcgMLMwcBdwETAMmGFmww45bAFQ6e4jgEeA/45nTdJ1hEPG58/tz9M3nsOgkm7c/Oe3+bf751Gza3/QpYl0KvG+IjgTqHb3Ve7eAMwEprY+wN1fcPd90ZevAWVxrkm6mP5F3Xjo2nH8x0eH8dqq7Xz4trk8NG+drg5EYhTvIOgNrG/1ekN039FcAzx9pDfM7FozqzKzqtra2nYsUbqCUMj47Nn9eOYr53Bq71y+8Zd3uOq+N1i2qS7o0kQSXsJ0FpvZFUAl8JMjve/u97h7pbtXFhUVdWxx0mlU9MjmT58by/cvG85b63dy0R0vcuPMBazZujfo0kQSVrwXptkIlLd6XRbd9wFmdgHwTeA8d6+Pc03SxYVCxpVjK/joiFLumbuK3768hicW1jC9sozrJw6kV35m0CWKJJS4DigzsxRgBTCJSADMAz7l7otbHTOKSCfxZHd/N5bv1YAyOR5bdh/gf15YyZ9eXwfAp8f24UvnD6CwW3rAlYl0rMDWIzCzi4HbgTBwn7v/0MxuBarc/TEz+ydwGlAT/cg6d7+0re9UEMiJ2LBjH3fOepdH5m8gIzXM9MpyrhxXwSlF3YIuTaRDaGEakaiVtXu46/lqHl/4Ho3NzjkDC7l6XF/OH1KsKSukS1MQiByidnc9D81bxx9eW8emugOUFWRy5dgKpleWU5CdFnR5Iu1OQSByFI3NLTy3ZDO/e2UNr6/eTnpKiPMHF3P2gB6cNaCQ/oXZmOlKQTq/owVBvO8aEkl4qeEQF59WysWnlbJsUx1/eG0tzy/dwjOLNwHQMzeDs06JhMJZp/TQXUfS5eiKQOQI3J212/bxysptvLxyK6+u3Mb2vQ0AVPTIYkxFAZUV3ansW8CAom6E1LcgnYCahkROQkuLs3zzbl6u3sobq7czf+0OtkWDIS8zldF98qns250xFQWMKMsjK00X25J4FAQi7cjdWbNtH1VrIqFQtXYH1Vv2AJHJ8AaX5DCqTz4jy/MZ1aeA/oXZumqQwCkIROJsx94G3ly3g7fW72TBup28vX4nu+ubAMjNSGFknwIuGt6TKSNKyclIDbhaSUYKApEO1tLirKzdw4J1O1mwfgevr9rOqq17yUgNcfHwUi6vLGNsvx66UpAOoyAQCZi789b6nfx5/gYef+s9dtc3Ud49k8tHlzNtTG/KCrKCLlG6OAWBSALZ39DMs4s38ef563m5ehtmUJKTQVZamKz0MFmpKZHHtDBZaSn0zs9k8vCeDOmZozENcsIUBCIJasOOfTy6YCPrt+9nb0MT+xuaWz02s6++iU11B2hx6F+Y/f6Yh6GlCgU5PgoCkU6sdnc9zy7exNOLanh15TZaHPoVZnPR8J5cNLyUYb1yNU+SHJOCQKSL2LannmcXb+apd2p4ddU2mlucnPQURlUUUBndRvbJ11gGOYyCQKQL2r63gTkrtlC1Zgfz1+5g+ebduEfGMpzaK5fRfQooykknMzXS35AZ7XM4+LwsP5OinHQ1MSUJBYFIEti1v5E31+1g/podzFuznbc37ORAY0ubn+mRncawXrkMLc1laGkOQ0tzOaWoG6nhhFnJVtqJJp0TSQJ5mamcP7iY8wcXA5FbVhuaW9jf0My+6BZ53sS+hmbWbNvL0po6ltTUcf8ra2hoioRGWjhE/6Js+vbIpm9hNn17ZEUfsynOSdfYhy5GQSDShZkZ6Slh0lPC5B9jmEJTcwurtu5lyXt1LK2po3rLHlZs2c2sZZtpbP5Xy0FGaoi+PbLp0z0SDn26Z9G3RzYVPbLolZ+pTutOSEEgIgCkhEMMKslhUEkOl43q/f7+5hbnvZ37WbNtL2u27WPt1r2s2baX1Vv3MntF7ftXEQCpYaN3fibZ6SmkpYRIC4dITw1HHlNCpKWEyMtMpTg3neKcDIpz0t9/XpCVqr6KgCgIRKRN4ZBR3j2L8u5ZnDPwg++1tDibdx9gzdZ9rN22l7Xb97Fu+z72NzTT0NRCQ1MLu/Y30tDUQn1TM/WNLezc18DehubDfk5q2OjTPYvTy/MZVZ7PyPIChpTmqK+iAygIROSEhUJGaV4mpXmZjDulR8yf21vfxJbd9WypOxB53F3Plt0HWLllD3NX1PLXNzcCkJ4SYnjvPEaW5zO4Zw4QuUJpam6hsdlpbnEaW1pobHL21Deya38jdfubIo8HIq93H2iiokcW5w0qYsLgIkaWF6j56hC6a0hEEoq7s2HHft5av/P9bdHGXdQ3tX33U2ZqmNzMFPIyU8nNSI08ZqbSLT2FpTV1vLluBy0e6VA/Z2AhEwYXc+6gQopzMo6rvoNrXT+3dAtj+hQw/YwyhvTMPZlfucPo9lER6bQam1uo2XkAs8jSoilhIyVkpIRDkcfo87bs2tfIi9W1zFley5wVtWzZXQ/Aqb1yOW9QEecNKmJ0RcERm6LcnXlrdvDAa2t5ZlENjc3Oqb1yWbF5N43NzulleUw/o5yPnt6L3ASeYlxBICIS5e4sqalj9vJa5q6oZf7aHTS1ON3SUzh7QA/OGxS5WsjPSuPRBRv5w2trWbZpNzkZKVw+poxPf6iCAcXd2L63gb8t2MjD89azfPPu96cYn35GOcN755EaNtLCoYTpBFcQiIgcRd2BRl6p3sacFZFg2LhzPxAZT9HQ3MKw0lyuGlfBpSN7HXHqDndn4YZdPFy1nseiU4y3lhaO3DGVGjbSUkKEzWhqifRxNLvT3Ozvv85MCzN+QCEThxQzYXARPbqlt9vvqSAQEYmBe2RBodnLa9mwYz+XjuzFqPL8mP+q39/QzHNLN7Np134am5366N1TDU0tNDZHHpvdSQ0bIYs0a4WizVvhUIhte+qZvaKW2t31mMGo8nwmDilm4pCSk55xVkEgItJJtLQ4i9+rY9ayzbywbAtvb9gFQGleBv/18dOYEB05frw0xYSISCcRChmnleVxWlkeX7lgEFt2H2D2slqeX7aFXvmZ7f7zFAQiIgmuOCeD6WeUM/2M8rh8f9yH7JnZZCDH0aYAAAXHSURBVDNbbmbVZnbLEd5PN7OHou+/bmZ9412TiIj8S1yDwMzCwF3ARcAwYIaZDTvksGuAHe4+APgZ8ON41iQiIh8U7yuCM4Fqd1/l7g3ATGDqIcdMBX4Xff4IMMkS5aZbEZEkEO8g6A2sb/V6Q3TfEY9x9yZgF3DYpCVmdq2ZVZlZVW1tbZzKFRFJPp1mWj93v8fdK929sqioKOhyRES6jHgHwUagdTd3WXTfEY8xsxQgD9gW57pERCQq3kEwDxhoZv3MLA34JPDYIcc8BlwdfX458Lx3xlFuIiKdVFzHEbh7k5l9GXgWCAP3uftiM7sVqHL3x4DfAA+YWTWwnUhYiIhIB+mUU0yYWS2w9gQ/XghsbcdyuiKdo7bp/BybzlHbgjo/Fe5+WCdrpwyCk2FmVUeaa0P+ReeobTo/x6Zz1LZEOz+d5q4hERGJDwWBiEiSS8YguCfoAjoBnaO26fwcm85R2xLq/CRdH4GIiHxQMl4RiIhIKwoCEZEkl1RBcKy1EZKNmd1nZlvMbFGrfd3N7Dkzezf6WBBkjUEzs3Ize8HMlpjZYjO7Mbpf5wkwswwze8PM3o6en+9F9/eLri9SHV1vJC3oWoNkZmEzW2BmT0RfJ9T5SZogiHFthGRzPzD5kH23ALPcfSAwK/o6mTUBN7v7MGAs8KXofzc6TxH1wER3Px0YCUw2s7FE1hX5WXSdkR1E1h1JZjcCS1u9TqjzkzRBQGxrIyQVd59LZFqP1lqvD/E74LIOLSrBuHuNu78Zfb6byD/m3ug8AeARe6IvU6ObAxOJrC8CSXx+AMysDLgE+HX0tZFg5yeZgiCWtREESty9Jvp8E1ASZDGJJLqM6ijgdXSe3hdt9ngL2AI8B6wEdkbXFwH9W7sd+DrQEn3dgwQ7P8kUBHKcorPA6v5iwMy6AX8BvuLuda3fS/bz5O7N7j6SyDTzZwJDAi4pYZjZFGCLu88Pupa2xHX20QQTy9oIApvNrNTda8yslMhfeUnNzFKJhMAf3f2v0d06T4dw951m9gIwDsg3s5ToX73J/G/tbOBSM7sYyABygTtIsPOTTFcEsayNIB9cH+Jq4O8B1hK4aHvub4Cl7n5bq7d0ngAzKzKz/OjzTOBCIv0oLxBZXwSS+Py4+/919zJ370vk/znPu/unSbDzk1Qji6OpfDv/WhvhhwGXFCgzexCYQGRK3M3AfwCPAg8DfYhM9T3d3Q/tUE4aZjYeeBF4h3+18f47kX6CpD9PZjaCSGdnmMgflg+7+61m1p/IDRndgQXAFe5eH1ylwTOzCcBX3X1Kop2fpAoCERE5XDI1DYmIyBEoCEREkpyCQEQkySkIRESSnIJARCTJKQhEWjGzZjN7q9XWbpPJmVnf1jO9iiSKZBpZLBKL/dHpEkSShq4IRGJgZmvM7L/N7J3o/PsDovv7mtnzZrbQzGaZWZ/o/hIz+1t0nv63zeys6FeFzeze6Nz9/4iOxsXMboiuebDQzGYG9GtKklIQiHxQ5iFNQ59o9d4udz8N+AWREeoAPwd+5+4jgD8Cd0b33wnMic7TPxpYHN0/ELjL3U8FdgLTovtvAUZFv+e6eP1yIkeikcUirZjZHnfvdoT9a4gswLIqOgndJnfvYWZbgVJ3b4zur3H3QjOrBcpaTxsQncb6uehiNpjZN4BUd/+BmT0D7CEyxcejreb4F4k7XRGIxM6P8vx4tJ5Pppl/9dNdQmQFvdHAPDNT/510GAWBSOw+0erx1ejzV4jMKgnwaSIT1EFk+covwPsLt+Qd7UvNLASUu/sLwDeAPOCwqxKReNFfHSIflBldbeugZ9z94C2kBWa2kMhf9TOi+64HfmtmXwNqgc9G998I3GNm1xD5y/8LQA1HFgb+EA0LA+50953t9huJHIP6CERiEO0jqHT3rUHXItLe1DQkIpLkdEUgIpLkdEUgIpLkFAQiIklOQSAikuQUBCIiSU5BICKS5P4/r6GNciOYlDIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pex6d6CO5ZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 464,
      "outputs": []
    }
  ]
}