{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "focus_random_classify_random_train_both_k_1_adam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjG64ra4aFu"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-7SARDZErK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acRFqJNrZErV",
        "outputId": "3954f88e-63de-41ec-be30-d3078b8a663b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3BOnEFUZOLx"
      },
      "source": [
        "k = 1"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_JUhwCeZErk"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SadRzWBBZEsP"
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w"
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM"
      },
      "source": [
        "def init_weights(m,k=1):\n",
        "  if type(m) == nn.Linear:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)\n",
        "  if type(m) == nn.Conv2d:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhjiW2hKZTCY",
        "outputId": "b76e5a0d-692e-43df-f9a4-c7184cb066fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "focus_net.apply(init_weights)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.1050,  0.1214,  0.0588],\n",
            "          [-0.1193,  0.0163,  0.0455],\n",
            "          [ 0.0215,  0.0241,  0.1083]],\n",
            "\n",
            "         [[ 0.0433,  0.0966, -0.0650],\n",
            "          [-0.1277,  0.1072, -0.0358],\n",
            "          [-0.0312,  0.0118, -0.0548]],\n",
            "\n",
            "         [[-0.0689, -0.0810,  0.0414],\n",
            "          [ 0.0412,  0.0663,  0.0657],\n",
            "          [-0.1363,  0.1377, -0.0697]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243,  0.1074,  0.0612],\n",
            "          [-0.0413,  0.1226,  0.0983],\n",
            "          [ 0.0922,  0.0167,  0.1221]],\n",
            "\n",
            "         [[ 0.0511,  0.1312, -0.0172],\n",
            "          [-0.0914, -0.0009, -0.0219],\n",
            "          [-0.0516, -0.0447,  0.1076]],\n",
            "\n",
            "         [[-0.1184,  0.0627,  0.1237],\n",
            "          [ 0.1283, -0.0161, -0.0057],\n",
            "          [ 0.0065, -0.0395,  0.0546]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024, -0.1245,  0.0225],\n",
            "          [ 0.1106,  0.0834, -0.0226],\n",
            "          [-0.1247, -0.0061, -0.1214]],\n",
            "\n",
            "         [[ 0.0866,  0.1358,  0.0561],\n",
            "          [-0.0469,  0.0484,  0.1072],\n",
            "          [-0.1322, -0.1119,  0.1240]],\n",
            "\n",
            "         [[ 0.0972,  0.0309, -0.0326],\n",
            "          [ 0.0429, -0.0177,  0.1361],\n",
            "          [-0.0201,  0.0622,  0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0303,  0.0592, -0.0878],\n",
            "          [ 0.0015, -0.0844,  0.0005],\n",
            "          [-0.0110, -0.1320,  0.0073]],\n",
            "\n",
            "         [[-0.0690, -0.0391, -0.1286],\n",
            "          [-0.1111, -0.0964,  0.0491],\n",
            "          [ 0.0080,  0.0899,  0.0564]],\n",
            "\n",
            "         [[ 0.1066, -0.0032,  0.1346],\n",
            "          [-0.0996, -0.0303,  0.0290],\n",
            "          [-0.1192, -0.0811,  0.0647]]],\n",
            "\n",
            "\n",
            "        [[[-0.0746,  0.0155,  0.0927],\n",
            "          [ 0.1275, -0.0648, -0.1212],\n",
            "          [-0.0438,  0.0703,  0.0093]],\n",
            "\n",
            "         [[ 0.0649, -0.1058, -0.1375],\n",
            "          [-0.0805,  0.0599, -0.0410],\n",
            "          [ 0.1259,  0.0705,  0.1220]],\n",
            "\n",
            "         [[ 0.0110,  0.0289,  0.0606],\n",
            "          [ 0.0577,  0.0234, -0.0851],\n",
            "          [ 0.0604, -0.0535,  0.0725]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0470, -0.0210,  0.1061],\n",
            "          [ 0.1273,  0.1034, -0.0953],\n",
            "          [ 0.1343, -0.0333,  0.0573]],\n",
            "\n",
            "         [[ 0.0107, -0.1018, -0.0632],\n",
            "          [-0.1064,  0.0825,  0.0589],\n",
            "          [ 0.1306, -0.1160, -0.0009]],\n",
            "\n",
            "         [[ 0.1033,  0.1369,  0.1329],\n",
            "          [-0.0583, -0.1006, -0.0515],\n",
            "          [ 0.0956, -0.0466,  0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0630, -0.1007, -0.0224],\n",
            "          [ 0.0597,  0.0746, -0.0809],\n",
            "          [ 0.1096, -0.0081,  0.0485]],\n",
            "\n",
            "         [[-0.0192,  0.0433, -0.0180],\n",
            "          [ 0.0555, -0.0442, -0.1342],\n",
            "          [ 0.0390, -0.0937, -0.1160]],\n",
            "\n",
            "         [[ 0.0635, -0.0448,  0.0776],\n",
            "          [-0.0472,  0.1219, -0.0217],\n",
            "          [ 0.0235,  0.1338, -0.1280]]],\n",
            "\n",
            "\n",
            "        [[[-0.1138,  0.0961,  0.0734],\n",
            "          [ 0.1227,  0.0692,  0.0687],\n",
            "          [ 0.0951, -0.0988, -0.1304]],\n",
            "\n",
            "         [[ 0.0414,  0.1211,  0.1038],\n",
            "          [ 0.0472,  0.0314,  0.1127],\n",
            "          [ 0.1249,  0.0592,  0.1128]],\n",
            "\n",
            "         [[-0.0023, -0.0187, -0.0323],\n",
            "          [ 0.0005, -0.0440,  0.1075],\n",
            "          [-0.0339, -0.0237,  0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1025, -0.0733,  0.0263],\n",
            "          [ 0.0634, -0.1255,  0.0807],\n",
            "          [-0.0945, -0.0226, -0.1057]],\n",
            "\n",
            "         [[-0.0354,  0.0731, -0.0700],\n",
            "          [-0.0865, -0.1230, -0.1273],\n",
            "          [-0.1034, -0.0091,  0.0499]],\n",
            "\n",
            "         [[-0.0941, -0.1289, -0.0261],\n",
            "          [-0.0112,  0.0301,  0.1376],\n",
            "          [ 0.0553, -0.1234, -0.0216]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1093, -0.0918,  0.0554],\n",
            "          [-0.0098,  0.0586, -0.0456],\n",
            "          [ 0.0957, -0.0791,  0.0954]],\n",
            "\n",
            "         [[ 0.0342, -0.0692, -0.0776],\n",
            "          [ 0.0679, -0.1333, -0.0824],\n",
            "          [ 0.0169,  0.0182,  0.0261]],\n",
            "\n",
            "         [[-0.0804, -0.0958,  0.0014],\n",
            "          [-0.0349,  0.1200, -0.1340],\n",
            "          [-0.0353, -0.0973,  0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0191,  0.0477, -0.0084],\n",
            "          [ 0.0818,  0.1183, -0.0276],\n",
            "          [-0.0286,  0.0132, -0.0614]],\n",
            "\n",
            "         [[ 0.0330,  0.0598,  0.1111],\n",
            "          [ 0.1165, -0.0417,  0.0480],\n",
            "          [-0.0908,  0.0554,  0.1349]],\n",
            "\n",
            "         [[-0.0483,  0.0873, -0.1318],\n",
            "          [ 0.0756,  0.0214,  0.1137],\n",
            "          [ 0.0039,  0.1094,  0.0119]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0383,  0.1257],\n",
            "          [-0.0961,  0.1246,  0.0706],\n",
            "          [ 0.0321,  0.0388, -0.0594]],\n",
            "\n",
            "         [[-0.1108,  0.0191,  0.1080],\n",
            "          [ 0.1116,  0.0277, -0.0775],\n",
            "          [-0.0249,  0.1057, -0.0952]],\n",
            "\n",
            "         [[ 0.1207, -0.1373, -0.0730],\n",
            "          [ 0.1134,  0.0365, -0.0702],\n",
            "          [-0.0340, -0.1309, -0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1354,  0.1205, -0.1124],\n",
            "          [-0.0645, -0.0902,  0.1234],\n",
            "          [-0.0884,  0.0080,  0.0424]],\n",
            "\n",
            "         [[-0.0670,  0.0203, -0.0854],\n",
            "          [ 0.0503, -0.0132,  0.1265],\n",
            "          [-0.0972,  0.0498,  0.1150]],\n",
            "\n",
            "         [[-0.1209,  0.1248,  0.0428],\n",
            "          [-0.0510,  0.0816,  0.0532],\n",
            "          [-0.0520, -0.0577,  0.1087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1126,  0.0255, -0.1296],\n",
            "          [ 0.0378,  0.0466, -0.0572],\n",
            "          [ 0.0232, -0.0410,  0.1117]],\n",
            "\n",
            "         [[ 0.0124, -0.1374,  0.1032],\n",
            "          [-0.0838, -0.1037,  0.0993],\n",
            "          [-0.0971,  0.0112,  0.1063]],\n",
            "\n",
            "         [[-0.1211,  0.1292, -0.0956],\n",
            "          [ 0.0564, -0.1087,  0.0525],\n",
            "          [ 0.1237,  0.0084,  0.0690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0790,  0.0170,  0.1157],\n",
            "          [-0.1304, -0.1316,  0.1206],\n",
            "          [ 0.1354, -0.1357,  0.0203]],\n",
            "\n",
            "         [[ 0.0671,  0.0099,  0.0534],\n",
            "          [ 0.0526, -0.0304,  0.0219],\n",
            "          [-0.0585,  0.0089, -0.0224]],\n",
            "\n",
            "         [[-0.0058, -0.0208,  0.0841],\n",
            "          [ 0.0215, -0.0465, -0.0621],\n",
            "          [-0.1283,  0.1176, -0.0754]]],\n",
            "\n",
            "\n",
            "        [[[-0.0220,  0.0226,  0.0721],\n",
            "          [-0.0388, -0.0747,  0.0138],\n",
            "          [-0.0008,  0.1340,  0.0115]],\n",
            "\n",
            "         [[-0.1081,  0.1344,  0.0052],\n",
            "          [ 0.1110, -0.1306, -0.1088],\n",
            "          [-0.0309,  0.0023,  0.0570]],\n",
            "\n",
            "         [[-0.0560, -0.1184,  0.0920],\n",
            "          [ 0.0252, -0.0433,  0.0878],\n",
            "          [ 0.0069, -0.1082,  0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0770,  0.0946, -0.0880],\n",
            "          [-0.0460,  0.1173,  0.0226],\n",
            "          [ 0.0407,  0.0980, -0.0654]],\n",
            "\n",
            "         [[-0.0717, -0.0724,  0.0412],\n",
            "          [-0.0562,  0.0682, -0.0425],\n",
            "          [ 0.0033, -0.1061,  0.0760]],\n",
            "\n",
            "         [[-0.1020, -0.0190, -0.0219],\n",
            "          [ 0.0550, -0.0851,  0.1220],\n",
            "          [ 0.0055,  0.0560,  0.1111]]],\n",
            "\n",
            "\n",
            "        [[[-0.0951, -0.0374, -0.1315],\n",
            "          [-0.1089,  0.0229,  0.1351],\n",
            "          [ 0.0422,  0.1377, -0.1347]],\n",
            "\n",
            "         [[-0.0214, -0.0826, -0.1109],\n",
            "          [-0.0246, -0.0491,  0.0648],\n",
            "          [-0.0400,  0.1292, -0.0168]],\n",
            "\n",
            "         [[ 0.0885, -0.0273, -0.0782],\n",
            "          [-0.0131, -0.0099,  0.0111],\n",
            "          [ 0.0437, -0.1332, -0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0438,  0.1056],\n",
            "          [ 0.0402, -0.1309,  0.1371],\n",
            "          [ 0.1017,  0.0284, -0.0202]],\n",
            "\n",
            "         [[ 0.1244, -0.1375,  0.0282],\n",
            "          [ 0.1086,  0.1217,  0.0943],\n",
            "          [-0.0004,  0.0387, -0.0833]],\n",
            "\n",
            "         [[-0.0171, -0.0782, -0.0358],\n",
            "          [ 0.0075, -0.1302,  0.0208],\n",
            "          [-0.0873, -0.0959,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102, -0.1067, -0.1025],\n",
            "          [ 0.1116,  0.0266, -0.1028],\n",
            "          [-0.0635, -0.0708, -0.0697]],\n",
            "\n",
            "         [[ 0.0030,  0.0739, -0.0855],\n",
            "          [-0.0650,  0.1201, -0.0131],\n",
            "          [-0.0618, -0.0680, -0.0356]],\n",
            "\n",
            "         [[-0.0797, -0.1149,  0.0272],\n",
            "          [ 0.0520,  0.0685,  0.0054],\n",
            "          [-0.0097, -0.0302,  0.1144]]],\n",
            "\n",
            "\n",
            "        [[[-0.1193,  0.0028,  0.0314],\n",
            "          [-0.1280,  0.1190, -0.1014],\n",
            "          [-0.1231,  0.0703,  0.0279]],\n",
            "\n",
            "         [[ 0.0904, -0.1331, -0.0808],\n",
            "          [ 0.0591, -0.0654,  0.1076],\n",
            "          [-0.0453, -0.0707,  0.1021]],\n",
            "\n",
            "         [[-0.0887, -0.0770, -0.0189],\n",
            "          [ 0.0863, -0.0374, -0.0307],\n",
            "          [-0.1057,  0.0172, -0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0808, -0.1211, -0.0311],\n",
            "          [-0.1210,  0.1079,  0.1335],\n",
            "          [ 0.0941, -0.0931,  0.1172]],\n",
            "\n",
            "         [[ 0.0292,  0.0663,  0.1289],\n",
            "          [ 0.0864, -0.0247, -0.1160],\n",
            "          [-0.0783,  0.0210,  0.0308]],\n",
            "\n",
            "         [[-0.1219,  0.0811, -0.1078],\n",
            "          [ 0.1174,  0.0290, -0.0027],\n",
            "          [-0.0488, -0.0225,  0.0816]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1049,  0.0749, -0.1125],\n",
            "          [ 0.1378, -0.0721,  0.1281],\n",
            "          [-0.0777,  0.1362,  0.1164]],\n",
            "\n",
            "         [[ 0.0799,  0.0223,  0.1133],\n",
            "          [-0.0881,  0.0412,  0.0543],\n",
            "          [-0.0111, -0.0803, -0.0113]],\n",
            "\n",
            "         [[-0.0609,  0.0141, -0.0534],\n",
            "          [-0.1238,  0.0143,  0.0859],\n",
            "          [-0.0301, -0.0316,  0.0964]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0993,  0.1189, -0.0055],\n",
            "          [ 0.0014, -0.0976,  0.0031],\n",
            "          [ 0.0043,  0.1026, -0.1371]],\n",
            "\n",
            "         [[-0.0154, -0.1327, -0.1321],\n",
            "          [ 0.0735,  0.0689,  0.1124],\n",
            "          [ 0.0417,  0.0066, -0.0752]],\n",
            "\n",
            "         [[-0.1169, -0.0826, -0.0636],\n",
            "          [-0.0801,  0.0542,  0.1322],\n",
            "          [ 0.1274, -0.0805, -0.1321]]],\n",
            "\n",
            "\n",
            "        [[[-0.0321, -0.1013, -0.1340],\n",
            "          [ 0.0549,  0.1229,  0.0187],\n",
            "          [ 0.0635,  0.0855, -0.0793]],\n",
            "\n",
            "         [[ 0.0163,  0.0576, -0.0725],\n",
            "          [ 0.1349,  0.1338,  0.0424],\n",
            "          [-0.0565, -0.0271, -0.0065]],\n",
            "\n",
            "         [[ 0.1057, -0.0662,  0.0843],\n",
            "          [ 0.1218, -0.0181, -0.0132],\n",
            "          [-0.0224,  0.0711,  0.1373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458, -0.0240, -0.0642],\n",
            "          [-0.1284,  0.1301, -0.0221],\n",
            "          [ 0.0513,  0.0357,  0.0685]],\n",
            "\n",
            "         [[ 0.0447,  0.0482,  0.0202],\n",
            "          [ 0.1029, -0.0415,  0.0292],\n",
            "          [ 0.0927, -0.0914,  0.1029]],\n",
            "\n",
            "         [[ 0.0587, -0.0453, -0.0390],\n",
            "          [ 0.0402, -0.1310,  0.1291],\n",
            "          [-0.1203, -0.0834,  0.0932]]],\n",
            "\n",
            "\n",
            "        [[[-0.1195, -0.0345, -0.0670],\n",
            "          [ 0.0642, -0.0037, -0.0502],\n",
            "          [-0.0359,  0.0489,  0.0630]],\n",
            "\n",
            "         [[-0.0950,  0.1065,  0.0999],\n",
            "          [ 0.0028, -0.0237,  0.0881],\n",
            "          [ 0.1140, -0.1286,  0.0987]],\n",
            "\n",
            "         [[-0.0686, -0.0377,  0.0912],\n",
            "          [ 0.1366, -0.0975, -0.0507],\n",
            "          [-0.0163,  0.0094,  0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1173,  0.1334, -0.0506],\n",
            "          [-0.1283, -0.1268,  0.0220],\n",
            "          [ 0.0777, -0.0241, -0.0772]],\n",
            "\n",
            "         [[-0.0849, -0.0376,  0.0414],\n",
            "          [ 0.1200,  0.0639, -0.0089],\n",
            "          [-0.0256,  0.1346,  0.0802]],\n",
            "\n",
            "         [[-0.1187,  0.1279,  0.0268],\n",
            "          [ 0.0801, -0.0363, -0.1048],\n",
            "          [-0.0573, -0.0708,  0.0379]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0796, -0.0600,  0.0439],\n",
            "          [ 0.0550, -0.1245, -0.0892],\n",
            "          [-0.0474, -0.1210,  0.1336]],\n",
            "\n",
            "         [[ 0.0692,  0.0903, -0.0840],\n",
            "          [ 0.1243,  0.1076,  0.1367],\n",
            "          [-0.0511, -0.0784, -0.0105]],\n",
            "\n",
            "         [[ 0.0425, -0.0139,  0.1241],\n",
            "          [-0.0850,  0.0267,  0.0743],\n",
            "          [-0.1332, -0.0337, -0.0154]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0971, -0.0718, -0.0420],\n",
            "          [-0.1062,  0.1183, -0.1028],\n",
            "          [-0.0097,  0.0813, -0.0535]],\n",
            "\n",
            "         [[ 0.1279,  0.1208,  0.0060],\n",
            "          [-0.1352, -0.0636,  0.0192],\n",
            "          [-0.1363, -0.0039,  0.0833]],\n",
            "\n",
            "         [[-0.0234,  0.0114, -0.0031],\n",
            "          [ 0.1271,  0.0990, -0.0219],\n",
            "          [ 0.0717, -0.1184, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[-0.0752,  0.0160,  0.1106],\n",
            "          [-0.1226,  0.0359, -0.0675],\n",
            "          [-0.0148,  0.1298,  0.0941]],\n",
            "\n",
            "         [[ 0.0124, -0.0077, -0.1213],\n",
            "          [ 0.0115, -0.0320,  0.1001],\n",
            "          [ 0.0701,  0.0954, -0.0785]],\n",
            "\n",
            "         [[-0.1014,  0.0947,  0.0171],\n",
            "          [ 0.1316, -0.0220, -0.0368],\n",
            "          [ 0.0536,  0.0620, -0.0759]]],\n",
            "\n",
            "\n",
            "        [[[-0.0462,  0.0865, -0.0109],\n",
            "          [-0.0799, -0.0852,  0.0181],\n",
            "          [-0.0158,  0.0746,  0.1030]],\n",
            "\n",
            "         [[-0.0636,  0.0897, -0.0426],\n",
            "          [ 0.0369, -0.0393, -0.0056],\n",
            "          [-0.0294,  0.1296, -0.1235]],\n",
            "\n",
            "         [[ 0.0002,  0.0252,  0.1291],\n",
            "          [-0.0383,  0.0881,  0.0236],\n",
            "          [-0.0026, -0.0574, -0.0595]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.1050,  0.1214,  0.0588],\n",
            "          [-0.1193,  0.0163,  0.0455],\n",
            "          [ 0.0215,  0.0241,  0.1083]],\n",
            "\n",
            "         [[ 0.0433,  0.0966, -0.0650],\n",
            "          [-0.1277,  0.1072, -0.0358],\n",
            "          [-0.0312,  0.0118, -0.0548]],\n",
            "\n",
            "         [[-0.0689, -0.0810,  0.0414],\n",
            "          [ 0.0412,  0.0663,  0.0657],\n",
            "          [-0.1363,  0.1377, -0.0697]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243,  0.1074,  0.0612],\n",
            "          [-0.0413,  0.1226,  0.0983],\n",
            "          [ 0.0922,  0.0167,  0.1221]],\n",
            "\n",
            "         [[ 0.0511,  0.1312, -0.0172],\n",
            "          [-0.0914, -0.0009, -0.0219],\n",
            "          [-0.0516, -0.0447,  0.1076]],\n",
            "\n",
            "         [[-0.1184,  0.0627,  0.1237],\n",
            "          [ 0.1283, -0.0161, -0.0057],\n",
            "          [ 0.0065, -0.0395,  0.0546]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024, -0.1245,  0.0225],\n",
            "          [ 0.1106,  0.0834, -0.0226],\n",
            "          [-0.1247, -0.0061, -0.1214]],\n",
            "\n",
            "         [[ 0.0866,  0.1358,  0.0561],\n",
            "          [-0.0469,  0.0484,  0.1072],\n",
            "          [-0.1322, -0.1119,  0.1240]],\n",
            "\n",
            "         [[ 0.0972,  0.0309, -0.0326],\n",
            "          [ 0.0429, -0.0177,  0.1361],\n",
            "          [-0.0201,  0.0622,  0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0303,  0.0592, -0.0878],\n",
            "          [ 0.0015, -0.0844,  0.0005],\n",
            "          [-0.0110, -0.1320,  0.0073]],\n",
            "\n",
            "         [[-0.0690, -0.0391, -0.1286],\n",
            "          [-0.1111, -0.0964,  0.0491],\n",
            "          [ 0.0080,  0.0899,  0.0564]],\n",
            "\n",
            "         [[ 0.1066, -0.0032,  0.1346],\n",
            "          [-0.0996, -0.0303,  0.0290],\n",
            "          [-0.1192, -0.0811,  0.0647]]],\n",
            "\n",
            "\n",
            "        [[[-0.0746,  0.0155,  0.0927],\n",
            "          [ 0.1275, -0.0648, -0.1212],\n",
            "          [-0.0438,  0.0703,  0.0093]],\n",
            "\n",
            "         [[ 0.0649, -0.1058, -0.1375],\n",
            "          [-0.0805,  0.0599, -0.0410],\n",
            "          [ 0.1259,  0.0705,  0.1220]],\n",
            "\n",
            "         [[ 0.0110,  0.0289,  0.0606],\n",
            "          [ 0.0577,  0.0234, -0.0851],\n",
            "          [ 0.0604, -0.0535,  0.0725]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0470, -0.0210,  0.1061],\n",
            "          [ 0.1273,  0.1034, -0.0953],\n",
            "          [ 0.1343, -0.0333,  0.0573]],\n",
            "\n",
            "         [[ 0.0107, -0.1018, -0.0632],\n",
            "          [-0.1064,  0.0825,  0.0589],\n",
            "          [ 0.1306, -0.1160, -0.0009]],\n",
            "\n",
            "         [[ 0.1033,  0.1369,  0.1329],\n",
            "          [-0.0583, -0.1006, -0.0515],\n",
            "          [ 0.0956, -0.0466,  0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0630, -0.1007, -0.0224],\n",
            "          [ 0.0597,  0.0746, -0.0809],\n",
            "          [ 0.1096, -0.0081,  0.0485]],\n",
            "\n",
            "         [[-0.0192,  0.0433, -0.0180],\n",
            "          [ 0.0555, -0.0442, -0.1342],\n",
            "          [ 0.0390, -0.0937, -0.1160]],\n",
            "\n",
            "         [[ 0.0635, -0.0448,  0.0776],\n",
            "          [-0.0472,  0.1219, -0.0217],\n",
            "          [ 0.0235,  0.1338, -0.1280]]],\n",
            "\n",
            "\n",
            "        [[[-0.1138,  0.0961,  0.0734],\n",
            "          [ 0.1227,  0.0692,  0.0687],\n",
            "          [ 0.0951, -0.0988, -0.1304]],\n",
            "\n",
            "         [[ 0.0414,  0.1211,  0.1038],\n",
            "          [ 0.0472,  0.0314,  0.1127],\n",
            "          [ 0.1249,  0.0592,  0.1128]],\n",
            "\n",
            "         [[-0.0023, -0.0187, -0.0323],\n",
            "          [ 0.0005, -0.0440,  0.1075],\n",
            "          [-0.0339, -0.0237,  0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1025, -0.0733,  0.0263],\n",
            "          [ 0.0634, -0.1255,  0.0807],\n",
            "          [-0.0945, -0.0226, -0.1057]],\n",
            "\n",
            "         [[-0.0354,  0.0731, -0.0700],\n",
            "          [-0.0865, -0.1230, -0.1273],\n",
            "          [-0.1034, -0.0091,  0.0499]],\n",
            "\n",
            "         [[-0.0941, -0.1289, -0.0261],\n",
            "          [-0.0112,  0.0301,  0.1376],\n",
            "          [ 0.0553, -0.1234, -0.0216]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1093, -0.0918,  0.0554],\n",
            "          [-0.0098,  0.0586, -0.0456],\n",
            "          [ 0.0957, -0.0791,  0.0954]],\n",
            "\n",
            "         [[ 0.0342, -0.0692, -0.0776],\n",
            "          [ 0.0679, -0.1333, -0.0824],\n",
            "          [ 0.0169,  0.0182,  0.0261]],\n",
            "\n",
            "         [[-0.0804, -0.0958,  0.0014],\n",
            "          [-0.0349,  0.1200, -0.1340],\n",
            "          [-0.0353, -0.0973,  0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0191,  0.0477, -0.0084],\n",
            "          [ 0.0818,  0.1183, -0.0276],\n",
            "          [-0.0286,  0.0132, -0.0614]],\n",
            "\n",
            "         [[ 0.0330,  0.0598,  0.1111],\n",
            "          [ 0.1165, -0.0417,  0.0480],\n",
            "          [-0.0908,  0.0554,  0.1349]],\n",
            "\n",
            "         [[-0.0483,  0.0873, -0.1318],\n",
            "          [ 0.0756,  0.0214,  0.1137],\n",
            "          [ 0.0039,  0.1094,  0.0119]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0383,  0.1257],\n",
            "          [-0.0961,  0.1246,  0.0706],\n",
            "          [ 0.0321,  0.0388, -0.0594]],\n",
            "\n",
            "         [[-0.1108,  0.0191,  0.1080],\n",
            "          [ 0.1116,  0.0277, -0.0775],\n",
            "          [-0.0249,  0.1057, -0.0952]],\n",
            "\n",
            "         [[ 0.1207, -0.1373, -0.0730],\n",
            "          [ 0.1134,  0.0365, -0.0702],\n",
            "          [-0.0340, -0.1309, -0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1354,  0.1205, -0.1124],\n",
            "          [-0.0645, -0.0902,  0.1234],\n",
            "          [-0.0884,  0.0080,  0.0424]],\n",
            "\n",
            "         [[-0.0670,  0.0203, -0.0854],\n",
            "          [ 0.0503, -0.0132,  0.1265],\n",
            "          [-0.0972,  0.0498,  0.1150]],\n",
            "\n",
            "         [[-0.1209,  0.1248,  0.0428],\n",
            "          [-0.0510,  0.0816,  0.0532],\n",
            "          [-0.0520, -0.0577,  0.1087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1126,  0.0255, -0.1296],\n",
            "          [ 0.0378,  0.0466, -0.0572],\n",
            "          [ 0.0232, -0.0410,  0.1117]],\n",
            "\n",
            "         [[ 0.0124, -0.1374,  0.1032],\n",
            "          [-0.0838, -0.1037,  0.0993],\n",
            "          [-0.0971,  0.0112,  0.1063]],\n",
            "\n",
            "         [[-0.1211,  0.1292, -0.0956],\n",
            "          [ 0.0564, -0.1087,  0.0525],\n",
            "          [ 0.1237,  0.0084,  0.0690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0790,  0.0170,  0.1157],\n",
            "          [-0.1304, -0.1316,  0.1206],\n",
            "          [ 0.1354, -0.1357,  0.0203]],\n",
            "\n",
            "         [[ 0.0671,  0.0099,  0.0534],\n",
            "          [ 0.0526, -0.0304,  0.0219],\n",
            "          [-0.0585,  0.0089, -0.0224]],\n",
            "\n",
            "         [[-0.0058, -0.0208,  0.0841],\n",
            "          [ 0.0215, -0.0465, -0.0621],\n",
            "          [-0.1283,  0.1176, -0.0754]]],\n",
            "\n",
            "\n",
            "        [[[-0.0220,  0.0226,  0.0721],\n",
            "          [-0.0388, -0.0747,  0.0138],\n",
            "          [-0.0008,  0.1340,  0.0115]],\n",
            "\n",
            "         [[-0.1081,  0.1344,  0.0052],\n",
            "          [ 0.1110, -0.1306, -0.1088],\n",
            "          [-0.0309,  0.0023,  0.0570]],\n",
            "\n",
            "         [[-0.0560, -0.1184,  0.0920],\n",
            "          [ 0.0252, -0.0433,  0.0878],\n",
            "          [ 0.0069, -0.1082,  0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0770,  0.0946, -0.0880],\n",
            "          [-0.0460,  0.1173,  0.0226],\n",
            "          [ 0.0407,  0.0980, -0.0654]],\n",
            "\n",
            "         [[-0.0717, -0.0724,  0.0412],\n",
            "          [-0.0562,  0.0682, -0.0425],\n",
            "          [ 0.0033, -0.1061,  0.0760]],\n",
            "\n",
            "         [[-0.1020, -0.0190, -0.0219],\n",
            "          [ 0.0550, -0.0851,  0.1220],\n",
            "          [ 0.0055,  0.0560,  0.1111]]],\n",
            "\n",
            "\n",
            "        [[[-0.0951, -0.0374, -0.1315],\n",
            "          [-0.1089,  0.0229,  0.1351],\n",
            "          [ 0.0422,  0.1377, -0.1347]],\n",
            "\n",
            "         [[-0.0214, -0.0826, -0.1109],\n",
            "          [-0.0246, -0.0491,  0.0648],\n",
            "          [-0.0400,  0.1292, -0.0168]],\n",
            "\n",
            "         [[ 0.0885, -0.0273, -0.0782],\n",
            "          [-0.0131, -0.0099,  0.0111],\n",
            "          [ 0.0437, -0.1332, -0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0438,  0.1056],\n",
            "          [ 0.0402, -0.1309,  0.1371],\n",
            "          [ 0.1017,  0.0284, -0.0202]],\n",
            "\n",
            "         [[ 0.1244, -0.1375,  0.0282],\n",
            "          [ 0.1086,  0.1217,  0.0943],\n",
            "          [-0.0004,  0.0387, -0.0833]],\n",
            "\n",
            "         [[-0.0171, -0.0782, -0.0358],\n",
            "          [ 0.0075, -0.1302,  0.0208],\n",
            "          [-0.0873, -0.0959,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102, -0.1067, -0.1025],\n",
            "          [ 0.1116,  0.0266, -0.1028],\n",
            "          [-0.0635, -0.0708, -0.0697]],\n",
            "\n",
            "         [[ 0.0030,  0.0739, -0.0855],\n",
            "          [-0.0650,  0.1201, -0.0131],\n",
            "          [-0.0618, -0.0680, -0.0356]],\n",
            "\n",
            "         [[-0.0797, -0.1149,  0.0272],\n",
            "          [ 0.0520,  0.0685,  0.0054],\n",
            "          [-0.0097, -0.0302,  0.1144]]],\n",
            "\n",
            "\n",
            "        [[[-0.1193,  0.0028,  0.0314],\n",
            "          [-0.1280,  0.1190, -0.1014],\n",
            "          [-0.1231,  0.0703,  0.0279]],\n",
            "\n",
            "         [[ 0.0904, -0.1331, -0.0808],\n",
            "          [ 0.0591, -0.0654,  0.1076],\n",
            "          [-0.0453, -0.0707,  0.1021]],\n",
            "\n",
            "         [[-0.0887, -0.0770, -0.0189],\n",
            "          [ 0.0863, -0.0374, -0.0307],\n",
            "          [-0.1057,  0.0172, -0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0808, -0.1211, -0.0311],\n",
            "          [-0.1210,  0.1079,  0.1335],\n",
            "          [ 0.0941, -0.0931,  0.1172]],\n",
            "\n",
            "         [[ 0.0292,  0.0663,  0.1289],\n",
            "          [ 0.0864, -0.0247, -0.1160],\n",
            "          [-0.0783,  0.0210,  0.0308]],\n",
            "\n",
            "         [[-0.1219,  0.0811, -0.1078],\n",
            "          [ 0.1174,  0.0290, -0.0027],\n",
            "          [-0.0488, -0.0225,  0.0816]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1049,  0.0749, -0.1125],\n",
            "          [ 0.1378, -0.0721,  0.1281],\n",
            "          [-0.0777,  0.1362,  0.1164]],\n",
            "\n",
            "         [[ 0.0799,  0.0223,  0.1133],\n",
            "          [-0.0881,  0.0412,  0.0543],\n",
            "          [-0.0111, -0.0803, -0.0113]],\n",
            "\n",
            "         [[-0.0609,  0.0141, -0.0534],\n",
            "          [-0.1238,  0.0143,  0.0859],\n",
            "          [-0.0301, -0.0316,  0.0964]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0993,  0.1189, -0.0055],\n",
            "          [ 0.0014, -0.0976,  0.0031],\n",
            "          [ 0.0043,  0.1026, -0.1371]],\n",
            "\n",
            "         [[-0.0154, -0.1327, -0.1321],\n",
            "          [ 0.0735,  0.0689,  0.1124],\n",
            "          [ 0.0417,  0.0066, -0.0752]],\n",
            "\n",
            "         [[-0.1169, -0.0826, -0.0636],\n",
            "          [-0.0801,  0.0542,  0.1322],\n",
            "          [ 0.1274, -0.0805, -0.1321]]],\n",
            "\n",
            "\n",
            "        [[[-0.0321, -0.1013, -0.1340],\n",
            "          [ 0.0549,  0.1229,  0.0187],\n",
            "          [ 0.0635,  0.0855, -0.0793]],\n",
            "\n",
            "         [[ 0.0163,  0.0576, -0.0725],\n",
            "          [ 0.1349,  0.1338,  0.0424],\n",
            "          [-0.0565, -0.0271, -0.0065]],\n",
            "\n",
            "         [[ 0.1057, -0.0662,  0.0843],\n",
            "          [ 0.1218, -0.0181, -0.0132],\n",
            "          [-0.0224,  0.0711,  0.1373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458, -0.0240, -0.0642],\n",
            "          [-0.1284,  0.1301, -0.0221],\n",
            "          [ 0.0513,  0.0357,  0.0685]],\n",
            "\n",
            "         [[ 0.0447,  0.0482,  0.0202],\n",
            "          [ 0.1029, -0.0415,  0.0292],\n",
            "          [ 0.0927, -0.0914,  0.1029]],\n",
            "\n",
            "         [[ 0.0587, -0.0453, -0.0390],\n",
            "          [ 0.0402, -0.1310,  0.1291],\n",
            "          [-0.1203, -0.0834,  0.0932]]],\n",
            "\n",
            "\n",
            "        [[[-0.1195, -0.0345, -0.0670],\n",
            "          [ 0.0642, -0.0037, -0.0502],\n",
            "          [-0.0359,  0.0489,  0.0630]],\n",
            "\n",
            "         [[-0.0950,  0.1065,  0.0999],\n",
            "          [ 0.0028, -0.0237,  0.0881],\n",
            "          [ 0.1140, -0.1286,  0.0987]],\n",
            "\n",
            "         [[-0.0686, -0.0377,  0.0912],\n",
            "          [ 0.1366, -0.0975, -0.0507],\n",
            "          [-0.0163,  0.0094,  0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1173,  0.1334, -0.0506],\n",
            "          [-0.1283, -0.1268,  0.0220],\n",
            "          [ 0.0777, -0.0241, -0.0772]],\n",
            "\n",
            "         [[-0.0849, -0.0376,  0.0414],\n",
            "          [ 0.1200,  0.0639, -0.0089],\n",
            "          [-0.0256,  0.1346,  0.0802]],\n",
            "\n",
            "         [[-0.1187,  0.1279,  0.0268],\n",
            "          [ 0.0801, -0.0363, -0.1048],\n",
            "          [-0.0573, -0.0708,  0.0379]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0796, -0.0600,  0.0439],\n",
            "          [ 0.0550, -0.1245, -0.0892],\n",
            "          [-0.0474, -0.1210,  0.1336]],\n",
            "\n",
            "         [[ 0.0692,  0.0903, -0.0840],\n",
            "          [ 0.1243,  0.1076,  0.1367],\n",
            "          [-0.0511, -0.0784, -0.0105]],\n",
            "\n",
            "         [[ 0.0425, -0.0139,  0.1241],\n",
            "          [-0.0850,  0.0267,  0.0743],\n",
            "          [-0.1332, -0.0337, -0.0154]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0971, -0.0718, -0.0420],\n",
            "          [-0.1062,  0.1183, -0.1028],\n",
            "          [-0.0097,  0.0813, -0.0535]],\n",
            "\n",
            "         [[ 0.1279,  0.1208,  0.0060],\n",
            "          [-0.1352, -0.0636,  0.0192],\n",
            "          [-0.1363, -0.0039,  0.0833]],\n",
            "\n",
            "         [[-0.0234,  0.0114, -0.0031],\n",
            "          [ 0.1271,  0.0990, -0.0219],\n",
            "          [ 0.0717, -0.1184, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[-0.0752,  0.0160,  0.1106],\n",
            "          [-0.1226,  0.0359, -0.0675],\n",
            "          [-0.0148,  0.1298,  0.0941]],\n",
            "\n",
            "         [[ 0.0124, -0.0077, -0.1213],\n",
            "          [ 0.0115, -0.0320,  0.1001],\n",
            "          [ 0.0701,  0.0954, -0.0785]],\n",
            "\n",
            "         [[-0.1014,  0.0947,  0.0171],\n",
            "          [ 0.1316, -0.0220, -0.0368],\n",
            "          [ 0.0536,  0.0620, -0.0759]]],\n",
            "\n",
            "\n",
            "        [[[-0.0462,  0.0865, -0.0109],\n",
            "          [-0.0799, -0.0852,  0.0181],\n",
            "          [-0.0158,  0.0746,  0.1030]],\n",
            "\n",
            "         [[-0.0636,  0.0897, -0.0426],\n",
            "          [ 0.0369, -0.0393, -0.0056],\n",
            "          [-0.0294,  0.1296, -0.1235]],\n",
            "\n",
            "         [[ 0.0002,  0.0252,  0.1291],\n",
            "          [-0.0383,  0.0881,  0.0236],\n",
            "          [-0.0026, -0.0574, -0.0595]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 6.3420e-02,  7.3276e-02,  3.5488e-02],\n",
            "          [-7.2040e-02,  9.8323e-03,  2.7458e-02],\n",
            "          [ 1.2968e-02,  1.4557e-02,  6.5395e-02]],\n",
            "\n",
            "         [[ 2.6170e-02,  5.8342e-02, -3.9271e-02],\n",
            "          [-7.7091e-02,  6.4732e-02, -2.1609e-02],\n",
            "          [-1.8860e-02,  7.0977e-03, -3.3068e-02]],\n",
            "\n",
            "         [[-4.1607e-02, -4.8902e-02,  2.5010e-02],\n",
            "          [ 2.4871e-02,  4.0022e-02,  3.9656e-02],\n",
            "          [-8.2284e-02,  8.3118e-02, -4.2069e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.8574e-02, -5.7834e-02,  8.3874e-04],\n",
            "          [-2.1052e-02,  7.2458e-02, -8.0893e-02],\n",
            "          [-2.1344e-02, -5.8761e-02,  3.1942e-03]],\n",
            "\n",
            "         [[ 1.1539e-02,  2.8821e-02, -5.0540e-03],\n",
            "          [ 4.9397e-02,  7.1442e-02, -1.6676e-02],\n",
            "          [-1.7296e-02,  7.9432e-03, -3.7044e-02]],\n",
            "\n",
            "         [[ 1.9931e-02,  3.6135e-02,  6.7053e-02],\n",
            "          [ 7.0346e-02, -2.5206e-02,  2.9000e-02],\n",
            "          [-5.4800e-02,  3.3441e-02,  8.1460e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9146e-02,  5.2727e-02, -7.9582e-02],\n",
            "          [ 4.5671e-02,  1.2910e-02,  6.8654e-02],\n",
            "          [ 2.3663e-03,  6.6062e-02,  7.1735e-03]],\n",
            "\n",
            "         [[-5.0448e-02, -2.3134e-02,  7.5889e-02],\n",
            "          [-5.8021e-02,  7.5218e-02,  4.2656e-02],\n",
            "          [ 1.9394e-02,  2.3413e-02, -3.5866e-02]],\n",
            "\n",
            "         [[-6.6916e-02,  1.1513e-02,  6.5213e-02],\n",
            "          [ 6.7408e-02,  1.6709e-02, -4.6795e-02],\n",
            "          [-1.5024e-02,  6.3795e-02, -5.7492e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4604e-02, -8.0372e-02, -4.8780e-02],\n",
            "          [ 3.5713e-02, -3.9517e-02,  6.4963e-02],\n",
            "          [-2.7380e-02, -4.2717e-02,  6.1674e-02]],\n",
            "\n",
            "         [[-5.3551e-02, -4.6499e-02, -1.1385e-02],\n",
            "          [ 5.2103e-02, -2.2561e-02, -1.8564e-02],\n",
            "          [-6.3842e-02,  1.0369e-02, -1.2117e-02]],\n",
            "\n",
            "         [[-4.8763e-02, -7.3097e-02, -1.8784e-02],\n",
            "          [-7.3069e-02,  6.5139e-02,  8.0630e-02],\n",
            "          [ 5.6838e-02, -5.6211e-02,  7.0789e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7635e-02,  4.0050e-02,  7.7815e-02],\n",
            "          [ 5.2183e-02, -1.4920e-02, -7.0026e-02],\n",
            "          [-4.7301e-02,  1.2658e-02,  1.8608e-02]],\n",
            "\n",
            "         [[-7.3607e-02,  4.8940e-02, -6.5101e-02],\n",
            "          [ 7.0861e-02,  1.7530e-02, -1.6527e-03],\n",
            "          [-2.9492e-02, -1.3609e-02,  4.9277e-02]],\n",
            "\n",
            "         [[ 6.3353e-02,  4.5206e-02, -6.7958e-02],\n",
            "          [ 8.3224e-02, -4.3525e-02,  7.7330e-02],\n",
            "          [-4.6917e-02,  8.2215e-02,  7.0256e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7900e-02,  5.2240e-02, -6.5858e-03],\n",
            "          [-4.8251e-02, -5.1474e-02,  1.0904e-02],\n",
            "          [-9.5620e-03,  4.5054e-02,  6.2167e-02]],\n",
            "\n",
            "         [[-3.8407e-02,  5.4180e-02, -2.5712e-02],\n",
            "          [ 2.2288e-02, -2.3744e-02, -3.3917e-03],\n",
            "          [-1.7741e-02,  7.8265e-02, -7.4556e-02]],\n",
            "\n",
            "         [[ 1.3336e-04,  1.5187e-02,  7.7969e-02],\n",
            "          [-2.3130e-02,  5.3177e-02,  1.4256e-02],\n",
            "          [-1.5449e-03, -3.4685e-02, -3.5939e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5518e-02, -7.8106e-03,  1.1188e-02],\n",
            "          [ 5.8566e-02, -7.5503e-02, -4.8799e-02],\n",
            "          [ 7.8534e-02, -7.6864e-03, -5.4235e-03]],\n",
            "\n",
            "         [[-4.8229e-02, -2.4747e-02,  1.4032e-02],\n",
            "          [-2.6408e-02, -3.0844e-02, -6.4617e-02],\n",
            "          [ 7.1523e-02,  7.5792e-03, -1.8219e-02]],\n",
            "\n",
            "         [[-1.2435e-02,  5.9314e-02,  6.8632e-02],\n",
            "          [ 6.1398e-02,  2.9868e-02, -8.2195e-02],\n",
            "          [-3.4634e-03,  2.8007e-02,  2.8763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0223e-02, -7.1725e-02, -5.0124e-02],\n",
            "          [ 9.6777e-03,  2.4223e-02, -7.1778e-02],\n",
            "          [ 3.2490e-02, -8.2311e-02, -3.7245e-02]],\n",
            "\n",
            "         [[-6.6682e-02, -3.9517e-02,  6.0189e-04],\n",
            "          [ 4.7752e-02,  4.7375e-02,  4.6630e-02],\n",
            "          [ 4.7163e-03,  8.7263e-03,  4.0087e-02]],\n",
            "\n",
            "         [[-8.1609e-02, -7.4239e-02, -6.0175e-02],\n",
            "          [ 7.7161e-02,  1.4216e-02,  2.8079e-02],\n",
            "          [-2.9038e-02, -7.9810e-02, -5.7194e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3276e-02,  6.2281e-02, -6.5992e-02],\n",
            "          [ 1.6867e-02,  4.9823e-02,  3.7555e-02],\n",
            "          [ 7.6220e-02,  6.5295e-02, -2.0038e-03]],\n",
            "\n",
            "         [[-4.5562e-02,  7.9474e-02,  1.4381e-02],\n",
            "          [-2.2909e-02, -8.0703e-02, -6.7262e-02],\n",
            "          [ 6.5767e-02, -7.8513e-02, -3.2978e-02]],\n",
            "\n",
            "         [[-8.0295e-02,  7.5996e-02, -8.0098e-02],\n",
            "          [ 3.8228e-02,  5.9146e-03,  3.0472e-02],\n",
            "          [ 7.3772e-02,  4.7300e-02, -5.7094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4906e-02,  1.9164e-02, -2.9368e-02],\n",
            "          [-2.2259e-02,  4.3675e-02, -8.1335e-02],\n",
            "          [-2.6379e-02,  8.2509e-02, -5.6902e-02]],\n",
            "\n",
            "         [[ 4.8517e-02, -5.3306e-02, -4.5405e-02],\n",
            "          [-7.2836e-02,  6.9791e-04, -2.0265e-02],\n",
            "          [ 3.9212e-02,  3.0947e-02,  8.1954e-02]],\n",
            "\n",
            "         [[-1.0525e-02,  3.9170e-02,  8.1547e-02],\n",
            "          [ 1.0298e-02,  2.4142e-02,  8.1552e-02],\n",
            "          [-4.1315e-02, -6.6417e-02, -4.2100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7834e-02, -3.7336e-02, -5.6150e-02],\n",
            "          [ 1.4851e-03,  2.7738e-02, -5.7369e-02],\n",
            "          [-7.0169e-02, -4.1213e-05, -4.9262e-02]],\n",
            "\n",
            "         [[-1.4965e-02,  4.0813e-02,  6.4681e-02],\n",
            "          [-4.0381e-02, -5.2670e-03,  3.8095e-02],\n",
            "          [ 5.0829e-02,  7.8358e-02, -5.9338e-03]],\n",
            "\n",
            "         [[ 5.0548e-02,  6.9506e-02,  3.5774e-03],\n",
            "          [-2.0453e-02, -2.2837e-02,  2.7631e-02],\n",
            "          [ 2.2321e-03,  4.0112e-03,  5.9683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7560e-02,  2.7013e-02,  3.8514e-02],\n",
            "          [-6.2757e-02,  7.1732e-02,  3.4445e-02],\n",
            "          [-5.7345e-03, -4.4443e-02, -7.9402e-02]],\n",
            "\n",
            "         [[-8.3232e-02,  3.6605e-02,  3.9557e-02],\n",
            "          [-3.0950e-02, -1.1902e-02,  2.3066e-02],\n",
            "          [ 8.3602e-03,  1.4968e-02, -6.2327e-02]],\n",
            "\n",
            "         [[ 3.4100e-02,  4.9295e-02,  2.1340e-02],\n",
            "          [-2.3296e-02,  3.6142e-02,  3.7400e-03],\n",
            "          [-1.0772e-02, -7.1674e-02, -2.9318e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 6.3420e-02,  7.3276e-02,  3.5488e-02],\n",
            "          [-7.2040e-02,  9.8323e-03,  2.7458e-02],\n",
            "          [ 1.2968e-02,  1.4557e-02,  6.5395e-02]],\n",
            "\n",
            "         [[ 2.6170e-02,  5.8342e-02, -3.9271e-02],\n",
            "          [-7.7091e-02,  6.4732e-02, -2.1609e-02],\n",
            "          [-1.8860e-02,  7.0977e-03, -3.3068e-02]],\n",
            "\n",
            "         [[-4.1607e-02, -4.8902e-02,  2.5010e-02],\n",
            "          [ 2.4871e-02,  4.0022e-02,  3.9656e-02],\n",
            "          [-8.2284e-02,  8.3118e-02, -4.2069e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.8574e-02, -5.7834e-02,  8.3874e-04],\n",
            "          [-2.1052e-02,  7.2458e-02, -8.0893e-02],\n",
            "          [-2.1344e-02, -5.8761e-02,  3.1942e-03]],\n",
            "\n",
            "         [[ 1.1539e-02,  2.8821e-02, -5.0540e-03],\n",
            "          [ 4.9397e-02,  7.1442e-02, -1.6676e-02],\n",
            "          [-1.7296e-02,  7.9432e-03, -3.7044e-02]],\n",
            "\n",
            "         [[ 1.9931e-02,  3.6135e-02,  6.7053e-02],\n",
            "          [ 7.0346e-02, -2.5206e-02,  2.9000e-02],\n",
            "          [-5.4800e-02,  3.3441e-02,  8.1460e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9146e-02,  5.2727e-02, -7.9582e-02],\n",
            "          [ 4.5671e-02,  1.2910e-02,  6.8654e-02],\n",
            "          [ 2.3663e-03,  6.6062e-02,  7.1735e-03]],\n",
            "\n",
            "         [[-5.0448e-02, -2.3134e-02,  7.5889e-02],\n",
            "          [-5.8021e-02,  7.5218e-02,  4.2656e-02],\n",
            "          [ 1.9394e-02,  2.3413e-02, -3.5866e-02]],\n",
            "\n",
            "         [[-6.6916e-02,  1.1513e-02,  6.5213e-02],\n",
            "          [ 6.7408e-02,  1.6709e-02, -4.6795e-02],\n",
            "          [-1.5024e-02,  6.3795e-02, -5.7492e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4604e-02, -8.0372e-02, -4.8780e-02],\n",
            "          [ 3.5713e-02, -3.9517e-02,  6.4963e-02],\n",
            "          [-2.7380e-02, -4.2717e-02,  6.1674e-02]],\n",
            "\n",
            "         [[-5.3551e-02, -4.6499e-02, -1.1385e-02],\n",
            "          [ 5.2103e-02, -2.2561e-02, -1.8564e-02],\n",
            "          [-6.3842e-02,  1.0369e-02, -1.2117e-02]],\n",
            "\n",
            "         [[-4.8763e-02, -7.3097e-02, -1.8784e-02],\n",
            "          [-7.3069e-02,  6.5139e-02,  8.0630e-02],\n",
            "          [ 5.6838e-02, -5.6211e-02,  7.0789e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7635e-02,  4.0050e-02,  7.7815e-02],\n",
            "          [ 5.2183e-02, -1.4920e-02, -7.0026e-02],\n",
            "          [-4.7301e-02,  1.2658e-02,  1.8608e-02]],\n",
            "\n",
            "         [[-7.3607e-02,  4.8940e-02, -6.5101e-02],\n",
            "          [ 7.0861e-02,  1.7530e-02, -1.6527e-03],\n",
            "          [-2.9492e-02, -1.3609e-02,  4.9277e-02]],\n",
            "\n",
            "         [[ 6.3353e-02,  4.5206e-02, -6.7958e-02],\n",
            "          [ 8.3224e-02, -4.3525e-02,  7.7330e-02],\n",
            "          [-4.6917e-02,  8.2215e-02,  7.0256e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7900e-02,  5.2240e-02, -6.5858e-03],\n",
            "          [-4.8251e-02, -5.1474e-02,  1.0904e-02],\n",
            "          [-9.5620e-03,  4.5054e-02,  6.2167e-02]],\n",
            "\n",
            "         [[-3.8407e-02,  5.4180e-02, -2.5712e-02],\n",
            "          [ 2.2288e-02, -2.3744e-02, -3.3917e-03],\n",
            "          [-1.7741e-02,  7.8265e-02, -7.4556e-02]],\n",
            "\n",
            "         [[ 1.3336e-04,  1.5187e-02,  7.7969e-02],\n",
            "          [-2.3130e-02,  5.3177e-02,  1.4256e-02],\n",
            "          [-1.5449e-03, -3.4685e-02, -3.5939e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5518e-02, -7.8106e-03,  1.1188e-02],\n",
            "          [ 5.8566e-02, -7.5503e-02, -4.8799e-02],\n",
            "          [ 7.8534e-02, -7.6864e-03, -5.4235e-03]],\n",
            "\n",
            "         [[-4.8229e-02, -2.4747e-02,  1.4032e-02],\n",
            "          [-2.6408e-02, -3.0844e-02, -6.4617e-02],\n",
            "          [ 7.1523e-02,  7.5792e-03, -1.8219e-02]],\n",
            "\n",
            "         [[-1.2435e-02,  5.9314e-02,  6.8632e-02],\n",
            "          [ 6.1398e-02,  2.9868e-02, -8.2195e-02],\n",
            "          [-3.4634e-03,  2.8007e-02,  2.8763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0223e-02, -7.1725e-02, -5.0124e-02],\n",
            "          [ 9.6777e-03,  2.4223e-02, -7.1778e-02],\n",
            "          [ 3.2490e-02, -8.2311e-02, -3.7245e-02]],\n",
            "\n",
            "         [[-6.6682e-02, -3.9517e-02,  6.0189e-04],\n",
            "          [ 4.7752e-02,  4.7375e-02,  4.6630e-02],\n",
            "          [ 4.7163e-03,  8.7263e-03,  4.0087e-02]],\n",
            "\n",
            "         [[-8.1609e-02, -7.4239e-02, -6.0175e-02],\n",
            "          [ 7.7161e-02,  1.4216e-02,  2.8079e-02],\n",
            "          [-2.9038e-02, -7.9810e-02, -5.7194e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3276e-02,  6.2281e-02, -6.5992e-02],\n",
            "          [ 1.6867e-02,  4.9823e-02,  3.7555e-02],\n",
            "          [ 7.6220e-02,  6.5295e-02, -2.0038e-03]],\n",
            "\n",
            "         [[-4.5562e-02,  7.9474e-02,  1.4381e-02],\n",
            "          [-2.2909e-02, -8.0703e-02, -6.7262e-02],\n",
            "          [ 6.5767e-02, -7.8513e-02, -3.2978e-02]],\n",
            "\n",
            "         [[-8.0295e-02,  7.5996e-02, -8.0098e-02],\n",
            "          [ 3.8228e-02,  5.9146e-03,  3.0472e-02],\n",
            "          [ 7.3772e-02,  4.7300e-02, -5.7094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4906e-02,  1.9164e-02, -2.9368e-02],\n",
            "          [-2.2259e-02,  4.3675e-02, -8.1335e-02],\n",
            "          [-2.6379e-02,  8.2509e-02, -5.6902e-02]],\n",
            "\n",
            "         [[ 4.8517e-02, -5.3306e-02, -4.5405e-02],\n",
            "          [-7.2836e-02,  6.9791e-04, -2.0265e-02],\n",
            "          [ 3.9212e-02,  3.0947e-02,  8.1954e-02]],\n",
            "\n",
            "         [[-1.0525e-02,  3.9170e-02,  8.1547e-02],\n",
            "          [ 1.0298e-02,  2.4142e-02,  8.1552e-02],\n",
            "          [-4.1315e-02, -6.6417e-02, -4.2100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7834e-02, -3.7336e-02, -5.6150e-02],\n",
            "          [ 1.4851e-03,  2.7738e-02, -5.7369e-02],\n",
            "          [-7.0169e-02, -4.1213e-05, -4.9262e-02]],\n",
            "\n",
            "         [[-1.4965e-02,  4.0813e-02,  6.4681e-02],\n",
            "          [-4.0381e-02, -5.2670e-03,  3.8095e-02],\n",
            "          [ 5.0829e-02,  7.8358e-02, -5.9338e-03]],\n",
            "\n",
            "         [[ 5.0548e-02,  6.9506e-02,  3.5774e-03],\n",
            "          [-2.0453e-02, -2.2837e-02,  2.7631e-02],\n",
            "          [ 2.2321e-03,  4.0112e-03,  5.9683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7560e-02,  2.7013e-02,  3.8514e-02],\n",
            "          [-6.2757e-02,  7.1732e-02,  3.4445e-02],\n",
            "          [-5.7345e-03, -4.4443e-02, -7.9402e-02]],\n",
            "\n",
            "         [[-8.3232e-02,  3.6605e-02,  3.9557e-02],\n",
            "          [-3.0950e-02, -1.1902e-02,  2.3066e-02],\n",
            "          [ 8.3602e-03,  1.4968e-02, -6.2327e-02]],\n",
            "\n",
            "         [[ 3.4100e-02,  4.9295e-02,  2.1340e-02],\n",
            "          [-2.3296e-02,  3.6142e-02,  3.7400e-03],\n",
            "          [-1.0772e-02, -7.1674e-02, -2.9318e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 4.4845e-02,  5.1814e-02,  2.5094e-02],\n",
            "          [-5.0940e-02,  6.9525e-03,  1.9416e-02],\n",
            "          [ 9.1698e-03,  1.0294e-02,  4.6242e-02]],\n",
            "\n",
            "         [[ 1.8505e-02,  4.1254e-02, -2.7769e-02],\n",
            "          [-5.4512e-02,  4.5773e-02, -1.5280e-02],\n",
            "          [-1.3336e-02,  5.0188e-03, -2.3383e-02]],\n",
            "\n",
            "         [[-2.9420e-02, -3.4579e-02,  1.7685e-02],\n",
            "          [ 1.7587e-02,  2.8300e-02,  2.8041e-02],\n",
            "          [-5.8184e-02,  5.8773e-02, -2.9748e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8611e-02, -5.6831e-02, -3.4493e-02],\n",
            "          [ 2.5253e-02, -2.7943e-02,  4.5936e-02],\n",
            "          [-1.9361e-02, -3.0206e-02,  4.3610e-02]],\n",
            "\n",
            "         [[-3.7867e-02, -3.2880e-02, -8.0507e-03],\n",
            "          [ 3.6842e-02, -1.5953e-02, -1.3127e-02],\n",
            "          [-4.5143e-02,  7.3322e-03, -8.5680e-03]],\n",
            "\n",
            "         [[-3.4480e-02, -5.1687e-02, -1.3282e-02],\n",
            "          [-5.1667e-02,  4.6060e-02,  5.7014e-02],\n",
            "          [ 4.0191e-02, -3.9747e-02,  5.0055e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2470e-02,  2.8320e-02,  5.5024e-02],\n",
            "          [ 3.6899e-02, -1.0550e-02, -4.9516e-02],\n",
            "          [-3.3447e-02,  8.9503e-03,  1.3158e-02]],\n",
            "\n",
            "         [[-5.2048e-02,  3.4606e-02, -4.6034e-02],\n",
            "          [ 5.0106e-02,  1.2395e-02, -1.1686e-03],\n",
            "          [-2.0854e-02, -9.6232e-03,  3.4844e-02]],\n",
            "\n",
            "         [[ 4.4797e-02,  3.1965e-02, -4.8054e-02],\n",
            "          [ 5.8849e-02, -3.0777e-02,  5.4680e-02],\n",
            "          [-3.3176e-02,  5.8135e-02,  4.9679e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8018e-02, -2.8994e-02, -1.9422e-02],\n",
            "          [-4.2067e-02,  4.9561e-02,  2.3140e-02],\n",
            "          [-3.1462e-02, -5.2222e-02, -2.3686e-02]],\n",
            "\n",
            "         [[ 2.6994e-02,  9.5118e-03,  4.8858e-02],\n",
            "          [-5.1181e-02, -2.8469e-02, -5.3310e-02],\n",
            "          [ 8.7096e-03, -4.6548e-02, -4.4055e-02]],\n",
            "\n",
            "         [[-2.0991e-02,  1.5334e-02, -2.1385e-05],\n",
            "          [-4.1707e-02, -2.3136e-02,  5.4723e-02],\n",
            "          [ 4.3699e-02, -2.4382e-02,  4.2242e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6010e-02,  4.3814e-02, -1.2413e-02],\n",
            "          [ 1.4332e-02,  2.2193e-02,  4.1069e-02],\n",
            "          [ 5.7213e-02,  5.2797e-02,  4.5663e-03]],\n",
            "\n",
            "         [[ 3.8029e-02,  1.2206e-02,  4.8959e-03],\n",
            "          [-2.0712e-02, -9.2328e-03, -5.3781e-02],\n",
            "          [ 5.6189e-02, -4.4071e-02,  3.2018e-02]],\n",
            "\n",
            "         [[-3.9593e-02,  2.4511e-02, -3.7413e-02],\n",
            "          [-2.7640e-02, -1.7677e-02, -4.9695e-02],\n",
            "          [ 3.8388e-02,  2.2945e-02,  3.6923e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1702e-02, -5.3557e-02,  6.4093e-03],\n",
            "          [ 1.3410e-03,  6.7015e-04, -3.5026e-02],\n",
            "          [-2.9028e-02, -5.0844e-02,  3.7384e-02]],\n",
            "\n",
            "         [[-3.0373e-02,  1.5145e-02, -4.7163e-02],\n",
            "          [ 4.8873e-02, -5.2805e-02,  5.1437e-02],\n",
            "          [ 3.3870e-02, -4.1796e-02, -3.0026e-02]],\n",
            "\n",
            "         [[ 5.5603e-02, -5.5660e-02, -3.8751e-02],\n",
            "          [-3.9777e-02, -3.9544e-03,  4.7205e-02],\n",
            "          [-4.0660e-02, -5.1045e-02,  1.9755e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.4225e-03,  5.8966e-03, -5.2181e-02],\n",
            "          [ 1.2877e-02,  2.1004e-02,  1.3849e-02],\n",
            "          [-4.5653e-02,  4.2465e-02,  4.4422e-02]],\n",
            "\n",
            "         [[ 4.0491e-02, -2.8070e-02, -1.0315e-02],\n",
            "          [-3.4855e-02,  1.6074e-03,  4.2435e-02],\n",
            "          [-2.5890e-02, -5.4121e-02,  4.9705e-02]],\n",
            "\n",
            "         [[ 2.6590e-02, -3.9334e-02,  1.9364e-02],\n",
            "          [ 1.3269e-02, -3.1462e-02, -1.2197e-02],\n",
            "          [-1.9240e-02, -2.5462e-02, -3.7559e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8641e-02,  5.1524e-03,  4.0639e-02],\n",
            "          [ 1.4711e-02, -5.1846e-02, -1.3381e-02],\n",
            "          [-1.2564e-02,  4.3656e-02,  2.9459e-02]],\n",
            "\n",
            "         [[ 2.5456e-02, -2.1583e-02, -1.7562e-03],\n",
            "          [-2.9417e-03,  1.4950e-02, -4.5875e-02],\n",
            "          [-1.3552e-02, -3.3755e-02, -1.1766e-02]],\n",
            "\n",
            "         [[-5.7903e-02, -9.0666e-03, -3.3530e-02],\n",
            "          [ 1.6275e-02,  2.2725e-02,  4.1409e-02],\n",
            "          [ 3.3421e-02, -4.1847e-02, -3.3518e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8453e-02,  3.0810e-02, -4.1492e-02],\n",
            "          [-4.9423e-04, -1.5643e-02, -9.2124e-05],\n",
            "          [ 3.8616e-02,  5.6951e-02, -8.8304e-03]],\n",
            "\n",
            "         [[-3.4053e-02,  5.7430e-02, -5.2374e-02],\n",
            "          [ 7.4370e-03,  4.7341e-02, -1.1173e-02],\n",
            "          [-2.9683e-02,  4.2699e-02,  1.0138e-02]],\n",
            "\n",
            "         [[ 1.4564e-02,  4.0759e-02,  3.0126e-02],\n",
            "          [-4.3103e-02,  3.3635e-02, -3.7708e-03],\n",
            "          [-4.5272e-02,  4.4780e-02,  3.5606e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9362e-03, -4.5270e-02,  3.2289e-02],\n",
            "          [-1.6807e-02, -4.4908e-03, -3.3104e-02],\n",
            "          [-3.9801e-02, -1.2665e-02, -8.7887e-03]],\n",
            "\n",
            "         [[ 5.3640e-02,  4.6053e-02,  2.0436e-03],\n",
            "          [-1.4994e-03, -4.7443e-02,  3.9075e-02],\n",
            "          [-1.6432e-02, -5.1907e-02, -2.9914e-02]],\n",
            "\n",
            "         [[ 2.9734e-03,  1.2944e-02,  3.5550e-03],\n",
            "          [ 4.5563e-02, -4.2431e-03, -5.0833e-02],\n",
            "          [ 6.6308e-03,  4.3820e-02, -4.6857e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7160e-02, -4.5592e-02,  2.1544e-02],\n",
            "          [ 1.9051e-02,  2.2201e-02, -5.4873e-02],\n",
            "          [ 4.6079e-02,  4.9803e-02, -5.8571e-02]],\n",
            "\n",
            "         [[ 5.2928e-02, -5.1257e-03,  5.3019e-02],\n",
            "          [-2.8608e-02,  5.2892e-02, -1.0667e-02],\n",
            "          [-2.4313e-02, -7.1462e-03,  2.9066e-02]],\n",
            "\n",
            "         [[ 4.2359e-02,  2.2497e-02, -5.1829e-02],\n",
            "          [-5.7952e-02,  2.0746e-02, -5.8498e-02],\n",
            "          [-1.8216e-02, -3.7258e-03, -5.3728e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8317e-03, -4.4953e-02,  5.4703e-02],\n",
            "          [-4.5709e-02,  4.0591e-02, -1.4609e-02],\n",
            "          [-3.5994e-02, -2.0875e-02,  4.4330e-02]],\n",
            "\n",
            "         [[ 2.5360e-02, -5.0337e-02, -1.6996e-02],\n",
            "          [ 4.8848e-02,  1.2624e-02, -3.9590e-02],\n",
            "          [-4.1340e-02,  3.8589e-02,  4.0635e-02]],\n",
            "\n",
            "         [[-2.7707e-02, -4.9222e-02,  6.5755e-03],\n",
            "          [ 2.0375e-02, -3.3991e-02,  1.6203e-02],\n",
            "          [ 1.3942e-02,  5.4028e-02, -5.4231e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 4.4845e-02,  5.1814e-02,  2.5094e-02],\n",
            "          [-5.0940e-02,  6.9525e-03,  1.9416e-02],\n",
            "          [ 9.1698e-03,  1.0294e-02,  4.6242e-02]],\n",
            "\n",
            "         [[ 1.8505e-02,  4.1254e-02, -2.7769e-02],\n",
            "          [-5.4512e-02,  4.5773e-02, -1.5280e-02],\n",
            "          [-1.3336e-02,  5.0188e-03, -2.3383e-02]],\n",
            "\n",
            "         [[-2.9420e-02, -3.4579e-02,  1.7685e-02],\n",
            "          [ 1.7587e-02,  2.8300e-02,  2.8041e-02],\n",
            "          [-5.8184e-02,  5.8773e-02, -2.9748e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8611e-02, -5.6831e-02, -3.4493e-02],\n",
            "          [ 2.5253e-02, -2.7943e-02,  4.5936e-02],\n",
            "          [-1.9361e-02, -3.0206e-02,  4.3610e-02]],\n",
            "\n",
            "         [[-3.7867e-02, -3.2880e-02, -8.0507e-03],\n",
            "          [ 3.6842e-02, -1.5953e-02, -1.3127e-02],\n",
            "          [-4.5143e-02,  7.3322e-03, -8.5680e-03]],\n",
            "\n",
            "         [[-3.4480e-02, -5.1687e-02, -1.3282e-02],\n",
            "          [-5.1667e-02,  4.6060e-02,  5.7014e-02],\n",
            "          [ 4.0191e-02, -3.9747e-02,  5.0055e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2470e-02,  2.8320e-02,  5.5024e-02],\n",
            "          [ 3.6899e-02, -1.0550e-02, -4.9516e-02],\n",
            "          [-3.3447e-02,  8.9503e-03,  1.3158e-02]],\n",
            "\n",
            "         [[-5.2048e-02,  3.4606e-02, -4.6034e-02],\n",
            "          [ 5.0106e-02,  1.2395e-02, -1.1686e-03],\n",
            "          [-2.0854e-02, -9.6232e-03,  3.4844e-02]],\n",
            "\n",
            "         [[ 4.4797e-02,  3.1965e-02, -4.8054e-02],\n",
            "          [ 5.8849e-02, -3.0777e-02,  5.4680e-02],\n",
            "          [-3.3176e-02,  5.8135e-02,  4.9679e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8018e-02, -2.8994e-02, -1.9422e-02],\n",
            "          [-4.2067e-02,  4.9561e-02,  2.3140e-02],\n",
            "          [-3.1462e-02, -5.2222e-02, -2.3686e-02]],\n",
            "\n",
            "         [[ 2.6994e-02,  9.5118e-03,  4.8858e-02],\n",
            "          [-5.1181e-02, -2.8469e-02, -5.3310e-02],\n",
            "          [ 8.7096e-03, -4.6548e-02, -4.4055e-02]],\n",
            "\n",
            "         [[-2.0991e-02,  1.5334e-02, -2.1385e-05],\n",
            "          [-4.1707e-02, -2.3136e-02,  5.4723e-02],\n",
            "          [ 4.3699e-02, -2.4382e-02,  4.2242e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6010e-02,  4.3814e-02, -1.2413e-02],\n",
            "          [ 1.4332e-02,  2.2193e-02,  4.1069e-02],\n",
            "          [ 5.7213e-02,  5.2797e-02,  4.5663e-03]],\n",
            "\n",
            "         [[ 3.8029e-02,  1.2206e-02,  4.8959e-03],\n",
            "          [-2.0712e-02, -9.2328e-03, -5.3781e-02],\n",
            "          [ 5.6189e-02, -4.4071e-02,  3.2018e-02]],\n",
            "\n",
            "         [[-3.9593e-02,  2.4511e-02, -3.7413e-02],\n",
            "          [-2.7640e-02, -1.7677e-02, -4.9695e-02],\n",
            "          [ 3.8388e-02,  2.2945e-02,  3.6923e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1702e-02, -5.3557e-02,  6.4093e-03],\n",
            "          [ 1.3410e-03,  6.7015e-04, -3.5026e-02],\n",
            "          [-2.9028e-02, -5.0844e-02,  3.7384e-02]],\n",
            "\n",
            "         [[-3.0373e-02,  1.5145e-02, -4.7163e-02],\n",
            "          [ 4.8873e-02, -5.2805e-02,  5.1437e-02],\n",
            "          [ 3.3870e-02, -4.1796e-02, -3.0026e-02]],\n",
            "\n",
            "         [[ 5.5603e-02, -5.5660e-02, -3.8751e-02],\n",
            "          [-3.9777e-02, -3.9544e-03,  4.7205e-02],\n",
            "          [-4.0660e-02, -5.1045e-02,  1.9755e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.4225e-03,  5.8966e-03, -5.2181e-02],\n",
            "          [ 1.2877e-02,  2.1004e-02,  1.3849e-02],\n",
            "          [-4.5653e-02,  4.2465e-02,  4.4422e-02]],\n",
            "\n",
            "         [[ 4.0491e-02, -2.8070e-02, -1.0315e-02],\n",
            "          [-3.4855e-02,  1.6074e-03,  4.2435e-02],\n",
            "          [-2.5890e-02, -5.4121e-02,  4.9705e-02]],\n",
            "\n",
            "         [[ 2.6590e-02, -3.9334e-02,  1.9364e-02],\n",
            "          [ 1.3269e-02, -3.1462e-02, -1.2197e-02],\n",
            "          [-1.9240e-02, -2.5462e-02, -3.7559e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8641e-02,  5.1524e-03,  4.0639e-02],\n",
            "          [ 1.4711e-02, -5.1846e-02, -1.3381e-02],\n",
            "          [-1.2564e-02,  4.3656e-02,  2.9459e-02]],\n",
            "\n",
            "         [[ 2.5456e-02, -2.1583e-02, -1.7562e-03],\n",
            "          [-2.9417e-03,  1.4950e-02, -4.5875e-02],\n",
            "          [-1.3552e-02, -3.3755e-02, -1.1766e-02]],\n",
            "\n",
            "         [[-5.7903e-02, -9.0666e-03, -3.3530e-02],\n",
            "          [ 1.6275e-02,  2.2725e-02,  4.1409e-02],\n",
            "          [ 3.3421e-02, -4.1847e-02, -3.3518e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8453e-02,  3.0810e-02, -4.1492e-02],\n",
            "          [-4.9423e-04, -1.5643e-02, -9.2124e-05],\n",
            "          [ 3.8616e-02,  5.6951e-02, -8.8304e-03]],\n",
            "\n",
            "         [[-3.4053e-02,  5.7430e-02, -5.2374e-02],\n",
            "          [ 7.4370e-03,  4.7341e-02, -1.1173e-02],\n",
            "          [-2.9683e-02,  4.2699e-02,  1.0138e-02]],\n",
            "\n",
            "         [[ 1.4564e-02,  4.0759e-02,  3.0126e-02],\n",
            "          [-4.3103e-02,  3.3635e-02, -3.7708e-03],\n",
            "          [-4.5272e-02,  4.4780e-02,  3.5606e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9362e-03, -4.5270e-02,  3.2289e-02],\n",
            "          [-1.6807e-02, -4.4908e-03, -3.3104e-02],\n",
            "          [-3.9801e-02, -1.2665e-02, -8.7887e-03]],\n",
            "\n",
            "         [[ 5.3640e-02,  4.6053e-02,  2.0436e-03],\n",
            "          [-1.4994e-03, -4.7443e-02,  3.9075e-02],\n",
            "          [-1.6432e-02, -5.1907e-02, -2.9914e-02]],\n",
            "\n",
            "         [[ 2.9734e-03,  1.2944e-02,  3.5550e-03],\n",
            "          [ 4.5563e-02, -4.2431e-03, -5.0833e-02],\n",
            "          [ 6.6308e-03,  4.3820e-02, -4.6857e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7160e-02, -4.5592e-02,  2.1544e-02],\n",
            "          [ 1.9051e-02,  2.2201e-02, -5.4873e-02],\n",
            "          [ 4.6079e-02,  4.9803e-02, -5.8571e-02]],\n",
            "\n",
            "         [[ 5.2928e-02, -5.1257e-03,  5.3019e-02],\n",
            "          [-2.8608e-02,  5.2892e-02, -1.0667e-02],\n",
            "          [-2.4313e-02, -7.1462e-03,  2.9066e-02]],\n",
            "\n",
            "         [[ 4.2359e-02,  2.2497e-02, -5.1829e-02],\n",
            "          [-5.7952e-02,  2.0746e-02, -5.8498e-02],\n",
            "          [-1.8216e-02, -3.7258e-03, -5.3728e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8317e-03, -4.4953e-02,  5.4703e-02],\n",
            "          [-4.5709e-02,  4.0591e-02, -1.4609e-02],\n",
            "          [-3.5994e-02, -2.0875e-02,  4.4330e-02]],\n",
            "\n",
            "         [[ 2.5360e-02, -5.0337e-02, -1.6996e-02],\n",
            "          [ 4.8848e-02,  1.2624e-02, -3.9590e-02],\n",
            "          [-4.1340e-02,  3.8589e-02,  4.0635e-02]],\n",
            "\n",
            "         [[-2.7707e-02, -4.9222e-02,  6.5755e-03],\n",
            "          [ 2.0375e-02, -3.3991e-02,  1.6203e-02],\n",
            "          [ 1.3942e-02,  5.4028e-02, -5.4231e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1345,  0.1554,  0.0753,  ...,  0.1563,  0.0141,  0.0370],\n",
            "        [ 0.0776,  0.0739,  0.0299,  ..., -0.0886, -0.0994,  0.0869],\n",
            "        [-0.1707, -0.1056,  0.0217,  ..., -0.1671, -0.1686,  0.1544],\n",
            "        ...,\n",
            "        [ 0.1737, -0.1332,  0.1021,  ...,  0.0214, -0.1230,  0.1506],\n",
            "        [ 0.0612,  0.0354, -0.0323,  ..., -0.0069,  0.1272, -0.1179],\n",
            "        [ 0.0882, -0.1238, -0.0774,  ...,  0.0117,  0.1326,  0.1735]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1345,  0.1554,  0.0753,  ...,  0.1563,  0.0141,  0.0370],\n",
            "        [ 0.0776,  0.0739,  0.0299,  ..., -0.0886, -0.0994,  0.0869],\n",
            "        [-0.1707, -0.1056,  0.0217,  ..., -0.1671, -0.1686,  0.1544],\n",
            "        ...,\n",
            "        [ 0.1737, -0.1332,  0.1021,  ...,  0.0214, -0.1230,  0.1506],\n",
            "        [ 0.0612,  0.0354, -0.0323,  ..., -0.0069,  0.1272, -0.1179],\n",
            "        [ 0.0882, -0.1238, -0.0774,  ...,  0.0117,  0.1326,  0.1735]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1903,  0.2198,  0.1065,  ..., -0.0110, -0.2199,  0.1569],\n",
            "        [ 0.2459,  0.1016, -0.0850,  ...,  0.2210,  0.0200,  0.0523],\n",
            "        [ 0.1097,  0.1046,  0.0423,  ..., -0.2061,  0.1741,  0.1329],\n",
            "        ...,\n",
            "        [-0.2453,  0.0792, -0.2213,  ...,  0.0881, -0.0387, -0.1407],\n",
            "        [-0.2055, -0.2485,  0.1241,  ...,  0.1913, -0.1581, -0.0015],\n",
            "        [ 0.0482,  0.0903, -0.2478,  ..., -0.1664,  0.2418, -0.0021]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1903,  0.2198,  0.1065,  ..., -0.0110, -0.2199,  0.1569],\n",
            "        [ 0.2459,  0.1016, -0.0850,  ...,  0.2210,  0.0200,  0.0523],\n",
            "        [ 0.1097,  0.1046,  0.0423,  ..., -0.2061,  0.1741,  0.1329],\n",
            "        ...,\n",
            "        [-0.2453,  0.0792, -0.2213,  ...,  0.0881, -0.0387, -0.1407],\n",
            "        [-0.2055, -0.2485,  0.1241,  ...,  0.1913, -0.1581, -0.0015],\n",
            "        [ 0.0482,  0.0903, -0.2478,  ..., -0.1664,  0.2418, -0.0021]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2876,  0.3324,  0.1610, -0.3267,  0.0446,  0.1245,  0.0588,  0.0660,\n",
            "          0.2966,  0.1187,  0.2646, -0.1781, -0.3497,  0.2936, -0.0980, -0.0855,\n",
            "          0.0322, -0.1500, -0.1887, -0.2218,  0.1134,  0.1128,  0.1815,  0.1799,\n",
            "         -0.3732,  0.3770, -0.1908, -0.0666,  0.2940,  0.1676, -0.1132,  0.3359],\n",
            "        [ 0.2693,  0.2526,  0.0457,  0.3344,  0.1400,  0.3594, -0.0472, -0.2504,\n",
            "         -0.0024, -0.0601, -0.1412, -0.1225,  0.2946, -0.3243,  0.1717,  0.3388,\n",
            "          0.3514, -0.0440, -0.0156,  0.0179, -0.1082,  0.1496, -0.0065, -0.3410,\n",
            "          0.0617,  0.3029,  0.2283, -0.0619, -0.3415, -0.0166, -0.3324,  0.2373],\n",
            "        [ 0.3718,  0.1536, -0.1285,  0.1325,  0.2936, -0.3619, -0.3065,  0.3395,\n",
            "          0.2661,  0.0847, -0.0894,  0.1175, -0.0485,  0.3726, -0.0551,  0.1704,\n",
            "          0.2330, -0.0829,  0.1621, -0.2405,  0.0042, -0.2313,  0.0014, -0.0303,\n",
            "         -0.3615,  0.0199, -0.1888, -0.1070, -0.3523, -0.3042, -0.2639,  0.1346],\n",
            "        [ 0.0220,  0.2461,  0.1544,  0.2919, -0.0088,  0.3688, -0.2728, -0.0831,\n",
            "          0.0794, -0.3264, -0.2222,  0.1773, -0.2044,  0.0425,  0.2537,  0.3493,\n",
            "         -0.1775, -0.3320, -0.1200,  0.1926,  0.0255,  0.1778, -0.2897, -0.3766,\n",
            "         -0.2204,  0.1639, -0.1122,  0.3449,  0.1931,  0.3341,  0.0302,  0.0791],\n",
            "        [ 0.1659,  0.1581,  0.0640, -0.2330,  0.1653, -0.1465,  0.1987,  0.1287,\n",
            "         -0.0574,  0.2905,  0.3487,  0.2831, -0.2610,  0.3678, -0.0913,  0.1569,\n",
            "          0.0292, -0.2788, -0.1731, -0.2915,  0.2259,  0.1612,  0.3578, -0.3176,\n",
            "         -0.0024,  0.2828,  0.3750,  0.3640, -0.1596, -0.2755, -0.1410,  0.2619],\n",
            "        [-0.1277,  0.0303,  0.1724, -0.2758, -0.0612,  0.1635,  0.2044, -0.2215,\n",
            "          0.3003, -0.0222,  0.1329, -0.0526,  0.1186, -0.0493,  0.1521, -0.1209,\n",
            "         -0.3676,  0.1067, -0.2567, -0.3178,  0.1740, -0.1226,  0.2126, -0.1293,\n",
            "          0.3338, -0.0593,  0.0644,  0.3663, -0.3504, -0.3116,  0.2632,  0.2009],\n",
            "        [ 0.3360,  0.1896,  0.1881,  0.2605, -0.2705, -0.3571,  0.1134,  0.3317,\n",
            "          0.2843,  0.1291,  0.0860,  0.3087,  0.3420,  0.1620,  0.3090, -0.0063,\n",
            "         -0.0511, -0.0883,  0.0013, -0.1205,  0.2943, -0.0929, -0.0650,  0.1938,\n",
            "          0.2806, -0.2008,  0.0719,  0.1736, -0.3436,  0.2210, -0.2587, -0.0619],\n",
            "        [-0.2896, -0.0970,  0.2001, -0.1918, -0.2368, -0.3368, -0.3487, -0.2831,\n",
            "         -0.0249,  0.1367, -0.2578, -0.3531, -0.0714, -0.0308,  0.0823,  0.3769,\n",
            "          0.1515, -0.3381, -0.0591,  0.2992, -0.2515,  0.1517, -0.0268,  0.1605,\n",
            "         -0.1250,  0.2620, -0.2167,  0.2611,  0.0937, -0.1894, -0.2125,  0.1859],\n",
            "        [-0.3650, -0.2258,  0.0464,  0.0498,  0.0715, -0.2203, -0.2623,  0.0038,\n",
            "         -0.0955,  0.3286, -0.3669, -0.0968, -0.2665,  0.0145,  0.0523,  0.1307,\n",
            "         -0.0229,  0.2240,  0.3240, -0.0756, -0.0784,  0.0360, -0.1680,  0.0904,\n",
            "          0.1639,  0.3041,  0.3191, -0.1143,  0.1315, -0.2486,  0.1517,  0.3695],\n",
            "        [-0.1322,  0.2391, -0.3609,  0.2071,  0.0586,  0.3114,  0.0107,  0.2996,\n",
            "          0.0325, -0.2288, -0.1049,  0.3442, -0.2632,  0.3412,  0.1935,  0.0880,\n",
            "          0.1062, -0.1627, -0.3035,  0.0522,  0.2958,  0.3057,  0.0758, -0.2122,\n",
            "         -0.0681,  0.2893, -0.2608,  0.3305, -0.3759, -0.1999,  0.3105,  0.1000]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2876,  0.3324,  0.1610, -0.3267,  0.0446,  0.1245,  0.0588,  0.0660,\n",
            "          0.2966,  0.1187,  0.2646, -0.1781, -0.3497,  0.2936, -0.0980, -0.0855,\n",
            "          0.0322, -0.1500, -0.1887, -0.2218,  0.1134,  0.1128,  0.1815,  0.1799,\n",
            "         -0.3732,  0.3770, -0.1908, -0.0666,  0.2940,  0.1676, -0.1132,  0.3359],\n",
            "        [ 0.2693,  0.2526,  0.0457,  0.3344,  0.1400,  0.3594, -0.0472, -0.2504,\n",
            "         -0.0024, -0.0601, -0.1412, -0.1225,  0.2946, -0.3243,  0.1717,  0.3388,\n",
            "          0.3514, -0.0440, -0.0156,  0.0179, -0.1082,  0.1496, -0.0065, -0.3410,\n",
            "          0.0617,  0.3029,  0.2283, -0.0619, -0.3415, -0.0166, -0.3324,  0.2373],\n",
            "        [ 0.3718,  0.1536, -0.1285,  0.1325,  0.2936, -0.3619, -0.3065,  0.3395,\n",
            "          0.2661,  0.0847, -0.0894,  0.1175, -0.0485,  0.3726, -0.0551,  0.1704,\n",
            "          0.2330, -0.0829,  0.1621, -0.2405,  0.0042, -0.2313,  0.0014, -0.0303,\n",
            "         -0.3615,  0.0199, -0.1888, -0.1070, -0.3523, -0.3042, -0.2639,  0.1346],\n",
            "        [ 0.0220,  0.2461,  0.1544,  0.2919, -0.0088,  0.3688, -0.2728, -0.0831,\n",
            "          0.0794, -0.3264, -0.2222,  0.1773, -0.2044,  0.0425,  0.2537,  0.3493,\n",
            "         -0.1775, -0.3320, -0.1200,  0.1926,  0.0255,  0.1778, -0.2897, -0.3766,\n",
            "         -0.2204,  0.1639, -0.1122,  0.3449,  0.1931,  0.3341,  0.0302,  0.0791],\n",
            "        [ 0.1659,  0.1581,  0.0640, -0.2330,  0.1653, -0.1465,  0.1987,  0.1287,\n",
            "         -0.0574,  0.2905,  0.3487,  0.2831, -0.2610,  0.3678, -0.0913,  0.1569,\n",
            "          0.0292, -0.2788, -0.1731, -0.2915,  0.2259,  0.1612,  0.3578, -0.3176,\n",
            "         -0.0024,  0.2828,  0.3750,  0.3640, -0.1596, -0.2755, -0.1410,  0.2619],\n",
            "        [-0.1277,  0.0303,  0.1724, -0.2758, -0.0612,  0.1635,  0.2044, -0.2215,\n",
            "          0.3003, -0.0222,  0.1329, -0.0526,  0.1186, -0.0493,  0.1521, -0.1209,\n",
            "         -0.3676,  0.1067, -0.2567, -0.3178,  0.1740, -0.1226,  0.2126, -0.1293,\n",
            "          0.3338, -0.0593,  0.0644,  0.3663, -0.3504, -0.3116,  0.2632,  0.2009],\n",
            "        [ 0.3360,  0.1896,  0.1881,  0.2605, -0.2705, -0.3571,  0.1134,  0.3317,\n",
            "          0.2843,  0.1291,  0.0860,  0.3087,  0.3420,  0.1620,  0.3090, -0.0063,\n",
            "         -0.0511, -0.0883,  0.0013, -0.1205,  0.2943, -0.0929, -0.0650,  0.1938,\n",
            "          0.2806, -0.2008,  0.0719,  0.1736, -0.3436,  0.2210, -0.2587, -0.0619],\n",
            "        [-0.2896, -0.0970,  0.2001, -0.1918, -0.2368, -0.3368, -0.3487, -0.2831,\n",
            "         -0.0249,  0.1367, -0.2578, -0.3531, -0.0714, -0.0308,  0.0823,  0.3769,\n",
            "          0.1515, -0.3381, -0.0591,  0.2992, -0.2515,  0.1517, -0.0268,  0.1605,\n",
            "         -0.1250,  0.2620, -0.2167,  0.2611,  0.0937, -0.1894, -0.2125,  0.1859],\n",
            "        [-0.3650, -0.2258,  0.0464,  0.0498,  0.0715, -0.2203, -0.2623,  0.0038,\n",
            "         -0.0955,  0.3286, -0.3669, -0.0968, -0.2665,  0.0145,  0.0523,  0.1307,\n",
            "         -0.0229,  0.2240,  0.3240, -0.0756, -0.0784,  0.0360, -0.1680,  0.0904,\n",
            "          0.1639,  0.3041,  0.3191, -0.1143,  0.1315, -0.2486,  0.1517,  0.3695],\n",
            "        [-0.1322,  0.2391, -0.3609,  0.2071,  0.0586,  0.3114,  0.0107,  0.2996,\n",
            "          0.0325, -0.2288, -0.1049,  0.3442, -0.2632,  0.3412,  0.1935,  0.0880,\n",
            "          0.1062, -0.1627, -0.3035,  0.0522,  0.2958,  0.3057,  0.0758, -0.2122,\n",
            "         -0.0681,  0.2893, -0.2608,  0.3305, -0.3759, -0.1999,  0.3105,  0.1000]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.5621,  0.6494,  0.3145, -0.6385,  0.0871,  0.2434,  0.1149,  0.1290,\n",
            "          0.5796,  0.2319]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.5621,  0.6494,  0.3145, -0.6385,  0.0871,  0.2434,  0.1149,  0.1290,\n",
            "          0.5796,  0.2319]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Focus(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (dropout1): Dropout2d(p=0.05, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9"
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I"
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX"
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7"
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_focus = optim.Adam(focus_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "# optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer_classify = optim.Adam(classify.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "# optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylCWkAlwv6EL"
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQASTbrKv586",
        "outputId": "8fe2f216-6a41-4362-8ac1-691d28ffe674",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 33 %\n",
            "total correct 10063\n",
            "total train set images 30000\n",
            "focus_true_pred_true 1038 =============> FTPT : 3 %\n",
            "focus_false_pred_true 9025 =============> FFPT : 30 %\n",
            "focus_true_pred_false 2190 =============> FTPF : 7 %\n",
            "focus_false_pred_false 17747 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  3\n",
            "argmax_less_than_half ==================>  29997\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZmkgV3cv55D",
        "outputId": "80700480-e035-4f43-bee9-8e0a0e05bb72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 34 %\n",
            "total correct 3401\n",
            "total train set images 10000\n",
            "focus_true_pred_true 314 =============> FTPT : 3 %\n",
            "focus_false_pred_true 3087 =============> FFPT : 30 %\n",
            "focus_true_pred_false 672 =============> FTPF : 6 %\n",
            "focus_false_pred_false 5927 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  0\n",
            "argmax_less_than_half ==================>  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFfAJZkcZEsY",
        "outputId": "30f74e72-455f-4bf8-8927-d2ba8222bf71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nos_epochs = 300\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_focus.step()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    col1.append(epoch+1)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 1.060\n",
            "[1,   120] loss: 0.996\n",
            "[2,    60] loss: 0.911\n",
            "[2,   120] loss: 0.810\n",
            "[3,    60] loss: 0.729\n",
            "[3,   120] loss: 0.655\n",
            "[4,    60] loss: 0.584\n",
            "[4,   120] loss: 0.561\n",
            "[5,    60] loss: 0.509\n",
            "[5,   120] loss: 0.501\n",
            "[6,    60] loss: 0.455\n",
            "[6,   120] loss: 0.431\n",
            "[7,    60] loss: 0.389\n",
            "[7,   120] loss: 0.398\n",
            "[8,    60] loss: 0.362\n",
            "[8,   120] loss: 0.350\n",
            "[9,    60] loss: 0.311\n",
            "[9,   120] loss: 0.316\n",
            "[10,    60] loss: 0.271\n",
            "[10,   120] loss: 0.280\n",
            "[11,    60] loss: 0.264\n",
            "[11,   120] loss: 0.266\n",
            "[12,    60] loss: 0.246\n",
            "[12,   120] loss: 0.242\n",
            "[13,    60] loss: 0.198\n",
            "[13,   120] loss: 0.219\n",
            "[14,    60] loss: 0.187\n",
            "[14,   120] loss: 0.202\n",
            "[15,    60] loss: 0.176\n",
            "[15,   120] loss: 0.190\n",
            "[16,    60] loss: 0.173\n",
            "[16,   120] loss: 0.175\n",
            "[17,    60] loss: 0.158\n",
            "[17,   120] loss: 0.150\n",
            "[18,    60] loss: 0.123\n",
            "[18,   120] loss: 0.138\n",
            "[19,    60] loss: 0.131\n",
            "[19,   120] loss: 0.132\n",
            "[20,    60] loss: 0.121\n",
            "[20,   120] loss: 0.138\n",
            "[21,    60] loss: 0.112\n",
            "[21,   120] loss: 0.112\n",
            "[22,    60] loss: 0.103\n",
            "[22,   120] loss: 0.110\n",
            "[23,    60] loss: 0.101\n",
            "[23,   120] loss: 0.110\n",
            "[24,    60] loss: 0.107\n",
            "[24,   120] loss: 0.103\n",
            "[25,    60] loss: 0.090\n",
            "[25,   120] loss: 0.098\n",
            "[26,    60] loss: 0.075\n",
            "[26,   120] loss: 0.079\n",
            "[27,    60] loss: 0.090\n",
            "[27,   120] loss: 0.082\n",
            "[28,    60] loss: 0.070\n",
            "[28,   120] loss: 0.078\n",
            "[29,    60] loss: 0.063\n",
            "[29,   120] loss: 0.069\n",
            "[30,    60] loss: 0.062\n",
            "[30,   120] loss: 0.073\n",
            "[31,    60] loss: 0.071\n",
            "[31,   120] loss: 0.066\n",
            "[32,    60] loss: 0.064\n",
            "[32,   120] loss: 0.067\n",
            "[33,    60] loss: 0.060\n",
            "[33,   120] loss: 0.068\n",
            "[34,    60] loss: 0.051\n",
            "[34,   120] loss: 0.049\n",
            "[35,    60] loss: 0.060\n",
            "[35,   120] loss: 0.059\n",
            "[36,    60] loss: 0.057\n",
            "[36,   120] loss: 0.059\n",
            "[37,    60] loss: 0.051\n",
            "[37,   120] loss: 0.050\n",
            "[38,    60] loss: 0.047\n",
            "[38,   120] loss: 0.056\n",
            "[39,    60] loss: 0.045\n",
            "[39,   120] loss: 0.050\n",
            "[40,    60] loss: 0.053\n",
            "[40,   120] loss: 0.054\n",
            "[41,    60] loss: 0.048\n",
            "[41,   120] loss: 0.062\n",
            "[42,    60] loss: 0.045\n",
            "[42,   120] loss: 0.042\n",
            "[43,    60] loss: 0.041\n",
            "[43,   120] loss: 0.038\n",
            "[44,    60] loss: 0.038\n",
            "[44,   120] loss: 0.045\n",
            "[45,    60] loss: 0.045\n",
            "[45,   120] loss: 0.055\n",
            "[46,    60] loss: 0.046\n",
            "[46,   120] loss: 0.047\n",
            "[47,    60] loss: 0.044\n",
            "[47,   120] loss: 0.038\n",
            "[48,    60] loss: 0.040\n",
            "[48,   120] loss: 0.037\n",
            "[49,    60] loss: 0.044\n",
            "[49,   120] loss: 0.053\n",
            "[50,    60] loss: 0.033\n",
            "[50,   120] loss: 0.028\n",
            "[51,    60] loss: 0.038\n",
            "[51,   120] loss: 0.035\n",
            "[52,    60] loss: 0.028\n",
            "[52,   120] loss: 0.033\n",
            "[53,    60] loss: 0.025\n",
            "[53,   120] loss: 0.043\n",
            "[54,    60] loss: 0.028\n",
            "[54,   120] loss: 0.037\n",
            "[55,    60] loss: 0.030\n",
            "[55,   120] loss: 0.027\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "outputId": "26d688ee-77e4-4ae1-b9f9-0317cc3a1c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "name = \"focus_random_classify_random_train_both_\"+str(k)\n",
        "name"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'focus_random_classify_random_train_both_1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE"
      },
      "source": [
        "#torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/focus_net_params_multiplied_by_k/\"+name+\".pt\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o"
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO"
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "outputId": "8a6810b9-e61f-4554-e616-3836071761b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "df_train"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>29997</td>\n",
              "      <td>1038</td>\n",
              "      <td>9025</td>\n",
              "      <td>2190</td>\n",
              "      <td>17747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15191</td>\n",
              "      <td>14809</td>\n",
              "      <td>6059</td>\n",
              "      <td>8122</td>\n",
              "      <td>2628</td>\n",
              "      <td>13191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>20148</td>\n",
              "      <td>9852</td>\n",
              "      <td>18335</td>\n",
              "      <td>6120</td>\n",
              "      <td>1908</td>\n",
              "      <td>3637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>24395</td>\n",
              "      <td>5605</td>\n",
              "      <td>21875</td>\n",
              "      <td>5166</td>\n",
              "      <td>1003</td>\n",
              "      <td>1956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>24768</td>\n",
              "      <td>5232</td>\n",
              "      <td>23554</td>\n",
              "      <td>4647</td>\n",
              "      <td>550</td>\n",
              "      <td>1249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>25414</td>\n",
              "      <td>4586</td>\n",
              "      <td>24430</td>\n",
              "      <td>4480</td>\n",
              "      <td>305</td>\n",
              "      <td>785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>25630</td>\n",
              "      <td>4370</td>\n",
              "      <td>25198</td>\n",
              "      <td>4066</td>\n",
              "      <td>226</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>25680</td>\n",
              "      <td>4320</td>\n",
              "      <td>25258</td>\n",
              "      <td>4074</td>\n",
              "      <td>186</td>\n",
              "      <td>482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>25524</td>\n",
              "      <td>4476</td>\n",
              "      <td>25273</td>\n",
              "      <td>4179</td>\n",
              "      <td>165</td>\n",
              "      <td>383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>25387</td>\n",
              "      <td>4613</td>\n",
              "      <td>25358</td>\n",
              "      <td>4108</td>\n",
              "      <td>150</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>25187</td>\n",
              "      <td>4813</td>\n",
              "      <td>25446</td>\n",
              "      <td>4111</td>\n",
              "      <td>129</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>51</td>\n",
              "      <td>25176</td>\n",
              "      <td>4824</td>\n",
              "      <td>25630</td>\n",
              "      <td>4034</td>\n",
              "      <td>97</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0             3  ...                   2190                   17747\n",
              "1        1         15191  ...                   2628                   13191\n",
              "2        6         20148  ...                   1908                    3637\n",
              "3       11         24395  ...                   1003                    1956\n",
              "4       16         24768  ...                    550                    1249\n",
              "5       21         25414  ...                    305                     785\n",
              "6       26         25630  ...                    226                     510\n",
              "7       31         25680  ...                    186                     482\n",
              "8       36         25524  ...                    165                     383\n",
              "9       41         25387  ...                    150                     384\n",
              "10      46         25187  ...                    129                     314\n",
              "11      51         25176  ...                     97                     239\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "outputId": "12ae1e08-2059-4ef3-e6d5-8fa78ee54c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "outputId": "e932b7e8-8632-42b2-8af3-99fe2a8f345c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "df_test"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>314</td>\n",
              "      <td>3087</td>\n",
              "      <td>672</td>\n",
              "      <td>5927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4395</td>\n",
              "      <td>5605</td>\n",
              "      <td>2617</td>\n",
              "      <td>2801</td>\n",
              "      <td>1084</td>\n",
              "      <td>3498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>7387</td>\n",
              "      <td>2613</td>\n",
              "      <td>6026</td>\n",
              "      <td>1969</td>\n",
              "      <td>730</td>\n",
              "      <td>1275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>7950</td>\n",
              "      <td>2050</td>\n",
              "      <td>7105</td>\n",
              "      <td>1630</td>\n",
              "      <td>407</td>\n",
              "      <td>858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>8353</td>\n",
              "      <td>1647</td>\n",
              "      <td>7574</td>\n",
              "      <td>1477</td>\n",
              "      <td>297</td>\n",
              "      <td>652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>8446</td>\n",
              "      <td>1554</td>\n",
              "      <td>7835</td>\n",
              "      <td>1406</td>\n",
              "      <td>240</td>\n",
              "      <td>519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>8357</td>\n",
              "      <td>1643</td>\n",
              "      <td>8013</td>\n",
              "      <td>1309</td>\n",
              "      <td>204</td>\n",
              "      <td>474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>8308</td>\n",
              "      <td>1692</td>\n",
              "      <td>8193</td>\n",
              "      <td>1166</td>\n",
              "      <td>204</td>\n",
              "      <td>437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>8651</td>\n",
              "      <td>1349</td>\n",
              "      <td>8067</td>\n",
              "      <td>1256</td>\n",
              "      <td>171</td>\n",
              "      <td>506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>8392</td>\n",
              "      <td>1608</td>\n",
              "      <td>8131</td>\n",
              "      <td>1239</td>\n",
              "      <td>186</td>\n",
              "      <td>444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>8290</td>\n",
              "      <td>1710</td>\n",
              "      <td>8118</td>\n",
              "      <td>1313</td>\n",
              "      <td>211</td>\n",
              "      <td>358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>51</td>\n",
              "      <td>8242</td>\n",
              "      <td>1758</td>\n",
              "      <td>8155</td>\n",
              "      <td>1294</td>\n",
              "      <td>202</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0             0  ...                    672                    5927\n",
              "1        1          4395  ...                   1084                    3498\n",
              "2        6          7387  ...                    730                    1275\n",
              "3       11          7950  ...                    407                     858\n",
              "4       16          8353  ...                    297                     652\n",
              "5       21          8446  ...                    240                     519\n",
              "6       26          8357  ...                    204                     474\n",
              "7       31          8308  ...                    204                     437\n",
              "8       36          8651  ...                    171                     506\n",
              "9       41          8392  ...                    186                     444\n",
              "10      46          8290  ...                    211                     358\n",
              "11      51          8242  ...                    202                     349\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "outputId": "aedef7a1-75f0-4361-e0ce-c649074cfde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLfaVcgE7pK",
        "outputId": "8fb81e25-bf21-40ad-84e7-ccf1d8d7ba08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29739\n",
            "total train set images 30000\n",
            "focus_true_pred_true 25385 =============> FTPT : 84 %\n",
            "focus_false_pred_true 4354 =============> FFPT : 14 %\n",
            "focus_true_pred_false 76 =============> FTPF : 0 %\n",
            "focus_false_pred_false 185 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  24857\n",
            "argmax_less_than_half ==================>  5143\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cSh5sGfFAlg",
        "outputId": "5bc3772d-13be-49f0-cf52-39c8e353c775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 94 %\n",
            "total correct 9421\n",
            "total train set images 10000\n",
            "focus_true_pred_true 8096 =============> FTPT : 80 %\n",
            "focus_false_pred_true 1325 =============> FFPT : 13 %\n",
            "focus_true_pred_false 184 =============> FTPF : 1 %\n",
            "focus_false_pred_false 395 =============> FFPF : 3 %\n",
            "argmax_more_than_half ==================>  8151\n",
            "argmax_less_than_half ==================>  1849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "outputId": "849c2c90-d044-4494-fab4-30c1b0011e46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "                                            correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29751\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "outputId": "a8e60e48-1bb3-4cc6-9737-6576f9daebdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 94 %\n",
            "total correct 9433\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HoIweZX_o3O"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}