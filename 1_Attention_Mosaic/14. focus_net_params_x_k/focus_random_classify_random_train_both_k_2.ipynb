{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "focus_random_classify_random_train_both_k_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjG64ra4aFu"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-7SARDZErK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acRFqJNrZErV",
        "outputId": "acf0d3c5-88eb-4009-f1b8-cedd96a56f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3BOnEFUZOLx"
      },
      "source": [
        "k = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_JUhwCeZErk"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SadRzWBBZEsP"
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w"
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM"
      },
      "source": [
        "def init_weights(m,k=2):\n",
        "  if type(m) == nn.Linear:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)\n",
        "  if type(m) == nn.Conv2d:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhjiW2hKZTCY",
        "outputId": "fcbfadd9-06f8-42a8-c5b7-6267d135bf2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "focus_net.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.1050,  0.1214,  0.0588],\n",
            "          [-0.1193,  0.0163,  0.0455],\n",
            "          [ 0.0215,  0.0241,  0.1083]],\n",
            "\n",
            "         [[ 0.0433,  0.0966, -0.0650],\n",
            "          [-0.1277,  0.1072, -0.0358],\n",
            "          [-0.0312,  0.0118, -0.0548]],\n",
            "\n",
            "         [[-0.0689, -0.0810,  0.0414],\n",
            "          [ 0.0412,  0.0663,  0.0657],\n",
            "          [-0.1363,  0.1377, -0.0697]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243,  0.1074,  0.0612],\n",
            "          [-0.0413,  0.1226,  0.0983],\n",
            "          [ 0.0922,  0.0167,  0.1221]],\n",
            "\n",
            "         [[ 0.0511,  0.1312, -0.0172],\n",
            "          [-0.0914, -0.0009, -0.0219],\n",
            "          [-0.0516, -0.0447,  0.1076]],\n",
            "\n",
            "         [[-0.1184,  0.0627,  0.1237],\n",
            "          [ 0.1283, -0.0161, -0.0057],\n",
            "          [ 0.0065, -0.0395,  0.0546]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024, -0.1245,  0.0225],\n",
            "          [ 0.1106,  0.0834, -0.0226],\n",
            "          [-0.1247, -0.0061, -0.1214]],\n",
            "\n",
            "         [[ 0.0866,  0.1358,  0.0561],\n",
            "          [-0.0469,  0.0484,  0.1072],\n",
            "          [-0.1322, -0.1119,  0.1240]],\n",
            "\n",
            "         [[ 0.0972,  0.0309, -0.0326],\n",
            "          [ 0.0429, -0.0177,  0.1361],\n",
            "          [-0.0201,  0.0622,  0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0303,  0.0592, -0.0878],\n",
            "          [ 0.0015, -0.0844,  0.0005],\n",
            "          [-0.0110, -0.1320,  0.0073]],\n",
            "\n",
            "         [[-0.0690, -0.0391, -0.1286],\n",
            "          [-0.1111, -0.0964,  0.0491],\n",
            "          [ 0.0080,  0.0899,  0.0564]],\n",
            "\n",
            "         [[ 0.1066, -0.0032,  0.1346],\n",
            "          [-0.0996, -0.0303,  0.0290],\n",
            "          [-0.1192, -0.0811,  0.0647]]],\n",
            "\n",
            "\n",
            "        [[[-0.0746,  0.0155,  0.0927],\n",
            "          [ 0.1275, -0.0648, -0.1212],\n",
            "          [-0.0438,  0.0703,  0.0093]],\n",
            "\n",
            "         [[ 0.0649, -0.1058, -0.1375],\n",
            "          [-0.0805,  0.0599, -0.0410],\n",
            "          [ 0.1259,  0.0705,  0.1220]],\n",
            "\n",
            "         [[ 0.0110,  0.0289,  0.0606],\n",
            "          [ 0.0577,  0.0234, -0.0851],\n",
            "          [ 0.0604, -0.0535,  0.0725]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0470, -0.0210,  0.1061],\n",
            "          [ 0.1273,  0.1034, -0.0953],\n",
            "          [ 0.1343, -0.0333,  0.0573]],\n",
            "\n",
            "         [[ 0.0107, -0.1018, -0.0632],\n",
            "          [-0.1064,  0.0825,  0.0589],\n",
            "          [ 0.1306, -0.1160, -0.0009]],\n",
            "\n",
            "         [[ 0.1033,  0.1369,  0.1329],\n",
            "          [-0.0583, -0.1006, -0.0515],\n",
            "          [ 0.0956, -0.0466,  0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0630, -0.1007, -0.0224],\n",
            "          [ 0.0597,  0.0746, -0.0809],\n",
            "          [ 0.1096, -0.0081,  0.0485]],\n",
            "\n",
            "         [[-0.0192,  0.0433, -0.0180],\n",
            "          [ 0.0555, -0.0442, -0.1342],\n",
            "          [ 0.0390, -0.0937, -0.1160]],\n",
            "\n",
            "         [[ 0.0635, -0.0448,  0.0776],\n",
            "          [-0.0472,  0.1219, -0.0217],\n",
            "          [ 0.0235,  0.1338, -0.1280]]],\n",
            "\n",
            "\n",
            "        [[[-0.1138,  0.0961,  0.0734],\n",
            "          [ 0.1227,  0.0692,  0.0687],\n",
            "          [ 0.0951, -0.0988, -0.1304]],\n",
            "\n",
            "         [[ 0.0414,  0.1211,  0.1038],\n",
            "          [ 0.0472,  0.0314,  0.1127],\n",
            "          [ 0.1249,  0.0592,  0.1128]],\n",
            "\n",
            "         [[-0.0023, -0.0187, -0.0323],\n",
            "          [ 0.0005, -0.0440,  0.1075],\n",
            "          [-0.0339, -0.0237,  0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1025, -0.0733,  0.0263],\n",
            "          [ 0.0634, -0.1255,  0.0807],\n",
            "          [-0.0945, -0.0226, -0.1057]],\n",
            "\n",
            "         [[-0.0354,  0.0731, -0.0700],\n",
            "          [-0.0865, -0.1230, -0.1273],\n",
            "          [-0.1034, -0.0091,  0.0499]],\n",
            "\n",
            "         [[-0.0941, -0.1289, -0.0261],\n",
            "          [-0.0112,  0.0301,  0.1376],\n",
            "          [ 0.0553, -0.1234, -0.0216]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1093, -0.0918,  0.0554],\n",
            "          [-0.0098,  0.0586, -0.0456],\n",
            "          [ 0.0957, -0.0791,  0.0954]],\n",
            "\n",
            "         [[ 0.0342, -0.0692, -0.0776],\n",
            "          [ 0.0679, -0.1333, -0.0824],\n",
            "          [ 0.0169,  0.0182,  0.0261]],\n",
            "\n",
            "         [[-0.0804, -0.0958,  0.0014],\n",
            "          [-0.0349,  0.1200, -0.1340],\n",
            "          [-0.0353, -0.0973,  0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0191,  0.0477, -0.0084],\n",
            "          [ 0.0818,  0.1183, -0.0276],\n",
            "          [-0.0286,  0.0132, -0.0614]],\n",
            "\n",
            "         [[ 0.0330,  0.0598,  0.1111],\n",
            "          [ 0.1165, -0.0417,  0.0480],\n",
            "          [-0.0908,  0.0554,  0.1349]],\n",
            "\n",
            "         [[-0.0483,  0.0873, -0.1318],\n",
            "          [ 0.0756,  0.0214,  0.1137],\n",
            "          [ 0.0039,  0.1094,  0.0119]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0383,  0.1257],\n",
            "          [-0.0961,  0.1246,  0.0706],\n",
            "          [ 0.0321,  0.0388, -0.0594]],\n",
            "\n",
            "         [[-0.1108,  0.0191,  0.1080],\n",
            "          [ 0.1116,  0.0277, -0.0775],\n",
            "          [-0.0249,  0.1057, -0.0952]],\n",
            "\n",
            "         [[ 0.1207, -0.1373, -0.0730],\n",
            "          [ 0.1134,  0.0365, -0.0702],\n",
            "          [-0.0340, -0.1309, -0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1354,  0.1205, -0.1124],\n",
            "          [-0.0645, -0.0902,  0.1234],\n",
            "          [-0.0884,  0.0080,  0.0424]],\n",
            "\n",
            "         [[-0.0670,  0.0203, -0.0854],\n",
            "          [ 0.0503, -0.0132,  0.1265],\n",
            "          [-0.0972,  0.0498,  0.1150]],\n",
            "\n",
            "         [[-0.1209,  0.1248,  0.0428],\n",
            "          [-0.0510,  0.0816,  0.0532],\n",
            "          [-0.0520, -0.0577,  0.1087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1126,  0.0255, -0.1296],\n",
            "          [ 0.0378,  0.0466, -0.0572],\n",
            "          [ 0.0232, -0.0410,  0.1117]],\n",
            "\n",
            "         [[ 0.0124, -0.1374,  0.1032],\n",
            "          [-0.0838, -0.1037,  0.0993],\n",
            "          [-0.0971,  0.0112,  0.1063]],\n",
            "\n",
            "         [[-0.1211,  0.1292, -0.0956],\n",
            "          [ 0.0564, -0.1087,  0.0525],\n",
            "          [ 0.1237,  0.0084,  0.0690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0790,  0.0170,  0.1157],\n",
            "          [-0.1304, -0.1316,  0.1206],\n",
            "          [ 0.1354, -0.1357,  0.0203]],\n",
            "\n",
            "         [[ 0.0671,  0.0099,  0.0534],\n",
            "          [ 0.0526, -0.0304,  0.0219],\n",
            "          [-0.0585,  0.0089, -0.0224]],\n",
            "\n",
            "         [[-0.0058, -0.0208,  0.0841],\n",
            "          [ 0.0215, -0.0465, -0.0621],\n",
            "          [-0.1283,  0.1176, -0.0754]]],\n",
            "\n",
            "\n",
            "        [[[-0.0220,  0.0226,  0.0721],\n",
            "          [-0.0388, -0.0747,  0.0138],\n",
            "          [-0.0008,  0.1340,  0.0115]],\n",
            "\n",
            "         [[-0.1081,  0.1344,  0.0052],\n",
            "          [ 0.1110, -0.1306, -0.1088],\n",
            "          [-0.0309,  0.0023,  0.0570]],\n",
            "\n",
            "         [[-0.0560, -0.1184,  0.0920],\n",
            "          [ 0.0252, -0.0433,  0.0878],\n",
            "          [ 0.0069, -0.1082,  0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0770,  0.0946, -0.0880],\n",
            "          [-0.0460,  0.1173,  0.0226],\n",
            "          [ 0.0407,  0.0980, -0.0654]],\n",
            "\n",
            "         [[-0.0717, -0.0724,  0.0412],\n",
            "          [-0.0562,  0.0682, -0.0425],\n",
            "          [ 0.0033, -0.1061,  0.0760]],\n",
            "\n",
            "         [[-0.1020, -0.0190, -0.0219],\n",
            "          [ 0.0550, -0.0851,  0.1220],\n",
            "          [ 0.0055,  0.0560,  0.1111]]],\n",
            "\n",
            "\n",
            "        [[[-0.0951, -0.0374, -0.1315],\n",
            "          [-0.1089,  0.0229,  0.1351],\n",
            "          [ 0.0422,  0.1377, -0.1347]],\n",
            "\n",
            "         [[-0.0214, -0.0826, -0.1109],\n",
            "          [-0.0246, -0.0491,  0.0648],\n",
            "          [-0.0400,  0.1292, -0.0168]],\n",
            "\n",
            "         [[ 0.0885, -0.0273, -0.0782],\n",
            "          [-0.0131, -0.0099,  0.0111],\n",
            "          [ 0.0437, -0.1332, -0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0438,  0.1056],\n",
            "          [ 0.0402, -0.1309,  0.1371],\n",
            "          [ 0.1017,  0.0284, -0.0202]],\n",
            "\n",
            "         [[ 0.1244, -0.1375,  0.0282],\n",
            "          [ 0.1086,  0.1217,  0.0943],\n",
            "          [-0.0004,  0.0387, -0.0833]],\n",
            "\n",
            "         [[-0.0171, -0.0782, -0.0358],\n",
            "          [ 0.0075, -0.1302,  0.0208],\n",
            "          [-0.0873, -0.0959,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102, -0.1067, -0.1025],\n",
            "          [ 0.1116,  0.0266, -0.1028],\n",
            "          [-0.0635, -0.0708, -0.0697]],\n",
            "\n",
            "         [[ 0.0030,  0.0739, -0.0855],\n",
            "          [-0.0650,  0.1201, -0.0131],\n",
            "          [-0.0618, -0.0680, -0.0356]],\n",
            "\n",
            "         [[-0.0797, -0.1149,  0.0272],\n",
            "          [ 0.0520,  0.0685,  0.0054],\n",
            "          [-0.0097, -0.0302,  0.1144]]],\n",
            "\n",
            "\n",
            "        [[[-0.1193,  0.0028,  0.0314],\n",
            "          [-0.1280,  0.1190, -0.1014],\n",
            "          [-0.1231,  0.0703,  0.0279]],\n",
            "\n",
            "         [[ 0.0904, -0.1331, -0.0808],\n",
            "          [ 0.0591, -0.0654,  0.1076],\n",
            "          [-0.0453, -0.0707,  0.1021]],\n",
            "\n",
            "         [[-0.0887, -0.0770, -0.0189],\n",
            "          [ 0.0863, -0.0374, -0.0307],\n",
            "          [-0.1057,  0.0172, -0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0808, -0.1211, -0.0311],\n",
            "          [-0.1210,  0.1079,  0.1335],\n",
            "          [ 0.0941, -0.0931,  0.1172]],\n",
            "\n",
            "         [[ 0.0292,  0.0663,  0.1289],\n",
            "          [ 0.0864, -0.0247, -0.1160],\n",
            "          [-0.0783,  0.0210,  0.0308]],\n",
            "\n",
            "         [[-0.1219,  0.0811, -0.1078],\n",
            "          [ 0.1174,  0.0290, -0.0027],\n",
            "          [-0.0488, -0.0225,  0.0816]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1049,  0.0749, -0.1125],\n",
            "          [ 0.1378, -0.0721,  0.1281],\n",
            "          [-0.0777,  0.1362,  0.1164]],\n",
            "\n",
            "         [[ 0.0799,  0.0223,  0.1133],\n",
            "          [-0.0881,  0.0412,  0.0543],\n",
            "          [-0.0111, -0.0803, -0.0113]],\n",
            "\n",
            "         [[-0.0609,  0.0141, -0.0534],\n",
            "          [-0.1238,  0.0143,  0.0859],\n",
            "          [-0.0301, -0.0316,  0.0964]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0993,  0.1189, -0.0055],\n",
            "          [ 0.0014, -0.0976,  0.0031],\n",
            "          [ 0.0043,  0.1026, -0.1371]],\n",
            "\n",
            "         [[-0.0154, -0.1327, -0.1321],\n",
            "          [ 0.0735,  0.0689,  0.1124],\n",
            "          [ 0.0417,  0.0066, -0.0752]],\n",
            "\n",
            "         [[-0.1169, -0.0826, -0.0636],\n",
            "          [-0.0801,  0.0542,  0.1322],\n",
            "          [ 0.1274, -0.0805, -0.1321]]],\n",
            "\n",
            "\n",
            "        [[[-0.0321, -0.1013, -0.1340],\n",
            "          [ 0.0549,  0.1229,  0.0187],\n",
            "          [ 0.0635,  0.0855, -0.0793]],\n",
            "\n",
            "         [[ 0.0163,  0.0576, -0.0725],\n",
            "          [ 0.1349,  0.1338,  0.0424],\n",
            "          [-0.0565, -0.0271, -0.0065]],\n",
            "\n",
            "         [[ 0.1057, -0.0662,  0.0843],\n",
            "          [ 0.1218, -0.0181, -0.0132],\n",
            "          [-0.0224,  0.0711,  0.1373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458, -0.0240, -0.0642],\n",
            "          [-0.1284,  0.1301, -0.0221],\n",
            "          [ 0.0513,  0.0357,  0.0685]],\n",
            "\n",
            "         [[ 0.0447,  0.0482,  0.0202],\n",
            "          [ 0.1029, -0.0415,  0.0292],\n",
            "          [ 0.0927, -0.0914,  0.1029]],\n",
            "\n",
            "         [[ 0.0587, -0.0453, -0.0390],\n",
            "          [ 0.0402, -0.1310,  0.1291],\n",
            "          [-0.1203, -0.0834,  0.0932]]],\n",
            "\n",
            "\n",
            "        [[[-0.1195, -0.0345, -0.0670],\n",
            "          [ 0.0642, -0.0037, -0.0502],\n",
            "          [-0.0359,  0.0489,  0.0630]],\n",
            "\n",
            "         [[-0.0950,  0.1065,  0.0999],\n",
            "          [ 0.0028, -0.0237,  0.0881],\n",
            "          [ 0.1140, -0.1286,  0.0987]],\n",
            "\n",
            "         [[-0.0686, -0.0377,  0.0912],\n",
            "          [ 0.1366, -0.0975, -0.0507],\n",
            "          [-0.0163,  0.0094,  0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1173,  0.1334, -0.0506],\n",
            "          [-0.1283, -0.1268,  0.0220],\n",
            "          [ 0.0777, -0.0241, -0.0772]],\n",
            "\n",
            "         [[-0.0849, -0.0376,  0.0414],\n",
            "          [ 0.1200,  0.0639, -0.0089],\n",
            "          [-0.0256,  0.1346,  0.0802]],\n",
            "\n",
            "         [[-0.1187,  0.1279,  0.0268],\n",
            "          [ 0.0801, -0.0363, -0.1048],\n",
            "          [-0.0573, -0.0708,  0.0379]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0796, -0.0600,  0.0439],\n",
            "          [ 0.0550, -0.1245, -0.0892],\n",
            "          [-0.0474, -0.1210,  0.1336]],\n",
            "\n",
            "         [[ 0.0692,  0.0903, -0.0840],\n",
            "          [ 0.1243,  0.1076,  0.1367],\n",
            "          [-0.0511, -0.0784, -0.0105]],\n",
            "\n",
            "         [[ 0.0425, -0.0139,  0.1241],\n",
            "          [-0.0850,  0.0267,  0.0743],\n",
            "          [-0.1332, -0.0337, -0.0154]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0971, -0.0718, -0.0420],\n",
            "          [-0.1062,  0.1183, -0.1028],\n",
            "          [-0.0097,  0.0813, -0.0535]],\n",
            "\n",
            "         [[ 0.1279,  0.1208,  0.0060],\n",
            "          [-0.1352, -0.0636,  0.0192],\n",
            "          [-0.1363, -0.0039,  0.0833]],\n",
            "\n",
            "         [[-0.0234,  0.0114, -0.0031],\n",
            "          [ 0.1271,  0.0990, -0.0219],\n",
            "          [ 0.0717, -0.1184, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[-0.0752,  0.0160,  0.1106],\n",
            "          [-0.1226,  0.0359, -0.0675],\n",
            "          [-0.0148,  0.1298,  0.0941]],\n",
            "\n",
            "         [[ 0.0124, -0.0077, -0.1213],\n",
            "          [ 0.0115, -0.0320,  0.1001],\n",
            "          [ 0.0701,  0.0954, -0.0785]],\n",
            "\n",
            "         [[-0.1014,  0.0947,  0.0171],\n",
            "          [ 0.1316, -0.0220, -0.0368],\n",
            "          [ 0.0536,  0.0620, -0.0759]]],\n",
            "\n",
            "\n",
            "        [[[-0.0462,  0.0865, -0.0109],\n",
            "          [-0.0799, -0.0852,  0.0181],\n",
            "          [-0.0158,  0.0746,  0.1030]],\n",
            "\n",
            "         [[-0.0636,  0.0897, -0.0426],\n",
            "          [ 0.0369, -0.0393, -0.0056],\n",
            "          [-0.0294,  0.1296, -0.1235]],\n",
            "\n",
            "         [[ 0.0002,  0.0252,  0.1291],\n",
            "          [-0.0383,  0.0881,  0.0236],\n",
            "          [-0.0026, -0.0574, -0.0595]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.2101,  0.2427,  0.1175],\n",
            "          [-0.2386,  0.0326,  0.0909],\n",
            "          [ 0.0430,  0.0482,  0.2166]],\n",
            "\n",
            "         [[ 0.0867,  0.1932, -0.1301],\n",
            "          [-0.2554,  0.2144, -0.0716],\n",
            "          [-0.0625,  0.0235, -0.1095]],\n",
            "\n",
            "         [[-0.1378, -0.1620,  0.0828],\n",
            "          [ 0.0824,  0.1326,  0.1314],\n",
            "          [-0.2726,  0.2753, -0.1393]]],\n",
            "\n",
            "\n",
            "        [[[-0.0486,  0.2147,  0.1224],\n",
            "          [-0.0826,  0.2453,  0.1967],\n",
            "          [ 0.1845,  0.0333,  0.2442]],\n",
            "\n",
            "         [[ 0.1022,  0.2625, -0.0345],\n",
            "          [-0.1829, -0.0018, -0.0439],\n",
            "          [-0.1031, -0.0895,  0.2151]],\n",
            "\n",
            "         [[-0.2368,  0.1254,  0.2474],\n",
            "          [ 0.2566, -0.0321, -0.0114],\n",
            "          [ 0.0131, -0.0790,  0.1093]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047, -0.2490,  0.0451],\n",
            "          [ 0.2212,  0.1667, -0.0452],\n",
            "          [-0.2494, -0.0121, -0.2428]],\n",
            "\n",
            "         [[ 0.1733,  0.2715,  0.1122],\n",
            "          [-0.0938,  0.0967,  0.2144],\n",
            "          [-0.2643, -0.2238,  0.2479]],\n",
            "\n",
            "         [[ 0.1943,  0.0618, -0.0653],\n",
            "          [ 0.0858, -0.0354,  0.2721],\n",
            "          [-0.0403,  0.1245,  0.1702]]],\n",
            "\n",
            "\n",
            "        [[[-0.0605,  0.1184, -0.1756],\n",
            "          [ 0.0031, -0.1689,  0.0010],\n",
            "          [-0.0221, -0.2640,  0.0145]],\n",
            "\n",
            "         [[-0.1379, -0.0781, -0.2573],\n",
            "          [-0.2221, -0.1927,  0.0983],\n",
            "          [ 0.0161,  0.1797,  0.1128]],\n",
            "\n",
            "         [[ 0.2132, -0.0064,  0.2693],\n",
            "          [-0.1992, -0.0607,  0.0580],\n",
            "          [-0.2384, -0.1623,  0.1295]]],\n",
            "\n",
            "\n",
            "        [[[-0.1493,  0.0311,  0.1853],\n",
            "          [ 0.2551, -0.1297, -0.2425],\n",
            "          [-0.0877,  0.1407,  0.0186]],\n",
            "\n",
            "         [[ 0.1299, -0.2116, -0.2750],\n",
            "          [-0.1609,  0.1197, -0.0819],\n",
            "          [ 0.2519,  0.1410,  0.2440]],\n",
            "\n",
            "         [[ 0.0221,  0.0577,  0.1212],\n",
            "          [ 0.1155,  0.0468, -0.1701],\n",
            "          [ 0.1207, -0.1070,  0.1451]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0940, -0.0419,  0.2122],\n",
            "          [ 0.2547,  0.2067, -0.1906],\n",
            "          [ 0.2686, -0.0667,  0.1146]],\n",
            "\n",
            "         [[ 0.0213, -0.2036, -0.1264],\n",
            "          [-0.2129,  0.1650,  0.1177],\n",
            "          [ 0.2613, -0.2320, -0.0018]],\n",
            "\n",
            "         [[ 0.2066,  0.2739,  0.2658],\n",
            "          [-0.1165, -0.2012, -0.1030],\n",
            "          [ 0.1913, -0.0932,  0.0221]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1259, -0.2014, -0.0447],\n",
            "          [ 0.1194,  0.1493, -0.1618],\n",
            "          [ 0.2193, -0.0162,  0.0971]],\n",
            "\n",
            "         [[-0.0384,  0.0866, -0.0360],\n",
            "          [ 0.1111, -0.0883, -0.2685],\n",
            "          [ 0.0779, -0.1875, -0.2321]],\n",
            "\n",
            "         [[ 0.1271, -0.0896,  0.1552],\n",
            "          [-0.0944,  0.2437, -0.0433],\n",
            "          [ 0.0470,  0.2675, -0.2559]]],\n",
            "\n",
            "\n",
            "        [[[-0.2276,  0.1922,  0.1467],\n",
            "          [ 0.2453,  0.1385,  0.1373],\n",
            "          [ 0.1902, -0.1976, -0.2608]],\n",
            "\n",
            "         [[ 0.0828,  0.2423,  0.2076],\n",
            "          [ 0.0943,  0.0628,  0.2255],\n",
            "          [ 0.2497,  0.1183,  0.2256]],\n",
            "\n",
            "         [[-0.0046, -0.0373, -0.0645],\n",
            "          [ 0.0010, -0.0880,  0.2149],\n",
            "          [-0.0678, -0.0474,  0.1415]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2049, -0.1466,  0.0525],\n",
            "          [ 0.1268, -0.2509,  0.1614],\n",
            "          [-0.1889, -0.0452, -0.2115]],\n",
            "\n",
            "         [[-0.0709,  0.1461, -0.1401],\n",
            "          [-0.1729, -0.2460, -0.2547],\n",
            "          [-0.2067, -0.0182,  0.0998]],\n",
            "\n",
            "         [[-0.1883, -0.2579, -0.0521],\n",
            "          [-0.0225,  0.0601,  0.2752],\n",
            "          [ 0.1107, -0.2469, -0.0432]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2185, -0.1837,  0.1108],\n",
            "          [-0.0196,  0.1172, -0.0913],\n",
            "          [ 0.1914, -0.1582,  0.1907]],\n",
            "\n",
            "         [[ 0.0684, -0.1383, -0.1552],\n",
            "          [ 0.1358, -0.2666, -0.1649],\n",
            "          [ 0.0339,  0.0364,  0.0522]],\n",
            "\n",
            "         [[-0.1609, -0.1916,  0.0028],\n",
            "          [-0.0697,  0.2400, -0.2679],\n",
            "          [-0.0707, -0.1946,  0.0106]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0382,  0.0955, -0.0167],\n",
            "          [ 0.1636,  0.2366, -0.0552],\n",
            "          [-0.0573,  0.0263, -0.1227]],\n",
            "\n",
            "         [[ 0.0660,  0.1197,  0.2221],\n",
            "          [ 0.2330, -0.0835,  0.0961],\n",
            "          [-0.1815,  0.1108,  0.2698]],\n",
            "\n",
            "         [[-0.0965,  0.1746, -0.2636],\n",
            "          [ 0.1513,  0.0428,  0.2274],\n",
            "          [ 0.0078,  0.2188,  0.0238]]],\n",
            "\n",
            "\n",
            "        [[[-0.1671, -0.0766,  0.2514],\n",
            "          [-0.1922,  0.2491,  0.1413],\n",
            "          [ 0.0642,  0.0776, -0.1188]],\n",
            "\n",
            "         [[-0.2216,  0.0381,  0.2160],\n",
            "          [ 0.2233,  0.0553, -0.1550],\n",
            "          [-0.0498,  0.2113, -0.1904]],\n",
            "\n",
            "         [[ 0.2413, -0.2745, -0.1460],\n",
            "          [ 0.2267,  0.0730, -0.1403],\n",
            "          [-0.0681, -0.2619, -0.0719]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2707,  0.2409, -0.2248],\n",
            "          [-0.1290, -0.1803,  0.2467],\n",
            "          [-0.1768,  0.0161,  0.0849]],\n",
            "\n",
            "         [[-0.1339,  0.0406, -0.1707],\n",
            "          [ 0.1007, -0.0264,  0.2531],\n",
            "          [-0.1945,  0.0996,  0.2300]],\n",
            "\n",
            "         [[-0.2417,  0.2496,  0.0857],\n",
            "          [-0.1019,  0.1633,  0.1065],\n",
            "          [-0.1040, -0.1154,  0.2175]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2253,  0.0511, -0.2592],\n",
            "          [ 0.0755,  0.0932, -0.1144],\n",
            "          [ 0.0463, -0.0819,  0.2234]],\n",
            "\n",
            "         [[ 0.0248, -0.2747,  0.2065],\n",
            "          [-0.1677, -0.2073,  0.1986],\n",
            "          [-0.1942,  0.0224,  0.2127]],\n",
            "\n",
            "         [[-0.2422,  0.2584, -0.1912],\n",
            "          [ 0.1128, -0.2175,  0.1051],\n",
            "          [ 0.2474,  0.0169,  0.1380]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1580,  0.0340,  0.2313],\n",
            "          [-0.2609, -0.2632,  0.2412],\n",
            "          [ 0.2708, -0.2714,  0.0406]],\n",
            "\n",
            "         [[ 0.1342,  0.0199,  0.1068],\n",
            "          [ 0.1051, -0.0608,  0.0439],\n",
            "          [-0.1169,  0.0177, -0.0447]],\n",
            "\n",
            "         [[-0.0117, -0.0416,  0.1681],\n",
            "          [ 0.0430, -0.0929, -0.1242],\n",
            "          [-0.2565,  0.2352, -0.1508]]],\n",
            "\n",
            "\n",
            "        [[[-0.0441,  0.0452,  0.1442],\n",
            "          [-0.0776, -0.1495,  0.0275],\n",
            "          [-0.0016,  0.2681,  0.0229]],\n",
            "\n",
            "         [[-0.2161,  0.2688,  0.0104],\n",
            "          [ 0.2220, -0.2613, -0.2176],\n",
            "          [-0.0617,  0.0047,  0.1139]],\n",
            "\n",
            "         [[-0.1120, -0.2369,  0.1839],\n",
            "          [ 0.0504, -0.0866,  0.1756],\n",
            "          [ 0.0139, -0.2165,  0.0174]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1540,  0.1893, -0.1760],\n",
            "          [-0.0919,  0.2345,  0.0452],\n",
            "          [ 0.0815,  0.1961, -0.1309]],\n",
            "\n",
            "         [[-0.1435, -0.1449,  0.0824],\n",
            "          [-0.1124,  0.1365, -0.0851],\n",
            "          [ 0.0067, -0.2121,  0.1520]],\n",
            "\n",
            "         [[-0.2041, -0.0380, -0.0438],\n",
            "          [ 0.1099, -0.1701,  0.2440],\n",
            "          [ 0.0110,  0.1121,  0.2222]]],\n",
            "\n",
            "\n",
            "        [[[-0.1901, -0.0749, -0.2629],\n",
            "          [-0.2177,  0.0458,  0.2703],\n",
            "          [ 0.0845,  0.2754, -0.2695]],\n",
            "\n",
            "         [[-0.0428, -0.1653, -0.2218],\n",
            "          [-0.0493, -0.0982,  0.1296],\n",
            "          [-0.0799,  0.2583, -0.0335]],\n",
            "\n",
            "         [[ 0.1769, -0.0547, -0.1564],\n",
            "          [-0.0262, -0.0199,  0.0223],\n",
            "          [ 0.0875, -0.2664, -0.2501]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1776, -0.0877,  0.2112],\n",
            "          [ 0.0804, -0.2617,  0.2741],\n",
            "          [ 0.2034,  0.0568, -0.0403]],\n",
            "\n",
            "         [[ 0.2488, -0.2751,  0.0564],\n",
            "          [ 0.2173,  0.2434,  0.1886],\n",
            "          [-0.0008,  0.0774, -0.1666]],\n",
            "\n",
            "         [[-0.0342, -0.1565, -0.0716],\n",
            "          [ 0.0151, -0.2604,  0.0415],\n",
            "          [-0.1747, -0.1919,  0.1403]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0204, -0.2134, -0.2051],\n",
            "          [ 0.2232,  0.0532, -0.2057],\n",
            "          [-0.1270, -0.1416, -0.1395]],\n",
            "\n",
            "         [[ 0.0060,  0.1477, -0.1709],\n",
            "          [-0.1300,  0.2401, -0.0262],\n",
            "          [-0.1235, -0.1360, -0.0711]],\n",
            "\n",
            "         [[-0.1593, -0.2299,  0.0543],\n",
            "          [ 0.1041,  0.1371,  0.0107],\n",
            "          [-0.0194, -0.0604,  0.2288]]],\n",
            "\n",
            "\n",
            "        [[[-0.2386,  0.0056,  0.0627],\n",
            "          [-0.2559,  0.2379, -0.2028],\n",
            "          [-0.2462,  0.1406,  0.0557]],\n",
            "\n",
            "         [[ 0.1809, -0.2662, -0.1616],\n",
            "          [ 0.1183, -0.1309,  0.2152],\n",
            "          [-0.0907, -0.1415,  0.2043]],\n",
            "\n",
            "         [[-0.1774, -0.1540, -0.0377],\n",
            "          [ 0.1726, -0.0747, -0.0615],\n",
            "          [-0.2115,  0.0343, -0.0401]]],\n",
            "\n",
            "\n",
            "        [[[-0.1615, -0.2421, -0.0622],\n",
            "          [-0.2420,  0.2158,  0.2671],\n",
            "          [ 0.1883, -0.1862,  0.2345]],\n",
            "\n",
            "         [[ 0.0584,  0.1327,  0.2577],\n",
            "          [ 0.1728, -0.0494, -0.2319],\n",
            "          [-0.1567,  0.0419,  0.0616]],\n",
            "\n",
            "         [[-0.2438,  0.1621, -0.2156],\n",
            "          [ 0.2347,  0.0581, -0.0055],\n",
            "          [-0.0977, -0.0451,  0.1632]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.1497, -0.2251],\n",
            "          [ 0.2757, -0.1442,  0.2561],\n",
            "          [-0.1554,  0.2723,  0.2327]],\n",
            "\n",
            "         [[ 0.1597,  0.0445,  0.2267],\n",
            "          [-0.1762,  0.0824,  0.1086],\n",
            "          [-0.0221, -0.1606, -0.0226]],\n",
            "\n",
            "         [[-0.1218,  0.0282, -0.1069],\n",
            "          [-0.2477,  0.0286,  0.1719],\n",
            "          [-0.0602, -0.0633,  0.1927]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1985,  0.2378, -0.0110],\n",
            "          [ 0.0029, -0.1952,  0.0063],\n",
            "          [ 0.0087,  0.2053, -0.2742]],\n",
            "\n",
            "         [[-0.0308, -0.2654, -0.2642],\n",
            "          [ 0.1471,  0.1377,  0.2248],\n",
            "          [ 0.0834,  0.0132, -0.1504]],\n",
            "\n",
            "         [[-0.2337, -0.1652, -0.1272],\n",
            "          [-0.1602,  0.1083,  0.2644],\n",
            "          [ 0.2548, -0.1610, -0.2642]]],\n",
            "\n",
            "\n",
            "        [[[-0.0643, -0.2027, -0.2680],\n",
            "          [ 0.1099,  0.2457,  0.0374],\n",
            "          [ 0.1269,  0.1710, -0.1587]],\n",
            "\n",
            "         [[ 0.0325,  0.1153, -0.1450],\n",
            "          [ 0.2698,  0.2675,  0.0848],\n",
            "          [-0.1130, -0.0542, -0.0130]],\n",
            "\n",
            "         [[ 0.2115, -0.1324,  0.1687],\n",
            "          [ 0.2437, -0.0361, -0.0265],\n",
            "          [-0.0448,  0.1421,  0.2745]]],\n",
            "\n",
            "\n",
            "        [[[-0.0916, -0.0480, -0.1283],\n",
            "          [-0.2568,  0.2601, -0.0443],\n",
            "          [ 0.1027,  0.0715,  0.1369]],\n",
            "\n",
            "         [[ 0.0894,  0.0964,  0.0404],\n",
            "          [ 0.2058, -0.0831,  0.0584],\n",
            "          [ 0.1853, -0.1829,  0.2058]],\n",
            "\n",
            "         [[ 0.1173, -0.0907, -0.0780],\n",
            "          [ 0.0805, -0.2621,  0.2582],\n",
            "          [-0.2406, -0.1668,  0.1864]]],\n",
            "\n",
            "\n",
            "        [[[-0.2390, -0.0691, -0.1340],\n",
            "          [ 0.1285, -0.0075, -0.1003],\n",
            "          [-0.0719,  0.0978,  0.1259]],\n",
            "\n",
            "         [[-0.1900,  0.2130,  0.1998],\n",
            "          [ 0.0057, -0.0474,  0.1762],\n",
            "          [ 0.2281, -0.2572,  0.1974]],\n",
            "\n",
            "         [[-0.1372, -0.0754,  0.1825],\n",
            "          [ 0.2732, -0.1950, -0.1014],\n",
            "          [-0.0327,  0.0187,  0.0355]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2346,  0.2669, -0.1012],\n",
            "          [-0.2567, -0.2536,  0.0439],\n",
            "          [ 0.1554, -0.0482, -0.1544]],\n",
            "\n",
            "         [[-0.1699, -0.0752,  0.0827],\n",
            "          [ 0.2400,  0.1278, -0.0178],\n",
            "          [-0.0511,  0.2692,  0.1604]],\n",
            "\n",
            "         [[-0.2373,  0.2559,  0.0536],\n",
            "          [ 0.1603, -0.0727, -0.2097],\n",
            "          [-0.1146, -0.1416,  0.0758]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1593, -0.1200,  0.0877],\n",
            "          [ 0.1100, -0.2490, -0.1784],\n",
            "          [-0.0949, -0.2419,  0.2671]],\n",
            "\n",
            "         [[ 0.1384,  0.1805, -0.1680],\n",
            "          [ 0.2485,  0.2151,  0.2735],\n",
            "          [-0.1023, -0.1568, -0.0209]],\n",
            "\n",
            "         [[ 0.0850, -0.0278,  0.2482],\n",
            "          [-0.1701,  0.0534,  0.1485],\n",
            "          [-0.2664, -0.0674, -0.0308]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1943, -0.1436, -0.0840],\n",
            "          [-0.2123,  0.2367, -0.2056],\n",
            "          [-0.0194,  0.1626, -0.1070]],\n",
            "\n",
            "         [[ 0.2559,  0.2416,  0.0119],\n",
            "          [-0.2704, -0.1272,  0.0383],\n",
            "          [-0.2726, -0.0077,  0.1666]],\n",
            "\n",
            "         [[-0.0468,  0.0229, -0.0063],\n",
            "          [ 0.2541,  0.1980, -0.0437],\n",
            "          [ 0.1434, -0.2368, -0.1541]]],\n",
            "\n",
            "\n",
            "        [[[-0.1504,  0.0320,  0.2211],\n",
            "          [-0.2451,  0.0718, -0.1350],\n",
            "          [-0.0296,  0.2597,  0.1882]],\n",
            "\n",
            "         [[ 0.0248, -0.0153, -0.2425],\n",
            "          [ 0.0230, -0.0641,  0.2002],\n",
            "          [ 0.1401,  0.1908, -0.1570]],\n",
            "\n",
            "         [[-0.2029,  0.1893,  0.0341],\n",
            "          [ 0.2631, -0.0440, -0.0737],\n",
            "          [ 0.1071,  0.1241, -0.1518]]],\n",
            "\n",
            "\n",
            "        [[[-0.0924,  0.1730, -0.0218],\n",
            "          [-0.1598, -0.1705,  0.0361],\n",
            "          [-0.0317,  0.1492,  0.2059]],\n",
            "\n",
            "         [[-0.1272,  0.1795, -0.0852],\n",
            "          [ 0.0738, -0.0786, -0.0112],\n",
            "          [-0.0588,  0.2592, -0.2470]],\n",
            "\n",
            "         [[ 0.0004,  0.0503,  0.2583],\n",
            "          [-0.0766,  0.1761,  0.0472],\n",
            "          [-0.0051, -0.1149, -0.1190]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 6.3420e-02,  7.3276e-02,  3.5488e-02],\n",
            "          [-7.2040e-02,  9.8323e-03,  2.7458e-02],\n",
            "          [ 1.2968e-02,  1.4557e-02,  6.5395e-02]],\n",
            "\n",
            "         [[ 2.6170e-02,  5.8342e-02, -3.9271e-02],\n",
            "          [-7.7091e-02,  6.4732e-02, -2.1609e-02],\n",
            "          [-1.8860e-02,  7.0977e-03, -3.3068e-02]],\n",
            "\n",
            "         [[-4.1607e-02, -4.8902e-02,  2.5010e-02],\n",
            "          [ 2.4871e-02,  4.0022e-02,  3.9656e-02],\n",
            "          [-8.2284e-02,  8.3118e-02, -4.2069e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.8574e-02, -5.7834e-02,  8.3874e-04],\n",
            "          [-2.1052e-02,  7.2458e-02, -8.0893e-02],\n",
            "          [-2.1344e-02, -5.8761e-02,  3.1942e-03]],\n",
            "\n",
            "         [[ 1.1539e-02,  2.8821e-02, -5.0540e-03],\n",
            "          [ 4.9397e-02,  7.1442e-02, -1.6676e-02],\n",
            "          [-1.7296e-02,  7.9432e-03, -3.7044e-02]],\n",
            "\n",
            "         [[ 1.9931e-02,  3.6135e-02,  6.7053e-02],\n",
            "          [ 7.0346e-02, -2.5206e-02,  2.9000e-02],\n",
            "          [-5.4800e-02,  3.3441e-02,  8.1460e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9146e-02,  5.2727e-02, -7.9582e-02],\n",
            "          [ 4.5671e-02,  1.2910e-02,  6.8654e-02],\n",
            "          [ 2.3663e-03,  6.6062e-02,  7.1735e-03]],\n",
            "\n",
            "         [[-5.0448e-02, -2.3134e-02,  7.5889e-02],\n",
            "          [-5.8021e-02,  7.5218e-02,  4.2656e-02],\n",
            "          [ 1.9394e-02,  2.3413e-02, -3.5866e-02]],\n",
            "\n",
            "         [[-6.6916e-02,  1.1513e-02,  6.5213e-02],\n",
            "          [ 6.7408e-02,  1.6709e-02, -4.6795e-02],\n",
            "          [-1.5024e-02,  6.3795e-02, -5.7492e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4604e-02, -8.0372e-02, -4.8780e-02],\n",
            "          [ 3.5713e-02, -3.9517e-02,  6.4963e-02],\n",
            "          [-2.7380e-02, -4.2717e-02,  6.1674e-02]],\n",
            "\n",
            "         [[-5.3551e-02, -4.6499e-02, -1.1385e-02],\n",
            "          [ 5.2103e-02, -2.2561e-02, -1.8564e-02],\n",
            "          [-6.3842e-02,  1.0369e-02, -1.2117e-02]],\n",
            "\n",
            "         [[-4.8763e-02, -7.3097e-02, -1.8784e-02],\n",
            "          [-7.3069e-02,  6.5139e-02,  8.0630e-02],\n",
            "          [ 5.6838e-02, -5.6211e-02,  7.0789e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7635e-02,  4.0050e-02,  7.7815e-02],\n",
            "          [ 5.2183e-02, -1.4920e-02, -7.0026e-02],\n",
            "          [-4.7301e-02,  1.2658e-02,  1.8608e-02]],\n",
            "\n",
            "         [[-7.3607e-02,  4.8940e-02, -6.5101e-02],\n",
            "          [ 7.0861e-02,  1.7530e-02, -1.6527e-03],\n",
            "          [-2.9492e-02, -1.3609e-02,  4.9277e-02]],\n",
            "\n",
            "         [[ 6.3353e-02,  4.5206e-02, -6.7958e-02],\n",
            "          [ 8.3224e-02, -4.3525e-02,  7.7330e-02],\n",
            "          [-4.6917e-02,  8.2215e-02,  7.0256e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7900e-02,  5.2240e-02, -6.5858e-03],\n",
            "          [-4.8251e-02, -5.1474e-02,  1.0904e-02],\n",
            "          [-9.5620e-03,  4.5054e-02,  6.2167e-02]],\n",
            "\n",
            "         [[-3.8407e-02,  5.4180e-02, -2.5712e-02],\n",
            "          [ 2.2288e-02, -2.3744e-02, -3.3917e-03],\n",
            "          [-1.7741e-02,  7.8265e-02, -7.4556e-02]],\n",
            "\n",
            "         [[ 1.3336e-04,  1.5187e-02,  7.7969e-02],\n",
            "          [-2.3130e-02,  5.3177e-02,  1.4256e-02],\n",
            "          [-1.5449e-03, -3.4685e-02, -3.5939e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5518e-02, -7.8106e-03,  1.1188e-02],\n",
            "          [ 5.8566e-02, -7.5503e-02, -4.8799e-02],\n",
            "          [ 7.8534e-02, -7.6864e-03, -5.4235e-03]],\n",
            "\n",
            "         [[-4.8229e-02, -2.4747e-02,  1.4032e-02],\n",
            "          [-2.6408e-02, -3.0844e-02, -6.4617e-02],\n",
            "          [ 7.1523e-02,  7.5792e-03, -1.8219e-02]],\n",
            "\n",
            "         [[-1.2435e-02,  5.9314e-02,  6.8632e-02],\n",
            "          [ 6.1398e-02,  2.9868e-02, -8.2195e-02],\n",
            "          [-3.4634e-03,  2.8007e-02,  2.8763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0223e-02, -7.1725e-02, -5.0124e-02],\n",
            "          [ 9.6777e-03,  2.4223e-02, -7.1778e-02],\n",
            "          [ 3.2490e-02, -8.2311e-02, -3.7245e-02]],\n",
            "\n",
            "         [[-6.6682e-02, -3.9517e-02,  6.0189e-04],\n",
            "          [ 4.7752e-02,  4.7375e-02,  4.6630e-02],\n",
            "          [ 4.7163e-03,  8.7263e-03,  4.0087e-02]],\n",
            "\n",
            "         [[-8.1609e-02, -7.4239e-02, -6.0175e-02],\n",
            "          [ 7.7161e-02,  1.4216e-02,  2.8079e-02],\n",
            "          [-2.9038e-02, -7.9810e-02, -5.7194e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3276e-02,  6.2281e-02, -6.5992e-02],\n",
            "          [ 1.6867e-02,  4.9823e-02,  3.7555e-02],\n",
            "          [ 7.6220e-02,  6.5295e-02, -2.0038e-03]],\n",
            "\n",
            "         [[-4.5562e-02,  7.9474e-02,  1.4381e-02],\n",
            "          [-2.2909e-02, -8.0703e-02, -6.7262e-02],\n",
            "          [ 6.5767e-02, -7.8513e-02, -3.2978e-02]],\n",
            "\n",
            "         [[-8.0295e-02,  7.5996e-02, -8.0098e-02],\n",
            "          [ 3.8228e-02,  5.9146e-03,  3.0472e-02],\n",
            "          [ 7.3772e-02,  4.7300e-02, -5.7094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4906e-02,  1.9164e-02, -2.9368e-02],\n",
            "          [-2.2259e-02,  4.3675e-02, -8.1335e-02],\n",
            "          [-2.6379e-02,  8.2509e-02, -5.6902e-02]],\n",
            "\n",
            "         [[ 4.8517e-02, -5.3306e-02, -4.5405e-02],\n",
            "          [-7.2836e-02,  6.9791e-04, -2.0265e-02],\n",
            "          [ 3.9212e-02,  3.0947e-02,  8.1954e-02]],\n",
            "\n",
            "         [[-1.0525e-02,  3.9170e-02,  8.1547e-02],\n",
            "          [ 1.0298e-02,  2.4142e-02,  8.1552e-02],\n",
            "          [-4.1315e-02, -6.6417e-02, -4.2100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7834e-02, -3.7336e-02, -5.6150e-02],\n",
            "          [ 1.4851e-03,  2.7738e-02, -5.7369e-02],\n",
            "          [-7.0169e-02, -4.1213e-05, -4.9262e-02]],\n",
            "\n",
            "         [[-1.4965e-02,  4.0813e-02,  6.4681e-02],\n",
            "          [-4.0381e-02, -5.2670e-03,  3.8095e-02],\n",
            "          [ 5.0829e-02,  7.8358e-02, -5.9338e-03]],\n",
            "\n",
            "         [[ 5.0548e-02,  6.9506e-02,  3.5774e-03],\n",
            "          [-2.0453e-02, -2.2837e-02,  2.7631e-02],\n",
            "          [ 2.2321e-03,  4.0112e-03,  5.9683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7560e-02,  2.7013e-02,  3.8514e-02],\n",
            "          [-6.2757e-02,  7.1732e-02,  3.4445e-02],\n",
            "          [-5.7345e-03, -4.4443e-02, -7.9402e-02]],\n",
            "\n",
            "         [[-8.3232e-02,  3.6605e-02,  3.9557e-02],\n",
            "          [-3.0950e-02, -1.1902e-02,  2.3066e-02],\n",
            "          [ 8.3602e-03,  1.4968e-02, -6.2327e-02]],\n",
            "\n",
            "         [[ 3.4100e-02,  4.9295e-02,  2.1340e-02],\n",
            "          [-2.3296e-02,  3.6142e-02,  3.7400e-03],\n",
            "          [-1.0772e-02, -7.1674e-02, -2.9318e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 1.2684e-01,  1.4655e-01,  7.0976e-02],\n",
            "          [-1.4408e-01,  1.9665e-02,  5.4916e-02],\n",
            "          [ 2.5936e-02,  2.9114e-02,  1.3079e-01]],\n",
            "\n",
            "         [[ 5.2340e-02,  1.1668e-01, -7.8542e-02],\n",
            "          [-1.5418e-01,  1.2946e-01, -4.3219e-02],\n",
            "          [-3.7720e-02,  1.4195e-02, -6.6136e-02]],\n",
            "\n",
            "         [[-8.3213e-02, -9.7804e-02,  5.0020e-02],\n",
            "          [ 4.9742e-02,  8.0043e-02,  7.9311e-02],\n",
            "          [-1.6457e-01,  1.6624e-01, -8.4139e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.7148e-02, -1.1567e-01,  1.6775e-03],\n",
            "          [-4.2104e-02,  1.4492e-01, -1.6179e-01],\n",
            "          [-4.2688e-02, -1.1752e-01,  6.3883e-03]],\n",
            "\n",
            "         [[ 2.3079e-02,  5.7641e-02, -1.0108e-02],\n",
            "          [ 9.8795e-02,  1.4288e-01, -3.3351e-02],\n",
            "          [-3.4592e-02,  1.5886e-02, -7.4089e-02]],\n",
            "\n",
            "         [[ 3.9862e-02,  7.2271e-02,  1.3411e-01],\n",
            "          [ 1.4069e-01, -5.0412e-02,  5.8001e-02],\n",
            "          [-1.0960e-01,  6.6881e-02,  1.6292e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.8292e-02,  1.0545e-01, -1.5916e-01],\n",
            "          [ 9.1343e-02,  2.5820e-02,  1.3731e-01],\n",
            "          [ 4.7326e-03,  1.3212e-01,  1.4347e-02]],\n",
            "\n",
            "         [[-1.0090e-01, -4.6269e-02,  1.5178e-01],\n",
            "          [-1.1604e-01,  1.5044e-01,  8.5311e-02],\n",
            "          [ 3.8788e-02,  4.6826e-02, -7.1732e-02]],\n",
            "\n",
            "         [[-1.3383e-01,  2.3026e-02,  1.3043e-01],\n",
            "          [ 1.3482e-01,  3.3417e-02, -9.3591e-02],\n",
            "          [-3.0049e-02,  1.2759e-01, -1.1498e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0921e-01, -1.6074e-01, -9.7560e-02],\n",
            "          [ 7.1427e-02, -7.9034e-02,  1.2993e-01],\n",
            "          [-5.4760e-02, -8.5435e-02,  1.2335e-01]],\n",
            "\n",
            "         [[-1.0710e-01, -9.2999e-02, -2.2771e-02],\n",
            "          [ 1.0421e-01, -4.5122e-02, -3.7128e-02],\n",
            "          [-1.2768e-01,  2.0739e-02, -2.4234e-02]],\n",
            "\n",
            "         [[-9.7525e-02, -1.4619e-01, -3.7567e-02],\n",
            "          [-1.4614e-01,  1.3028e-01,  1.6126e-01],\n",
            "          [ 1.1368e-01, -1.1242e-01,  1.4158e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.5270e-02,  8.0100e-02,  1.5563e-01],\n",
            "          [ 1.0437e-01, -2.9840e-02, -1.4005e-01],\n",
            "          [-9.4602e-02,  2.5315e-02,  3.7217e-02]],\n",
            "\n",
            "         [[-1.4721e-01,  9.7880e-02, -1.3020e-01],\n",
            "          [ 1.4172e-01,  3.5060e-02, -3.3054e-03],\n",
            "          [-5.8983e-02, -2.7218e-02,  9.8553e-02]],\n",
            "\n",
            "         [[ 1.2671e-01,  9.0411e-02, -1.3592e-01],\n",
            "          [ 1.6645e-01, -8.7049e-02,  1.5466e-01],\n",
            "          [-9.3834e-02,  1.6443e-01,  1.4051e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.5800e-02,  1.0448e-01, -1.3172e-02],\n",
            "          [-9.6501e-02, -1.0295e-01,  2.1809e-02],\n",
            "          [-1.9124e-02,  9.0107e-02,  1.2433e-01]],\n",
            "\n",
            "         [[-7.6814e-02,  1.0836e-01, -5.1424e-02],\n",
            "          [ 4.4577e-02, -4.7487e-02, -6.7833e-03],\n",
            "          [-3.5483e-02,  1.5653e-01, -1.4911e-01]],\n",
            "\n",
            "         [[ 2.6671e-04,  3.0374e-02,  1.5594e-01],\n",
            "          [-4.6259e-02,  1.0635e-01,  2.8513e-02],\n",
            "          [-3.0897e-03, -6.9370e-02, -7.1877e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-9.1037e-02, -1.5621e-02,  2.2375e-02],\n",
            "          [ 1.1713e-01, -1.5101e-01, -9.7598e-02],\n",
            "          [ 1.5707e-01, -1.5373e-02, -1.0847e-02]],\n",
            "\n",
            "         [[-9.6458e-02, -4.9494e-02,  2.8063e-02],\n",
            "          [-5.2816e-02, -6.1688e-02, -1.2923e-01],\n",
            "          [ 1.4305e-01,  1.5158e-02, -3.6437e-02]],\n",
            "\n",
            "         [[-2.4871e-02,  1.1863e-01,  1.3726e-01],\n",
            "          [ 1.2280e-01,  5.9736e-02, -1.6439e-01],\n",
            "          [-6.9267e-03,  5.6014e-02,  5.7527e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.0445e-02, -1.4345e-01, -1.0025e-01],\n",
            "          [ 1.9355e-02,  4.8446e-02, -1.4356e-01],\n",
            "          [ 6.4980e-02, -1.6462e-01, -7.4490e-02]],\n",
            "\n",
            "         [[-1.3336e-01, -7.9034e-02,  1.2038e-03],\n",
            "          [ 9.5503e-02,  9.4751e-02,  9.3260e-02],\n",
            "          [ 9.4326e-03,  1.7453e-02,  8.0174e-02]],\n",
            "\n",
            "         [[-1.6322e-01, -1.4848e-01, -1.2035e-01],\n",
            "          [ 1.5432e-01,  2.8432e-02,  5.6158e-02],\n",
            "          [-5.8077e-02, -1.5962e-01, -1.1439e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6553e-02,  1.2456e-01, -1.3198e-01],\n",
            "          [ 3.3733e-02,  9.9646e-02,  7.5110e-02],\n",
            "          [ 1.5244e-01,  1.3059e-01, -4.0075e-03]],\n",
            "\n",
            "         [[-9.1124e-02,  1.5895e-01,  2.8763e-02],\n",
            "          [-4.5817e-02, -1.6141e-01, -1.3452e-01],\n",
            "          [ 1.3153e-01, -1.5703e-01, -6.5956e-02]],\n",
            "\n",
            "         [[-1.6059e-01,  1.5199e-01, -1.6020e-01],\n",
            "          [ 7.6456e-02,  1.1829e-02,  6.0944e-02],\n",
            "          [ 1.4754e-01,  9.4600e-02, -1.1419e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2981e-01,  3.8329e-02, -5.8735e-02],\n",
            "          [-4.4518e-02,  8.7351e-02, -1.6267e-01],\n",
            "          [-5.2757e-02,  1.6502e-01, -1.1380e-01]],\n",
            "\n",
            "         [[ 9.7033e-02, -1.0661e-01, -9.0810e-02],\n",
            "          [-1.4567e-01,  1.3958e-03, -4.0531e-02],\n",
            "          [ 7.8424e-02,  6.1894e-02,  1.6391e-01]],\n",
            "\n",
            "         [[-2.1050e-02,  7.8340e-02,  1.6309e-01],\n",
            "          [ 2.0596e-02,  4.8285e-02,  1.6310e-01],\n",
            "          [-8.2630e-02, -1.3283e-01, -8.4201e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.5668e-02, -7.4672e-02, -1.1230e-01],\n",
            "          [ 2.9702e-03,  5.5476e-02, -1.1474e-01],\n",
            "          [-1.4034e-01, -8.2427e-05, -9.8524e-02]],\n",
            "\n",
            "         [[-2.9930e-02,  8.1625e-02,  1.2936e-01],\n",
            "          [-8.0762e-02, -1.0534e-02,  7.6189e-02],\n",
            "          [ 1.0166e-01,  1.5672e-01, -1.1868e-02]],\n",
            "\n",
            "         [[ 1.0110e-01,  1.3901e-01,  7.1547e-03],\n",
            "          [-4.0906e-02, -4.5674e-02,  5.5262e-02],\n",
            "          [ 4.4642e-03,  8.0224e-03,  1.1937e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5512e-01,  5.4025e-02,  7.7028e-02],\n",
            "          [-1.2551e-01,  1.4346e-01,  6.8889e-02],\n",
            "          [-1.1469e-02, -8.8887e-02, -1.5880e-01]],\n",
            "\n",
            "         [[-1.6646e-01,  7.3210e-02,  7.9114e-02],\n",
            "          [-6.1900e-02, -2.3804e-02,  4.6133e-02],\n",
            "          [ 1.6720e-02,  2.9937e-02, -1.2465e-01]],\n",
            "\n",
            "         [[ 6.8200e-02,  9.8589e-02,  4.2681e-02],\n",
            "          [-4.6592e-02,  7.2285e-02,  7.4800e-03],\n",
            "          [-2.1544e-02, -1.4335e-01, -5.8636e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 4.4845e-02,  5.1814e-02,  2.5094e-02],\n",
            "          [-5.0940e-02,  6.9525e-03,  1.9416e-02],\n",
            "          [ 9.1698e-03,  1.0294e-02,  4.6242e-02]],\n",
            "\n",
            "         [[ 1.8505e-02,  4.1254e-02, -2.7769e-02],\n",
            "          [-5.4512e-02,  4.5773e-02, -1.5280e-02],\n",
            "          [-1.3336e-02,  5.0188e-03, -2.3383e-02]],\n",
            "\n",
            "         [[-2.9420e-02, -3.4579e-02,  1.7685e-02],\n",
            "          [ 1.7587e-02,  2.8300e-02,  2.8041e-02],\n",
            "          [-5.8184e-02,  5.8773e-02, -2.9748e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8611e-02, -5.6831e-02, -3.4493e-02],\n",
            "          [ 2.5253e-02, -2.7943e-02,  4.5936e-02],\n",
            "          [-1.9361e-02, -3.0206e-02,  4.3610e-02]],\n",
            "\n",
            "         [[-3.7867e-02, -3.2880e-02, -8.0507e-03],\n",
            "          [ 3.6842e-02, -1.5953e-02, -1.3127e-02],\n",
            "          [-4.5143e-02,  7.3322e-03, -8.5680e-03]],\n",
            "\n",
            "         [[-3.4480e-02, -5.1687e-02, -1.3282e-02],\n",
            "          [-5.1667e-02,  4.6060e-02,  5.7014e-02],\n",
            "          [ 4.0191e-02, -3.9747e-02,  5.0055e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2470e-02,  2.8320e-02,  5.5024e-02],\n",
            "          [ 3.6899e-02, -1.0550e-02, -4.9516e-02],\n",
            "          [-3.3447e-02,  8.9503e-03,  1.3158e-02]],\n",
            "\n",
            "         [[-5.2048e-02,  3.4606e-02, -4.6034e-02],\n",
            "          [ 5.0106e-02,  1.2395e-02, -1.1686e-03],\n",
            "          [-2.0854e-02, -9.6232e-03,  3.4844e-02]],\n",
            "\n",
            "         [[ 4.4797e-02,  3.1965e-02, -4.8054e-02],\n",
            "          [ 5.8849e-02, -3.0777e-02,  5.4680e-02],\n",
            "          [-3.3176e-02,  5.8135e-02,  4.9679e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8018e-02, -2.8994e-02, -1.9422e-02],\n",
            "          [-4.2067e-02,  4.9561e-02,  2.3140e-02],\n",
            "          [-3.1462e-02, -5.2222e-02, -2.3686e-02]],\n",
            "\n",
            "         [[ 2.6994e-02,  9.5118e-03,  4.8858e-02],\n",
            "          [-5.1181e-02, -2.8469e-02, -5.3310e-02],\n",
            "          [ 8.7096e-03, -4.6548e-02, -4.4055e-02]],\n",
            "\n",
            "         [[-2.0991e-02,  1.5334e-02, -2.1385e-05],\n",
            "          [-4.1707e-02, -2.3136e-02,  5.4723e-02],\n",
            "          [ 4.3699e-02, -2.4382e-02,  4.2242e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6010e-02,  4.3814e-02, -1.2413e-02],\n",
            "          [ 1.4332e-02,  2.2193e-02,  4.1069e-02],\n",
            "          [ 5.7213e-02,  5.2797e-02,  4.5663e-03]],\n",
            "\n",
            "         [[ 3.8029e-02,  1.2206e-02,  4.8959e-03],\n",
            "          [-2.0712e-02, -9.2328e-03, -5.3781e-02],\n",
            "          [ 5.6189e-02, -4.4071e-02,  3.2018e-02]],\n",
            "\n",
            "         [[-3.9593e-02,  2.4511e-02, -3.7413e-02],\n",
            "          [-2.7640e-02, -1.7677e-02, -4.9695e-02],\n",
            "          [ 3.8388e-02,  2.2945e-02,  3.6923e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1702e-02, -5.3557e-02,  6.4093e-03],\n",
            "          [ 1.3410e-03,  6.7015e-04, -3.5026e-02],\n",
            "          [-2.9028e-02, -5.0844e-02,  3.7384e-02]],\n",
            "\n",
            "         [[-3.0373e-02,  1.5145e-02, -4.7163e-02],\n",
            "          [ 4.8873e-02, -5.2805e-02,  5.1437e-02],\n",
            "          [ 3.3870e-02, -4.1796e-02, -3.0026e-02]],\n",
            "\n",
            "         [[ 5.5603e-02, -5.5660e-02, -3.8751e-02],\n",
            "          [-3.9777e-02, -3.9544e-03,  4.7205e-02],\n",
            "          [-4.0660e-02, -5.1045e-02,  1.9755e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.4225e-03,  5.8966e-03, -5.2181e-02],\n",
            "          [ 1.2877e-02,  2.1004e-02,  1.3849e-02],\n",
            "          [-4.5653e-02,  4.2465e-02,  4.4422e-02]],\n",
            "\n",
            "         [[ 4.0491e-02, -2.8070e-02, -1.0315e-02],\n",
            "          [-3.4855e-02,  1.6074e-03,  4.2435e-02],\n",
            "          [-2.5890e-02, -5.4121e-02,  4.9705e-02]],\n",
            "\n",
            "         [[ 2.6590e-02, -3.9334e-02,  1.9364e-02],\n",
            "          [ 1.3269e-02, -3.1462e-02, -1.2197e-02],\n",
            "          [-1.9240e-02, -2.5462e-02, -3.7559e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8641e-02,  5.1524e-03,  4.0639e-02],\n",
            "          [ 1.4711e-02, -5.1846e-02, -1.3381e-02],\n",
            "          [-1.2564e-02,  4.3656e-02,  2.9459e-02]],\n",
            "\n",
            "         [[ 2.5456e-02, -2.1583e-02, -1.7562e-03],\n",
            "          [-2.9417e-03,  1.4950e-02, -4.5875e-02],\n",
            "          [-1.3552e-02, -3.3755e-02, -1.1766e-02]],\n",
            "\n",
            "         [[-5.7903e-02, -9.0666e-03, -3.3530e-02],\n",
            "          [ 1.6275e-02,  2.2725e-02,  4.1409e-02],\n",
            "          [ 3.3421e-02, -4.1847e-02, -3.3518e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8453e-02,  3.0810e-02, -4.1492e-02],\n",
            "          [-4.9423e-04, -1.5643e-02, -9.2124e-05],\n",
            "          [ 3.8616e-02,  5.6951e-02, -8.8304e-03]],\n",
            "\n",
            "         [[-3.4053e-02,  5.7430e-02, -5.2374e-02],\n",
            "          [ 7.4370e-03,  4.7341e-02, -1.1173e-02],\n",
            "          [-2.9683e-02,  4.2699e-02,  1.0138e-02]],\n",
            "\n",
            "         [[ 1.4564e-02,  4.0759e-02,  3.0126e-02],\n",
            "          [-4.3103e-02,  3.3635e-02, -3.7708e-03],\n",
            "          [-4.5272e-02,  4.4780e-02,  3.5606e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9362e-03, -4.5270e-02,  3.2289e-02],\n",
            "          [-1.6807e-02, -4.4908e-03, -3.3104e-02],\n",
            "          [-3.9801e-02, -1.2665e-02, -8.7887e-03]],\n",
            "\n",
            "         [[ 5.3640e-02,  4.6053e-02,  2.0436e-03],\n",
            "          [-1.4994e-03, -4.7443e-02,  3.9075e-02],\n",
            "          [-1.6432e-02, -5.1907e-02, -2.9914e-02]],\n",
            "\n",
            "         [[ 2.9734e-03,  1.2944e-02,  3.5550e-03],\n",
            "          [ 4.5563e-02, -4.2431e-03, -5.0833e-02],\n",
            "          [ 6.6308e-03,  4.3820e-02, -4.6857e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7160e-02, -4.5592e-02,  2.1544e-02],\n",
            "          [ 1.9051e-02,  2.2201e-02, -5.4873e-02],\n",
            "          [ 4.6079e-02,  4.9803e-02, -5.8571e-02]],\n",
            "\n",
            "         [[ 5.2928e-02, -5.1257e-03,  5.3019e-02],\n",
            "          [-2.8608e-02,  5.2892e-02, -1.0667e-02],\n",
            "          [-2.4313e-02, -7.1462e-03,  2.9066e-02]],\n",
            "\n",
            "         [[ 4.2359e-02,  2.2497e-02, -5.1829e-02],\n",
            "          [-5.7952e-02,  2.0746e-02, -5.8498e-02],\n",
            "          [-1.8216e-02, -3.7258e-03, -5.3728e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8317e-03, -4.4953e-02,  5.4703e-02],\n",
            "          [-4.5709e-02,  4.0591e-02, -1.4609e-02],\n",
            "          [-3.5994e-02, -2.0875e-02,  4.4330e-02]],\n",
            "\n",
            "         [[ 2.5360e-02, -5.0337e-02, -1.6996e-02],\n",
            "          [ 4.8848e-02,  1.2624e-02, -3.9590e-02],\n",
            "          [-4.1340e-02,  3.8589e-02,  4.0635e-02]],\n",
            "\n",
            "         [[-2.7707e-02, -4.9222e-02,  6.5755e-03],\n",
            "          [ 2.0375e-02, -3.3991e-02,  1.6203e-02],\n",
            "          [ 1.3942e-02,  5.4028e-02, -5.4231e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 8.9689e-02,  1.0363e-01,  5.0187e-02],\n",
            "          [-1.0188e-01,  1.3905e-02,  3.8832e-02],\n",
            "          [ 1.8340e-02,  2.0587e-02,  9.2483e-02]],\n",
            "\n",
            "         [[ 3.7010e-02,  8.2508e-02, -5.5537e-02],\n",
            "          [-1.0902e-01,  9.1545e-02, -3.0560e-02],\n",
            "          [-2.6672e-02,  1.0038e-02, -4.6765e-02]],\n",
            "\n",
            "         [[-5.8841e-02, -6.9158e-02,  3.5369e-02],\n",
            "          [ 3.5173e-02,  5.6599e-02,  5.6082e-02],\n",
            "          [-1.1637e-01,  1.1755e-01, -5.9495e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7222e-02, -1.1366e-01, -6.8985e-02],\n",
            "          [ 5.0506e-02, -5.5885e-02,  9.1872e-02],\n",
            "          [-3.8721e-02, -6.0412e-02,  8.7220e-02]],\n",
            "\n",
            "         [[-7.5733e-02, -6.5760e-02, -1.6101e-02],\n",
            "          [ 7.3685e-02, -3.1906e-02, -2.6254e-02],\n",
            "          [-9.0286e-02,  1.4664e-02, -1.7136e-02]],\n",
            "\n",
            "         [[-6.8961e-02, -1.0337e-01, -2.6564e-02],\n",
            "          [-1.0333e-01,  9.2120e-02,  1.1403e-01],\n",
            "          [ 8.0381e-02, -7.9494e-02,  1.0011e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4939e-02,  5.6639e-02,  1.1005e-01],\n",
            "          [ 7.3797e-02, -2.1100e-02, -9.9031e-02],\n",
            "          [-6.6893e-02,  1.7901e-02,  2.6316e-02]],\n",
            "\n",
            "         [[-1.0410e-01,  6.9212e-02, -9.2067e-02],\n",
            "          [ 1.0021e-01,  2.4791e-02, -2.3373e-03],\n",
            "          [-4.1707e-02, -1.9246e-02,  6.9688e-02]],\n",
            "\n",
            "         [[ 8.9595e-02,  6.3930e-02, -9.6107e-02],\n",
            "          [ 1.1770e-01, -6.1553e-02,  1.0936e-01],\n",
            "          [-6.6351e-02,  1.1627e-01,  9.9357e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1604e-01, -5.7988e-02, -3.8845e-02],\n",
            "          [-8.4134e-02,  9.9122e-02,  4.6280e-02],\n",
            "          [-6.2923e-02, -1.0444e-01, -4.7371e-02]],\n",
            "\n",
            "         [[ 5.3987e-02,  1.9024e-02,  9.7716e-02],\n",
            "          [-1.0236e-01, -5.6938e-02, -1.0662e-01],\n",
            "          [ 1.7419e-02, -9.3096e-02, -8.8110e-02]],\n",
            "\n",
            "         [[-4.1983e-02,  3.0668e-02, -4.2770e-05],\n",
            "          [-8.3413e-02, -4.6272e-02,  1.0945e-01],\n",
            "          [ 8.7398e-02, -4.8763e-02,  8.4484e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.2021e-02,  8.7628e-02, -2.4827e-02],\n",
            "          [ 2.8664e-02,  4.4386e-02,  8.2137e-02],\n",
            "          [ 1.1443e-01,  1.0559e-01,  9.1325e-03]],\n",
            "\n",
            "         [[ 7.6058e-02,  2.4411e-02,  9.7918e-03],\n",
            "          [-4.1424e-02, -1.8466e-02, -1.0756e-01],\n",
            "          [ 1.1238e-01, -8.8143e-02,  6.4037e-02]],\n",
            "\n",
            "         [[-7.9187e-02,  4.9022e-02, -7.4825e-02],\n",
            "          [-5.5280e-02, -3.5355e-02, -9.9391e-02],\n",
            "          [ 7.6776e-02,  4.5890e-02,  7.3846e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.3403e-02, -1.0711e-01,  1.2819e-02],\n",
            "          [ 2.6821e-03,  1.3403e-03, -7.0052e-02],\n",
            "          [-5.8056e-02, -1.0169e-01,  7.4768e-02]],\n",
            "\n",
            "         [[-6.0745e-02,  3.0290e-02, -9.4325e-02],\n",
            "          [ 9.7745e-02, -1.0561e-01,  1.0287e-01],\n",
            "          [ 6.7739e-02, -8.3592e-02, -6.0051e-02]],\n",
            "\n",
            "         [[ 1.1121e-01, -1.1132e-01, -7.7501e-02],\n",
            "          [-7.9555e-02, -7.9089e-03,  9.4409e-02],\n",
            "          [-8.1320e-02, -1.0209e-01,  3.9509e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 8.8449e-03,  1.1793e-02, -1.0436e-01],\n",
            "          [ 2.5753e-02,  4.2008e-02,  2.7699e-02],\n",
            "          [-9.1306e-02,  8.4930e-02,  8.8843e-02]],\n",
            "\n",
            "         [[ 8.0983e-02, -5.6139e-02, -2.0630e-02],\n",
            "          [-6.9710e-02,  3.2149e-03,  8.4871e-02],\n",
            "          [-5.1781e-02, -1.0824e-01,  9.9410e-02]],\n",
            "\n",
            "         [[ 5.3181e-02, -7.8669e-02,  3.8729e-02],\n",
            "          [ 2.6538e-02, -6.2925e-02, -2.4395e-02],\n",
            "          [-3.8480e-02, -5.0924e-02, -7.5118e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7283e-02,  1.0305e-02,  8.1279e-02],\n",
            "          [ 2.9422e-02, -1.0369e-01, -2.6762e-02],\n",
            "          [-2.5127e-02,  8.7312e-02,  5.8917e-02]],\n",
            "\n",
            "         [[ 5.0913e-02, -4.3166e-02, -3.5125e-03],\n",
            "          [-5.8833e-03,  2.9901e-02, -9.1750e-02],\n",
            "          [-2.7103e-02, -6.7509e-02, -2.3533e-02]],\n",
            "\n",
            "         [[-1.1581e-01, -1.8133e-02, -6.7060e-02],\n",
            "          [ 3.2549e-02,  4.5451e-02,  8.2819e-02],\n",
            "          [ 6.6843e-02, -8.3694e-02, -6.7036e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1691e-01,  6.1620e-02, -8.2984e-02],\n",
            "          [-9.8845e-04, -3.1285e-02, -1.8425e-04],\n",
            "          [ 7.7231e-02,  1.1390e-01, -1.7661e-02]],\n",
            "\n",
            "         [[-6.8105e-02,  1.1486e-01, -1.0475e-01],\n",
            "          [ 1.4874e-02,  9.4683e-02, -2.2346e-02],\n",
            "          [-5.9367e-02,  8.5398e-02,  2.0275e-02]],\n",
            "\n",
            "         [[ 2.9129e-02,  8.1517e-02,  6.0252e-02],\n",
            "          [-8.6207e-02,  6.7271e-02, -7.5415e-03],\n",
            "          [-9.0543e-02,  8.9560e-02,  7.1212e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9872e-02, -9.0539e-02,  6.4578e-02],\n",
            "          [-3.3613e-02, -8.9816e-03, -6.6207e-02],\n",
            "          [-7.9601e-02, -2.5330e-02, -1.7577e-02]],\n",
            "\n",
            "         [[ 1.0728e-01,  9.2106e-02,  4.0873e-03],\n",
            "          [-2.9988e-03, -9.4886e-02,  7.8151e-02],\n",
            "          [-3.2863e-02, -1.0381e-01, -5.9828e-02]],\n",
            "\n",
            "         [[ 5.9468e-03,  2.5889e-02,  7.1100e-03],\n",
            "          [ 9.1126e-02, -8.4863e-03, -1.0167e-01],\n",
            "          [ 1.3262e-02,  8.7639e-02, -9.3714e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4320e-02, -9.1183e-02,  4.3087e-02],\n",
            "          [ 3.8101e-02,  4.4402e-02, -1.0975e-01],\n",
            "          [ 9.2158e-02,  9.9605e-02, -1.1714e-01]],\n",
            "\n",
            "         [[ 1.0586e-01, -1.0251e-02,  1.0604e-01],\n",
            "          [-5.7217e-02,  1.0578e-01, -2.1334e-02],\n",
            "          [-4.8627e-02, -1.4292e-02,  5.8131e-02]],\n",
            "\n",
            "         [[ 8.4719e-02,  4.4994e-02, -1.0366e-01],\n",
            "          [-1.1590e-01,  4.1493e-02, -1.1700e-01],\n",
            "          [-3.6432e-02, -7.4515e-03, -1.0746e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.6634e-03, -8.9907e-02,  1.0941e-01],\n",
            "          [-9.1419e-02,  8.1182e-02, -2.9217e-02],\n",
            "          [-7.1989e-02, -4.1749e-02,  8.8660e-02]],\n",
            "\n",
            "         [[ 5.0719e-02, -1.0067e-01, -3.3993e-02],\n",
            "          [ 9.7695e-02,  2.5248e-02, -7.9180e-02],\n",
            "          [-8.2680e-02,  7.7178e-02,  8.1269e-02]],\n",
            "\n",
            "         [[-5.5414e-02, -9.8445e-02,  1.3151e-02],\n",
            "          [ 4.0750e-02, -6.7982e-02,  3.2406e-02],\n",
            "          [ 2.7884e-02,  1.0806e-01, -1.0846e-01]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 7.7673e-02,  8.9745e-02,  4.3464e-02],\n",
            "          [-8.8231e-02,  1.2042e-02,  3.3629e-02],\n",
            "          [ 1.5883e-02,  1.7829e-02,  8.0093e-02]],\n",
            "\n",
            "         [[ 3.2051e-02,  7.1454e-02, -4.8097e-02],\n",
            "          [-9.4417e-02,  7.9280e-02, -2.6466e-02],\n",
            "          [-2.3099e-02,  8.6929e-03, -4.0500e-02]],\n",
            "\n",
            "         [[-5.0958e-02, -5.9893e-02,  3.0631e-02],\n",
            "          [ 3.0461e-02,  4.9016e-02,  4.8568e-02],\n",
            "          [-1.0078e-01,  1.0180e-01, -5.1524e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0049e-01, -5.0219e-02, -3.3640e-02],\n",
            "          [-7.2862e-02,  8.5842e-02,  4.0080e-02],\n",
            "          [-5.4493e-02, -9.0451e-02, -4.1025e-02]],\n",
            "\n",
            "         [[ 4.6754e-02,  1.6475e-02,  8.4625e-02],\n",
            "          [-8.8648e-02, -4.9310e-02, -9.2335e-02],\n",
            "          [ 1.5085e-02, -8.0624e-02, -7.6305e-02]],\n",
            "\n",
            "         [[-3.6358e-02,  2.6560e-02, -3.7040e-05],\n",
            "          [-7.2238e-02, -4.0072e-02,  9.4783e-02],\n",
            "          [ 7.5688e-02, -4.2230e-02,  7.3166e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9692e-02,  7.5888e-02, -2.1501e-02],\n",
            "          [ 2.4824e-02,  3.8440e-02,  7.1133e-02],\n",
            "          [ 9.9096e-02,  9.1447e-02,  7.9090e-03]],\n",
            "\n",
            "         [[ 6.5868e-02,  2.1141e-02,  8.4799e-03],\n",
            "          [-3.5874e-02, -1.5992e-02, -9.3151e-02],\n",
            "          [ 9.7323e-02, -7.6334e-02,  5.5458e-02]],\n",
            "\n",
            "         [[-6.8578e-02,  4.2455e-02, -6.4801e-02],\n",
            "          [-4.7874e-02, -3.0618e-02, -8.6075e-02],\n",
            "          [ 6.6490e-02,  3.9742e-02,  6.3952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0213e-02,  2.2065e-02,  8.9753e-02],\n",
            "          [-2.1181e-03,  2.4122e-02, -7.7390e-02],\n",
            "          [-2.8738e-02, -1.0140e-01,  2.5717e-02]],\n",
            "\n",
            "         [[ 2.2444e-03,  7.1494e-02,  1.1665e-02],\n",
            "          [ 2.3931e-02, -4.7832e-02,  6.5808e-02],\n",
            "          [ 4.3576e-02,  7.4369e-02, -2.9443e-02]],\n",
            "\n",
            "         [[-3.9376e-02,  5.1194e-02, -4.8463e-02],\n",
            "          [-6.5288e-02, -9.9709e-02,  6.9117e-02],\n",
            "          [-7.7806e-02,  9.5594e-02,  4.1468e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.8904e-02,  1.2896e-02, -1.5296e-02],\n",
            "          [-5.8474e-02, -8.2693e-02,  1.0590e-02],\n",
            "          [ 9.4664e-02, -3.1011e-02,  6.6813e-02]],\n",
            "\n",
            "         [[ 2.1779e-02, -8.0226e-02,  4.7674e-02],\n",
            "          [ 9.6281e-02,  5.2221e-02,  3.0164e-02],\n",
            "          [ 9.7515e-02, -4.1972e-02, -1.4942e-02]],\n",
            "\n",
            "         [[ 6.9423e-02, -2.8329e-02, -6.8502e-02],\n",
            "          [ 8.5771e-02,  5.1299e-02, -6.9670e-02],\n",
            "          [-3.9235e-02, -3.2658e-02, -2.0557e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8619e-02, -8.1971e-02, -9.4728e-02],\n",
            "          [ 2.4756e-02,  1.7562e-02,  2.2271e-03],\n",
            "          [-8.5356e-03,  8.7380e-03,  8.8085e-03]],\n",
            "\n",
            "         [[ 5.4909e-03,  3.2560e-03,  9.3927e-02],\n",
            "          [ 5.2675e-02,  9.9299e-02,  5.6058e-02],\n",
            "          [-2.0746e-02, -2.7663e-02, -1.0026e-01]],\n",
            "\n",
            "         [[ 4.9393e-02,  1.7127e-02, -6.6261e-02],\n",
            "          [-5.3797e-02,  8.1027e-02, -2.2789e-02],\n",
            "          [-7.8732e-02,  3.6763e-02, -1.6730e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.7944e-02,  9.6322e-02,  3.5949e-02],\n",
            "          [-3.9560e-02, -3.4152e-02, -5.8694e-02],\n",
            "          [ 5.8052e-02,  5.4945e-02,  1.2409e-02]],\n",
            "\n",
            "         [[ 8.5249e-03, -6.4980e-03, -2.4291e-02],\n",
            "          [-7.1527e-03, -5.8020e-02, -7.4571e-02],\n",
            "          [-5.6637e-02, -7.9044e-02, -7.7166e-03]],\n",
            "\n",
            "         [[ 3.3570e-02, -4.7266e-03, -5.6219e-03],\n",
            "          [-3.7667e-02, -6.3444e-02, -2.3672e-02],\n",
            "          [ 1.7902e-02, -7.8110e-02, -2.5365e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3959e-02, -1.0763e-03, -3.0287e-02],\n",
            "          [-8.6898e-02,  2.6970e-02,  2.6024e-02],\n",
            "          [-1.8734e-03, -5.6031e-02, -8.2332e-02]],\n",
            "\n",
            "         [[-2.5456e-03,  6.8973e-02, -5.8509e-02],\n",
            "          [-1.8447e-02, -4.8398e-02,  1.7098e-02],\n",
            "          [ 6.9066e-02,  4.3917e-02,  3.7743e-02]],\n",
            "\n",
            "         [[-5.3266e-02,  5.3887e-02,  2.1169e-02],\n",
            "          [-9.7531e-02,  4.3728e-02,  1.9794e-02],\n",
            "          [-7.4367e-02, -5.5669e-02, -9.7229e-02]]],\n",
            "\n",
            "\n",
            "        [[[-8.0299e-02, -9.6149e-03, -6.8598e-02],\n",
            "          [ 2.2405e-02,  2.6585e-03,  6.7110e-02],\n",
            "          [-7.9032e-02,  6.1874e-02, -8.1865e-02]],\n",
            "\n",
            "         [[-4.5832e-02,  3.8936e-02, -4.4544e-02],\n",
            "          [ 5.9631e-03,  7.3064e-02,  5.4907e-02],\n",
            "          [-2.7513e-02,  4.1368e-04, -2.8873e-02]],\n",
            "\n",
            "         [[-9.8644e-02, -8.2903e-02, -2.8742e-02],\n",
            "          [-6.3764e-02,  3.8214e-02,  9.2715e-02],\n",
            "          [ 4.6300e-02,  1.5674e-02, -9.4199e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2535e-02,  7.1071e-02,  9.5044e-02],\n",
            "          [ 9.5970e-02,  8.6572e-02,  6.6470e-02],\n",
            "          [ 1.3319e-02, -4.4959e-02,  4.4317e-02]],\n",
            "\n",
            "         [[ 9.6185e-02, -2.0609e-02,  3.7233e-02],\n",
            "          [ 7.8972e-02, -4.3608e-02, -1.1126e-02],\n",
            "          [ 4.2804e-02, -6.5102e-02, -6.2820e-02]],\n",
            "\n",
            "         [[ 3.2811e-02,  4.4362e-02,  5.5386e-02],\n",
            "          [-4.4232e-02, -1.4854e-02, -1.6287e-02],\n",
            "          [ 3.7681e-02,  1.6571e-02, -2.6075e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.8440e-02,  9.3798e-02, -2.7464e-02],\n",
            "          [ 2.9905e-02, -9.7491e-02, -5.5263e-02],\n",
            "          [-1.3487e-02,  7.9381e-02, -6.8890e-02]],\n",
            "\n",
            "         [[-1.7421e-02, -2.3345e-02, -1.0018e-01],\n",
            "          [-8.3883e-02,  1.0092e-01, -7.5700e-02],\n",
            "          [ 2.3137e-02, -7.9897e-02, -4.8981e-02]],\n",
            "\n",
            "         [[-1.8268e-02, -9.7018e-02, -9.0961e-02],\n",
            "          [ 7.1083e-02, -8.9243e-02, -7.6647e-02],\n",
            "          [ 8.4471e-02, -2.0688e-02, -8.1335e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.5338e-02,  2.4017e-02,  4.6641e-02],\n",
            "          [-7.2771e-02,  6.8789e-03, -3.6700e-02],\n",
            "          [ 2.3962e-02,  9.9337e-02, -7.1242e-02]],\n",
            "\n",
            "         [[-7.9407e-02, -1.8254e-02, -3.9803e-03],\n",
            "          [ 9.3338e-03, -8.5793e-02, -8.0215e-02],\n",
            "          [ 5.2438e-02,  7.3217e-02, -2.6117e-02]],\n",
            "\n",
            "         [[ 7.6430e-02, -4.8134e-02, -4.3899e-02],\n",
            "          [ 1.6737e-03,  9.6192e-04,  7.8756e-02],\n",
            "          [ 4.2284e-02,  2.8839e-02,  8.9208e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 7.7673e-02,  8.9745e-02,  4.3464e-02],\n",
            "          [-8.8231e-02,  1.2042e-02,  3.3629e-02],\n",
            "          [ 1.5883e-02,  1.7829e-02,  8.0093e-02]],\n",
            "\n",
            "         [[ 3.2051e-02,  7.1454e-02, -4.8097e-02],\n",
            "          [-9.4417e-02,  7.9280e-02, -2.6466e-02],\n",
            "          [-2.3099e-02,  8.6929e-03, -4.0500e-02]],\n",
            "\n",
            "         [[-5.0958e-02, -5.9893e-02,  3.0631e-02],\n",
            "          [ 3.0461e-02,  4.9016e-02,  4.8568e-02],\n",
            "          [-1.0078e-01,  1.0180e-01, -5.1524e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0049e-01, -5.0219e-02, -3.3640e-02],\n",
            "          [-7.2862e-02,  8.5842e-02,  4.0080e-02],\n",
            "          [-5.4493e-02, -9.0451e-02, -4.1025e-02]],\n",
            "\n",
            "         [[ 4.6754e-02,  1.6475e-02,  8.4625e-02],\n",
            "          [-8.8648e-02, -4.9310e-02, -9.2335e-02],\n",
            "          [ 1.5085e-02, -8.0624e-02, -7.6305e-02]],\n",
            "\n",
            "         [[-3.6358e-02,  2.6560e-02, -3.7040e-05],\n",
            "          [-7.2238e-02, -4.0072e-02,  9.4783e-02],\n",
            "          [ 7.5688e-02, -4.2230e-02,  7.3166e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9692e-02,  7.5888e-02, -2.1501e-02],\n",
            "          [ 2.4824e-02,  3.8440e-02,  7.1133e-02],\n",
            "          [ 9.9096e-02,  9.1447e-02,  7.9090e-03]],\n",
            "\n",
            "         [[ 6.5868e-02,  2.1141e-02,  8.4799e-03],\n",
            "          [-3.5874e-02, -1.5992e-02, -9.3151e-02],\n",
            "          [ 9.7323e-02, -7.6334e-02,  5.5458e-02]],\n",
            "\n",
            "         [[-6.8578e-02,  4.2455e-02, -6.4801e-02],\n",
            "          [-4.7874e-02, -3.0618e-02, -8.6075e-02],\n",
            "          [ 6.6490e-02,  3.9742e-02,  6.3952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0213e-02,  2.2065e-02,  8.9753e-02],\n",
            "          [-2.1181e-03,  2.4122e-02, -7.7390e-02],\n",
            "          [-2.8738e-02, -1.0140e-01,  2.5717e-02]],\n",
            "\n",
            "         [[ 2.2444e-03,  7.1494e-02,  1.1665e-02],\n",
            "          [ 2.3931e-02, -4.7832e-02,  6.5808e-02],\n",
            "          [ 4.3576e-02,  7.4369e-02, -2.9443e-02]],\n",
            "\n",
            "         [[-3.9376e-02,  5.1194e-02, -4.8463e-02],\n",
            "          [-6.5288e-02, -9.9709e-02,  6.9117e-02],\n",
            "          [-7.7806e-02,  9.5594e-02,  4.1468e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.8904e-02,  1.2896e-02, -1.5296e-02],\n",
            "          [-5.8474e-02, -8.2693e-02,  1.0590e-02],\n",
            "          [ 9.4664e-02, -3.1011e-02,  6.6813e-02]],\n",
            "\n",
            "         [[ 2.1779e-02, -8.0226e-02,  4.7674e-02],\n",
            "          [ 9.6281e-02,  5.2221e-02,  3.0164e-02],\n",
            "          [ 9.7515e-02, -4.1972e-02, -1.4942e-02]],\n",
            "\n",
            "         [[ 6.9423e-02, -2.8329e-02, -6.8502e-02],\n",
            "          [ 8.5771e-02,  5.1299e-02, -6.9670e-02],\n",
            "          [-3.9235e-02, -3.2658e-02, -2.0557e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8619e-02, -8.1971e-02, -9.4728e-02],\n",
            "          [ 2.4756e-02,  1.7562e-02,  2.2271e-03],\n",
            "          [-8.5356e-03,  8.7380e-03,  8.8085e-03]],\n",
            "\n",
            "         [[ 5.4909e-03,  3.2560e-03,  9.3927e-02],\n",
            "          [ 5.2675e-02,  9.9299e-02,  5.6058e-02],\n",
            "          [-2.0746e-02, -2.7663e-02, -1.0026e-01]],\n",
            "\n",
            "         [[ 4.9393e-02,  1.7127e-02, -6.6261e-02],\n",
            "          [-5.3797e-02,  8.1027e-02, -2.2789e-02],\n",
            "          [-7.8732e-02,  3.6763e-02, -1.6730e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.7944e-02,  9.6322e-02,  3.5949e-02],\n",
            "          [-3.9560e-02, -3.4152e-02, -5.8694e-02],\n",
            "          [ 5.8052e-02,  5.4945e-02,  1.2409e-02]],\n",
            "\n",
            "         [[ 8.5249e-03, -6.4980e-03, -2.4291e-02],\n",
            "          [-7.1527e-03, -5.8020e-02, -7.4571e-02],\n",
            "          [-5.6637e-02, -7.9044e-02, -7.7166e-03]],\n",
            "\n",
            "         [[ 3.3570e-02, -4.7266e-03, -5.6219e-03],\n",
            "          [-3.7667e-02, -6.3444e-02, -2.3672e-02],\n",
            "          [ 1.7902e-02, -7.8110e-02, -2.5365e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3959e-02, -1.0763e-03, -3.0287e-02],\n",
            "          [-8.6898e-02,  2.6970e-02,  2.6024e-02],\n",
            "          [-1.8734e-03, -5.6031e-02, -8.2332e-02]],\n",
            "\n",
            "         [[-2.5456e-03,  6.8973e-02, -5.8509e-02],\n",
            "          [-1.8447e-02, -4.8398e-02,  1.7098e-02],\n",
            "          [ 6.9066e-02,  4.3917e-02,  3.7743e-02]],\n",
            "\n",
            "         [[-5.3266e-02,  5.3887e-02,  2.1169e-02],\n",
            "          [-9.7531e-02,  4.3728e-02,  1.9794e-02],\n",
            "          [-7.4367e-02, -5.5669e-02, -9.7229e-02]]],\n",
            "\n",
            "\n",
            "        [[[-8.0299e-02, -9.6149e-03, -6.8598e-02],\n",
            "          [ 2.2405e-02,  2.6585e-03,  6.7110e-02],\n",
            "          [-7.9032e-02,  6.1874e-02, -8.1865e-02]],\n",
            "\n",
            "         [[-4.5832e-02,  3.8936e-02, -4.4544e-02],\n",
            "          [ 5.9631e-03,  7.3064e-02,  5.4907e-02],\n",
            "          [-2.7513e-02,  4.1368e-04, -2.8873e-02]],\n",
            "\n",
            "         [[-9.8644e-02, -8.2903e-02, -2.8742e-02],\n",
            "          [-6.3764e-02,  3.8214e-02,  9.2715e-02],\n",
            "          [ 4.6300e-02,  1.5674e-02, -9.4199e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2535e-02,  7.1071e-02,  9.5044e-02],\n",
            "          [ 9.5970e-02,  8.6572e-02,  6.6470e-02],\n",
            "          [ 1.3319e-02, -4.4959e-02,  4.4317e-02]],\n",
            "\n",
            "         [[ 9.6185e-02, -2.0609e-02,  3.7233e-02],\n",
            "          [ 7.8972e-02, -4.3608e-02, -1.1126e-02],\n",
            "          [ 4.2804e-02, -6.5102e-02, -6.2820e-02]],\n",
            "\n",
            "         [[ 3.2811e-02,  4.4362e-02,  5.5386e-02],\n",
            "          [-4.4232e-02, -1.4854e-02, -1.6287e-02],\n",
            "          [ 3.7681e-02,  1.6571e-02, -2.6075e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.8440e-02,  9.3798e-02, -2.7464e-02],\n",
            "          [ 2.9905e-02, -9.7491e-02, -5.5263e-02],\n",
            "          [-1.3487e-02,  7.9381e-02, -6.8890e-02]],\n",
            "\n",
            "         [[-1.7421e-02, -2.3345e-02, -1.0018e-01],\n",
            "          [-8.3883e-02,  1.0092e-01, -7.5700e-02],\n",
            "          [ 2.3137e-02, -7.9897e-02, -4.8981e-02]],\n",
            "\n",
            "         [[-1.8268e-02, -9.7018e-02, -9.0961e-02],\n",
            "          [ 7.1083e-02, -8.9243e-02, -7.6647e-02],\n",
            "          [ 8.4471e-02, -2.0688e-02, -8.1335e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.5338e-02,  2.4017e-02,  4.6641e-02],\n",
            "          [-7.2771e-02,  6.8789e-03, -3.6700e-02],\n",
            "          [ 2.3962e-02,  9.9337e-02, -7.1242e-02]],\n",
            "\n",
            "         [[-7.9407e-02, -1.8254e-02, -3.9803e-03],\n",
            "          [ 9.3338e-03, -8.5793e-02, -8.0215e-02],\n",
            "          [ 5.2438e-02,  7.3217e-02, -2.6117e-02]],\n",
            "\n",
            "         [[ 7.6430e-02, -4.8134e-02, -4.3899e-02],\n",
            "          [ 1.6737e-03,  9.6192e-04,  7.8756e-02],\n",
            "          [ 4.2284e-02,  2.8839e-02,  8.9208e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 7.7673e-02,  8.9745e-02,  4.3464e-02],\n",
            "          [-8.8231e-02,  1.2042e-02,  3.3629e-02],\n",
            "          [ 1.5883e-02,  1.7829e-02,  8.0093e-02]],\n",
            "\n",
            "         [[ 3.2051e-02,  7.1454e-02, -4.8097e-02],\n",
            "          [-9.4417e-02,  7.9280e-02, -2.6466e-02],\n",
            "          [-2.3099e-02,  8.6929e-03, -4.0500e-02]],\n",
            "\n",
            "         [[-5.0958e-02, -5.9893e-02,  3.0631e-02],\n",
            "          [ 3.0461e-02,  4.9016e-02,  4.8568e-02],\n",
            "          [-1.0078e-01,  1.0180e-01, -5.1524e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0049e-01, -5.0219e-02, -3.3640e-02],\n",
            "          [-7.2862e-02,  8.5842e-02,  4.0080e-02],\n",
            "          [-5.4493e-02, -9.0451e-02, -4.1025e-02]],\n",
            "\n",
            "         [[ 4.6754e-02,  1.6475e-02,  8.4625e-02],\n",
            "          [-8.8648e-02, -4.9310e-02, -9.2335e-02],\n",
            "          [ 1.5085e-02, -8.0624e-02, -7.6305e-02]],\n",
            "\n",
            "         [[-3.6358e-02,  2.6560e-02, -3.7040e-05],\n",
            "          [-7.2238e-02, -4.0072e-02,  9.4783e-02],\n",
            "          [ 7.5688e-02, -4.2230e-02,  7.3166e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9692e-02,  7.5888e-02, -2.1501e-02],\n",
            "          [ 2.4824e-02,  3.8440e-02,  7.1133e-02],\n",
            "          [ 9.9096e-02,  9.1447e-02,  7.9090e-03]],\n",
            "\n",
            "         [[ 6.5868e-02,  2.1141e-02,  8.4799e-03],\n",
            "          [-3.5874e-02, -1.5992e-02, -9.3151e-02],\n",
            "          [ 9.7323e-02, -7.6334e-02,  5.5458e-02]],\n",
            "\n",
            "         [[-6.8578e-02,  4.2455e-02, -6.4801e-02],\n",
            "          [-4.7874e-02, -3.0618e-02, -8.6075e-02],\n",
            "          [ 6.6490e-02,  3.9742e-02,  6.3952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0213e-02,  2.2065e-02,  8.9753e-02],\n",
            "          [-2.1181e-03,  2.4122e-02, -7.7390e-02],\n",
            "          [-2.8738e-02, -1.0140e-01,  2.5717e-02]],\n",
            "\n",
            "         [[ 2.2444e-03,  7.1494e-02,  1.1665e-02],\n",
            "          [ 2.3931e-02, -4.7832e-02,  6.5808e-02],\n",
            "          [ 4.3576e-02,  7.4369e-02, -2.9443e-02]],\n",
            "\n",
            "         [[-3.9376e-02,  5.1194e-02, -4.8463e-02],\n",
            "          [-6.5288e-02, -9.9709e-02,  6.9117e-02],\n",
            "          [-7.7806e-02,  9.5594e-02,  4.1468e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.8904e-02,  1.2896e-02, -1.5296e-02],\n",
            "          [-5.8474e-02, -8.2693e-02,  1.0590e-02],\n",
            "          [ 9.4664e-02, -3.1011e-02,  6.6813e-02]],\n",
            "\n",
            "         [[ 2.1779e-02, -8.0226e-02,  4.7674e-02],\n",
            "          [ 9.6281e-02,  5.2221e-02,  3.0164e-02],\n",
            "          [ 9.7515e-02, -4.1972e-02, -1.4942e-02]],\n",
            "\n",
            "         [[ 6.9423e-02, -2.8329e-02, -6.8502e-02],\n",
            "          [ 8.5771e-02,  5.1299e-02, -6.9670e-02],\n",
            "          [-3.9235e-02, -3.2658e-02, -2.0557e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8619e-02, -8.1971e-02, -9.4728e-02],\n",
            "          [ 2.4756e-02,  1.7562e-02,  2.2271e-03],\n",
            "          [-8.5356e-03,  8.7380e-03,  8.8085e-03]],\n",
            "\n",
            "         [[ 5.4909e-03,  3.2560e-03,  9.3927e-02],\n",
            "          [ 5.2675e-02,  9.9299e-02,  5.6058e-02],\n",
            "          [-2.0746e-02, -2.7663e-02, -1.0026e-01]],\n",
            "\n",
            "         [[ 4.9393e-02,  1.7127e-02, -6.6261e-02],\n",
            "          [-5.3797e-02,  8.1027e-02, -2.2789e-02],\n",
            "          [-7.8732e-02,  3.6763e-02, -1.6730e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.7944e-02,  9.6322e-02,  3.5949e-02],\n",
            "          [-3.9560e-02, -3.4152e-02, -5.8694e-02],\n",
            "          [ 5.8052e-02,  5.4945e-02,  1.2409e-02]],\n",
            "\n",
            "         [[ 8.5249e-03, -6.4980e-03, -2.4291e-02],\n",
            "          [-7.1527e-03, -5.8020e-02, -7.4571e-02],\n",
            "          [-5.6637e-02, -7.9044e-02, -7.7166e-03]],\n",
            "\n",
            "         [[ 3.3570e-02, -4.7266e-03, -5.6219e-03],\n",
            "          [-3.7667e-02, -6.3444e-02, -2.3672e-02],\n",
            "          [ 1.7902e-02, -7.8110e-02, -2.5365e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3959e-02, -1.0763e-03, -3.0287e-02],\n",
            "          [-8.6898e-02,  2.6970e-02,  2.6024e-02],\n",
            "          [-1.8734e-03, -5.6031e-02, -8.2332e-02]],\n",
            "\n",
            "         [[-2.5456e-03,  6.8973e-02, -5.8509e-02],\n",
            "          [-1.8447e-02, -4.8398e-02,  1.7098e-02],\n",
            "          [ 6.9066e-02,  4.3917e-02,  3.7743e-02]],\n",
            "\n",
            "         [[-5.3266e-02,  5.3887e-02,  2.1169e-02],\n",
            "          [-9.7531e-02,  4.3728e-02,  1.9794e-02],\n",
            "          [-7.4367e-02, -5.5669e-02, -9.7229e-02]]],\n",
            "\n",
            "\n",
            "        [[[-8.0299e-02, -9.6149e-03, -6.8598e-02],\n",
            "          [ 2.2405e-02,  2.6585e-03,  6.7110e-02],\n",
            "          [-7.9032e-02,  6.1874e-02, -8.1865e-02]],\n",
            "\n",
            "         [[-4.5832e-02,  3.8936e-02, -4.4544e-02],\n",
            "          [ 5.9631e-03,  7.3064e-02,  5.4907e-02],\n",
            "          [-2.7513e-02,  4.1368e-04, -2.8873e-02]],\n",
            "\n",
            "         [[-9.8644e-02, -8.2903e-02, -2.8742e-02],\n",
            "          [-6.3764e-02,  3.8214e-02,  9.2715e-02],\n",
            "          [ 4.6300e-02,  1.5674e-02, -9.4199e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2535e-02,  7.1071e-02,  9.5044e-02],\n",
            "          [ 9.5970e-02,  8.6572e-02,  6.6470e-02],\n",
            "          [ 1.3319e-02, -4.4959e-02,  4.4317e-02]],\n",
            "\n",
            "         [[ 9.6185e-02, -2.0609e-02,  3.7233e-02],\n",
            "          [ 7.8972e-02, -4.3608e-02, -1.1126e-02],\n",
            "          [ 4.2804e-02, -6.5102e-02, -6.2820e-02]],\n",
            "\n",
            "         [[ 3.2811e-02,  4.4362e-02,  5.5386e-02],\n",
            "          [-4.4232e-02, -1.4854e-02, -1.6287e-02],\n",
            "          [ 3.7681e-02,  1.6571e-02, -2.6075e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.8440e-02,  9.3798e-02, -2.7464e-02],\n",
            "          [ 2.9905e-02, -9.7491e-02, -5.5263e-02],\n",
            "          [-1.3487e-02,  7.9381e-02, -6.8890e-02]],\n",
            "\n",
            "         [[-1.7421e-02, -2.3345e-02, -1.0018e-01],\n",
            "          [-8.3883e-02,  1.0092e-01, -7.5700e-02],\n",
            "          [ 2.3137e-02, -7.9897e-02, -4.8981e-02]],\n",
            "\n",
            "         [[-1.8268e-02, -9.7018e-02, -9.0961e-02],\n",
            "          [ 7.1083e-02, -8.9243e-02, -7.6647e-02],\n",
            "          [ 8.4471e-02, -2.0688e-02, -8.1335e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.5338e-02,  2.4017e-02,  4.6641e-02],\n",
            "          [-7.2771e-02,  6.8789e-03, -3.6700e-02],\n",
            "          [ 2.3962e-02,  9.9337e-02, -7.1242e-02]],\n",
            "\n",
            "         [[-7.9407e-02, -1.8254e-02, -3.9803e-03],\n",
            "          [ 9.3338e-03, -8.5793e-02, -8.0215e-02],\n",
            "          [ 5.2438e-02,  7.3217e-02, -2.6117e-02]],\n",
            "\n",
            "         [[ 7.6430e-02, -4.8134e-02, -4.3899e-02],\n",
            "          [ 1.6737e-03,  9.6192e-04,  7.8756e-02],\n",
            "          [ 4.2284e-02,  2.8839e-02,  8.9208e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1345,  0.1554,  0.0753,  ...,  0.1563,  0.0141,  0.0370],\n",
            "        [ 0.0776,  0.0739,  0.0299,  ..., -0.0886, -0.0994,  0.0869],\n",
            "        [-0.1707, -0.1056,  0.0217,  ..., -0.1671, -0.1686,  0.1544],\n",
            "        ...,\n",
            "        [ 0.1737, -0.1332,  0.1021,  ...,  0.0214, -0.1230,  0.1506],\n",
            "        [ 0.0612,  0.0354, -0.0323,  ..., -0.0069,  0.1272, -0.1179],\n",
            "        [ 0.0882, -0.1238, -0.0774,  ...,  0.0117,  0.1326,  0.1735]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2691,  0.3109,  0.1506,  ...,  0.3125,  0.0283,  0.0739],\n",
            "        [ 0.1552,  0.1479,  0.0599,  ..., -0.1772, -0.1988,  0.1739],\n",
            "        [-0.3415, -0.2112,  0.0434,  ..., -0.3342, -0.3372,  0.3089],\n",
            "        ...,\n",
            "        [ 0.3474, -0.2665,  0.2042,  ...,  0.0428, -0.2460,  0.3013],\n",
            "        [ 0.1224,  0.0708, -0.0646,  ..., -0.0138,  0.2543, -0.2358],\n",
            "        [ 0.1765, -0.2476, -0.1548,  ...,  0.0234,  0.2652,  0.3471]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1903,  0.2198,  0.1065,  ..., -0.0110, -0.2199,  0.1569],\n",
            "        [ 0.2459,  0.1016, -0.0850,  ...,  0.2210,  0.0200,  0.0523],\n",
            "        [ 0.1097,  0.1046,  0.0423,  ..., -0.2061,  0.1741,  0.1329],\n",
            "        ...,\n",
            "        [-0.2453,  0.0792, -0.2213,  ...,  0.0881, -0.0387, -0.1407],\n",
            "        [-0.2055, -0.2485,  0.1241,  ...,  0.1913, -0.1581, -0.0015],\n",
            "        [ 0.0482,  0.0903, -0.2478,  ..., -0.1664,  0.2418, -0.0021]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.3805,  0.4397,  0.2129,  ..., -0.0220, -0.4398,  0.3139],\n",
            "        [ 0.4918,  0.2033, -0.1699,  ...,  0.4420,  0.0400,  0.1046],\n",
            "        [ 0.2195,  0.2091,  0.0847,  ..., -0.4123,  0.3482,  0.2658],\n",
            "        ...,\n",
            "        [-0.4907,  0.1583, -0.4426,  ...,  0.1762, -0.0773, -0.2815],\n",
            "        [-0.4109, -0.4971,  0.2481,  ...,  0.3825, -0.3162, -0.0031],\n",
            "        [ 0.0964,  0.1807, -0.4956,  ..., -0.3327,  0.4836, -0.0043]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200, 0.0200, 0.0200, 0.0200, 0.0200], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2876,  0.3324,  0.1610, -0.3267,  0.0446,  0.1245,  0.0588,  0.0660,\n",
            "          0.2966,  0.1187,  0.2646, -0.1781, -0.3497,  0.2936, -0.0980, -0.0855,\n",
            "          0.0322, -0.1500, -0.1887, -0.2218,  0.1134,  0.1128,  0.1815,  0.1799,\n",
            "         -0.3732,  0.3770, -0.1908, -0.0666,  0.2940,  0.1676, -0.1132,  0.3359],\n",
            "        [ 0.2693,  0.2526,  0.0457,  0.3344,  0.1400,  0.3594, -0.0472, -0.2504,\n",
            "         -0.0024, -0.0601, -0.1412, -0.1225,  0.2946, -0.3243,  0.1717,  0.3388,\n",
            "          0.3514, -0.0440, -0.0156,  0.0179, -0.1082,  0.1496, -0.0065, -0.3410,\n",
            "          0.0617,  0.3029,  0.2283, -0.0619, -0.3415, -0.0166, -0.3324,  0.2373],\n",
            "        [ 0.3718,  0.1536, -0.1285,  0.1325,  0.2936, -0.3619, -0.3065,  0.3395,\n",
            "          0.2661,  0.0847, -0.0894,  0.1175, -0.0485,  0.3726, -0.0551,  0.1704,\n",
            "          0.2330, -0.0829,  0.1621, -0.2405,  0.0042, -0.2313,  0.0014, -0.0303,\n",
            "         -0.3615,  0.0199, -0.1888, -0.1070, -0.3523, -0.3042, -0.2639,  0.1346],\n",
            "        [ 0.0220,  0.2461,  0.1544,  0.2919, -0.0088,  0.3688, -0.2728, -0.0831,\n",
            "          0.0794, -0.3264, -0.2222,  0.1773, -0.2044,  0.0425,  0.2537,  0.3493,\n",
            "         -0.1775, -0.3320, -0.1200,  0.1926,  0.0255,  0.1778, -0.2897, -0.3766,\n",
            "         -0.2204,  0.1639, -0.1122,  0.3449,  0.1931,  0.3341,  0.0302,  0.0791],\n",
            "        [ 0.1659,  0.1581,  0.0640, -0.2330,  0.1653, -0.1465,  0.1987,  0.1287,\n",
            "         -0.0574,  0.2905,  0.3487,  0.2831, -0.2610,  0.3678, -0.0913,  0.1569,\n",
            "          0.0292, -0.2788, -0.1731, -0.2915,  0.2259,  0.1612,  0.3578, -0.3176,\n",
            "         -0.0024,  0.2828,  0.3750,  0.3640, -0.1596, -0.2755, -0.1410,  0.2619],\n",
            "        [-0.1277,  0.0303,  0.1724, -0.2758, -0.0612,  0.1635,  0.2044, -0.2215,\n",
            "          0.3003, -0.0222,  0.1329, -0.0526,  0.1186, -0.0493,  0.1521, -0.1209,\n",
            "         -0.3676,  0.1067, -0.2567, -0.3178,  0.1740, -0.1226,  0.2126, -0.1293,\n",
            "          0.3338, -0.0593,  0.0644,  0.3663, -0.3504, -0.3116,  0.2632,  0.2009],\n",
            "        [ 0.3360,  0.1896,  0.1881,  0.2605, -0.2705, -0.3571,  0.1134,  0.3317,\n",
            "          0.2843,  0.1291,  0.0860,  0.3087,  0.3420,  0.1620,  0.3090, -0.0063,\n",
            "         -0.0511, -0.0883,  0.0013, -0.1205,  0.2943, -0.0929, -0.0650,  0.1938,\n",
            "          0.2806, -0.2008,  0.0719,  0.1736, -0.3436,  0.2210, -0.2587, -0.0619],\n",
            "        [-0.2896, -0.0970,  0.2001, -0.1918, -0.2368, -0.3368, -0.3487, -0.2831,\n",
            "         -0.0249,  0.1367, -0.2578, -0.3531, -0.0714, -0.0308,  0.0823,  0.3769,\n",
            "          0.1515, -0.3381, -0.0591,  0.2992, -0.2515,  0.1517, -0.0268,  0.1605,\n",
            "         -0.1250,  0.2620, -0.2167,  0.2611,  0.0937, -0.1894, -0.2125,  0.1859],\n",
            "        [-0.3650, -0.2258,  0.0464,  0.0498,  0.0715, -0.2203, -0.2623,  0.0038,\n",
            "         -0.0955,  0.3286, -0.3669, -0.0968, -0.2665,  0.0145,  0.0523,  0.1307,\n",
            "         -0.0229,  0.2240,  0.3240, -0.0756, -0.0784,  0.0360, -0.1680,  0.0904,\n",
            "          0.1639,  0.3041,  0.3191, -0.1143,  0.1315, -0.2486,  0.1517,  0.3695],\n",
            "        [-0.1322,  0.2391, -0.3609,  0.2071,  0.0586,  0.3114,  0.0107,  0.2996,\n",
            "          0.0325, -0.2288, -0.1049,  0.3442, -0.2632,  0.3412,  0.1935,  0.0880,\n",
            "          0.1062, -0.1627, -0.3035,  0.0522,  0.2958,  0.3057,  0.0758, -0.2122,\n",
            "         -0.0681,  0.2893, -0.2608,  0.3305, -0.3759, -0.1999,  0.3105,  0.1000]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.5753,  0.6647,  0.3219, -0.6535,  0.0892,  0.2491,  0.1176,  0.1321,\n",
            "          0.5932,  0.2374,  0.5292, -0.3562, -0.6993,  0.5872, -0.1960, -0.1711,\n",
            "          0.0644, -0.3000, -0.3774, -0.4436,  0.2269,  0.2256,  0.3630,  0.3597,\n",
            "         -0.7464,  0.7540, -0.3816, -0.1332,  0.5880,  0.3353, -0.2263,  0.6717],\n",
            "        [ 0.5386,  0.5052,  0.0913,  0.6688,  0.2799,  0.7188, -0.0945, -0.5008,\n",
            "         -0.0048, -0.1202, -0.2824, -0.2450,  0.5891, -0.6486,  0.3434,  0.6776,\n",
            "          0.7029, -0.0879, -0.0312,  0.0358, -0.2164,  0.2992, -0.0129, -0.6819,\n",
            "          0.1235,  0.6058,  0.4565, -0.1238, -0.6831, -0.0333, -0.6649,  0.4745],\n",
            "        [ 0.7435,  0.3073, -0.2569,  0.2649,  0.5872, -0.7239, -0.6130,  0.6790,\n",
            "          0.5321,  0.1693, -0.1787,  0.2349, -0.0970,  0.7452, -0.1102,  0.3408,\n",
            "          0.4660, -0.1657,  0.3242, -0.4810,  0.0084, -0.4625,  0.0028, -0.0605,\n",
            "         -0.7231,  0.0398, -0.3777, -0.2140, -0.7046, -0.6083, -0.5278,  0.2692],\n",
            "        [ 0.0440,  0.4922,  0.3088,  0.5838, -0.0176,  0.7375, -0.5456, -0.1662,\n",
            "          0.1588, -0.6529, -0.4444,  0.3546, -0.4088,  0.0851,  0.5075,  0.6985,\n",
            "         -0.3551, -0.6641, -0.2401,  0.3852,  0.0509,  0.3557, -0.5794, -0.7532,\n",
            "         -0.4407,  0.3279, -0.2244,  0.6897,  0.3861,  0.6682,  0.0605,  0.1581],\n",
            "        [ 0.3318,  0.3162,  0.1280, -0.4659,  0.3306, -0.2931,  0.3973,  0.2575,\n",
            "         -0.1148,  0.5810,  0.6974,  0.5661, -0.5219,  0.7356, -0.1826,  0.3138,\n",
            "          0.0584, -0.5575, -0.3462, -0.5830,  0.4518,  0.3224,  0.7156, -0.6352,\n",
            "         -0.0049,  0.5657,  0.7500,  0.7279, -0.3191, -0.5510, -0.2821,  0.5238],\n",
            "        [-0.2554,  0.0606,  0.3449, -0.5516, -0.1224,  0.3270,  0.4087, -0.4430,\n",
            "          0.6006, -0.0444,  0.2658, -0.1052,  0.2371, -0.0987,  0.3043, -0.2418,\n",
            "         -0.7352,  0.2134, -0.5134, -0.6356,  0.3480, -0.2453,  0.4252, -0.2587,\n",
            "          0.6675, -0.1186,  0.1288,  0.7327, -0.7009, -0.6233,  0.5264,  0.4018],\n",
            "        [ 0.6719,  0.3792,  0.3761,  0.5210, -0.5410, -0.7142,  0.2269,  0.6634,\n",
            "          0.5685,  0.2583,  0.1719,  0.6175,  0.6839,  0.3240,  0.6179, -0.0126,\n",
            "         -0.1022, -0.1766,  0.0026, -0.2409,  0.5886, -0.1858, -0.1299,  0.3876,\n",
            "          0.5613, -0.4015,  0.1438,  0.3472, -0.6873,  0.4419, -0.5174, -0.1238],\n",
            "        [-0.5792, -0.1941,  0.4001, -0.3837, -0.4735, -0.6737, -0.6974, -0.5662,\n",
            "         -0.0498,  0.2733, -0.5156, -0.7062, -0.1428, -0.0616,  0.1646,  0.7538,\n",
            "          0.3031, -0.6761, -0.1182,  0.5985, -0.5030,  0.3034, -0.0536,  0.3209,\n",
            "         -0.2500,  0.5241, -0.4333,  0.5223,  0.1873, -0.3789, -0.4250,  0.3718],\n",
            "        [-0.7301, -0.4516,  0.0928,  0.0997,  0.1431, -0.4406, -0.5246,  0.0076,\n",
            "         -0.1910,  0.6573, -0.7338, -0.1936, -0.5330,  0.0290,  0.1047,  0.2614,\n",
            "         -0.0458,  0.4481,  0.6481, -0.1513, -0.1569,  0.0721, -0.3360,  0.1808,\n",
            "          0.3278,  0.6083,  0.6381, -0.2286,  0.2631, -0.4971,  0.3033,  0.7389],\n",
            "        [-0.2644,  0.4783, -0.7219,  0.4143,  0.1171,  0.6228,  0.0215,  0.5993,\n",
            "          0.0651, -0.4576, -0.2099,  0.6884, -0.5263,  0.6823,  0.3869,  0.1759,\n",
            "          0.2124, -0.3253, -0.6070,  0.1044,  0.5916,  0.6115,  0.1516, -0.4245,\n",
            "         -0.1363,  0.5787, -0.5215,  0.6609, -0.7519, -0.3998,  0.6210,  0.2000]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
            "        0.0200], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "2\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.5621,  0.6494,  0.3145, -0.6385,  0.0871,  0.2434,  0.1149,  0.1290,\n",
            "          0.5796,  0.2319]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 1.1241,  1.2988,  0.6290, -1.2769,  0.1743,  0.4867,  0.2299,  0.2580,\n",
            "          1.1591,  0.4639]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0200], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Focus(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (dropout1): Dropout2d(p=0.05, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9"
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I"
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX"
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7"
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_focus = optim.Adam(focus_net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.009, amsgrad=False)\n",
        "# optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer_classify = optim.Adam(classify.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.009, amsgrad=False)\n",
        "# optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylCWkAlwv6EL"
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQASTbrKv586",
        "outputId": "d8ed31c1-f953-4778-8459-ed07d86085c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 33 %\n",
            "total correct 9972\n",
            "total train set images 30000\n",
            "focus_true_pred_true 1014 =============> FTPT : 3 %\n",
            "focus_false_pred_true 8958 =============> FFPT : 29 %\n",
            "focus_true_pred_false 2223 =============> FTPF : 7 %\n",
            "focus_false_pred_false 17805 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  29373\n",
            "argmax_less_than_half ==================>  627\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZmkgV3cv55D",
        "outputId": "22908cc9-61e6-444a-ed14-6371a1447016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 33 %\n",
            "total correct 3366\n",
            "total train set images 10000\n",
            "focus_true_pred_true 342 =============> FTPT : 3 %\n",
            "focus_false_pred_true 3024 =============> FFPT : 30 %\n",
            "focus_true_pred_false 705 =============> FTPF : 7 %\n",
            "focus_false_pred_false 5929 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  9776\n",
            "argmax_less_than_half ==================>  224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFfAJZkcZEsY",
        "outputId": "285b5032-39ed-48ce-9c3c-fd178f8dadef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nos_epochs = 300\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_focus.step()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    col1.append(epoch+1)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 1.103\n",
            "[1,   120] loss: 1.100\n",
            "[2,    60] loss: 1.088\n",
            "[2,   120] loss: 1.062\n",
            "[3,    60] loss: 1.038\n",
            "[3,   120] loss: 1.007\n",
            "[4,    60] loss: 0.979\n",
            "[4,   120] loss: 0.957\n",
            "[5,    60] loss: 0.932\n",
            "[5,   120] loss: 0.908\n",
            "[6,    60] loss: 0.862\n",
            "[6,   120] loss: 0.854\n",
            "[7,    60] loss: 0.820\n",
            "[7,   120] loss: 0.814\n",
            "[8,    60] loss: 0.788\n",
            "[8,   120] loss: 0.785\n",
            "[9,    60] loss: 0.768\n",
            "[9,   120] loss: 0.743\n",
            "[10,    60] loss: 0.741\n",
            "[10,   120] loss: 0.751\n",
            "[11,    60] loss: 0.715\n",
            "[11,   120] loss: 0.722\n",
            "[12,    60] loss: 0.704\n",
            "[12,   120] loss: 0.702\n",
            "[13,    60] loss: 0.689\n",
            "[13,   120] loss: 0.682\n",
            "[14,    60] loss: 0.650\n",
            "[14,   120] loss: 0.666\n",
            "[15,    60] loss: 0.635\n",
            "[15,   120] loss: 0.653\n",
            "[16,    60] loss: 0.613\n",
            "[16,   120] loss: 0.617\n",
            "[17,    60] loss: 0.605\n",
            "[17,   120] loss: 0.642\n",
            "[18,    60] loss: 0.618\n",
            "[18,   120] loss: 0.597\n",
            "[19,    60] loss: 0.581\n",
            "[19,   120] loss: 0.583\n",
            "[20,    60] loss: 0.563\n",
            "[20,   120] loss: 0.571\n",
            "[21,    60] loss: 0.554\n",
            "[21,   120] loss: 0.557\n",
            "[22,    60] loss: 0.548\n",
            "[22,   120] loss: 0.538\n",
            "[23,    60] loss: 0.528\n",
            "[23,   120] loss: 0.537\n",
            "[24,    60] loss: 0.508\n",
            "[24,   120] loss: 0.516\n",
            "[25,    60] loss: 0.527\n",
            "[25,   120] loss: 0.527\n",
            "[26,    60] loss: 0.501\n",
            "[26,   120] loss: 0.512\n",
            "[27,    60] loss: 0.490\n",
            "[27,   120] loss: 0.503\n",
            "[28,    60] loss: 0.486\n",
            "[28,   120] loss: 0.498\n",
            "[29,    60] loss: 0.461\n",
            "[29,   120] loss: 0.495\n",
            "[30,    60] loss: 0.471\n",
            "[30,   120] loss: 0.450\n",
            "[31,    60] loss: 0.427\n",
            "[31,   120] loss: 0.467\n",
            "[32,    60] loss: 0.430\n",
            "[32,   120] loss: 0.446\n",
            "[33,    60] loss: 0.428\n",
            "[33,   120] loss: 0.442\n",
            "[34,    60] loss: 0.429\n",
            "[34,   120] loss: 0.438\n",
            "[35,    60] loss: 0.405\n",
            "[35,   120] loss: 0.421\n",
            "[36,    60] loss: 0.406\n",
            "[36,   120] loss: 0.398\n",
            "[37,    60] loss: 0.401\n",
            "[37,   120] loss: 0.403\n",
            "[38,    60] loss: 0.386\n",
            "[38,   120] loss: 0.394\n",
            "[39,    60] loss: 0.381\n",
            "[39,   120] loss: 0.396\n",
            "[40,    60] loss: 0.379\n",
            "[40,   120] loss: 0.381\n",
            "[41,    60] loss: 0.352\n",
            "[41,   120] loss: 0.364\n",
            "[42,    60] loss: 0.369\n",
            "[42,   120] loss: 0.357\n",
            "[43,    60] loss: 0.343\n",
            "[43,   120] loss: 0.358\n",
            "[44,    60] loss: 0.352\n",
            "[44,   120] loss: 0.359\n",
            "[45,    60] loss: 0.334\n",
            "[45,   120] loss: 0.336\n",
            "[46,    60] loss: 0.315\n",
            "[46,   120] loss: 0.327\n",
            "[47,    60] loss: 0.311\n",
            "[47,   120] loss: 0.316\n",
            "[48,    60] loss: 0.298\n",
            "[48,   120] loss: 0.330\n",
            "[49,    60] loss: 0.291\n",
            "[49,   120] loss: 0.286\n",
            "[50,    60] loss: 0.281\n",
            "[50,   120] loss: 0.294\n",
            "[51,    60] loss: 0.270\n",
            "[51,   120] loss: 0.291\n",
            "[52,    60] loss: 0.267\n",
            "[52,   120] loss: 0.288\n",
            "[53,    60] loss: 0.257\n",
            "[53,   120] loss: 0.268\n",
            "[54,    60] loss: 0.244\n",
            "[54,   120] loss: 0.258\n",
            "[55,    60] loss: 0.228\n",
            "[55,   120] loss: 0.250\n",
            "[56,    60] loss: 0.223\n",
            "[56,   120] loss: 0.246\n",
            "[57,    60] loss: 0.218\n",
            "[57,   120] loss: 0.248\n",
            "[58,    60] loss: 0.218\n",
            "[58,   120] loss: 0.239\n",
            "[59,    60] loss: 0.200\n",
            "[59,   120] loss: 0.220\n",
            "[60,    60] loss: 0.193\n",
            "[60,   120] loss: 0.218\n",
            "[61,    60] loss: 0.198\n",
            "[61,   120] loss: 0.219\n",
            "[62,    60] loss: 0.184\n",
            "[62,   120] loss: 0.206\n",
            "[63,    60] loss: 0.185\n",
            "[63,   120] loss: 0.196\n",
            "[64,    60] loss: 0.172\n",
            "[64,   120] loss: 0.191\n",
            "[65,    60] loss: 0.172\n",
            "[65,   120] loss: 0.180\n",
            "[66,    60] loss: 0.158\n",
            "[66,   120] loss: 0.166\n",
            "[67,    60] loss: 0.146\n",
            "[67,   120] loss: 0.171\n",
            "[68,    60] loss: 0.141\n",
            "[68,   120] loss: 0.170\n",
            "[69,    60] loss: 0.143\n",
            "[69,   120] loss: 0.162\n",
            "[70,    60] loss: 0.136\n",
            "[70,   120] loss: 0.138\n",
            "[71,    60] loss: 0.133\n",
            "[71,   120] loss: 0.137\n",
            "[72,    60] loss: 0.130\n",
            "[72,   120] loss: 0.134\n",
            "[73,    60] loss: 0.115\n",
            "[73,   120] loss: 0.129\n",
            "[74,    60] loss: 0.117\n",
            "[74,   120] loss: 0.125\n",
            "[75,    60] loss: 0.109\n",
            "[75,   120] loss: 0.118\n",
            "[76,    60] loss: 0.107\n",
            "[76,   120] loss: 0.111\n",
            "[77,    60] loss: 0.098\n",
            "[77,   120] loss: 0.107\n",
            "[78,    60] loss: 0.099\n",
            "[78,   120] loss: 0.116\n",
            "[79,    60] loss: 0.100\n",
            "[79,   120] loss: 0.103\n",
            "[80,    60] loss: 0.092\n",
            "[80,   120] loss: 0.109\n",
            "[81,    60] loss: 0.096\n",
            "[81,   120] loss: 0.102\n",
            "[82,    60] loss: 0.088\n",
            "[82,   120] loss: 0.089\n",
            "[83,    60] loss: 0.084\n",
            "[83,   120] loss: 0.092\n",
            "[84,    60] loss: 0.080\n",
            "[84,   120] loss: 0.094\n",
            "[85,    60] loss: 0.086\n",
            "[85,   120] loss: 0.081\n",
            "[86,    60] loss: 0.074\n",
            "[86,   120] loss: 0.083\n",
            "[87,    60] loss: 0.073\n",
            "[87,   120] loss: 0.090\n",
            "[88,    60] loss: 0.081\n",
            "[88,   120] loss: 0.088\n",
            "[89,    60] loss: 0.076\n",
            "[89,   120] loss: 0.082\n",
            "[90,    60] loss: 0.065\n",
            "[90,   120] loss: 0.088\n",
            "[91,    60] loss: 0.072\n",
            "[91,   120] loss: 0.075\n",
            "[92,    60] loss: 0.070\n",
            "[92,   120] loss: 0.064\n",
            "[93,    60] loss: 0.068\n",
            "[93,   120] loss: 0.074\n",
            "[94,    60] loss: 0.066\n",
            "[94,   120] loss: 0.073\n",
            "[95,    60] loss: 0.061\n",
            "[95,   120] loss: 0.067\n",
            "[96,    60] loss: 0.062\n",
            "[96,   120] loss: 0.065\n",
            "[97,    60] loss: 0.061\n",
            "[97,   120] loss: 0.065\n",
            "[98,    60] loss: 0.056\n",
            "[98,   120] loss: 0.066\n",
            "[99,    60] loss: 0.057\n",
            "[99,   120] loss: 0.055\n",
            "[100,    60] loss: 0.047\n",
            "[100,   120] loss: 0.064\n",
            "[101,    60] loss: 0.070\n",
            "[101,   120] loss: 0.066\n",
            "[102,    60] loss: 0.058\n",
            "[102,   120] loss: 0.066\n",
            "[103,    60] loss: 0.054\n",
            "[103,   120] loss: 0.053\n",
            "[104,    60] loss: 0.058\n",
            "[104,   120] loss: 0.063\n",
            "[105,    60] loss: 0.057\n",
            "[105,   120] loss: 0.065\n",
            "[106,    60] loss: 0.059\n",
            "[106,   120] loss: 0.055\n",
            "[107,    60] loss: 0.056\n",
            "[107,   120] loss: 0.066\n",
            "[108,    60] loss: 0.049\n",
            "[108,   120] loss: 0.056\n",
            "[109,    60] loss: 0.049\n",
            "[109,   120] loss: 0.049\n",
            "[110,    60] loss: 0.047\n",
            "[110,   120] loss: 0.051\n",
            "[111,    60] loss: 0.044\n",
            "[111,   120] loss: 0.051\n",
            "[112,    60] loss: 0.041\n",
            "[112,   120] loss: 0.051\n",
            "[113,    60] loss: 0.040\n",
            "[113,   120] loss: 0.049\n",
            "[114,    60] loss: 0.046\n",
            "[114,   120] loss: 0.047\n",
            "[115,    60] loss: 0.048\n",
            "[115,   120] loss: 0.051\n",
            "[116,    60] loss: 0.040\n",
            "[116,   120] loss: 0.046\n",
            "[117,    60] loss: 0.050\n",
            "[117,   120] loss: 0.054\n",
            "[118,    60] loss: 0.059\n",
            "[118,   120] loss: 0.060\n",
            "[119,    60] loss: 0.049\n",
            "[119,   120] loss: 0.050\n",
            "[120,    60] loss: 0.042\n",
            "[120,   120] loss: 0.050\n",
            "[121,    60] loss: 0.047\n",
            "[121,   120] loss: 0.044\n",
            "[122,    60] loss: 0.041\n",
            "[122,   120] loss: 0.051\n",
            "[123,    60] loss: 0.039\n",
            "[123,   120] loss: 0.043\n",
            "[124,    60] loss: 0.039\n",
            "[124,   120] loss: 0.045\n",
            "[125,    60] loss: 0.040\n",
            "[125,   120] loss: 0.058\n",
            "[126,    60] loss: 0.044\n",
            "[126,   120] loss: 0.059\n",
            "[127,    60] loss: 0.053\n",
            "[127,   120] loss: 0.057\n",
            "[128,    60] loss: 0.048\n",
            "[128,   120] loss: 0.044\n",
            "[129,    60] loss: 0.039\n",
            "[129,   120] loss: 0.049\n",
            "[130,    60] loss: 0.043\n",
            "[130,   120] loss: 0.043\n",
            "[131,    60] loss: 0.044\n",
            "[131,   120] loss: 0.044\n",
            "[132,    60] loss: 0.040\n",
            "[132,   120] loss: 0.043\n",
            "[133,    60] loss: 0.037\n",
            "[133,   120] loss: 0.044\n",
            "[134,    60] loss: 0.042\n",
            "[134,   120] loss: 0.056\n",
            "[135,    60] loss: 0.040\n",
            "[135,   120] loss: 0.041\n",
            "[136,    60] loss: 0.036\n",
            "[136,   120] loss: 0.037\n",
            "[137,    60] loss: 0.042\n",
            "[137,   120] loss: 0.043\n",
            "[138,    60] loss: 0.042\n",
            "[138,   120] loss: 0.044\n",
            "[139,    60] loss: 0.034\n",
            "[139,   120] loss: 0.038\n",
            "[140,    60] loss: 0.039\n",
            "[140,   120] loss: 0.042\n",
            "[141,    60] loss: 0.036\n",
            "[141,   120] loss: 0.036\n",
            "[142,    60] loss: 0.035\n",
            "[142,   120] loss: 0.035\n",
            "[143,    60] loss: 0.035\n",
            "[143,   120] loss: 0.039\n",
            "[144,    60] loss: 0.036\n",
            "[144,   120] loss: 0.047\n",
            "[145,    60] loss: 0.042\n",
            "[145,   120] loss: 0.043\n",
            "[146,    60] loss: 0.039\n",
            "[146,   120] loss: 0.044\n",
            "[147,    60] loss: 0.036\n",
            "[147,   120] loss: 0.039\n",
            "[148,    60] loss: 0.036\n",
            "[148,   120] loss: 0.032\n",
            "[149,    60] loss: 0.027\n",
            "[149,   120] loss: 0.030\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "outputId": "974ed991-7c6f-4486-d3cc-6e536c746715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "name = \"focus_random_classify_random_train_both_\"+str(k)\n",
        "name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'focus_random_classify_random_train_both_2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE"
      },
      "source": [
        "#torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/focus_net_params_multiplied_by_k/\"+name+\".pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o"
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO"
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "outputId": "7ce59a4e-0851-4a0c-c513-aa0d33e6a881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>29373</td>\n",
              "      <td>627</td>\n",
              "      <td>1014</td>\n",
              "      <td>8958</td>\n",
              "      <td>2223</td>\n",
              "      <td>17805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29192</td>\n",
              "      <td>808</td>\n",
              "      <td>1311</td>\n",
              "      <td>8788</td>\n",
              "      <td>2148</td>\n",
              "      <td>17753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>29871</td>\n",
              "      <td>129</td>\n",
              "      <td>8970</td>\n",
              "      <td>8320</td>\n",
              "      <td>1047</td>\n",
              "      <td>11663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>29834</td>\n",
              "      <td>166</td>\n",
              "      <td>10982</td>\n",
              "      <td>8899</td>\n",
              "      <td>786</td>\n",
              "      <td>9333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>29401</td>\n",
              "      <td>599</td>\n",
              "      <td>12904</td>\n",
              "      <td>8932</td>\n",
              "      <td>603</td>\n",
              "      <td>7561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>29574</td>\n",
              "      <td>426</td>\n",
              "      <td>13994</td>\n",
              "      <td>8840</td>\n",
              "      <td>501</td>\n",
              "      <td>6665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>29487</td>\n",
              "      <td>513</td>\n",
              "      <td>14533</td>\n",
              "      <td>9025</td>\n",
              "      <td>354</td>\n",
              "      <td>6088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>29274</td>\n",
              "      <td>726</td>\n",
              "      <td>15979</td>\n",
              "      <td>8593</td>\n",
              "      <td>370</td>\n",
              "      <td>5058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>29324</td>\n",
              "      <td>676</td>\n",
              "      <td>16612</td>\n",
              "      <td>8530</td>\n",
              "      <td>338</td>\n",
              "      <td>4520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>29041</td>\n",
              "      <td>959</td>\n",
              "      <td>17544</td>\n",
              "      <td>8182</td>\n",
              "      <td>327</td>\n",
              "      <td>3947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>28598</td>\n",
              "      <td>1402</td>\n",
              "      <td>18406</td>\n",
              "      <td>7909</td>\n",
              "      <td>354</td>\n",
              "      <td>3331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>51</td>\n",
              "      <td>28545</td>\n",
              "      <td>1455</td>\n",
              "      <td>19218</td>\n",
              "      <td>7583</td>\n",
              "      <td>346</td>\n",
              "      <td>2853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>56</td>\n",
              "      <td>27693</td>\n",
              "      <td>2307</td>\n",
              "      <td>20098</td>\n",
              "      <td>7297</td>\n",
              "      <td>325</td>\n",
              "      <td>2280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>61</td>\n",
              "      <td>27374</td>\n",
              "      <td>2626</td>\n",
              "      <td>20749</td>\n",
              "      <td>6998</td>\n",
              "      <td>321</td>\n",
              "      <td>1932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>66</td>\n",
              "      <td>26527</td>\n",
              "      <td>3473</td>\n",
              "      <td>21415</td>\n",
              "      <td>6927</td>\n",
              "      <td>261</td>\n",
              "      <td>1397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>71</td>\n",
              "      <td>26028</td>\n",
              "      <td>3972</td>\n",
              "      <td>21927</td>\n",
              "      <td>6718</td>\n",
              "      <td>238</td>\n",
              "      <td>1117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>76</td>\n",
              "      <td>25514</td>\n",
              "      <td>4486</td>\n",
              "      <td>22321</td>\n",
              "      <td>6582</td>\n",
              "      <td>209</td>\n",
              "      <td>888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>81</td>\n",
              "      <td>24855</td>\n",
              "      <td>5145</td>\n",
              "      <td>22595</td>\n",
              "      <td>6440</td>\n",
              "      <td>227</td>\n",
              "      <td>738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>86</td>\n",
              "      <td>24326</td>\n",
              "      <td>5674</td>\n",
              "      <td>22904</td>\n",
              "      <td>6331</td>\n",
              "      <td>176</td>\n",
              "      <td>589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>91</td>\n",
              "      <td>23951</td>\n",
              "      <td>6049</td>\n",
              "      <td>23034</td>\n",
              "      <td>6295</td>\n",
              "      <td>167</td>\n",
              "      <td>504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>96</td>\n",
              "      <td>23754</td>\n",
              "      <td>6246</td>\n",
              "      <td>23137</td>\n",
              "      <td>6265</td>\n",
              "      <td>159</td>\n",
              "      <td>439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>101</td>\n",
              "      <td>23276</td>\n",
              "      <td>6724</td>\n",
              "      <td>23079</td>\n",
              "      <td>6310</td>\n",
              "      <td>196</td>\n",
              "      <td>415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>106</td>\n",
              "      <td>23183</td>\n",
              "      <td>6817</td>\n",
              "      <td>23262</td>\n",
              "      <td>6227</td>\n",
              "      <td>149</td>\n",
              "      <td>362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>111</td>\n",
              "      <td>23068</td>\n",
              "      <td>6932</td>\n",
              "      <td>23388</td>\n",
              "      <td>6204</td>\n",
              "      <td>123</td>\n",
              "      <td>285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>116</td>\n",
              "      <td>22777</td>\n",
              "      <td>7223</td>\n",
              "      <td>23455</td>\n",
              "      <td>6177</td>\n",
              "      <td>118</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>121</td>\n",
              "      <td>22758</td>\n",
              "      <td>7242</td>\n",
              "      <td>23651</td>\n",
              "      <td>5976</td>\n",
              "      <td>122</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>126</td>\n",
              "      <td>22431</td>\n",
              "      <td>7569</td>\n",
              "      <td>23425</td>\n",
              "      <td>6113</td>\n",
              "      <td>157</td>\n",
              "      <td>305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>131</td>\n",
              "      <td>22386</td>\n",
              "      <td>7614</td>\n",
              "      <td>23548</td>\n",
              "      <td>6082</td>\n",
              "      <td>130</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>136</td>\n",
              "      <td>22216</td>\n",
              "      <td>7784</td>\n",
              "      <td>23693</td>\n",
              "      <td>6001</td>\n",
              "      <td>105</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>141</td>\n",
              "      <td>22097</td>\n",
              "      <td>7903</td>\n",
              "      <td>23709</td>\n",
              "      <td>6002</td>\n",
              "      <td>101</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>146</td>\n",
              "      <td>22034</td>\n",
              "      <td>7966</td>\n",
              "      <td>23617</td>\n",
              "      <td>6018</td>\n",
              "      <td>124</td>\n",
              "      <td>241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0         29373  ...                   2223                   17805\n",
              "1        1         29192  ...                   2148                   17753\n",
              "2        6         29871  ...                   1047                   11663\n",
              "3       11         29834  ...                    786                    9333\n",
              "4       16         29401  ...                    603                    7561\n",
              "5       21         29574  ...                    501                    6665\n",
              "6       26         29487  ...                    354                    6088\n",
              "7       31         29274  ...                    370                    5058\n",
              "8       36         29324  ...                    338                    4520\n",
              "9       41         29041  ...                    327                    3947\n",
              "10      46         28598  ...                    354                    3331\n",
              "11      51         28545  ...                    346                    2853\n",
              "12      56         27693  ...                    325                    2280\n",
              "13      61         27374  ...                    321                    1932\n",
              "14      66         26527  ...                    261                    1397\n",
              "15      71         26028  ...                    238                    1117\n",
              "16      76         25514  ...                    209                     888\n",
              "17      81         24855  ...                    227                     738\n",
              "18      86         24326  ...                    176                     589\n",
              "19      91         23951  ...                    167                     504\n",
              "20      96         23754  ...                    159                     439\n",
              "21     101         23276  ...                    196                     415\n",
              "22     106         23183  ...                    149                     362\n",
              "23     111         23068  ...                    123                     285\n",
              "24     116         22777  ...                    118                     250\n",
              "25     121         22758  ...                    122                     251\n",
              "26     126         22431  ...                    157                     305\n",
              "27     131         22386  ...                    130                     240\n",
              "28     136         22216  ...                    105                     201\n",
              "29     141         22097  ...                    101                     188\n",
              "30     146         22034  ...                    124                     241\n",
              "\n",
              "[31 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "outputId": "065a59ae-bf93-4b38-ae1a-80cdbdf4f07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "outputId": "7e40b049-ecb4-41b6-a1bb-13014110667e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9776</td>\n",
              "      <td>224</td>\n",
              "      <td>342</td>\n",
              "      <td>3024</td>\n",
              "      <td>705</td>\n",
              "      <td>5929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9695</td>\n",
              "      <td>305</td>\n",
              "      <td>761</td>\n",
              "      <td>2850</td>\n",
              "      <td>586</td>\n",
              "      <td>5803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>9945</td>\n",
              "      <td>55</td>\n",
              "      <td>2957</td>\n",
              "      <td>2700</td>\n",
              "      <td>391</td>\n",
              "      <td>3952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>9949</td>\n",
              "      <td>51</td>\n",
              "      <td>3603</td>\n",
              "      <td>2819</td>\n",
              "      <td>355</td>\n",
              "      <td>3223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>9853</td>\n",
              "      <td>147</td>\n",
              "      <td>4221</td>\n",
              "      <td>2675</td>\n",
              "      <td>255</td>\n",
              "      <td>2849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>9857</td>\n",
              "      <td>143</td>\n",
              "      <td>4601</td>\n",
              "      <td>2657</td>\n",
              "      <td>269</td>\n",
              "      <td>2473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>9822</td>\n",
              "      <td>178</td>\n",
              "      <td>4805</td>\n",
              "      <td>2640</td>\n",
              "      <td>245</td>\n",
              "      <td>2310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>9768</td>\n",
              "      <td>232</td>\n",
              "      <td>5183</td>\n",
              "      <td>2504</td>\n",
              "      <td>214</td>\n",
              "      <td>2099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>9785</td>\n",
              "      <td>215</td>\n",
              "      <td>5369</td>\n",
              "      <td>2471</td>\n",
              "      <td>235</td>\n",
              "      <td>1925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>9584</td>\n",
              "      <td>416</td>\n",
              "      <td>5667</td>\n",
              "      <td>2328</td>\n",
              "      <td>241</td>\n",
              "      <td>1764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>9560</td>\n",
              "      <td>440</td>\n",
              "      <td>5805</td>\n",
              "      <td>2351</td>\n",
              "      <td>258</td>\n",
              "      <td>1586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>51</td>\n",
              "      <td>9537</td>\n",
              "      <td>463</td>\n",
              "      <td>6070</td>\n",
              "      <td>2253</td>\n",
              "      <td>233</td>\n",
              "      <td>1444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>56</td>\n",
              "      <td>9328</td>\n",
              "      <td>672</td>\n",
              "      <td>6281</td>\n",
              "      <td>2166</td>\n",
              "      <td>251</td>\n",
              "      <td>1302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>61</td>\n",
              "      <td>9063</td>\n",
              "      <td>937</td>\n",
              "      <td>6513</td>\n",
              "      <td>2112</td>\n",
              "      <td>284</td>\n",
              "      <td>1091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>66</td>\n",
              "      <td>8730</td>\n",
              "      <td>1270</td>\n",
              "      <td>6896</td>\n",
              "      <td>1985</td>\n",
              "      <td>249</td>\n",
              "      <td>870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>71</td>\n",
              "      <td>8435</td>\n",
              "      <td>1565</td>\n",
              "      <td>6907</td>\n",
              "      <td>2024</td>\n",
              "      <td>266</td>\n",
              "      <td>803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>76</td>\n",
              "      <td>8399</td>\n",
              "      <td>1601</td>\n",
              "      <td>7013</td>\n",
              "      <td>1851</td>\n",
              "      <td>256</td>\n",
              "      <td>880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>81</td>\n",
              "      <td>8111</td>\n",
              "      <td>1889</td>\n",
              "      <td>7148</td>\n",
              "      <td>1824</td>\n",
              "      <td>254</td>\n",
              "      <td>774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>86</td>\n",
              "      <td>7999</td>\n",
              "      <td>2001</td>\n",
              "      <td>7237</td>\n",
              "      <td>1753</td>\n",
              "      <td>245</td>\n",
              "      <td>765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>91</td>\n",
              "      <td>7978</td>\n",
              "      <td>2022</td>\n",
              "      <td>7323</td>\n",
              "      <td>1785</td>\n",
              "      <td>233</td>\n",
              "      <td>659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>96</td>\n",
              "      <td>7734</td>\n",
              "      <td>2266</td>\n",
              "      <td>7128</td>\n",
              "      <td>1939</td>\n",
              "      <td>257</td>\n",
              "      <td>676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>101</td>\n",
              "      <td>7540</td>\n",
              "      <td>2460</td>\n",
              "      <td>7291</td>\n",
              "      <td>1791</td>\n",
              "      <td>284</td>\n",
              "      <td>634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>106</td>\n",
              "      <td>7725</td>\n",
              "      <td>2275</td>\n",
              "      <td>7302</td>\n",
              "      <td>1780</td>\n",
              "      <td>251</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>111</td>\n",
              "      <td>7376</td>\n",
              "      <td>2624</td>\n",
              "      <td>7390</td>\n",
              "      <td>1755</td>\n",
              "      <td>269</td>\n",
              "      <td>586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>116</td>\n",
              "      <td>7197</td>\n",
              "      <td>2803</td>\n",
              "      <td>7377</td>\n",
              "      <td>1764</td>\n",
              "      <td>286</td>\n",
              "      <td>573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>121</td>\n",
              "      <td>7418</td>\n",
              "      <td>2582</td>\n",
              "      <td>7340</td>\n",
              "      <td>1792</td>\n",
              "      <td>256</td>\n",
              "      <td>612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>126</td>\n",
              "      <td>7218</td>\n",
              "      <td>2782</td>\n",
              "      <td>7259</td>\n",
              "      <td>1859</td>\n",
              "      <td>314</td>\n",
              "      <td>568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>131</td>\n",
              "      <td>7302</td>\n",
              "      <td>2698</td>\n",
              "      <td>7384</td>\n",
              "      <td>1813</td>\n",
              "      <td>298</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>136</td>\n",
              "      <td>7315</td>\n",
              "      <td>2685</td>\n",
              "      <td>7459</td>\n",
              "      <td>1719</td>\n",
              "      <td>290</td>\n",
              "      <td>532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>141</td>\n",
              "      <td>7150</td>\n",
              "      <td>2850</td>\n",
              "      <td>7484</td>\n",
              "      <td>1768</td>\n",
              "      <td>290</td>\n",
              "      <td>458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>146</td>\n",
              "      <td>7074</td>\n",
              "      <td>2926</td>\n",
              "      <td>7440</td>\n",
              "      <td>1690</td>\n",
              "      <td>293</td>\n",
              "      <td>577</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0          9776  ...                    705                    5929\n",
              "1        1          9695  ...                    586                    5803\n",
              "2        6          9945  ...                    391                    3952\n",
              "3       11          9949  ...                    355                    3223\n",
              "4       16          9853  ...                    255                    2849\n",
              "5       21          9857  ...                    269                    2473\n",
              "6       26          9822  ...                    245                    2310\n",
              "7       31          9768  ...                    214                    2099\n",
              "8       36          9785  ...                    235                    1925\n",
              "9       41          9584  ...                    241                    1764\n",
              "10      46          9560  ...                    258                    1586\n",
              "11      51          9537  ...                    233                    1444\n",
              "12      56          9328  ...                    251                    1302\n",
              "13      61          9063  ...                    284                    1091\n",
              "14      66          8730  ...                    249                     870\n",
              "15      71          8435  ...                    266                     803\n",
              "16      76          8399  ...                    256                     880\n",
              "17      81          8111  ...                    254                     774\n",
              "18      86          7999  ...                    245                     765\n",
              "19      91          7978  ...                    233                     659\n",
              "20      96          7734  ...                    257                     676\n",
              "21     101          7540  ...                    284                     634\n",
              "22     106          7725  ...                    251                     667\n",
              "23     111          7376  ...                    269                     586\n",
              "24     116          7197  ...                    286                     573\n",
              "25     121          7418  ...                    256                     612\n",
              "26     126          7218  ...                    314                     568\n",
              "27     131          7302  ...                    298                     505\n",
              "28     136          7315  ...                    290                     532\n",
              "29     141          7150  ...                    290                     458\n",
              "30     146          7074  ...                    293                     577\n",
              "\n",
              "[31 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "outputId": "b731cd40-1008-4885-c30c-ee491c48d783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAEWCAYAAABoup70AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV5dn/8c+VPWFJgISwE/ZVWQuK+1Z3LeJCixVri+1jbevSWm2fx1r7a5/aWn26aUvdwLpRtWLVuqGiuIMsyr6FNUBYwpI9Odfvj5lIigESSHKSk+/79ZrXmblnzsx1RsM1c889923ujoiIiLQccdEOQERERBqXkr+IiEgLo+QvIiLSwij5i4iItDBK/iIiIi2Mkr+IiEgLo+Qv0sSYWQ8z22dm8dGORURik5K/tAhmdrWZfWpmRWa2xczuN7OMI9hPVWKumtzMCqstn3QE+8w1szOrlt19vbu3dvfKuu6roRwYo4g0b0r+EvPM7GbgLuBHQDpwHNATeM3Mkuqyr2qJubW7tw6Lh1Ure6degxcRaQBK/hLTzKwt8HPge+7+sruXu3sucDmQA1wZbneHmc0ws+lmttfMFpvZ6DoeK9nM7jaz9Wa21cz+Ymap4bpMM3vBzArMbKeZvWNmcWb2KNAD+FdYc3CLmeWENQoJ4XffMrNfmNm7YWyvmllmteNeZWbrzGyHmf3Poe7Szew8M1sS7meTmf2w2roLzGxBGON7ZnZsWP6FGOtyXkSk6VHyl1g3DkgBnq1e6O77gJeAs6oVXwQ8CWQAzwN/quOxfg30B4YDfYGuwO3hupuBjUAWkA38JAjDvw6sBy4Maw5+c5B9fw34BtARSAJ+CGBmg4H7gElAZ4Kaja6HiPFB4Nvu3gYYCrwR7mcE8BDwbaAD8FfgeTNLrkOMItJMKPlLrMsEtrt7RQ3r8sL1Vea4+0vhs/ZHgWG1PYiZGXAtcKO773T3vcCvgInhJuUEyblnWPvwjtdtYI2H3X2FuxcDMwguMAAuBf7l7nPcvYzgYuNQ+y0HBptZW3ff5e6fhOXXAn919w/dvdLdpwGlBI9IRCTGKPlLrNsOZFZVoR+gc7i+ypZq80VAykG+V5MsIA2YF1abFwAvh+UAvwVWAa+a2Rozu7UuP6KG2KraG3QBNlStcPciYMch9jMBOA9YZ2azzez4sLwncHNV7GH83cP9i0iMUfKXWPc+wR3sJdULzaw1cC4wq56Osx0oBoa4e0Y4pVc1CnT3ve5+s7v3Jni8cJOZnRF+92iG1swDulUthG0MOhxsY3f/2N0vJnh88BxBLQIEFxC/rBZ7hrunufsT9RCjiDQxSv4S09x9N0GDvz+a2TlmlmhmOQRJbyNB9X59HCcC/A2418w6AphZVzM7O5y/wMz6ho8HdgOVQCT8+lag9xEe+mngQjMbF765cAdgNW1oZklmNsnM0t29HNhTLYa/Ad8xs7EWaGVm55tZm3qIUUSaGCV/iXlhA7WfAHcTJLwPCe50z3D30no81I8JqvY/MLM9wOvAgHBdv3B5H0FtxH3u/ma47n+B/w6r239IHbj7YuB7BA0V88L9byOo7ajJ14HcML7vEDQUxN3nAlMIGjnuCn/H1dW+d8QxikjTY3VrcyQiTVn4OKMA6Ofua6Mdj4g0TbrzF2nmzOxCM0szs1YEtRufArnRjUpEmjIlf5Hm72Jgczj1AybW8TVCEWlhVO0vIiLSwujOX0REpIWpbQcmMSMzM9NzcnKiHYaISLMxb9687e6edfgtpblocck/JyeHuXPnRjsMEZFmw8zWRTsGqV+q9hcREWlhlPxFRERaGCV/ERGRFkbJX0REpIVpsORvZg+Z2TYz+6xaWXsze83MVoaf7cJyM7M/mNkqM1tkZiOrfWdyuP1KM5tcrXyUmX0afucP4YApIiIichgNeef/CHDOAWW3ArPcvR/BUKpVY5qfS9AzWT/gWuB+CC4WgJ8BY4ExwM+qLhjCbaZU+96BxxIREZEaNFjyd/e3gZ0HFF8MTAvnpwFfqVY+3QMfABlm1hk4G3jN3Xe6+y7gNeCccF1bd/8g7MZ0erV9iYiIyCE09nv+2e6eF85vAbLD+a4EQ6xW2RiWHap8Yw3lNTKzawlqFOjRo8dRhF97udsLmb0in4qI4+5E3Ik4RNxxh0ik2jLQrV0qgzu3pV92a5IT4hslRhERaZmi1smPu7uZNcrAAu4+FZgKMHr06AY95rIte7jvzdW8sGgzkSM4Unyc0SerFYM6t602taFjm5T6D1ZERFqkxk7+W82ss7vnhVX328LyTUD3att1C8s2AaceUP5WWN6thu2jZsGGAv70xipeX7qVVknxTDm5N1eO7Unb1ETiDOLMiDPDPp8HCz8jDrk7Clmatyec9vLR2p3MXLD58/1ntk5iUOe2dGuXBjiRCJ/XJnyhZgHAoXVyAulpiaSnJtI2Nfg8cGqbkkBCvF76EBFpSRo7+T8PTAZ+HX7OrFZ+vZk9SdC4b3d4gfAK8Ktqjfy+DNzm7jvNbI+ZHQd8CFwF/LEhA9+ws4iuGanExe1/qcDdeX/NDu57czVzVm0nIy2RG8/sz+RxPclIS6r1vuMN+mS1pk9Way44tsvn5bsKy1i6JbgYqH5hEHfgBUTcf15cVEW4r7SC3cXllJRHDnn8jLREstukkJ2eQnabZDqlp9CxbQqd2qaQ3TaZTm1T6NA6mfgDfntZZYSS8gilFZWUlkcorYhQUl5JWWWEPlmtSU9NrPU5EBGRxtNgyd/MniC4a880s40ErfZ/Dcwws28C64DLw81fAs4DVgFFwDcAwiT/C+DjcLs73b2qEeF1BG8UpAL/DqcGUVBUxvj73mNYt3TuuXw4bVMTeHP5Nv70xio+WV9AVptkfnLeQL42tietk+vvlLZrlcS4PpmM65N5VPspKa9kT3E5u2uYCorK2VFYytY9pWzdU8LyLXvI31v6hUcW8XFGRmoiFRGnpLyS0opDX1AkJcRxzpBOXPGl7hzfu8N/XDSJiEh0WdBYvuUYPXq013VgH3dn+vvr+MULS+iSkUqr5ASW5u2ha0Yq3zm1D5eN6kZKYuw00quojLCjsIwtu0vYuqdqKmVHYRlJ8UZKYjzJCXEkH/BZVZ4QZ7y9Ip9/zt/EnpIKurVL5bJR3bl0dDe6ZqRG++eJSB2Z2Tx3Hx3tOKT+KPnXwbx1u7j+8U9ITYrnulP7cvHwLiTqeflBlZRX8sriLfxj7kbmrNqOGZzYN5MrvtSdswZn660GkWZCyT/2KPnXUUVlhPg4Qx0K1s2GnUX8Y95Gnp67gc27S8hIS+Qrw7ty7tBOtG+VRFpyAq2S4klNiicpPk7nV6QJUfKPPUr+0qgqI867q7YzY+4GXl28lbLKL7YdSIgz0pLiaZWcQGpSPK2SEkhLig+n/fOpSfsvGNKSEmiVHE9qYjy9MlvRL7tNFH6dSGxS8o89UXvPX1qm+Djj5P5ZnNw/i12FZczfsIvC0kqKyyopLKugqKySwtLgs6isgsKySopKg8/t+8ooLCuiuKySorLgOzVdPAAM757B18b24IJjO5OWpP/NRUSq052/NGvllZHPLwQKyyooLqvko7U7efyj9azato82yQmMH9mVr47pwaDObaMdrkizpDv/2KPkLzHJ3Zm7bhdPfLieFz7No6wiwogeGXx1TA8uPLYLqUlqbChSW0r+sUfJX2JeQVEZz3yyiSeqagNSEhg/QrUBIrWl5B97lPylxXB3Ps7dxRMfrefFsDbgtAFZ3HhWf47tlhHt8ESaLCX/2KPkLy1SQVEZj3+0nqlvr6GgqJwzB2Vz41n9GNIlPdqhiTQ5Sv6xR8lfWrS9JeVMey+XqW+vYU9JBecM6cQNZ/VjYCc9DhCpouQfe5T8RYDdxeU8NGctD81Zy97SCs4/tjM3nNFP/QWIoOQfi5T8RaopKCrjgXfW8vC7aykqr+SiYV34/hn96JPVOtqhiUSNkn/sUfIXqcHOwjKmvr2Gae/lUlpRyRVf6s6t5wwiPU3DFEvLo+QfezQqjUgN2rdK4tZzB/LOj0/j6nG9mDF3I2fcM5sXFm2mpV0wi0jsUfIXOYTM1sncfuFgZn73BDqlJ3P94/OZMn0umwuKox2aiMgRU/IXqYWhXdN57roT+Ol5g5izajtn3TOb6e/nEomoFkBEmh8lf5FaSoiPY8rJvXn1hlMY2bMdt89czKV/eY8VW/dGOzQRkTpR8hepox4d0ph+zRjuuXwYa7cXcv4f3uGe11ZQWlEZ7dBERGpFyV/kCJgZl4zsxus3ncL5x3TmD7NWct7v3+Hj3J3RDk1E5LCU/EWOQofWyfzfxBFMu2YMJeURLvvL+/zgyflsUoNAEWnClPxF6sEp/bN47aaTuf60vrz82RZOv/stfvfqcgpLK6IdmojIFyj5i9STtKQEfnj2AN744amcM7QTf3xjFafe/RYzPt5Apd4KEJEmRMlfpJ51zUjl9xNH8Ox14+jeLpVbnlnEhX+cw3urt0c7NBERQMlfpMGM7NGOZ/5rHH/86gh2F5fztb99yJTpc1m7vTDaoYlIC6e+/UUaQUl5JQ/OWct9b66itCLCVcfncP6xnUhPTSQ9NYn01ESSEnQtLk2T+vaPPUr+Io1o294S7nl1BU/N3cCBf3ppSfFkpCaSnpZEemoCGalJZKQl0iuzFZOO60nr5IToBC0tnpJ/7FHyF4mC9TuKWLujkN3F5ewuKqOgqJzdxeUUFJdTUFTOnuJyCoqD8m17S8lsncQNZ/Zn4pe6kxCvGgJpXEr+sUe3EiJR0KNDGj06pNVq2wUbCvjVi0v57+c+4+F313LruYM4c1BHzKyBoxSRWKVbCJEmbnj3DJ769nFM/fooHJgyfS4Tp37Aoo0F0Q5NRJopJX+RZsDM+PKQTrxyw8n84itDWbVtHxf96V2+/8R8NuwsinZ4ItLM6Jm/SDO0t6Scv85ewwNz1hCJwORxPbn+tH6kpyVGOzSJQXrmH3uikvzN7EbgW4ADnwLfADoDTwIdgHnA1929zMySgenAKGAHcIW754b7uQ34JlAJfN/dXzncsZX8JZbk7S7mnldX8PQnG2mbkshpA7IY3j2D4T3aMbhzW70+KPVCyT/2NHryN7OuwBxgsLsXm9kM4CXgPOBZd3/SzP4CLHT3+83sOuBYd/+OmU0Exrv7FWY2GHgCGAN0AV4H+rv7IcdVVfKXWLRk8x7+/NYqPl67k217SwFIio9jcJe2DO+ewYgeGQzvnkGP9mlqKCh1puQfe6LV2j8BSDWzciANyANOB74Wrp8G3AHcD1wczgM8DfzJgn+9LgaedPdSYK2ZrSK4EHi/kX6DSJMxuEtb/vy1kbg7ebtLWLChIJjWF/Dkx+t55L1cANq3SmJYt3T6ZLUmLSmelKR4UhPjg/nEYD41af9yemoi3drV7q0EEWk+Gj35u/smM7sbWA8UA68SVPMXuHvVEGgbga7hfFdgQ/jdCjPbTfBooCvwQbVdV//OfzCza4FrAXr06FGvv0ekKTEzumSk0iUjlfOO6QxARWWE5Vv3fn4xsGBDAR+s2UlJReUXOhqqyZic9vzXqX04dUCWag1EYkSjJ38za0dw194LKAD+AZzTkMd096nAVAiq/RvyWCJNTUJ8HEO6pDOkSzqTxvb8vNzdKa2IUFxWSVF5JcVllZSUV1JUVklxuJy7o5Bp7+XyjUc+ZmCnNvzXqX04/5jO6mhIpJmLRrX/mcBad88HMLNngROADDNLCO/+uwGbwu03Ad2BjWaWAKQTNPyrKq9S/TsichhmRkpiUL3f7hDbXXNCL55fuJm/zF7ND55cwG9fWc61J/fmslHdSU2Kb7R4RaT+ROPyfT1wnJmlhc/uzwCWAG8Cl4bbTAZmhvPPh8uE69/woJXi88BEM0s2s15AP+CjRvoNIi1GUkIcl47qxqs3nMzfrhpNxzbJ3D5zMSfc9QZ/nLWS3UXl0Q5RROooWq/6/Ry4AqgA5hO89teV4FW/9mHZle5eamYpwKPACGAnMNHd14T7+SlwTbifG9z934c7tlr7ixwdd+fj3F3c/9Yq3lyeT6ukeL46pgdXn5BTr40DKyojerzQRKi1f+xRJz8icsSWbN7DX99ezQuL8oi4c3zvDkwY2Y1zj+lEWlLdnyqWlFfy+tKtzFywmbeWb2Nkj3b89tJhtR4HQRqGkn/sUfIXkaO2cVcRz8zbxDOfbGT9ziLSkuI5d2hnLh3VjbG92hMXd/C3BCoqI7y3egfPLdjEq4u3sq+0go5tkjltQEde+jSPiohz23kDuXJsz0PuRxqOkn/sUfIXkXpT9UjgmXkbefHTPPaVVtA1I5UJI7tyychu5GS2+ny7hRt389z8TbywKI/t+0ppk5zAucd04ivDuzK2dwfi44zNBcXc+uynvL0in+N6t+e3lw6je3vVAjQ2Jf/Yo+QvIg2iuKySVxZv4ZlPNjJn1XbcYXTPdozokcFrS7aSu6OIpPg4Th/YkYuHd+G0gR1JSfzi2wPuzlMfb+D/vbiUiDu3nTuQSaoFaFRK/rFHyV9EGlze7mL+OX8Tz8zbyJrthRzXqwNfGdGFc4Z2Jj21doMRbSoo5tZnFvHOyu2M69OBuyYcq1qARqLkH3uU/EWk0bg7xeWVR9QYsOr7T368gV++uBR357bzBjFpbA/1PNjAlPxjj5K/iDQ7mwqK+fHTi5izajsn9O3Ary+pn1qAkvJKnl+4mcc+WEdpRYTxI7oyfmRXOrZJqYeomy8l/9ij5C8izZK78/hH6/nVi0spqYhwYt9MLhzWhS8PyaZtSu0eJVTZuKuIv3+wnqc+Xs+uonL6Z7emdXICn6wvID7OOH1gRy4f3Z1TB2SR2AL7HlDyjz1K/iLSrG3cVcRjH67nXws3s3FXMUnxcZwyIIsLh3XhzEEdD/qIwd15f/UOHnkvl9eXbgXgrMHZTB6Xw/G9O2BmrNq2j3/M28Az8zaxfV8pma2TmTCyK5eN7kbfjm0OGVfVCIurtu1j1bZ9rM7fR0FROWWVEcorI5RVhJ+V/vl8VXlqYjwn98/i7CGd+FJOu6h3dqTkH3uU/EUkJrg7CzYU8K+Febz46Wa27iklNTGe0wd15MJju3DqgCxSEuMpLK3g2fmbmP5eLiu37aNdWiITx/TgyuN60jUjtcZ9l1dGmL08nxlzN/DGsm1URJyRPTK4fHR3zh3amZ1FZazcupdV+WGi37aP1fmF7Cut+Hwf6amJZLZOIjE+jqSEOJLi40iMjyMxnE9KsM/LdhSWMWfVdsoqIrRLS+TMQdmcPaQTJ/bLrPGNiIam5B97lPxFJOZEIs7HuTv516LNvPTpFnYWltE6OYHjerfnwzU72VtawTFd05k8LocLju1cp4Sav7eU5+Zv4qm5G1i1bd8X1me3TaZfxzb07diaPh1b0zerNX07tiazdVKdGiYWllYwe0U+ryzewhtLt7G3tIK0pHhOHRDUCJw2sGOdH28cKSX/2KPkLyIxraoHwRcWbWbOyu18qVd7Jo/LYUT3jKN6S6CqpuGdldvpnJ7yebJviIRcVhHh/TU7eGXxFl5bspX8vaUkxhvH98lkeLd0emW1IqdDK3pltiIjLanej6/kH3uU/EVEmpFIxJm/oYBXF2/h9aVbWbu9kEi1f8bbpSWSk9mKXuHFQE7m/s/WyUf2iqWSf+xR8hcRacZKKyrZsLOY3O2FrN1eyNodhZ/P5+0u+Xy7NikJLPrZl4+otkPJP/Yc2WWgiIg0CckJ8fTtGLQrOFBxWSXrdhayNr+QvaUV6gxJPqfkLyISo1KT4hnYqS0DO7WNdijSxLS83ipERERaOCV/ERGRFkbJX0REpIVR8hcREWlhlPxFRERaGCV/ERGRFkbJX0REpIVR8hcREWlhlPxFRERaGCV/ERGRFkbJX0REpIU5bN/+ZtYP+F9gMJBSVe7uvRswLhEREWkgtbnzfxi4H6gATgOmA39vyKBERESk4dQm+ae6+yzA3H2du98BnN+wYYmIiEhDqc2QvqVmFgesNLPrgU3AFweOFhERkWahNnf+PwDSgO8Do4ArgasaMigRERFpOLVJ/jnuvs/dN7r7N9x9AtDjaA5qZhlm9rSZLTOzpWZ2vJm1N7PXzGxl+Nku3NbM7A9mtsrMFpnZyGr7mRxuv9LMJh9NTCIiIi1FbZL/bbUsq4vfAy+7+0BgGLAUuBWY5e79gFnhMsC5QL9wupag8SFm1h74GTAWGAP8rOqCQURERA7uoM/8zexc4Dygq5n9odqqtgQt/4+ImaUDJwNXA7h7GVBmZhcDp4abTQPeAn4MXAxMd3cHPghrDTqH277m7jvD/b4GnAM8caSxiYiItASHuvPfDMwFSoB51abngbOP4pi9gHzgYTObb2YPmFkrINvd88JttgDZ4XxXYEO1728Myw5W/gVmdq2ZzTWzufn5+UcRuoiISPN30Dt/d18ILDSzx929vJ6PORL4nrt/aGa/Z38Vf9Wx3cy8vg7o7lOBqQCjR4+ut/2KiIg0R7Vq8Bc2zltiZmuqpqM45kZgo7t/GC4/TXAxsDWszif83Bau3wR0r/b9bmHZwcpFRETkEBq9hz933wJsMLMBYdEZwBKCxwlVLfYnAzPD+eeBq8JW/8cBu8PHA68AXzazdmFDvy+HZSIiInIItenkJ9XdZ5mZufs64A4zmwfcfhTH/R7wmJklAWuAbxBciMwws28C64DLw21fImh4uAooCrfF3Xea2S+Aj8Pt7qxq/CciIg1r3rx5HRMSEh4AhqJB4pqaCPBZRUXFt0aNGrWtpg2i0sOfuy8ARtew6owatnXguwfZz0PAQ0cTi4iI1F1CQsIDnTp1GpSVlbUrLi5ObamakEgkYvn5+YO3bNnyAHBRTdscSQ9/X2d/9byIiLRMQ7OysvYo8Tc9cXFxnpWVtZugVqZGh73zd/eqavV9hFXuIiLS4sUp8Tdd4X+bg97gH6qTn38BB/0P6+41ViWIiIhI3UUiEa655prub7zxRnpKSkrkoYceyj3xxBOLDtxuzJgxA7Zt25aYkpISAZg1a9aKrl271qnzvUPd+d8dfl4CdGJ/C/+vAlvrchAREZFoqKioICGhNs3bGkZ+fn58VlZWZW22/cc//pG+Zs2alNzc3M/efPPNVtddd12PRYsWLatp2+nTp685+eSTv3BhUFsHrRJw99nuPhs4wd2vcPd/hdPXgJOO9IAiIiL14cwzz+wzZMiQQX379h1y9913Z1aVp6WljZgyZUq3AQMGDJ41a1bre++9NzMnJ2foMcccM2jixIk9r7rqqh4AEyZMyJk0aVKPYcOGDezWrdsxL7zwQpvLLrssp3fv3kMmTJiQU7W/SZMm9Rg6dOigvn37Drnxxhu7AOzYsSM+Jydn6MKFC5MBLrzwwl6/+93vMg8IkW9961s9jjvuuP73339/+6KiIjvU75k5c2bGpEmTdsTFxXHGGWcU7tmzJ2HdunWJ9XS6/kNtLodamVlvd18DYGa9gFYNEYyIiDQ/P3p6YfcVW/am1ec++3dqU/TbS4dtONQ2jz32WG52dnblvn37bMSIEYOvvPLKXZ06daosLi6OGzt2bOHf/va3jbm5uYnXXHNNr08++WRJRkZGZNy4cf2HDBlSXLWP3bt3J8yfP3/Z448/njFx4sS+b7zxxrJRo0YVH3vssYPee++91HHjxhXfc889m7KzsysrKioYN27cgA8//DB17Nixxffee+/6yZMn97ruuuu2FhQUJNx8883bD4xx5syZa9955520qVOnZv7qV7/qcvrpp+/+zne+s/34448vPnDbvLy8xJycnLKq5c6dO5etW7cusWfPnl/oZfdb3/pWTlxcHBdeeOGuu+66Ky8urm5vW9Zm6xuBt8zsLTObDbxJ8AaAiIhI1Nx1113ZAwYMGDxq1KhBW7ZsSVy8eHEKQHx8PFdfffUugHfeeafV2LFj92ZnZ1cmJyf7+PHjd1Xfx/nnn18QFxfHyJEjizp06FA+ZsyY4vj4ePr371+8evXqZIBp06a1Hzx48KDBgwcPXrlyZcrChQtTAMaPH79n0KBBxbfcckvPRx55JPdgcZ500klFjz766Prly5cv7tu3b+kpp5wy6I477sg+2PaH89RTT61ZsWLFkvfff3/Ze++91/q+++7rUNd91Ka1/8tm1g8YGBYtc/fSuh5IRERi0+Hu0BvCCy+80Gb27Nlt5s6du6xNmzaRMWPGDCguLo4DSEpKitT2OX9KSopDcMGQlJT0eSP3uLg4KioqbNmyZUl/+tOfsufNm7c0KyurcsKECTklJSVxAJWVlaxYsSIlJSUlsmPHjoQ+ffrUOA5OeXk5M2bMSH/44Ycz161bl/KjH/1o85QpU3YcuF3nzp3Lc3Nzk6qW8/Lykmq66+/Vq1c5QLt27SJXXHHFzo8++qgV8IX9HUqt6gncvdTdF4aTEr+IiERVQUFBfHp6emWbNm0i8+fPT1m4cGGNj6NPPPHEwg8//LBNfn5+fHl5OTNnzmxXl+Ps2rUrPjU1NdK+ffvKDRs2JLz11lvpVevuvPPO7P79+5c88sgja6655pqc0tLSLzzTv+OOO7J79ep1zDPPPNPuhz/84daVK1cu/uUvf7mlptb5F110UcFjjz3WIRKJMGvWrFZt2rSpPDD5l5eXk5eXlwBQWlpqL730UvrQoUO/8AjhcKLXBFJEROQITZgwYffUqVOzevfuPaR3794lw4YNK6xpu169epXfeOONeaNHjx6Unp5e0bdv35L09PRatb4HOP7444uHDh1a1KdPn6GdO3cuGzVq1D6AhQsXJj/66KOZ8+bNW9quXbvI008/vffWW2/tfO+9926u/v3hw4cXLVq0aHH79u0jhzvW5ZdfvvvFF19M79mz59DU1NTIAw88kFu1buDAgYOXLVu2pLi4OO7MM8/sV15ebpFIxE466aQ9N910U53Hqreg99yWY/To0T537txohyEi0myY2Tx3/48u2RcuXJg7bNiwLzRwa4p2794dl56eHikvL+fss8/ue/XVV2+/6qqrCqIdV0NbuHBh5rBhw3JqWnfYO38zG1lD8W5gnbvXqVMBERGRxvajHxx9/bwAABrISURBVP2oy9tvv922tLTUTjnllD1XXnllzCf+w6lNtf99wEhgEWAEfQUvBtLN7L/c/dUGjE9EROSoTJ06dWO0Y2hqatPgbzMwwt1Hu/soYATBMLxnAb9pyOBERESk/tUm+fd398VVC+6+BBhY1emPiIiINC+1qfZfbGb3A0+Gy1cAS8wsGajxnUYRERFpumpz5381sAq4IZzWhGXlwGkNFZiIiIg0jNr08FcM/C6cDrSv3iMSERFpgZrKkL4AmNkJwB1Az+rbu3vvuhxIRESksUV7SN+DqWmo3yYxpG81DwL3ACcCX6o2iYiIRE1zGNK3uk2bNiXcfvvt2f369Rvy8MMPtz9wfVMb0ne3u/+7IQ4uIiIx4Lnvdmfbknod0peOg4v4yp+b/ZC+lZWV/POf/2z7wAMPZK5cuTJ1woQJO19++eUVNQ0C1JhD+tYm+b9pZr8FngU+H9TH3T+p05FERETq0V133ZX94osvZgBUDenbqVOnwoMN6Qswfvz4XStWrEip2kdNQ/oCnw/pO27cuOJp06a1f+SRRzIrKiosPz8/ceHChSljx44tHj9+/J4ZM2a0u+WWW3rOmzdvcU0xnnXWWX0XL16c9uc//zn3kksu2VPXJF2Tp556ak2vXr3Kd+3aFXfBBRf0ue+++zpcf/31dRrVrzbJf2z4Wb1fZwdOr8uBREQkRh3mDr0hNJchfX/zm99svO+++7JuvvnmHs8999yeKVOmbD/llFNqfFbfpIb0dffTapiU+EVEJGqay5C+o0ePLnnooYc2LF++fPEpp5yy9yc/+UnX/v37D3722WfbHrhtkxjS18yudPe/m9lNNa1393vqejAREZH60FyG9K2SkpLiU6ZM2TVlypRdK1asSNq6desX8m+TGNLXzL7t7n81s5/VsNrd/c66Hqwp0JC+IiJ1oyF9m6cjGtLX3f8azr7u7u9WXxe++y8iItLkaUjfL6pNi4g/Egzpe7gyERGRJkdD+n7RoZ75Hw+MA7IOeO7fFohv6MBERESkYRzqzj8JaB1u06Za+R7g0oYMSkREmrxIJBKxuLi4mhuOSVRFIhEDIgdbf6hn/rOB2Wb2iLuvAzCzOKC1u++p90hFRKQ5+Sw/P39wVlbWbl0ANC2RSMTy8/PTgc8Otk1tnvn/r5l9B6gEPgbamtnv3f23RxOcmcUDc4FN7n6BmfUCngQ6APOAr7t7mZklA9OBUQSdGFzh7rnhPm4DvhnG9n13f+VoYhIRkdqpqKj41pYtWx7YsmXLUGo3Tow0ngjwWUVFxbcOtkFtkv9gd99jZpOAfwO3EiTno0r+wA+ApQRtCADuAu519yfN7C8ESf3+8HOXu/c1s4nhdleY2WBgIjAE6AK8bmb93b3W72+KiMiRGTVq1DbgomjHIUemNldriWaWCHwFeN7dywm69z1iZtYNOB94IFw2gu6Cnw43mRYeD+DicJlw/Rnh9hcDT7p7qbuvBVYBY44mLhERkZagNsn/r0Au0Ap428x6EjT6Oxr/B9zC/sYIHYACd68IlzcCXcP5rsAGgHD97nD7z8tr+M5/MLNrzWyumc3Nz69zR0giIiIxpTZ9+//B3bu6+3keWAecdqQHNLMLgG3uPu9I91FX7j7V3Ue7++isrKzGOqyIiEiTdNjkb2bZZvagmf07XB4MTD6KY54AXGRmuQQN/E4Hfg9kmFlVG4RuwKZwfhPQPTx2ApBO0PDv8/IaviMiIiIHUZtq/0eAVwga1QGsAG440gO6+23u3s3dcwga7L3h7pOAN9nff8BkYGY4/zz7LzYuDbf3sHyimSWHbwr0Az460rhERERaioMm/2p34ZnuPoPw+Xz43L0hWtT/GLjJzFYRPNN/MCx/EOgQlt9E8LYB7r4YmAEsAV4GvquW/iIiIod3qFf9PiLov7/QzDoQtvA3s+MIGt0dNXd/C3grnF9DDa313b0EuOwg3/8l8Mv6iEVERKSlOFTyt/DzJoIq9j5m9i6Qhbr3FRERabYOlfyrD+jzT+AlgguCUuBMYFEDxyYiIiIN4FDJP55gYB87oDyt4cIRERGRhnao5J/n7nc2WiQiIiLSKA71qt+Bd/wiIiISAw6V/M9otChERESk0Rw0+bv7zsYMRERERBqHxmAWERFpYZT8RUREWhglfxERkRZGyV9ERKSFUfIXERFpYZT8RUREWhglfxERkRZGyV9EJJaVl8C2pZD7brQjkSbkUH37i4hIc1BZDgXrYccq2LEadq4O59fA7g2AQ1om3LI62pFKE6HkLyLS3BRuh+X/hhUvw7YlsGsdeOX+9Snp0L4P9BgLHSYF8x16gzuYhm0RJX8RaQkK1sPif8Kat6DH8TDqamjd8ej3W7gdcudA266Q1T9Iug2lYD0sfQGWvQDr3wePQHp36DoKhlwCHfqESb4vpLVXkpdDUvIXkdi0dwssfg4+ewY2fhSUte8Nq9+A2b+BIeNh7LeD5FmXRFlZAatnwfxHg7vvSMX+da07BRcBWQMhsz9kDYDMAcGFRl2TsXvwrH7ZC7D0X7BlUVDecTCc9EMYdAF0OlZJXo6Ikr+IxI7CHbD0+SDh584BHLKHwhm3B3fH7XvB9pXw8QMw/zH4dAZ0GQFjvh1cDCSmHHzf21fBgr/Dgidg35bgGfrY78Dgi6FoB+Qvg/wVsH15sE3Z3v3fTUnffxEQnwjxSf85JVTNJwfrC/Nh+Uuwc03w/W5j4Kw7YeAFwR2+yFEyd492DI1q9OjRPnfu3GiHISL1pawQlswMEv7qN4Nn3x36wdAJMPSS4O67JqV7YeGT8NHfgoSd1gFGToYvfRPSu4Xb7IMlz8H8vwdV7RYP/b4MI66E/mcHibom7rA3D/KXB9P25cGFQfEuqCw7YCqHilKoLN3//bgE6HVykOwHng9tOtXvOasjM5vn7qOjGoTUKyV/EWm+1r4DM78LBesgo0eQ8IdcAp2OqX11uDusnR1cBCx/KSgbeH5wt774OSjbFzxHH/F1GDax4RKxO0Qqg4sAiz90LUQjU/KPPar2F5Hmp6wQXr8DPpoaPMe/aib0OuXInn+bQe9Tg6lgPXz8IHwyLbgjHzI+SPrdxzT8s3UziE8IJpEGpjt/EWlecucEd/u71gXP3M+4HZLS6vcYleVBa/qE5PrdbzOlO//Yo0tMEWl4FWWw8lVY+ATkLYJ+Z8Gxl0P3sbW/oy4rhNd/Dh/9Fdr1gm+8BD3HNUy8B3uWLxIjlPxFpGG4Q96CoOX7Z08HLeJbdQxa1y94DOY+GDynP+ayYOo46OD7yn03vNtfG7TMP/NnkNSq8X6LSIxR8heR+rV3CyyaEdzlb1sSvMI24DwY/jXoc0bwTLt0b9BhzaczYM698M7vIPsYOPYyGHoppHcN9lVWCLPuhA//Cu16wtUvQs6J0f19IjFAz/xF5OiVlwQt5Rc8HnSA4xHo9iUY9tXgdbvUdgf/7r5t8NmzwYXApnmABQm+/9kw96HgXfcvTYEz74Dk1o30g6Q6PfOPPUr+InLkinYGreM/vD+o1m/bDYZdEST9zH5139+O1fDp08GFwI5VwWOBi/8cvPMuUaPkH3tU7S8idbd7E3xwH8x9GMoLod/ZcNx/Ba/bxR3FSOEd+sCpP4ZTbgnu+Nt0rv+W/CKi5C8idZC/HN79Ayx6KqjaP+ZSOOEHkD2kfo9jpm5sRRrQUVyiHxkz625mb5rZEjNbbGY/CMvbm9lrZrYy/GwXlpuZ/cHMVpnZIjMbWW1fk8PtV5rZ5Mb+LSItxsa58OQk+POYoBvd0d+A78+HS6bWf+IXkQYXjTv/CuBmd//EzNoA88zsNeBqYJa7/9rMbgVuBX4MnAv0C6exwP3AWDNrD/wMGA14uJ/n3X1Xo/8ikVgQiUBFCZQXhVNxUPX+/p8h9x1IyYCTbwlGwmuVGe1oReQoNHryd/c8IC+c32tmS4GuwMXAqeFm04C3CJL/xcB0D1omfmBmGWbWOdz2NXffCRBeQJwDPNFoP0akuSjdF7xzv3EubJoLBRv2J/jyIigrgorimr/bpgt8+ZcwajIkt2ncuEWkQUT1mb+Z5QAjgA+B7PDCAGALkB3OdwU2VPvaxrDsYOU1Heda4FqAHj161E/wIk1VpDJ4Nr9pbpjs5wXv23skWN8uJxj1LqkVJKZBYmrQqK5qPrHafEpG0NI+ISmqP0lE6lfUkr+ZtQaeAW5w9z1WrYtPd3czq7d3EN19KjAVglf96mu/Ik1G4Y5gkJt178Lm+cFIdBAk766jglHquo4KJlXZi7R4UUn+ZpZIkPgfc/dnw+KtZtbZ3fPCav1tYfkmoHu1r3cLyzax/zFBVflbDRm3SJNTXgIf/gXeuQfK9kLnYcE79t1GQ9fRQYv5hh6NTkSanUZP/hbc4j8ILHX3e6qteh6YDPw6/JxZrfx6M3uSoMHf7vAC4RXgV1VvBQBfBm5rjN8gEnWRCHz6D3jjF7B7A/Q/B878OXQcGO3IRKQZiMad/wnA14FPzWxBWPYTgqQ/w8y+CawDLg/XvQScB6wCioBvALj7TjP7BfBxuN2dVY3/RGLamtnw2v9A3sLgTv8r96kHPBGpE3XvK9JcbFsKr90eDI2b3j0Yx37opUfXo55ILah739ijHv5Emrq9W+DNX8H8RyGpDZx1ZzCsbWJKtCMTkWZKyV8kGipKYd9WKN4FxQXhZziVVF8ugE2fQGVZkPBPuQXS2kc7ehFp5pT8RRpTRVnwSt7bv4GS3TVvE58UDIFbNQ0dDyfdDO17N26sIhKzlPxFGoM7LHsBXv0f2LUW+p4Jgy/+zySfkhF8Jqbq9TwRaVBK/iINbfMCeOWnsG4OZA2ESc9AvzOjHZWItGBK/iINZU9e8B7+gseD5/Tn/w5GXg3x+rMTkejSv0Ii9a2sCN77I7z7fxCpgHHfC57Zp2ZEOzIREUDJX6T+VPW6N+vnsGcTDLoIzvq5GuqJSJOj5C9SH7avhH/9IBhYp/NwmPAA9BwX7ahERGqk5C9yNCrK4L3fw+zfBp3uXPgHGPF19bonIk2akr/Ikdo4F57/HmxbAkPGwzl3QZvsaEclInJYSv4idVW6F2b9Iuisp20X+OqTMODcaEclIlJrSv4idbHiFXjhpqBB35gpcPr/QErbaEclIlInSv4itbFvG/z7x7D42aCjnm++Ct3HRDsqEZEjouQvciiV5TD/7/D6HVBeBKf+BE68ERKSoh2ZiMgRU/IXqUllBXw6A2bfBbtyocc4uPD/IGtAtCMTETlqSv4i1UUq4bNn4K1fw87V0HkYfG0G9PuyBtsRkZih5C8CQe98S/4ZJP3tKyD7GJj4OAw4T0lfRGKOkr+0bJEILPsXvPm/kL8UsgbB5dNh4IXqqEdEYpaSv7RMkQgsfym409/6KWT2h0sfgsHjlfRFJOYp+UvLsncLzH8U5k2H3euhfR+45G8wdALExUc7OhGRRqHkL7EvEoE1b8Dch2H5v8ErodcpwYh7gy6CeP0ZiEjLon/1JHZV3eV/Mh0K1kNaJoy7HkZOhg59oh2diEjUKPlL7HCH8mJY/x7MeyS4y49UBHf5Z/4cBl6gznlERFDyl2iKRKBgHZTtg7Ki8LMwnPYFPepVXy4Ll8sLg/nyov3lVdviwb7TMuH47+ouX0SkBkr+0vh2rYMFj8OCx2D3hsNvn9gKktIgqVU4Hy63yto/X728fW/ofw4kJDf8bxERaYaU/KVxlJfAsheCZ/BrZgdlfU6Dk26GtA5h4m69P8kntQ4+E1L16p2ISD1T8q+LgvXw3HWQ3BZOugm6jY52RE1f3sJgYJxFM6CkANJ7wKm3wfCvQkaPaEcnItIiKfnX1qpZ8Mw3g77f4+LhgReDhmQn/xByTorNLmBL9wYt5vdsDj6LdkB8IiSkhFMyJKYGn5+XpQTnZ/UbQSv7LYsgPhkGXQgjrgzOme7kRUSiSsm/Nop2woyrgjvVK/4OrbNh3sPw3h9h2oXQ7Utw0g+h/9lN+yIgUgklu6F4V3AXXlwQzBduh715+6c9eUGyL9t7dMfrdCycd3fQgU5a+/r5DSIictTM3aMdQ6MaPXq0z507t+5fXPc+dD42eA5dpbwEFvwd5vw+6C0ue2jwOGDwV+qntzh32LcVtnwWdEG75bMgKZuBxR1iCi9ASveECb4gSPalew5+rLhEaNMZ2nSCtp3D+XCqWk7rEFxAVBRDRSlUlATnoKJk/3LV1OmYYEQ8EWn2zGyeu+s5Zwxp9snfzM4Bfg/EAw+4+68Ptf0RJ/9DqSyHT5+GOfcEI8K17wMn3gjHXlH798oryyF/OWz9DLZ8Gn5+BkXb92/Tttv+5+QeOcjkgAefyW0gNQNSMg79mZYZJHZVx4tIDZT8Y0+zTv5mFg+sAM4CNgIfA1919yUH+06DJP8qVSPEvX138Kw7qXXwTLymO/Pqy+5BY8JIebCf+GToODAYVrbT0KBGIXuIqs5FJCqU/GNPc3/mPwZY5e5rAMzsSeBi4KDJv0HFxcHgi4P+4le9DiteCXqYq35XXtPdOg6DLtif7Dv0U3/zIiLSYJp7hukKVO8lZiMw9sCNzOxa4FqAHj0a4fUyM+h3VjCJiIg0MS3iIa+7T3X30e4+OisrK9rhiIiIRFVzT/6bgO7VlruFZSIiInIQzT35fwz0M7NeZpYETASej3JMIiIiTVqzfubv7hVmdj3wCsGrfg+5++IohyUiItKkNevkD+DuLwEvRTsOERGR5qK5V/uLiIhIHSn5i4iItDBK/iIiIi1Ms+7e90iYWT6w7gi/nglsP+xW0dUcYgTFWd+aQ5zNIUZQnDXp6e7qJCWGtLjkfzTMbG5T79+6OcQIirO+NYc4m0OMoDilZVC1v4iISAuj5C8iItLCKPnXzdRoB1ALzSFGUJz1rTnE2RxiBMUpLYCe+YuIiLQwuvMXERFpYZT8RUREWhgl/1ows3PMbLmZrTKzW6MdTxUz625mb5rZEjNbbGY/CMvbm9lrZrYy/GzXBGKNN7P5ZvZCuNzLzD4Mz+lT4aiM0Y4xw8yeNrNlZrbUzI5voufyxvC/92dm9oSZpTSF82lmD5nZNjP7rFpZjefPAn8I411kZiOjHOdvw//ui8zsn2aWUW3dbWGcy83s7GjFWG3dzWbmZpYZLkftXErzpeR/GGYWD/wZOBcYDHzVzAZHN6rPVQA3u/tg4Djgu2FstwKz3L0fMCtcjrYfAEurLd8F3OvufYFdwDejEtV/+j3wsrsPBIYRxNukzqWZdQW+D4x296EEo1lOpGmcz0eAcw4oO9j5OxfoF07XAvc3UoxQc5yvAUPd/VhgBXAbQPj3NBEYEn7nvvDfhGjEiJl1B74MrK9WHM1zKc2Ukv/hjQFWufsady8DngQujnJMALh7nrt/Es7vJUhWXQnimxZuNg34SnQiDJhZN+B84IFw2YDTgafDTZpCjOnAycCDAO5e5u4FNLFzGUoAUs0sAUgD8mgC59Pd3wZ2HlB8sPN3MTDdAx8AGWbWOVpxuvur7l4RLn4AdKsW55PuXurua4FVBP8mNHqMoXuBW4DqLbWjdi6l+VLyP7yuwIZqyxvDsibFzHKAEcCHQLa754WrtgDZUQqryv8R/IMVCZc7AAXV/rFtCue0F5APPBw+nnjAzFrRxM6lu28C7ia488sDdgPzaHrns8rBzl9T/ru6Bvh3ON9k4jSzi4FN7r7wgFVNJkZpPpT8Y4CZtQaeAW5w9z3V13nwLmfU3uc0swuAbe4+L1ox1FICMBK4391HAIUcUMUf7XMJED4zv5jgYqUL0IoaqoeboqZw/g7HzH5K8DjtsWjHUp2ZpQE/AW6PdiwSG5T8D28T0L3acrewrEkws0SCxP+Yuz8bFm+tqvYLP7dFKz7gBOAiM8sleGRyOsGz9Yyw2hqaxjndCGx09w/D5acJLgaa0rkEOBNY6+757l4OPEtwjpva+axysPPX5P6uzOxq4AJgku/vAKWpxNmH4IJvYfi31A34xMw60XRilGZEyf/wPgb6ha2pkwga/zwf5ZiAz5+dPwgsdfd7qq16Hpgczk8GZjZ2bFXc/TZ37+buOQTn7g13nwS8CVwabhbVGAHcfQuwwcwGhEVnAEtoQucytB44zszSwv/+VXE2qfNZzcHO3/PAVWFL9eOA3dUeDzQ6MzuH4NHURe5eVG3V88BEM0s2s14Ejeo+auz43P1Td+/o7jnh39JGYGT4/22TOpfSTLi7psNMwHkELYBXAz+NdjzV4jqRoBp1EbAgnM4jeKY+C1gJvA60j3asYbynAi+E870J/hFdBfwDSG4C8Q0H5obn8zmgXVM8l8DPgWXAZ8CjQHJTOJ/AEwTtEMoJktM3D3b+ACN4i2Y18CnB2wvRjHMVwXPzqr+jv1Tb/qdhnMuBc6MV4wHrc4HMaJ9LTc13Uve+IiIiLYyq/UVERFoYJX8REZEWRslfRESkhVHyFxERaWGU/EVERFoYJX+RJs7MTrVwNEQRkfqg5C8iItLCKPmL1BMzu9LMPjKzBWb2VzOLN7N9ZnavmS02s1lmlhVuO9zMPqg2fnzVOPd9zex1M1toZp+YWZ9w963N7OlwzPnHwt79MLNfm9mScD93R+mni0gzo+QvUg/MbBBwBXCCuw8HKoFJBAPvzHX3IcBs4GfhV6YDP/Zg/PhPq5U/BvzZ3YcB4wh6eYNgxMYbgMEEvfmdYGYdgPHAkHA//69hf6WIxAolf5H6cQYwCvjYzBaEy70JhjF+Ktzm78CJZpYOZLj77LB8GnCymbUBurr7PwHcvcT39zP/kbtvdPcIQfezOQTD+ZYAD5rZJUD1PulFRA5KyV+kfhgwzd2Hh9MAd7+jhu2OtD/t0mrzlUCCu1cAYwhGILwAePkI9y0iLYySv0j9mAVcamYdAcysvZn1JPgbqxpt72vAHHffDewys5PC8q8Ds919L7DRzL4S7iM5HMe9RmbWGkh395eAG4FhDfHDRCT2JBx+ExE5HHdfYmb/DbxqZnEEo7F9FygExoTrthG0C4BgeNu/hMl9DfCNsPzrwF/N7M5wH5cd4rBtgJlmlkJQ83BTPf8sEYlRGtVPpAGZ2T53bx3tOEREqlO1v4iISAujO38REZEWRnf+IiIiLYySv4iISAuj5C8iItLCKPmLiIi0MEr+IiIiLcz/B3oU3WHTUD2AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLfaVcgE7pK",
        "outputId": "d9e031dd-28c1-4f53-8a35-cbf65dd06e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29822\n",
            "total train set images 30000\n",
            "focus_true_pred_true 23986 =============> FTPT : 79 %\n",
            "focus_false_pred_true 5836 =============> FFPT : 19 %\n",
            "focus_true_pred_false 84 =============> FTPF : 0 %\n",
            "focus_false_pred_false 94 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  21793\n",
            "argmax_less_than_half ==================>  8207\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cSh5sGfFAlg",
        "outputId": "fe5cb4a5-8af6-4e94-9c94-96a9257dfb5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "total correct 9213\n",
            "total train set images 10000\n",
            "focus_true_pred_true 7480 =============> FTPT : 74 %\n",
            "focus_false_pred_true 1733 =============> FFPT : 17 %\n",
            "focus_true_pred_false 312 =============> FTPF : 3 %\n",
            "focus_false_pred_false 475 =============> FFPF : 4 %\n",
            "argmax_more_than_half ==================>  6942\n",
            "argmax_less_than_half ==================>  3058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "outputId": "d760bd7a-a1ba-4504-dd8f-6b8df3c42d1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "                                            correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29820\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "outputId": "fc12f55c-5a08-42ce-9676-137b550be919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92 %\n",
            "total correct 9230\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HoIweZX_o3O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}