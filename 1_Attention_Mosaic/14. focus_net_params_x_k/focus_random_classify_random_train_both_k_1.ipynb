{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "focus_random_classify_random_train_both_k_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7452a2c8c340458795d2fcf7bd389c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5aac85c7496f4b9a85a2fa26600839d7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6930fb87ea4e43898cfd42f8888672d3",
              "IPY_MODEL_306c151e42f24cceb816e73a4fae5d5b"
            ]
          }
        },
        "5aac85c7496f4b9a85a2fa26600839d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6930fb87ea4e43898cfd42f8888672d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_550a6b6c141c498f9ead5f238348cf26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32ed7d04d77c4175b823fce33b616b76"
          }
        },
        "306c151e42f24cceb816e73a4fae5d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5ab50e424114031b664ec216f1846bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 17946580.29it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a991624bf394a7592ab32cd1507760e"
          }
        },
        "550a6b6c141c498f9ead5f238348cf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32ed7d04d77c4175b823fce33b616b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5ab50e424114031b664ec216f1846bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a991624bf394a7592ab32cd1507760e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjG64ra4aFu",
        "outputId": "e6249e0d-8307-4821-e9c8-3d4691732f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-7SARDZErK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acRFqJNrZErV",
        "outputId": "76eeeb11-954f-43fb-e987-5318d340bae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "7452a2c8c340458795d2fcf7bd389c7d",
            "5aac85c7496f4b9a85a2fa26600839d7",
            "6930fb87ea4e43898cfd42f8888672d3",
            "306c151e42f24cceb816e73a4fae5d5b",
            "550a6b6c141c498f9ead5f238348cf26",
            "32ed7d04d77c4175b823fce33b616b76",
            "f5ab50e424114031b664ec216f1846bd",
            "0a991624bf394a7592ab32cd1507760e"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7452a2c8c340458795d2fcf7bd389c7d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3BOnEFUZOLx"
      },
      "source": [
        "k = 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_JUhwCeZErk"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SadRzWBBZEsP"
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w"
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM"
      },
      "source": [
        "def init_weights(m,k=1):\n",
        "  if type(m) == nn.Linear:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)\n",
        "  if type(m) == nn.Conv2d:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhjiW2hKZTCY",
        "outputId": "9e303f1a-a6af-4fa4-fd85-400f3047dfbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "focus_net.apply(init_weights)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.1050,  0.1214,  0.0588],\n",
            "          [-0.1193,  0.0163,  0.0455],\n",
            "          [ 0.0215,  0.0241,  0.1083]],\n",
            "\n",
            "         [[ 0.0433,  0.0966, -0.0650],\n",
            "          [-0.1277,  0.1072, -0.0358],\n",
            "          [-0.0312,  0.0118, -0.0548]],\n",
            "\n",
            "         [[-0.0689, -0.0810,  0.0414],\n",
            "          [ 0.0412,  0.0663,  0.0657],\n",
            "          [-0.1363,  0.1377, -0.0697]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243,  0.1074,  0.0612],\n",
            "          [-0.0413,  0.1226,  0.0983],\n",
            "          [ 0.0922,  0.0167,  0.1221]],\n",
            "\n",
            "         [[ 0.0511,  0.1312, -0.0172],\n",
            "          [-0.0914, -0.0009, -0.0219],\n",
            "          [-0.0516, -0.0447,  0.1076]],\n",
            "\n",
            "         [[-0.1184,  0.0627,  0.1237],\n",
            "          [ 0.1283, -0.0161, -0.0057],\n",
            "          [ 0.0065, -0.0395,  0.0546]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024, -0.1245,  0.0225],\n",
            "          [ 0.1106,  0.0834, -0.0226],\n",
            "          [-0.1247, -0.0061, -0.1214]],\n",
            "\n",
            "         [[ 0.0866,  0.1358,  0.0561],\n",
            "          [-0.0469,  0.0484,  0.1072],\n",
            "          [-0.1322, -0.1119,  0.1240]],\n",
            "\n",
            "         [[ 0.0972,  0.0309, -0.0326],\n",
            "          [ 0.0429, -0.0177,  0.1361],\n",
            "          [-0.0201,  0.0622,  0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0303,  0.0592, -0.0878],\n",
            "          [ 0.0015, -0.0844,  0.0005],\n",
            "          [-0.0110, -0.1320,  0.0073]],\n",
            "\n",
            "         [[-0.0690, -0.0391, -0.1286],\n",
            "          [-0.1111, -0.0964,  0.0491],\n",
            "          [ 0.0080,  0.0899,  0.0564]],\n",
            "\n",
            "         [[ 0.1066, -0.0032,  0.1346],\n",
            "          [-0.0996, -0.0303,  0.0290],\n",
            "          [-0.1192, -0.0811,  0.0647]]],\n",
            "\n",
            "\n",
            "        [[[-0.0746,  0.0155,  0.0927],\n",
            "          [ 0.1275, -0.0648, -0.1212],\n",
            "          [-0.0438,  0.0703,  0.0093]],\n",
            "\n",
            "         [[ 0.0649, -0.1058, -0.1375],\n",
            "          [-0.0805,  0.0599, -0.0410],\n",
            "          [ 0.1259,  0.0705,  0.1220]],\n",
            "\n",
            "         [[ 0.0110,  0.0289,  0.0606],\n",
            "          [ 0.0577,  0.0234, -0.0851],\n",
            "          [ 0.0604, -0.0535,  0.0725]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0470, -0.0210,  0.1061],\n",
            "          [ 0.1273,  0.1034, -0.0953],\n",
            "          [ 0.1343, -0.0333,  0.0573]],\n",
            "\n",
            "         [[ 0.0107, -0.1018, -0.0632],\n",
            "          [-0.1064,  0.0825,  0.0589],\n",
            "          [ 0.1306, -0.1160, -0.0009]],\n",
            "\n",
            "         [[ 0.1033,  0.1369,  0.1329],\n",
            "          [-0.0583, -0.1006, -0.0515],\n",
            "          [ 0.0956, -0.0466,  0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0630, -0.1007, -0.0224],\n",
            "          [ 0.0597,  0.0746, -0.0809],\n",
            "          [ 0.1096, -0.0081,  0.0485]],\n",
            "\n",
            "         [[-0.0192,  0.0433, -0.0180],\n",
            "          [ 0.0555, -0.0442, -0.1342],\n",
            "          [ 0.0390, -0.0937, -0.1160]],\n",
            "\n",
            "         [[ 0.0635, -0.0448,  0.0776],\n",
            "          [-0.0472,  0.1219, -0.0217],\n",
            "          [ 0.0235,  0.1338, -0.1280]]],\n",
            "\n",
            "\n",
            "        [[[-0.1138,  0.0961,  0.0734],\n",
            "          [ 0.1227,  0.0692,  0.0687],\n",
            "          [ 0.0951, -0.0988, -0.1304]],\n",
            "\n",
            "         [[ 0.0414,  0.1211,  0.1038],\n",
            "          [ 0.0472,  0.0314,  0.1127],\n",
            "          [ 0.1249,  0.0592,  0.1128]],\n",
            "\n",
            "         [[-0.0023, -0.0187, -0.0323],\n",
            "          [ 0.0005, -0.0440,  0.1075],\n",
            "          [-0.0339, -0.0237,  0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1025, -0.0733,  0.0263],\n",
            "          [ 0.0634, -0.1255,  0.0807],\n",
            "          [-0.0945, -0.0226, -0.1057]],\n",
            "\n",
            "         [[-0.0354,  0.0731, -0.0700],\n",
            "          [-0.0865, -0.1230, -0.1273],\n",
            "          [-0.1034, -0.0091,  0.0499]],\n",
            "\n",
            "         [[-0.0941, -0.1289, -0.0261],\n",
            "          [-0.0112,  0.0301,  0.1376],\n",
            "          [ 0.0553, -0.1234, -0.0216]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1093, -0.0918,  0.0554],\n",
            "          [-0.0098,  0.0586, -0.0456],\n",
            "          [ 0.0957, -0.0791,  0.0954]],\n",
            "\n",
            "         [[ 0.0342, -0.0692, -0.0776],\n",
            "          [ 0.0679, -0.1333, -0.0824],\n",
            "          [ 0.0169,  0.0182,  0.0261]],\n",
            "\n",
            "         [[-0.0804, -0.0958,  0.0014],\n",
            "          [-0.0349,  0.1200, -0.1340],\n",
            "          [-0.0353, -0.0973,  0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0191,  0.0477, -0.0084],\n",
            "          [ 0.0818,  0.1183, -0.0276],\n",
            "          [-0.0286,  0.0132, -0.0614]],\n",
            "\n",
            "         [[ 0.0330,  0.0598,  0.1111],\n",
            "          [ 0.1165, -0.0417,  0.0480],\n",
            "          [-0.0908,  0.0554,  0.1349]],\n",
            "\n",
            "         [[-0.0483,  0.0873, -0.1318],\n",
            "          [ 0.0756,  0.0214,  0.1137],\n",
            "          [ 0.0039,  0.1094,  0.0119]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0383,  0.1257],\n",
            "          [-0.0961,  0.1246,  0.0706],\n",
            "          [ 0.0321,  0.0388, -0.0594]],\n",
            "\n",
            "         [[-0.1108,  0.0191,  0.1080],\n",
            "          [ 0.1116,  0.0277, -0.0775],\n",
            "          [-0.0249,  0.1057, -0.0952]],\n",
            "\n",
            "         [[ 0.1207, -0.1373, -0.0730],\n",
            "          [ 0.1134,  0.0365, -0.0702],\n",
            "          [-0.0340, -0.1309, -0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1354,  0.1205, -0.1124],\n",
            "          [-0.0645, -0.0902,  0.1234],\n",
            "          [-0.0884,  0.0080,  0.0424]],\n",
            "\n",
            "         [[-0.0670,  0.0203, -0.0854],\n",
            "          [ 0.0503, -0.0132,  0.1265],\n",
            "          [-0.0972,  0.0498,  0.1150]],\n",
            "\n",
            "         [[-0.1209,  0.1248,  0.0428],\n",
            "          [-0.0510,  0.0816,  0.0532],\n",
            "          [-0.0520, -0.0577,  0.1087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1126,  0.0255, -0.1296],\n",
            "          [ 0.0378,  0.0466, -0.0572],\n",
            "          [ 0.0232, -0.0410,  0.1117]],\n",
            "\n",
            "         [[ 0.0124, -0.1374,  0.1032],\n",
            "          [-0.0838, -0.1037,  0.0993],\n",
            "          [-0.0971,  0.0112,  0.1063]],\n",
            "\n",
            "         [[-0.1211,  0.1292, -0.0956],\n",
            "          [ 0.0564, -0.1087,  0.0525],\n",
            "          [ 0.1237,  0.0084,  0.0690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0790,  0.0170,  0.1157],\n",
            "          [-0.1304, -0.1316,  0.1206],\n",
            "          [ 0.1354, -0.1357,  0.0203]],\n",
            "\n",
            "         [[ 0.0671,  0.0099,  0.0534],\n",
            "          [ 0.0526, -0.0304,  0.0219],\n",
            "          [-0.0585,  0.0089, -0.0224]],\n",
            "\n",
            "         [[-0.0058, -0.0208,  0.0841],\n",
            "          [ 0.0215, -0.0465, -0.0621],\n",
            "          [-0.1283,  0.1176, -0.0754]]],\n",
            "\n",
            "\n",
            "        [[[-0.0220,  0.0226,  0.0721],\n",
            "          [-0.0388, -0.0747,  0.0138],\n",
            "          [-0.0008,  0.1340,  0.0115]],\n",
            "\n",
            "         [[-0.1081,  0.1344,  0.0052],\n",
            "          [ 0.1110, -0.1306, -0.1088],\n",
            "          [-0.0309,  0.0023,  0.0570]],\n",
            "\n",
            "         [[-0.0560, -0.1184,  0.0920],\n",
            "          [ 0.0252, -0.0433,  0.0878],\n",
            "          [ 0.0069, -0.1082,  0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0770,  0.0946, -0.0880],\n",
            "          [-0.0460,  0.1173,  0.0226],\n",
            "          [ 0.0407,  0.0980, -0.0654]],\n",
            "\n",
            "         [[-0.0717, -0.0724,  0.0412],\n",
            "          [-0.0562,  0.0682, -0.0425],\n",
            "          [ 0.0033, -0.1061,  0.0760]],\n",
            "\n",
            "         [[-0.1020, -0.0190, -0.0219],\n",
            "          [ 0.0550, -0.0851,  0.1220],\n",
            "          [ 0.0055,  0.0560,  0.1111]]],\n",
            "\n",
            "\n",
            "        [[[-0.0951, -0.0374, -0.1315],\n",
            "          [-0.1089,  0.0229,  0.1351],\n",
            "          [ 0.0422,  0.1377, -0.1347]],\n",
            "\n",
            "         [[-0.0214, -0.0826, -0.1109],\n",
            "          [-0.0246, -0.0491,  0.0648],\n",
            "          [-0.0400,  0.1292, -0.0168]],\n",
            "\n",
            "         [[ 0.0885, -0.0273, -0.0782],\n",
            "          [-0.0131, -0.0099,  0.0111],\n",
            "          [ 0.0437, -0.1332, -0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0438,  0.1056],\n",
            "          [ 0.0402, -0.1309,  0.1371],\n",
            "          [ 0.1017,  0.0284, -0.0202]],\n",
            "\n",
            "         [[ 0.1244, -0.1375,  0.0282],\n",
            "          [ 0.1086,  0.1217,  0.0943],\n",
            "          [-0.0004,  0.0387, -0.0833]],\n",
            "\n",
            "         [[-0.0171, -0.0782, -0.0358],\n",
            "          [ 0.0075, -0.1302,  0.0208],\n",
            "          [-0.0873, -0.0959,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102, -0.1067, -0.1025],\n",
            "          [ 0.1116,  0.0266, -0.1028],\n",
            "          [-0.0635, -0.0708, -0.0697]],\n",
            "\n",
            "         [[ 0.0030,  0.0739, -0.0855],\n",
            "          [-0.0650,  0.1201, -0.0131],\n",
            "          [-0.0618, -0.0680, -0.0356]],\n",
            "\n",
            "         [[-0.0797, -0.1149,  0.0272],\n",
            "          [ 0.0520,  0.0685,  0.0054],\n",
            "          [-0.0097, -0.0302,  0.1144]]],\n",
            "\n",
            "\n",
            "        [[[-0.1193,  0.0028,  0.0314],\n",
            "          [-0.1280,  0.1190, -0.1014],\n",
            "          [-0.1231,  0.0703,  0.0279]],\n",
            "\n",
            "         [[ 0.0904, -0.1331, -0.0808],\n",
            "          [ 0.0591, -0.0654,  0.1076],\n",
            "          [-0.0453, -0.0707,  0.1021]],\n",
            "\n",
            "         [[-0.0887, -0.0770, -0.0189],\n",
            "          [ 0.0863, -0.0374, -0.0307],\n",
            "          [-0.1057,  0.0172, -0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0808, -0.1211, -0.0311],\n",
            "          [-0.1210,  0.1079,  0.1335],\n",
            "          [ 0.0941, -0.0931,  0.1172]],\n",
            "\n",
            "         [[ 0.0292,  0.0663,  0.1289],\n",
            "          [ 0.0864, -0.0247, -0.1160],\n",
            "          [-0.0783,  0.0210,  0.0308]],\n",
            "\n",
            "         [[-0.1219,  0.0811, -0.1078],\n",
            "          [ 0.1174,  0.0290, -0.0027],\n",
            "          [-0.0488, -0.0225,  0.0816]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1049,  0.0749, -0.1125],\n",
            "          [ 0.1378, -0.0721,  0.1281],\n",
            "          [-0.0777,  0.1362,  0.1164]],\n",
            "\n",
            "         [[ 0.0799,  0.0223,  0.1133],\n",
            "          [-0.0881,  0.0412,  0.0543],\n",
            "          [-0.0111, -0.0803, -0.0113]],\n",
            "\n",
            "         [[-0.0609,  0.0141, -0.0534],\n",
            "          [-0.1238,  0.0143,  0.0859],\n",
            "          [-0.0301, -0.0316,  0.0964]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0993,  0.1189, -0.0055],\n",
            "          [ 0.0014, -0.0976,  0.0031],\n",
            "          [ 0.0043,  0.1026, -0.1371]],\n",
            "\n",
            "         [[-0.0154, -0.1327, -0.1321],\n",
            "          [ 0.0735,  0.0689,  0.1124],\n",
            "          [ 0.0417,  0.0066, -0.0752]],\n",
            "\n",
            "         [[-0.1169, -0.0826, -0.0636],\n",
            "          [-0.0801,  0.0542,  0.1322],\n",
            "          [ 0.1274, -0.0805, -0.1321]]],\n",
            "\n",
            "\n",
            "        [[[-0.0321, -0.1013, -0.1340],\n",
            "          [ 0.0549,  0.1229,  0.0187],\n",
            "          [ 0.0635,  0.0855, -0.0793]],\n",
            "\n",
            "         [[ 0.0163,  0.0576, -0.0725],\n",
            "          [ 0.1349,  0.1338,  0.0424],\n",
            "          [-0.0565, -0.0271, -0.0065]],\n",
            "\n",
            "         [[ 0.1057, -0.0662,  0.0843],\n",
            "          [ 0.1218, -0.0181, -0.0132],\n",
            "          [-0.0224,  0.0711,  0.1373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458, -0.0240, -0.0642],\n",
            "          [-0.1284,  0.1301, -0.0221],\n",
            "          [ 0.0513,  0.0357,  0.0685]],\n",
            "\n",
            "         [[ 0.0447,  0.0482,  0.0202],\n",
            "          [ 0.1029, -0.0415,  0.0292],\n",
            "          [ 0.0927, -0.0914,  0.1029]],\n",
            "\n",
            "         [[ 0.0587, -0.0453, -0.0390],\n",
            "          [ 0.0402, -0.1310,  0.1291],\n",
            "          [-0.1203, -0.0834,  0.0932]]],\n",
            "\n",
            "\n",
            "        [[[-0.1195, -0.0345, -0.0670],\n",
            "          [ 0.0642, -0.0037, -0.0502],\n",
            "          [-0.0359,  0.0489,  0.0630]],\n",
            "\n",
            "         [[-0.0950,  0.1065,  0.0999],\n",
            "          [ 0.0028, -0.0237,  0.0881],\n",
            "          [ 0.1140, -0.1286,  0.0987]],\n",
            "\n",
            "         [[-0.0686, -0.0377,  0.0912],\n",
            "          [ 0.1366, -0.0975, -0.0507],\n",
            "          [-0.0163,  0.0094,  0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1173,  0.1334, -0.0506],\n",
            "          [-0.1283, -0.1268,  0.0220],\n",
            "          [ 0.0777, -0.0241, -0.0772]],\n",
            "\n",
            "         [[-0.0849, -0.0376,  0.0414],\n",
            "          [ 0.1200,  0.0639, -0.0089],\n",
            "          [-0.0256,  0.1346,  0.0802]],\n",
            "\n",
            "         [[-0.1187,  0.1279,  0.0268],\n",
            "          [ 0.0801, -0.0363, -0.1048],\n",
            "          [-0.0573, -0.0708,  0.0379]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0796, -0.0600,  0.0439],\n",
            "          [ 0.0550, -0.1245, -0.0892],\n",
            "          [-0.0474, -0.1210,  0.1336]],\n",
            "\n",
            "         [[ 0.0692,  0.0903, -0.0840],\n",
            "          [ 0.1243,  0.1076,  0.1367],\n",
            "          [-0.0511, -0.0784, -0.0105]],\n",
            "\n",
            "         [[ 0.0425, -0.0139,  0.1241],\n",
            "          [-0.0850,  0.0267,  0.0743],\n",
            "          [-0.1332, -0.0337, -0.0154]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0971, -0.0718, -0.0420],\n",
            "          [-0.1062,  0.1183, -0.1028],\n",
            "          [-0.0097,  0.0813, -0.0535]],\n",
            "\n",
            "         [[ 0.1279,  0.1208,  0.0060],\n",
            "          [-0.1352, -0.0636,  0.0192],\n",
            "          [-0.1363, -0.0039,  0.0833]],\n",
            "\n",
            "         [[-0.0234,  0.0114, -0.0031],\n",
            "          [ 0.1271,  0.0990, -0.0219],\n",
            "          [ 0.0717, -0.1184, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[-0.0752,  0.0160,  0.1106],\n",
            "          [-0.1226,  0.0359, -0.0675],\n",
            "          [-0.0148,  0.1298,  0.0941]],\n",
            "\n",
            "         [[ 0.0124, -0.0077, -0.1213],\n",
            "          [ 0.0115, -0.0320,  0.1001],\n",
            "          [ 0.0701,  0.0954, -0.0785]],\n",
            "\n",
            "         [[-0.1014,  0.0947,  0.0171],\n",
            "          [ 0.1316, -0.0220, -0.0368],\n",
            "          [ 0.0536,  0.0620, -0.0759]]],\n",
            "\n",
            "\n",
            "        [[[-0.0462,  0.0865, -0.0109],\n",
            "          [-0.0799, -0.0852,  0.0181],\n",
            "          [-0.0158,  0.0746,  0.1030]],\n",
            "\n",
            "         [[-0.0636,  0.0897, -0.0426],\n",
            "          [ 0.0369, -0.0393, -0.0056],\n",
            "          [-0.0294,  0.1296, -0.1235]],\n",
            "\n",
            "         [[ 0.0002,  0.0252,  0.1291],\n",
            "          [-0.0383,  0.0881,  0.0236],\n",
            "          [-0.0026, -0.0574, -0.0595]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.1050,  0.1214,  0.0588],\n",
            "          [-0.1193,  0.0163,  0.0455],\n",
            "          [ 0.0215,  0.0241,  0.1083]],\n",
            "\n",
            "         [[ 0.0433,  0.0966, -0.0650],\n",
            "          [-0.1277,  0.1072, -0.0358],\n",
            "          [-0.0312,  0.0118, -0.0548]],\n",
            "\n",
            "         [[-0.0689, -0.0810,  0.0414],\n",
            "          [ 0.0412,  0.0663,  0.0657],\n",
            "          [-0.1363,  0.1377, -0.0697]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243,  0.1074,  0.0612],\n",
            "          [-0.0413,  0.1226,  0.0983],\n",
            "          [ 0.0922,  0.0167,  0.1221]],\n",
            "\n",
            "         [[ 0.0511,  0.1312, -0.0172],\n",
            "          [-0.0914, -0.0009, -0.0219],\n",
            "          [-0.0516, -0.0447,  0.1076]],\n",
            "\n",
            "         [[-0.1184,  0.0627,  0.1237],\n",
            "          [ 0.1283, -0.0161, -0.0057],\n",
            "          [ 0.0065, -0.0395,  0.0546]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024, -0.1245,  0.0225],\n",
            "          [ 0.1106,  0.0834, -0.0226],\n",
            "          [-0.1247, -0.0061, -0.1214]],\n",
            "\n",
            "         [[ 0.0866,  0.1358,  0.0561],\n",
            "          [-0.0469,  0.0484,  0.1072],\n",
            "          [-0.1322, -0.1119,  0.1240]],\n",
            "\n",
            "         [[ 0.0972,  0.0309, -0.0326],\n",
            "          [ 0.0429, -0.0177,  0.1361],\n",
            "          [-0.0201,  0.0622,  0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0303,  0.0592, -0.0878],\n",
            "          [ 0.0015, -0.0844,  0.0005],\n",
            "          [-0.0110, -0.1320,  0.0073]],\n",
            "\n",
            "         [[-0.0690, -0.0391, -0.1286],\n",
            "          [-0.1111, -0.0964,  0.0491],\n",
            "          [ 0.0080,  0.0899,  0.0564]],\n",
            "\n",
            "         [[ 0.1066, -0.0032,  0.1346],\n",
            "          [-0.0996, -0.0303,  0.0290],\n",
            "          [-0.1192, -0.0811,  0.0647]]],\n",
            "\n",
            "\n",
            "        [[[-0.0746,  0.0155,  0.0927],\n",
            "          [ 0.1275, -0.0648, -0.1212],\n",
            "          [-0.0438,  0.0703,  0.0093]],\n",
            "\n",
            "         [[ 0.0649, -0.1058, -0.1375],\n",
            "          [-0.0805,  0.0599, -0.0410],\n",
            "          [ 0.1259,  0.0705,  0.1220]],\n",
            "\n",
            "         [[ 0.0110,  0.0289,  0.0606],\n",
            "          [ 0.0577,  0.0234, -0.0851],\n",
            "          [ 0.0604, -0.0535,  0.0725]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0470, -0.0210,  0.1061],\n",
            "          [ 0.1273,  0.1034, -0.0953],\n",
            "          [ 0.1343, -0.0333,  0.0573]],\n",
            "\n",
            "         [[ 0.0107, -0.1018, -0.0632],\n",
            "          [-0.1064,  0.0825,  0.0589],\n",
            "          [ 0.1306, -0.1160, -0.0009]],\n",
            "\n",
            "         [[ 0.1033,  0.1369,  0.1329],\n",
            "          [-0.0583, -0.1006, -0.0515],\n",
            "          [ 0.0956, -0.0466,  0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0630, -0.1007, -0.0224],\n",
            "          [ 0.0597,  0.0746, -0.0809],\n",
            "          [ 0.1096, -0.0081,  0.0485]],\n",
            "\n",
            "         [[-0.0192,  0.0433, -0.0180],\n",
            "          [ 0.0555, -0.0442, -0.1342],\n",
            "          [ 0.0390, -0.0937, -0.1160]],\n",
            "\n",
            "         [[ 0.0635, -0.0448,  0.0776],\n",
            "          [-0.0472,  0.1219, -0.0217],\n",
            "          [ 0.0235,  0.1338, -0.1280]]],\n",
            "\n",
            "\n",
            "        [[[-0.1138,  0.0961,  0.0734],\n",
            "          [ 0.1227,  0.0692,  0.0687],\n",
            "          [ 0.0951, -0.0988, -0.1304]],\n",
            "\n",
            "         [[ 0.0414,  0.1211,  0.1038],\n",
            "          [ 0.0472,  0.0314,  0.1127],\n",
            "          [ 0.1249,  0.0592,  0.1128]],\n",
            "\n",
            "         [[-0.0023, -0.0187, -0.0323],\n",
            "          [ 0.0005, -0.0440,  0.1075],\n",
            "          [-0.0339, -0.0237,  0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1025, -0.0733,  0.0263],\n",
            "          [ 0.0634, -0.1255,  0.0807],\n",
            "          [-0.0945, -0.0226, -0.1057]],\n",
            "\n",
            "         [[-0.0354,  0.0731, -0.0700],\n",
            "          [-0.0865, -0.1230, -0.1273],\n",
            "          [-0.1034, -0.0091,  0.0499]],\n",
            "\n",
            "         [[-0.0941, -0.1289, -0.0261],\n",
            "          [-0.0112,  0.0301,  0.1376],\n",
            "          [ 0.0553, -0.1234, -0.0216]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1093, -0.0918,  0.0554],\n",
            "          [-0.0098,  0.0586, -0.0456],\n",
            "          [ 0.0957, -0.0791,  0.0954]],\n",
            "\n",
            "         [[ 0.0342, -0.0692, -0.0776],\n",
            "          [ 0.0679, -0.1333, -0.0824],\n",
            "          [ 0.0169,  0.0182,  0.0261]],\n",
            "\n",
            "         [[-0.0804, -0.0958,  0.0014],\n",
            "          [-0.0349,  0.1200, -0.1340],\n",
            "          [-0.0353, -0.0973,  0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0191,  0.0477, -0.0084],\n",
            "          [ 0.0818,  0.1183, -0.0276],\n",
            "          [-0.0286,  0.0132, -0.0614]],\n",
            "\n",
            "         [[ 0.0330,  0.0598,  0.1111],\n",
            "          [ 0.1165, -0.0417,  0.0480],\n",
            "          [-0.0908,  0.0554,  0.1349]],\n",
            "\n",
            "         [[-0.0483,  0.0873, -0.1318],\n",
            "          [ 0.0756,  0.0214,  0.1137],\n",
            "          [ 0.0039,  0.1094,  0.0119]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0383,  0.1257],\n",
            "          [-0.0961,  0.1246,  0.0706],\n",
            "          [ 0.0321,  0.0388, -0.0594]],\n",
            "\n",
            "         [[-0.1108,  0.0191,  0.1080],\n",
            "          [ 0.1116,  0.0277, -0.0775],\n",
            "          [-0.0249,  0.1057, -0.0952]],\n",
            "\n",
            "         [[ 0.1207, -0.1373, -0.0730],\n",
            "          [ 0.1134,  0.0365, -0.0702],\n",
            "          [-0.0340, -0.1309, -0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1354,  0.1205, -0.1124],\n",
            "          [-0.0645, -0.0902,  0.1234],\n",
            "          [-0.0884,  0.0080,  0.0424]],\n",
            "\n",
            "         [[-0.0670,  0.0203, -0.0854],\n",
            "          [ 0.0503, -0.0132,  0.1265],\n",
            "          [-0.0972,  0.0498,  0.1150]],\n",
            "\n",
            "         [[-0.1209,  0.1248,  0.0428],\n",
            "          [-0.0510,  0.0816,  0.0532],\n",
            "          [-0.0520, -0.0577,  0.1087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1126,  0.0255, -0.1296],\n",
            "          [ 0.0378,  0.0466, -0.0572],\n",
            "          [ 0.0232, -0.0410,  0.1117]],\n",
            "\n",
            "         [[ 0.0124, -0.1374,  0.1032],\n",
            "          [-0.0838, -0.1037,  0.0993],\n",
            "          [-0.0971,  0.0112,  0.1063]],\n",
            "\n",
            "         [[-0.1211,  0.1292, -0.0956],\n",
            "          [ 0.0564, -0.1087,  0.0525],\n",
            "          [ 0.1237,  0.0084,  0.0690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0790,  0.0170,  0.1157],\n",
            "          [-0.1304, -0.1316,  0.1206],\n",
            "          [ 0.1354, -0.1357,  0.0203]],\n",
            "\n",
            "         [[ 0.0671,  0.0099,  0.0534],\n",
            "          [ 0.0526, -0.0304,  0.0219],\n",
            "          [-0.0585,  0.0089, -0.0224]],\n",
            "\n",
            "         [[-0.0058, -0.0208,  0.0841],\n",
            "          [ 0.0215, -0.0465, -0.0621],\n",
            "          [-0.1283,  0.1176, -0.0754]]],\n",
            "\n",
            "\n",
            "        [[[-0.0220,  0.0226,  0.0721],\n",
            "          [-0.0388, -0.0747,  0.0138],\n",
            "          [-0.0008,  0.1340,  0.0115]],\n",
            "\n",
            "         [[-0.1081,  0.1344,  0.0052],\n",
            "          [ 0.1110, -0.1306, -0.1088],\n",
            "          [-0.0309,  0.0023,  0.0570]],\n",
            "\n",
            "         [[-0.0560, -0.1184,  0.0920],\n",
            "          [ 0.0252, -0.0433,  0.0878],\n",
            "          [ 0.0069, -0.1082,  0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0770,  0.0946, -0.0880],\n",
            "          [-0.0460,  0.1173,  0.0226],\n",
            "          [ 0.0407,  0.0980, -0.0654]],\n",
            "\n",
            "         [[-0.0717, -0.0724,  0.0412],\n",
            "          [-0.0562,  0.0682, -0.0425],\n",
            "          [ 0.0033, -0.1061,  0.0760]],\n",
            "\n",
            "         [[-0.1020, -0.0190, -0.0219],\n",
            "          [ 0.0550, -0.0851,  0.1220],\n",
            "          [ 0.0055,  0.0560,  0.1111]]],\n",
            "\n",
            "\n",
            "        [[[-0.0951, -0.0374, -0.1315],\n",
            "          [-0.1089,  0.0229,  0.1351],\n",
            "          [ 0.0422,  0.1377, -0.1347]],\n",
            "\n",
            "         [[-0.0214, -0.0826, -0.1109],\n",
            "          [-0.0246, -0.0491,  0.0648],\n",
            "          [-0.0400,  0.1292, -0.0168]],\n",
            "\n",
            "         [[ 0.0885, -0.0273, -0.0782],\n",
            "          [-0.0131, -0.0099,  0.0111],\n",
            "          [ 0.0437, -0.1332, -0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0438,  0.1056],\n",
            "          [ 0.0402, -0.1309,  0.1371],\n",
            "          [ 0.1017,  0.0284, -0.0202]],\n",
            "\n",
            "         [[ 0.1244, -0.1375,  0.0282],\n",
            "          [ 0.1086,  0.1217,  0.0943],\n",
            "          [-0.0004,  0.0387, -0.0833]],\n",
            "\n",
            "         [[-0.0171, -0.0782, -0.0358],\n",
            "          [ 0.0075, -0.1302,  0.0208],\n",
            "          [-0.0873, -0.0959,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102, -0.1067, -0.1025],\n",
            "          [ 0.1116,  0.0266, -0.1028],\n",
            "          [-0.0635, -0.0708, -0.0697]],\n",
            "\n",
            "         [[ 0.0030,  0.0739, -0.0855],\n",
            "          [-0.0650,  0.1201, -0.0131],\n",
            "          [-0.0618, -0.0680, -0.0356]],\n",
            "\n",
            "         [[-0.0797, -0.1149,  0.0272],\n",
            "          [ 0.0520,  0.0685,  0.0054],\n",
            "          [-0.0097, -0.0302,  0.1144]]],\n",
            "\n",
            "\n",
            "        [[[-0.1193,  0.0028,  0.0314],\n",
            "          [-0.1280,  0.1190, -0.1014],\n",
            "          [-0.1231,  0.0703,  0.0279]],\n",
            "\n",
            "         [[ 0.0904, -0.1331, -0.0808],\n",
            "          [ 0.0591, -0.0654,  0.1076],\n",
            "          [-0.0453, -0.0707,  0.1021]],\n",
            "\n",
            "         [[-0.0887, -0.0770, -0.0189],\n",
            "          [ 0.0863, -0.0374, -0.0307],\n",
            "          [-0.1057,  0.0172, -0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0808, -0.1211, -0.0311],\n",
            "          [-0.1210,  0.1079,  0.1335],\n",
            "          [ 0.0941, -0.0931,  0.1172]],\n",
            "\n",
            "         [[ 0.0292,  0.0663,  0.1289],\n",
            "          [ 0.0864, -0.0247, -0.1160],\n",
            "          [-0.0783,  0.0210,  0.0308]],\n",
            "\n",
            "         [[-0.1219,  0.0811, -0.1078],\n",
            "          [ 0.1174,  0.0290, -0.0027],\n",
            "          [-0.0488, -0.0225,  0.0816]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1049,  0.0749, -0.1125],\n",
            "          [ 0.1378, -0.0721,  0.1281],\n",
            "          [-0.0777,  0.1362,  0.1164]],\n",
            "\n",
            "         [[ 0.0799,  0.0223,  0.1133],\n",
            "          [-0.0881,  0.0412,  0.0543],\n",
            "          [-0.0111, -0.0803, -0.0113]],\n",
            "\n",
            "         [[-0.0609,  0.0141, -0.0534],\n",
            "          [-0.1238,  0.0143,  0.0859],\n",
            "          [-0.0301, -0.0316,  0.0964]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0993,  0.1189, -0.0055],\n",
            "          [ 0.0014, -0.0976,  0.0031],\n",
            "          [ 0.0043,  0.1026, -0.1371]],\n",
            "\n",
            "         [[-0.0154, -0.1327, -0.1321],\n",
            "          [ 0.0735,  0.0689,  0.1124],\n",
            "          [ 0.0417,  0.0066, -0.0752]],\n",
            "\n",
            "         [[-0.1169, -0.0826, -0.0636],\n",
            "          [-0.0801,  0.0542,  0.1322],\n",
            "          [ 0.1274, -0.0805, -0.1321]]],\n",
            "\n",
            "\n",
            "        [[[-0.0321, -0.1013, -0.1340],\n",
            "          [ 0.0549,  0.1229,  0.0187],\n",
            "          [ 0.0635,  0.0855, -0.0793]],\n",
            "\n",
            "         [[ 0.0163,  0.0576, -0.0725],\n",
            "          [ 0.1349,  0.1338,  0.0424],\n",
            "          [-0.0565, -0.0271, -0.0065]],\n",
            "\n",
            "         [[ 0.1057, -0.0662,  0.0843],\n",
            "          [ 0.1218, -0.0181, -0.0132],\n",
            "          [-0.0224,  0.0711,  0.1373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458, -0.0240, -0.0642],\n",
            "          [-0.1284,  0.1301, -0.0221],\n",
            "          [ 0.0513,  0.0357,  0.0685]],\n",
            "\n",
            "         [[ 0.0447,  0.0482,  0.0202],\n",
            "          [ 0.1029, -0.0415,  0.0292],\n",
            "          [ 0.0927, -0.0914,  0.1029]],\n",
            "\n",
            "         [[ 0.0587, -0.0453, -0.0390],\n",
            "          [ 0.0402, -0.1310,  0.1291],\n",
            "          [-0.1203, -0.0834,  0.0932]]],\n",
            "\n",
            "\n",
            "        [[[-0.1195, -0.0345, -0.0670],\n",
            "          [ 0.0642, -0.0037, -0.0502],\n",
            "          [-0.0359,  0.0489,  0.0630]],\n",
            "\n",
            "         [[-0.0950,  0.1065,  0.0999],\n",
            "          [ 0.0028, -0.0237,  0.0881],\n",
            "          [ 0.1140, -0.1286,  0.0987]],\n",
            "\n",
            "         [[-0.0686, -0.0377,  0.0912],\n",
            "          [ 0.1366, -0.0975, -0.0507],\n",
            "          [-0.0163,  0.0094,  0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1173,  0.1334, -0.0506],\n",
            "          [-0.1283, -0.1268,  0.0220],\n",
            "          [ 0.0777, -0.0241, -0.0772]],\n",
            "\n",
            "         [[-0.0849, -0.0376,  0.0414],\n",
            "          [ 0.1200,  0.0639, -0.0089],\n",
            "          [-0.0256,  0.1346,  0.0802]],\n",
            "\n",
            "         [[-0.1187,  0.1279,  0.0268],\n",
            "          [ 0.0801, -0.0363, -0.1048],\n",
            "          [-0.0573, -0.0708,  0.0379]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0796, -0.0600,  0.0439],\n",
            "          [ 0.0550, -0.1245, -0.0892],\n",
            "          [-0.0474, -0.1210,  0.1336]],\n",
            "\n",
            "         [[ 0.0692,  0.0903, -0.0840],\n",
            "          [ 0.1243,  0.1076,  0.1367],\n",
            "          [-0.0511, -0.0784, -0.0105]],\n",
            "\n",
            "         [[ 0.0425, -0.0139,  0.1241],\n",
            "          [-0.0850,  0.0267,  0.0743],\n",
            "          [-0.1332, -0.0337, -0.0154]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0971, -0.0718, -0.0420],\n",
            "          [-0.1062,  0.1183, -0.1028],\n",
            "          [-0.0097,  0.0813, -0.0535]],\n",
            "\n",
            "         [[ 0.1279,  0.1208,  0.0060],\n",
            "          [-0.1352, -0.0636,  0.0192],\n",
            "          [-0.1363, -0.0039,  0.0833]],\n",
            "\n",
            "         [[-0.0234,  0.0114, -0.0031],\n",
            "          [ 0.1271,  0.0990, -0.0219],\n",
            "          [ 0.0717, -0.1184, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[-0.0752,  0.0160,  0.1106],\n",
            "          [-0.1226,  0.0359, -0.0675],\n",
            "          [-0.0148,  0.1298,  0.0941]],\n",
            "\n",
            "         [[ 0.0124, -0.0077, -0.1213],\n",
            "          [ 0.0115, -0.0320,  0.1001],\n",
            "          [ 0.0701,  0.0954, -0.0785]],\n",
            "\n",
            "         [[-0.1014,  0.0947,  0.0171],\n",
            "          [ 0.1316, -0.0220, -0.0368],\n",
            "          [ 0.0536,  0.0620, -0.0759]]],\n",
            "\n",
            "\n",
            "        [[[-0.0462,  0.0865, -0.0109],\n",
            "          [-0.0799, -0.0852,  0.0181],\n",
            "          [-0.0158,  0.0746,  0.1030]],\n",
            "\n",
            "         [[-0.0636,  0.0897, -0.0426],\n",
            "          [ 0.0369, -0.0393, -0.0056],\n",
            "          [-0.0294,  0.1296, -0.1235]],\n",
            "\n",
            "         [[ 0.0002,  0.0252,  0.1291],\n",
            "          [-0.0383,  0.0881,  0.0236],\n",
            "          [-0.0026, -0.0574, -0.0595]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 6.3420e-02,  7.3276e-02,  3.5488e-02],\n",
            "          [-7.2040e-02,  9.8323e-03,  2.7458e-02],\n",
            "          [ 1.2968e-02,  1.4557e-02,  6.5395e-02]],\n",
            "\n",
            "         [[ 2.6170e-02,  5.8342e-02, -3.9271e-02],\n",
            "          [-7.7091e-02,  6.4732e-02, -2.1609e-02],\n",
            "          [-1.8860e-02,  7.0977e-03, -3.3068e-02]],\n",
            "\n",
            "         [[-4.1607e-02, -4.8902e-02,  2.5010e-02],\n",
            "          [ 2.4871e-02,  4.0022e-02,  3.9656e-02],\n",
            "          [-8.2284e-02,  8.3118e-02, -4.2069e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.8574e-02, -5.7834e-02,  8.3874e-04],\n",
            "          [-2.1052e-02,  7.2458e-02, -8.0893e-02],\n",
            "          [-2.1344e-02, -5.8761e-02,  3.1942e-03]],\n",
            "\n",
            "         [[ 1.1539e-02,  2.8821e-02, -5.0540e-03],\n",
            "          [ 4.9397e-02,  7.1442e-02, -1.6676e-02],\n",
            "          [-1.7296e-02,  7.9432e-03, -3.7044e-02]],\n",
            "\n",
            "         [[ 1.9931e-02,  3.6135e-02,  6.7053e-02],\n",
            "          [ 7.0346e-02, -2.5206e-02,  2.9000e-02],\n",
            "          [-5.4800e-02,  3.3441e-02,  8.1460e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9146e-02,  5.2727e-02, -7.9582e-02],\n",
            "          [ 4.5671e-02,  1.2910e-02,  6.8654e-02],\n",
            "          [ 2.3663e-03,  6.6062e-02,  7.1735e-03]],\n",
            "\n",
            "         [[-5.0448e-02, -2.3134e-02,  7.5889e-02],\n",
            "          [-5.8021e-02,  7.5218e-02,  4.2656e-02],\n",
            "          [ 1.9394e-02,  2.3413e-02, -3.5866e-02]],\n",
            "\n",
            "         [[-6.6916e-02,  1.1513e-02,  6.5213e-02],\n",
            "          [ 6.7408e-02,  1.6709e-02, -4.6795e-02],\n",
            "          [-1.5024e-02,  6.3795e-02, -5.7492e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4604e-02, -8.0372e-02, -4.8780e-02],\n",
            "          [ 3.5713e-02, -3.9517e-02,  6.4963e-02],\n",
            "          [-2.7380e-02, -4.2717e-02,  6.1674e-02]],\n",
            "\n",
            "         [[-5.3551e-02, -4.6499e-02, -1.1385e-02],\n",
            "          [ 5.2103e-02, -2.2561e-02, -1.8564e-02],\n",
            "          [-6.3842e-02,  1.0369e-02, -1.2117e-02]],\n",
            "\n",
            "         [[-4.8763e-02, -7.3097e-02, -1.8784e-02],\n",
            "          [-7.3069e-02,  6.5139e-02,  8.0630e-02],\n",
            "          [ 5.6838e-02, -5.6211e-02,  7.0789e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7635e-02,  4.0050e-02,  7.7815e-02],\n",
            "          [ 5.2183e-02, -1.4920e-02, -7.0026e-02],\n",
            "          [-4.7301e-02,  1.2658e-02,  1.8608e-02]],\n",
            "\n",
            "         [[-7.3607e-02,  4.8940e-02, -6.5101e-02],\n",
            "          [ 7.0861e-02,  1.7530e-02, -1.6527e-03],\n",
            "          [-2.9492e-02, -1.3609e-02,  4.9277e-02]],\n",
            "\n",
            "         [[ 6.3353e-02,  4.5206e-02, -6.7958e-02],\n",
            "          [ 8.3224e-02, -4.3525e-02,  7.7330e-02],\n",
            "          [-4.6917e-02,  8.2215e-02,  7.0256e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7900e-02,  5.2240e-02, -6.5858e-03],\n",
            "          [-4.8251e-02, -5.1474e-02,  1.0904e-02],\n",
            "          [-9.5620e-03,  4.5054e-02,  6.2167e-02]],\n",
            "\n",
            "         [[-3.8407e-02,  5.4180e-02, -2.5712e-02],\n",
            "          [ 2.2288e-02, -2.3744e-02, -3.3917e-03],\n",
            "          [-1.7741e-02,  7.8265e-02, -7.4556e-02]],\n",
            "\n",
            "         [[ 1.3336e-04,  1.5187e-02,  7.7969e-02],\n",
            "          [-2.3130e-02,  5.3177e-02,  1.4256e-02],\n",
            "          [-1.5449e-03, -3.4685e-02, -3.5939e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5518e-02, -7.8106e-03,  1.1188e-02],\n",
            "          [ 5.8566e-02, -7.5503e-02, -4.8799e-02],\n",
            "          [ 7.8534e-02, -7.6864e-03, -5.4235e-03]],\n",
            "\n",
            "         [[-4.8229e-02, -2.4747e-02,  1.4032e-02],\n",
            "          [-2.6408e-02, -3.0844e-02, -6.4617e-02],\n",
            "          [ 7.1523e-02,  7.5792e-03, -1.8219e-02]],\n",
            "\n",
            "         [[-1.2435e-02,  5.9314e-02,  6.8632e-02],\n",
            "          [ 6.1398e-02,  2.9868e-02, -8.2195e-02],\n",
            "          [-3.4634e-03,  2.8007e-02,  2.8763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0223e-02, -7.1725e-02, -5.0124e-02],\n",
            "          [ 9.6777e-03,  2.4223e-02, -7.1778e-02],\n",
            "          [ 3.2490e-02, -8.2311e-02, -3.7245e-02]],\n",
            "\n",
            "         [[-6.6682e-02, -3.9517e-02,  6.0189e-04],\n",
            "          [ 4.7752e-02,  4.7375e-02,  4.6630e-02],\n",
            "          [ 4.7163e-03,  8.7263e-03,  4.0087e-02]],\n",
            "\n",
            "         [[-8.1609e-02, -7.4239e-02, -6.0175e-02],\n",
            "          [ 7.7161e-02,  1.4216e-02,  2.8079e-02],\n",
            "          [-2.9038e-02, -7.9810e-02, -5.7194e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3276e-02,  6.2281e-02, -6.5992e-02],\n",
            "          [ 1.6867e-02,  4.9823e-02,  3.7555e-02],\n",
            "          [ 7.6220e-02,  6.5295e-02, -2.0038e-03]],\n",
            "\n",
            "         [[-4.5562e-02,  7.9474e-02,  1.4381e-02],\n",
            "          [-2.2909e-02, -8.0703e-02, -6.7262e-02],\n",
            "          [ 6.5767e-02, -7.8513e-02, -3.2978e-02]],\n",
            "\n",
            "         [[-8.0295e-02,  7.5996e-02, -8.0098e-02],\n",
            "          [ 3.8228e-02,  5.9146e-03,  3.0472e-02],\n",
            "          [ 7.3772e-02,  4.7300e-02, -5.7094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4906e-02,  1.9164e-02, -2.9368e-02],\n",
            "          [-2.2259e-02,  4.3675e-02, -8.1335e-02],\n",
            "          [-2.6379e-02,  8.2509e-02, -5.6902e-02]],\n",
            "\n",
            "         [[ 4.8517e-02, -5.3306e-02, -4.5405e-02],\n",
            "          [-7.2836e-02,  6.9791e-04, -2.0265e-02],\n",
            "          [ 3.9212e-02,  3.0947e-02,  8.1954e-02]],\n",
            "\n",
            "         [[-1.0525e-02,  3.9170e-02,  8.1547e-02],\n",
            "          [ 1.0298e-02,  2.4142e-02,  8.1552e-02],\n",
            "          [-4.1315e-02, -6.6417e-02, -4.2100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7834e-02, -3.7336e-02, -5.6150e-02],\n",
            "          [ 1.4851e-03,  2.7738e-02, -5.7369e-02],\n",
            "          [-7.0169e-02, -4.1213e-05, -4.9262e-02]],\n",
            "\n",
            "         [[-1.4965e-02,  4.0813e-02,  6.4681e-02],\n",
            "          [-4.0381e-02, -5.2670e-03,  3.8095e-02],\n",
            "          [ 5.0829e-02,  7.8358e-02, -5.9338e-03]],\n",
            "\n",
            "         [[ 5.0548e-02,  6.9506e-02,  3.5774e-03],\n",
            "          [-2.0453e-02, -2.2837e-02,  2.7631e-02],\n",
            "          [ 2.2321e-03,  4.0112e-03,  5.9683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7560e-02,  2.7013e-02,  3.8514e-02],\n",
            "          [-6.2757e-02,  7.1732e-02,  3.4445e-02],\n",
            "          [-5.7345e-03, -4.4443e-02, -7.9402e-02]],\n",
            "\n",
            "         [[-8.3232e-02,  3.6605e-02,  3.9557e-02],\n",
            "          [-3.0950e-02, -1.1902e-02,  2.3066e-02],\n",
            "          [ 8.3602e-03,  1.4968e-02, -6.2327e-02]],\n",
            "\n",
            "         [[ 3.4100e-02,  4.9295e-02,  2.1340e-02],\n",
            "          [-2.3296e-02,  3.6142e-02,  3.7400e-03],\n",
            "          [-1.0772e-02, -7.1674e-02, -2.9318e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 6.3420e-02,  7.3276e-02,  3.5488e-02],\n",
            "          [-7.2040e-02,  9.8323e-03,  2.7458e-02],\n",
            "          [ 1.2968e-02,  1.4557e-02,  6.5395e-02]],\n",
            "\n",
            "         [[ 2.6170e-02,  5.8342e-02, -3.9271e-02],\n",
            "          [-7.7091e-02,  6.4732e-02, -2.1609e-02],\n",
            "          [-1.8860e-02,  7.0977e-03, -3.3068e-02]],\n",
            "\n",
            "         [[-4.1607e-02, -4.8902e-02,  2.5010e-02],\n",
            "          [ 2.4871e-02,  4.0022e-02,  3.9656e-02],\n",
            "          [-8.2284e-02,  8.3118e-02, -4.2069e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.8574e-02, -5.7834e-02,  8.3874e-04],\n",
            "          [-2.1052e-02,  7.2458e-02, -8.0893e-02],\n",
            "          [-2.1344e-02, -5.8761e-02,  3.1942e-03]],\n",
            "\n",
            "         [[ 1.1539e-02,  2.8821e-02, -5.0540e-03],\n",
            "          [ 4.9397e-02,  7.1442e-02, -1.6676e-02],\n",
            "          [-1.7296e-02,  7.9432e-03, -3.7044e-02]],\n",
            "\n",
            "         [[ 1.9931e-02,  3.6135e-02,  6.7053e-02],\n",
            "          [ 7.0346e-02, -2.5206e-02,  2.9000e-02],\n",
            "          [-5.4800e-02,  3.3441e-02,  8.1460e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9146e-02,  5.2727e-02, -7.9582e-02],\n",
            "          [ 4.5671e-02,  1.2910e-02,  6.8654e-02],\n",
            "          [ 2.3663e-03,  6.6062e-02,  7.1735e-03]],\n",
            "\n",
            "         [[-5.0448e-02, -2.3134e-02,  7.5889e-02],\n",
            "          [-5.8021e-02,  7.5218e-02,  4.2656e-02],\n",
            "          [ 1.9394e-02,  2.3413e-02, -3.5866e-02]],\n",
            "\n",
            "         [[-6.6916e-02,  1.1513e-02,  6.5213e-02],\n",
            "          [ 6.7408e-02,  1.6709e-02, -4.6795e-02],\n",
            "          [-1.5024e-02,  6.3795e-02, -5.7492e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4604e-02, -8.0372e-02, -4.8780e-02],\n",
            "          [ 3.5713e-02, -3.9517e-02,  6.4963e-02],\n",
            "          [-2.7380e-02, -4.2717e-02,  6.1674e-02]],\n",
            "\n",
            "         [[-5.3551e-02, -4.6499e-02, -1.1385e-02],\n",
            "          [ 5.2103e-02, -2.2561e-02, -1.8564e-02],\n",
            "          [-6.3842e-02,  1.0369e-02, -1.2117e-02]],\n",
            "\n",
            "         [[-4.8763e-02, -7.3097e-02, -1.8784e-02],\n",
            "          [-7.3069e-02,  6.5139e-02,  8.0630e-02],\n",
            "          [ 5.6838e-02, -5.6211e-02,  7.0789e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7635e-02,  4.0050e-02,  7.7815e-02],\n",
            "          [ 5.2183e-02, -1.4920e-02, -7.0026e-02],\n",
            "          [-4.7301e-02,  1.2658e-02,  1.8608e-02]],\n",
            "\n",
            "         [[-7.3607e-02,  4.8940e-02, -6.5101e-02],\n",
            "          [ 7.0861e-02,  1.7530e-02, -1.6527e-03],\n",
            "          [-2.9492e-02, -1.3609e-02,  4.9277e-02]],\n",
            "\n",
            "         [[ 6.3353e-02,  4.5206e-02, -6.7958e-02],\n",
            "          [ 8.3224e-02, -4.3525e-02,  7.7330e-02],\n",
            "          [-4.6917e-02,  8.2215e-02,  7.0256e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7900e-02,  5.2240e-02, -6.5858e-03],\n",
            "          [-4.8251e-02, -5.1474e-02,  1.0904e-02],\n",
            "          [-9.5620e-03,  4.5054e-02,  6.2167e-02]],\n",
            "\n",
            "         [[-3.8407e-02,  5.4180e-02, -2.5712e-02],\n",
            "          [ 2.2288e-02, -2.3744e-02, -3.3917e-03],\n",
            "          [-1.7741e-02,  7.8265e-02, -7.4556e-02]],\n",
            "\n",
            "         [[ 1.3336e-04,  1.5187e-02,  7.7969e-02],\n",
            "          [-2.3130e-02,  5.3177e-02,  1.4256e-02],\n",
            "          [-1.5449e-03, -3.4685e-02, -3.5939e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5518e-02, -7.8106e-03,  1.1188e-02],\n",
            "          [ 5.8566e-02, -7.5503e-02, -4.8799e-02],\n",
            "          [ 7.8534e-02, -7.6864e-03, -5.4235e-03]],\n",
            "\n",
            "         [[-4.8229e-02, -2.4747e-02,  1.4032e-02],\n",
            "          [-2.6408e-02, -3.0844e-02, -6.4617e-02],\n",
            "          [ 7.1523e-02,  7.5792e-03, -1.8219e-02]],\n",
            "\n",
            "         [[-1.2435e-02,  5.9314e-02,  6.8632e-02],\n",
            "          [ 6.1398e-02,  2.9868e-02, -8.2195e-02],\n",
            "          [-3.4634e-03,  2.8007e-02,  2.8763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0223e-02, -7.1725e-02, -5.0124e-02],\n",
            "          [ 9.6777e-03,  2.4223e-02, -7.1778e-02],\n",
            "          [ 3.2490e-02, -8.2311e-02, -3.7245e-02]],\n",
            "\n",
            "         [[-6.6682e-02, -3.9517e-02,  6.0189e-04],\n",
            "          [ 4.7752e-02,  4.7375e-02,  4.6630e-02],\n",
            "          [ 4.7163e-03,  8.7263e-03,  4.0087e-02]],\n",
            "\n",
            "         [[-8.1609e-02, -7.4239e-02, -6.0175e-02],\n",
            "          [ 7.7161e-02,  1.4216e-02,  2.8079e-02],\n",
            "          [-2.9038e-02, -7.9810e-02, -5.7194e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3276e-02,  6.2281e-02, -6.5992e-02],\n",
            "          [ 1.6867e-02,  4.9823e-02,  3.7555e-02],\n",
            "          [ 7.6220e-02,  6.5295e-02, -2.0038e-03]],\n",
            "\n",
            "         [[-4.5562e-02,  7.9474e-02,  1.4381e-02],\n",
            "          [-2.2909e-02, -8.0703e-02, -6.7262e-02],\n",
            "          [ 6.5767e-02, -7.8513e-02, -3.2978e-02]],\n",
            "\n",
            "         [[-8.0295e-02,  7.5996e-02, -8.0098e-02],\n",
            "          [ 3.8228e-02,  5.9146e-03,  3.0472e-02],\n",
            "          [ 7.3772e-02,  4.7300e-02, -5.7094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4906e-02,  1.9164e-02, -2.9368e-02],\n",
            "          [-2.2259e-02,  4.3675e-02, -8.1335e-02],\n",
            "          [-2.6379e-02,  8.2509e-02, -5.6902e-02]],\n",
            "\n",
            "         [[ 4.8517e-02, -5.3306e-02, -4.5405e-02],\n",
            "          [-7.2836e-02,  6.9791e-04, -2.0265e-02],\n",
            "          [ 3.9212e-02,  3.0947e-02,  8.1954e-02]],\n",
            "\n",
            "         [[-1.0525e-02,  3.9170e-02,  8.1547e-02],\n",
            "          [ 1.0298e-02,  2.4142e-02,  8.1552e-02],\n",
            "          [-4.1315e-02, -6.6417e-02, -4.2100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7834e-02, -3.7336e-02, -5.6150e-02],\n",
            "          [ 1.4851e-03,  2.7738e-02, -5.7369e-02],\n",
            "          [-7.0169e-02, -4.1213e-05, -4.9262e-02]],\n",
            "\n",
            "         [[-1.4965e-02,  4.0813e-02,  6.4681e-02],\n",
            "          [-4.0381e-02, -5.2670e-03,  3.8095e-02],\n",
            "          [ 5.0829e-02,  7.8358e-02, -5.9338e-03]],\n",
            "\n",
            "         [[ 5.0548e-02,  6.9506e-02,  3.5774e-03],\n",
            "          [-2.0453e-02, -2.2837e-02,  2.7631e-02],\n",
            "          [ 2.2321e-03,  4.0112e-03,  5.9683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7560e-02,  2.7013e-02,  3.8514e-02],\n",
            "          [-6.2757e-02,  7.1732e-02,  3.4445e-02],\n",
            "          [-5.7345e-03, -4.4443e-02, -7.9402e-02]],\n",
            "\n",
            "         [[-8.3232e-02,  3.6605e-02,  3.9557e-02],\n",
            "          [-3.0950e-02, -1.1902e-02,  2.3066e-02],\n",
            "          [ 8.3602e-03,  1.4968e-02, -6.2327e-02]],\n",
            "\n",
            "         [[ 3.4100e-02,  4.9295e-02,  2.1340e-02],\n",
            "          [-2.3296e-02,  3.6142e-02,  3.7400e-03],\n",
            "          [-1.0772e-02, -7.1674e-02, -2.9318e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 4.4845e-02,  5.1814e-02,  2.5094e-02],\n",
            "          [-5.0940e-02,  6.9525e-03,  1.9416e-02],\n",
            "          [ 9.1698e-03,  1.0294e-02,  4.6242e-02]],\n",
            "\n",
            "         [[ 1.8505e-02,  4.1254e-02, -2.7769e-02],\n",
            "          [-5.4512e-02,  4.5773e-02, -1.5280e-02],\n",
            "          [-1.3336e-02,  5.0188e-03, -2.3383e-02]],\n",
            "\n",
            "         [[-2.9420e-02, -3.4579e-02,  1.7685e-02],\n",
            "          [ 1.7587e-02,  2.8300e-02,  2.8041e-02],\n",
            "          [-5.8184e-02,  5.8773e-02, -2.9748e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8611e-02, -5.6831e-02, -3.4493e-02],\n",
            "          [ 2.5253e-02, -2.7943e-02,  4.5936e-02],\n",
            "          [-1.9361e-02, -3.0206e-02,  4.3610e-02]],\n",
            "\n",
            "         [[-3.7867e-02, -3.2880e-02, -8.0507e-03],\n",
            "          [ 3.6842e-02, -1.5953e-02, -1.3127e-02],\n",
            "          [-4.5143e-02,  7.3322e-03, -8.5680e-03]],\n",
            "\n",
            "         [[-3.4480e-02, -5.1687e-02, -1.3282e-02],\n",
            "          [-5.1667e-02,  4.6060e-02,  5.7014e-02],\n",
            "          [ 4.0191e-02, -3.9747e-02,  5.0055e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2470e-02,  2.8320e-02,  5.5024e-02],\n",
            "          [ 3.6899e-02, -1.0550e-02, -4.9516e-02],\n",
            "          [-3.3447e-02,  8.9503e-03,  1.3158e-02]],\n",
            "\n",
            "         [[-5.2048e-02,  3.4606e-02, -4.6034e-02],\n",
            "          [ 5.0106e-02,  1.2395e-02, -1.1686e-03],\n",
            "          [-2.0854e-02, -9.6232e-03,  3.4844e-02]],\n",
            "\n",
            "         [[ 4.4797e-02,  3.1965e-02, -4.8054e-02],\n",
            "          [ 5.8849e-02, -3.0777e-02,  5.4680e-02],\n",
            "          [-3.3176e-02,  5.8135e-02,  4.9679e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8018e-02, -2.8994e-02, -1.9422e-02],\n",
            "          [-4.2067e-02,  4.9561e-02,  2.3140e-02],\n",
            "          [-3.1462e-02, -5.2222e-02, -2.3686e-02]],\n",
            "\n",
            "         [[ 2.6994e-02,  9.5118e-03,  4.8858e-02],\n",
            "          [-5.1181e-02, -2.8469e-02, -5.3310e-02],\n",
            "          [ 8.7096e-03, -4.6548e-02, -4.4055e-02]],\n",
            "\n",
            "         [[-2.0991e-02,  1.5334e-02, -2.1385e-05],\n",
            "          [-4.1707e-02, -2.3136e-02,  5.4723e-02],\n",
            "          [ 4.3699e-02, -2.4382e-02,  4.2242e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6010e-02,  4.3814e-02, -1.2413e-02],\n",
            "          [ 1.4332e-02,  2.2193e-02,  4.1069e-02],\n",
            "          [ 5.7213e-02,  5.2797e-02,  4.5663e-03]],\n",
            "\n",
            "         [[ 3.8029e-02,  1.2206e-02,  4.8959e-03],\n",
            "          [-2.0712e-02, -9.2328e-03, -5.3781e-02],\n",
            "          [ 5.6189e-02, -4.4071e-02,  3.2018e-02]],\n",
            "\n",
            "         [[-3.9593e-02,  2.4511e-02, -3.7413e-02],\n",
            "          [-2.7640e-02, -1.7677e-02, -4.9695e-02],\n",
            "          [ 3.8388e-02,  2.2945e-02,  3.6923e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1702e-02, -5.3557e-02,  6.4093e-03],\n",
            "          [ 1.3410e-03,  6.7015e-04, -3.5026e-02],\n",
            "          [-2.9028e-02, -5.0844e-02,  3.7384e-02]],\n",
            "\n",
            "         [[-3.0373e-02,  1.5145e-02, -4.7163e-02],\n",
            "          [ 4.8873e-02, -5.2805e-02,  5.1437e-02],\n",
            "          [ 3.3870e-02, -4.1796e-02, -3.0026e-02]],\n",
            "\n",
            "         [[ 5.5603e-02, -5.5660e-02, -3.8751e-02],\n",
            "          [-3.9777e-02, -3.9544e-03,  4.7205e-02],\n",
            "          [-4.0660e-02, -5.1045e-02,  1.9755e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.4225e-03,  5.8966e-03, -5.2181e-02],\n",
            "          [ 1.2877e-02,  2.1004e-02,  1.3849e-02],\n",
            "          [-4.5653e-02,  4.2465e-02,  4.4422e-02]],\n",
            "\n",
            "         [[ 4.0491e-02, -2.8070e-02, -1.0315e-02],\n",
            "          [-3.4855e-02,  1.6074e-03,  4.2435e-02],\n",
            "          [-2.5890e-02, -5.4121e-02,  4.9705e-02]],\n",
            "\n",
            "         [[ 2.6590e-02, -3.9334e-02,  1.9364e-02],\n",
            "          [ 1.3269e-02, -3.1462e-02, -1.2197e-02],\n",
            "          [-1.9240e-02, -2.5462e-02, -3.7559e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8641e-02,  5.1524e-03,  4.0639e-02],\n",
            "          [ 1.4711e-02, -5.1846e-02, -1.3381e-02],\n",
            "          [-1.2564e-02,  4.3656e-02,  2.9459e-02]],\n",
            "\n",
            "         [[ 2.5456e-02, -2.1583e-02, -1.7562e-03],\n",
            "          [-2.9417e-03,  1.4950e-02, -4.5875e-02],\n",
            "          [-1.3552e-02, -3.3755e-02, -1.1766e-02]],\n",
            "\n",
            "         [[-5.7903e-02, -9.0666e-03, -3.3530e-02],\n",
            "          [ 1.6275e-02,  2.2725e-02,  4.1409e-02],\n",
            "          [ 3.3421e-02, -4.1847e-02, -3.3518e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8453e-02,  3.0810e-02, -4.1492e-02],\n",
            "          [-4.9423e-04, -1.5643e-02, -9.2124e-05],\n",
            "          [ 3.8616e-02,  5.6951e-02, -8.8304e-03]],\n",
            "\n",
            "         [[-3.4053e-02,  5.7430e-02, -5.2374e-02],\n",
            "          [ 7.4370e-03,  4.7341e-02, -1.1173e-02],\n",
            "          [-2.9683e-02,  4.2699e-02,  1.0138e-02]],\n",
            "\n",
            "         [[ 1.4564e-02,  4.0759e-02,  3.0126e-02],\n",
            "          [-4.3103e-02,  3.3635e-02, -3.7708e-03],\n",
            "          [-4.5272e-02,  4.4780e-02,  3.5606e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9362e-03, -4.5270e-02,  3.2289e-02],\n",
            "          [-1.6807e-02, -4.4908e-03, -3.3104e-02],\n",
            "          [-3.9801e-02, -1.2665e-02, -8.7887e-03]],\n",
            "\n",
            "         [[ 5.3640e-02,  4.6053e-02,  2.0436e-03],\n",
            "          [-1.4994e-03, -4.7443e-02,  3.9075e-02],\n",
            "          [-1.6432e-02, -5.1907e-02, -2.9914e-02]],\n",
            "\n",
            "         [[ 2.9734e-03,  1.2944e-02,  3.5550e-03],\n",
            "          [ 4.5563e-02, -4.2431e-03, -5.0833e-02],\n",
            "          [ 6.6308e-03,  4.3820e-02, -4.6857e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7160e-02, -4.5592e-02,  2.1544e-02],\n",
            "          [ 1.9051e-02,  2.2201e-02, -5.4873e-02],\n",
            "          [ 4.6079e-02,  4.9803e-02, -5.8571e-02]],\n",
            "\n",
            "         [[ 5.2928e-02, -5.1257e-03,  5.3019e-02],\n",
            "          [-2.8608e-02,  5.2892e-02, -1.0667e-02],\n",
            "          [-2.4313e-02, -7.1462e-03,  2.9066e-02]],\n",
            "\n",
            "         [[ 4.2359e-02,  2.2497e-02, -5.1829e-02],\n",
            "          [-5.7952e-02,  2.0746e-02, -5.8498e-02],\n",
            "          [-1.8216e-02, -3.7258e-03, -5.3728e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8317e-03, -4.4953e-02,  5.4703e-02],\n",
            "          [-4.5709e-02,  4.0591e-02, -1.4609e-02],\n",
            "          [-3.5994e-02, -2.0875e-02,  4.4330e-02]],\n",
            "\n",
            "         [[ 2.5360e-02, -5.0337e-02, -1.6996e-02],\n",
            "          [ 4.8848e-02,  1.2624e-02, -3.9590e-02],\n",
            "          [-4.1340e-02,  3.8589e-02,  4.0635e-02]],\n",
            "\n",
            "         [[-2.7707e-02, -4.9222e-02,  6.5755e-03],\n",
            "          [ 2.0375e-02, -3.3991e-02,  1.6203e-02],\n",
            "          [ 1.3942e-02,  5.4028e-02, -5.4231e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 4.4845e-02,  5.1814e-02,  2.5094e-02],\n",
            "          [-5.0940e-02,  6.9525e-03,  1.9416e-02],\n",
            "          [ 9.1698e-03,  1.0294e-02,  4.6242e-02]],\n",
            "\n",
            "         [[ 1.8505e-02,  4.1254e-02, -2.7769e-02],\n",
            "          [-5.4512e-02,  4.5773e-02, -1.5280e-02],\n",
            "          [-1.3336e-02,  5.0188e-03, -2.3383e-02]],\n",
            "\n",
            "         [[-2.9420e-02, -3.4579e-02,  1.7685e-02],\n",
            "          [ 1.7587e-02,  2.8300e-02,  2.8041e-02],\n",
            "          [-5.8184e-02,  5.8773e-02, -2.9748e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8611e-02, -5.6831e-02, -3.4493e-02],\n",
            "          [ 2.5253e-02, -2.7943e-02,  4.5936e-02],\n",
            "          [-1.9361e-02, -3.0206e-02,  4.3610e-02]],\n",
            "\n",
            "         [[-3.7867e-02, -3.2880e-02, -8.0507e-03],\n",
            "          [ 3.6842e-02, -1.5953e-02, -1.3127e-02],\n",
            "          [-4.5143e-02,  7.3322e-03, -8.5680e-03]],\n",
            "\n",
            "         [[-3.4480e-02, -5.1687e-02, -1.3282e-02],\n",
            "          [-5.1667e-02,  4.6060e-02,  5.7014e-02],\n",
            "          [ 4.0191e-02, -3.9747e-02,  5.0055e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2470e-02,  2.8320e-02,  5.5024e-02],\n",
            "          [ 3.6899e-02, -1.0550e-02, -4.9516e-02],\n",
            "          [-3.3447e-02,  8.9503e-03,  1.3158e-02]],\n",
            "\n",
            "         [[-5.2048e-02,  3.4606e-02, -4.6034e-02],\n",
            "          [ 5.0106e-02,  1.2395e-02, -1.1686e-03],\n",
            "          [-2.0854e-02, -9.6232e-03,  3.4844e-02]],\n",
            "\n",
            "         [[ 4.4797e-02,  3.1965e-02, -4.8054e-02],\n",
            "          [ 5.8849e-02, -3.0777e-02,  5.4680e-02],\n",
            "          [-3.3176e-02,  5.8135e-02,  4.9679e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8018e-02, -2.8994e-02, -1.9422e-02],\n",
            "          [-4.2067e-02,  4.9561e-02,  2.3140e-02],\n",
            "          [-3.1462e-02, -5.2222e-02, -2.3686e-02]],\n",
            "\n",
            "         [[ 2.6994e-02,  9.5118e-03,  4.8858e-02],\n",
            "          [-5.1181e-02, -2.8469e-02, -5.3310e-02],\n",
            "          [ 8.7096e-03, -4.6548e-02, -4.4055e-02]],\n",
            "\n",
            "         [[-2.0991e-02,  1.5334e-02, -2.1385e-05],\n",
            "          [-4.1707e-02, -2.3136e-02,  5.4723e-02],\n",
            "          [ 4.3699e-02, -2.4382e-02,  4.2242e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6010e-02,  4.3814e-02, -1.2413e-02],\n",
            "          [ 1.4332e-02,  2.2193e-02,  4.1069e-02],\n",
            "          [ 5.7213e-02,  5.2797e-02,  4.5663e-03]],\n",
            "\n",
            "         [[ 3.8029e-02,  1.2206e-02,  4.8959e-03],\n",
            "          [-2.0712e-02, -9.2328e-03, -5.3781e-02],\n",
            "          [ 5.6189e-02, -4.4071e-02,  3.2018e-02]],\n",
            "\n",
            "         [[-3.9593e-02,  2.4511e-02, -3.7413e-02],\n",
            "          [-2.7640e-02, -1.7677e-02, -4.9695e-02],\n",
            "          [ 3.8388e-02,  2.2945e-02,  3.6923e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1702e-02, -5.3557e-02,  6.4093e-03],\n",
            "          [ 1.3410e-03,  6.7015e-04, -3.5026e-02],\n",
            "          [-2.9028e-02, -5.0844e-02,  3.7384e-02]],\n",
            "\n",
            "         [[-3.0373e-02,  1.5145e-02, -4.7163e-02],\n",
            "          [ 4.8873e-02, -5.2805e-02,  5.1437e-02],\n",
            "          [ 3.3870e-02, -4.1796e-02, -3.0026e-02]],\n",
            "\n",
            "         [[ 5.5603e-02, -5.5660e-02, -3.8751e-02],\n",
            "          [-3.9777e-02, -3.9544e-03,  4.7205e-02],\n",
            "          [-4.0660e-02, -5.1045e-02,  1.9755e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.4225e-03,  5.8966e-03, -5.2181e-02],\n",
            "          [ 1.2877e-02,  2.1004e-02,  1.3849e-02],\n",
            "          [-4.5653e-02,  4.2465e-02,  4.4422e-02]],\n",
            "\n",
            "         [[ 4.0491e-02, -2.8070e-02, -1.0315e-02],\n",
            "          [-3.4855e-02,  1.6074e-03,  4.2435e-02],\n",
            "          [-2.5890e-02, -5.4121e-02,  4.9705e-02]],\n",
            "\n",
            "         [[ 2.6590e-02, -3.9334e-02,  1.9364e-02],\n",
            "          [ 1.3269e-02, -3.1462e-02, -1.2197e-02],\n",
            "          [-1.9240e-02, -2.5462e-02, -3.7559e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8641e-02,  5.1524e-03,  4.0639e-02],\n",
            "          [ 1.4711e-02, -5.1846e-02, -1.3381e-02],\n",
            "          [-1.2564e-02,  4.3656e-02,  2.9459e-02]],\n",
            "\n",
            "         [[ 2.5456e-02, -2.1583e-02, -1.7562e-03],\n",
            "          [-2.9417e-03,  1.4950e-02, -4.5875e-02],\n",
            "          [-1.3552e-02, -3.3755e-02, -1.1766e-02]],\n",
            "\n",
            "         [[-5.7903e-02, -9.0666e-03, -3.3530e-02],\n",
            "          [ 1.6275e-02,  2.2725e-02,  4.1409e-02],\n",
            "          [ 3.3421e-02, -4.1847e-02, -3.3518e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8453e-02,  3.0810e-02, -4.1492e-02],\n",
            "          [-4.9423e-04, -1.5643e-02, -9.2124e-05],\n",
            "          [ 3.8616e-02,  5.6951e-02, -8.8304e-03]],\n",
            "\n",
            "         [[-3.4053e-02,  5.7430e-02, -5.2374e-02],\n",
            "          [ 7.4370e-03,  4.7341e-02, -1.1173e-02],\n",
            "          [-2.9683e-02,  4.2699e-02,  1.0138e-02]],\n",
            "\n",
            "         [[ 1.4564e-02,  4.0759e-02,  3.0126e-02],\n",
            "          [-4.3103e-02,  3.3635e-02, -3.7708e-03],\n",
            "          [-4.5272e-02,  4.4780e-02,  3.5606e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9362e-03, -4.5270e-02,  3.2289e-02],\n",
            "          [-1.6807e-02, -4.4908e-03, -3.3104e-02],\n",
            "          [-3.9801e-02, -1.2665e-02, -8.7887e-03]],\n",
            "\n",
            "         [[ 5.3640e-02,  4.6053e-02,  2.0436e-03],\n",
            "          [-1.4994e-03, -4.7443e-02,  3.9075e-02],\n",
            "          [-1.6432e-02, -5.1907e-02, -2.9914e-02]],\n",
            "\n",
            "         [[ 2.9734e-03,  1.2944e-02,  3.5550e-03],\n",
            "          [ 4.5563e-02, -4.2431e-03, -5.0833e-02],\n",
            "          [ 6.6308e-03,  4.3820e-02, -4.6857e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7160e-02, -4.5592e-02,  2.1544e-02],\n",
            "          [ 1.9051e-02,  2.2201e-02, -5.4873e-02],\n",
            "          [ 4.6079e-02,  4.9803e-02, -5.8571e-02]],\n",
            "\n",
            "         [[ 5.2928e-02, -5.1257e-03,  5.3019e-02],\n",
            "          [-2.8608e-02,  5.2892e-02, -1.0667e-02],\n",
            "          [-2.4313e-02, -7.1462e-03,  2.9066e-02]],\n",
            "\n",
            "         [[ 4.2359e-02,  2.2497e-02, -5.1829e-02],\n",
            "          [-5.7952e-02,  2.0746e-02, -5.8498e-02],\n",
            "          [-1.8216e-02, -3.7258e-03, -5.3728e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8317e-03, -4.4953e-02,  5.4703e-02],\n",
            "          [-4.5709e-02,  4.0591e-02, -1.4609e-02],\n",
            "          [-3.5994e-02, -2.0875e-02,  4.4330e-02]],\n",
            "\n",
            "         [[ 2.5360e-02, -5.0337e-02, -1.6996e-02],\n",
            "          [ 4.8848e-02,  1.2624e-02, -3.9590e-02],\n",
            "          [-4.1340e-02,  3.8589e-02,  4.0635e-02]],\n",
            "\n",
            "         [[-2.7707e-02, -4.9222e-02,  6.5755e-03],\n",
            "          [ 2.0375e-02, -3.3991e-02,  1.6203e-02],\n",
            "          [ 1.3942e-02,  5.4028e-02, -5.4231e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1345,  0.1554,  0.0753,  ...,  0.1563,  0.0141,  0.0370],\n",
            "        [ 0.0776,  0.0739,  0.0299,  ..., -0.0886, -0.0994,  0.0869],\n",
            "        [-0.1707, -0.1056,  0.0217,  ..., -0.1671, -0.1686,  0.1544],\n",
            "        ...,\n",
            "        [ 0.1737, -0.1332,  0.1021,  ...,  0.0214, -0.1230,  0.1506],\n",
            "        [ 0.0612,  0.0354, -0.0323,  ..., -0.0069,  0.1272, -0.1179],\n",
            "        [ 0.0882, -0.1238, -0.0774,  ...,  0.0117,  0.1326,  0.1735]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1345,  0.1554,  0.0753,  ...,  0.1563,  0.0141,  0.0370],\n",
            "        [ 0.0776,  0.0739,  0.0299,  ..., -0.0886, -0.0994,  0.0869],\n",
            "        [-0.1707, -0.1056,  0.0217,  ..., -0.1671, -0.1686,  0.1544],\n",
            "        ...,\n",
            "        [ 0.1737, -0.1332,  0.1021,  ...,  0.0214, -0.1230,  0.1506],\n",
            "        [ 0.0612,  0.0354, -0.0323,  ..., -0.0069,  0.1272, -0.1179],\n",
            "        [ 0.0882, -0.1238, -0.0774,  ...,  0.0117,  0.1326,  0.1735]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1903,  0.2198,  0.1065,  ..., -0.0110, -0.2199,  0.1569],\n",
            "        [ 0.2459,  0.1016, -0.0850,  ...,  0.2210,  0.0200,  0.0523],\n",
            "        [ 0.1097,  0.1046,  0.0423,  ..., -0.2061,  0.1741,  0.1329],\n",
            "        ...,\n",
            "        [-0.2453,  0.0792, -0.2213,  ...,  0.0881, -0.0387, -0.1407],\n",
            "        [-0.2055, -0.2485,  0.1241,  ...,  0.1913, -0.1581, -0.0015],\n",
            "        [ 0.0482,  0.0903, -0.2478,  ..., -0.1664,  0.2418, -0.0021]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1903,  0.2198,  0.1065,  ..., -0.0110, -0.2199,  0.1569],\n",
            "        [ 0.2459,  0.1016, -0.0850,  ...,  0.2210,  0.0200,  0.0523],\n",
            "        [ 0.1097,  0.1046,  0.0423,  ..., -0.2061,  0.1741,  0.1329],\n",
            "        ...,\n",
            "        [-0.2453,  0.0792, -0.2213,  ...,  0.0881, -0.0387, -0.1407],\n",
            "        [-0.2055, -0.2485,  0.1241,  ...,  0.1913, -0.1581, -0.0015],\n",
            "        [ 0.0482,  0.0903, -0.2478,  ..., -0.1664,  0.2418, -0.0021]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2876,  0.3324,  0.1610, -0.3267,  0.0446,  0.1245,  0.0588,  0.0660,\n",
            "          0.2966,  0.1187,  0.2646, -0.1781, -0.3497,  0.2936, -0.0980, -0.0855,\n",
            "          0.0322, -0.1500, -0.1887, -0.2218,  0.1134,  0.1128,  0.1815,  0.1799,\n",
            "         -0.3732,  0.3770, -0.1908, -0.0666,  0.2940,  0.1676, -0.1132,  0.3359],\n",
            "        [ 0.2693,  0.2526,  0.0457,  0.3344,  0.1400,  0.3594, -0.0472, -0.2504,\n",
            "         -0.0024, -0.0601, -0.1412, -0.1225,  0.2946, -0.3243,  0.1717,  0.3388,\n",
            "          0.3514, -0.0440, -0.0156,  0.0179, -0.1082,  0.1496, -0.0065, -0.3410,\n",
            "          0.0617,  0.3029,  0.2283, -0.0619, -0.3415, -0.0166, -0.3324,  0.2373],\n",
            "        [ 0.3718,  0.1536, -0.1285,  0.1325,  0.2936, -0.3619, -0.3065,  0.3395,\n",
            "          0.2661,  0.0847, -0.0894,  0.1175, -0.0485,  0.3726, -0.0551,  0.1704,\n",
            "          0.2330, -0.0829,  0.1621, -0.2405,  0.0042, -0.2313,  0.0014, -0.0303,\n",
            "         -0.3615,  0.0199, -0.1888, -0.1070, -0.3523, -0.3042, -0.2639,  0.1346],\n",
            "        [ 0.0220,  0.2461,  0.1544,  0.2919, -0.0088,  0.3688, -0.2728, -0.0831,\n",
            "          0.0794, -0.3264, -0.2222,  0.1773, -0.2044,  0.0425,  0.2537,  0.3493,\n",
            "         -0.1775, -0.3320, -0.1200,  0.1926,  0.0255,  0.1778, -0.2897, -0.3766,\n",
            "         -0.2204,  0.1639, -0.1122,  0.3449,  0.1931,  0.3341,  0.0302,  0.0791],\n",
            "        [ 0.1659,  0.1581,  0.0640, -0.2330,  0.1653, -0.1465,  0.1987,  0.1287,\n",
            "         -0.0574,  0.2905,  0.3487,  0.2831, -0.2610,  0.3678, -0.0913,  0.1569,\n",
            "          0.0292, -0.2788, -0.1731, -0.2915,  0.2259,  0.1612,  0.3578, -0.3176,\n",
            "         -0.0024,  0.2828,  0.3750,  0.3640, -0.1596, -0.2755, -0.1410,  0.2619],\n",
            "        [-0.1277,  0.0303,  0.1724, -0.2758, -0.0612,  0.1635,  0.2044, -0.2215,\n",
            "          0.3003, -0.0222,  0.1329, -0.0526,  0.1186, -0.0493,  0.1521, -0.1209,\n",
            "         -0.3676,  0.1067, -0.2567, -0.3178,  0.1740, -0.1226,  0.2126, -0.1293,\n",
            "          0.3338, -0.0593,  0.0644,  0.3663, -0.3504, -0.3116,  0.2632,  0.2009],\n",
            "        [ 0.3360,  0.1896,  0.1881,  0.2605, -0.2705, -0.3571,  0.1134,  0.3317,\n",
            "          0.2843,  0.1291,  0.0860,  0.3087,  0.3420,  0.1620,  0.3090, -0.0063,\n",
            "         -0.0511, -0.0883,  0.0013, -0.1205,  0.2943, -0.0929, -0.0650,  0.1938,\n",
            "          0.2806, -0.2008,  0.0719,  0.1736, -0.3436,  0.2210, -0.2587, -0.0619],\n",
            "        [-0.2896, -0.0970,  0.2001, -0.1918, -0.2368, -0.3368, -0.3487, -0.2831,\n",
            "         -0.0249,  0.1367, -0.2578, -0.3531, -0.0714, -0.0308,  0.0823,  0.3769,\n",
            "          0.1515, -0.3381, -0.0591,  0.2992, -0.2515,  0.1517, -0.0268,  0.1605,\n",
            "         -0.1250,  0.2620, -0.2167,  0.2611,  0.0937, -0.1894, -0.2125,  0.1859],\n",
            "        [-0.3650, -0.2258,  0.0464,  0.0498,  0.0715, -0.2203, -0.2623,  0.0038,\n",
            "         -0.0955,  0.3286, -0.3669, -0.0968, -0.2665,  0.0145,  0.0523,  0.1307,\n",
            "         -0.0229,  0.2240,  0.3240, -0.0756, -0.0784,  0.0360, -0.1680,  0.0904,\n",
            "          0.1639,  0.3041,  0.3191, -0.1143,  0.1315, -0.2486,  0.1517,  0.3695],\n",
            "        [-0.1322,  0.2391, -0.3609,  0.2071,  0.0586,  0.3114,  0.0107,  0.2996,\n",
            "          0.0325, -0.2288, -0.1049,  0.3442, -0.2632,  0.3412,  0.1935,  0.0880,\n",
            "          0.1062, -0.1627, -0.3035,  0.0522,  0.2958,  0.3057,  0.0758, -0.2122,\n",
            "         -0.0681,  0.2893, -0.2608,  0.3305, -0.3759, -0.1999,  0.3105,  0.1000]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2876,  0.3324,  0.1610, -0.3267,  0.0446,  0.1245,  0.0588,  0.0660,\n",
            "          0.2966,  0.1187,  0.2646, -0.1781, -0.3497,  0.2936, -0.0980, -0.0855,\n",
            "          0.0322, -0.1500, -0.1887, -0.2218,  0.1134,  0.1128,  0.1815,  0.1799,\n",
            "         -0.3732,  0.3770, -0.1908, -0.0666,  0.2940,  0.1676, -0.1132,  0.3359],\n",
            "        [ 0.2693,  0.2526,  0.0457,  0.3344,  0.1400,  0.3594, -0.0472, -0.2504,\n",
            "         -0.0024, -0.0601, -0.1412, -0.1225,  0.2946, -0.3243,  0.1717,  0.3388,\n",
            "          0.3514, -0.0440, -0.0156,  0.0179, -0.1082,  0.1496, -0.0065, -0.3410,\n",
            "          0.0617,  0.3029,  0.2283, -0.0619, -0.3415, -0.0166, -0.3324,  0.2373],\n",
            "        [ 0.3718,  0.1536, -0.1285,  0.1325,  0.2936, -0.3619, -0.3065,  0.3395,\n",
            "          0.2661,  0.0847, -0.0894,  0.1175, -0.0485,  0.3726, -0.0551,  0.1704,\n",
            "          0.2330, -0.0829,  0.1621, -0.2405,  0.0042, -0.2313,  0.0014, -0.0303,\n",
            "         -0.3615,  0.0199, -0.1888, -0.1070, -0.3523, -0.3042, -0.2639,  0.1346],\n",
            "        [ 0.0220,  0.2461,  0.1544,  0.2919, -0.0088,  0.3688, -0.2728, -0.0831,\n",
            "          0.0794, -0.3264, -0.2222,  0.1773, -0.2044,  0.0425,  0.2537,  0.3493,\n",
            "         -0.1775, -0.3320, -0.1200,  0.1926,  0.0255,  0.1778, -0.2897, -0.3766,\n",
            "         -0.2204,  0.1639, -0.1122,  0.3449,  0.1931,  0.3341,  0.0302,  0.0791],\n",
            "        [ 0.1659,  0.1581,  0.0640, -0.2330,  0.1653, -0.1465,  0.1987,  0.1287,\n",
            "         -0.0574,  0.2905,  0.3487,  0.2831, -0.2610,  0.3678, -0.0913,  0.1569,\n",
            "          0.0292, -0.2788, -0.1731, -0.2915,  0.2259,  0.1612,  0.3578, -0.3176,\n",
            "         -0.0024,  0.2828,  0.3750,  0.3640, -0.1596, -0.2755, -0.1410,  0.2619],\n",
            "        [-0.1277,  0.0303,  0.1724, -0.2758, -0.0612,  0.1635,  0.2044, -0.2215,\n",
            "          0.3003, -0.0222,  0.1329, -0.0526,  0.1186, -0.0493,  0.1521, -0.1209,\n",
            "         -0.3676,  0.1067, -0.2567, -0.3178,  0.1740, -0.1226,  0.2126, -0.1293,\n",
            "          0.3338, -0.0593,  0.0644,  0.3663, -0.3504, -0.3116,  0.2632,  0.2009],\n",
            "        [ 0.3360,  0.1896,  0.1881,  0.2605, -0.2705, -0.3571,  0.1134,  0.3317,\n",
            "          0.2843,  0.1291,  0.0860,  0.3087,  0.3420,  0.1620,  0.3090, -0.0063,\n",
            "         -0.0511, -0.0883,  0.0013, -0.1205,  0.2943, -0.0929, -0.0650,  0.1938,\n",
            "          0.2806, -0.2008,  0.0719,  0.1736, -0.3436,  0.2210, -0.2587, -0.0619],\n",
            "        [-0.2896, -0.0970,  0.2001, -0.1918, -0.2368, -0.3368, -0.3487, -0.2831,\n",
            "         -0.0249,  0.1367, -0.2578, -0.3531, -0.0714, -0.0308,  0.0823,  0.3769,\n",
            "          0.1515, -0.3381, -0.0591,  0.2992, -0.2515,  0.1517, -0.0268,  0.1605,\n",
            "         -0.1250,  0.2620, -0.2167,  0.2611,  0.0937, -0.1894, -0.2125,  0.1859],\n",
            "        [-0.3650, -0.2258,  0.0464,  0.0498,  0.0715, -0.2203, -0.2623,  0.0038,\n",
            "         -0.0955,  0.3286, -0.3669, -0.0968, -0.2665,  0.0145,  0.0523,  0.1307,\n",
            "         -0.0229,  0.2240,  0.3240, -0.0756, -0.0784,  0.0360, -0.1680,  0.0904,\n",
            "          0.1639,  0.3041,  0.3191, -0.1143,  0.1315, -0.2486,  0.1517,  0.3695],\n",
            "        [-0.1322,  0.2391, -0.3609,  0.2071,  0.0586,  0.3114,  0.0107,  0.2996,\n",
            "          0.0325, -0.2288, -0.1049,  0.3442, -0.2632,  0.3412,  0.1935,  0.0880,\n",
            "          0.1062, -0.1627, -0.3035,  0.0522,  0.2958,  0.3057,  0.0758, -0.2122,\n",
            "         -0.0681,  0.2893, -0.2608,  0.3305, -0.3759, -0.1999,  0.3105,  0.1000]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
            "        0.0100], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "1\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.5621,  0.6494,  0.3145, -0.6385,  0.0871,  0.2434,  0.1149,  0.1290,\n",
            "          0.5796,  0.2319]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.5621,  0.6494,  0.3145, -0.6385,  0.0871,  0.2434,  0.1149,  0.1290,\n",
            "          0.5796,  0.2319]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0100], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Focus(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (dropout1): Dropout2d(p=0.05, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9"
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I"
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX"
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7"
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_classify = optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylCWkAlwv6EL"
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQASTbrKv586",
        "outputId": "e13c91b6-42da-4ce4-fdee-a3de25623b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 33 %\n",
            "total correct 10010\n",
            "total train set images 30000\n",
            "focus_true_pred_true 1004 =============> FTPT : 3 %\n",
            "focus_false_pred_true 9006 =============> FFPT : 30 %\n",
            "focus_true_pred_false 2191 =============> FTPF : 7 %\n",
            "focus_false_pred_false 17799 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  3\n",
            "argmax_less_than_half ==================>  29997\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZmkgV3cv55D",
        "outputId": "dd411d44-a271-43e8-948c-2937cf76504f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 32 %\n",
            "total correct 3289\n",
            "total train set images 10000\n",
            "focus_true_pred_true 342 =============> FTPT : 3 %\n",
            "focus_false_pred_true 2947 =============> FFPT : 29 %\n",
            "focus_true_pred_false 775 =============> FTPF : 7 %\n",
            "focus_false_pred_false 5936 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  0\n",
            "argmax_less_than_half ==================>  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFfAJZkcZEsY",
        "outputId": "3b72d65e-bb3e-4560-95e2-c61320d29dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "nos_epochs = 300\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_focus.step()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    col1.append(epoch+1)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 1.100\n",
            "[1,   120] loss: 1.097\n",
            "[1,   180] loss: 1.095\n",
            "[1,   240] loss: 1.087\n",
            "[2,    60] loss: 1.070\n",
            "[2,   120] loss: 1.067\n",
            "[2,   180] loss: 1.042\n",
            "[2,   240] loss: 1.013\n",
            "[3,    60] loss: 0.972\n",
            "[3,   120] loss: 0.961\n",
            "[3,   180] loss: 0.949\n",
            "[3,   240] loss: 0.911\n",
            "[4,    60] loss: 0.881\n",
            "[4,   120] loss: 0.862\n",
            "[4,   180] loss: 0.850\n",
            "[4,   240] loss: 0.817\n",
            "[5,    60] loss: 0.789\n",
            "[5,   120] loss: 0.762\n",
            "[5,   180] loss: 0.755\n",
            "[5,   240] loss: 0.739\n",
            "[6,    60] loss: 0.699\n",
            "[6,   120] loss: 0.679\n",
            "[6,   180] loss: 0.698\n",
            "[6,   240] loss: 0.655\n",
            "[7,    60] loss: 0.614\n",
            "[7,   120] loss: 0.627\n",
            "[7,   180] loss: 0.613\n",
            "[7,   240] loss: 0.614\n",
            "[8,    60] loss: 0.573\n",
            "[8,   120] loss: 0.557\n",
            "[8,   180] loss: 0.555\n",
            "[8,   240] loss: 0.540\n",
            "[9,    60] loss: 0.503\n",
            "[9,   120] loss: 0.507\n",
            "[9,   180] loss: 0.509\n",
            "[9,   240] loss: 0.509\n",
            "[10,    60] loss: 0.447\n",
            "[10,   120] loss: 0.478\n",
            "[10,   180] loss: 0.456\n",
            "[10,   240] loss: 0.462\n",
            "[11,    60] loss: 0.422\n",
            "[11,   120] loss: 0.416\n",
            "[11,   180] loss: 0.443\n",
            "[11,   240] loss: 0.447\n",
            "[12,    60] loss: 0.397\n",
            "[12,   120] loss: 0.404\n",
            "[12,   180] loss: 0.411\n",
            "[12,   240] loss: 0.394\n",
            "[13,    60] loss: 0.380\n",
            "[13,   120] loss: 0.384\n",
            "[13,   180] loss: 0.356\n",
            "[13,   240] loss: 0.374\n",
            "[14,    60] loss: 0.335\n",
            "[14,   120] loss: 0.331\n",
            "[14,   180] loss: 0.353\n",
            "[14,   240] loss: 0.347\n",
            "[15,    60] loss: 0.307\n",
            "[15,   120] loss: 0.312\n",
            "[15,   180] loss: 0.303\n",
            "[15,   240] loss: 0.316\n",
            "[16,    60] loss: 0.269\n",
            "[16,   120] loss: 0.306\n",
            "[16,   180] loss: 0.280\n",
            "[16,   240] loss: 0.295\n",
            "[17,    60] loss: 0.259\n",
            "[17,   120] loss: 0.251\n",
            "[17,   180] loss: 0.279\n",
            "[17,   240] loss: 0.285\n",
            "[18,    60] loss: 0.240\n",
            "[18,   120] loss: 0.236\n",
            "[18,   180] loss: 0.241\n",
            "[18,   240] loss: 0.263\n",
            "[19,    60] loss: 0.218\n",
            "[19,   120] loss: 0.242\n",
            "[19,   180] loss: 0.235\n",
            "[19,   240] loss: 0.227\n",
            "[20,    60] loss: 0.217\n",
            "[20,   120] loss: 0.221\n",
            "[20,   180] loss: 0.221\n",
            "[20,   240] loss: 0.217\n",
            "[21,    60] loss: 0.196\n",
            "[21,   120] loss: 0.201\n",
            "[21,   180] loss: 0.192\n",
            "[21,   240] loss: 0.209\n",
            "[22,    60] loss: 0.184\n",
            "[22,   120] loss: 0.177\n",
            "[22,   180] loss: 0.199\n",
            "[22,   240] loss: 0.191\n",
            "[23,    60] loss: 0.171\n",
            "[23,   120] loss: 0.178\n",
            "[23,   180] loss: 0.178\n",
            "[23,   240] loss: 0.178\n",
            "[24,    60] loss: 0.140\n",
            "[24,   120] loss: 0.161\n",
            "[24,   180] loss: 0.171\n",
            "[24,   240] loss: 0.157\n",
            "[25,    60] loss: 0.147\n",
            "[25,   120] loss: 0.140\n",
            "[25,   180] loss: 0.148\n",
            "[25,   240] loss: 0.159\n",
            "[26,    60] loss: 0.129\n",
            "[26,   120] loss: 0.136\n",
            "[26,   180] loss: 0.138\n",
            "[26,   240] loss: 0.142\n",
            "[27,    60] loss: 0.129\n",
            "[27,   120] loss: 0.142\n",
            "[27,   180] loss: 0.135\n",
            "[27,   240] loss: 0.128\n",
            "[28,    60] loss: 0.100\n",
            "[28,   120] loss: 0.123\n",
            "[28,   180] loss: 0.128\n",
            "[28,   240] loss: 0.129\n",
            "[29,    60] loss: 0.100\n",
            "[29,   120] loss: 0.109\n",
            "[29,   180] loss: 0.129\n",
            "[29,   240] loss: 0.124\n",
            "[30,    60] loss: 0.099\n",
            "[30,   120] loss: 0.106\n",
            "[30,   180] loss: 0.110\n",
            "[30,   240] loss: 0.107\n",
            "[31,    60] loss: 0.084\n",
            "[31,   120] loss: 0.103\n",
            "[31,   180] loss: 0.101\n",
            "[31,   240] loss: 0.108\n",
            "[32,    60] loss: 0.080\n",
            "[32,   120] loss: 0.084\n",
            "[32,   180] loss: 0.096\n",
            "[32,   240] loss: 0.109\n",
            "[33,    60] loss: 0.072\n",
            "[33,   120] loss: 0.077\n",
            "[33,   180] loss: 0.084\n",
            "[33,   240] loss: 0.090\n",
            "[34,    60] loss: 0.077\n",
            "[34,   120] loss: 0.077\n",
            "[34,   180] loss: 0.093\n",
            "[34,   240] loss: 0.089\n",
            "[35,    60] loss: 0.079\n",
            "[35,   120] loss: 0.079\n",
            "[35,   180] loss: 0.079\n",
            "[35,   240] loss: 0.074\n",
            "[36,    60] loss: 0.075\n",
            "[36,   120] loss: 0.091\n",
            "[36,   180] loss: 0.074\n",
            "[36,   240] loss: 0.066\n",
            "[37,    60] loss: 0.067\n",
            "[37,   120] loss: 0.058\n",
            "[37,   180] loss: 0.068\n",
            "[37,   240] loss: 0.084\n",
            "[38,    60] loss: 0.066\n",
            "[38,   120] loss: 0.062\n",
            "[38,   180] loss: 0.061\n",
            "[38,   240] loss: 0.062\n",
            "[39,    60] loss: 0.053\n",
            "[39,   120] loss: 0.061\n",
            "[39,   180] loss: 0.073\n",
            "[39,   240] loss: 0.065\n",
            "[40,    60] loss: 0.050\n",
            "[40,   120] loss: 0.062\n",
            "[40,   180] loss: 0.064\n",
            "[40,   240] loss: 0.043\n",
            "[41,    60] loss: 0.048\n",
            "[41,   120] loss: 0.044\n",
            "[41,   180] loss: 0.046\n",
            "[41,   240] loss: 0.051\n",
            "[42,    60] loss: 0.050\n",
            "[42,   120] loss: 0.045\n",
            "[42,   180] loss: 0.047\n",
            "[42,   240] loss: 0.045\n",
            "[43,    60] loss: 0.042\n",
            "[43,   120] loss: 0.049\n",
            "[43,   180] loss: 0.047\n",
            "[43,   240] loss: 0.045\n",
            "[44,    60] loss: 0.053\n",
            "[44,   120] loss: 0.048\n",
            "[44,   180] loss: 0.046\n",
            "[44,   240] loss: 0.048\n",
            "[45,    60] loss: 0.040\n",
            "[45,   120] loss: 0.049\n",
            "[45,   180] loss: 0.042\n",
            "[45,   240] loss: 0.046\n",
            "[46,    60] loss: 0.035\n",
            "[46,   120] loss: 0.037\n",
            "[46,   180] loss: 0.043\n",
            "[46,   240] loss: 0.040\n",
            "[47,    60] loss: 0.033\n",
            "[47,   120] loss: 0.038\n",
            "[47,   180] loss: 0.039\n",
            "[47,   240] loss: 0.031\n",
            "[48,    60] loss: 0.027\n",
            "[48,   120] loss: 0.030\n",
            "[48,   180] loss: 0.039\n",
            "[48,   240] loss: 0.047\n",
            "[49,    60] loss: 0.030\n",
            "[49,   120] loss: 0.037\n",
            "[49,   180] loss: 0.036\n",
            "[49,   240] loss: 0.023\n",
            "[50,    60] loss: 0.030\n",
            "[50,   120] loss: 0.028\n",
            "[50,   180] loss: 0.037\n",
            "[50,   240] loss: 0.035\n",
            "[51,    60] loss: 0.032\n",
            "[51,   120] loss: 0.030\n",
            "[51,   180] loss: 0.033\n",
            "[51,   240] loss: 0.034\n",
            "[52,    60] loss: 0.023\n",
            "[52,   120] loss: 0.031\n",
            "[52,   180] loss: 0.039\n",
            "[52,   240] loss: 0.033\n",
            "[53,    60] loss: 0.022\n",
            "[53,   120] loss: 0.028\n",
            "[53,   180] loss: 0.037\n",
            "[53,   240] loss: 0.030\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "outputId": "67c33b16-cf5e-4184-b122-a9073694082e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "name = \"focus_random_classify_random_train_both_\"+str(k)\n",
        "name"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'focus_random_classify_random_train_both_1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE"
      },
      "source": [
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/focus_net_params_multiplied_by_k/\"+name+\".pt\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o"
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO"
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "outputId": "4bb895d5-9e6a-4cfc-cf30-a9d7b0b3d4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "df_train"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>29997</td>\n",
              "      <td>1004</td>\n",
              "      <td>9006</td>\n",
              "      <td>2191</td>\n",
              "      <td>17799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>29998</td>\n",
              "      <td>1342</td>\n",
              "      <td>10040</td>\n",
              "      <td>1864</td>\n",
              "      <td>16754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>13934</td>\n",
              "      <td>16066</td>\n",
              "      <td>13136</td>\n",
              "      <td>7731</td>\n",
              "      <td>2440</td>\n",
              "      <td>6693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>18858</td>\n",
              "      <td>11142</td>\n",
              "      <td>17557</td>\n",
              "      <td>7141</td>\n",
              "      <td>1415</td>\n",
              "      <td>3887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>20714</td>\n",
              "      <td>9286</td>\n",
              "      <td>20044</td>\n",
              "      <td>6687</td>\n",
              "      <td>876</td>\n",
              "      <td>2393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>20986</td>\n",
              "      <td>9014</td>\n",
              "      <td>21380</td>\n",
              "      <td>6435</td>\n",
              "      <td>574</td>\n",
              "      <td>1611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>20918</td>\n",
              "      <td>9082</td>\n",
              "      <td>22364</td>\n",
              "      <td>6181</td>\n",
              "      <td>391</td>\n",
              "      <td>1064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>20277</td>\n",
              "      <td>9723</td>\n",
              "      <td>22668</td>\n",
              "      <td>6333</td>\n",
              "      <td>282</td>\n",
              "      <td>717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>20187</td>\n",
              "      <td>9813</td>\n",
              "      <td>22950</td>\n",
              "      <td>6303</td>\n",
              "      <td>234</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>20041</td>\n",
              "      <td>9959</td>\n",
              "      <td>23222</td>\n",
              "      <td>6305</td>\n",
              "      <td>159</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>19999</td>\n",
              "      <td>10001</td>\n",
              "      <td>23436</td>\n",
              "      <td>6199</td>\n",
              "      <td>133</td>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>51</td>\n",
              "      <td>19842</td>\n",
              "      <td>10158</td>\n",
              "      <td>23356</td>\n",
              "      <td>6348</td>\n",
              "      <td>102</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0             3  ...                   2191                   17799\n",
              "1        1             2  ...                   1864                   16754\n",
              "2        6         13934  ...                   2440                    6693\n",
              "3       11         18858  ...                   1415                    3887\n",
              "4       16         20714  ...                    876                    2393\n",
              "5       21         20986  ...                    574                    1611\n",
              "6       26         20918  ...                    391                    1064\n",
              "7       31         20277  ...                    282                     717\n",
              "8       36         20187  ...                    234                     513\n",
              "9       41         20041  ...                    159                     314\n",
              "10      46         19999  ...                    133                     232\n",
              "11      51         19842  ...                    102                     194\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "outputId": "7551e09b-f619-409c-c140-6204c73db437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAEWCAYAAABoup70AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV5d3//9fnZCEsYQ/7viegoERAa9W6olXQaq2tC+53q+23i7Xa/vq9a9e7erd697at/VJFcKtaW8VaQCnuVUGQIgEREEHAhJ2wJiQ5n98fM4FDCCTQczInyfv5eJzHmXPNNTOfQeQzc80112XujoiIiDQfsagDEBERkYal5C8iItLMKPmLiIg0M0r+IiIizYySv4iISDOj5C8iItLMKPmLRMDMlpjZGcmuKyJSH0r+0qSZ2bVmttjM9phZiZk9YGbtj2E/fcxsV8LHzWx3wu/PHs3+3H24u7+a7LoNwcymmtnPoo5DRI6dkr80WWZ2G3A3cDvQDhgH9AVmm1n20ezL3T9x9zbVn7B4ZELZGwnHzUzSKYiIpISSvzRJZtYW+DHwDXef5e4V7r4auBzoB1wV1rvLzJ42s0fMbGfYxF54lMe61sz+aWb3mdkW4C4zG2hmL5vZFjPbbGaPJ7Y4mNlqMzu7PjEcZd0TzWxhuO7PZvbU4e7SzWyQmb1mZqVhjE8lrBtmZrPNbKuZfWhml4flNwNXAt8LWzz+djR/ViKSHpT8pak6BcgB/ppY6O67gBnAOQnFE4AngfbA88Bvj+F4Y4FVQFfg54AB/wX0APKB3sBdR9j+aGKotW7YmvEsMBXoCPwJuOQI+/kp8BLQAegF3B/upzUwG3gC6AJcAfzezArcfTLwOHBP2OJx0RH2LyJpSslfmqrOwGZ3r6xlXXG4vtqb7j7D3auAR4GRx3C8T939fnevdPe97r7S3We7e7m7bwLuBU4/wvZHE8Ph6o4DMoH/DVs6/grMO8J+Kggeg/Rw9zJ3fzMsvxBY7e4Ph+ezEPgL8MU6/gxEpJFQ8pemajPQ+TDP37uH66uVJCzvAXKO4bn92sQfZtbVzJ40s/VmtgN4jIMvOGo6mhgOV7cHsN4Pnq3roLhq+B5BC8W88PHB9WF5X2CsmW2v/hA09Xc7wr5EpBFR8pem6m2gHPhCYqGZtQHOB+Yk+Xg1p8f8RVh2nLu3JehjYEk+Zk3FQE8zSzxO78NVdvcSd7/J3XsA/0HQtD+I4ILhNXdvn/Bp4+5fq940ZWcgIg1CyV+aJHcvJejwd7+ZjTezLDPrBzwNrCNoLk+lXGAXUGpmPQneOEi1t4Eq4OtmlmlmE4Exh6tsZl80s17hz20EST0OvAAMMbOrwz+3LDM7yczyw7obgAGpOw0RSTUlf2my3P0e4AfAr4AdwFyCu9qz3L08xYf/MXAiUAr8nRodD1PB3fcRtHTcAGwnaG14gaAFpDYnAXPNbBdBx8Fvuvsqd98JnEvQ0e9TgscMdwMtwu0eAgrCRwLPpep8RCR17ODHgyLSlJjZXOAP7v5w1LGISPrQnb9IE2Jmp5tZt7DZfxJwPDAr6rhEJL1oJDKRpmUoQb+G1gTjDlzm7sXRhiQi6UbN/iIiIs2Mmv1FRESamWbX7N+5c2fv169f1GGIiDQqCxYs2OzueVHHIcnR7JJ/v379mD9/ftRhiIg0Kma2JuoYJHnU7C8iItLMKPmLiIg0M0r+IiIizYySv4iISDOj5C8iItLMpCz5m1mOmc0zs0XhXOE/Dsv7m9lcM1tpZk+ZWXZY3iL8vTJc3y9hX98Pyz80s/MSyseHZSvN7M5UnYuIiEhTkso7/3LgTHcfCYwCxpvZOILZwe5z90EE04jeENa/AdgWlt8X1sPMCghmFxsOjCeYczzDzDKA3xHMzV4AfDmsKyIiIkeQsvf8PRg3eFf4Myv8OHAm8JWwfBpwF/AAMDFcBngG+K2ZWVj+ZDgF68dmtpIDc5SvdPdVAGb2ZFh3aUpOaN4fYfem6pM7eF3+RdD9+JQcVkREJNlSOshPeHe+ABhEcJf+EbDd3SvDKuuAnuFyT4K51nH3SjMrBTqF5e8k7DZxm7U1ysceJo6bgZsB+vTpc2wn8+6DsGlZ7etWvwnXzzy2/YqIiDSwlCZ/d68CRplZe+BZYFgqj3eEOCYDkwEKCwuPbSajW+fWXv7Kf8Frd8PODZDb9VhDFBERaTAN0tvf3bcDrwAnA+3NrPqioxewPlxeD/QGCNe3A7YkltfY5nDlDatgAuCw7IUGP7SIiMixSGVv/7zwjh8zawmcA3xAcBFwWVhtEjA9XH4+/E24/uWw38DzwBXh2wD9gcHAPOBdYHD49kA2QafA51N1PofVpQA6DoQPGv7QIiIixyKVzf7dgWnhc/8Y8LS7v2BmS4EnzexnwELgobD+Q8CjYYe+rQTJHHdfYmZPE3TkqwRuDR8nYGZfB14EMoAp7r4khedTOzMomAj//A3s2QqtOjZ4CCIiIkfDvGbP9SausLDQkz6r36cLYfIZMOG3cOLVyd23iEgaMLMF7l4YdRySHBrhLxm6j4L2fdT0LyIijYKSfzKYQf4E+OgVKCuNOhoREZEjUvJPlvwJEK+A5S9GHYmIiMgRKfknS6+TILc7LJ1ed10REZEIKfknSywWDPO78h9Qvqvu+iIiIhFR8k+m/AlQWQYrZ0cdiYiIyGEp+SdT31OgVWdYql7/IiKSvpT8kymWAfkXwoqXoKIs6mhERERqpeSfbPkTYN8u+OjlqCMRERGplZJ/svU/DXLaq9e/iIikLSX/ZMvIgqEXwIczoXJf1NGIiIgcQsk/FQomQHkpfPx61JGIiIgcQsk/FQZ8DrJz4QM1/YuISPpR8k+FrBwYch4s+ztUVUYdjYiIyEGU/FOlYALs2QJr/hl1JCIiIgdR8k+VQWdDZktN8ysiImlHyT9VslvD4LPhgxcgHo86GhERkf2U/FOp4GLYVQLr5kUdiYiIyH5K/qk0+FzIyNZY/yIiklaU/FMppy0MPDN47u8edTQiIiKAkn/q5U+A0rXw6XtRRyIiIgIo+afe0PMhlqmmfxERSRtK/qnWqmMw2Y+a/kVEJE0o+TeE/AmwdRVsWBJ1JCIiIqlL/mbW28xeMbOlZrbEzL4Zlt9lZuvN7F/h54KEbb5vZivN7EMzOy+hfHxYttLM7kwo729mc8Pyp8wsO1Xn828ZdiFYTNP8iohIWkjlnX8lcJu7FwDjgFvNrCBcd5+7jwo/MwDCdVcAw4HxwO/NLMPMMoDfAecDBcCXE/Zzd7ivQcA24IYUns+xa5MHfU7RaH8iIpIWUpb83b3Y3d8Ll3cCHwA9j7DJROBJdy9394+BlcCY8LPS3Ve5+z7gSWCimRlwJvBMuP004OLUnE0SFEyATctg0/KoIxERkWauQZ75m1k/4ARgblj0dTN738ymmFmHsKwnsDZhs3Vh2eHKOwHb3b2yRnltx7/ZzOab2fxNmzYl4YyOQf5Fwbem+RURkYilPPmbWRvgL8C33H0H8AAwEBgFFAO/TnUM7j7Z3QvdvTAvLy/Vh6td2x7Qa4xe+RMRkcilNPmbWRZB4n/c3f8K4O4b3L3K3ePAHwma9QHWA70TNu8Vlh2ufAvQ3swya5Snr4IJUPI+bP046khERKQZS2VvfwMeAj5w93sTyrsnVLsEKAqXnweuMLMWZtYfGAzMA94FBoc9+7MJOgU+7+4OvAJcFm4/CUjvNvX9Tf+6+xcRkeik8s7/M8DVwJk1Xuu7x8wWm9n7wOeAbwO4+xLgaWApMAu4NWwhqAS+DrxI0Gnw6bAuwB3Ad8xsJUEfgIdSeD7/vg79oPsoNf2LiEikzJvZqHOFhYU+f/786AJ449cw5yfw7aXQ7kgvP4iIpA8zW+DuhVHHIcmhEf4aWv7E4PuDv0Ubh4iINFtK/g2t8yDoUqDR/kREJDJK/lHInwCfvA07N0QdiYiINENK/lEomAg4LHsh6khERKQZUvKPQpd86DRIr/yJiEgklPyjYBY0/X/8BuzZGnU0IiLSzCj5R6VgAngVLPt71JGIiEgzo+Qfle6joH0fNf2LiEiDU/KPSnXT/0evQFlp1NGIiEgzouQfpYKJEK+A5S9GHYmIiDQjSv5R6lkIud014I+IiDQoJf8oxWLBTH8r/wHlu6KORkREmgkl/6jlT4DKMlg5O+pIRESkmVDyj1rfU6BVZ03zKyIiDUbJP2qxDMi/EFa8BBVlUUcjIiLNgJJ/OsifAPt2wUcvRx2JiIg0A0r+6aD/aZDTXr3+RUSkQSj5p4OMLBh6AXw4Eyr3RR2NiIg0cUr+6aJgIpSXwsevRx2JiIg0cZlRByChgZ+D7Fz4YDoMPjvqaJq9iqo4O8sqKauoIiNmZMSMzP3fsf1lMQMzizpcEZGjouSfLjJbwJDzgln+Pn8fZOg/zbGKx53d+yrZUVbJzrIKduwNvneWVbIj4bvW8r3B996KqnofL7PmxUFGjJgl/j6wPmbVv2OHbJe43DYni36dW9O3Uyv6dQq+c3OyUvinJiLNiTJMOimYAEXPwJp/woDTo44mbZTureCtlZvZvrdif3LeWVZxUHJPTOq7yitxP/I+szNjtM3JpG1OFrk5mbRtmUX3djnktsiibctMcsPyllkZxB2q4nEq405V3Pd/H1gO11U5VZ5QXnVgfVX1Pqpq2UeVU1ZRdVD51t37+POCdQfF3LlNNn07Hbgg6Ne5Nf06taJvp9a0a6kLAxGpPyX/dDLoHMhqFUzzq+TP4nWlPPbOGp5f9OlBd+IxY39yzs3Jom1OJr06tKJty4RknpDUE+tVb5eTlRHhmdXPnn2VfLJ1D6s372b1lj2s2bKb1Zv38PZHW/jre+sPqtuhVVZ4MXBwa0H/zq1p3yo7ojMQkXSl5J9OslvBoLPhgxfg/P8Oxv5vZvbuq+Jv73/K4++sYdG6UnKyYkwc2ZMvFvaiR/uWtG2ZRevsjGbxnL1VdibDurVlWLe2h6wrq6hKuDA4cHEw7+OtPPev9Qe1fLRrmbW/haBfp1bh44RguWPr7GbxZykiB0tZ8jez3sAjQFfAgcnu/hsz6wg8BfQDVgOXu/s2C/4F+g1wAbAHuNbd3wv3NQn4Ybjrn7n7tLB8NDAVaAnMAL7pXleDb5ormBjc+a+bB33GRR1Ng1m5cRdPzP2EZxasZUdZJYO6tOGuiwq45MReatKuRU5WBkO65jKka+4h68oqqli3bQ+rN+8JLwx2s2bLHhau3cYL739KPOH/kNwWmfTtHD5G6NSaDq2zycoIOjVmZtj+5cSy7IwYmRnh+hr1guUYWTXWZ8ZMFxkiaSSVd/6VwG3u/p6Z5QILzGw2cC0wx91/aWZ3AncCdwDnA4PDz1jgAWBseLHwI6CQ4CJigZk97+7bwjo3AXMJkv94YGYKzyn1Bp8LGdnBWP9NPPlXVMV5ackGHntnDW+v2kJWhnHe8G5cNa4vY/t3VLI4RjlZGQzqksugLodeGOyrjLN224FHCGu27ObjLXtYvL6UmUUlVMVTd+2cGXZ+3H9BkBELLySCC4qcrAxaZMZokRWjRWYGOeF3i8wYLTIT19f4zgzrZcXICb+ry/bvIyzLzojp75UIKUz+7l4MFIfLO83sA6AnMBE4I6w2DXiVIPlPBB4J79zfMbP2ZtY9rDvb3bcChBcQ483sVaCtu78Tlj8CXExjT/45bWHgmcHd/3k/hyb4D9Wn2/fyp3mf8OS7a9m0s5ye7Vty+3lDubywN3m5LaIOr0nLzowxMK8NA/PaHLKuoirOnvIqKsKOiRVVQUfGyqo4+6qCssp4nIqqoJNidb3KqjgVYb3KKg/rBttW1FwfD/cb7r8i3Oe+yjjllXHKK6soq4hTureC8oqgrKyi6qB1/w4zDlwsZMbC1zWNWAwyLFg2Y3+5mZERI6hjwaudQf0Dyxlhq0ZG+PugbWIHtstIWFd9YZKTlbH/oqZ6OSfh4icnK4OchOUWCWVZGWpNkWPXIM/8zawfcALBHXrX8MIAoITgsQAEFwZrEzZbF5YdqXxdLeW1Hf9m4GaAPn36HPuJNJSCibB8Fnz6HvQcHXU0SRGPO6+v2MRj73zCy8s24MAZQ/K4alxfzhjahYyY/hGLWlZGjHat0rufiXtwcVFeGQ8vDoILgvLKqsOXVcYpr76ACL+rLyiq4k7cIe4efoK/q/HwrY24B8es8oTlcH08DpUeD+qG64LtDq7nTrh9uE14sVNWEaessqrON1MOJ2ZHuoiIHfw7rPeDz+fTIjP9O7tK6qU8+ZtZG+AvwLfcfUfilaq7u5ml/Bm9u08GJgMUFhamf5+AoedDLDNo+m/kyX/LrnL+vGAdT8z9hE+27qFzm2y+evpAvjymD707too6PGlkzCy8a8+AnKij+fdVX8yUVQQXJtUXBOXhd1l1WUW4XOMC5qD14bqycN223fv276/6YueHFxZEfcqSJlKa/M0siyDxP+7ufw2LN5hZd3cvDpv1N4bl64HeCZv3CsvWc+AxQXX5q2F5r1rqN34tOwST/XzwPJx9V6Nr+nd35q/ZxuPvrGHG4hL2VcUZ078j3z1vKOOHdyM7M73vLkUaykEXM+rYKg2ozuRvZnkEz+QLSLjWdvcz69jOgIeAD9z93oRVzwOTgF+G39MTyr9uZk8SdPgrDS8QXgR+YWYdwnrnAt93961mtsPMxhE8TrgGuL+u82k08ifAC9+CDUug24ioo6mXnWUVPLdwPY/P/YRlJTvJbZHJl8f05spxfWvtlS4iItGoz53/4wSv5n0e+CpBwt5Uj+0+A1wNLDazf4VlPyBI+k+b2Q3AGuDycN0Mgtf8VhK86ncdQJjkfwq8G9b7SXXnP+AWDrzqN5PG3tkv0bAL4e/fCab5TfPkv/TTHTw2dw3TF65n974qhvdoy3994TgmjOxB6xYaSkJEJN1YXa/Fm9kCdx9tZu+7+/Fh2bvuflKDRJhkhYWFPn/+/KjDqJ+pF8LuTXDr3KgjOURZRRUzFhfz2DtreO+T7bTIjHHRyB5cNa4vI3u1Uy9kkSYmzAWFUcchyVGf27KK8LvYzD4PfAp0TF1Isl/+BJh5O2xaDnlDoo4GgDVbdvP43E/48/y1bNtTwYDOrfnh5/O5bHQvDSMrItJI1Cf5/8zM2gG3ETxTbwt8K6VRSSD/wiD5fzAd8m6POhpmLC7mG39aCMC5BV25alxfThnYSXf5IiKNTH2S/zZ3LwVKgc8BmNlnUhqVBNr2gF5jglf+Tos2+f9z5Wa+9eS/GNW7Pb+/8kS6tm0C71mJiDRT9XnnqrYe9E2nV326K5gAJe/D1o8jC2HR2u3c/Mh8BuS1Zsqkk5T4RUQaucPe+ZvZycApQJ6ZfSdhVVtAQ0Q1lPwJ8NIPg3f+P/PNBj/8yo27uPbheXRsk82068fQrpXeRRYRaeyOdOefDbQhuEDITfjsAC5LfWgCQIe+0H1U0PTfwD7dvpdrHppLRizGo9eP1R2/iEgTcdg7f3d/DXjNzKa6+5oGjElqKpgAc34CpeuhXa3TFyTd1t37uPqhuewsq+TJ/xhHv86tG+S4IiKSevV55r/HzP7bzGaY2cvVn5RHJgfkTwy+P/hbgxxud3kl1019l3Xb9vLgpEKG92jXIMcVEZGGUZ/k/ziwDOgP/BhYzYHR9qQhdB4EXQqC0f5SrLyyiq8+toCi9aX89isnMnZAp5QfU0REGlZ9kn8nd38IqHD319z9euCI4/pLChRMhE/ehp0bUnaIqrjznacW8caKzdx96fGcU9C17o1ERKTRqU/yP2iEPzM7AY3w1/DyJwAOy15Iye7dnf87vYi/Ly7m/7sgGLFPRESapmMd4e/bKY1KDtUlHzoNCl75O+mGpO/+3tnLeWLuJ3ztjIHcdNqApO9fRJqeBQsWdMnMzHwQGEH9bialYcSBosrKyhtHjx69sbYKdSZ/d6++1dw/wp9EwCy4+//nb2DPVmiVvMaXKW9+zP0vr+SKk3rzvfOGJm2/ItK0ZWZmPtitW7f8vLy8bbFY7MizxEmDicfjtmnTpoKSkpIHgQm11TnSID/3A4f9j+nu/+ffD1GOSsFEePNeWPZ3OPHqpOzy2YXr+MkLSzlveFd+dvEIjdMvIkdjhBJ/+onFYp6Xl1daUlJy2Pngj9RMMx9YAOQAJwIrws8oggGApKF1Hwnt+wRN/0nwyrKN3P7n9zl5QCd+c8UJZGao1U5EjkpMiT89hf9dDvuP+mFXuPs0d58GHA+c4e73u/v9wFkEFwDS0Kqb/j96BcpK/61dzV+9la89voBh3XOZfM1ocrI0YrOISNTi8TjXXntt7z59+owYMmRIwZtvvtmqtnpjxowZ2q9fvxHDhg0rGDZsWMH69evr04dvv/rc6nUg6ORXrU1YJlEomAjxClj+4jHvYlnJDq6f+i492rVk6nVjyM3ReP0i0nRVVlZGevxNmzbV++7qz3/+c7tVq1blrF69uuiBBx5Yc8stt/Q5XN1HHnlk1bJly5YuW7Zsac+ePY/qJOuT/H8JLDSzqWY2DXgP+MXRHESSqGch5HY/5gF/Ptmyh2semker7EweuWEMndu0SHKAIiIN5+yzzx44fPjw/EGDBg3/1a9+1bm6vFWrVifcdNNNvYYOHVowZ86cNvfdd1/nfv36jTjuuOPyr7jiir7XXHNNH4BLL72035VXXtln5MiRw3r16nXcCy+8kPvFL36x34ABA4Zfeuml/ar3d+WVV/YZMWJE/qBBg4Z/+9vf7gGwZcuWjH79+o1YtGhRC4CLLrqo/69//evONULkxhtv7DNu3LghDzzwQMc9e/YcsWPV9OnT21955ZVbYrEYZ5111u4dO3ZkrlmzJul3aPXp7f+wmc0ExoZFd7h7SbIDkXqKxYKm//emQfkuaNGm3ptu3FnG1VPmUl4Z589fPZleHWptTRIROWq3P7Oo9/KSnUn9R2VIt9w9/33ZyLVHqvP444+v7tq1a9WuXbvshBNOKLjqqqu2devWrWrv3r2xsWPH7v7jH/+4bvXq1VnXX399//fee29p+/bt46eccsqQ4cOH763eR2lpaebChQuXPfHEE+2vuOKKQS+//PKy0aNH7z3++OPz33rrrZannHLK3nvvvXd9165dqyorKznllFOGzp07t+XYsWP33nfffZ9MmjSp/y233LJh+/btmbfddtvmmjFOnz794zfeeKPV5MmTO//iF7/oceaZZ5Z+9atf3XzyySfvrVm3uLg4q1+/fvuqf3fv3n3fmjVrsvr27VtRs+6NN97YLxaLcdFFF227++67i2Ox+vfbqldNdy9x9+nhR4k/agUToLLsqMb631FWwaQp77JxRzkPX3cSQ7rmpjBAEZGGcffdd3cdOnRowejRo/NLSkqylixZkgOQkZHBtddeuw3gjTfeaD127NidXbt2rWrRooVfcskl2xL38fnPf357LBbjxBNP3NOpU6eKMWPG7M3IyGDIkCF7P/rooxYA06ZN61hQUJBfUFBQsGLFipxFixblAFxyySU78vPz937ve9/rO3Xq1NWHi/Ozn/3snkcfffSTDz/8cMmgQYPKTz/99Py77rrrmIdRfeqpp1YtX7586dtvv73srbfeavP73//+qMZiP6oOApIm+pwMXY+DGd+FvKHQ88QjVi+rqOLGafNZuXEnD046iRP7qMuGiCRXXXfoqfDCCy/kvvbaa7nz589flpubGx8zZszQvXv3xgCys7PjmZn1S3E5OTkOwQVDdnb2/rcXYrEYlZWVtmzZsuzf/va3XRcsWPBBXl5e1aWXXtqvrKwsBlBVVcXy5ctzcnJy4lu2bMkcOHDgIXfoABUVFTz99NPtHn744c5r1qzJuf322z+96aabttSs171794rVq1fvf6OuuLg4u7a7/v79+1cAdOjQIf6lL31p67x581oDh+zvcPRuV2MUy4Ar/xwM9PP4ZbBp+WGrVlbF+foTC3l39VZ+ffkoTh+S14CBioikzvbt2zPatWtXlZubG1+4cGHOokWLap17/NRTT909d+7c3E2bNmVUVFQwffr0o7oD2rZtW0bLli3jHTt2rFq7dm3mq6++un+q05/85CddhwwZUjZ16tRV119/fb/y8vJDnunfddddXfv373/cX/7ylw7f/e53N6xYsWLJz3/+85LaOulNmDBh++OPP94pHo8zZ86c1rm5uVU1k39FRQXFxcWZAOXl5TZjxox2I0aMOOQRwpHUeVlkZrUNJbfT3Wu9upEG0rY7XP0cTDkPHr0EbngR2h08Hn887tzxl8X844MN/HTicCaM7BFRsCIiyXfppZeWTp48OW/AgAHDBwwYUDZy5MjdtdXr379/xbe//e3iwsLC/Hbt2lUOGjSorF27dlX1Pc7JJ5+8d8SIEXsGDhw4onv37vtGjx69C2DRokUtHn300c4LFiz4oEOHDvFnnnlm55133tn9vvvu+zRx+1GjRu15//33l3Ts2DFe17Euv/zy0r///e/t+vbtO6Jly5bxBx98cHX1umHDhhUsW7Zs6d69e2Nnn3324IqKCovH4/bZz352x3e+851N9T0fAHM/8vgMZrYa6A1sAwxoD5QAG4Cb3H3B0RwwaoWFhT5//vyow0ie4kUw9cLgDYDrZ+0f9tfd+cWMD/jjGx/zrbMH862zh0QcqIg0Zma2wN0LE8sWLVq0euTIkYd0cEtHpaWlsXbt2sUrKio477zzBl177bWbr7nmmu1Rx5VKixYt6jxy5Mh+ta2rT7P/bOACd+/s7p2A84EXgFuA3x9uIzObYmYbzawooewuM1tvZv8KPxckrPu+ma00sw/N7LyE8vFh2UozuzOhvL+ZzQ3LnzKz5jnqYPeR8OU/wbbVwSOA8l0A/OG1VfzxjY+ZdHJfvnnW4GhjFBGJ2O23395j2LBhBUOGDBnep0+f8quuuqpJJ/661Kc3xDh3v6n6h7u/ZGa/cvf/MLMjvSQ+Ffgt8EiN8vvc/VeJBWZWAFwBDAd6AP8ws+pb1d8B5wDrgHfN7Hl3XwrcHe7rSTP7A3AD8EA9zqfp6XcqfHEqPHUVPHUVTw/+FXfP+pAJI3vwo4uGa7x+EWn2Jk+evC7qGNJJfe78i5FrH5cAABvtSURBVM3sDjPrG36+B2wwswyCaQNr5e6vA1vrGcdE4El3L3f3j4GVwJjws9LdV7n7PuBJYKIF2exM4Jlw+2nAxfU8VtM07AKYcD+seoVWM27ljMEd+dUXRxKLKfGLiMjB6pP8vwL0Ap4LP33Csgzg8mM45tfN7P3wsUB1j8ueQOJrIuvCssOVdwK2u3tljfJamdnNZjbfzOZv2nRUfSIalbfanscvq67kwox3+GPnJ8nOUOIXEZFD1Zn83X2zu3/D3U8IP193903uvs/dVx7l8R4ABhJMDFQM/PoYYj5q7j7Z3QvdvTAvr2m+6rZ4XSk3TZvPyx2/RNnYb5C1cCq8olGYRUTkUPV51W8I8F2gX2J9dz/zaA/m7hsS9vtHgo6DAOsJ3iio1iss4zDlW4D2ZpYZ3v0n1m92Ptq0i0kPz6N9q2weuX4sOW1Pg33b4fV7oFUnGPfVqEMUEZE0Up8Of38G/gA8CNT7vcjamFl3dy8Of14CVL8J8DzwhJndS9DhbzAwj+DVwsFm1p8guV8BfMXd3cxeAS4j6AcwCTi2mW4aueLSvVzz0DwMeOzGsXRrlxOsuPB/YO82mHVH8Prf8cfyhEZERBpSPB7n+uuv7/3yyy+3y8nJiU+ZMmX1qaeeuqdmvTFjxgzduHFjVk5OThxgzpw5y49mZr/6JP9Kdz/qXvRm9ifgDKCzma0DfgScYWajAAdWA/8B4O5LzOxpYClQCdzq7lXhfr4OvEjQx2CKuy8JD3EH8KSZ/QxYCDx0tDE2dtt27+Oah+ZRureCJ28eR//OCYNbZWTCpQ8Fr/899zXIaQ9Dzo0uWBGRiFRWVlLfoX4b0qZNmzLy8vIOuqlOnNL3lVdeaX3LLbf0ef/995fVtv0jjzyy6rTTTjvkwqA+6tPh729mdouZdTezjtWfujZy9y+7e3d3z3L3Xu7+kLtf7e7Hufvx7j4hoRUAd/+5uw9096HuPjOhfIa7DwnX/TyhfJW7j3H3Qe7+RXcvP+qzb8R2l1dy3dR3WbN1D3+8ppARPdsdWikrB654AroOh6evgU/eafhARURSqDFM6Zto/fr1mf/5n//ZdfDgwcMffvjhQ3Jp2kzpS9CkDnB7QpkDA5IdjNSPu3PrE+/x/rrtPHDVaE4eeITJnHLawpV/CYYBfuJyuG5mcDEgIpJMz93am41LkztPeJeCPVz8u0Y/pW9VVRXPPvts2wcffLDzihUrWl566aVbZ82atby2SYDSZkpfd+9fy0eJP0JLPt3Bqx9u4o7xwzhveLe6N2iTB9c8B1mt4NEvBKMBiog0AY1hSt9zzjln0K233trvxhtv3LxixYol99xzT/HhZv+rr5RN6WtmZ7r7y2b2hdrWu/tfjzZYSY6ZRcVkxIzLC3vXXbla+z5w9bMwZTw8cjHc8BK06ZK6IEWkeanjDj0VGsuUvvfcc8+63//+93m33XZbn+eee27HTTfdtPn000+v9Vl9Okzpe3r4fVEtnwvrewBJLndn5uISxg3oSIfWRzmdQZd8uPIZ2LUBHvsClJWmJkgRkQbQWKb0LSwsLJsyZcraDz/8cMnpp5++8wc/+EHPIUOGFPz1r39tW7Nu5FP6uvuPwu/rjmaHklrLN+xi1ebdXHdq/2PbQe+T4EuPwhNXwJ++DFf9BbJaJjdIEZEG0Fim9K2Wk5PjN91007abbrpp2/Lly7M3bNhwSA5Opyl9WwCXcuggPz85mgOli8Y+pe///GM5v5mzgrk/OIsuuTnHvqPFz8BfboSh58PljwavBoqIHIam9G18/t0pfacTTLxTCexO+EgEZhWVcFLfjv9e4gc47jK44L/hwxnwt/8DdVwEiog0ZprS92D1ud3r5e7jUx6J1OnjzbtZVrKT/7ywIDk7HHMT7NkCr/5XMArguT9Lzn5FRNKMpvQ9WH2S/1tmdpy7L055NHJEM4uCMZHGj6jH6331dfodwQXAW/dDq85w6reSt28REUlL9Un+pwLXmtnHQDnBePvu7senNDI5xMzFJYzs3Z4e7ZPYQc8Mxt8Ne7bCP34UtACceE3y9i8iTVk8Ho9bLBbTc8M0E4/HDYgfbn19kv/5yQtHjtXarXtYvL6U758/LPk7j8Xg4geCiYD+9k1o2QHyL0r+cUSkqSnatGlTQV5eXqkuANJHPB63TZs2tePA5HmHONIgP23dfQewMxXBydF5cUkJAOeP6J6aA2RmB68APjIRnrk+eAWw/2mpOZaINAmVlZU3lpSUPFhSUjKC+nUgl4YRB4oqKytvPFyFI935P0EwmM8CgrH8Ewcu0Nj+DWxmUQkF3dvSp1Nyh84+SHZr+MrT8PAF8KevwLUvQI9RqTueiDRqo0eP3ghMiDoOOXqHvVJz9wvD7/7uPkBj+0enpLSMBWu2cX4yO/odTquOcPVfg6b/xy6FzStTf0wREWlQ9WqmMbMOZjbGzE6r/qQ6MDlgf5P/cQ2Q/AHa9gjmAQB49GLYUetgVSIi0kjVmfzN7EbgdeBF4Mfh912pDUsSzSwqZnCXNgzqkttwB+08KHjuv3c7PHpJ8DaAiIg0CfW58/8mcBKwxt0/B5wANOuRkRrSll3lzPt4a8M0+dfUYxR8+QnYugqeuBz2aWBHEZGmoD7Jv8zdyyAY59/dlwFDUxuWVHtp6QbiDuNT1cu/Lv1Pg8umwPoF8NTVULkvmjhERCRp6pP815lZe+A5YLaZTQfWpDYsqTazqIS+nVqR370Bm/xryr8ILvoNfDQHnv0PXQCIiDRydQ7y4+6XhIt3mdkrQDtgVkqjEgBK91Tw1srN3PDZ/pgdMkV0wzrxmgOjAK5+M/g9+lpo3zvauERE5Kgd8c7fzDLMbFn1b3d/zd2fd3fd+jWA2R9soDLuXBBVk39Np34r6ATY80R449fwm+PhiStgxWyIH3YUSRERSTNHvPN39yoz+9DM+rj7Jw0VlARmFRXTs31Lju/VLupQDhh0dvDZ/gksmArvPQLLZ0L7vlB4HZxwNbTuHHWUIiJyBPV55t8BWGJmc8zs+epPqgNr7naVV/L6is2cN7xb9E3+tWnfB876T/j20qBDYLve8I+74N58eOYGWPMWuIb6FhFJR/WZ2Of/pjwKOcTLyzayrzLecAP7HKvMbBhxafDZuAzmT4FFf4KiZ6BLARReD8d/CXLaRh2piIiE6nPnf0H4rH//B7igro3MbIqZbTSzooSyjmY228xWhN8dwnIzs/81s5Vm9r6ZnZiwzaSw/gozm5RQPtrMFofb/K+l5e3xsZu5uJi83BaM7tMh6lDqr8swuOAeuG0ZTLgfMrJhxnfh18OC2QKL3486QhERAczraJo1s/fc/cQaZe+7+/F1bHcasAt4xN1HhGX3AFvd/ZdmdifQwd3vMLMLgG8QXFSMBX7j7mPNrCMwHygkmExoATDa3beZ2Tzg/wBzgRnA/7r7zLpOuLCw0OfPn19XtUjt3VfFiT+dzWWje/HTi0dEHc6/Z/0CeHdK0BJQWQa9ToLCG2D4xZDVMuroRNJPvCr4f6WiDCr3HvpdWQ4Ve8M6Nb7r2u7aGZBRnwbfQ5nZAncvTPLZSkSONKXv14BbgAFmlnjLlgv8s64du/vrZtavRvFE4IxweRrwKnBHWP6IB1ci75hZezPrHtad7e5bw5hmA+PN7FWgrbu/E5Y/AlwM1Jn8G4PXlm9kb0VVNKP6JVvP0cHnvJ/Bv/4UPBZ47qvw4vdh1JXBY4FOA6OOUhoz9yCxVZYlfJcd/LuirPb18SrwOHhVsB+P1yiLh2XxA8vV5fvreY26R9pnHOKVYRw1E3SYxOMVx/5nkZENmS0hKwcyw09WTljWMtj3MSZ/aVrqmtJ3JvBfwJ0J5Turk/Ex6OruxeFyCdA1XO4JrE2oty4sO1L5ulrKa2VmNwM3A/Tp0+cYQ284M4tK6NAqizH9O0YdSvK07AAn3wLjvgYfvw7zH4K5f4C3fwsDPhdcBAy9QP8wpaN4HKr2BYmjqiJIXlUV4e/KhPLw9/66lYfZpvr3vgPLByXvvQf/rth75PWVZck/Z8sAiwWfWPVyBpjVKIsdqBuL1VKWsE1iWWYLyGmXkJhrfGe2CJJ1Zs7hvw9K7OHvWEby/yykSTrsv7TuXgqUAl9OxYHd3c2sQbqDu/tkYDIEzf4NccxjVV5ZxZwPNvL547qTmVGvSRcbFzMYcHrw2VkSvCq4YCo8fTXkdocTJ8HoScHMgpIaVZVQ+kkwZ8PWj2HLR+HyKijbfmiy9gYYw8FiB5JeZk5C8gt/Z7eCVp0OXr8/+SX8zsw5zPrqssRjZEMss0aijgV/R0WauIa+zdpgZt3dvThs1t8Ylq8HEoeK6xWWrefAY4Lq8lfD8l611G/03lyxmV3llYxP917+yZDbDU7/Hpz6HVjxYvBI4LW74fX/hqHnw0k3QP8zgjsqOTpVFcFYDFtXHZzct66C7WuC5F4tqzV0HBB02GzVGTKyIJYVtMLEssLfmQnlWQcvH7SuepvsI6xL+J2RHSxX3yGLSINo6OT/PDAJ+GX4PT2h/Otm9iRBh7/S8ALhReAX1W8FAOcC33f3rWa2w8zGEXT4uwa4vyFPJFVmFpWQm5PJZwY2o4FyMjJh2OeDz9aPYcHDsPAxWPZCkJRGXwcnXAWtmtBjkGSo3Bck8prJfetHsH1t8My5WnYudOwP3Y4LOlt2HHDg06arEq9IM1Nnb/9j3rHZnwju2jsDG4AfEUwO9DTQh2ByoMvDRG7Ab4HxwB7gOnefH+7neuAH4W5/7u4Ph+WFwFSgJUHfhG94PU4mnXv7V1TFKfzZPzhrWBfu/dKoqMOJVmU5LJ0O7z4Ea98JyrJaBc9JW7QNvnPaHrx80Lpa6rXIbXxJrqIMtq0+NLlvXQWl6w5ukm/RDjoNODixdxwYfLfu3PjOXdKKevs3LSlL/ukqnZP/Gys2cfVD85h89WjOHd4Mmv3rq6QoGEJ47/bgmXTZDijfAWWlwXJZafC7qo4pJywWXADktAsS5SEXDG0PXc5uHfTUjleGn3DZqw7+fdD6Wsq8tnq1fYefvVuDVpDSdQRvuYZadjg0sVd/WnVUgpeUUfJvWtS1Oo3MWFxCq+wMThuSF3Uo6aXbiOBTl4qyAxcCZTuCC4XEi4TalrevhfLScLudqe3cZhnBs+1YZvhJXM4MO52Fyzltoe9nDiT2TgOgQ389+hCRpFDyTxNVcWf20hI+N6wLOVl6XeeYZIW9u3O71l23NvE47NuVcPFQChV7Dk7QByXtmt+HSeTVdXRXLiJpQsk/Tby7eiubd+1Ln+l7m6NYLHwU0BbSaCJFEZFk0ztUaWJWUQktMmOcMVRN/iIiklpK/mkgHndmFZVw+pA8WrdQY4yIiKSWkn8aWLh2OyU7ytJ/+l4REWkSlPzTwKyiYrIyjDOHHWNHNRERkaOg5B8xd2dmUQmnDupMu5ZZUYcjIiLNgJJ/xJZ8uoN12/Zyvnr5i4hIA1Hyj9jMomIyYsY5BWryFxGRhqHkHyF3Z+biEsYN6EiH1tlRhyMiIs2Ekn+Elm/YxarNuxmvJn8REWlASv4RmllUjBmcN1xN/iIi0nCU/CM0q6iEk/p2pEtuTtShiIhIM6LkH5FVm3axrGQn40doYB8REWlYSv4RmVlUAqDkLyIiDU7JPyKzikoY2bs9Pdq3jDoUERFpZpT8I7B26x4Wry/lAt31i4hIBJT8I/DikqDJX6P6iYhIFJT8IzBjcTEF3dvSp1OrqEMREZFmSMm/gZWUlvHeJ9s5X03+IiISESX/Bra/yf84JX8REYmGkn8Dm1lUzOAubRjUJTfqUEREpJlS8m9Am3eVM+/jrWryFxGRSEWS/M1stZktNrN/mdn8sKyjmc02sxXhd4ew3Mzsf81spZm9b2YnJuxnUlh/hZlNiuJcjsZLSzYQdzSRj4iIRCrKO//Pufsody8Mf98JzHH3wcCc8DfA+cDg8HMz8AAEFwvAj4CxwBjgR9UXDOlqZlExfTu1Ir+7mvxFRCQ66dTsPxGYFi5PAy5OKH/EA+8A7c2sO3AeMNvdt7r7NmA2ML6hg66v0j0VvP3RFsaP6IaZRR2OiIg0Y1ElfwdeMrMFZnZzWNbV3YvD5RKgep7bnsDahG3XhWWHKz+Emd1sZvPNbP6mTZuSdQ5HZfYHG6iMOxeoyV9ERCKWGdFxT3X39WbWBZhtZssSV7q7m5kn62DuPhmYDFBYWJi0/R6NWUXF9GzfkuN7tYvi8CIiIvtFcufv7uvD743AswTP7DeEzfmE3xvD6uuB3gmb9wrLDleednaWVfD68s2cN1xN/iIiEr0GT/5m1trMcquXgXOBIuB5oLrH/iRgerj8PHBN2Ot/HFAaPh54ETjXzDqEHf3ODcvSzsvLNrKvKq6BfUREJC1E0ezfFXg2vAPOBJ5w91lm9i7wtJndAKwBLg/rzwAuAFYCe4DrANx9q5n9FHg3rPcTd9/acKdRf7OKSsjLbcHoPmn9MoKIiDQTDZ783X0VMLKW8i3AWbWUO3DrYfY1BZiS7BiTae++Kl79cBOXje5FLKYmfxERiV46verXJL22fCN7K6o0qp+IiKQNJf8Um7G4hA6tshjTv2PUoYiIiABK/ilVXlnFy8s2cm5BNzIz9EctIiLpQRkphd5csZld5ZWMVy9/ERFJI0r+KTSzqITcnEw+M7Bz1KGIiIjsp+SfIhVVcWYv3cA5+V3JztQfs4iIpA9lpRR5+6MtlO6tYLx6+YuISJpR8k+RmUUltMrO4LQheVGHIiIichAl/xSoijuzl5Zw5rAu5GRlRB2OiIjIQZT8U+Dd1VvZvGsf52v6XhERSUNK/ikwc3ExLTJjnDFUTf4iIpJ+lPyTLB53Zi0p4fQhebRuEcW8SSIiIkem5J9kC9duZ8OOck3fKyIiaUvJP8lmFRWTlWGcld816lBERERqpeSfRO7OzKISTh3UmbY5WVGHIyIiUisl/yQqWr+Dddv2qpe/iIikNSX/JJpZVExGzDinQE3+IiKSvpT8k8TdmVVUwrgBHenQOjvqcERERA5LyT9Jlm/YxarNu9XkLyIiaU/JP0lmFhVjBucOV5O/iIikNyX/JJm5uIST+nakS25O1KGIiIgckZJ/EqzatIsPN+zU9L0iItIoKPknwcyiEgAlfxERaRSU/JNgVlEJo3q3p0f7llGHIiIiUqdGn/zNbLyZfWhmK83szoY+/tqte1i8vpTzddcvIiKNRKNO/maWAfwOOB8oAL5sZgUNGcOssMlfr/iJiEhj0djnnB0DrHT3VQBm9iQwEVia7APdMPVdVm/ZfUj5xh3lFHRvS59OrZJ9SBERkZRo7Mm/J7A24fc6YGzNSmZ2M3AzQJ8+fY7pQP07tyYnOyP44QfKh3WDywp7HdM+RUREotDYk3+9uPtkYDJAYWGh11G9Vj+8sEGfJoiIiKRMo37mD6wHeif87hWWiYiIyGE09uT/LjDYzPqbWTZwBfB8xDGJiIiktUbd7O/ulWb2deBFIAOY4u5LIg5LREQkrTXq5A/g7jOAGVHHISIi0lg09mZ/EREROUpK/iIiIs2Mkr+IiEgzo+QvIiLSzJj7MY1502iZ2SZgzTFu3hnYnMRw0l1zOt/mdK6g823KUnWufd09LwX7lQg0u+T/7zCz+e5eGHUcDaU5nW9zOlfQ+TZlzelc5dip2V9ERKSZUfIXERFpZpT8j87kqANoYM3pfJvTuYLOtylrTucqx0jP/EVERJoZ3fmLiIg0M0r+IiIizYySfz2Y2Xgz+9DMVprZnVHHk2xmNsXMNppZUUJZRzObbWYrwu8OUcaYTGbW28xeMbOlZrbEzL4Zlje5czazHDObZ2aLwnP9cVje38zmhn+nnwqnxG4yzCzDzBaa2Qvh7yZ7vma22swWm9m/zGx+WNbk/i5Lcin518HMMoDfAecDBcCXzawg2qiSbiowvkbZncAcdx8MzAl/NxWVwG3uXgCMA24N/5s2xXMuB85095HAKGC8mY0D7gbuc/dBwDbghghjTIVvAh8k/G7q5/s5dx+V8H5/U/y7LEmk5F+3McBKd1/l7vuAJ4GJEceUVO7+OrC1RvFEYFq4PA24uEGDSiF3L3b398LlnQRJoidN8Jw9sCv8mRV+HDgTeCYsbxLnWs3MegGfBx4MfxtN+HwPo8n9XZbkUvKvW09gbcLvdWFZU9fV3YvD5RKga5TBpIqZ9QNOAObSRM85bAL/F7ARmA18BGx398qwSlP7O/0/wPeAePi7E037fB14ycwWmNnNYVmT/LssyZMZdQCS/tzdzazJvRNqZm2AvwDfcvcdwQ1ioCmds7tXAaPMrD3wLDAs4pBSxswuBDa6+wIzOyPqeBrIqe6+3sy6ALPNbFniyqb0d1mSR3f+dVsP9E743Sssa+o2mFl3gPB7Y8TxJJWZZREk/sfd/a9hcZM+Z3ffDrwCnAy0N7Pqi/+m9Hf6M8AEM1tN8IjuTOA3NN3zxd3Xh98bCS7uxtDE/y7Lv0/Jv27vAoPD3sLZwBXA8xHH1BCeByaFy5OA6RHGklThM+CHgA/c/d6EVU3unM0sL7zjx8xaAucQ9HF4BbgsrNYkzhXA3b/v7r3cvR/B/6svu/uVNNHzNbPWZpZbvQycCxTRBP8uS3JphL96MLMLCJ4jZgBT3P3nEYeUVGb2J+AMgqlANwA/Ap4Dngb6EEyBfLm71+wU2CiZ2anAG8BiDjwX/gHBc/8mdc5mdjxBh68Mgov9p939J2Y2gODOuCOwELjK3cujizT5wmb/77r7hU31fMPzejb8mQk84e4/N7NONLG/y5JcSv4iIiLNjJr9RUREmhklfxERkWZGyV9ERKSZUfIXERFpZpT8RUREmhklf5E0Z2ZnVM9OJyKSDEr+IiIizYySv0iSmNlVZjYvnFf9/4UT6uwys/vMbImZzTGzvLDuKDN7x8zeN7Nnq+dbN7NBZvYPM1tkZu+Z2cBw923M7BkzW2Zmj4ejFGJmvzSzpeF+fhXRqYtII6PkL5IEZpYPfAn4jLuPAqqAK4HWwHx3Hw68RjB6IsAjwB3ufjzBSIPV5Y8Dv3P3kcApQPXMbCcA3wIKgAHAZ8JR3C4Bhof7+Vlqz1JEmgolf5HkOAsYDbwbTp97FkGSjgNPhXUeA041s3ZAe3d/LSyfBpwWjtHe092fBXD3MnffE9aZ5+7r3D0O/AvoB5QCZcBDZvYFoLquiMgRKfmLJIcB09x9VPgZ6u531VLvWMfTThyHvgrIDOenHwM8A1wIzDrGfYtIM6PkL5Icc4DLwjnVMbOOZtaX4P+x6tnkvgK86e6lwDYz+2xYfjXwmrvvBNaZ2cXhPlqYWavDHdDM2gDt3H0G8G1gZCpOTESansy6q4hIXdx9qZn9EHjJzGJABXArsBsYE67bSNAvAIJpVv8QJvdVwHVh+dXA/zOzn4T7+OIRDpsLTDezHIKWh+8k+bREpInSrH4iKWRmu9y9TdRxiIgkUrO/iIhIM6M7fxERkWZGd/4iIiLNjJK/iIhIM6PkLyIi0swo+YuIiDQzSv4iIiLNzP8PdPSjlFA03dMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "outputId": "504e823a-6079-4cd8-c08e-23e53a177bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "df_test"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>342</td>\n",
              "      <td>2947</td>\n",
              "      <td>775</td>\n",
              "      <td>5936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>548</td>\n",
              "      <td>3559</td>\n",
              "      <td>677</td>\n",
              "      <td>5216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>5633</td>\n",
              "      <td>4367</td>\n",
              "      <td>4410</td>\n",
              "      <td>2532</td>\n",
              "      <td>777</td>\n",
              "      <td>2281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>5751</td>\n",
              "      <td>4249</td>\n",
              "      <td>5610</td>\n",
              "      <td>2124</td>\n",
              "      <td>582</td>\n",
              "      <td>1684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>6930</td>\n",
              "      <td>3070</td>\n",
              "      <td>6352</td>\n",
              "      <td>1967</td>\n",
              "      <td>430</td>\n",
              "      <td>1251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>6720</td>\n",
              "      <td>3280</td>\n",
              "      <td>6710</td>\n",
              "      <td>1911</td>\n",
              "      <td>464</td>\n",
              "      <td>915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>6664</td>\n",
              "      <td>3336</td>\n",
              "      <td>6940</td>\n",
              "      <td>1725</td>\n",
              "      <td>438</td>\n",
              "      <td>897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>6596</td>\n",
              "      <td>3404</td>\n",
              "      <td>7024</td>\n",
              "      <td>1757</td>\n",
              "      <td>402</td>\n",
              "      <td>817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>6484</td>\n",
              "      <td>3516</td>\n",
              "      <td>7165</td>\n",
              "      <td>1695</td>\n",
              "      <td>422</td>\n",
              "      <td>718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>6415</td>\n",
              "      <td>3585</td>\n",
              "      <td>7153</td>\n",
              "      <td>1666</td>\n",
              "      <td>382</td>\n",
              "      <td>799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>6235</td>\n",
              "      <td>3765</td>\n",
              "      <td>7127</td>\n",
              "      <td>1760</td>\n",
              "      <td>435</td>\n",
              "      <td>678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>51</td>\n",
              "      <td>6154</td>\n",
              "      <td>3846</td>\n",
              "      <td>7190</td>\n",
              "      <td>1704</td>\n",
              "      <td>404</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0             0  ...                    775                    5936\n",
              "1        1             0  ...                    677                    5216\n",
              "2        6          5633  ...                    777                    2281\n",
              "3       11          5751  ...                    582                    1684\n",
              "4       16          6930  ...                    430                    1251\n",
              "5       21          6720  ...                    464                     915\n",
              "6       26          6664  ...                    438                     897\n",
              "7       31          6596  ...                    402                     817\n",
              "8       36          6484  ...                    422                     718\n",
              "9       41          6415  ...                    382                     799\n",
              "10      46          6235  ...                    435                     678\n",
              "11      51          6154  ...                    404                     702\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "outputId": "b63cbc1b-cf95-4dfe-e275-a7007097ab85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAEWCAYAAABoup70AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dfnZk8IWSCyQxIWFVBUKLhAharVLmpbu9jRqnVrR6fTsdaO7fymdewytZtddaTWrbVVa2t1WqetRbGgVgUVFUQTWQRkSSAEyJ7cz++PcwIXSCCJSc5N7vv5eNzHued7zj3nczT6Oef7/Z7v19wdERERSR2xqAMQERGR/qXkLyIikmKU/EVERFKMkr+IiEiKUfIXERFJMUr+IiIiKUbJXyTJmNl4M9tjZmlRxyIig5OSv6QEM7vEzF4xs3oz22Jmt5pZYQ+O056Y2z9uZnUJ6/N6cMx1ZnZ6+7q7v+XuQ9y9rbvH6isHxigiA5uSvwx6ZnYtcBNwHVAAnAhMAB4zs8zuHCshMQ9x9yFh8YyEsiW9GryISB9Q8pdBzcyGAv8FfM7d/+zuLe6+Dvg4UApcGO53g5k9YGb3mNluM1tpZrO6ea4sM/uemb1lZlvN7H/MLCfcNtzM/mhmO81sh5ktMbOYmf0SGA/8b1hz8CUzKw1rFNLD3y42s6+b2VNhbH81s+EJ573IzNab2XYz+89DPaWb2fvNbFV4nE1m9sWEbR80s5fCGJ82s2PD8oNi7M4/FxFJPkr+MtidDGQDv08sdPc9wKPAGQnF5wD3AYXAI8BPu3mubwNTgOOAScAY4KvhtmuBjUAJMAL4ShCGfwp4Czg7rDn4TifH/ifg08ARQCbwRQAzmwrcAlwAjCKo2RhziBh/AXzG3fOB6cDj4XGOB+4APgMMA24DHjGzrG7EKCIDhJK/DHbDgWp3b+1g2+Zwe7ul7v5o2Nb+S2BGV09iZgZcCVzj7jvcfTfwLeD8cJcWguQ8Iax9WOLdm1jjTnd/w90bgAcIbjAAPgr8r7svdfdmgpuNQx23BZhqZkPdvcbdXwjLrwRuc/dn3b3N3e8GmgiaSERkkFHyl8GuGhjeXoV+gFHh9nZbEr7XA9md/K4jJUAusDysNt8J/DksB/guUAn81czWmNn13bmIDmJr728wGtjQvsHd64HthzjOecD7gfVm9qSZnRSWTwCubY89jH9ceHwRGWSU/GWwe4bgCfYjiYVmNgR4H7Col85TDTQA09y9MPwUtHcKdPfd7n6tu5cTNC98wcxOC3/7TqbW3AyMbV8J+xgM62xnd3/e3c8laD74A0EtAgQ3EN9MiL3Q3XPd/Te9EKOIJBklfxnU3L2WoMPfT8zsLDPLMLNSgqS3kaB6vzfOEwd+DtxsZkcAmNkYMzsz/P5BM5sUNg/UAm1APPz5VqC8h6d+EDjbzE4O31y4AbCOdjSzTDO7wMwK3L0F2JUQw8+Bz5rZHAvkmdkHzCy/F2IUkSSj5C+DXthB7SvA9wgS3rMET7qnuXtTL57q3wmq9v9hZruAvwFHhtsmh+t7CGojbnH3J8Jt/w38v7C6/Yt0g7uvBD5H0FFxc3j8bQS1HR35FLAujO+zBB0FcfdlwBUEnRxrwuu4JOF3PY5RRJKPda/PkYgks7A5Yycw2d3XRh2PiCQnPfmLDHBmdraZ5ZpZHkHtxivAumijEpFkpuQvMvCdC7wdfiYD53fzNUIRSTGq9hcREUkxevIXERFJMV0dwGTQGD58uJeWlkYdhojIgLF8+fJqdy85/J4yUKRc8i8tLWXZsmVRhyEiMmCY2fqoY5DepWp/ERGRFKPkLyIikmKU/EVERFKMkr+IiEiKUfIXERFJMX2W/M3sDjPbZmavJpQVm9ljZlYRLovCcjOzH5tZpZm9bGYnJPzm4nD/CjO7OKF8ppm9Ev7mx+FsaSIiInIYffnkfxdw1gFl1wOL3H0ywTzq14fl7yMYlnQycCVwKwQ3C8DXgDnAbOBr7TcM4T5XJPzuwHOJiIhIB/rsPX93/3s4b3qic4H54fe7gcUE06CeC9wTjkf+DzMrNLNR4b6PufsOADN7DDjLzBYDQ939H2H5PcCHgP/rq+vhye9AW8vB5RaD4z4JRaV9dmoREZHe1N+D/Ixw983h9y3AiPD7GIL51dttDMsOVb6xg/IOmdmVBDUKjB8/vmeRL/0htNR3sMFh99twzk96dlwREZF+FtkIf+7uZtYvswq5+0JgIcCsWbN6ds7/eLvj8vsugDcXgzuo24GIiAwA/d3bf2tYnU+43BaWbwLGJew3Niw7VPnYDsr738QFUPsW7FgTyelFRES6q7+T/yNAe4/9i4GHE8ovCnv9nwjUhs0DfwHea2ZFYUe/9wJ/CbftMrMTw17+FyUcq3+VLwiWaxZHcnoREZHu6stX/X4DPAMcaWYbzewy4NvAGWZWAZwergM8CqwBKoGfA1cBhB39vg48H35ubO/8F+5ze/ibN+nLzn6HUlwOBeNhzRORnF5ERKS7+rK3/yc72XRaB/s6cHUnx7kDuKOD8mXA9HcSY68wg/JT4bVHIN4GsbSoIxIRETkkjfDXGyYugMZaePulqCMRERE5LCX/3lA2P1iueTzSMERERLpCyb835A2DkcfCmiejjkREROSwlPx7y8QF8NY/oLku6khEREQOScm/t5TPh3gLrH866khEREQOScm/t4w/CdKy9L6/iIgkPSX/3pKRAxNOgjf1vr+IiCQ3Jf/eVD4ftq2E3VujjkRERKRTSv69qX2o37Xq9S8iIslLyb83jTwWcopV9S8iIklNyb83xWLBUL9rFgdT/IqIiCQhJf/eVr4Adr8N1W9EHYmIiEiHlPx7W/n8YKmqfxERSVJK/r2taEIwza/e9xcRkSSl5N8XyufDuqXQ1hJ1JCIiIgdR8u8L5QugeTdsWh51JCIiIgdR8u8LZfPAYmr3FxGRpKTk3xdyimD08bBGyV9ERJKPkn9fKV8AG5dB466oIxEREdmPkn9fKZ8P3hZ0/BMREUkiSv59ZdxsyMjVK38iIpJ0lPz7SnoWTDhF7f4iIpJ0lPz7Uvn8YJjf2k1RRyIiIrKXkn9fmhhO8auqfxERSSJK/n3piKmQd4Sq/kVEJKko+fcls6DqX1P8iohIElHy72sTF0BdFWxdGXUkIiIigJJ/3yufHyxV9S8iIklCyb+vDR0Nw49Upz8REUkaSv79oXw+rHsKWpuijkRERETJv19MXACtDbDhuagjERERiSb5m9k1ZrbSzF41s9+YWbaZlZnZs2ZWaWb3m1lmuG9WuF4Zbi9NOM6Xw/LXzezMKK6lS0rngqWp3V9ERJJCvyd/MxsD/Cswy92nA2nA+cBNwM3uPgmoAS4Lf3IZUBOW3xzuh5lNDX83DTgLuMXM0vrzWrosKx/GvgveVPIXEZHoRVXtnw7kmFk6kAtsBt4DPBhuvxv4UPj93HCdcPtpZmZh+X3u3uTua4FKYHY/xd99ExfA2y9CQ03UkYiISIrr9+Tv7puA7wFvEST9WmA5sNPdW8PdNgJjwu9jgA3hb1vD/Ycllnfwm/2Y2ZVmtszMllVVVfXuBXVV+XzAYe3fozm/iIhIKIpq/yKCp/YyYDSQR1Bt32fcfaG7z3L3WSUlJX15qs6NmQmZ+XrlT0REIhdFtf/pwFp3r3L3FuD3wClAYdgMADAWaJ8KbxMwDiDcXgBsTyzv4DfJJy0j6Pindn8REYlYFMn/LeBEM8sN2+5PA1YBTwAfDfe5GHg4/P5IuE64/XF397D8/PBtgDJgMpDc79JNXAA1a6FmXdSRiIhICouizf9Zgo57LwCvhDEsBP4d+IKZVRK06f8i/MkvgGFh+ReA68PjrAQeILhx+DNwtbu39eOldF+5pvgVEZHomafYbHOzZs3yZcuWRXNyd/jBVBg3Gz5+9+H3FxFJAma23N1nRR2H9B6N8NefzIKq/7VPQjwedTQiIpKilPz7W/n84F3/LSuijkRERFKUkn9/K58fLNXrX0REIqLk39+GHAEjpqvTn4iIREbJPwrl8+Gtf0BLQ9SRiIhIClLyj0L5AmhrgvVPRx2JiIikICX/KEw4CdIyVfUvIiKRUPKPQmYejJsDa9TpT0RE+p+Sf1TK58OWV6CuOupIREQkxSj5R0VD/YqISESU/KMy+jjILlDVv4iI9Dsl/6jE0qDs3fDm4mDMfxERkX6i5B+l8gWwayNsfzPqSEREJIUo+UdpYnu7v6r+RUSk/6RHHUBKKyqDwvFBp7/ZV0QdTVJyd3717Fv84cVNjCzIpnRYLhOK85gwLJfS4XkckZ+FmUUdpojIgKLkHyWzoOp/5UPQ1gpp+teRqKG5ja889AoPvbiJI0fks3JPLX95dQut8X19JLIzYkwozmP8sNzgxmBYeGMwLI9RBdmkp6lyS0TkQMo2USufDy/cDW+/COPeFXU0SWNddR2f/dVyXt+6m2vPmMLVCyYRixmtbXHe3tnIuu11rN9Rz/rqcLm9jr+/UUVTa3zvMdJjxrjiXCYMy2VC8b4bgwnD8hhXnENWelqEVygiEh0l/6iVzwcsaPdX8gfgb6u2cs0DL5EWM+769GxOnVKyd1t6Wozxw3IZPyz3oN/F48623U3BjcH2OtZvr2f99nrWba9j2boa9jS17t3XDEYX5IQ3A8ENQemwXMaHTQp5WfpPQ0QGL/0fLmq5xTBqRtDuf+qXoo4mUm1x54d/e4OfPF7J9DFDufWCmYwrPjjJdyYWM0YWZDOyIJsTy4ftt83d2VHXvLeWYF11PW/tCG4M/rJyKzvqmvfbf/iQLEqH5TKiIJucjDSyM2Lhct+n4/IYOZlpZKen7V1mZ8bITIupb4KIJA0l/2RQPh+e+Rk07YGsIVFHE4maumb+9b4XWVJRzcdnjeXGc6eTndF71fJmxrAhWQwbksUJ44sO2r6rsYW3EmoK2msOXtu8i6aWOA0tbTS2tNHQ0tajYRnM2HuTkJORRlbCTUP7TUTiTUVOZhq5ez/p+y3zstLIyUgPlplp5GWmk5ORRiymmwsR6Rol/2QwcQE89UNY/xRMOTPqaPrdyxt38s+/eoGq3U18+yPHcP7s8f0ew9DsDKaPKWD6mIJD7ufuNLfFaWyO09jaRkNz275lS5zGhJuExoSbhsTyhvC3jeFv65tb2VG3/2/bf98dORnhzUJWeEOQmbhMIycznbz2G4qs9ANuLILvQ3PSKcrNpDA3Q30iRAYxJf9kMO5ESM8Oqv5TLPnf//xb/OfDKykZksVvP3sSM8YVRh3SIZkZWelpZKWnUUBGn56rLe40tLRR39RKfXMbdc3Bsr55X1l9c/u2NhqaW8NlG3VNrTS0BMvqPU377Vvf3Nal8+dlplGYm0lRXkZ4Q5BJUW7G3mX7TUJRbmbwPS+D/Kx0NW+IDABK/skgIxvGnwRvps5gP40tbdzwyErue34D8yYP50fnH09xXmbUYSWVtJgxJCudIb3c+TAedxpb26hrCm8U2m8gmlrZ1dhCTX0LO+uag2V9MzX1wfcNO+qpqW9hV2NLp00f6TGjMOEGYf8bhQPK8oKbh8KcTDLT9UqmSH9S8k8WExfAY1+F3Vsgf2TU0fSpjTX1/POvXuCVTbX8y4JJXHPGFNLUXt1vYjELq/t79p9/W9ypbWihpr45uDmoa//esvdGof2mYcOOel7ZGJQnvoZ5oMz0WNgkkb63WSIvoTkisZ/DvvU08rLa+0Gk710PmjiC/fR3JdIxJf9kUT4/WK5ZDDPOjzCQvvXkG1V8/r4XaWtzfn7RLM6YOiLqkKSb0mJGcV5mt2tqGprbwpuDA24U6pqpC5sl6praaGgJlvXNrWyubdlbK9HedBHvRofL7IzYfv0fcrP23VDkZ6UzsiCb0YU5jCnKYUxh8NFrnpIKDvtXbmaTgf8GpgLZ7eXuXt6HcaWeEcdA7rCg6n8QJv943PnZE5X84G9vcOSIfG69cCZlw/OiDkv6UU5mGjmZOYwuzOnxMdydptZ4ws1A2GzRlNj/oTXs97B/WX3Tvm076hrY3djC1l2NtLTtfzdRkJPBmMIgzrFFOYwuzGZMYW6wLMpheF6W3qyQAa8rt7h3Al8DbgYWAJ9GEwL1vlgMyk4Nnvzdg3fDBonahha+cP9LLFq9jQ8dN5pvfeSYHlc5S2ozs72vRA47/O6H1RZ3qvc0sbGmgbd3NrBpZwObwu8ba+p5du12dje27vebzLQYowuDGoPRhftqDMYUBeujCrJ79TVVkb7Qlf8D57j7IjMzd18P3GBmy4Gv9nFsqWfiAlj5e6haDUccHXU0veK1zbv47K+Ws6mmgf86ZxoXnTRBvcElaaTFjBFDsxkxNJuZEw4e/wGCMSDeTrwp2NnA2zsb2VRTz9KKarbubjyoA+TwIVlhU0L23lqE9uWogmzyszPUyVEi1ZXk32RmMaDCzP4F2ASk5kg0fa28fYrfxYMi+T/04ka+/PtXKMjJ4P7PnMjMCcVRhyTSbUOzMxg6MoOjRg7tcHtza5wttY1BrcHOhn03CrUNrN68m0Wvbeuws2NmWowh2el73+gYkpW+b72z8vB7flY6eeH3PHVslB7oSvL/PJAL/CvwdYKq/4v6MqiUVTgOiicG7f4n/nPU0fRYc2ucb/xpFfc8s545ZcX85J+O54j87MP/UGQAykzvfL4JCPopbK9r3ntTsHVXI3uaWtnd1EpdUyt7GluD9cZWtu1uZE3VvvVDvSGRKC9846H9xqD9piBxvTgvi8vmlvXmpcsA1pXkX+ruzwN7CNr7MbOPAc/29KRmVgjcDkwHHLgUeB24HygF1gEfd/caC+qIfwS8H6gHLnH3F8LjXAz8v/Cw33D3u3saU9KYuABe+g20NkP6wHvvfXNtA1fd+wIvvrWTK99dzpfOPFLT6kpKMzOGD8li+JAsjh3bvUGsWtqCzo27wxuEuvCmYU/ievh9T2Mre5r3baveXR+Uh5/hQzKV/GWvriT/LwO/7UJZd/wI+LO7f9TMMglqFr4CLHL3b5vZ9cD1wL8D7wMmh585wK3AHDMrJuiIOIvgBmK5mT3i7jXvIK7olc+H52+HTctgwslRR9Mtz7y5nc/95gUamtu45YITeP8xo6IOSWRAy0iLURgOkPROtL8lIdKu0+RvZu8jeNoeY2Y/Ttg0FGjt+FeHZ2YFwLuBSwDcvRloNrNzgfnhbncDiwmS/7nAPe7uwD/MrNDMRoX7PubuO8LjPgacBfymp7ElhdJ5YLGg6n+AJH935+dL1nDTn1+ndFgu9115IpOOyI86LBEJtb8lIdLuUPWxbwPLgEZgecLnEeCdDEBfBlQBd5rZi2Z2u5nlASPcfXO4zxagffSXMcCGhN9vDMs6Kz+ImV1pZsvMbFlVVdU7CL0f5BTCmJlBp78BYE9TK1fd+wLfenQ1Z04bwcP/MleJX0QkyXX65O/uK4AVZvZrd2/p5XOeAHzO3Z81sx8RVPEnntvNrAcTp3bM3RcCCwFmzZrVa8ftM+XzYckPoLEWsg89y1yUKrft5jO/XM667fX8x/uP5vJ5ZXqNT0RkAOhKT6xSM3vQzFaZ2Zr2zzs450Zgo7u3dxh8kOBmYGtYnU+43BZu3wSMS/j92LCss/KBr3wBeBusXRJ1JJ3648tvc85Pn6K2oYVfXTaHK95drsQvIjJAdCX530nQya6V4DW/e4Bf9fSE7r4F2GBmR4ZFpwGrCJoTLg7LLgYeDr8/AlxkgROB2rB54C/Ae82syMyKgPeGZQPf2HdBRl5SVv23tsX5xh9X8S+/fpGjRubzx8/N46SJvTHWmoiI9JeoRvj7HHBv2NN/DfuGDH7AzC4D1gMfD/d9lKDjYSXBq36fBnD3HWb2deD5cL8b2zv/DXjpmVB6CqyJZopfd2dPUys1dS3sqG+mpq6ZHXXBhCx/WbmF59fVcPFJE/iPD0zVKGUiKWr58uVHpKent7+yrf8RJJc48Gpra+vlM2fO3NbRDpGM8OfuLxG8oneg0zrY14GrOznOHcAd7ySWpFW+ACr+Cjs3BIP/vAMNzW0HJfEddeF6OCXrfuX1zQdNdtIuPyudmz8xgw8fP/YdxSQiA1t6evrtI0eOPLqkpKQmFoslf1+qFBKPx62qqmrqli1bbgfO6Wifnozw9x72Vc9LXymfHyzXLIYTPnXQ5re217Oxpj4hqbfsl7wTk3tjS8fv95pBUW4mRbkZFOdlMr44l+PGFVKUl0lxbmawzMugKDeYvrUoL5P8rHS17YsIwHQl/uQUi8W8pKSkdsuWLdM72+ewyT8c3Q8SRviTfnDE0TBkRFD1f0DyX1tdx3u+v/igyUSGZqfvTdIjh2Zz9KihwXruwUm8ODeToTkZGhNcRHoqpsSfvMJ/N502xxxqkJ//JRg5r0Pu3mFVgvQSs+Dpv3IRxOPBlL+hxa9vwx1u+9RMyobnUZSbSWFuBhkaRldEZMCKx+Nceuml4x5//PGC7Ozs+B133LFu7ty59QfuN3v27CO3bduWkZ2dHQdYtGjRG2PGjOnW4HuHevL/Xrj8CDCSfT38Pwls7c5JpIfKF8DL98PWV2HUsXuLl1ZUM2FYLmdOGxlhcCIiya+1tZX09K60cPeNqqqqtJKSkrau7Pvb3/62YM2aNdnr1q179Yknnsi76qqrxr/88surO9r3nnvuWfPud7/7oBuDrur0UdHdn3T3J4FT3P0T7v6/4eefgHk9PaF0Q/n8YJnQ67+lLc4/1mxn7qThkYQkIpIsTj/99InTpk07etKkSdO+973v7f2fYm5u7vFXXHHF2COPPHLqokWLhtx8883DS0tLpx9zzDFHn3/++RMuuuii8QDnnXde6QUXXDB+xowZR40dO/aYP/7xj/kf+9jHSsvLy6edd955pe3Hu+CCC8ZPnz796EmTJk275pprRgNs3749rbS0dPqKFSuyAM4+++yy73//+wf9j/nyyy8ff+KJJ0659dZbi+vr6w/Zzvrwww8XXnDBBdtjsRinnXZa3a5du9LXr1+f0Uv/uPbTlduhPDMrd/c1AGZWBuT1RTBygKGjoOSooNPfKZ8H4KUNO6lrbmPeZCV/EUkO1z24YtwbW3Z3PKdxD00ZmV//3Y/O2HCofe699951I0aMaNuzZ48df/zxUy+88MKakSNHtjU0NMTmzJlT9/Of/3zjunXrMi699NKyF154YVVhYWH85JNPnjJt2rSG9mPU1tamv/jii6t//etfF55//vmTHn/88dUzZ85sOPbYY49++umnc04++eSGH/zgB5tGjBjR1traysknn3zks88+mzNnzpyGm2+++a2LL7647Kqrrtq6c+fO9Guvvbb6wBgffvjhtUuWLMlduHDh8G9961uj3/Oe99R+9rOfrT7ppJMaDtx38+bNGaWlpc3t66NGjWpev359xoQJEw4aZffyyy8vjcVinH322TU33XTT5lise82+Xdn7GmCxmS02syeBJwjeAJD+UL4A1j8NLY1AUOUfMzipXMlfRFLbTTfdNOLII4+cOnPmzKO3bNmSsXLlymyAtLQ0LrnkkhqAJUuW5M2ZM2f3iBEj2rKysvzDH/7wfjO/fuADH9gZi8U44YQT6ocNG9Yye/bshrS0NKZMmdLw5ptvZgHcfffdxVOnTj166tSpUysqKrJXrFiRDfDhD39419FHH93wpS99acJdd921rrM4582bV//LX/7yrddff33lpEmTmk499dSjb7jhhhGd7X84999//5o33nhj1TPPPLP66aefHnLLLbd0e6S1rvT2/7OZTQaOCotWu3tTd08kPVQ+H569FTY8C+WnsrSymmPGFlKQ2yc1QSIi3Xa4J/S+8Mc//jH/ySefzF+2bNnq/Pz8+OzZs49saGiIAWRmZsa72s6fnZ3tENwwZGZm7u3kHovFaG1ttdWrV2f+9Kc/HbF8+fLXSkpK2s4777zSxsbGGEBbWxtvvPFGdnZ2dnz79u3pEydO7HAenJaWFh544IGCO++8c/j69euzr7vuurevuOKK7QfuN2rUqJZ169btnb958+bNmR099ZeVlbUAFBUVxT/xiU/seO655/KAg453KF2qJ3D3JndfEX6U+PtT6SkQS4c1T7CrsYWXNuxk7iQNpysiqW3nzp1pBQUFbfn5+fEXX3wxe8WKFR02R8+dO7fu2Wefza+qqkpraWnh4YcfLurOeWpqatJycnLixcXFbRs2bEhfvHjx3tnWbrzxxhFTpkxpvOuuu9ZceumlpU1NTQe16d9www0jysrKjvnd735X9MUvfnFrRUXFym9+85tbOuqdf8455+y89957h8XjcRYtWpSXn5/fdmDyb2lpYfPmzekATU1N9uijjxZMnz79oCaEw4muC6R0TVY+jJ0Nbz7Bs6P/mba4M3dSSdRRiYhE6rzzzqtduHBhSXl5+bTy8vLGGTNm1HW0X1lZWcs111yzedasWUcXFBS0Tpo0qbGgoKBLve8BTjrppIbp06fXT5w4cfqoUaOaZ86cuQdgxYoVWb/85S+HL1++/LWioqL4gw8+uPv6668fdfPNN7+d+Pvjjjuu/uWXX15ZXFzc8WhrCT7+8Y/X/ulPfyqYMGHC9JycnPjtt9++rn3bUUcdNXX16tWrGhoaYqeffvrklpYWi8fjNm/evF1f+MIXuj1XvfmBI8UMcrNmzfJly5ZFHUb3LL4JFv833z7mT9z90m5e+toZZKWnRR2ViKQIM1vu7vsNyb5ixYp1M2bMOKiDWzKqra2NFRQUxFtaWjjzzDMnXXLJJdUXXXTRzqjj6msrVqwYPmPGjNKOth222t/MTujgM9HMVGvQXyYuAJymisXMLitW4hcR6Ybrrrtu9FFHHTV1ypQp08aPH9904YUXDvrEfzhdSeC3ACcALwNGMIPTSqDAzP7Z3f/ah/EJwOgTiGfmM3nPMsac8smooxERGVAWLly4MeoYkk1XOvy9DRzv7rPcfSZwPME0vGcA3+nL4CSUls7moncxN/YKp2hwHxEReYe6kvynuPvK9hV3XwUc1T7oj/SPZ5jO+FgVR2UOiCY2ERFJYl1J/ivN7FYzOzX83AKsMrMsoMN3GqV3xePOb6onAmBrF0cbjA8Jk8UAABm1SURBVIiIDHhdSf6XAJXAv4WfNWFZC7CgrwKTfV7fupvldcOpzx4Jbz5x+B+IiIgcQldG+GsAvh9+DrSn1yOSgyytqAYMJs6HN/8M8TaIqce/iMhg0p9T+nblVb9TzOwxM3vDzNa0f7pzEnlnllRWM7Ekj9yjzoDGnbD5pahDEhEZEFpbu5UT+01VVdVBT3CJU/reeuut66+66qrxnf3+nnvuWbN69epVq1evXtXdxA9dq/b/BfADYC7wroSP9IOm1jaeW7udeZNLoOzUoFBV/yIiA2JK30SbNm1K/+pXvzpi8uTJ0+68887iA7cn25S+te7+f31xcjm85etraGyJM3fScBhSAiOOCab4ffcXow5NRCTwh6vHsW1Vr07pyxFT6/nQzwb8lL5tbW089NBDQ2+//fbhFRUVOeedd96OP//5z290NAlQsk3p+4SZfdfMTkoc5a9bZ5Eee6qymrSYMac8vEmcOD+Y4a/5oGYgEZGUMhCm9D3jjDMmXX311aWXX355dUVFxcrvfOc7mzub/a+r+mVKX2BOuEwc19mB93T3ZNJ9SyuqOX5cIfnZYc1P+Xx4+ifw1tMw6fQoQxMRCRzmCb0vDJQpfb/zne9svOWWW0quvfba8X/4wx92XXHFFdWnnnpqh09vSTWlr7sv6OCjxN8PautbeHlT7f6j+o0/GdIy1e4vIiltoEzpO2vWrMY77rhjw+uvv77y1FNP3f2Vr3xlzJQpU6b+/ve/H3rgvkkxpa+ZXejuvzKzL3S03d1/0N2TSfc8/WY17jBvckLyz8yFcXOCdn8RkRQ1UKb0bZedne1XXHFFzRVXXFHzxhtvZG7duvWg/JsUU/qa2Wfc/TYz+1oHm93db+zuyZLBQJrS9ysPvcIjL73Ni189g4y0hEqaJd+HRTfC1c9DcRmk9UlnUBERQFP6DlSHmtK30yd/d78t/Po3d38qcZuZndJ74Ulnnqqs5sTy4v0TP8DE04Lk/7PwjcvsAsgddsCnuIOy8JNdCN3sGSoiMlBdd911o//+978PbWpqslNPPXWXpvTtWoe/nxBM6Xu4MulFG3bUs357PZ8+ufTgjaOPgwt+BzVroX4H1G/f99n1Nmx5FeqrobWx44NbDHKKunizEJZnDQU7qDlLRCTpaUrfgx2qzf8k4GSg5IB2/6GAxpbtY0srg9q0uZM7GTNichd6+jfX739jcOCNQvtnx1rYuCz4Hu/kDZRYenATUDAWzvo2jJvdwysTEZGoHerJPxMYEu6Tn1C+C/hoXwYlwSt+I4dmM7FkSM8PkpkbfArHdW1/d2jafegbhTVPwJ3vh7P+G951uWoDRFJXPB6PWywW67jjmEQqHo8bEO9s+6Ha/J8EnjSzu9x9PYCZxYAh7r6r1yOVvdrizlNvVnP60SOw/kyuZpA9NPgUl3W8T0MN/P4z8OgXYePz8MEfBjcYIpJqXq2qqppaUlJSqxuA5BKPx62qqqoAeLWzfbrS5v/fZvZZoA14HhhqZj9y9+++k+DMLA1YBmxy9w+aWRlwHzAMWA58yt2bzSwLuAeYSTCIwSfcfV14jC8Dl4Wx/au7/+WdxJQsVr29i531LcGQvskmpwg+eV/wxsET34StK+Hj98CwiVFHJiL9qLW19fItW7bcvmXLlul0bbRY6T9x4NXW1tbLO9uhK8l/qrvvMrMLgP8DridIzu8o+QOfB14j6EMAcBNws7vfZ2b/Q5DUbw2XNe4+yczOD/f7hJlNBc4HpgGjgb+Z2RR37/L7m8lqSWXwyuYpyZj8IXhT4NTrYMzx8LvLYeEC+MhtcOT7oo5MRPrJzJkztwHnRB2H9ExX7tYyzCwD+BDwiLu3EAzv22NmNhb4AHB7uG4EwwU/GO5yd3g+gHPDdcLtp4X7nwvc5+5N7r4WqAQGRS+0pyqrOWpkPiX5WVGHcmiTTocrn4TiUvjN+fD4NyA+4O+9REQGva4k/9uAdUAe8Hczm0DQ6e+d+CHwJfZ1RhgG7HT39jmJNwJjwu9jgA0A4fbacP+95R38Zj9mdqWZLTOzZVVV3R4IqV81trTx/Lqa5Kzy70jRBLj0r3D8hfD378K9Hw06C4qISNLqytj+P3b3Me7+fg+sBxb09IRm9kFgm7sv7+kxusvdF7r7LHefVVJS0l+n7ZHn1u6guTXe+St+ySgjG879GZz9Y1i3FG47FTa9EHVUIiLSicO2+ZvZCOBbwGh3f1/Y1n4S8IsenvMU4Bwzez+QTdDm/yOg0MzSw6f7scCmcP9NwDhgo5mlAwUEHf/ay9sl/mbAeqqymsy0GLPLiqMOpftmXgwjp8MDF8MdZ8EHvgcnXBR1VCKDQ2szNO+Bpl3BK7lNu6HpgPXmPeH3XQnbw22ZeXDFoqivQpJEVzr83QXcCfxHuP4GcD89TP7u/mXgywBmNh/4ortfYGa/JRg/4D7gYuDh8CePhOvPhNsfd3c3s0eAX5vZDwg6/E0GnutJTMlkSUU1J0woJDeza9NRJp0xM4N+AL+7DB75XPA64Pu+G9QOiKSypj1QuwF2bz4geSck6+aEZN20a//k3dbUtfNk5kNWPmQNCZf5kD8Chozo2+uTAeVQI/y1P4UPd/cHwtfqcPdWM+uLXl3/DtxnZt8AXmTfzcUvgF+aWSWwg6CHP+6+0sweAFYBrcDVA72n//Y9TazavIvrzjwy6lDembxhcOHv4IlvwZLvweaX4RO/hMLxUUcm0jficairCpJ77QbYuQFqN+6/3niI4eTTc/ZP1pn5MHTswUk8ayhkJq4f8MnI07wd0iWHerx8jmD8/jozG0bYw9/MTiTodPeOuftiYHH4fQ0d9NZ390bgY538/pvAN3sjlmTw1JvbgSR+xa87Ymlw2n8GNQEPfQZuezecd3vwhoDIQNPalJDMNyYk97fC5UZoa97/N1kFwXDYheOCabgLxgXrQ0cHk3ElJnHNzCn97FDJv31ouS8QVL1PNLOngBI0vG+fWFpRxdDsdI4ZUxB1KL3nqPfDlYvh/k/Brz4KC/4D5l2rpxNJHu7ByJX7Jfe39l/fs/WAHxnkjwqS+ejj4eizw+Q+Lkj2BWODBC+SpA6V/BMn9HkIeJTghqAJOB14uY9jSynuztKKak6eOJy02CAbL3/YRLj8Mfjff4MnvgGblsGHb4Ocwqgjk4GurSVoJ2+uh+a68HsdtNTv+96c+L0OWsJl4y7YtSlI7s179j9uenaQwAvGweT3Bk1W7esFY2HoGEjPjOaaRXrBoZJ/GsHEPgdmIg3k3gfWVtfxdm0jVy0YBFX+HcnMg48shLHvgr98GRbOh0/8Kng7QFJLS0MwFkTDjnBZk5CcD0jkLfX7knZH2w6saj8USwvazzPygr/HrCEwbBKUL9j3tN7+9J43XJNWyaB2qOS/2d1v7LdIUtxT4RS+8wbS+/3dZQZzroRRM+C3F8Ptp8PZP4IZn4g6MumJeDzoxNZQc0Ay72hZs2+9teHQx7VY0B6emQcZucEyc0gwpXTh+AO2hd8P/GR0UJaWqYQuEupKm7/0gyUV1YwtymF8cQpUrIyfE7wO+OCl8NCVweuAZ35L1ahRaW3eVxXesLOD5N1Jcm/cCd7JjKEWCyaByimG3OLgqXrUsUFZbvG+8pzioCwrP0zkuUGVu5K0SJ86VPI/rd+iSHGtbXGeeXM7H5wxqn+n8I1S/gi46GFYdAM8/RPY/BJ87G4o6HCEZnEPepwntlm3t2XvVzV+4PbE9cR96vdVo8dbDn3ujNwwWYfJvOCY/ZP3fsswuWcVqFOnSBLrNPm7uwZo7ycvb6pld1Pr4HjFrzvS0uG934Axs+Dhq2HhqfDRO6FsXtSRdU9bS5BMWxqDZWtjwnpDUM3dkvjp4j57k3SYsLszjEUsfV91+d6q8zwYckRCdXnuAVXkuUEP9ZzioIq9PZln5PTdPzsRicQAHUZucFlaUY0ZnDIxxZJ/u2kfgiOOhvsvhHvOhdNvgJM/1/9Vv811ULMOdqwJP2thz7aDE/Pe9TCB93RsqfScYOTDjLCqOyM3WE/PhpzRB7Rrd5CoD0zsifurCUVEDkHJPwksraxm+ugCivJS+H/YJUfCFY8HNQCP/WfQD+BDtwRtwb2poSZI6jvWQM3afd93rIU9W/bfN6c4eJe7vR16yIiOk3VGTpjIEz6HW0/LUrW4iERGyT9idU2tvPhWDZfNLY86lOhl5Qft/s/8FB77Gvz8PcHrgCXdGO7YPRhmtT2htz/F14TfG2r23z9/FBSVBSMPFpeFn/KgTOMQiMggpeQfsWfXbqelzQf3K37dYRZU+Y86Dh78NCxcAOf+FKZ/ZN8+8Tjsfnv/6vn2Zc3a/QdssVjw3nZxGUz7cJDUi8vDBF8aPNWLiKQYJf+ILa3YTlZ6jJkTiqIOJbmUzYPP/D2YHvjBT8PKh4IBXXasDdrlE2c4S8uEwglBQi+du//Te+F4tX+LiBxAyT9iSyurmF1WTHZGWtShJJ+ho+GSPwV9AFbcF7wrXjIFppy57+m9uCwYajWmf34iIl2l5B+hbbsaeWPrHs47YWzUoSSv9Ex4303BR0REeoW6G0doaTikb8q93y8iIpFS8o/Q0opqivMymTpqaNShiIhIClHyj4i7s7SympMnDiM22KbwFRGRpKbkH5GKbXvYtrtJr/iJiEi/U/KPyNKKoL1/7uSSiCMREZFUo+QfkaWV1ZQNz2NMoSZNERGR/qXkH4Hm1jj/WLOduerlLyIiEVDyj8BLG3ZS39ymV/xERCQSSv4RWFpRRczgpInDog5FRERSkJJ/BJZWVjNjXCEFORlRhyIiIilIyb+f7WpsYcXGWrX3i4hIZJT8+9kzb26nLe5K/iIiEhkl/372VGU1uZlpHD9eU/iKiEg0lPz72dKKauaUFZOZrn/0IiISDWWgfrRpZwNrqus0qp+IiERKyb8fPdU+pK/a+0VEJEL9nvzNbJyZPWFmq8xspZl9PiwvNrPHzKwiXBaF5WZmPzazSjN72cxOSDjWxeH+FWZ2cX9fS3ctqazmiPwspowYEnUoIiKSwqJ48m8FrnX3qcCJwNVmNhW4Hljk7pOBReE6wPuAyeHnSuBWCG4WgK8Bc4DZwNfabxiSUTzuPF1ZzdxJwzHTFL4iIhKdfk/+7r7Z3V8Iv+8GXgPGAOcCd4e73Q18KPx+LnCPB/4BFJrZKOBM4DF33+HuNcBjwFn9eCnd8tqWXWyva9aQviIiErlI2/zNrBQ4HngWGOHum8NNW4AR4fcxwIaEn20Myzor7+g8V5rZMjNbVlVV1Wvxd8dTle1T+Cr5i4hItCJL/mY2BPgd8G/uvitxm7s74L11Lndf6O6z3H1WSUk0Pe2XVFQz+YghjBiaHcn5RURE2kWS/M0sgyDx3+vuvw+Lt4bV+YTLbWH5JmBcws/HhmWdlSedxpY2nlu7Q0/9IiKSFKLo7W/AL4DX3P0HCZseAdp77F8MPJxQflHY6/9EoDZsHvgL8F4zKwo7+r03LEs6L6yvoak1zjwlfxERSQLpEZzzFOBTwCtm9lJY9hXg28ADZnYZsB74eLjtUeD9QCVQD3wawN13mNnXgefD/W509x39cwnds6SymvSYMbtMU/iKiEj0+j35u/tSoLN33U7rYH8Hru7kWHcAd/RedH3jqcpqThhfxJCsKO61RERE9qcR/vpYTV0zr2yq1St+IiKSNJT8+9gza7bjrlf8REQkeSj597ElFdXkZ6UzY2xB1KGIiIgASv59bmllFSdOHEZ6mv5Ri4hIclBG6kNvba9nw44GveInIiJJRcm/Dy2pDIYSVmc/ERFJJkr+feipympGF2RTPjwv6lBERET2UvLvI21x56nK7cydrCl8RUQkuSj595FXN9VS29CiKn8REUk6Sv59ZGk4ha+Sv4iIJBsl/z6ytKKao0cNZfiQrKhDERER2Y+Sfx9oaG5j+foaveInIiJJScm/Dzy3bgfNbXHmqspfRESSkJJ/H1haUUVmWox3lRZHHYqIiMhBlPz7wNLK7cwqLSInMy3qUERERA6i5N/LqnY38drmXerlLyIiSUvJv5c9/Wbwip86+4mISLJS8u9lSyuqKczNYNpoTeErIiLJScm/F7k7SyurOXniMNJiGtJXRESSk5J/L1pTXcfm2kbmTiqJOhQREZFOKfn3oqUVau8XEZHkp+Tfi5ZWVjO+OJdxxblRhyIiItIpJf9e0toW5x9vBlP4ioiIJDMl/16yYuNOdje1akhfERFJekr+vWRpxXbM4OSJw6IORURE5JCU/HvJ0soqjh1TQGFuZtShiIiIHJKSfy/Y09TKi2/t1JC+IiIyICj594Jn12ynNe7q7CciIgOCkn8vWFJRTXZGjJkTiqIORURE5LCU/HvBU5XVzC4bRla6pvAVEZHkp+T/Dm2pbaRi2x7mqb1fREQGiAGf/M3sLDN73cwqzez6/j7/U5XBkL7q7CciIgPFgE7+ZpYG/Ax4HzAV+KSZTe3PGJZWVjN8SCZHjczvz9OKiIj0WHrUAbxDs4FKd18DYGb3AecCq3r7RGf/ZCmNLW0Hla/fUc9Z00YS0xS+IiIyQAz05D8G2JCwvhGYc+BOZnYlcCXA+PHje3SiiSV5NLfFDyqfMjKfy+aW9eiYIiIiURjoyb9L3H0hsBBg1qxZ3pNj/PD843s1JhERkagM6DZ/YBMwLmF9bFgmIiIinRjoyf95YLKZlZlZJnA+8EjEMYmIiCS1AV3t7+6tZvYvwF+ANOAOd18ZcVgiIiJJbUAnfwB3fxR4NOo4REREBoqBXu0vIiIi3aTkLyIikmKU/EVERFKMkr+IiEiKMfcejXkzYJlZFbC+hz8fDlT3YjjJLJWuFXS9g10qXW9fXOsEdy/p5WNKhFIu+b8TZrbM3WdFHUd/SKVrBV3vYJdK15tK1yo9p2p/ERGRFKPkLyIikmKU/LtnYdQB9KNUulbQ9Q52qXS9qXSt0kNq8xcREUkxevIXERFJMUr+IiIiKUbJvwvM7Cwze93MKs3s+qjj6W1mdoeZbTOzVxPKis3sMTOrCJdFUcbYm8xsnJk9YWarzGylmX0+LB9012xm2Wb2nJmtCK/1v8LyMjN7Nvybvj+cEnvQMLM0M3vRzP4Yrg/a6zWzdWb2ipm9ZGbLwrJB97csvUvJ/zDMLA34GfA+YCrwSTObGm1Uve4u4KwDyq4HFrn7ZGBRuD5YtALXuvtU4ETg6vDf6WC85ibgPe4+AzgOOMvMTgRuAm5290lADXBZhDH2hc8DryWsD/brXeDuxyW83z8Y/5alFyn5H95soNLd17h7M3AfcG7EMfUqd/87sOOA4nOBu8PvdwMf6teg+pC7b3b3F8LvuwmSxBgG4TV7YE+4mhF+HHgP8GBYPiiutZ2ZjQU+ANwerhuD+Ho7Mej+lqV3Kfkf3hhgQ8L6xrBssBvh7pvD71uAEVEG01fMrBQ4HniWQXrNYRX4S8A24DHgTWCnu7eGuwy2v+kfAl8C4uH6MAb39TrwVzNbbmZXhmWD8m9Zek961AFI8nN3N7NB906omQ0Bfgf8m7vvCh4QA4Ppmt29DTjOzAqBh4CjIg6pz5jZB4Ft7r7czOZHHU8/mevum8zsCOAxM1uduHEw/S1L79GT/+FtAsYlrI8Nywa7rWY2CiBcbos4nl5lZhkEif9ed/99WDyor9nddwJPACcBhWbWfvM/mP6mTwHOMbN1BE107wF+xOC9Xtx9U7jcRnBzN5tB/rcs75yS/+E9D0wOewtnAucDj0QcU394BLg4/H4x8HCEsfSqsA34F8Br7v6DhE2D7prNrCR84sfMcoAzCPo4PAF8NNxtUFwrgLt/2d3HunspwX+rj7v7BQzS6zWzPDPLb/8OvBd4lUH4tyy9SyP8dYGZvZ+gHTENuMPdvxlxSL3KzH4DzCeYCnQr8DXgD8ADwHiCKZA/7u4HdgockMxsLrAEeIV97cJfIWj3H1TXbGbHEnT4SiO42X/A3W80s3KCJ+Ni4EXgQndvii7S3hdW+3/R3T84WK83vK6HwtV04Nfu/k0zG8Yg+1uW3qXkLyIikmJU7S8iIpJilPxFRERSjJK/iIhIilHyFxERSTFK/iIiIilGyV8kyZnZ/PbZ6UREeoOSv4iISIpR8hfpJWZ2oZk9F86rfls4oc4eM7vZzFaa2SIzKwn3Pc7M/mFmL5vZQ+3zrZvZJDP7m5mtMLMXzGxiePghZvagma02s3vDUQoxs2+b2arwON+L6NJFZIBR8hfpBWZ2NPAJ4BR3Pw5oAy4A8oBl7j4NeJJg9ESAe4B/d/djCUYabC+/F/iZu88ATgbaZ2Y7Hvg3YCpQDpwSjuL2YWBaeJxv9O1VishgoeQv0jtOA2YCz4fT555GkKTjwP3hPr8C5ppZAVDo7k+G5XcD7w7HaB/j7g8BuHuju9eH+zzn7hvdPQ68BJQCtUAj8Asz+wjQvq+IyCEp+Yv0DgPudvfjws+R7n5DB/v1dDztxHHo24D0cH762cCDwAeBP/fw2CKSYpT8RXrHIuCj4ZzqmFmxmU0g+G+sfTa5fwKWunstUGNm88LyTwFPuvtuYKOZfSg8RpaZ5XZ2QjMbAhS4+6PANcCMvrgwERl80g+/i4gcjruvMrP/B/zVzGJAC3A1UAfMDrdtI+gXAME0q/8TJvc1wKfD8k8Bt5nZjeExPnaI0+YDD5tZNkHNwxd6+bJEZJDSrH4ifcjM9rj7kKjjEBFJpGp/ERGRFKMnfxERkRSjJ38REZEUo+QvIiKSYpT8RUREUoySv4iISIpR8hcREUkx/x8yilL10/B5+QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLfaVcgE7pK",
        "outputId": "18bfc97f-5f4d-4007-e2f7-3a3eb009e2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29744\n",
            "total train set images 30000\n",
            "focus_true_pred_true 23451 =============> FTPT : 78 %\n",
            "focus_false_pred_true 6293 =============> FFPT : 20 %\n",
            "focus_true_pred_false 82 =============> FTPF : 0 %\n",
            "focus_false_pred_false 174 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  19606\n",
            "argmax_less_than_half ==================>  10394\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cSh5sGfFAlg",
        "outputId": "2e567be0-ce7f-4efb-eb07-77f045355c3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 88 %\n",
            "total correct 8877\n",
            "total train set images 10000\n",
            "focus_true_pred_true 7190 =============> FTPT : 71 %\n",
            "focus_false_pred_true 1687 =============> FFPT : 16 %\n",
            "focus_true_pred_false 400 =============> FTPF : 4 %\n",
            "focus_false_pred_false 723 =============> FFPF : 7 %\n",
            "argmax_more_than_half ==================>  6214\n",
            "argmax_less_than_half ==================>  3786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "outputId": "d34e7b64-5137-43b2-b30e-ad30f32eeab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "                                            correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29711\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "outputId": "9ca2ca87-f54c-423e-b5df-2adbd74feead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 88 %\n",
            "total correct 8840\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xu8I6TCE4r7"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}