{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "focus_random_classify_random_train_both_k_05_adam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjG64ra4aFu"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-7SARDZErK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acRFqJNrZErV",
        "outputId": "5b0335b9-92df-4695-e525-27432f58dae5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3BOnEFUZOLx"
      },
      "source": [
        "k = 0.5"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_JUhwCeZErk"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SadRzWBBZEsP"
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w"
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM"
      },
      "source": [
        "def init_weights(m,k=0.5):\n",
        "  if type(m) == nn.Linear:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)\n",
        "  if type(m) == nn.Conv2d:\n",
        "    torch.manual_seed(0)\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    m.weight.data = m.weight.data*k\n",
        "    m.bias.data.fill_(0.01 * k)\n",
        "    print(\"weights\"+\"*\"*20,m.weight)\n",
        "    print(\"bias\",m.bias)\n",
        "    print(k)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhjiW2hKZTCY",
        "outputId": "2832ae18-0bb8-4815-c09b-928ca6ed92b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "focus_net.apply(init_weights)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.1050,  0.1214,  0.0588],\n",
            "          [-0.1193,  0.0163,  0.0455],\n",
            "          [ 0.0215,  0.0241,  0.1083]],\n",
            "\n",
            "         [[ 0.0433,  0.0966, -0.0650],\n",
            "          [-0.1277,  0.1072, -0.0358],\n",
            "          [-0.0312,  0.0118, -0.0548]],\n",
            "\n",
            "         [[-0.0689, -0.0810,  0.0414],\n",
            "          [ 0.0412,  0.0663,  0.0657],\n",
            "          [-0.1363,  0.1377, -0.0697]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243,  0.1074,  0.0612],\n",
            "          [-0.0413,  0.1226,  0.0983],\n",
            "          [ 0.0922,  0.0167,  0.1221]],\n",
            "\n",
            "         [[ 0.0511,  0.1312, -0.0172],\n",
            "          [-0.0914, -0.0009, -0.0219],\n",
            "          [-0.0516, -0.0447,  0.1076]],\n",
            "\n",
            "         [[-0.1184,  0.0627,  0.1237],\n",
            "          [ 0.1283, -0.0161, -0.0057],\n",
            "          [ 0.0065, -0.0395,  0.0546]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024, -0.1245,  0.0225],\n",
            "          [ 0.1106,  0.0834, -0.0226],\n",
            "          [-0.1247, -0.0061, -0.1214]],\n",
            "\n",
            "         [[ 0.0866,  0.1358,  0.0561],\n",
            "          [-0.0469,  0.0484,  0.1072],\n",
            "          [-0.1322, -0.1119,  0.1240]],\n",
            "\n",
            "         [[ 0.0972,  0.0309, -0.0326],\n",
            "          [ 0.0429, -0.0177,  0.1361],\n",
            "          [-0.0201,  0.0622,  0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0303,  0.0592, -0.0878],\n",
            "          [ 0.0015, -0.0844,  0.0005],\n",
            "          [-0.0110, -0.1320,  0.0073]],\n",
            "\n",
            "         [[-0.0690, -0.0391, -0.1286],\n",
            "          [-0.1111, -0.0964,  0.0491],\n",
            "          [ 0.0080,  0.0899,  0.0564]],\n",
            "\n",
            "         [[ 0.1066, -0.0032,  0.1346],\n",
            "          [-0.0996, -0.0303,  0.0290],\n",
            "          [-0.1192, -0.0811,  0.0647]]],\n",
            "\n",
            "\n",
            "        [[[-0.0746,  0.0155,  0.0927],\n",
            "          [ 0.1275, -0.0648, -0.1212],\n",
            "          [-0.0438,  0.0703,  0.0093]],\n",
            "\n",
            "         [[ 0.0649, -0.1058, -0.1375],\n",
            "          [-0.0805,  0.0599, -0.0410],\n",
            "          [ 0.1259,  0.0705,  0.1220]],\n",
            "\n",
            "         [[ 0.0110,  0.0289,  0.0606],\n",
            "          [ 0.0577,  0.0234, -0.0851],\n",
            "          [ 0.0604, -0.0535,  0.0725]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0470, -0.0210,  0.1061],\n",
            "          [ 0.1273,  0.1034, -0.0953],\n",
            "          [ 0.1343, -0.0333,  0.0573]],\n",
            "\n",
            "         [[ 0.0107, -0.1018, -0.0632],\n",
            "          [-0.1064,  0.0825,  0.0589],\n",
            "          [ 0.1306, -0.1160, -0.0009]],\n",
            "\n",
            "         [[ 0.1033,  0.1369,  0.1329],\n",
            "          [-0.0583, -0.1006, -0.0515],\n",
            "          [ 0.0956, -0.0466,  0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0630, -0.1007, -0.0224],\n",
            "          [ 0.0597,  0.0746, -0.0809],\n",
            "          [ 0.1096, -0.0081,  0.0485]],\n",
            "\n",
            "         [[-0.0192,  0.0433, -0.0180],\n",
            "          [ 0.0555, -0.0442, -0.1342],\n",
            "          [ 0.0390, -0.0937, -0.1160]],\n",
            "\n",
            "         [[ 0.0635, -0.0448,  0.0776],\n",
            "          [-0.0472,  0.1219, -0.0217],\n",
            "          [ 0.0235,  0.1338, -0.1280]]],\n",
            "\n",
            "\n",
            "        [[[-0.1138,  0.0961,  0.0734],\n",
            "          [ 0.1227,  0.0692,  0.0687],\n",
            "          [ 0.0951, -0.0988, -0.1304]],\n",
            "\n",
            "         [[ 0.0414,  0.1211,  0.1038],\n",
            "          [ 0.0472,  0.0314,  0.1127],\n",
            "          [ 0.1249,  0.0592,  0.1128]],\n",
            "\n",
            "         [[-0.0023, -0.0187, -0.0323],\n",
            "          [ 0.0005, -0.0440,  0.1075],\n",
            "          [-0.0339, -0.0237,  0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1025, -0.0733,  0.0263],\n",
            "          [ 0.0634, -0.1255,  0.0807],\n",
            "          [-0.0945, -0.0226, -0.1057]],\n",
            "\n",
            "         [[-0.0354,  0.0731, -0.0700],\n",
            "          [-0.0865, -0.1230, -0.1273],\n",
            "          [-0.1034, -0.0091,  0.0499]],\n",
            "\n",
            "         [[-0.0941, -0.1289, -0.0261],\n",
            "          [-0.0112,  0.0301,  0.1376],\n",
            "          [ 0.0553, -0.1234, -0.0216]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1093, -0.0918,  0.0554],\n",
            "          [-0.0098,  0.0586, -0.0456],\n",
            "          [ 0.0957, -0.0791,  0.0954]],\n",
            "\n",
            "         [[ 0.0342, -0.0692, -0.0776],\n",
            "          [ 0.0679, -0.1333, -0.0824],\n",
            "          [ 0.0169,  0.0182,  0.0261]],\n",
            "\n",
            "         [[-0.0804, -0.0958,  0.0014],\n",
            "          [-0.0349,  0.1200, -0.1340],\n",
            "          [-0.0353, -0.0973,  0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0191,  0.0477, -0.0084],\n",
            "          [ 0.0818,  0.1183, -0.0276],\n",
            "          [-0.0286,  0.0132, -0.0614]],\n",
            "\n",
            "         [[ 0.0330,  0.0598,  0.1111],\n",
            "          [ 0.1165, -0.0417,  0.0480],\n",
            "          [-0.0908,  0.0554,  0.1349]],\n",
            "\n",
            "         [[-0.0483,  0.0873, -0.1318],\n",
            "          [ 0.0756,  0.0214,  0.1137],\n",
            "          [ 0.0039,  0.1094,  0.0119]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0383,  0.1257],\n",
            "          [-0.0961,  0.1246,  0.0706],\n",
            "          [ 0.0321,  0.0388, -0.0594]],\n",
            "\n",
            "         [[-0.1108,  0.0191,  0.1080],\n",
            "          [ 0.1116,  0.0277, -0.0775],\n",
            "          [-0.0249,  0.1057, -0.0952]],\n",
            "\n",
            "         [[ 0.1207, -0.1373, -0.0730],\n",
            "          [ 0.1134,  0.0365, -0.0702],\n",
            "          [-0.0340, -0.1309, -0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1354,  0.1205, -0.1124],\n",
            "          [-0.0645, -0.0902,  0.1234],\n",
            "          [-0.0884,  0.0080,  0.0424]],\n",
            "\n",
            "         [[-0.0670,  0.0203, -0.0854],\n",
            "          [ 0.0503, -0.0132,  0.1265],\n",
            "          [-0.0972,  0.0498,  0.1150]],\n",
            "\n",
            "         [[-0.1209,  0.1248,  0.0428],\n",
            "          [-0.0510,  0.0816,  0.0532],\n",
            "          [-0.0520, -0.0577,  0.1087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1126,  0.0255, -0.1296],\n",
            "          [ 0.0378,  0.0466, -0.0572],\n",
            "          [ 0.0232, -0.0410,  0.1117]],\n",
            "\n",
            "         [[ 0.0124, -0.1374,  0.1032],\n",
            "          [-0.0838, -0.1037,  0.0993],\n",
            "          [-0.0971,  0.0112,  0.1063]],\n",
            "\n",
            "         [[-0.1211,  0.1292, -0.0956],\n",
            "          [ 0.0564, -0.1087,  0.0525],\n",
            "          [ 0.1237,  0.0084,  0.0690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0790,  0.0170,  0.1157],\n",
            "          [-0.1304, -0.1316,  0.1206],\n",
            "          [ 0.1354, -0.1357,  0.0203]],\n",
            "\n",
            "         [[ 0.0671,  0.0099,  0.0534],\n",
            "          [ 0.0526, -0.0304,  0.0219],\n",
            "          [-0.0585,  0.0089, -0.0224]],\n",
            "\n",
            "         [[-0.0058, -0.0208,  0.0841],\n",
            "          [ 0.0215, -0.0465, -0.0621],\n",
            "          [-0.1283,  0.1176, -0.0754]]],\n",
            "\n",
            "\n",
            "        [[[-0.0220,  0.0226,  0.0721],\n",
            "          [-0.0388, -0.0747,  0.0138],\n",
            "          [-0.0008,  0.1340,  0.0115]],\n",
            "\n",
            "         [[-0.1081,  0.1344,  0.0052],\n",
            "          [ 0.1110, -0.1306, -0.1088],\n",
            "          [-0.0309,  0.0023,  0.0570]],\n",
            "\n",
            "         [[-0.0560, -0.1184,  0.0920],\n",
            "          [ 0.0252, -0.0433,  0.0878],\n",
            "          [ 0.0069, -0.1082,  0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0770,  0.0946, -0.0880],\n",
            "          [-0.0460,  0.1173,  0.0226],\n",
            "          [ 0.0407,  0.0980, -0.0654]],\n",
            "\n",
            "         [[-0.0717, -0.0724,  0.0412],\n",
            "          [-0.0562,  0.0682, -0.0425],\n",
            "          [ 0.0033, -0.1061,  0.0760]],\n",
            "\n",
            "         [[-0.1020, -0.0190, -0.0219],\n",
            "          [ 0.0550, -0.0851,  0.1220],\n",
            "          [ 0.0055,  0.0560,  0.1111]]],\n",
            "\n",
            "\n",
            "        [[[-0.0951, -0.0374, -0.1315],\n",
            "          [-0.1089,  0.0229,  0.1351],\n",
            "          [ 0.0422,  0.1377, -0.1347]],\n",
            "\n",
            "         [[-0.0214, -0.0826, -0.1109],\n",
            "          [-0.0246, -0.0491,  0.0648],\n",
            "          [-0.0400,  0.1292, -0.0168]],\n",
            "\n",
            "         [[ 0.0885, -0.0273, -0.0782],\n",
            "          [-0.0131, -0.0099,  0.0111],\n",
            "          [ 0.0437, -0.1332, -0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0438,  0.1056],\n",
            "          [ 0.0402, -0.1309,  0.1371],\n",
            "          [ 0.1017,  0.0284, -0.0202]],\n",
            "\n",
            "         [[ 0.1244, -0.1375,  0.0282],\n",
            "          [ 0.1086,  0.1217,  0.0943],\n",
            "          [-0.0004,  0.0387, -0.0833]],\n",
            "\n",
            "         [[-0.0171, -0.0782, -0.0358],\n",
            "          [ 0.0075, -0.1302,  0.0208],\n",
            "          [-0.0873, -0.0959,  0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102, -0.1067, -0.1025],\n",
            "          [ 0.1116,  0.0266, -0.1028],\n",
            "          [-0.0635, -0.0708, -0.0697]],\n",
            "\n",
            "         [[ 0.0030,  0.0739, -0.0855],\n",
            "          [-0.0650,  0.1201, -0.0131],\n",
            "          [-0.0618, -0.0680, -0.0356]],\n",
            "\n",
            "         [[-0.0797, -0.1149,  0.0272],\n",
            "          [ 0.0520,  0.0685,  0.0054],\n",
            "          [-0.0097, -0.0302,  0.1144]]],\n",
            "\n",
            "\n",
            "        [[[-0.1193,  0.0028,  0.0314],\n",
            "          [-0.1280,  0.1190, -0.1014],\n",
            "          [-0.1231,  0.0703,  0.0279]],\n",
            "\n",
            "         [[ 0.0904, -0.1331, -0.0808],\n",
            "          [ 0.0591, -0.0654,  0.1076],\n",
            "          [-0.0453, -0.0707,  0.1021]],\n",
            "\n",
            "         [[-0.0887, -0.0770, -0.0189],\n",
            "          [ 0.0863, -0.0374, -0.0307],\n",
            "          [-0.1057,  0.0172, -0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0808, -0.1211, -0.0311],\n",
            "          [-0.1210,  0.1079,  0.1335],\n",
            "          [ 0.0941, -0.0931,  0.1172]],\n",
            "\n",
            "         [[ 0.0292,  0.0663,  0.1289],\n",
            "          [ 0.0864, -0.0247, -0.1160],\n",
            "          [-0.0783,  0.0210,  0.0308]],\n",
            "\n",
            "         [[-0.1219,  0.0811, -0.1078],\n",
            "          [ 0.1174,  0.0290, -0.0027],\n",
            "          [-0.0488, -0.0225,  0.0816]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1049,  0.0749, -0.1125],\n",
            "          [ 0.1378, -0.0721,  0.1281],\n",
            "          [-0.0777,  0.1362,  0.1164]],\n",
            "\n",
            "         [[ 0.0799,  0.0223,  0.1133],\n",
            "          [-0.0881,  0.0412,  0.0543],\n",
            "          [-0.0111, -0.0803, -0.0113]],\n",
            "\n",
            "         [[-0.0609,  0.0141, -0.0534],\n",
            "          [-0.1238,  0.0143,  0.0859],\n",
            "          [-0.0301, -0.0316,  0.0964]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0993,  0.1189, -0.0055],\n",
            "          [ 0.0014, -0.0976,  0.0031],\n",
            "          [ 0.0043,  0.1026, -0.1371]],\n",
            "\n",
            "         [[-0.0154, -0.1327, -0.1321],\n",
            "          [ 0.0735,  0.0689,  0.1124],\n",
            "          [ 0.0417,  0.0066, -0.0752]],\n",
            "\n",
            "         [[-0.1169, -0.0826, -0.0636],\n",
            "          [-0.0801,  0.0542,  0.1322],\n",
            "          [ 0.1274, -0.0805, -0.1321]]],\n",
            "\n",
            "\n",
            "        [[[-0.0321, -0.1013, -0.1340],\n",
            "          [ 0.0549,  0.1229,  0.0187],\n",
            "          [ 0.0635,  0.0855, -0.0793]],\n",
            "\n",
            "         [[ 0.0163,  0.0576, -0.0725],\n",
            "          [ 0.1349,  0.1338,  0.0424],\n",
            "          [-0.0565, -0.0271, -0.0065]],\n",
            "\n",
            "         [[ 0.1057, -0.0662,  0.0843],\n",
            "          [ 0.1218, -0.0181, -0.0132],\n",
            "          [-0.0224,  0.0711,  0.1373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458, -0.0240, -0.0642],\n",
            "          [-0.1284,  0.1301, -0.0221],\n",
            "          [ 0.0513,  0.0357,  0.0685]],\n",
            "\n",
            "         [[ 0.0447,  0.0482,  0.0202],\n",
            "          [ 0.1029, -0.0415,  0.0292],\n",
            "          [ 0.0927, -0.0914,  0.1029]],\n",
            "\n",
            "         [[ 0.0587, -0.0453, -0.0390],\n",
            "          [ 0.0402, -0.1310,  0.1291],\n",
            "          [-0.1203, -0.0834,  0.0932]]],\n",
            "\n",
            "\n",
            "        [[[-0.1195, -0.0345, -0.0670],\n",
            "          [ 0.0642, -0.0037, -0.0502],\n",
            "          [-0.0359,  0.0489,  0.0630]],\n",
            "\n",
            "         [[-0.0950,  0.1065,  0.0999],\n",
            "          [ 0.0028, -0.0237,  0.0881],\n",
            "          [ 0.1140, -0.1286,  0.0987]],\n",
            "\n",
            "         [[-0.0686, -0.0377,  0.0912],\n",
            "          [ 0.1366, -0.0975, -0.0507],\n",
            "          [-0.0163,  0.0094,  0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1173,  0.1334, -0.0506],\n",
            "          [-0.1283, -0.1268,  0.0220],\n",
            "          [ 0.0777, -0.0241, -0.0772]],\n",
            "\n",
            "         [[-0.0849, -0.0376,  0.0414],\n",
            "          [ 0.1200,  0.0639, -0.0089],\n",
            "          [-0.0256,  0.1346,  0.0802]],\n",
            "\n",
            "         [[-0.1187,  0.1279,  0.0268],\n",
            "          [ 0.0801, -0.0363, -0.1048],\n",
            "          [-0.0573, -0.0708,  0.0379]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0796, -0.0600,  0.0439],\n",
            "          [ 0.0550, -0.1245, -0.0892],\n",
            "          [-0.0474, -0.1210,  0.1336]],\n",
            "\n",
            "         [[ 0.0692,  0.0903, -0.0840],\n",
            "          [ 0.1243,  0.1076,  0.1367],\n",
            "          [-0.0511, -0.0784, -0.0105]],\n",
            "\n",
            "         [[ 0.0425, -0.0139,  0.1241],\n",
            "          [-0.0850,  0.0267,  0.0743],\n",
            "          [-0.1332, -0.0337, -0.0154]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0971, -0.0718, -0.0420],\n",
            "          [-0.1062,  0.1183, -0.1028],\n",
            "          [-0.0097,  0.0813, -0.0535]],\n",
            "\n",
            "         [[ 0.1279,  0.1208,  0.0060],\n",
            "          [-0.1352, -0.0636,  0.0192],\n",
            "          [-0.1363, -0.0039,  0.0833]],\n",
            "\n",
            "         [[-0.0234,  0.0114, -0.0031],\n",
            "          [ 0.1271,  0.0990, -0.0219],\n",
            "          [ 0.0717, -0.1184, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[-0.0752,  0.0160,  0.1106],\n",
            "          [-0.1226,  0.0359, -0.0675],\n",
            "          [-0.0148,  0.1298,  0.0941]],\n",
            "\n",
            "         [[ 0.0124, -0.0077, -0.1213],\n",
            "          [ 0.0115, -0.0320,  0.1001],\n",
            "          [ 0.0701,  0.0954, -0.0785]],\n",
            "\n",
            "         [[-0.1014,  0.0947,  0.0171],\n",
            "          [ 0.1316, -0.0220, -0.0368],\n",
            "          [ 0.0536,  0.0620, -0.0759]]],\n",
            "\n",
            "\n",
            "        [[[-0.0462,  0.0865, -0.0109],\n",
            "          [-0.0799, -0.0852,  0.0181],\n",
            "          [-0.0158,  0.0746,  0.1030]],\n",
            "\n",
            "         [[-0.0636,  0.0897, -0.0426],\n",
            "          [ 0.0369, -0.0393, -0.0056],\n",
            "          [-0.0294,  0.1296, -0.1235]],\n",
            "\n",
            "         [[ 0.0002,  0.0252,  0.1291],\n",
            "          [-0.0383,  0.0881,  0.0236],\n",
            "          [-0.0026, -0.0574, -0.0595]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 0.0525,  0.0607,  0.0294],\n",
            "          [-0.0597,  0.0081,  0.0227],\n",
            "          [ 0.0107,  0.0121,  0.0542]],\n",
            "\n",
            "         [[ 0.0217,  0.0483, -0.0325],\n",
            "          [-0.0638,  0.0536, -0.0179],\n",
            "          [-0.0156,  0.0059, -0.0274]],\n",
            "\n",
            "         [[-0.0345, -0.0405,  0.0207],\n",
            "          [ 0.0206,  0.0331,  0.0328],\n",
            "          [-0.0681,  0.0688, -0.0348]]],\n",
            "\n",
            "\n",
            "        [[[-0.0122,  0.0537,  0.0306],\n",
            "          [-0.0207,  0.0613,  0.0492],\n",
            "          [ 0.0461,  0.0083,  0.0611]],\n",
            "\n",
            "         [[ 0.0256,  0.0656, -0.0086],\n",
            "          [-0.0457, -0.0004, -0.0110],\n",
            "          [-0.0258, -0.0224,  0.0538]],\n",
            "\n",
            "         [[-0.0592,  0.0313,  0.0619],\n",
            "          [ 0.0642, -0.0080, -0.0028],\n",
            "          [ 0.0033, -0.0198,  0.0273]]],\n",
            "\n",
            "\n",
            "        [[[-0.0012, -0.0623,  0.0113],\n",
            "          [ 0.0553,  0.0417, -0.0113],\n",
            "          [-0.0624, -0.0030, -0.0607]],\n",
            "\n",
            "         [[ 0.0433,  0.0679,  0.0281],\n",
            "          [-0.0235,  0.0242,  0.0536],\n",
            "          [-0.0661, -0.0560,  0.0620]],\n",
            "\n",
            "         [[ 0.0486,  0.0155, -0.0163],\n",
            "          [ 0.0214, -0.0089,  0.0680],\n",
            "          [-0.0101,  0.0311,  0.0425]]],\n",
            "\n",
            "\n",
            "        [[[-0.0151,  0.0296, -0.0439],\n",
            "          [ 0.0008, -0.0422,  0.0003],\n",
            "          [-0.0055, -0.0660,  0.0036]],\n",
            "\n",
            "         [[-0.0345, -0.0195, -0.0643],\n",
            "          [-0.0555, -0.0482,  0.0246],\n",
            "          [ 0.0040,  0.0449,  0.0282]],\n",
            "\n",
            "         [[ 0.0533, -0.0016,  0.0673],\n",
            "          [-0.0498, -0.0152,  0.0145],\n",
            "          [-0.0596, -0.0406,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[-0.0373,  0.0078,  0.0463],\n",
            "          [ 0.0638, -0.0324, -0.0606],\n",
            "          [-0.0219,  0.0352,  0.0047]],\n",
            "\n",
            "         [[ 0.0325, -0.0529, -0.0688],\n",
            "          [-0.0402,  0.0299, -0.0205],\n",
            "          [ 0.0630,  0.0352,  0.0610]],\n",
            "\n",
            "         [[ 0.0055,  0.0144,  0.0303],\n",
            "          [ 0.0289,  0.0117, -0.0425],\n",
            "          [ 0.0302, -0.0268,  0.0363]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0235, -0.0105,  0.0530],\n",
            "          [ 0.0637,  0.0517, -0.0476],\n",
            "          [ 0.0672, -0.0167,  0.0286]],\n",
            "\n",
            "         [[ 0.0053, -0.0509, -0.0316],\n",
            "          [-0.0532,  0.0412,  0.0294],\n",
            "          [ 0.0653, -0.0580, -0.0004]],\n",
            "\n",
            "         [[ 0.0516,  0.0685,  0.0665],\n",
            "          [-0.0291, -0.0503, -0.0258],\n",
            "          [ 0.0478, -0.0233,  0.0055]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0315, -0.0504, -0.0112],\n",
            "          [ 0.0299,  0.0373, -0.0404],\n",
            "          [ 0.0548, -0.0041,  0.0243]],\n",
            "\n",
            "         [[-0.0096,  0.0216, -0.0090],\n",
            "          [ 0.0278, -0.0221, -0.0671],\n",
            "          [ 0.0195, -0.0469, -0.0580]],\n",
            "\n",
            "         [[ 0.0318, -0.0224,  0.0388],\n",
            "          [-0.0236,  0.0609, -0.0108],\n",
            "          [ 0.0118,  0.0669, -0.0640]]],\n",
            "\n",
            "\n",
            "        [[[-0.0569,  0.0481,  0.0367],\n",
            "          [ 0.0613,  0.0346,  0.0343],\n",
            "          [ 0.0476, -0.0494, -0.0652]],\n",
            "\n",
            "         [[ 0.0207,  0.0606,  0.0519],\n",
            "          [ 0.0236,  0.0157,  0.0564],\n",
            "          [ 0.0624,  0.0296,  0.0564]],\n",
            "\n",
            "         [[-0.0012, -0.0093, -0.0161],\n",
            "          [ 0.0002, -0.0220,  0.0537],\n",
            "          [-0.0170, -0.0119,  0.0354]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0512, -0.0367,  0.0131],\n",
            "          [ 0.0317, -0.0627,  0.0403],\n",
            "          [-0.0472, -0.0113, -0.0529]],\n",
            "\n",
            "         [[-0.0177,  0.0365, -0.0350],\n",
            "          [-0.0432, -0.0615, -0.0637],\n",
            "          [-0.0517, -0.0045,  0.0250]],\n",
            "\n",
            "         [[-0.0471, -0.0645, -0.0130],\n",
            "          [-0.0056,  0.0150,  0.0688],\n",
            "          [ 0.0277, -0.0617, -0.0108]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0546, -0.0459,  0.0277],\n",
            "          [-0.0049,  0.0293, -0.0228],\n",
            "          [ 0.0478, -0.0396,  0.0477]],\n",
            "\n",
            "         [[ 0.0171, -0.0346, -0.0388],\n",
            "          [ 0.0339, -0.0666, -0.0412],\n",
            "          [ 0.0085,  0.0091,  0.0131]],\n",
            "\n",
            "         [[-0.0402, -0.0479,  0.0007],\n",
            "          [-0.0174,  0.0600, -0.0670],\n",
            "          [-0.0177, -0.0487,  0.0026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0096,  0.0239, -0.0042],\n",
            "          [ 0.0409,  0.0592, -0.0138],\n",
            "          [-0.0143,  0.0066, -0.0307]],\n",
            "\n",
            "         [[ 0.0165,  0.0299,  0.0555],\n",
            "          [ 0.0583, -0.0209,  0.0240],\n",
            "          [-0.0454,  0.0277,  0.0675]],\n",
            "\n",
            "         [[-0.0241,  0.0437, -0.0659],\n",
            "          [ 0.0378,  0.0107,  0.0569],\n",
            "          [ 0.0020,  0.0547,  0.0059]]],\n",
            "\n",
            "\n",
            "        [[[-0.0418, -0.0192,  0.0628],\n",
            "          [-0.0480,  0.0623,  0.0353],\n",
            "          [ 0.0161,  0.0194, -0.0297]],\n",
            "\n",
            "         [[-0.0554,  0.0095,  0.0540],\n",
            "          [ 0.0558,  0.0138, -0.0388],\n",
            "          [-0.0124,  0.0528, -0.0476]],\n",
            "\n",
            "         [[ 0.0603, -0.0686, -0.0365],\n",
            "          [ 0.0567,  0.0183, -0.0351],\n",
            "          [-0.0170, -0.0655, -0.0180]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0677,  0.0602, -0.0562],\n",
            "          [-0.0323, -0.0451,  0.0617],\n",
            "          [-0.0442,  0.0040,  0.0212]],\n",
            "\n",
            "         [[-0.0335,  0.0101, -0.0427],\n",
            "          [ 0.0252, -0.0066,  0.0633],\n",
            "          [-0.0486,  0.0249,  0.0575]],\n",
            "\n",
            "         [[-0.0604,  0.0624,  0.0214],\n",
            "          [-0.0255,  0.0408,  0.0266],\n",
            "          [-0.0260, -0.0288,  0.0544]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0563,  0.0128, -0.0648],\n",
            "          [ 0.0189,  0.0233, -0.0286],\n",
            "          [ 0.0116, -0.0205,  0.0559]],\n",
            "\n",
            "         [[ 0.0062, -0.0687,  0.0516],\n",
            "          [-0.0419, -0.0518,  0.0497],\n",
            "          [-0.0486,  0.0056,  0.0532]],\n",
            "\n",
            "         [[-0.0606,  0.0646, -0.0478],\n",
            "          [ 0.0282, -0.0544,  0.0263],\n",
            "          [ 0.0619,  0.0042,  0.0345]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0395,  0.0085,  0.0578],\n",
            "          [-0.0652, -0.0658,  0.0603],\n",
            "          [ 0.0677, -0.0678,  0.0101]],\n",
            "\n",
            "         [[ 0.0336,  0.0050,  0.0267],\n",
            "          [ 0.0263, -0.0152,  0.0110],\n",
            "          [-0.0292,  0.0044, -0.0112]],\n",
            "\n",
            "         [[-0.0029, -0.0104,  0.0420],\n",
            "          [ 0.0108, -0.0232, -0.0310],\n",
            "          [-0.0641,  0.0588, -0.0377]]],\n",
            "\n",
            "\n",
            "        [[[-0.0110,  0.0113,  0.0361],\n",
            "          [-0.0194, -0.0374,  0.0069],\n",
            "          [-0.0004,  0.0670,  0.0057]],\n",
            "\n",
            "         [[-0.0540,  0.0672,  0.0026],\n",
            "          [ 0.0555, -0.0653, -0.0544],\n",
            "          [-0.0154,  0.0012,  0.0285]],\n",
            "\n",
            "         [[-0.0280, -0.0592,  0.0460],\n",
            "          [ 0.0126, -0.0216,  0.0439],\n",
            "          [ 0.0035, -0.0541,  0.0044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0385,  0.0473, -0.0440],\n",
            "          [-0.0230,  0.0586,  0.0113],\n",
            "          [ 0.0204,  0.0490, -0.0327]],\n",
            "\n",
            "         [[-0.0359, -0.0362,  0.0206],\n",
            "          [-0.0281,  0.0341, -0.0213],\n",
            "          [ 0.0017, -0.0530,  0.0380]],\n",
            "\n",
            "         [[-0.0510, -0.0095, -0.0109],\n",
            "          [ 0.0275, -0.0425,  0.0610],\n",
            "          [ 0.0028,  0.0280,  0.0555]]],\n",
            "\n",
            "\n",
            "        [[[-0.0475, -0.0187, -0.0657],\n",
            "          [-0.0544,  0.0114,  0.0676],\n",
            "          [ 0.0211,  0.0689, -0.0674]],\n",
            "\n",
            "         [[-0.0107, -0.0413, -0.0555],\n",
            "          [-0.0123, -0.0245,  0.0324],\n",
            "          [-0.0200,  0.0646, -0.0084]],\n",
            "\n",
            "         [[ 0.0442, -0.0137, -0.0391],\n",
            "          [-0.0066, -0.0050,  0.0056],\n",
            "          [ 0.0219, -0.0666, -0.0625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0444, -0.0219,  0.0528],\n",
            "          [ 0.0201, -0.0654,  0.0685],\n",
            "          [ 0.0508,  0.0142, -0.0101]],\n",
            "\n",
            "         [[ 0.0622, -0.0688,  0.0141],\n",
            "          [ 0.0543,  0.0609,  0.0472],\n",
            "          [-0.0002,  0.0194, -0.0416]],\n",
            "\n",
            "         [[-0.0085, -0.0391, -0.0179],\n",
            "          [ 0.0038, -0.0651,  0.0104],\n",
            "          [-0.0437, -0.0480,  0.0351]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0051, -0.0534, -0.0513],\n",
            "          [ 0.0558,  0.0133, -0.0514],\n",
            "          [-0.0317, -0.0354, -0.0349]],\n",
            "\n",
            "         [[ 0.0015,  0.0369, -0.0427],\n",
            "          [-0.0325,  0.0600, -0.0065],\n",
            "          [-0.0309, -0.0340, -0.0178]],\n",
            "\n",
            "         [[-0.0398, -0.0575,  0.0136],\n",
            "          [ 0.0260,  0.0343,  0.0027],\n",
            "          [-0.0049, -0.0151,  0.0572]]],\n",
            "\n",
            "\n",
            "        [[[-0.0597,  0.0014,  0.0157],\n",
            "          [-0.0640,  0.0595, -0.0507],\n",
            "          [-0.0615,  0.0351,  0.0139]],\n",
            "\n",
            "         [[ 0.0452, -0.0666, -0.0404],\n",
            "          [ 0.0296, -0.0327,  0.0538],\n",
            "          [-0.0227, -0.0354,  0.0511]],\n",
            "\n",
            "         [[-0.0443, -0.0385, -0.0094],\n",
            "          [ 0.0431, -0.0187, -0.0154],\n",
            "          [-0.0529,  0.0086, -0.0100]]],\n",
            "\n",
            "\n",
            "        [[[-0.0404, -0.0605, -0.0156],\n",
            "          [-0.0605,  0.0539,  0.0668],\n",
            "          [ 0.0471, -0.0465,  0.0586]],\n",
            "\n",
            "         [[ 0.0146,  0.0332,  0.0644],\n",
            "          [ 0.0432, -0.0124, -0.0580],\n",
            "          [-0.0392,  0.0105,  0.0154]],\n",
            "\n",
            "         [[-0.0610,  0.0405, -0.0539],\n",
            "          [ 0.0587,  0.0145, -0.0014],\n",
            "          [-0.0244, -0.0113,  0.0408]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0525,  0.0374, -0.0563],\n",
            "          [ 0.0689, -0.0360,  0.0640],\n",
            "          [-0.0389,  0.0681,  0.0582]],\n",
            "\n",
            "         [[ 0.0399,  0.0111,  0.0567],\n",
            "          [-0.0441,  0.0206,  0.0272],\n",
            "          [-0.0055, -0.0402, -0.0056]],\n",
            "\n",
            "         [[-0.0305,  0.0071, -0.0267],\n",
            "          [-0.0619,  0.0071,  0.0430],\n",
            "          [-0.0151, -0.0158,  0.0482]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0496,  0.0595, -0.0027],\n",
            "          [ 0.0007, -0.0488,  0.0016],\n",
            "          [ 0.0022,  0.0513, -0.0685]],\n",
            "\n",
            "         [[-0.0077, -0.0664, -0.0660],\n",
            "          [ 0.0368,  0.0344,  0.0562],\n",
            "          [ 0.0209,  0.0033, -0.0376]],\n",
            "\n",
            "         [[-0.0584, -0.0413, -0.0318],\n",
            "          [-0.0401,  0.0271,  0.0661],\n",
            "          [ 0.0637, -0.0402, -0.0660]]],\n",
            "\n",
            "\n",
            "        [[[-0.0161, -0.0507, -0.0670],\n",
            "          [ 0.0275,  0.0614,  0.0093],\n",
            "          [ 0.0317,  0.0428, -0.0397]],\n",
            "\n",
            "         [[ 0.0081,  0.0288, -0.0362],\n",
            "          [ 0.0674,  0.0669,  0.0212],\n",
            "          [-0.0282, -0.0136, -0.0033]],\n",
            "\n",
            "         [[ 0.0529, -0.0331,  0.0422],\n",
            "          [ 0.0609, -0.0090, -0.0066],\n",
            "          [-0.0112,  0.0355,  0.0686]]],\n",
            "\n",
            "\n",
            "        [[[-0.0229, -0.0120, -0.0321],\n",
            "          [-0.0642,  0.0650, -0.0111],\n",
            "          [ 0.0257,  0.0179,  0.0342]],\n",
            "\n",
            "         [[ 0.0224,  0.0241,  0.0101],\n",
            "          [ 0.0515, -0.0208,  0.0146],\n",
            "          [ 0.0463, -0.0457,  0.0515]],\n",
            "\n",
            "         [[ 0.0293, -0.0227, -0.0195],\n",
            "          [ 0.0201, -0.0655,  0.0646],\n",
            "          [-0.0601, -0.0417,  0.0466]]],\n",
            "\n",
            "\n",
            "        [[[-0.0597, -0.0173, -0.0335],\n",
            "          [ 0.0321, -0.0019, -0.0251],\n",
            "          [-0.0180,  0.0245,  0.0315]],\n",
            "\n",
            "         [[-0.0475,  0.0533,  0.0499],\n",
            "          [ 0.0014, -0.0119,  0.0441],\n",
            "          [ 0.0570, -0.0643,  0.0494]],\n",
            "\n",
            "         [[-0.0343, -0.0188,  0.0456],\n",
            "          [ 0.0683, -0.0488, -0.0253],\n",
            "          [-0.0082,  0.0047,  0.0089]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0587,  0.0667, -0.0253],\n",
            "          [-0.0642, -0.0634,  0.0110],\n",
            "          [ 0.0388, -0.0121, -0.0386]],\n",
            "\n",
            "         [[-0.0425, -0.0188,  0.0207],\n",
            "          [ 0.0600,  0.0319, -0.0045],\n",
            "          [-0.0128,  0.0673,  0.0401]],\n",
            "\n",
            "         [[-0.0593,  0.0640,  0.0134],\n",
            "          [ 0.0401, -0.0182, -0.0524],\n",
            "          [-0.0286, -0.0354,  0.0189]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0398, -0.0300,  0.0219],\n",
            "          [ 0.0275, -0.0623, -0.0446],\n",
            "          [-0.0237, -0.0605,  0.0668]],\n",
            "\n",
            "         [[ 0.0346,  0.0451, -0.0420],\n",
            "          [ 0.0621,  0.0538,  0.0684],\n",
            "          [-0.0256, -0.0392, -0.0052]],\n",
            "\n",
            "         [[ 0.0213, -0.0069,  0.0621],\n",
            "          [-0.0425,  0.0133,  0.0371],\n",
            "          [-0.0666, -0.0168, -0.0077]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0486, -0.0359, -0.0210],\n",
            "          [-0.0531,  0.0592, -0.0514],\n",
            "          [-0.0049,  0.0406, -0.0267]],\n",
            "\n",
            "         [[ 0.0640,  0.0604,  0.0030],\n",
            "          [-0.0676, -0.0318,  0.0096],\n",
            "          [-0.0681, -0.0019,  0.0416]],\n",
            "\n",
            "         [[-0.0117,  0.0057, -0.0016],\n",
            "          [ 0.0635,  0.0495, -0.0109],\n",
            "          [ 0.0359, -0.0592, -0.0385]]],\n",
            "\n",
            "\n",
            "        [[[-0.0376,  0.0080,  0.0553],\n",
            "          [-0.0613,  0.0180, -0.0337],\n",
            "          [-0.0074,  0.0649,  0.0470]],\n",
            "\n",
            "         [[ 0.0062, -0.0038, -0.0606],\n",
            "          [ 0.0058, -0.0160,  0.0500],\n",
            "          [ 0.0350,  0.0477, -0.0393]],\n",
            "\n",
            "         [[-0.0507,  0.0473,  0.0085],\n",
            "          [ 0.0658, -0.0110, -0.0184],\n",
            "          [ 0.0268,  0.0310, -0.0379]]],\n",
            "\n",
            "\n",
            "        [[[-0.0231,  0.0433, -0.0055],\n",
            "          [-0.0400, -0.0426,  0.0090],\n",
            "          [-0.0079,  0.0373,  0.0515]],\n",
            "\n",
            "         [[-0.0318,  0.0449, -0.0213],\n",
            "          [ 0.0185, -0.0197, -0.0028],\n",
            "          [-0.0147,  0.0648, -0.0617]],\n",
            "\n",
            "         [[ 0.0001,  0.0126,  0.0646],\n",
            "          [-0.0192,  0.0440,  0.0118],\n",
            "          [-0.0013, -0.0287, -0.0298]]]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 6.3420e-02,  7.3276e-02,  3.5488e-02],\n",
            "          [-7.2040e-02,  9.8323e-03,  2.7458e-02],\n",
            "          [ 1.2968e-02,  1.4557e-02,  6.5395e-02]],\n",
            "\n",
            "         [[ 2.6170e-02,  5.8342e-02, -3.9271e-02],\n",
            "          [-7.7091e-02,  6.4732e-02, -2.1609e-02],\n",
            "          [-1.8860e-02,  7.0977e-03, -3.3068e-02]],\n",
            "\n",
            "         [[-4.1607e-02, -4.8902e-02,  2.5010e-02],\n",
            "          [ 2.4871e-02,  4.0022e-02,  3.9656e-02],\n",
            "          [-8.2284e-02,  8.3118e-02, -4.2069e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.8574e-02, -5.7834e-02,  8.3874e-04],\n",
            "          [-2.1052e-02,  7.2458e-02, -8.0893e-02],\n",
            "          [-2.1344e-02, -5.8761e-02,  3.1942e-03]],\n",
            "\n",
            "         [[ 1.1539e-02,  2.8821e-02, -5.0540e-03],\n",
            "          [ 4.9397e-02,  7.1442e-02, -1.6676e-02],\n",
            "          [-1.7296e-02,  7.9432e-03, -3.7044e-02]],\n",
            "\n",
            "         [[ 1.9931e-02,  3.6135e-02,  6.7053e-02],\n",
            "          [ 7.0346e-02, -2.5206e-02,  2.9000e-02],\n",
            "          [-5.4800e-02,  3.3441e-02,  8.1460e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9146e-02,  5.2727e-02, -7.9582e-02],\n",
            "          [ 4.5671e-02,  1.2910e-02,  6.8654e-02],\n",
            "          [ 2.3663e-03,  6.6062e-02,  7.1735e-03]],\n",
            "\n",
            "         [[-5.0448e-02, -2.3134e-02,  7.5889e-02],\n",
            "          [-5.8021e-02,  7.5218e-02,  4.2656e-02],\n",
            "          [ 1.9394e-02,  2.3413e-02, -3.5866e-02]],\n",
            "\n",
            "         [[-6.6916e-02,  1.1513e-02,  6.5213e-02],\n",
            "          [ 6.7408e-02,  1.6709e-02, -4.6795e-02],\n",
            "          [-1.5024e-02,  6.3795e-02, -5.7492e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4604e-02, -8.0372e-02, -4.8780e-02],\n",
            "          [ 3.5713e-02, -3.9517e-02,  6.4963e-02],\n",
            "          [-2.7380e-02, -4.2717e-02,  6.1674e-02]],\n",
            "\n",
            "         [[-5.3551e-02, -4.6499e-02, -1.1385e-02],\n",
            "          [ 5.2103e-02, -2.2561e-02, -1.8564e-02],\n",
            "          [-6.3842e-02,  1.0369e-02, -1.2117e-02]],\n",
            "\n",
            "         [[-4.8763e-02, -7.3097e-02, -1.8784e-02],\n",
            "          [-7.3069e-02,  6.5139e-02,  8.0630e-02],\n",
            "          [ 5.6838e-02, -5.6211e-02,  7.0789e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7635e-02,  4.0050e-02,  7.7815e-02],\n",
            "          [ 5.2183e-02, -1.4920e-02, -7.0026e-02],\n",
            "          [-4.7301e-02,  1.2658e-02,  1.8608e-02]],\n",
            "\n",
            "         [[-7.3607e-02,  4.8940e-02, -6.5101e-02],\n",
            "          [ 7.0861e-02,  1.7530e-02, -1.6527e-03],\n",
            "          [-2.9492e-02, -1.3609e-02,  4.9277e-02]],\n",
            "\n",
            "         [[ 6.3353e-02,  4.5206e-02, -6.7958e-02],\n",
            "          [ 8.3224e-02, -4.3525e-02,  7.7330e-02],\n",
            "          [-4.6917e-02,  8.2215e-02,  7.0256e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7900e-02,  5.2240e-02, -6.5858e-03],\n",
            "          [-4.8251e-02, -5.1474e-02,  1.0904e-02],\n",
            "          [-9.5620e-03,  4.5054e-02,  6.2167e-02]],\n",
            "\n",
            "         [[-3.8407e-02,  5.4180e-02, -2.5712e-02],\n",
            "          [ 2.2288e-02, -2.3744e-02, -3.3917e-03],\n",
            "          [-1.7741e-02,  7.8265e-02, -7.4556e-02]],\n",
            "\n",
            "         [[ 1.3336e-04,  1.5187e-02,  7.7969e-02],\n",
            "          [-2.3130e-02,  5.3177e-02,  1.4256e-02],\n",
            "          [-1.5449e-03, -3.4685e-02, -3.5939e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5518e-02, -7.8106e-03,  1.1188e-02],\n",
            "          [ 5.8566e-02, -7.5503e-02, -4.8799e-02],\n",
            "          [ 7.8534e-02, -7.6864e-03, -5.4235e-03]],\n",
            "\n",
            "         [[-4.8229e-02, -2.4747e-02,  1.4032e-02],\n",
            "          [-2.6408e-02, -3.0844e-02, -6.4617e-02],\n",
            "          [ 7.1523e-02,  7.5792e-03, -1.8219e-02]],\n",
            "\n",
            "         [[-1.2435e-02,  5.9314e-02,  6.8632e-02],\n",
            "          [ 6.1398e-02,  2.9868e-02, -8.2195e-02],\n",
            "          [-3.4634e-03,  2.8007e-02,  2.8763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0223e-02, -7.1725e-02, -5.0124e-02],\n",
            "          [ 9.6777e-03,  2.4223e-02, -7.1778e-02],\n",
            "          [ 3.2490e-02, -8.2311e-02, -3.7245e-02]],\n",
            "\n",
            "         [[-6.6682e-02, -3.9517e-02,  6.0189e-04],\n",
            "          [ 4.7752e-02,  4.7375e-02,  4.6630e-02],\n",
            "          [ 4.7163e-03,  8.7263e-03,  4.0087e-02]],\n",
            "\n",
            "         [[-8.1609e-02, -7.4239e-02, -6.0175e-02],\n",
            "          [ 7.7161e-02,  1.4216e-02,  2.8079e-02],\n",
            "          [-2.9038e-02, -7.9810e-02, -5.7194e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3276e-02,  6.2281e-02, -6.5992e-02],\n",
            "          [ 1.6867e-02,  4.9823e-02,  3.7555e-02],\n",
            "          [ 7.6220e-02,  6.5295e-02, -2.0038e-03]],\n",
            "\n",
            "         [[-4.5562e-02,  7.9474e-02,  1.4381e-02],\n",
            "          [-2.2909e-02, -8.0703e-02, -6.7262e-02],\n",
            "          [ 6.5767e-02, -7.8513e-02, -3.2978e-02]],\n",
            "\n",
            "         [[-8.0295e-02,  7.5996e-02, -8.0098e-02],\n",
            "          [ 3.8228e-02,  5.9146e-03,  3.0472e-02],\n",
            "          [ 7.3772e-02,  4.7300e-02, -5.7094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4906e-02,  1.9164e-02, -2.9368e-02],\n",
            "          [-2.2259e-02,  4.3675e-02, -8.1335e-02],\n",
            "          [-2.6379e-02,  8.2509e-02, -5.6902e-02]],\n",
            "\n",
            "         [[ 4.8517e-02, -5.3306e-02, -4.5405e-02],\n",
            "          [-7.2836e-02,  6.9791e-04, -2.0265e-02],\n",
            "          [ 3.9212e-02,  3.0947e-02,  8.1954e-02]],\n",
            "\n",
            "         [[-1.0525e-02,  3.9170e-02,  8.1547e-02],\n",
            "          [ 1.0298e-02,  2.4142e-02,  8.1552e-02],\n",
            "          [-4.1315e-02, -6.6417e-02, -4.2100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7834e-02, -3.7336e-02, -5.6150e-02],\n",
            "          [ 1.4851e-03,  2.7738e-02, -5.7369e-02],\n",
            "          [-7.0169e-02, -4.1213e-05, -4.9262e-02]],\n",
            "\n",
            "         [[-1.4965e-02,  4.0813e-02,  6.4681e-02],\n",
            "          [-4.0381e-02, -5.2670e-03,  3.8095e-02],\n",
            "          [ 5.0829e-02,  7.8358e-02, -5.9338e-03]],\n",
            "\n",
            "         [[ 5.0548e-02,  6.9506e-02,  3.5774e-03],\n",
            "          [-2.0453e-02, -2.2837e-02,  2.7631e-02],\n",
            "          [ 2.2321e-03,  4.0112e-03,  5.9683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7560e-02,  2.7013e-02,  3.8514e-02],\n",
            "          [-6.2757e-02,  7.1732e-02,  3.4445e-02],\n",
            "          [-5.7345e-03, -4.4443e-02, -7.9402e-02]],\n",
            "\n",
            "         [[-8.3232e-02,  3.6605e-02,  3.9557e-02],\n",
            "          [-3.0950e-02, -1.1902e-02,  2.3066e-02],\n",
            "          [ 8.3602e-03,  1.4968e-02, -6.2327e-02]],\n",
            "\n",
            "         [[ 3.4100e-02,  4.9295e-02,  2.1340e-02],\n",
            "          [-2.3296e-02,  3.6142e-02,  3.7400e-03],\n",
            "          [-1.0772e-02, -7.1674e-02, -2.9318e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.1710e-02,  3.6638e-02,  1.7744e-02],\n",
            "          [-3.6020e-02,  4.9161e-03,  1.3729e-02],\n",
            "          [ 6.4840e-03,  7.2786e-03,  3.2698e-02]],\n",
            "\n",
            "         [[ 1.3085e-02,  2.9171e-02, -1.9635e-02],\n",
            "          [-3.8546e-02,  3.2366e-02, -1.0805e-02],\n",
            "          [-9.4300e-03,  3.5489e-03, -1.6534e-02]],\n",
            "\n",
            "         [[-2.0803e-02, -2.4451e-02,  1.2505e-02],\n",
            "          [ 1.2436e-02,  2.0011e-02,  1.9828e-02],\n",
            "          [-4.1142e-02,  4.1559e-02, -2.1035e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4287e-02, -2.8917e-02,  4.1937e-04],\n",
            "          [-1.0526e-02,  3.6229e-02, -4.0446e-02],\n",
            "          [-1.0672e-02, -2.9381e-02,  1.5971e-03]],\n",
            "\n",
            "         [[ 5.7697e-03,  1.4410e-02, -2.5270e-03],\n",
            "          [ 2.4699e-02,  3.5721e-02, -8.3378e-03],\n",
            "          [-8.6479e-03,  3.9716e-03, -1.8522e-02]],\n",
            "\n",
            "         [[ 9.9656e-03,  1.8068e-02,  3.3527e-02],\n",
            "          [ 3.5173e-02, -1.2603e-02,  1.4500e-02],\n",
            "          [-2.7400e-02,  1.6720e-02,  4.0730e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4573e-02,  2.6364e-02, -3.9791e-02],\n",
            "          [ 2.2836e-02,  6.4549e-03,  3.4327e-02],\n",
            "          [ 1.1832e-03,  3.3031e-02,  3.5868e-03]],\n",
            "\n",
            "         [[-2.5224e-02, -1.1567e-02,  3.7945e-02],\n",
            "          [-2.9010e-02,  3.7609e-02,  2.1328e-02],\n",
            "          [ 9.6970e-03,  1.1707e-02, -1.7933e-02]],\n",
            "\n",
            "         [[-3.3458e-02,  5.7565e-03,  3.2606e-02],\n",
            "          [ 3.3704e-02,  8.3544e-03, -2.3398e-02],\n",
            "          [-7.5121e-03,  3.1898e-02, -2.8746e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7302e-02, -4.0186e-02, -2.4390e-02],\n",
            "          [ 1.7857e-02, -1.9759e-02,  3.2482e-02],\n",
            "          [-1.3690e-02, -2.1359e-02,  3.0837e-02]],\n",
            "\n",
            "         [[-2.6776e-02, -2.3250e-02, -5.6927e-03],\n",
            "          [ 2.6051e-02, -1.1280e-02, -9.2821e-03],\n",
            "          [-3.1921e-02,  5.1847e-03, -6.0585e-03]],\n",
            "\n",
            "         [[-2.4381e-02, -3.6548e-02, -9.3918e-03],\n",
            "          [-3.6534e-02,  3.2569e-02,  4.0315e-02],\n",
            "          [ 2.8419e-02, -2.8105e-02,  3.5394e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.8174e-03,  2.0025e-02,  3.8908e-02],\n",
            "          [ 2.6091e-02, -7.4599e-03, -3.5013e-02],\n",
            "          [-2.3650e-02,  6.3288e-03,  9.3041e-03]],\n",
            "\n",
            "         [[-3.6804e-02,  2.4470e-02, -3.2551e-02],\n",
            "          [ 3.5430e-02,  8.7649e-03, -8.2635e-04],\n",
            "          [-1.4746e-02, -6.8046e-03,  2.4638e-02]],\n",
            "\n",
            "         [[ 3.1676e-02,  2.2603e-02, -3.3979e-02],\n",
            "          [ 4.1612e-02, -2.1762e-02,  3.8665e-02],\n",
            "          [-2.3459e-02,  4.1107e-02,  3.5128e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3950e-02,  2.6120e-02, -3.2929e-03],\n",
            "          [-2.4125e-02, -2.5737e-02,  5.4522e-03],\n",
            "          [-4.7810e-03,  2.2527e-02,  3.1083e-02]],\n",
            "\n",
            "         [[-1.9203e-02,  2.7090e-02, -1.2856e-02],\n",
            "          [ 1.1144e-02, -1.1872e-02, -1.6958e-03],\n",
            "          [-8.8707e-03,  3.9133e-02, -3.7278e-02]],\n",
            "\n",
            "         [[ 6.6678e-05,  7.5935e-03,  3.8985e-02],\n",
            "          [-1.1565e-02,  2.6588e-02,  7.1282e-03],\n",
            "          [-7.7244e-04, -1.7343e-02, -1.7969e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.2759e-02, -3.9053e-03,  5.5939e-03],\n",
            "          [ 2.9283e-02, -3.7751e-02, -2.4399e-02],\n",
            "          [ 3.9267e-02, -3.8432e-03, -2.7117e-03]],\n",
            "\n",
            "         [[-2.4115e-02, -1.2373e-02,  7.0158e-03],\n",
            "          [-1.3204e-02, -1.5422e-02, -3.2308e-02],\n",
            "          [ 3.5761e-02,  3.7896e-03, -9.1093e-03]],\n",
            "\n",
            "         [[-6.2177e-03,  2.9657e-02,  3.4316e-02],\n",
            "          [ 3.0699e-02,  1.4934e-02, -4.1098e-02],\n",
            "          [-1.7317e-03,  1.4004e-02,  1.4382e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0111e-02, -3.5862e-02, -2.5062e-02],\n",
            "          [ 4.8388e-03,  1.2111e-02, -3.5889e-02],\n",
            "          [ 1.6245e-02, -4.1156e-02, -1.8622e-02]],\n",
            "\n",
            "         [[-3.3341e-02, -1.9758e-02,  3.0094e-04],\n",
            "          [ 2.3876e-02,  2.3688e-02,  2.3315e-02],\n",
            "          [ 2.3582e-03,  4.3631e-03,  2.0044e-02]],\n",
            "\n",
            "         [[-4.0805e-02, -3.7120e-02, -3.0088e-02],\n",
            "          [ 3.8580e-02,  7.1080e-03,  1.4040e-02],\n",
            "          [-1.4519e-02, -3.9905e-02, -2.8597e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1638e-02,  3.1141e-02, -3.2996e-02],\n",
            "          [ 8.4333e-03,  2.4912e-02,  1.8777e-02],\n",
            "          [ 3.8110e-02,  3.2648e-02, -1.0019e-03]],\n",
            "\n",
            "         [[-2.2781e-02,  3.9737e-02,  7.1907e-03],\n",
            "          [-1.1454e-02, -4.0352e-02, -3.3631e-02],\n",
            "          [ 3.2883e-02, -3.9256e-02, -1.6489e-02]],\n",
            "\n",
            "         [[-4.0147e-02,  3.7998e-02, -4.0049e-02],\n",
            "          [ 1.9114e-02,  2.9573e-03,  1.5236e-02],\n",
            "          [ 3.6886e-02,  2.3650e-02, -2.8547e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2453e-02,  9.5822e-03, -1.4684e-02],\n",
            "          [-1.1130e-02,  2.1838e-02, -4.0668e-02],\n",
            "          [-1.3189e-02,  4.1254e-02, -2.8451e-02]],\n",
            "\n",
            "         [[ 2.4258e-02, -2.6653e-02, -2.2703e-02],\n",
            "          [-3.6418e-02,  3.4895e-04, -1.0133e-02],\n",
            "          [ 1.9606e-02,  1.5474e-02,  4.0977e-02]],\n",
            "\n",
            "         [[-5.2624e-03,  1.9585e-02,  4.0773e-02],\n",
            "          [ 5.1489e-03,  1.2071e-02,  4.0776e-02],\n",
            "          [-2.0658e-02, -3.3209e-02, -2.1050e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.8917e-02, -1.8668e-02, -2.8075e-02],\n",
            "          [ 7.4255e-04,  1.3869e-02, -2.8684e-02],\n",
            "          [-3.5085e-02, -2.0607e-05, -2.4631e-02]],\n",
            "\n",
            "         [[-7.4824e-03,  2.0406e-02,  3.2341e-02],\n",
            "          [-2.0191e-02, -2.6335e-03,  1.9047e-02],\n",
            "          [ 2.5414e-02,  3.9179e-02, -2.9669e-03]],\n",
            "\n",
            "         [[ 2.5274e-02,  3.4753e-02,  1.7887e-03],\n",
            "          [-1.0227e-02, -1.1419e-02,  1.3815e-02],\n",
            "          [ 1.1161e-03,  2.0056e-03,  2.9841e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8780e-02,  1.3506e-02,  1.9257e-02],\n",
            "          [-3.1378e-02,  3.5866e-02,  1.7222e-02],\n",
            "          [-2.8672e-03, -2.2222e-02, -3.9701e-02]],\n",
            "\n",
            "         [[-4.1616e-02,  1.8303e-02,  1.9778e-02],\n",
            "          [-1.5475e-02, -5.9509e-03,  1.1533e-02],\n",
            "          [ 4.1801e-03,  7.4842e-03, -3.1163e-02]],\n",
            "\n",
            "         [[ 1.7050e-02,  2.4647e-02,  1.0670e-02],\n",
            "          [-1.1648e-02,  1.8071e-02,  1.8700e-03],\n",
            "          [-5.3860e-03, -3.5837e-02, -1.4659e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 4.4845e-02,  5.1814e-02,  2.5094e-02],\n",
            "          [-5.0940e-02,  6.9525e-03,  1.9416e-02],\n",
            "          [ 9.1698e-03,  1.0294e-02,  4.6242e-02]],\n",
            "\n",
            "         [[ 1.8505e-02,  4.1254e-02, -2.7769e-02],\n",
            "          [-5.4512e-02,  4.5773e-02, -1.5280e-02],\n",
            "          [-1.3336e-02,  5.0188e-03, -2.3383e-02]],\n",
            "\n",
            "         [[-2.9420e-02, -3.4579e-02,  1.7685e-02],\n",
            "          [ 1.7587e-02,  2.8300e-02,  2.8041e-02],\n",
            "          [-5.8184e-02,  5.8773e-02, -2.9748e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8611e-02, -5.6831e-02, -3.4493e-02],\n",
            "          [ 2.5253e-02, -2.7943e-02,  4.5936e-02],\n",
            "          [-1.9361e-02, -3.0206e-02,  4.3610e-02]],\n",
            "\n",
            "         [[-3.7867e-02, -3.2880e-02, -8.0507e-03],\n",
            "          [ 3.6842e-02, -1.5953e-02, -1.3127e-02],\n",
            "          [-4.5143e-02,  7.3322e-03, -8.5680e-03]],\n",
            "\n",
            "         [[-3.4480e-02, -5.1687e-02, -1.3282e-02],\n",
            "          [-5.1667e-02,  4.6060e-02,  5.7014e-02],\n",
            "          [ 4.0191e-02, -3.9747e-02,  5.0055e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2470e-02,  2.8320e-02,  5.5024e-02],\n",
            "          [ 3.6899e-02, -1.0550e-02, -4.9516e-02],\n",
            "          [-3.3447e-02,  8.9503e-03,  1.3158e-02]],\n",
            "\n",
            "         [[-5.2048e-02,  3.4606e-02, -4.6034e-02],\n",
            "          [ 5.0106e-02,  1.2395e-02, -1.1686e-03],\n",
            "          [-2.0854e-02, -9.6232e-03,  3.4844e-02]],\n",
            "\n",
            "         [[ 4.4797e-02,  3.1965e-02, -4.8054e-02],\n",
            "          [ 5.8849e-02, -3.0777e-02,  5.4680e-02],\n",
            "          [-3.3176e-02,  5.8135e-02,  4.9679e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8018e-02, -2.8994e-02, -1.9422e-02],\n",
            "          [-4.2067e-02,  4.9561e-02,  2.3140e-02],\n",
            "          [-3.1462e-02, -5.2222e-02, -2.3686e-02]],\n",
            "\n",
            "         [[ 2.6994e-02,  9.5118e-03,  4.8858e-02],\n",
            "          [-5.1181e-02, -2.8469e-02, -5.3310e-02],\n",
            "          [ 8.7096e-03, -4.6548e-02, -4.4055e-02]],\n",
            "\n",
            "         [[-2.0991e-02,  1.5334e-02, -2.1385e-05],\n",
            "          [-4.1707e-02, -2.3136e-02,  5.4723e-02],\n",
            "          [ 4.3699e-02, -2.4382e-02,  4.2242e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6010e-02,  4.3814e-02, -1.2413e-02],\n",
            "          [ 1.4332e-02,  2.2193e-02,  4.1069e-02],\n",
            "          [ 5.7213e-02,  5.2797e-02,  4.5663e-03]],\n",
            "\n",
            "         [[ 3.8029e-02,  1.2206e-02,  4.8959e-03],\n",
            "          [-2.0712e-02, -9.2328e-03, -5.3781e-02],\n",
            "          [ 5.6189e-02, -4.4071e-02,  3.2018e-02]],\n",
            "\n",
            "         [[-3.9593e-02,  2.4511e-02, -3.7413e-02],\n",
            "          [-2.7640e-02, -1.7677e-02, -4.9695e-02],\n",
            "          [ 3.8388e-02,  2.2945e-02,  3.6923e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1702e-02, -5.3557e-02,  6.4093e-03],\n",
            "          [ 1.3410e-03,  6.7015e-04, -3.5026e-02],\n",
            "          [-2.9028e-02, -5.0844e-02,  3.7384e-02]],\n",
            "\n",
            "         [[-3.0373e-02,  1.5145e-02, -4.7163e-02],\n",
            "          [ 4.8873e-02, -5.2805e-02,  5.1437e-02],\n",
            "          [ 3.3870e-02, -4.1796e-02, -3.0026e-02]],\n",
            "\n",
            "         [[ 5.5603e-02, -5.5660e-02, -3.8751e-02],\n",
            "          [-3.9777e-02, -3.9544e-03,  4.7205e-02],\n",
            "          [-4.0660e-02, -5.1045e-02,  1.9755e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.4225e-03,  5.8966e-03, -5.2181e-02],\n",
            "          [ 1.2877e-02,  2.1004e-02,  1.3849e-02],\n",
            "          [-4.5653e-02,  4.2465e-02,  4.4422e-02]],\n",
            "\n",
            "         [[ 4.0491e-02, -2.8070e-02, -1.0315e-02],\n",
            "          [-3.4855e-02,  1.6074e-03,  4.2435e-02],\n",
            "          [-2.5890e-02, -5.4121e-02,  4.9705e-02]],\n",
            "\n",
            "         [[ 2.6590e-02, -3.9334e-02,  1.9364e-02],\n",
            "          [ 1.3269e-02, -3.1462e-02, -1.2197e-02],\n",
            "          [-1.9240e-02, -2.5462e-02, -3.7559e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8641e-02,  5.1524e-03,  4.0639e-02],\n",
            "          [ 1.4711e-02, -5.1846e-02, -1.3381e-02],\n",
            "          [-1.2564e-02,  4.3656e-02,  2.9459e-02]],\n",
            "\n",
            "         [[ 2.5456e-02, -2.1583e-02, -1.7562e-03],\n",
            "          [-2.9417e-03,  1.4950e-02, -4.5875e-02],\n",
            "          [-1.3552e-02, -3.3755e-02, -1.1766e-02]],\n",
            "\n",
            "         [[-5.7903e-02, -9.0666e-03, -3.3530e-02],\n",
            "          [ 1.6275e-02,  2.2725e-02,  4.1409e-02],\n",
            "          [ 3.3421e-02, -4.1847e-02, -3.3518e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8453e-02,  3.0810e-02, -4.1492e-02],\n",
            "          [-4.9423e-04, -1.5643e-02, -9.2124e-05],\n",
            "          [ 3.8616e-02,  5.6951e-02, -8.8304e-03]],\n",
            "\n",
            "         [[-3.4053e-02,  5.7430e-02, -5.2374e-02],\n",
            "          [ 7.4370e-03,  4.7341e-02, -1.1173e-02],\n",
            "          [-2.9683e-02,  4.2699e-02,  1.0138e-02]],\n",
            "\n",
            "         [[ 1.4564e-02,  4.0759e-02,  3.0126e-02],\n",
            "          [-4.3103e-02,  3.3635e-02, -3.7708e-03],\n",
            "          [-4.5272e-02,  4.4780e-02,  3.5606e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9362e-03, -4.5270e-02,  3.2289e-02],\n",
            "          [-1.6807e-02, -4.4908e-03, -3.3104e-02],\n",
            "          [-3.9801e-02, -1.2665e-02, -8.7887e-03]],\n",
            "\n",
            "         [[ 5.3640e-02,  4.6053e-02,  2.0436e-03],\n",
            "          [-1.4994e-03, -4.7443e-02,  3.9075e-02],\n",
            "          [-1.6432e-02, -5.1907e-02, -2.9914e-02]],\n",
            "\n",
            "         [[ 2.9734e-03,  1.2944e-02,  3.5550e-03],\n",
            "          [ 4.5563e-02, -4.2431e-03, -5.0833e-02],\n",
            "          [ 6.6308e-03,  4.3820e-02, -4.6857e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7160e-02, -4.5592e-02,  2.1544e-02],\n",
            "          [ 1.9051e-02,  2.2201e-02, -5.4873e-02],\n",
            "          [ 4.6079e-02,  4.9803e-02, -5.8571e-02]],\n",
            "\n",
            "         [[ 5.2928e-02, -5.1257e-03,  5.3019e-02],\n",
            "          [-2.8608e-02,  5.2892e-02, -1.0667e-02],\n",
            "          [-2.4313e-02, -7.1462e-03,  2.9066e-02]],\n",
            "\n",
            "         [[ 4.2359e-02,  2.2497e-02, -5.1829e-02],\n",
            "          [-5.7952e-02,  2.0746e-02, -5.8498e-02],\n",
            "          [-1.8216e-02, -3.7258e-03, -5.3728e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8317e-03, -4.4953e-02,  5.4703e-02],\n",
            "          [-4.5709e-02,  4.0591e-02, -1.4609e-02],\n",
            "          [-3.5994e-02, -2.0875e-02,  4.4330e-02]],\n",
            "\n",
            "         [[ 2.5360e-02, -5.0337e-02, -1.6996e-02],\n",
            "          [ 4.8848e-02,  1.2624e-02, -3.9590e-02],\n",
            "          [-4.1340e-02,  3.8589e-02,  4.0635e-02]],\n",
            "\n",
            "         [[-2.7707e-02, -4.9222e-02,  6.5755e-03],\n",
            "          [ 2.0375e-02, -3.3991e-02,  1.6203e-02],\n",
            "          [ 1.3942e-02,  5.4028e-02, -5.4231e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 2.2422e-02,  2.5907e-02,  1.2547e-02],\n",
            "          [-2.5470e-02,  3.4762e-03,  9.7079e-03],\n",
            "          [ 4.5849e-03,  5.1468e-03,  2.3121e-02]],\n",
            "\n",
            "         [[ 9.2524e-03,  2.0627e-02, -1.3884e-02],\n",
            "          [-2.7256e-02,  2.2886e-02, -7.6401e-03],\n",
            "          [-6.6680e-03,  2.5094e-03, -1.1691e-02]],\n",
            "\n",
            "         [[-1.4710e-02, -1.7290e-02,  8.8423e-03],\n",
            "          [ 8.7933e-03,  1.4150e-02,  1.4020e-02],\n",
            "          [-2.9092e-02,  2.9387e-02, -1.4874e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9305e-02, -2.8416e-02, -1.7246e-02],\n",
            "          [ 1.2627e-02, -1.3971e-02,  2.2968e-02],\n",
            "          [-9.6803e-03, -1.5103e-02,  2.1805e-02]],\n",
            "\n",
            "         [[-1.8933e-02, -1.6440e-02, -4.0254e-03],\n",
            "          [ 1.8421e-02, -7.9764e-03, -6.5634e-03],\n",
            "          [-2.2572e-02,  3.6661e-03, -4.2840e-03]],\n",
            "\n",
            "         [[-1.7240e-02, -2.5844e-02, -6.6410e-03],\n",
            "          [-2.5834e-02,  2.3030e-02,  2.8507e-02],\n",
            "          [ 2.0095e-02, -1.9873e-02,  2.5028e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.2349e-03,  1.4160e-02,  2.7512e-02],\n",
            "          [ 1.8449e-02, -5.2749e-03, -2.4758e-02],\n",
            "          [-1.6723e-02,  4.4752e-03,  6.5790e-03]],\n",
            "\n",
            "         [[-2.6024e-02,  1.7303e-02, -2.3017e-02],\n",
            "          [ 2.5053e-02,  6.1977e-03, -5.8432e-04],\n",
            "          [-1.0427e-02, -4.8116e-03,  1.7422e-02]],\n",
            "\n",
            "         [[ 2.2399e-02,  1.5983e-02, -2.4027e-02],\n",
            "          [ 2.9424e-02, -1.5388e-02,  2.7340e-02],\n",
            "          [-1.6588e-02,  2.9067e-02,  2.4839e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9009e-02, -1.4497e-02, -9.7111e-03],\n",
            "          [-2.1034e-02,  2.4781e-02,  1.1570e-02],\n",
            "          [-1.5731e-02, -2.6111e-02, -1.1843e-02]],\n",
            "\n",
            "         [[ 1.3497e-02,  4.7559e-03,  2.4429e-02],\n",
            "          [-2.5590e-02, -1.4234e-02, -2.6655e-02],\n",
            "          [ 4.3548e-03, -2.3274e-02, -2.2027e-02]],\n",
            "\n",
            "         [[-1.0496e-02,  7.6671e-03, -1.0693e-05],\n",
            "          [-2.0853e-02, -1.1568e-02,  2.7362e-02],\n",
            "          [ 2.1849e-02, -1.2191e-02,  2.1121e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.3005e-02,  2.1907e-02, -6.2067e-03],\n",
            "          [ 7.1661e-03,  1.1097e-02,  2.0534e-02],\n",
            "          [ 2.8607e-02,  2.6399e-02,  2.2831e-03]],\n",
            "\n",
            "         [[ 1.9014e-02,  6.1028e-03,  2.4479e-03],\n",
            "          [-1.0356e-02, -4.6164e-03, -2.6890e-02],\n",
            "          [ 2.8095e-02, -2.2036e-02,  1.6009e-02]],\n",
            "\n",
            "         [[-1.9797e-02,  1.2256e-02, -1.8706e-02],\n",
            "          [-1.3820e-02, -8.8387e-03, -2.4848e-02],\n",
            "          [ 1.9194e-02,  1.1472e-02,  1.8461e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5851e-02, -2.6779e-02,  3.2047e-03],\n",
            "          [ 6.7052e-04,  3.3507e-04, -1.7513e-02],\n",
            "          [-1.4514e-02, -2.5422e-02,  1.8692e-02]],\n",
            "\n",
            "         [[-1.5186e-02,  7.5726e-03, -2.3581e-02],\n",
            "          [ 2.4436e-02, -2.6403e-02,  2.5719e-02],\n",
            "          [ 1.6935e-02, -2.0898e-02, -1.5013e-02]],\n",
            "\n",
            "         [[ 2.7802e-02, -2.7830e-02, -1.9375e-02],\n",
            "          [-1.9889e-02, -1.9772e-03,  2.3602e-02],\n",
            "          [-2.0330e-02, -2.5522e-02,  9.8773e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.2112e-03,  2.9483e-03, -2.6090e-02],\n",
            "          [ 6.4383e-03,  1.0502e-02,  6.9247e-03],\n",
            "          [-2.2827e-02,  2.1233e-02,  2.2211e-02]],\n",
            "\n",
            "         [[ 2.0246e-02, -1.4035e-02, -5.1574e-03],\n",
            "          [-1.7428e-02,  8.0372e-04,  2.1218e-02],\n",
            "          [-1.2945e-02, -2.7060e-02,  2.4852e-02]],\n",
            "\n",
            "         [[ 1.3295e-02, -1.9667e-02,  9.6822e-03],\n",
            "          [ 6.6344e-03, -1.5731e-02, -6.0987e-03],\n",
            "          [-9.6199e-03, -1.2731e-02, -1.8779e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9321e-02,  2.5762e-03,  2.0320e-02],\n",
            "          [ 7.3555e-03, -2.5923e-02, -6.6904e-03],\n",
            "          [-6.2819e-03,  2.1828e-02,  1.4729e-02]],\n",
            "\n",
            "         [[ 1.2728e-02, -1.0792e-02, -8.7812e-04],\n",
            "          [-1.4708e-03,  7.4752e-03, -2.2938e-02],\n",
            "          [-6.7758e-03, -1.6877e-02, -5.8832e-03]],\n",
            "\n",
            "         [[-2.8951e-02, -4.5333e-03, -1.6765e-02],\n",
            "          [ 8.1373e-03,  1.1363e-02,  2.0705e-02],\n",
            "          [ 1.6711e-02, -2.0924e-02, -1.6759e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9227e-02,  1.5405e-02, -2.0746e-02],\n",
            "          [-2.4711e-04, -7.8213e-03, -4.6062e-05],\n",
            "          [ 1.9308e-02,  2.8476e-02, -4.4152e-03]],\n",
            "\n",
            "         [[-1.7026e-02,  2.8715e-02, -2.6187e-02],\n",
            "          [ 3.7185e-03,  2.3671e-02, -5.5866e-03],\n",
            "          [-1.4842e-02,  2.1350e-02,  5.0688e-03]],\n",
            "\n",
            "         [[ 7.2821e-03,  2.0379e-02,  1.5063e-02],\n",
            "          [-2.1552e-02,  1.6818e-02, -1.8854e-03],\n",
            "          [-2.2636e-02,  2.2390e-02,  1.7803e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.9681e-03, -2.2635e-02,  1.6144e-02],\n",
            "          [-8.4033e-03, -2.2454e-03, -1.6552e-02],\n",
            "          [-1.9900e-02, -6.3325e-03, -4.3944e-03]],\n",
            "\n",
            "         [[ 2.6820e-02,  2.3026e-02,  1.0218e-03],\n",
            "          [-7.4970e-04, -2.3721e-02,  1.9538e-02],\n",
            "          [-8.2158e-03, -2.5953e-02, -1.4957e-02]],\n",
            "\n",
            "         [[ 1.4867e-03,  6.4721e-03,  1.7775e-03],\n",
            "          [ 2.2781e-02, -2.1216e-03, -2.5416e-02],\n",
            "          [ 3.3154e-03,  2.1910e-02, -2.3428e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5801e-03, -2.2796e-02,  1.0772e-02],\n",
            "          [ 9.5253e-03,  1.1100e-02, -2.7436e-02],\n",
            "          [ 2.3039e-02,  2.4901e-02, -2.9285e-02]],\n",
            "\n",
            "         [[ 2.6464e-02, -2.5628e-03,  2.6510e-02],\n",
            "          [-1.4304e-02,  2.6446e-02, -5.3335e-03],\n",
            "          [-1.2157e-02, -3.5731e-03,  1.4533e-02]],\n",
            "\n",
            "         [[ 2.1180e-02,  1.1249e-02, -2.5914e-02],\n",
            "          [-2.8976e-02,  1.0373e-02, -2.9249e-02],\n",
            "          [-9.1081e-03, -1.8629e-03, -2.6864e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.1585e-04, -2.2477e-02,  2.7352e-02],\n",
            "          [-2.2855e-02,  2.0296e-02, -7.3043e-03],\n",
            "          [-1.7997e-02, -1.0437e-02,  2.2165e-02]],\n",
            "\n",
            "         [[ 1.2680e-02, -2.5169e-02, -8.4982e-03],\n",
            "          [ 2.4424e-02,  6.3120e-03, -1.9795e-02],\n",
            "          [-2.0670e-02,  1.9294e-02,  2.0317e-02]],\n",
            "\n",
            "         [[-1.3853e-02, -2.4611e-02,  3.2878e-03],\n",
            "          [ 1.0187e-02, -1.6995e-02,  8.1016e-03],\n",
            "          [ 6.9710e-03,  2.7014e-02, -2.7116e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 1.9418e-02,  2.2436e-02,  1.0866e-02],\n",
            "          [-2.2058e-02,  3.0105e-03,  8.4073e-03],\n",
            "          [ 3.9706e-03,  4.4572e-03,  2.0023e-02]],\n",
            "\n",
            "         [[ 8.0129e-03,  1.7864e-02, -1.2024e-02],\n",
            "          [-2.3604e-02,  1.9820e-02, -6.6165e-03],\n",
            "          [-5.7747e-03,  2.1732e-03, -1.0125e-02]],\n",
            "\n",
            "         [[-1.2739e-02, -1.4973e-02,  7.6577e-03],\n",
            "          [ 7.6152e-03,  1.2254e-02,  1.2142e-02],\n",
            "          [-2.5194e-02,  2.5449e-02, -1.2881e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5123e-02, -1.2555e-02, -8.4101e-03],\n",
            "          [-1.8216e-02,  2.1461e-02,  1.0020e-02],\n",
            "          [-1.3623e-02, -2.2613e-02, -1.0256e-02]],\n",
            "\n",
            "         [[ 1.1689e-02,  4.1187e-03,  2.1156e-02],\n",
            "          [-2.2162e-02, -1.2327e-02, -2.3084e-02],\n",
            "          [ 3.7713e-03, -2.0156e-02, -1.9076e-02]],\n",
            "\n",
            "         [[-9.0895e-03,  6.6399e-03, -9.2600e-06],\n",
            "          [-1.8059e-02, -1.0018e-02,  2.3696e-02],\n",
            "          [ 1.8922e-02, -1.0558e-02,  1.8291e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9923e-02,  1.8972e-02, -5.3751e-03],\n",
            "          [ 6.2060e-03,  9.6099e-03,  1.7783e-02],\n",
            "          [ 2.4774e-02,  2.2862e-02,  1.9772e-03]],\n",
            "\n",
            "         [[ 1.6467e-02,  5.2852e-03,  2.1200e-03],\n",
            "          [-8.9686e-03, -3.9979e-03, -2.3288e-02],\n",
            "          [ 2.4331e-02, -1.9083e-02,  1.3864e-02]],\n",
            "\n",
            "         [[-1.7144e-02,  1.0614e-02, -1.6200e-02],\n",
            "          [-1.1968e-02, -7.6545e-03, -2.1519e-02],\n",
            "          [ 1.6622e-02,  9.9354e-03,  1.5988e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5532e-03,  5.5162e-03,  2.2438e-02],\n",
            "          [-5.2952e-04,  6.0305e-03, -1.9347e-02],\n",
            "          [-7.1844e-03, -2.5350e-02,  6.4293e-03]],\n",
            "\n",
            "         [[ 5.6110e-04,  1.7873e-02,  2.9161e-03],\n",
            "          [ 5.9827e-03, -1.1958e-02,  1.6452e-02],\n",
            "          [ 1.0894e-02,  1.8592e-02, -7.3609e-03]],\n",
            "\n",
            "         [[-9.8439e-03,  1.2798e-02, -1.2116e-02],\n",
            "          [-1.6322e-02, -2.4927e-02,  1.7279e-02],\n",
            "          [-1.9452e-02,  2.3898e-02,  1.0367e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.7261e-03,  3.2239e-03, -3.8240e-03],\n",
            "          [-1.4618e-02, -2.0673e-02,  2.6474e-03],\n",
            "          [ 2.3666e-02, -7.7527e-03,  1.6703e-02]],\n",
            "\n",
            "         [[ 5.4446e-03, -2.0056e-02,  1.1919e-02],\n",
            "          [ 2.4070e-02,  1.3055e-02,  7.5409e-03],\n",
            "          [ 2.4379e-02, -1.0493e-02, -3.7355e-03]],\n",
            "\n",
            "         [[ 1.7356e-02, -7.0822e-03, -1.7125e-02],\n",
            "          [ 2.1443e-02,  1.2825e-02, -1.7417e-02],\n",
            "          [-9.8088e-03, -8.1646e-03, -5.1392e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6548e-03, -2.0493e-02, -2.3682e-02],\n",
            "          [ 6.1891e-03,  4.3905e-03,  5.5676e-04],\n",
            "          [-2.1339e-03,  2.1845e-03,  2.2021e-03]],\n",
            "\n",
            "         [[ 1.3727e-03,  8.1400e-04,  2.3482e-02],\n",
            "          [ 1.3169e-02,  2.4825e-02,  1.4014e-02],\n",
            "          [-5.1866e-03, -6.9157e-03, -2.5065e-02]],\n",
            "\n",
            "         [[ 1.2348e-02,  4.2818e-03, -1.6565e-02],\n",
            "          [-1.3449e-02,  2.0257e-02, -5.6973e-03],\n",
            "          [-1.9683e-02,  9.1907e-03, -4.1826e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4486e-02,  2.4080e-02,  8.9872e-03],\n",
            "          [-9.8901e-03, -8.5381e-03, -1.4673e-02],\n",
            "          [ 1.4513e-02,  1.3736e-02,  3.1022e-03]],\n",
            "\n",
            "         [[ 2.1312e-03, -1.6245e-03, -6.0728e-03],\n",
            "          [-1.7882e-03, -1.4505e-02, -1.8643e-02],\n",
            "          [-1.4159e-02, -1.9761e-02, -1.9291e-03]],\n",
            "\n",
            "         [[ 8.3926e-03, -1.1816e-03, -1.4055e-03],\n",
            "          [-9.4168e-03, -1.5861e-02, -5.9180e-03],\n",
            "          [ 4.4754e-03, -1.9528e-02, -6.3413e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4897e-03, -2.6907e-04, -7.5718e-03],\n",
            "          [-2.1725e-02,  6.7425e-03,  6.5060e-03],\n",
            "          [-4.6834e-04, -1.4008e-02, -2.0583e-02]],\n",
            "\n",
            "         [[-6.3640e-04,  1.7243e-02, -1.4627e-02],\n",
            "          [-4.6118e-03, -1.2100e-02,  4.2745e-03],\n",
            "          [ 1.7266e-02,  1.0979e-02,  9.4358e-03]],\n",
            "\n",
            "         [[-1.3317e-02,  1.3472e-02,  5.2924e-03],\n",
            "          [-2.4383e-02,  1.0932e-02,  4.9484e-03],\n",
            "          [-1.8592e-02, -1.3917e-02, -2.4307e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0075e-02, -2.4037e-03, -1.7149e-02],\n",
            "          [ 5.6013e-03,  6.6462e-04,  1.6778e-02],\n",
            "          [-1.9758e-02,  1.5468e-02, -2.0466e-02]],\n",
            "\n",
            "         [[-1.1458e-02,  9.7341e-03, -1.1136e-02],\n",
            "          [ 1.4908e-03,  1.8266e-02,  1.3727e-02],\n",
            "          [-6.8782e-03,  1.0342e-04, -7.2181e-03]],\n",
            "\n",
            "         [[-2.4661e-02, -2.0726e-02, -7.1855e-03],\n",
            "          [-1.5941e-02,  9.5535e-03,  2.3179e-02],\n",
            "          [ 1.1575e-02,  3.9184e-03, -2.3550e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3134e-02,  1.7768e-02,  2.3761e-02],\n",
            "          [ 2.3992e-02,  2.1643e-02,  1.6617e-02],\n",
            "          [ 3.3297e-03, -1.1240e-02,  1.1079e-02]],\n",
            "\n",
            "         [[ 2.4046e-02, -5.1523e-03,  9.3083e-03],\n",
            "          [ 1.9743e-02, -1.0902e-02, -2.7816e-03],\n",
            "          [ 1.0701e-02, -1.6276e-02, -1.5705e-02]],\n",
            "\n",
            "         [[ 8.2027e-03,  1.1091e-02,  1.3847e-02],\n",
            "          [-1.1058e-02, -3.7134e-03, -4.0717e-03],\n",
            "          [ 9.4203e-03,  4.1429e-03, -6.5186e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.4610e-02,  2.3450e-02, -6.8661e-03],\n",
            "          [ 7.4763e-03, -2.4373e-02, -1.3816e-02],\n",
            "          [-3.3717e-03,  1.9845e-02, -1.7222e-02]],\n",
            "\n",
            "         [[-4.3553e-03, -5.8362e-03, -2.5045e-02],\n",
            "          [-2.0971e-02,  2.5230e-02, -1.8925e-02],\n",
            "          [ 5.7844e-03, -1.9974e-02, -1.2245e-02]],\n",
            "\n",
            "         [[-4.5670e-03, -2.4255e-02, -2.2740e-02],\n",
            "          [ 1.7771e-02, -2.2311e-02, -1.9162e-02],\n",
            "          [ 2.1118e-02, -5.1721e-03, -2.0334e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3835e-02,  6.0042e-03,  1.1660e-02],\n",
            "          [-1.8193e-02,  1.7197e-03, -9.1749e-03],\n",
            "          [ 5.9905e-03,  2.4834e-02, -1.7811e-02]],\n",
            "\n",
            "         [[-1.9852e-02, -4.5635e-03, -9.9507e-04],\n",
            "          [ 2.3334e-03, -2.1448e-02, -2.0054e-02],\n",
            "          [ 1.3109e-02,  1.8304e-02, -6.5293e-03]],\n",
            "\n",
            "         [[ 1.9108e-02, -1.2034e-02, -1.0975e-02],\n",
            "          [ 4.1844e-04,  2.4048e-04,  1.9689e-02],\n",
            "          [ 1.0571e-02,  7.2097e-03,  2.2302e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 1.9418e-02,  2.2436e-02,  1.0866e-02],\n",
            "          [-2.2058e-02,  3.0105e-03,  8.4073e-03],\n",
            "          [ 3.9706e-03,  4.4572e-03,  2.0023e-02]],\n",
            "\n",
            "         [[ 8.0129e-03,  1.7864e-02, -1.2024e-02],\n",
            "          [-2.3604e-02,  1.9820e-02, -6.6165e-03],\n",
            "          [-5.7747e-03,  2.1732e-03, -1.0125e-02]],\n",
            "\n",
            "         [[-1.2739e-02, -1.4973e-02,  7.6577e-03],\n",
            "          [ 7.6152e-03,  1.2254e-02,  1.2142e-02],\n",
            "          [-2.5194e-02,  2.5449e-02, -1.2881e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5123e-02, -1.2555e-02, -8.4101e-03],\n",
            "          [-1.8216e-02,  2.1461e-02,  1.0020e-02],\n",
            "          [-1.3623e-02, -2.2613e-02, -1.0256e-02]],\n",
            "\n",
            "         [[ 1.1689e-02,  4.1187e-03,  2.1156e-02],\n",
            "          [-2.2162e-02, -1.2327e-02, -2.3084e-02],\n",
            "          [ 3.7713e-03, -2.0156e-02, -1.9076e-02]],\n",
            "\n",
            "         [[-9.0895e-03,  6.6399e-03, -9.2600e-06],\n",
            "          [-1.8059e-02, -1.0018e-02,  2.3696e-02],\n",
            "          [ 1.8922e-02, -1.0558e-02,  1.8291e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9923e-02,  1.8972e-02, -5.3751e-03],\n",
            "          [ 6.2060e-03,  9.6099e-03,  1.7783e-02],\n",
            "          [ 2.4774e-02,  2.2862e-02,  1.9772e-03]],\n",
            "\n",
            "         [[ 1.6467e-02,  5.2852e-03,  2.1200e-03],\n",
            "          [-8.9686e-03, -3.9979e-03, -2.3288e-02],\n",
            "          [ 2.4331e-02, -1.9083e-02,  1.3864e-02]],\n",
            "\n",
            "         [[-1.7144e-02,  1.0614e-02, -1.6200e-02],\n",
            "          [-1.1968e-02, -7.6545e-03, -2.1519e-02],\n",
            "          [ 1.6622e-02,  9.9354e-03,  1.5988e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5532e-03,  5.5162e-03,  2.2438e-02],\n",
            "          [-5.2952e-04,  6.0305e-03, -1.9347e-02],\n",
            "          [-7.1844e-03, -2.5350e-02,  6.4293e-03]],\n",
            "\n",
            "         [[ 5.6110e-04,  1.7873e-02,  2.9161e-03],\n",
            "          [ 5.9827e-03, -1.1958e-02,  1.6452e-02],\n",
            "          [ 1.0894e-02,  1.8592e-02, -7.3609e-03]],\n",
            "\n",
            "         [[-9.8439e-03,  1.2798e-02, -1.2116e-02],\n",
            "          [-1.6322e-02, -2.4927e-02,  1.7279e-02],\n",
            "          [-1.9452e-02,  2.3898e-02,  1.0367e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.7261e-03,  3.2239e-03, -3.8240e-03],\n",
            "          [-1.4618e-02, -2.0673e-02,  2.6474e-03],\n",
            "          [ 2.3666e-02, -7.7527e-03,  1.6703e-02]],\n",
            "\n",
            "         [[ 5.4446e-03, -2.0056e-02,  1.1919e-02],\n",
            "          [ 2.4070e-02,  1.3055e-02,  7.5409e-03],\n",
            "          [ 2.4379e-02, -1.0493e-02, -3.7355e-03]],\n",
            "\n",
            "         [[ 1.7356e-02, -7.0822e-03, -1.7125e-02],\n",
            "          [ 2.1443e-02,  1.2825e-02, -1.7417e-02],\n",
            "          [-9.8088e-03, -8.1646e-03, -5.1392e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6548e-03, -2.0493e-02, -2.3682e-02],\n",
            "          [ 6.1891e-03,  4.3905e-03,  5.5676e-04],\n",
            "          [-2.1339e-03,  2.1845e-03,  2.2021e-03]],\n",
            "\n",
            "         [[ 1.3727e-03,  8.1400e-04,  2.3482e-02],\n",
            "          [ 1.3169e-02,  2.4825e-02,  1.4014e-02],\n",
            "          [-5.1866e-03, -6.9157e-03, -2.5065e-02]],\n",
            "\n",
            "         [[ 1.2348e-02,  4.2818e-03, -1.6565e-02],\n",
            "          [-1.3449e-02,  2.0257e-02, -5.6973e-03],\n",
            "          [-1.9683e-02,  9.1907e-03, -4.1826e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4486e-02,  2.4080e-02,  8.9872e-03],\n",
            "          [-9.8901e-03, -8.5381e-03, -1.4673e-02],\n",
            "          [ 1.4513e-02,  1.3736e-02,  3.1022e-03]],\n",
            "\n",
            "         [[ 2.1312e-03, -1.6245e-03, -6.0728e-03],\n",
            "          [-1.7882e-03, -1.4505e-02, -1.8643e-02],\n",
            "          [-1.4159e-02, -1.9761e-02, -1.9291e-03]],\n",
            "\n",
            "         [[ 8.3926e-03, -1.1816e-03, -1.4055e-03],\n",
            "          [-9.4168e-03, -1.5861e-02, -5.9180e-03],\n",
            "          [ 4.4754e-03, -1.9528e-02, -6.3413e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4897e-03, -2.6907e-04, -7.5718e-03],\n",
            "          [-2.1725e-02,  6.7425e-03,  6.5060e-03],\n",
            "          [-4.6834e-04, -1.4008e-02, -2.0583e-02]],\n",
            "\n",
            "         [[-6.3640e-04,  1.7243e-02, -1.4627e-02],\n",
            "          [-4.6118e-03, -1.2100e-02,  4.2745e-03],\n",
            "          [ 1.7266e-02,  1.0979e-02,  9.4358e-03]],\n",
            "\n",
            "         [[-1.3317e-02,  1.3472e-02,  5.2924e-03],\n",
            "          [-2.4383e-02,  1.0932e-02,  4.9484e-03],\n",
            "          [-1.8592e-02, -1.3917e-02, -2.4307e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0075e-02, -2.4037e-03, -1.7149e-02],\n",
            "          [ 5.6013e-03,  6.6462e-04,  1.6778e-02],\n",
            "          [-1.9758e-02,  1.5468e-02, -2.0466e-02]],\n",
            "\n",
            "         [[-1.1458e-02,  9.7341e-03, -1.1136e-02],\n",
            "          [ 1.4908e-03,  1.8266e-02,  1.3727e-02],\n",
            "          [-6.8782e-03,  1.0342e-04, -7.2181e-03]],\n",
            "\n",
            "         [[-2.4661e-02, -2.0726e-02, -7.1855e-03],\n",
            "          [-1.5941e-02,  9.5535e-03,  2.3179e-02],\n",
            "          [ 1.1575e-02,  3.9184e-03, -2.3550e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3134e-02,  1.7768e-02,  2.3761e-02],\n",
            "          [ 2.3992e-02,  2.1643e-02,  1.6617e-02],\n",
            "          [ 3.3297e-03, -1.1240e-02,  1.1079e-02]],\n",
            "\n",
            "         [[ 2.4046e-02, -5.1523e-03,  9.3083e-03],\n",
            "          [ 1.9743e-02, -1.0902e-02, -2.7816e-03],\n",
            "          [ 1.0701e-02, -1.6276e-02, -1.5705e-02]],\n",
            "\n",
            "         [[ 8.2027e-03,  1.1091e-02,  1.3847e-02],\n",
            "          [-1.1058e-02, -3.7134e-03, -4.0717e-03],\n",
            "          [ 9.4203e-03,  4.1429e-03, -6.5186e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.4610e-02,  2.3450e-02, -6.8661e-03],\n",
            "          [ 7.4763e-03, -2.4373e-02, -1.3816e-02],\n",
            "          [-3.3717e-03,  1.9845e-02, -1.7222e-02]],\n",
            "\n",
            "         [[-4.3553e-03, -5.8362e-03, -2.5045e-02],\n",
            "          [-2.0971e-02,  2.5230e-02, -1.8925e-02],\n",
            "          [ 5.7844e-03, -1.9974e-02, -1.2245e-02]],\n",
            "\n",
            "         [[-4.5670e-03, -2.4255e-02, -2.2740e-02],\n",
            "          [ 1.7771e-02, -2.2311e-02, -1.9162e-02],\n",
            "          [ 2.1118e-02, -5.1721e-03, -2.0334e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3835e-02,  6.0042e-03,  1.1660e-02],\n",
            "          [-1.8193e-02,  1.7197e-03, -9.1749e-03],\n",
            "          [ 5.9905e-03,  2.4834e-02, -1.7811e-02]],\n",
            "\n",
            "         [[-1.9852e-02, -4.5635e-03, -9.9507e-04],\n",
            "          [ 2.3334e-03, -2.1448e-02, -2.0054e-02],\n",
            "          [ 1.3109e-02,  1.8304e-02, -6.5293e-03]],\n",
            "\n",
            "         [[ 1.9108e-02, -1.2034e-02, -1.0975e-02],\n",
            "          [ 4.1844e-04,  2.4048e-04,  1.9689e-02],\n",
            "          [ 1.0571e-02,  7.2097e-03,  2.2302e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 3.8837e-02,  4.4872e-02,  2.1732e-02],\n",
            "          [-4.4116e-02,  6.0210e-03,  1.6815e-02],\n",
            "          [ 7.9413e-03,  8.9145e-03,  4.0046e-02]],\n",
            "\n",
            "         [[ 1.6026e-02,  3.5727e-02, -2.4048e-02],\n",
            "          [-4.7208e-02,  3.9640e-02, -1.3233e-02],\n",
            "          [-1.1549e-02,  4.3464e-03, -2.0250e-02]],\n",
            "\n",
            "         [[-2.5479e-02, -2.9946e-02,  1.5315e-02],\n",
            "          [ 1.5230e-02,  2.4508e-02,  2.4284e-02],\n",
            "          [-5.0388e-02,  5.0899e-02, -2.5762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0245e-02, -2.5110e-02, -1.6820e-02],\n",
            "          [-3.6431e-02,  4.2921e-02,  2.0040e-02],\n",
            "          [-2.7246e-02, -4.5226e-02, -2.0512e-02]],\n",
            "\n",
            "         [[ 2.3377e-02,  8.2374e-03,  4.2312e-02],\n",
            "          [-4.4324e-02, -2.4655e-02, -4.6167e-02],\n",
            "          [ 7.5427e-03, -4.0312e-02, -3.8153e-02]],\n",
            "\n",
            "         [[-1.8179e-02,  1.3280e-02, -1.8520e-05],\n",
            "          [-3.6119e-02, -2.0036e-02,  4.7392e-02],\n",
            "          [ 3.7844e-02, -2.1115e-02,  3.6583e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9846e-02,  3.7944e-02, -1.0750e-02],\n",
            "          [ 1.2412e-02,  1.9220e-02,  3.5566e-02],\n",
            "          [ 4.9548e-02,  4.5724e-02,  3.9545e-03]],\n",
            "\n",
            "         [[ 3.2934e-02,  1.0570e-02,  4.2400e-03],\n",
            "          [-1.7937e-02, -7.9959e-03, -4.6575e-02],\n",
            "          [ 4.8661e-02, -3.8167e-02,  2.7729e-02]],\n",
            "\n",
            "         [[-3.4289e-02,  2.1227e-02, -3.2400e-02],\n",
            "          [-2.3937e-02, -1.5309e-02, -4.3037e-02],\n",
            "          [ 3.3245e-02,  1.9871e-02,  3.1976e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1064e-03,  1.1032e-02,  4.4876e-02],\n",
            "          [-1.0590e-03,  1.2061e-02, -3.8695e-02],\n",
            "          [-1.4369e-02, -5.0699e-02,  1.2859e-02]],\n",
            "\n",
            "         [[ 1.1222e-03,  3.5747e-02,  5.8323e-03],\n",
            "          [ 1.1965e-02, -2.3916e-02,  3.2904e-02],\n",
            "          [ 2.1788e-02,  3.7185e-02, -1.4722e-02]],\n",
            "\n",
            "         [[-1.9688e-02,  2.5597e-02, -2.4231e-02],\n",
            "          [-3.2644e-02, -4.9854e-02,  3.4559e-02],\n",
            "          [-3.8903e-02,  4.7797e-02,  2.0734e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.9452e-02,  6.4478e-03, -7.6480e-03],\n",
            "          [-2.9237e-02, -4.1347e-02,  5.2949e-03],\n",
            "          [ 4.7332e-02, -1.5505e-02,  3.3406e-02]],\n",
            "\n",
            "         [[ 1.0889e-02, -4.0113e-02,  2.3837e-02],\n",
            "          [ 4.8141e-02,  2.6111e-02,  1.5082e-02],\n",
            "          [ 4.8758e-02, -2.0986e-02, -7.4710e-03]],\n",
            "\n",
            "         [[ 3.4711e-02, -1.4164e-02, -3.4251e-02],\n",
            "          [ 4.2885e-02,  2.5650e-02, -3.4835e-02],\n",
            "          [-1.9618e-02, -1.6329e-02, -1.0278e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3096e-03, -4.0985e-02, -4.7364e-02],\n",
            "          [ 1.2378e-02,  8.7809e-03,  1.1135e-03],\n",
            "          [-4.2678e-03,  4.3690e-03,  4.4042e-03]],\n",
            "\n",
            "         [[ 2.7454e-03,  1.6280e-03,  4.6964e-02],\n",
            "          [ 2.6337e-02,  4.9649e-02,  2.8029e-02],\n",
            "          [-1.0373e-02, -1.3831e-02, -5.0130e-02]],\n",
            "\n",
            "         [[ 2.4697e-02,  8.5635e-03, -3.3131e-02],\n",
            "          [-2.6898e-02,  4.0514e-02, -1.1395e-02],\n",
            "          [-3.9366e-02,  1.8381e-02, -8.3652e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8972e-02,  4.8161e-02,  1.7974e-02],\n",
            "          [-1.9780e-02, -1.7076e-02, -2.9347e-02],\n",
            "          [ 2.9026e-02,  2.7472e-02,  6.2044e-03]],\n",
            "\n",
            "         [[ 4.2625e-03, -3.2490e-03, -1.2146e-02],\n",
            "          [-3.5764e-03, -2.9010e-02, -3.7285e-02],\n",
            "          [-2.8318e-02, -3.9522e-02, -3.8583e-03]],\n",
            "\n",
            "         [[ 1.6785e-02, -2.3633e-03, -2.8109e-03],\n",
            "          [-1.8834e-02, -3.1722e-02, -1.1836e-02],\n",
            "          [ 8.9508e-03, -3.9055e-02, -1.2683e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9794e-03, -5.3815e-04, -1.5144e-02],\n",
            "          [-4.3449e-02,  1.3485e-02,  1.3012e-02],\n",
            "          [-9.3669e-04, -2.8015e-02, -4.1166e-02]],\n",
            "\n",
            "         [[-1.2728e-03,  3.4486e-02, -2.9254e-02],\n",
            "          [-9.2236e-03, -2.4199e-02,  8.5491e-03],\n",
            "          [ 3.4533e-02,  2.1959e-02,  1.8872e-02]],\n",
            "\n",
            "         [[-2.6633e-02,  2.6943e-02,  1.0585e-02],\n",
            "          [-4.8765e-02,  2.1864e-02,  9.8968e-03],\n",
            "          [-3.7183e-02, -2.7835e-02, -4.8615e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.0150e-02, -4.8074e-03, -3.4299e-02],\n",
            "          [ 1.1203e-02,  1.3292e-03,  3.3555e-02],\n",
            "          [-3.9516e-02,  3.0937e-02, -4.0933e-02]],\n",
            "\n",
            "         [[-2.2916e-02,  1.9468e-02, -2.2272e-02],\n",
            "          [ 2.9815e-03,  3.6532e-02,  2.7453e-02],\n",
            "          [-1.3756e-02,  2.0684e-04, -1.4436e-02]],\n",
            "\n",
            "         [[-4.9322e-02, -4.1452e-02, -1.4371e-02],\n",
            "          [-3.1882e-02,  1.9107e-02,  4.6358e-02],\n",
            "          [ 2.3150e-02,  7.8368e-03, -4.7099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6268e-02,  3.5536e-02,  4.7522e-02],\n",
            "          [ 4.7985e-02,  4.3286e-02,  3.3235e-02],\n",
            "          [ 6.6593e-03, -2.2479e-02,  2.2158e-02]],\n",
            "\n",
            "         [[ 4.8092e-02, -1.0305e-02,  1.8617e-02],\n",
            "          [ 3.9486e-02, -2.1804e-02, -5.5632e-03],\n",
            "          [ 2.1402e-02, -3.2551e-02, -3.1410e-02]],\n",
            "\n",
            "         [[ 1.6405e-02,  2.2181e-02,  2.7693e-02],\n",
            "          [-2.2116e-02, -7.4268e-03, -8.1434e-03],\n",
            "          [ 1.8841e-02,  8.2857e-03, -1.3037e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9220e-02,  4.6899e-02, -1.3732e-02],\n",
            "          [ 1.4953e-02, -4.8745e-02, -2.7631e-02],\n",
            "          [-6.7435e-03,  3.9691e-02, -3.4445e-02]],\n",
            "\n",
            "         [[-8.7106e-03, -1.1672e-02, -5.0089e-02],\n",
            "          [-4.1942e-02,  5.0460e-02, -3.7850e-02],\n",
            "          [ 1.1569e-02, -3.9948e-02, -2.4491e-02]],\n",
            "\n",
            "         [[-9.1340e-03, -4.8509e-02, -4.5480e-02],\n",
            "          [ 3.5541e-02, -4.4621e-02, -3.8324e-02],\n",
            "          [ 4.2235e-02, -1.0344e-02, -4.0667e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7669e-02,  1.2008e-02,  2.3320e-02],\n",
            "          [-3.6385e-02,  3.4395e-03, -1.8350e-02],\n",
            "          [ 1.1981e-02,  4.9668e-02, -3.5621e-02]],\n",
            "\n",
            "         [[-3.9704e-02, -9.1269e-03, -1.9901e-03],\n",
            "          [ 4.6669e-03, -4.2897e-02, -4.0107e-02],\n",
            "          [ 2.6219e-02,  3.6608e-02, -1.3059e-02]],\n",
            "\n",
            "         [[ 3.8215e-02, -2.4067e-02, -2.1949e-02],\n",
            "          [ 8.3687e-04,  4.8096e-04,  3.9378e-02],\n",
            "          [ 2.1142e-02,  1.4419e-02,  4.4604e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[[[ 1.9418e-02,  2.2436e-02,  1.0866e-02],\n",
            "          [-2.2058e-02,  3.0105e-03,  8.4073e-03],\n",
            "          [ 3.9706e-03,  4.4572e-03,  2.0023e-02]],\n",
            "\n",
            "         [[ 8.0129e-03,  1.7864e-02, -1.2024e-02],\n",
            "          [-2.3604e-02,  1.9820e-02, -6.6165e-03],\n",
            "          [-5.7747e-03,  2.1732e-03, -1.0125e-02]],\n",
            "\n",
            "         [[-1.2739e-02, -1.4973e-02,  7.6577e-03],\n",
            "          [ 7.6152e-03,  1.2254e-02,  1.2142e-02],\n",
            "          [-2.5194e-02,  2.5449e-02, -1.2881e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5123e-02, -1.2555e-02, -8.4101e-03],\n",
            "          [-1.8216e-02,  2.1461e-02,  1.0020e-02],\n",
            "          [-1.3623e-02, -2.2613e-02, -1.0256e-02]],\n",
            "\n",
            "         [[ 1.1689e-02,  4.1187e-03,  2.1156e-02],\n",
            "          [-2.2162e-02, -1.2327e-02, -2.3084e-02],\n",
            "          [ 3.7713e-03, -2.0156e-02, -1.9076e-02]],\n",
            "\n",
            "         [[-9.0895e-03,  6.6399e-03, -9.2600e-06],\n",
            "          [-1.8059e-02, -1.0018e-02,  2.3696e-02],\n",
            "          [ 1.8922e-02, -1.0558e-02,  1.8291e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9923e-02,  1.8972e-02, -5.3751e-03],\n",
            "          [ 6.2060e-03,  9.6099e-03,  1.7783e-02],\n",
            "          [ 2.4774e-02,  2.2862e-02,  1.9772e-03]],\n",
            "\n",
            "         [[ 1.6467e-02,  5.2852e-03,  2.1200e-03],\n",
            "          [-8.9686e-03, -3.9979e-03, -2.3288e-02],\n",
            "          [ 2.4331e-02, -1.9083e-02,  1.3864e-02]],\n",
            "\n",
            "         [[-1.7144e-02,  1.0614e-02, -1.6200e-02],\n",
            "          [-1.1968e-02, -7.6545e-03, -2.1519e-02],\n",
            "          [ 1.6622e-02,  9.9354e-03,  1.5988e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5532e-03,  5.5162e-03,  2.2438e-02],\n",
            "          [-5.2952e-04,  6.0305e-03, -1.9347e-02],\n",
            "          [-7.1844e-03, -2.5350e-02,  6.4293e-03]],\n",
            "\n",
            "         [[ 5.6110e-04,  1.7873e-02,  2.9161e-03],\n",
            "          [ 5.9827e-03, -1.1958e-02,  1.6452e-02],\n",
            "          [ 1.0894e-02,  1.8592e-02, -7.3609e-03]],\n",
            "\n",
            "         [[-9.8439e-03,  1.2798e-02, -1.2116e-02],\n",
            "          [-1.6322e-02, -2.4927e-02,  1.7279e-02],\n",
            "          [-1.9452e-02,  2.3898e-02,  1.0367e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.7261e-03,  3.2239e-03, -3.8240e-03],\n",
            "          [-1.4618e-02, -2.0673e-02,  2.6474e-03],\n",
            "          [ 2.3666e-02, -7.7527e-03,  1.6703e-02]],\n",
            "\n",
            "         [[ 5.4446e-03, -2.0056e-02,  1.1919e-02],\n",
            "          [ 2.4070e-02,  1.3055e-02,  7.5409e-03],\n",
            "          [ 2.4379e-02, -1.0493e-02, -3.7355e-03]],\n",
            "\n",
            "         [[ 1.7356e-02, -7.0822e-03, -1.7125e-02],\n",
            "          [ 2.1443e-02,  1.2825e-02, -1.7417e-02],\n",
            "          [-9.8088e-03, -8.1646e-03, -5.1392e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6548e-03, -2.0493e-02, -2.3682e-02],\n",
            "          [ 6.1891e-03,  4.3905e-03,  5.5676e-04],\n",
            "          [-2.1339e-03,  2.1845e-03,  2.2021e-03]],\n",
            "\n",
            "         [[ 1.3727e-03,  8.1400e-04,  2.3482e-02],\n",
            "          [ 1.3169e-02,  2.4825e-02,  1.4014e-02],\n",
            "          [-5.1866e-03, -6.9157e-03, -2.5065e-02]],\n",
            "\n",
            "         [[ 1.2348e-02,  4.2818e-03, -1.6565e-02],\n",
            "          [-1.3449e-02,  2.0257e-02, -5.6973e-03],\n",
            "          [-1.9683e-02,  9.1907e-03, -4.1826e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4486e-02,  2.4080e-02,  8.9872e-03],\n",
            "          [-9.8901e-03, -8.5381e-03, -1.4673e-02],\n",
            "          [ 1.4513e-02,  1.3736e-02,  3.1022e-03]],\n",
            "\n",
            "         [[ 2.1312e-03, -1.6245e-03, -6.0728e-03],\n",
            "          [-1.7882e-03, -1.4505e-02, -1.8643e-02],\n",
            "          [-1.4159e-02, -1.9761e-02, -1.9291e-03]],\n",
            "\n",
            "         [[ 8.3926e-03, -1.1816e-03, -1.4055e-03],\n",
            "          [-9.4168e-03, -1.5861e-02, -5.9180e-03],\n",
            "          [ 4.4754e-03, -1.9528e-02, -6.3413e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4897e-03, -2.6907e-04, -7.5718e-03],\n",
            "          [-2.1725e-02,  6.7425e-03,  6.5060e-03],\n",
            "          [-4.6834e-04, -1.4008e-02, -2.0583e-02]],\n",
            "\n",
            "         [[-6.3640e-04,  1.7243e-02, -1.4627e-02],\n",
            "          [-4.6118e-03, -1.2100e-02,  4.2745e-03],\n",
            "          [ 1.7266e-02,  1.0979e-02,  9.4358e-03]],\n",
            "\n",
            "         [[-1.3317e-02,  1.3472e-02,  5.2924e-03],\n",
            "          [-2.4383e-02,  1.0932e-02,  4.9484e-03],\n",
            "          [-1.8592e-02, -1.3917e-02, -2.4307e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0075e-02, -2.4037e-03, -1.7149e-02],\n",
            "          [ 5.6013e-03,  6.6462e-04,  1.6778e-02],\n",
            "          [-1.9758e-02,  1.5468e-02, -2.0466e-02]],\n",
            "\n",
            "         [[-1.1458e-02,  9.7341e-03, -1.1136e-02],\n",
            "          [ 1.4908e-03,  1.8266e-02,  1.3727e-02],\n",
            "          [-6.8782e-03,  1.0342e-04, -7.2181e-03]],\n",
            "\n",
            "         [[-2.4661e-02, -2.0726e-02, -7.1855e-03],\n",
            "          [-1.5941e-02,  9.5535e-03,  2.3179e-02],\n",
            "          [ 1.1575e-02,  3.9184e-03, -2.3550e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3134e-02,  1.7768e-02,  2.3761e-02],\n",
            "          [ 2.3992e-02,  2.1643e-02,  1.6617e-02],\n",
            "          [ 3.3297e-03, -1.1240e-02,  1.1079e-02]],\n",
            "\n",
            "         [[ 2.4046e-02, -5.1523e-03,  9.3083e-03],\n",
            "          [ 1.9743e-02, -1.0902e-02, -2.7816e-03],\n",
            "          [ 1.0701e-02, -1.6276e-02, -1.5705e-02]],\n",
            "\n",
            "         [[ 8.2027e-03,  1.1091e-02,  1.3847e-02],\n",
            "          [-1.1058e-02, -3.7134e-03, -4.0717e-03],\n",
            "          [ 9.4203e-03,  4.1429e-03, -6.5186e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.4610e-02,  2.3450e-02, -6.8661e-03],\n",
            "          [ 7.4763e-03, -2.4373e-02, -1.3816e-02],\n",
            "          [-3.3717e-03,  1.9845e-02, -1.7222e-02]],\n",
            "\n",
            "         [[-4.3553e-03, -5.8362e-03, -2.5045e-02],\n",
            "          [-2.0971e-02,  2.5230e-02, -1.8925e-02],\n",
            "          [ 5.7844e-03, -1.9974e-02, -1.2245e-02]],\n",
            "\n",
            "         [[-4.5670e-03, -2.4255e-02, -2.2740e-02],\n",
            "          [ 1.7771e-02, -2.2311e-02, -1.9162e-02],\n",
            "          [ 2.1118e-02, -5.1721e-03, -2.0334e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3835e-02,  6.0042e-03,  1.1660e-02],\n",
            "          [-1.8193e-02,  1.7197e-03, -9.1749e-03],\n",
            "          [ 5.9905e-03,  2.4834e-02, -1.7811e-02]],\n",
            "\n",
            "         [[-1.9852e-02, -4.5635e-03, -9.9507e-04],\n",
            "          [ 2.3334e-03, -2.1448e-02, -2.0054e-02],\n",
            "          [ 1.3109e-02,  1.8304e-02, -6.5293e-03]],\n",
            "\n",
            "         [[ 1.9108e-02, -1.2034e-02, -1.0975e-02],\n",
            "          [ 4.1844e-04,  2.4048e-04,  1.9689e-02],\n",
            "          [ 1.0571e-02,  7.2097e-03,  2.2302e-02]]]], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1345,  0.1554,  0.0753,  ...,  0.1563,  0.0141,  0.0370],\n",
            "        [ 0.0776,  0.0739,  0.0299,  ..., -0.0886, -0.0994,  0.0869],\n",
            "        [-0.1707, -0.1056,  0.0217,  ..., -0.1671, -0.1686,  0.1544],\n",
            "        ...,\n",
            "        [ 0.1737, -0.1332,  0.1021,  ...,  0.0214, -0.1230,  0.1506],\n",
            "        [ 0.0612,  0.0354, -0.0323,  ..., -0.0069,  0.1272, -0.1179],\n",
            "        [ 0.0882, -0.1238, -0.0774,  ...,  0.0117,  0.1326,  0.1735]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.0673,  0.0777,  0.0376,  ...,  0.0781,  0.0071,  0.0185],\n",
            "        [ 0.0388,  0.0370,  0.0150,  ..., -0.0443, -0.0497,  0.0435],\n",
            "        [-0.0854, -0.0528,  0.0109,  ..., -0.0835, -0.0843,  0.0772],\n",
            "        ...,\n",
            "        [ 0.0869, -0.0666,  0.0511,  ...,  0.0107, -0.0615,  0.0753],\n",
            "        [ 0.0306,  0.0177, -0.0162,  ..., -0.0034,  0.0636, -0.0590],\n",
            "        [ 0.0441, -0.0619, -0.0387,  ...,  0.0059,  0.0663,  0.0868]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1903,  0.2198,  0.1065,  ..., -0.0110, -0.2199,  0.1569],\n",
            "        [ 0.2459,  0.1016, -0.0850,  ...,  0.2210,  0.0200,  0.0523],\n",
            "        [ 0.1097,  0.1046,  0.0423,  ..., -0.2061,  0.1741,  0.1329],\n",
            "        ...,\n",
            "        [-0.2453,  0.0792, -0.2213,  ...,  0.0881, -0.0387, -0.1407],\n",
            "        [-0.2055, -0.2485,  0.1241,  ...,  0.1913, -0.1581, -0.0015],\n",
            "        [ 0.0482,  0.0903, -0.2478,  ..., -0.1664,  0.2418, -0.0021]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.0951,  0.1099,  0.0532,  ..., -0.0055, -0.1099,  0.0785],\n",
            "        [ 0.1230,  0.0508, -0.0425,  ...,  0.1105,  0.0100,  0.0261],\n",
            "        [ 0.0549,  0.0523,  0.0212,  ..., -0.1031,  0.0870,  0.0664],\n",
            "        ...,\n",
            "        [-0.1227,  0.0396, -0.1106,  ...,  0.0440, -0.0193, -0.0704],\n",
            "        [-0.1027, -0.1243,  0.0620,  ...,  0.0956, -0.0790, -0.0008],\n",
            "        [ 0.0241,  0.0452, -0.1239,  ..., -0.0832,  0.1209, -0.0011]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050], device='cuda:0',\n",
            "       dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2876,  0.3324,  0.1610, -0.3267,  0.0446,  0.1245,  0.0588,  0.0660,\n",
            "          0.2966,  0.1187,  0.2646, -0.1781, -0.3497,  0.2936, -0.0980, -0.0855,\n",
            "          0.0322, -0.1500, -0.1887, -0.2218,  0.1134,  0.1128,  0.1815,  0.1799,\n",
            "         -0.3732,  0.3770, -0.1908, -0.0666,  0.2940,  0.1676, -0.1132,  0.3359],\n",
            "        [ 0.2693,  0.2526,  0.0457,  0.3344,  0.1400,  0.3594, -0.0472, -0.2504,\n",
            "         -0.0024, -0.0601, -0.1412, -0.1225,  0.2946, -0.3243,  0.1717,  0.3388,\n",
            "          0.3514, -0.0440, -0.0156,  0.0179, -0.1082,  0.1496, -0.0065, -0.3410,\n",
            "          0.0617,  0.3029,  0.2283, -0.0619, -0.3415, -0.0166, -0.3324,  0.2373],\n",
            "        [ 0.3718,  0.1536, -0.1285,  0.1325,  0.2936, -0.3619, -0.3065,  0.3395,\n",
            "          0.2661,  0.0847, -0.0894,  0.1175, -0.0485,  0.3726, -0.0551,  0.1704,\n",
            "          0.2330, -0.0829,  0.1621, -0.2405,  0.0042, -0.2313,  0.0014, -0.0303,\n",
            "         -0.3615,  0.0199, -0.1888, -0.1070, -0.3523, -0.3042, -0.2639,  0.1346],\n",
            "        [ 0.0220,  0.2461,  0.1544,  0.2919, -0.0088,  0.3688, -0.2728, -0.0831,\n",
            "          0.0794, -0.3264, -0.2222,  0.1773, -0.2044,  0.0425,  0.2537,  0.3493,\n",
            "         -0.1775, -0.3320, -0.1200,  0.1926,  0.0255,  0.1778, -0.2897, -0.3766,\n",
            "         -0.2204,  0.1639, -0.1122,  0.3449,  0.1931,  0.3341,  0.0302,  0.0791],\n",
            "        [ 0.1659,  0.1581,  0.0640, -0.2330,  0.1653, -0.1465,  0.1987,  0.1287,\n",
            "         -0.0574,  0.2905,  0.3487,  0.2831, -0.2610,  0.3678, -0.0913,  0.1569,\n",
            "          0.0292, -0.2788, -0.1731, -0.2915,  0.2259,  0.1612,  0.3578, -0.3176,\n",
            "         -0.0024,  0.2828,  0.3750,  0.3640, -0.1596, -0.2755, -0.1410,  0.2619],\n",
            "        [-0.1277,  0.0303,  0.1724, -0.2758, -0.0612,  0.1635,  0.2044, -0.2215,\n",
            "          0.3003, -0.0222,  0.1329, -0.0526,  0.1186, -0.0493,  0.1521, -0.1209,\n",
            "         -0.3676,  0.1067, -0.2567, -0.3178,  0.1740, -0.1226,  0.2126, -0.1293,\n",
            "          0.3338, -0.0593,  0.0644,  0.3663, -0.3504, -0.3116,  0.2632,  0.2009],\n",
            "        [ 0.3360,  0.1896,  0.1881,  0.2605, -0.2705, -0.3571,  0.1134,  0.3317,\n",
            "          0.2843,  0.1291,  0.0860,  0.3087,  0.3420,  0.1620,  0.3090, -0.0063,\n",
            "         -0.0511, -0.0883,  0.0013, -0.1205,  0.2943, -0.0929, -0.0650,  0.1938,\n",
            "          0.2806, -0.2008,  0.0719,  0.1736, -0.3436,  0.2210, -0.2587, -0.0619],\n",
            "        [-0.2896, -0.0970,  0.2001, -0.1918, -0.2368, -0.3368, -0.3487, -0.2831,\n",
            "         -0.0249,  0.1367, -0.2578, -0.3531, -0.0714, -0.0308,  0.0823,  0.3769,\n",
            "          0.1515, -0.3381, -0.0591,  0.2992, -0.2515,  0.1517, -0.0268,  0.1605,\n",
            "         -0.1250,  0.2620, -0.2167,  0.2611,  0.0937, -0.1894, -0.2125,  0.1859],\n",
            "        [-0.3650, -0.2258,  0.0464,  0.0498,  0.0715, -0.2203, -0.2623,  0.0038,\n",
            "         -0.0955,  0.3286, -0.3669, -0.0968, -0.2665,  0.0145,  0.0523,  0.1307,\n",
            "         -0.0229,  0.2240,  0.3240, -0.0756, -0.0784,  0.0360, -0.1680,  0.0904,\n",
            "          0.1639,  0.3041,  0.3191, -0.1143,  0.1315, -0.2486,  0.1517,  0.3695],\n",
            "        [-0.1322,  0.2391, -0.3609,  0.2071,  0.0586,  0.3114,  0.0107,  0.2996,\n",
            "          0.0325, -0.2288, -0.1049,  0.3442, -0.2632,  0.3412,  0.1935,  0.0880,\n",
            "          0.1062, -0.1627, -0.3035,  0.0522,  0.2958,  0.3057,  0.0758, -0.2122,\n",
            "         -0.0681,  0.2893, -0.2608,  0.3305, -0.3759, -0.1999,  0.3105,  0.1000]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.1438,  0.1662,  0.0805, -0.1634,  0.0223,  0.0623,  0.0294,  0.0330,\n",
            "          0.1483,  0.0593,  0.1323, -0.0891, -0.1748,  0.1468, -0.0490, -0.0428,\n",
            "          0.0161, -0.0750, -0.0944, -0.1109,  0.0567,  0.0564,  0.0908,  0.0899,\n",
            "         -0.1866,  0.1885, -0.0954, -0.0333,  0.1470,  0.0838, -0.0566,  0.1679],\n",
            "        [ 0.1346,  0.1263,  0.0228,  0.1672,  0.0700,  0.1797, -0.0236, -0.1252,\n",
            "         -0.0012, -0.0300, -0.0706, -0.0612,  0.1473, -0.1621,  0.0858,  0.1694,\n",
            "          0.1757, -0.0220, -0.0078,  0.0090, -0.0541,  0.0748, -0.0032, -0.1705,\n",
            "          0.0309,  0.1514,  0.1141, -0.0310, -0.1708, -0.0083, -0.1662,  0.1186],\n",
            "        [ 0.1859,  0.0768, -0.0642,  0.0662,  0.1468, -0.1810, -0.1532,  0.1697,\n",
            "          0.1330,  0.0423, -0.0447,  0.0587, -0.0243,  0.1863, -0.0276,  0.0852,\n",
            "          0.1165, -0.0414,  0.0810, -0.1202,  0.0021, -0.1156,  0.0007, -0.0151,\n",
            "         -0.1808,  0.0100, -0.0944, -0.0535, -0.1762, -0.1521, -0.1320,  0.0673],\n",
            "        [ 0.0110,  0.1231,  0.0772,  0.1459, -0.0044,  0.1844, -0.1364, -0.0416,\n",
            "          0.0397, -0.1632, -0.1111,  0.0887, -0.1022,  0.0213,  0.1269,  0.1746,\n",
            "         -0.0888, -0.1660, -0.0600,  0.0963,  0.0127,  0.0889, -0.1449, -0.1883,\n",
            "         -0.1102,  0.0820, -0.0561,  0.1724,  0.0965,  0.1671,  0.0151,  0.0395],\n",
            "        [ 0.0830,  0.0790,  0.0320, -0.1165,  0.0826, -0.0733,  0.0993,  0.0644,\n",
            "         -0.0287,  0.1453,  0.1744,  0.1415, -0.1305,  0.1839, -0.0457,  0.0785,\n",
            "          0.0146, -0.1394, -0.0865, -0.1457,  0.1129,  0.0806,  0.1789, -0.1588,\n",
            "         -0.0012,  0.1414,  0.1875,  0.1820, -0.0798, -0.1378, -0.0705,  0.1310],\n",
            "        [-0.0638,  0.0152,  0.0862, -0.1379, -0.0306,  0.0818,  0.1022, -0.1108,\n",
            "          0.1501, -0.0111,  0.0665, -0.0263,  0.0593, -0.0247,  0.0761, -0.0605,\n",
            "         -0.1838,  0.0534, -0.1284, -0.1589,  0.0870, -0.0613,  0.1063, -0.0647,\n",
            "          0.1669, -0.0296,  0.0322,  0.1832, -0.1752, -0.1558,  0.1316,  0.1005],\n",
            "        [ 0.1680,  0.0948,  0.0940,  0.1303, -0.1353, -0.1786,  0.0567,  0.1659,\n",
            "          0.1421,  0.0646,  0.0430,  0.1544,  0.1710,  0.0810,  0.1545, -0.0032,\n",
            "         -0.0256, -0.0442,  0.0007, -0.0602,  0.1471, -0.0464, -0.0325,  0.0969,\n",
            "          0.1403, -0.1004,  0.0360,  0.0868, -0.1718,  0.1105, -0.1294, -0.0309],\n",
            "        [-0.1448, -0.0485,  0.1000, -0.0959, -0.1184, -0.1684, -0.1744, -0.1415,\n",
            "         -0.0125,  0.0683, -0.1289, -0.1765, -0.0357, -0.0154,  0.0412,  0.1884,\n",
            "          0.0758, -0.1690, -0.0296,  0.1496, -0.1257,  0.0758, -0.0134,  0.0802,\n",
            "         -0.0625,  0.1310, -0.1083,  0.1306,  0.0468, -0.0947, -0.1063,  0.0930],\n",
            "        [-0.1825, -0.1129,  0.0232,  0.0249,  0.0358, -0.1102, -0.1312,  0.0019,\n",
            "         -0.0477,  0.1643, -0.1834, -0.0484, -0.1333,  0.0072,  0.0262,  0.0654,\n",
            "         -0.0115,  0.1120,  0.1620, -0.0378, -0.0392,  0.0180, -0.0840,  0.0452,\n",
            "          0.0819,  0.1521,  0.1595, -0.0572,  0.0658, -0.1243,  0.0758,  0.1847],\n",
            "        [-0.0661,  0.1196, -0.1805,  0.1036,  0.0293,  0.1557,  0.0054,  0.1498,\n",
            "          0.0163, -0.1144, -0.0525,  0.1721, -0.1316,  0.1706,  0.0967,  0.0440,\n",
            "          0.0531, -0.0813, -0.1518,  0.0261,  0.1479,  0.1529,  0.0379, -0.1061,\n",
            "         -0.0341,  0.1447, -0.1304,  0.1652, -0.1880, -0.0999,  0.1552,  0.0500]],\n",
            "       device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
            "        0.0050], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "0.5\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.5621,  0.6494,  0.3145, -0.6385,  0.0871,  0.2434,  0.1149,  0.1290,\n",
            "          0.5796,  0.2319]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weights******************** Parameter containing:\n",
            "tensor([[ 0.2810,  0.3247,  0.1573, -0.3192,  0.0436,  0.1217,  0.0575,  0.0645,\n",
            "          0.2898,  0.1160]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0.0050], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Focus(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (dropout1): Dropout2d(p=0.05, inplace=False)\n",
              "  (dropout2): Dropout2d(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9"
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "  def forward(self,x):  \n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I"
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX"
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7"
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_focus = optim.Adam(focus_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "# optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer_classify = optim.Adam(classify.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "# optim.SGD(classify.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylCWkAlwv6EL"
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQASTbrKv586",
        "outputId": "c0af898c-888d-489b-fafb-0bc9abbdeb67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 33 %\n",
            "total correct 9980\n",
            "total train set images 30000\n",
            "focus_true_pred_true 931 =============> FTPT : 3 %\n",
            "focus_false_pred_true 9049 =============> FFPT : 30 %\n",
            "focus_true_pred_false 2052 =============> FTPF : 6 %\n",
            "focus_false_pred_false 17968 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  0\n",
            "argmax_less_than_half ==================>  30000\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZmkgV3cv55D",
        "outputId": "12e4fd41-30e7-43f5-f446-09e4e7bfd11d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 32 %\n",
            "total correct 3274\n",
            "total train set images 10000\n",
            "focus_true_pred_true 325 =============> FTPT : 3 %\n",
            "focus_false_pred_true 2949 =============> FFPT : 29 %\n",
            "focus_true_pred_false 733 =============> FTPF : 7 %\n",
            "focus_false_pred_false 5993 =============> FFPF : 59 %\n",
            "argmax_more_than_half ==================>  0\n",
            "argmax_less_than_half ==================>  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFfAJZkcZEsY",
        "outputId": "e12f2184-4e0f-4ffd-9b09-b9da7d08018c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nos_epochs = 300\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    optimizer_classify.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion(outputs, labels) \n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_focus.step()\n",
        "    optimizer_classify.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    col1.append(epoch+1)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 1.060\n",
            "[1,   120] loss: 0.958\n",
            "[2,    60] loss: 0.884\n",
            "[2,   120] loss: 0.792\n",
            "[3,    60] loss: 0.713\n",
            "[3,   120] loss: 0.644\n",
            "[4,    60] loss: 0.587\n",
            "[4,   120] loss: 0.553\n",
            "[5,    60] loss: 0.506\n",
            "[5,   120] loss: 0.508\n",
            "[6,    60] loss: 0.458\n",
            "[6,   120] loss: 0.432\n",
            "[7,    60] loss: 0.407\n",
            "[7,   120] loss: 0.405\n",
            "[8,    60] loss: 0.358\n",
            "[8,   120] loss: 0.346\n",
            "[9,    60] loss: 0.319\n",
            "[9,   120] loss: 0.332\n",
            "[10,    60] loss: 0.281\n",
            "[10,   120] loss: 0.299\n",
            "[11,    60] loss: 0.261\n",
            "[11,   120] loss: 0.258\n",
            "[12,    60] loss: 0.238\n",
            "[12,   120] loss: 0.240\n",
            "[13,    60] loss: 0.216\n",
            "[13,   120] loss: 0.217\n",
            "[14,    60] loss: 0.192\n",
            "[14,   120] loss: 0.200\n",
            "[15,    60] loss: 0.192\n",
            "[15,   120] loss: 0.179\n",
            "[16,    60] loss: 0.166\n",
            "[16,   120] loss: 0.190\n",
            "[17,    60] loss: 0.158\n",
            "[17,   120] loss: 0.170\n",
            "[18,    60] loss: 0.142\n",
            "[18,   120] loss: 0.147\n",
            "[19,    60] loss: 0.129\n",
            "[19,   120] loss: 0.136\n",
            "[20,    60] loss: 0.114\n",
            "[20,   120] loss: 0.127\n",
            "[21,    60] loss: 0.114\n",
            "[21,   120] loss: 0.115\n",
            "[22,    60] loss: 0.104\n",
            "[22,   120] loss: 0.110\n",
            "[23,    60] loss: 0.092\n",
            "[23,   120] loss: 0.103\n",
            "[24,    60] loss: 0.095\n",
            "[24,   120] loss: 0.100\n",
            "[25,    60] loss: 0.090\n",
            "[25,   120] loss: 0.094\n",
            "[26,    60] loss: 0.087\n",
            "[26,   120] loss: 0.092\n",
            "[27,    60] loss: 0.081\n",
            "[27,   120] loss: 0.089\n",
            "[28,    60] loss: 0.068\n",
            "[28,   120] loss: 0.074\n",
            "[29,    60] loss: 0.063\n",
            "[29,   120] loss: 0.072\n",
            "[30,    60] loss: 0.069\n",
            "[30,   120] loss: 0.075\n",
            "[31,    60] loss: 0.059\n",
            "[31,   120] loss: 0.068\n",
            "[32,    60] loss: 0.073\n",
            "[32,   120] loss: 0.065\n",
            "[33,    60] loss: 0.055\n",
            "[33,   120] loss: 0.065\n",
            "[34,    60] loss: 0.061\n",
            "[34,   120] loss: 0.055\n",
            "[35,    60] loss: 0.057\n",
            "[35,   120] loss: 0.065\n",
            "[36,    60] loss: 0.046\n",
            "[36,   120] loss: 0.058\n",
            "[37,    60] loss: 0.049\n",
            "[37,   120] loss: 0.059\n",
            "[38,    60] loss: 0.046\n",
            "[38,   120] loss: 0.053\n",
            "[39,    60] loss: 0.041\n",
            "[39,   120] loss: 0.050\n",
            "[40,    60] loss: 0.037\n",
            "[40,   120] loss: 0.061\n",
            "[41,    60] loss: 0.040\n",
            "[41,   120] loss: 0.049\n",
            "[42,    60] loss: 0.030\n",
            "[42,   120] loss: 0.041\n",
            "[43,    60] loss: 0.039\n",
            "[43,   120] loss: 0.052\n",
            "[44,    60] loss: 0.036\n",
            "[44,   120] loss: 0.046\n",
            "[45,    60] loss: 0.037\n",
            "[45,   120] loss: 0.046\n",
            "[46,    60] loss: 0.030\n",
            "[46,   120] loss: 0.044\n",
            "[47,    60] loss: 0.045\n",
            "[47,   120] loss: 0.031\n",
            "[48,    60] loss: 0.041\n",
            "[48,   120] loss: 0.032\n",
            "[49,    60] loss: 0.027\n",
            "[49,   120] loss: 0.031\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTQIADTrQED",
        "outputId": "82071934-0a2d-4ec8-efe5-146793942b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "name = \"focus_random_classify_random_train_both_\"+str(k)\n",
        "name"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'focus_random_classify_random_train_both_0.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE"
      },
      "source": [
        "#torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/focus_net_params_multiplied_by_k/\"+name+\".pt\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o"
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO"
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "outputId": "17f2e712-2689-41a0-d74b-45cbed728359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "df_train"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>931</td>\n",
              "      <td>9049</td>\n",
              "      <td>2052</td>\n",
              "      <td>17968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6263</td>\n",
              "      <td>23737</td>\n",
              "      <td>6304</td>\n",
              "      <td>8579</td>\n",
              "      <td>3171</td>\n",
              "      <td>11946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>18705</td>\n",
              "      <td>11295</td>\n",
              "      <td>17988</td>\n",
              "      <td>6414</td>\n",
              "      <td>2021</td>\n",
              "      <td>3577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>21963</td>\n",
              "      <td>8037</td>\n",
              "      <td>21721</td>\n",
              "      <td>5336</td>\n",
              "      <td>1088</td>\n",
              "      <td>1855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>23574</td>\n",
              "      <td>6426</td>\n",
              "      <td>23139</td>\n",
              "      <td>4941</td>\n",
              "      <td>672</td>\n",
              "      <td>1248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>24282</td>\n",
              "      <td>5718</td>\n",
              "      <td>24154</td>\n",
              "      <td>4643</td>\n",
              "      <td>379</td>\n",
              "      <td>824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>24128</td>\n",
              "      <td>5872</td>\n",
              "      <td>24483</td>\n",
              "      <td>4567</td>\n",
              "      <td>292</td>\n",
              "      <td>658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>23939</td>\n",
              "      <td>6061</td>\n",
              "      <td>24696</td>\n",
              "      <td>4684</td>\n",
              "      <td>184</td>\n",
              "      <td>436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>23721</td>\n",
              "      <td>6279</td>\n",
              "      <td>24934</td>\n",
              "      <td>4563</td>\n",
              "      <td>149</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>23716</td>\n",
              "      <td>6284</td>\n",
              "      <td>24981</td>\n",
              "      <td>4594</td>\n",
              "      <td>148</td>\n",
              "      <td>277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>23746</td>\n",
              "      <td>6254</td>\n",
              "      <td>25059</td>\n",
              "      <td>4580</td>\n",
              "      <td>108</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0             0  ...                   2052                   17968\n",
              "1        1          6263  ...                   3171                   11946\n",
              "2        6         18705  ...                   2021                    3577\n",
              "3       11         21963  ...                   1088                    1855\n",
              "4       16         23574  ...                    672                    1248\n",
              "5       21         24282  ...                    379                     824\n",
              "6       26         24128  ...                    292                     658\n",
              "7       31         23939  ...                    184                     436\n",
              "8       36         23721  ...                    149                     354\n",
              "9       41         23716  ...                    148                     277\n",
              "10      46         23746  ...                    108                     253\n",
              "\n",
              "[11 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "outputId": "7c0a3b04-d42a-4f42-8042-817899053266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "outputId": "47096c00-d085-4834-e60f-ae1f758636ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "df_test"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>325</td>\n",
              "      <td>2949</td>\n",
              "      <td>733</td>\n",
              "      <td>5993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4793</td>\n",
              "      <td>5207</td>\n",
              "      <td>3166</td>\n",
              "      <td>2513</td>\n",
              "      <td>836</td>\n",
              "      <td>3485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>5956</td>\n",
              "      <td>4044</td>\n",
              "      <td>5825</td>\n",
              "      <td>2117</td>\n",
              "      <td>887</td>\n",
              "      <td>1171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>7662</td>\n",
              "      <td>2338</td>\n",
              "      <td>6979</td>\n",
              "      <td>1724</td>\n",
              "      <td>378</td>\n",
              "      <td>919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>7518</td>\n",
              "      <td>2482</td>\n",
              "      <td>7398</td>\n",
              "      <td>1597</td>\n",
              "      <td>369</td>\n",
              "      <td>636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>21</td>\n",
              "      <td>7576</td>\n",
              "      <td>2424</td>\n",
              "      <td>7622</td>\n",
              "      <td>1530</td>\n",
              "      <td>249</td>\n",
              "      <td>599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>7999</td>\n",
              "      <td>2001</td>\n",
              "      <td>7930</td>\n",
              "      <td>1367</td>\n",
              "      <td>245</td>\n",
              "      <td>458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>8116</td>\n",
              "      <td>1884</td>\n",
              "      <td>7958</td>\n",
              "      <td>1335</td>\n",
              "      <td>224</td>\n",
              "      <td>483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36</td>\n",
              "      <td>8160</td>\n",
              "      <td>1840</td>\n",
              "      <td>7940</td>\n",
              "      <td>1399</td>\n",
              "      <td>193</td>\n",
              "      <td>468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>41</td>\n",
              "      <td>7414</td>\n",
              "      <td>2586</td>\n",
              "      <td>8011</td>\n",
              "      <td>1341</td>\n",
              "      <td>260</td>\n",
              "      <td>388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>46</td>\n",
              "      <td>7520</td>\n",
              "      <td>2480</td>\n",
              "      <td>7931</td>\n",
              "      <td>1285</td>\n",
              "      <td>255</td>\n",
              "      <td>529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0             0  ...                    733                    5993\n",
              "1        1          4793  ...                    836                    3485\n",
              "2        6          5956  ...                    887                    1171\n",
              "3       11          7662  ...                    378                     919\n",
              "4       16          7518  ...                    369                     636\n",
              "5       21          7576  ...                    249                     599\n",
              "6       26          7999  ...                    245                     458\n",
              "7       31          8116  ...                    224                     483\n",
              "8       36          8160  ...                    193                     468\n",
              "9       41          7414  ...                    260                     388\n",
              "10      46          7520  ...                    255                     529\n",
              "\n",
              "[11 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "outputId": "2ebd0084-3735-4958-81b4-17923536dd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAEWCAYAAABoup70AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c+VPYGQsARkD/uqiEQ2RVuXulWtYhVXUMHuT6t2sf31aW37dNFarbbVioiidaNWq7XuuOECCiruArIICLImCNkmyfX745xAgACZkGQyM9/36zWvmXOfM+fcOZBc93bu29wdERERSR4psc6AiIiItCwFfxERkSSj4C8iIpJkFPxFRESSjIK/iIhIklHwFxERSTIK/iKtjJn1MrNtZpYa67yISGJS8JekYGZTzOxdMys1s3VmdouZ5TfiPLWBufblZra9zvaERpxzhZkdV7vt7p+6e1t3r472XM1l9zyKSHxT8JeEZ2ZXAtcAPwLygLFAb+AZM8uI5lx1AnNbd28bJo+okza3STMvItIMFPwloZlZO+BXwPfc/Ul3j7j7CuBsoBC4IDzuajObbWZ3mdkXZva+mRVFea1MM7vOzD41s8/N7O9mlh3u62Rmj5lZsZltNrO5ZpZiZncDvYD/hC0HPzazwrBFIS387gtm9hszeyXM29Nm1qnOdS8ys5VmtsnM/ndftXQzO9nMPgjPs8bMflhn31fN7O0wj6+a2SFh+h55jOa+iEjro+AviW48kAU8VDfR3bcBjwPH10k+DbgfyAceBf4a5bX+AAwEDgX6A92BX4T7rgRWAwVAF+BnQTb8QuBT4NSw5eDavZz7POBioDOQAfwQwMyGAjcD5wNdCVo2uu8jj7cD33D3XGA48Fx4npHATOAbQEfgVuBRM8uMIo8iEicU/CXRdQI2untVPfvWhvtrvezuj4d97XcDIxp6ETMz4DLgcnff7O5fAL8DJoWHRAiCc++w9WGuR7ewxh3uvtjdy4DZBAUMgLOA/7j7y+5eSVDY2Nd5I8BQM2vn7lvc/c0w/TLgVnef7+7V7j4LqCDoIhGRBKPgL4luI9Cptgl9N13D/bXW1flcCmTt5Xv1KQBygIVhs3kx8GSYDvBHYCnwtJktM7Orovkh6slb7XiDbsCq2h3uXgps2sd5JgInAyvN7EUzGxem9waurM17mP+e4flFJMEo+Euie42gBntm3UQzawucBMxpoutsBMqAYe6eH77yagcFuvsX7n6lu/cl6F64wsyODb97IEtrrgV61G6EYww67u1gd3/D3U8n6D74N0ErAgQFiN/WyXu+u+e4+31NkEcRaWUU/CWhuXsJwYC/v5jZiWaWbmaFBEFvNUHzflNcpwa4DbjBzDoDmFl3Mzsh/PxVM+sfdg+UANVATfj1z4G+jbz0g8CpZjY+fHLhasDqO9DMMszsfDPLc/cIsLVOHm4DvmlmYyzQxsxOMbPcJsijiLQyCv6S8MIBaj8DriMIePMJarrHuntFE17qJwRN+/PMbCvwLDAo3Dcg3N5G0Bpxs7s/H+77PfDzsLn9h0TB3d8HvkcwUHFteP71BK0d9bkQWBHm75sEAwVx9wXANIJBjlvCn2NKne81Oo8i0vpYdGOORKQ1C7szioEB7r481vkRkdZJNX+ROGdmp5pZjpm1IWjdeBdYEdtciUhrpuAvEv9OBz4LXwOASVE+RigiSUbN/iIiIklGNX8REZEk09AJTBJGp06dvLCwMNbZEBGJGwsXLtzo7gX7P1LiRdIF/8LCQhYsWBDrbIiIxA0zWxnrPEjTUrO/iIhIklHwFxERSTIK/iIiIklGwV9ERCTJKPiLiIgkmWYL/mY208zWm9l7ddI6mNkzZrYkfG8fppuZ3WRmS83sHTM7rM53JofHLzGzyXXSR5nZu+F3bgpXSxMREZH9aM6a/53AibulXQXMcfcBBOuoXxWmn0QwLekA4DLgFggKC8AvgTHAaOCXtQWG8Jhpdb63+7VERESkHs0W/N39JWDzbsmnA7PCz7OAr9VJv8sD84B8M+sKnAA84+6b3X0L8AxwYrivnbvPC+cwv6vOuZrjh4EXr4WlzzbbJURERFpKS/f5d3H3teHndUCX8HN3gvXVa60O0/aVvrqe9HqZ2WVmtsDMFmzYsCH6XJvBKzfB0jnRf1dERKSVidmAv7DG3iKrCrn7dHcvcveigoJGzlCZ3R7KtjRtxkRERGKgpYP/52GTPeH7+jB9DdCzznE9wrR9pfeoJ735ZOcr+IuISEJo6eD/KFA7Yn8y8Eid9IvCUf9jgZKwe+Ap4Ctm1j4c6PcV4Klw31YzGxuO8r+ozrmah2r+IiKSIJptYR8zuw/4EtDJzFYTjNr/AzDbzC4FVgJnh4c/DpwMLAVKgYsB3H2zmf0GeCM87tfuXjuI8NsETxRkA0+Er+aT3R7Wf9CslxAREWkJzRb83f3cvew6tp5jHfjOXs4zE5hZT/oCYPiB5DEqqvmLiEiC0Ax/DVUb/L1FxiiKiIg0GwX/hspuDzVVULkt1jkRERE5IAr+DZWdH7yr6V9EROKcgn9DZYezCpcVxzYfIiIiB0jBv6F2BH/V/EVEJL4p+DeUgr+IiCQIBf+GUvAXEZEEoeDfUAr+IiKSIBT8Gyo9G9KyFPxFRCTuKfhHQ7P8iYhIAlDwj0aWVvYTEZH4p+Afjez2UF4S61yIiIgcEAX/aKjZX0REEoCCfzQU/EVEJAEo+EcjW33+IiIS/xT8o5HdHiKlECmPdU5EREQaTcE/GrUT/ZRrcR8REYlfCv7R0Cx/IiKSABT8o5GdH7wr+IuISBxT8I/Gjpq/mv1FRCR+KfhHQ83+IiKSABT8o6HgLyIiCUDBPxqZ7cBSFfxFRCSuKfhHw0wT/YiISNxT8I+WpvgVEZE4p+AfLQV/ERGJcwr+0VLwFxGROKfgH60s9fmLiEh8U/CPVnZ7ze0vIiJxLS3WGYg72e2hvARqqiElNda5EZGQu1NV41RW1RCprqGyqoaKqhoKcjPJStfvqkhdCv7R2rGyXwnkdIhtXkRamfJINSVlEYpLIxSXVlIaqd4lGFdW1VBZvev7nvs8fK8mUu079lVU1xDZ1/eqa3DfM0+5WWmcN6YXU8YX0jUvu+VvikgrFJPgb2aXA1MBB94FLga6AvcDHYGFwIXuXmlmmcBdwChgE3COu68Iz/NT4FKgGvgfd3+q2TNfd5Y/BX9JQO7O9spqiksrKS6N7AzmZXW3K8O0CFvr7C+P1ER9vdQUIyM1hYy0FNJTU8hMCz5npKaQnrZzX15GOhmptnNfmJ5R5/i65wnejZcWb+S2l5Zx+9zlnHJIV6Ye2ZeDe+Q1w50TiR8tHvzNrDvwP8BQdy8zs9nAJOBk4AZ3v9/M/k4Q1G8J37e4e38zmwRcA5xjZkPD7w0DugHPmtlAd69u1h9AU/xKnKiucbaWhcE6DNg7a+VBsC4p3bmvuCxCSRjcq2rqqUKHMtNSyM9JJz87g7ycdHp1yOGQHunk52SQl52+c192OjmZqTsC8u6BOTP8nJpizXofzjm8F6s2l3Lnqyt44I1VPPL2Z4zp04GpE/py7ODOpDTz9UVao1g1+6cB2WYWAXKAtcAxwHnh/lnA1QTB//TwM8CDwF/NzML0+929AlhuZkuB0cBrzZpzBX9phdydlZtKmbdsE68t28TryzeztqR8n9/JzUwjLycI1nnZ6XTNyw626wbwHdsZO46Lx/7znh1y+N+vDuX7xw1g9huruOOVFUy7awGFHXO49Mg+TBzVg5wM9YJK8mjx/+3uvsbMrgM+BcqApwma+YvdvSo8bDXQPfzcHVgVfrfKzEoIuga6A/PqnLrud3ZhZpcBlwH06tXrwH4ABX9pJVZtLuW1TzbtCPi1wb5T20zG9u1A34K2OwN5Tjp52RlhUE+nXXY66anJ97BPu6x0pk7oy5TxhTzx3jpmzF3G/z7yPtc9vZjzx/Ri8vhCurTLinU2RZpdLJr92xPU2vsAxcA/gROb85ruPh2YDlBUVLT39syGyM4P3hX8pYWtKS7bGew/2cSa4jIAOrbJYGzfjozt15FxfTvQr6AtQeOY7E1aagqnjujGVw/pysKVW5gxdzm3vPgJt81dxqmHdOPSCX0Y1k3jAiRxxaKd6zhgubtvADCzh4AjgHwzSwtr/z2ANeHxa4CewGozSwPyCAb+1abXqvud5pNVG/z1rL80r3Ul5by2bGMY8Dfz6eZSAPJz0hnbpyOXHdWXsX07MrCLgn1jmRlFhR0oKuzAyk3bueOVFcxesIqH3lrDuL4dmTqhD18epHEBknhiEfw/BcaaWQ5Bs/+xwALgeeAsghH/k4FHwuMfDbdfC/c/5+5uZo8C95rZ9QQD/gYArzd77lPTgqV9VfOXJrZ+azmvLQtq9vOWbWb5xu0AtMtKY0zfjkwZX8i4fh0Z1CVXwagZ9O7YhqtPG8blxw/k/tc/5c5XV3DprAX0LWjDpUf24cyRPcjOiL/xDiL1Ma/vwdjmvqjZr4BzgCrgLYLH/roTBP4OYdoF7l5hZlnA3cBIYDMwyd2Xhef5f8Al4Xl+4O5P7O/aRUVFvmDBggP7Af58MPQaD2feemDnkaS2cVvFjib8ecs28cmGINjnZqYxuk8HxvXryNi+HRnStV2zj4iXPUWqa3j83bXMmLucd9eU0D4nnQvG9ubCcb3pnJtc4wLMbKG7F8U6H9J0YhL8Y6lJgv+tR0Hbg+D82U2TqQTg7ixaXUKNO53aZNIpN0Ojp3ezeXsl88PBea99sokl67cB0DYzjcML2zO2b0fG9evIsG55CvatiLvz+vLNzHh5Oc9++DnpKSmcdmg3Lj2yD0O6tot19lqEgn/i0V/nxtDKfrtwd657+mP+9vwnu6Rnp6fSsW0GHdtm0qlNxo7PHdtk0KltZrDdJpNObTNo3yYj4UafF5dWMn/55h01+4/WfQFATkYqRYUdOPOwHozt24GDu+eRlmA/eyIxM8b07ciYvh1ZvnE7d7yynH8uWM2DC1dzZP9OTJ3Qh6MHFmjchcQV1fwb459TYN178L0DPE+CuOGZxdw4ZwlnF/XgxOEHsXFbJZu2VbJpWwWbtleycVtFsL09eN/bBDL5Oel0bBMWFsKCwa6Fh2C7U5tM2mWnNcsfW3enoqqGikgN5VXVlEeqqaiqoTxSTXmk9r2a8jAtOLZ6l/3bK6tZtKqYD9dtxR2y0lMo6r2zGf+QHnkJV9BJNsWlldz7+qfMenUFn2+tYEDntlx6ZB++NrJ7XM6DsD+q+SceBf/GeOxy+OBR+PEn+z82wf1lzhL+9Mxivj6qB9dMPGS/A9Hcna1lVWwMCwKbtlWwcXtYUAgLCBvrFByKSyP1nic91ejQZmcBoVPYotChbQbu7AzStQG7NkjXBu3afbsF+Iqq+ueHb4gUg6z0VLLSUxnUJZdx/YJm/EN65JGZlngBQaCyqob/vvsZt720nA/WbqVjm4wd4wI6tc1s0bxU1zjbyqvYWh7M0ri1LMLW8ghby6ooKYtgBlMn9G3UuRX8E4+a/RsjKz9o9neHJG7qu+WFT/jTM4s5c2R3/tCAwA9BE2peTjp5Oen0K9j/NSLVNWzZXhkUCMICw8awYFBbYNi4vZLlG7ezcVvFjrnlzSArLZWs9JQdATkzLYXM9FSy0lLIz8nYuS8tlcwdn8Nj0sPv1u5Lq5MWvmfu8r1U0lNNTb9JJiMthTNG9uBrh3bntWWbmPnycm6cs4RbXvyEMw7tzqUT+jCwS26DzuXubKuoYmt5VRC4w6mZd2zXCeTB58gux35RUbXP83dok9Ho4C+JR8G/MbLbg1dD5TbIbNgvdqKZMXcZ1zz5EaeO6MYfvz6i2Qaopaem0LldFp0bOOtaWWU1KSmQkZqiQCwtxswY368T4/t14pMN25j58nL+9eZqHliwiqMGFvDlQQU7auVby8L3HTX0qh3BfB9LKgDB4NB2WWm0C2dp7J6fzZCuubTLCqZebpedvnP/jrRgu60G4Eod+t/QGHWn+E3C4H/HK8v5v/9+yMkHH8QNZzdf4G8MPYctsdavoC2/PeNgrvzKIO6dv5JZr63kpcUbgGAQbLvstB2BuXNuFv0L6gnWWel7pLXNTNPAUGkyCv6NUTf45x/gWgFx5u55K/nVfz7ghGFduHHSSP0xEtmLDm0y+O4xA/jG0f0oKYvQLiudjDT9vkjroODfGEm6uM99r3/K//77PY4b0pm/nHuYRqyLNEB6akqLD/4T2R/99W6MJAz+/1ywip89/C5fGlTA384/TDUYEZE4pr/gjZFkwf/ht1bz43+9w5H9O/H3C0bpsTURkTin4N8YSbSs76OLPuPK2YsY26cj0y8sSsgJTEREko2Cf2OkZ0NaVsIH//++s5bLH3ibosIO3D6lSCPpRUQShIJ/YyX4/P5Pvb+O79//FiN75jNzyuFapEdEJIEo+DdWdnsoK451LprFnA8/57v3vsnBPfK44+LDaZupwC8ikkgU/BsrQYP/Cx+v51v/eJMhXdsx65LR5GalxzpLIiLSxBT8GysBm/3nLtnAZXcvZECXttx9yRjaKfCLiCQkBf/Gys5PqOD/6icbmTprAX07teEfl44hL0eBX0QkUSn4N1YC1fznL9vEpXcuoHfHHO6ZOob2bTJinSUREWlGCv6Nld0eqsogUhbrnByQBSs2c/Gdb9AtP4t7po6lo6YhFRFJeAr+jZVVO9FP/A76e/PTLUy54w0OapfFfdPGUpCrwC8ikgwU/Bsrzqf4fWd1MZNvf52ObTO4d9pYOrfLinWWRESkhSj4N1Zt8C+Pv5r/e2tKuGDGfPJy0rl32lgOylPgFxFJJgr+jRWnNf8P127lgtvnk5uVzn3TxtI9PzvWWRIRkRam4N9YcRj8F3/+BefPmE9WWir3ThtDzw45sc6SiIjEgIJ/Y8VZ8F+6fhvn3TaftBTjvsvG0rtjm1hnSUREYmS/k7ab2QDg98BQYEfnsLv3bcZ8tX6ZuWCpcRH8l23Yxnm3zQPg3mlj6dNJgV9EJJk1pOZ/B3ALUAV8GbgL+EdzZioumMXFRD8rN23nvNvmU13j3DdtDP07t411lkREJMYaEvyz3X0OYO6+0t2vBk5p3mzFiVY+xe+qzaWcO30eFVXV3DNtDAO65MY6SyIi0go0ZK3WCjNLAZaY2XeBNYCqj9Cqa/5riss497Z5bK+s5t5pYxh8ULtYZ0lERFqJhtT8vw/kAP8DjAIuAC5qzkzFjVa6rO/akjLOnT6PkrII/7h0DMO65cU6SyIi0oo0JPgXuvs2d1/t7he7+0Sg14Fc1MzyzexBM/vIzD40s3Fm1sHMnjGzJeF7+/BYM7ObzGypmb1jZofVOc/k8PglZjb5QPLUKK2w5v/51nLOu20+m7dXctclozm4hwK/iIjsqiHB/6cNTIvGjcCT7j4YGAF8CFwFzHH3AcCccBvgJGBA+LqMYPAhZtYB+CUwBhgN/LK2wNBiWlnNf8MXFZx32zzWby1n1iWHM7JXy94OERGJD3vt8zezk4CTge5mdlOdXe0IRv43ipnlAUcBUwDcvRKoNLPTgS+Fh80CXgB+ApwO3OXuDswLWw26hsc+4+6bw/M+A5wI3NfYvEUtuz1UlEB1FaQ2ZPhE89m0LQj8nxWXM+uS0Yzq3SGm+RERkdZrXzX/z4AFQDmwsM7rUeCEA7hmH2ADcIeZvWVmM8ysDdDF3deGx6wDuoSfuwOr6nx/dZi2t/Q9mNllZrbAzBZs2LDhALK+mx3z+5c03Tkb4bPiMs6fMZ9VW0qZOeVwRvdR4BcRkb3ba3XV3RcBi8zsXnePNPE1DwO+5+7zzexGdjbx117bzcyb6oLuPh2YDlBUVNRk591llr82HZvstNF45O01/Pzf71Fd48y46HDG9YtNPkREJH40aMBfODjvAzNbVvs6gGuuBla7+/xw+0GCwsDnYXM+4fv6cP8aoGed7/cI0/aW3nKy8oP3GAz6Ky6t5Lv3vsn373+bAZ3b8sT3J3DkgE4tng8REYk/LT7Dn7uvA1aZ2aAw6VjgA4LuhNoR+5OBR8LPjwIXhaP+xwIlYffAU8BXzKx9ONDvK2Fay4nR/P5zl2zghD+/xJPvreNHJwxi9jfGaa5+ERFpsIaMUst29zlmZu6+ErjazBYCvziA634PuMfMMoBlwMUEBZHZZnYpsBI4Ozz2cYKBh0uB0vBY3H2zmf0GeCM87te1g/9azI4+/5YZ8V9WWc01T37Ena+uoH/nttw++XCGd9ejfCLS8hYuXNg5LS1tBjAcLRLX2tQA71VVVU0dNWrU+voOiMkMf+7+NlBUz65j6znWge/s5TwzgZkHkpcD0oI1/3dWF3P5A2/zyYbtXHxEIT85cTBZ6anNfl0RkfqkpaXNOOigg4YUFBRsSUlJabqxVHLAampqbMOGDUPXrVs3AzitvmMaEvzrzvD3G+AYdjbPJ7essNbdjMG/qrqGW174hBvnLKFT20z+cekY9e2LSGswXIG/dUpJSfGCgoKSdevWDd/bMfsN/u5e26y+jbDJXUKpaZCZ12zBf/nG7Vwx+23e+rSY00Z04zenDycvJ71ZriUiEqUUBf7WK/y32Wt3zL4m+fkPsNd/WHevtykh6TTDyn7uzr2vf8r/PfYh6anGTeeO5LQR3Zr0GiIi0rrU1NRwySWX9HzuuefysrKyambOnLniyCOPLN39uNGjRw9av359elZWVg3AnDlzFnfv3j2qyff2VfO/Lnw/EziInSP8zwU+j+YiCa2J5/df/0U5P3nwHZ7/eAMTBnTi2rMOoWtedpOdX0QkmVRVVZGWFrsZWDds2JBaUFBQ3ZBj//nPf+YtW7Ysa8WKFe89//zzbb797W/3eueddz6q79i77rpr2VFHHbVHwaCh9tok4O4vuvuLwBHufo67/yd8nQdMaOwFE04T1vyffG8tJ9zwEq9+somrTx3KrItHK/CLiOzFcccd12/YsGFD+vfvP+y6667bMRgqJydn5LRp03oMGjRo6Jw5c9recMMNnQoLC4cffPDBQyZNmtT7oosu6gUwceLEwvPPP7/XiBEjBvfo0ePgxx57LPfrX/96Yd++fYdNnDixsPZ8559/fq/hw4cP6d+//7DLL7+8G8CmTZtSCwsLhy9atCgT4NRTT+3zpz/9aY8BWVOnTu01duzYgbfcckuH0tJS29fP88gjj+Sff/75m1JSUjj22GO3b926NW3lypXN0tfbkOJQGzPr6+7LAMysD6CHymtlt4eS1Qd0ii/KI/zqPx/w4MLVDO/ejj+fcyj9O+c2UQZFRJrXjx5c1HPxui9ymvKcAw/KLf3jWSNW7euYe+65Z0WXLl2qt23bZiNHjhx6wQUXbDnooIOqy8rKUsaMGbP9tttuW71ixYr0Sy65pM+bb775QX5+fs348eMHDhs2rKz2HCUlJWlvvfXWR/fee2/+pEmT+j/33HMfjRo1quyQQw4Z8uqrr2aPHz++7Prrr1/TpUuX6qqqKsaPHz9o/vz52WPGjCm74YYbPp08eXKfb3/7258XFxenXXnllRt3z+MjjzyyfO7cuTnTp0/v9Lvf/a7bMcccU/LNb35z47hx48p2P3bt2rXphYWFlbXbXbt2rVy5cmV6796995hld+rUqYUpKSmceuqpW6655pq1KSnRPW3ZkKMvB14wsxfM7EXgeYInAAQOuNl//rJNnPjnuTz05mq+d0x/HvrWEQr8IiINcM0113QZNGjQ0FGjRg1Zt25d+vvvv58FkJqaypQpU7YAzJ07t82YMWO+6NKlS3VmZqafccYZu/zBPuWUU4pTUlI47LDDSjt27BgZPXp0WWpqKgMHDiz75JNPMgFmzZrVYejQoUOGDh06dMmSJVmLFi3KAjjjjDO2DhkypOzHP/5x7zvvvHPF3vI5YcKE0rvvvvvTjz/++P3+/ftXHH300UOuvvrqLns7fn8eeOCBZYsXL/7gtdde++jVV19te/PNN0c9r3tDRvs/aWYDgMFh0kfuXhHthRJW7bK+7mD7bNHZRUVVNdc/vZjpc5fRq0MO//zmeEb11hK8IhJ/9ldDbw6PPfZY7osvvpi7YMGCj3Jzc2tGjx49qKysLAUgIyOjpqH9/FlZWQ5BgSEjI2PHIPeUlBSqqqrso48+yvjrX//aZeHChR8WFBRUT5w4sbC8vDwFoLq6msWLF2dlZWXVbNq0Ka1fv371roMTiUSYPXt23h133NFp5cqVWT/60Y8+mzZt2qbdj+vatWtkxYoVGbXba9euzaiv1t+nT58IQPv27WvOOeecza+//nobYI/z7UuD2gncvcLdF4UvBf66stuDV0PFFw3+yodrt3L6X1/h1peWce7oXjz+PxMU+EVEolBcXJyal5dXnZubW/PWW29lLVq0qN7u6COPPHL7/Pnzczds2JAaiUR45JFHovpju2XLltTs7OyaDh06VK9atSrthRde2DGt6q9//esuAwcOLL/zzjuXXXLJJYUVFRV71ACvvvrqLn369Dn4X//6V/sf/vCHny9ZsuT93/72t+vqG51/2mmnFd9zzz0da2pqmDNnTpvc3Nzq3YN/JBJh7dq1aQAVFRX2+OOP5w0fPnyPLoT9ie0i9Imgdpa/tYugz77HQVbXOLe/vIzrnlpMu+x0Zk4p4pjBjW75ERFJWhMnTiyZPn16Qd++fYf17du3fMSIEdvrO65Pnz6Ryy+/fG1RUdGQvLy8qv79+5fn5eU1aPQ9wLhx48qGDx9e2q9fv+Fdu3atHDVq1DaARYsWZd59992dFi5c+GH79u1rHnzwwS+uuuqqrjfccMNndb9/6KGHlr7zzjvvd+jQoWZ/1zr77LNL/vvf/+b17t17eHZ2ds2MGTNW1O4bPHjw0I8++uiDsrKylOOOO25AJBKxmpoamzBhwtYrrrgi6rXqLZg9N3kUFRX5ggULmu6ExatgxnFQugm+/FM44geQsue0u6u3lHLl7EXMX76Zrwztwu/PPJiObTObLh8iIs3EzBa6+y5Tsi9atGjFiBEj9hjg1hqVlJSk5OXl1UQiEU444YT+U6ZM2XjRRRe1zKIsMbRo0aJOI0aMKKxv3++QQRAAABwJSURBVH5r/mZ2WD3JJcBKd49qUoGElN8Tvv0aPHY5zPk1LH4azvg7dOgDBBP2PPTmGn756PsA/PGsQzhrVA8sivEBIiLSeD/60Y+6vfTSS+0qKirs6KOP3nrBBRckfODfn4Y0+98MHAa8AxjBCk7vA3lm9i13f7oZ8xcfcjrA1++Ed/8J//0h/P1IOPH3bB54Dv/v3+/xxHvrGF3YgT+dPYKeHZr0aRgREdmP6dOnH9jz2AmoIQP+PgNGunuRu48CRhIsw3s8cG1zZi6umMEhZ8O3XoFuI+HR7/Hen07mrQ8/5qqTBnPfZWMV+EVEpFVoSPAf6O7v1264+wfA4NpJf2RXpTld+Xm73/KbyAWM9UW8nPtzvtnlY1JT1MwvIiKtQ0OC//tmdouZHR2+bgY+MLNMoN5nGpPVW59u4ZSbXuaeN1aTesR38cteIC2/G9x/Ljzy3ageBxQREWkuDenznwJ8G/hBuP0K8EOCwP/l5slWfIlU1/CX55byt+eXclC7LO6dOpZx/cIJl6Y+By/8Dl7+Myx/Cc6cDr3GxjbDIiKS1PZb83f3Mnf/k7ufEb6uc/dSd69x920tkcnWrKQ0wsRbXuWmOUs4/dBuPPGDCTsDP0BaBhx3NVz8RLB9x0nw7K+gqrK+04mISJKqqalhypQpPXv16jV84MCBQ19++eV6B4qNHj16UGFh4fDBgwcPHTx48NA1a9ZEPWdPQx71OwK4Guhd93h37xvtxRLRsx9+zjurS7ju6yM4a1SPvR/Ye1wwGPDJn8LL18PSZ+DM26DzkJbLrIhIkon1kr57U99Sv61iSd86bgeuB44EDq/zEqC4LBj2cPyQBszUl5kLp/8VJt0LW9fCrUfDazdDzX4nfhIRkd3Ew5K+da1ZsybtF7/4RZcBAwYMu+OOOzrsvr+1Lelb4u5PNMfFE0FJaSVmkJsVRcly8CnQ43B49H/gqZ/C4ifga7dA3j5aDkREWqt/f6cn6z9o2meZOw8t5Wt/i/slfaurq3n44YfbzZgxo9OSJUuyJ06cuPnJJ59cXN8iQK1tSd/nzeyPZjbOzA6rfUV1lQRWXBYhLzudlGgf5WvbGc69D069CVYvhJvHwzuzg9UBRURkv+JhSd/jjz++/3e+853CqVOnblyyZMn711577dq9rf7XUC2ypC8wJnyvO6+zA8dEe7FEVFwaBP9GMYNRk4MFgR7+Jjw0DT5+HE65Ppg1UEQkHuynht4c4mVJ32uvvXb1zTffXHDllVf2+ve//7112rRpG48++uh6++pb1ZK+7v7lel4K/KHisgj5jQ3+tTr0DZ4GOPYX8OF/4JbxsHRO02RQRCQBxcuSvkVFReUzZ85c9fHHH79/9NFHf/Gzn/2s+8CBA4c+9NBD7XY/tlUs6WtmF7j7P8zsivr2u/v10V4sEZWUVpKXk7H/A/cnJRUmXAn9joWHvwH/OBNGXwbH/QoyNC2wiEhd8bKkb62srCyfNm3almnTpm1ZvHhxxueff75H/G0VS/qa2Tfc/VYz+2U9u93dfx3txVqDpl7S90t/fJ5DeuRz07kjm+ycRMqCFQLn3QwdBwQTA3XXMAsRiQ0t6RufGrWkr7vfGn581t1fqbsvfPZfCJv9c5r4SYz0bDjx9zDwBPj3t+H24+GoHwctA6mt73lVEZHWTEv67qkhkeQvBEv67i8t6dTUOCVN0ee/N32/BN96FR7/UTBF8JKng1aAjv2a53oiIglIS/ruaV99/uOA8UDBbv3+7YDU5s5YPPiivAp3mqbPf2+y82HibTDoRHjscvj7kXDCb2HUxcHTAiIiIlHa12j/DKAtQQEht85rK3BW82et9SsuC+ZiaLaaf13DJ8K350HPMUEh4N6z4Yt1zX9dEZH61dTU1KgG0kqF/zZ7nT52X33+LwIvmtmd7r4SwMxSgLbuvrXJcxqHikuDJzCavM9/b9p1gwsegjdmwDP/CzePg1NvhKGntcz1RUR2em/Dhg1DCwoKSlJSUjQ7WStSU1NjGzZsyAPe29sxDenz/72ZfROoBt4A2pnZje7+xwPJnJmlAguANe7+VTPrA9wPdAQWAhe6e6WZZQJ3AaMIJjE4x91XhOf4KXBpmLf/cfenDiRP0aqd17/Rk/w0RkoKjLksGA/w0DSYfSGMOA9O+gNk5e3v2yIiTaKqqmrqunXrZqxbt244DZstVlpODfBeVVXV1L0d0JDgP9Tdt5rZ+cATwFUEwfmAgj/wfeBDgjEEANcAN7j7/Wb2d4Kgfkv4vsXd+5vZpPC4c8xsKDAJGAZ0A541s4Hu3uDnNw9UcWnY7N9SNf+6CgbC1GfhxWth7nWw4mU4/5/QeXDL50VEks6oUaPWA2p2jFMNKa2lm1k68DXgUXePEEzv22hm1gM4BZgRbhvBdMEPhofMCq8HcHq4Tbj/2PD404H73b3C3ZcDS4HRB5KvaG3dUfNvxgF/+5KaDsf8P7jkaaiugFmnwsYlscmLiIjEjYYE/1uBFUAb4CUz600w6O9A/Bn4MTsHI3QEit29KtxeDXQPP3cHVgGE+0vC43ek1/OdXZjZZWa2wMwWbNgQ9URIe1Xb59+izf716Xk4TP4P4EEBYNMnsc2PiIi0ag2Z2/8md+/u7id7YCXw5cZe0My+Cqx394WNPUe03H26uxe5e1FBQUGTnbe4LEKbjFQy0lpBd1fBILjoUaiuDAoAm5fHOkciItJK7TdqmVkXM7vdzJ4It4cCkw/gmkcAp5nZCoIBfscANwL5ZlY7BqEHsCb8vAboGV47DcgjGPi3I72e77SI4tII+c35jH+0ugyFix6BSGlQACj+NNY5EhGRVqghVdY7gacIBtUBLAZ+0NgLuvtP3b2HuxcSDNh7zt3PB55n5/wBk4FHws+PsrOwcVZ4vIfpk8wsM3xSYADwemPz1RglZZWxb/Lf3UEHw4X/hoqtcOdXoUQTW4mIyK72Gvzr1MI7uftswv75sN+9OUbU/wS4wsyWEvTp3x6m3w50DNOvIHjaAHd/H5gNfAA8CXynJUf6Q23Nv5UFf4Buh8KFD0PZlqAAsLXeRaZERCRJ7avmX1uL3m5mHQlH+JvZWIJBdwfM3V9w96+Gn5e5+2h37+/uX3f3ijC9PNzuH+5fVuf7v3X3fu4+yN2faIo8RaO4LNL6av61uo8KJgTavjHoAtBsgCIiEtpX8K+dtvEKgib2fmb2CsGEO99r7ozFg1Zb86/V83C44EHYuhZmnQbb1sc6RyIi0grsK/jXLujzJeBh4FqCSX5uA45r/qy1bu7O1rJI7J7xb6heY+H82cHgv7tOh+2bYp0jERGJsX0F/1SChX1yCZ7xTwvTcsK0pFYWqaayuqZ11/xrFR4J5z0Am5cFBYDSzbHOkYiIxNC+pvdd6+6/brGcxJkdi/q01j7/3fU9GibdC/edC3d/LXgkMLt9rHMlIiIx0JA+f6lHi6/o1xT6HwuT7oH1H8LdZ0J5k4zbFBGROLOv4H9si+UiDhWXBYv6tPo+/90NOB7OvgvWvQv/mAjlWp1ZRCTZ7DX4u7s6hvehJB5r/rUGnQRfvwPWvAn3fB0qtsU6RyIi0oJawaT08am4LI6DP8CQU+Gs22H1G3DvOVC5PdY5EhGRFqLg30itZkW/AzHsDDhzOnz6Ktw3CSJlsc6RiIi0AAX/Riopi5CRmkJ2emqss3JgDj4LvnYLLJ8L958HkfJY50hERJqZgn8jlZRVkpeTjlkCPBQxYhKc/lf45Dl44AKoqoh1jkREpBkp+DdScWkkfp7xb4iRF8CpN8LSZ2D2ZKiqjHWORESkmSj4N1Krn9e/MUZNgZOvg8VPwIMXQ3Uk1jkSEZFmoODfSMXxMK9/Y4yeBideAx89Bv+aCtVVsc6RiIg0sX1N7yv7UFJaybBu7WKdjeYx9ptQE4Gnfw6p6XDGrZAS5wMbRURkBwX/RiouS7A+/92N/17Q7D/nV2Cp8LWbVQAQEUkQCv6NUFlVQ2lldXw/498QE66Amip4/reQkgan/QVS1FMkIhLvFPwboSTeZ/eLxtE/DloAXroWUtPglBtUABARiXMK/o1QUruoT04CDvirz5d/FrQAvHx90AJw8nWQCPMbiIgkKQX/RtixnG+iN/vXMoNjfxEMAnz1L5CSDif+XgUAEZE4peDfCMXxvKJfY5nB8b8JHv2bf0vQBXD8b1QAEBGJQwr+jbBjRb9EfM5/X8yCGn9N1c4WgGN/oQKASH1qqoP5MubdAhs+gqy83V75u73nQXb+nsel5+h3TJqcgn8jFJfW9vknUc2/lhmcdG3QBfDy9cE8AF/+WaxzJdJ6VHwBb/0jCPrFKyG/d7CCZuV2KCuG8hLYuDR4Ly+ByH6W005J37NAUF8hISt/14JE7XFpmS3zc0tcUfBvhJKyCCkGuZlJevtSUoJR/zVV8OI1wSDAo3/cvNeMlEPpRti+AbbXvm/Yc7t0c1BAScuG9Kxd39MyIT0b0rL2fE/L2vP4fX0vLUtPPciuilfB67fCwrugogR6joWv/B8MPmXfc2RUVULF1rAwEBYOagsJu7zqpG1ds/O46v0sxJWWFRQE8nrCtDlN+zNL3ErS6HVgiksjtMtOJyUliZviUlLg1JuCMQC18wBMuKLh36+phrItew/iu3+u2Fr/edKyoE0BtOkEbQ+CzkPBHarKggJDVRlUlkLppmC1wtq02veaA5i+ODWzTqGhboEiBzoPgT4ToHBCkDdJXGvehNf+Bu8/HGwPPR3GfQd6FDXs+2kZkNap8f9PIuV7KSTUKSyUFQe/oyIh/W9ohJJEn92voVLCmf9qqsKZAFNg6Gn7rpnXfi7dBF6z5zktBXI67gzo3Ubu/NymoM4r3M5oe2D9odVVQSGgqgIiZVBVvud7VfmehYba9/q+V7EN3nkAFtweXKOgTkGg8EjI6dD4/ErrUFMNHz8RBP1PX4XMdjD2WzDmG5Dfq2Xzkh4WQHO7tOx1Ja4p+DdCcVkkeZ7x35+U1GDu/5oqePaXwWt3me12BusOfaHn6D2DeO0ru33LTiOcmgapuZCZ27TnrY7AZ2/DirnB661/wOvTg31dhgcFgT4ToPf44GeW+FCxDd6+F+bdDFuWQ14vOOH3wZLYWQm61ockJAX/RigprSRfwX+n1DSYOAMGnhjU5nc0w3eGnE5BrSTZpKZDz8OD14Qrgn7dz96CFS/B8rmw8I7gkUkMDjoY+hwVtAr0Hh/0z0rrUrImKLwtvCNoRu9eBMf9EgafGvz/F4kz+l/bCMVlEQo7tYl1NlqX1HQ49NxY56L1SsuAXmOC11E/CroL1iwMCgIr5sLrt8Frfw26PbqOCAoChUdB73FN3yohDffZ20Et/71/BQXbIafCuO8GrVcicUzBvxGKS9XnLwcoLTOo5fceD/wkGEOw+o2gILB8Lsz7ezCXgqUG4x4Kjwy6CXqOhcy2sc59YqupgSVPBf35K+YG40pGXxb057cvjHXuRJpEiwd/M+sJ3AV0ARyY7u43mlkH4AGgEFgBnO3uW8zMgBuBk4FSYIq7vxmeazLw8/DU/+fus5o7/9U1ztZy9flLE0vPCoJ7nwnwZYInFFa/HrYMvBy0Crzy52DEdrfDdg4g7DkGMnJinfvEULkdFt0Hr90Mmz+Bdj2CWSxHTVZXjCScWNT8q4Ar3f1NM8sFFprZM8AUYI67/8HMrgKuAn4CnAQMCF9jgFuAMWFh4ZdAEUEhYqGZPeruW5oz81+UR3BPonn9JTYycqDvl4IXBIHp03nhAMKX4eU/w9w/BRPA9Cja+SRBz9HBI4fScFvXwhu3wYKZweOn3UbCxNuDR/ZS9XsuianFg7+7rwXWhp+/MLMPge7A6cCXwsNmAS8QBP/Tgbvc3YF5ZpZvZl3DY59x980AYQHiROC+5sx/Us7rL7GX0Qb6Hxu8IJhF7tN5sPyloDAw97pw2eVM6HF4UBDoNCCY4S27/c5XZp4mJ6q17t2gaf/dB4OnVQafEvTn9xqr6XQl4cW0z9/MCoGRwHygS1gwAFhH0C0AQcFgVZ2vrQ7T9pZe33UuAy4D6NXrwJ7BrZ3XP081f4mlzFwYcHzwgmAE+srXdj5a+OI1BA1iu7M9CwTZ7YNpYXdP2+WVnxi14JoaWPps0I2y/EVIbwNFl8DYbwaPoYokiZgFfzNrC/wL+IG7b7U6JW13dzOr7y9Xo7j7dGA6QFFR0QGdt6RMNX9phbLyYNCJwQuCwsAX64KZ3cq27P1Vuhk2fRJ8Li+h/gJDKCM3LDjsr6BQp0CR0SYY3Jia0bLzN+wuUgaL7g9G7m9cDLnd4LhfBf35mmdBklBMgr+ZpRME/nvc/aEw+XMz6+rua8Nm/fVh+hqgZ52v9wjT1rCzm6A2/YXmzDfUWdQn2Vb0k/hSu7BLNGqqd04Lu6OAsI/Cw/oPd35uyDTJlhoWBNLDqZHDQkFqRvAo5I602v3hvh2fw31pmbt9ztjtXHXOkZoOS+cEsy2WbgoeozzztmChnURoyRBppFiM9jfgduBDd7++zq5HgcnAH8L3R+qkf9fM7icY8FcSFhCeAn5nZrXF9q8AP23u/KvmLwkrJTWYejja6YfdwxXrdi8gbA6nPK4IZjysrgg/Vwavqsogre7nqsrgO7WfdxxbsevnfbVQ7MFg0EnBfPu9j1B/vgixqfkfAVwIvGtmb4dpPyMI+rPN7FJgJXB2uO9xgsf8lhI86ncxgLtvNrPfAG+Ex/26dvBfc6od8Kc+f5GQWTD3QGZbyO+5/+MPlHvQ0rBHoaCyTgEjsrMA0bGv+vNFdhOL0f4vA3sreh9bz/EOfGcv55oJzGy63O1fcWmEtplppKdqxLRITJiFzfrpwZgCEYmaIliUissqVesXEZG4puAfpZLSiPr7RUQkrin4R6m4LKKav4iIxDUF/yiVlKnmLyIi8U3BP0rFpRE94y8iInFNwT8K7k5JWaVq/iIiEtcU/KNQWllNpNq1op+IiMQ1Bf8oFGt2PxERSQAK/lHQvP4iIpIIFPyjUFKqmr+IiMQ/Bf8o1Db76zl/ERGJZwr+UdCKfiIikggU/KNQu6Jfvvr8RUQkjin4R6G4rJKMtBSy0nXbREQkfimKRaGkNEJ+djpme1uRWEREpPVT8I9CsVb0ExGRBKDgH4Xiskr194uISNxT8I9CcWmEPNX8RUQkzin4R6GkLKJ5/UVEJO4p+EehpCyiCX5ERCTuKfg3UEVVNaWV1RrwJyIicU/Bv4FqZ/fLy9GAPxERiW8K/g20Y1EfNfuLiEicU/BvoGLN6y8iIglCwb+BNK+/iIgkCgX/BiourQRU8xcRkfin4N9AOwf8KfiLiEh8U/BvoJKyCCkGbTPSYp0VERGRA6Lg30DFpcEEPykpWtFPRETim4J/AxWXRcjXM/4iIpIAFPwbqLi0UlP7iohIQoj74G9mJ5rZx2a21Myuaq7rlJRFNNJfREQSQlwHfzNLBf4GnAQMBc41s6HNca3iUq3oJyIiiSGugz8wGljq7svcvRK4Hzi9OS5UXFqpPn8REUkI8R78uwOr6myvDtN2YWaXmdkCM1uwYcOGqC/i7hwzuDMjeuY1PqciIiKtRFI8tO7u04HpAEVFRR7t982MP08a2eT5EhERiYV4r/mvAXrW2e4RpomIiMhexHvwfwMYYGZ9zCwDmAQ8GuM8iYiItGpx3ezv7lVm9l3gKSAVmOnu78c4WyIiIq1aXAd/AHd/HHg81vkQERGJF/He7C8iIiJRUvAXERFJMgr+IiIiSUbBX0REJMmYe9Rz3sQ1M9sArGzk1zsBG5swO/FK9yGg+xDQfQgk8n3o7e4Fsc6ENJ2kC/4HwswWuHtRrPMRa7oPAd2HgO5DQPdB4oma/UVERJKMgr+IiEiSUfCPzvRYZ6CV0H0I6D4EdB8Cug8SN9TnLyIikmRU8xcREUkyCv4iIiJJRsG/AczsRDP72MyWmtlVsc5PSzKzmWa23szeq5PWwcyeMbMl4Xv7WOaxJZhZTzN73sw+MLP3zez7YXpS3QszyzKz181sUXgffhWm9zGz+eHvyAPhEtsJz8xSzewtM3ss3E7K+yDxR8F/P8wsFfgbcBIwFDjXzIbGNlct6k7gxN3SrgLmuPsAYE64neiqgCvdfSgwFvhO+P8g2e5FBXCMu48ADgVONLOxwDXADe7eH9gCXBrDPLak7wMf1tlO1vsgcUbBf/9GA0vdfZm7VwL3A6fHOE8txt1fAjbvlnw6MCv8PAv4WotmKgbcfa27vxl+/oLgD353kuxeeGBbuJkevhw4BngwTE/4+wBgZj2AU4AZ4baRhPdB4pOC//51B1bV2V4dpiWzLu6+Nvy8DugSy8y0NDMrBEYC80nCexE2db8NrAeeAT4Bit29KjwkWX5H/gz8GKgJtzuSnPdB4pCCvxwQD54VTZrnRc2sLfAv4AfuvrXuvmS5F+5e7e6HAj0IWsYGxzhLLc7Mvgqsd/eFsc6LSGOkxToDcWAN0LPOdo8wLZl9bmZd3X2tmXUlqAEmPDNLJwj897j7Q2FyUt4LAHcvNrPngXFAvpmlhbXeZPgdOQI4zcxOBrKAdsCNJN99kDilmv/+vQEMCEfxZgCTgEdjnKdYexSYHH6eDDwSw7y0iLA/93bgQ3e/vs6upLoXZlZgZvnh52zgeILxD88DZ4WHJfx9cPefunsPdy8k+JvwnLufT5LdB4lfmuGvAcLS/Z+BVGCmu/82xllqMWZ2H/AlguVKPwd+CfwbmA30Ilge+Wx3331QYEIxsyOBucC77Ozj/RlBv3/S3AszO4RgIFsqQeVhtrv/2sz6EgyG7QC8BVzg7hWxy2nLMbMvAT90968m832Q+KLgLyIikmTU7C8iIpJkFPxFRESSjIK/iIhIklHwFxERSTIK/iIiIklGwV+klTOzL9WuGici0hQU/EVERJKMgr9IEzGzC8K17t82s1vDBXC2mdkNZva+mc0xs4Lw2EPNbJ6ZvWNmD5tZ+zC9v5k9a2aLzOxNM+sXnr6tmT1oZh+Z2T3hjIOY2R/M7IPwPNfF6EcXkTij4C/SBMxsCHAOcES46E01cD7QBljg7sOAFwlmSAS4C/iJux9CMGtgbfo9wN/cfQQwHqhdMXAk8ANgKNAXOMLMOgJnAMPC8/xf8/6UIpIoFPxFmsaxwCjgjXC522MJgnQN8EB4zD+AI80sD8h39xfD9FnAUWaWC3R394cB3L3c3UvDY15399XuXgO8DRQCJUA5cLuZnQnUHisisk8K/iJNw4BZ7n5o+Brk7lfXc1xj59OuOz98NVC7ctxo4EHgq8CTjTy3iCQZBX+RpjEHOMvMOgOYWQcz603wO1a7ytt5wMvuXgJsMbMJYfqFwIvu/gWw2sy+Fp4j08xy9nZBM2sL5Ln748DlwIjm+MFEJPGkxToDIonA3T8ws58DT5tZChABvgNsB0aH+9YTjAuAYLnXv4fBfRlwcZh+IXCrmf06PMfX93HZXOARM8siaHm4ool/LBFJUFrVT6QZmdk2d28b63yIiNSlZn8REZEko5q/iIhIklHNX0REJMko+IuIiCQZBX8REZEko+AvIiKSZBT8RUREksz/By18bbBWuZ9kAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLfaVcgE7pK",
        "outputId": "fb7eba15-0e75-4442-c179-c28cbc3f2b3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29714\n",
            "total train set images 30000\n",
            "focus_true_pred_true 24960 =============> FTPT : 83 %\n",
            "focus_false_pred_true 4754 =============> FFPT : 15 %\n",
            "focus_true_pred_false 57 =============> FTPF : 0 %\n",
            "focus_false_pred_false 229 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  24151\n",
            "argmax_less_than_half ==================>  5849\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cSh5sGfFAlg",
        "outputId": "815d2997-ba5b-4a52-d90a-58a2bbf32665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 93 %\n",
            "total correct 9350\n",
            "total train set images 10000\n",
            "focus_true_pred_true 7925 =============> FTPT : 79 %\n",
            "focus_false_pred_true 1425 =============> FFPT : 14 %\n",
            "focus_true_pred_false 190 =============> FTPF : 1 %\n",
            "focus_false_pred_false 460 =============> FFPF : 4 %\n",
            "argmax_more_than_half ==================>  7911\n",
            "argmax_less_than_half ==================>  2089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "outputId": "61a96adc-404a-4c54-d51d-e9ebe6bcd055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "                                            correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 99 %\n",
            "total correct 29728\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "outputId": "fab2c60d-cfd0-40b6-fa05-f15210f17139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 93 %\n",
            "total correct 9339\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HoIweZX_o3O"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}