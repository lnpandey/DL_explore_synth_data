{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R2j0wT2NxUG",
        "colab_type": "code",
        "outputId": "766a23a4-c509-4d97-ae01-3d5a8ae47c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Models import Classification_Module as Classification_Module\n",
        "from Models import Focus_Module as Focus_Module\n",
        "from Mosaic import mosaic_data, MosaicDataset,split_foreground_background\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SblUamycPE7O",
        "colab_type": "code",
        "outputId": "9839d26e-f4ee-44df-8c9a-408de7e9cbc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsd9DNgUPMBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = split_foreground_background(trainloader,total = 50000)\n",
        "mosaic_list_of_images,mosaic_label,fore_idx = mosaic_data(data,desired_num=30000,total=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC1dUctdPgmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "train_dataset  = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "mosaic_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCm_yFatRxib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mimages_val,mlabel_val,fidx_val = mosaic_data(data,desired_num=10000,total=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RccSHk3DU3jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "test_dataset  = MosaicDataset(mimages_val,mlabel_val,fidx_val)\n",
        "test_loader = DataLoader( test_dataset,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di1vx00TVFgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net =  Focus_Module(3,1).double()\n",
        "focus_net = focus_net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0wsFjYFVPfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classification_net  = Classification_Module(3,3).double()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz6llbjujOm8",
        "colab_type": "code",
        "outputId": "63ce182a-bde4-41bc-d0b9-f5c1592bfeab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "classification_net = classification_net.to(device)\n",
        "classification_net"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification_Module(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=200, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emZvvTp0VbIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_focus = optim.SGD(focus_net.parameters(),lr = 0.01,momentum=0.9)\n",
        "optimizer_classification = optim.SGD(classification_net.parameters(),lr =0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cClaMnSRVfS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8iOl6JEVjJJ",
        "colab_type": "code",
        "outputId": "0797cb10-1a68-4924-d287-5b7e09e6af69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tr_loss = []\n",
        "for epoch in range(110):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    cnt=0\n",
        "    iteration = 30000 // batch\n",
        "    ep_loss = []\n",
        "    for i, data in  enumerate(mosaic_loader):\n",
        "        inputs , labels , fgrnd_idx = data\n",
        "        inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "        optimizer_focus.zero_grad()\n",
        "        optimizer_classification.zero_grad()\n",
        "        avg_data , alphas = focus_net(inputs)\n",
        "        outputs = classification_net(avg_data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_focus.step()\n",
        "        optimizer_classification.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        mini = 40\n",
        "        if cnt % mini == mini-1:    # print every mini mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "            ep_loss.append(running_loss/mini)\n",
        "            running_loss = 0.0  \n",
        "        cnt=cnt+1\n",
        "    tr_loss.append(np.mean(ep_loss))      \n",
        "print('Finished Training')    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.100\n",
            "[1,    80] loss: 1.099\n",
            "[1,   120] loss: 1.099\n",
            "[2,    40] loss: 1.099\n",
            "[2,    80] loss: 1.099\n",
            "[2,   120] loss: 1.099\n",
            "[3,    40] loss: 1.099\n",
            "[3,    80] loss: 1.099\n",
            "[3,   120] loss: 1.099\n",
            "[4,    40] loss: 1.098\n",
            "[4,    80] loss: 1.099\n",
            "[4,   120] loss: 1.098\n",
            "[5,    40] loss: 1.099\n",
            "[5,    80] loss: 1.098\n",
            "[5,   120] loss: 1.098\n",
            "[6,    40] loss: 1.098\n",
            "[6,    80] loss: 1.098\n",
            "[6,   120] loss: 1.098\n",
            "[7,    40] loss: 1.098\n",
            "[7,    80] loss: 1.098\n",
            "[7,   120] loss: 1.098\n",
            "[8,    40] loss: 1.097\n",
            "[8,    80] loss: 1.097\n",
            "[8,   120] loss: 1.097\n",
            "[9,    40] loss: 1.096\n",
            "[9,    80] loss: 1.095\n",
            "[9,   120] loss: 1.093\n",
            "[10,    40] loss: 1.091\n",
            "[10,    80] loss: 1.089\n",
            "[10,   120] loss: 1.086\n",
            "[11,    40] loss: 1.086\n",
            "[11,    80] loss: 1.081\n",
            "[11,   120] loss: 1.080\n",
            "[12,    40] loss: 1.078\n",
            "[12,    80] loss: 1.083\n",
            "[12,   120] loss: 1.078\n",
            "[13,    40] loss: 1.079\n",
            "[13,    80] loss: 1.075\n",
            "[13,   120] loss: 1.073\n",
            "[14,    40] loss: 1.074\n",
            "[14,    80] loss: 1.071\n",
            "[14,   120] loss: 1.072\n",
            "[15,    40] loss: 1.071\n",
            "[15,    80] loss: 1.068\n",
            "[15,   120] loss: 1.073\n",
            "[16,    40] loss: 1.069\n",
            "[16,    80] loss: 1.067\n",
            "[16,   120] loss: 1.066\n",
            "[17,    40] loss: 1.065\n",
            "[17,    80] loss: 1.066\n",
            "[17,   120] loss: 1.069\n",
            "[18,    40] loss: 1.063\n",
            "[18,    80] loss: 1.065\n",
            "[18,   120] loss: 1.063\n",
            "[19,    40] loss: 1.060\n",
            "[19,    80] loss: 1.064\n",
            "[19,   120] loss: 1.060\n",
            "[20,    40] loss: 1.064\n",
            "[20,    80] loss: 1.056\n",
            "[20,   120] loss: 1.061\n",
            "[21,    40] loss: 1.059\n",
            "[21,    80] loss: 1.058\n",
            "[21,   120] loss: 1.054\n",
            "[22,    40] loss: 1.059\n",
            "[22,    80] loss: 1.054\n",
            "[22,   120] loss: 1.054\n",
            "[23,    40] loss: 1.054\n",
            "[23,    80] loss: 1.052\n",
            "[23,   120] loss: 1.050\n",
            "[24,    40] loss: 1.050\n",
            "[24,    80] loss: 1.046\n",
            "[24,   120] loss: 1.051\n",
            "[25,    40] loss: 1.050\n",
            "[25,    80] loss: 1.045\n",
            "[25,   120] loss: 1.045\n",
            "[26,    40] loss: 1.045\n",
            "[26,    80] loss: 1.045\n",
            "[26,   120] loss: 1.045\n",
            "[27,    40] loss: 1.045\n",
            "[27,    80] loss: 1.047\n",
            "[27,   120] loss: 1.045\n",
            "[28,    40] loss: 1.047\n",
            "[28,    80] loss: 1.042\n",
            "[28,   120] loss: 1.037\n",
            "[29,    40] loss: 1.039\n",
            "[29,    80] loss: 1.037\n",
            "[29,   120] loss: 1.041\n",
            "[30,    40] loss: 1.040\n",
            "[30,    80] loss: 1.033\n",
            "[30,   120] loss: 1.035\n",
            "[31,    40] loss: 1.035\n",
            "[31,    80] loss: 1.027\n",
            "[31,   120] loss: 1.027\n",
            "[32,    40] loss: 1.028\n",
            "[32,    80] loss: 1.019\n",
            "[32,   120] loss: 1.013\n",
            "[33,    40] loss: 1.011\n",
            "[33,    80] loss: 1.015\n",
            "[33,   120] loss: 1.010\n",
            "[34,    40] loss: 1.004\n",
            "[34,    80] loss: 1.006\n",
            "[34,   120] loss: 1.005\n",
            "[35,    40] loss: 1.006\n",
            "[35,    80] loss: 0.987\n",
            "[35,   120] loss: 0.983\n",
            "[36,    40] loss: 0.992\n",
            "[36,    80] loss: 0.984\n",
            "[36,   120] loss: 0.973\n",
            "[37,    40] loss: 0.967\n",
            "[37,    80] loss: 0.969\n",
            "[37,   120] loss: 0.945\n",
            "[38,    40] loss: 0.947\n",
            "[38,    80] loss: 0.933\n",
            "[38,   120] loss: 0.932\n",
            "[39,    40] loss: 0.919\n",
            "[39,    80] loss: 0.932\n",
            "[39,   120] loss: 0.912\n",
            "[40,    40] loss: 0.896\n",
            "[40,    80] loss: 0.890\n",
            "[40,   120] loss: 0.890\n",
            "[41,    40] loss: 0.870\n",
            "[41,    80] loss: 0.870\n",
            "[41,   120] loss: 0.856\n",
            "[42,    40] loss: 0.837\n",
            "[42,    80] loss: 0.822\n",
            "[42,   120] loss: 0.813\n",
            "[43,    40] loss: 0.805\n",
            "[43,    80] loss: 0.788\n",
            "[43,   120] loss: 0.814\n",
            "[44,    40] loss: 0.782\n",
            "[44,    80] loss: 0.801\n",
            "[44,   120] loss: 0.756\n",
            "[45,    40] loss: 0.753\n",
            "[45,    80] loss: 0.752\n",
            "[45,   120] loss: 0.756\n",
            "[46,    40] loss: 0.735\n",
            "[46,    80] loss: 0.737\n",
            "[46,   120] loss: 0.719\n",
            "[47,    40] loss: 0.704\n",
            "[47,    80] loss: 0.712\n",
            "[47,   120] loss: 0.688\n",
            "[48,    40] loss: 0.675\n",
            "[48,    80] loss: 0.693\n",
            "[48,   120] loss: 0.678\n",
            "[49,    40] loss: 0.651\n",
            "[49,    80] loss: 0.660\n",
            "[49,   120] loss: 0.675\n",
            "[50,    40] loss: 0.649\n",
            "[50,    80] loss: 0.656\n",
            "[50,   120] loss: 0.637\n",
            "[51,    40] loss: 0.600\n",
            "[51,    80] loss: 0.619\n",
            "[51,   120] loss: 0.624\n",
            "[52,    40] loss: 0.597\n",
            "[52,    80] loss: 0.574\n",
            "[52,   120] loss: 0.602\n",
            "[53,    40] loss: 0.597\n",
            "[53,    80] loss: 0.587\n",
            "[53,   120] loss: 0.588\n",
            "[54,    40] loss: 0.572\n",
            "[54,    80] loss: 0.577\n",
            "[54,   120] loss: 0.568\n",
            "[55,    40] loss: 0.551\n",
            "[55,    80] loss: 0.563\n",
            "[55,   120] loss: 0.549\n",
            "[56,    40] loss: 0.532\n",
            "[56,    80] loss: 0.529\n",
            "[56,   120] loss: 0.532\n",
            "[57,    40] loss: 0.497\n",
            "[57,    80] loss: 0.506\n",
            "[57,   120] loss: 0.508\n",
            "[58,    40] loss: 0.493\n",
            "[58,    80] loss: 0.514\n",
            "[58,   120] loss: 0.520\n",
            "[59,    40] loss: 0.505\n",
            "[59,    80] loss: 0.482\n",
            "[59,   120] loss: 0.477\n",
            "[60,    40] loss: 0.453\n",
            "[60,    80] loss: 0.471\n",
            "[60,   120] loss: 0.469\n",
            "[61,    40] loss: 0.432\n",
            "[61,    80] loss: 0.468\n",
            "[61,   120] loss: 0.467\n",
            "[62,    40] loss: 0.433\n",
            "[62,    80] loss: 0.436\n",
            "[62,   120] loss: 0.438\n",
            "[63,    40] loss: 0.426\n",
            "[63,    80] loss: 0.431\n",
            "[63,   120] loss: 0.419\n",
            "[64,    40] loss: 0.399\n",
            "[64,    80] loss: 0.413\n",
            "[64,   120] loss: 0.399\n",
            "[65,    40] loss: 0.382\n",
            "[65,    80] loss: 0.408\n",
            "[65,   120] loss: 0.404\n",
            "[66,    40] loss: 0.375\n",
            "[66,    80] loss: 0.382\n",
            "[66,   120] loss: 0.398\n",
            "[67,    40] loss: 0.362\n",
            "[67,    80] loss: 0.382\n",
            "[67,   120] loss: 0.370\n",
            "[68,    40] loss: 0.378\n",
            "[68,    80] loss: 0.376\n",
            "[68,   120] loss: 0.370\n",
            "[69,    40] loss: 0.338\n",
            "[69,    80] loss: 0.354\n",
            "[69,   120] loss: 0.363\n",
            "[70,    40] loss: 0.337\n",
            "[70,    80] loss: 0.348\n",
            "[70,   120] loss: 0.345\n",
            "[71,    40] loss: 0.325\n",
            "[71,    80] loss: 0.336\n",
            "[71,   120] loss: 0.331\n",
            "[72,    40] loss: 0.312\n",
            "[72,    80] loss: 0.315\n",
            "[72,   120] loss: 0.322\n",
            "[73,    40] loss: 0.295\n",
            "[73,    80] loss: 0.298\n",
            "[73,   120] loss: 0.314\n",
            "[74,    40] loss: 0.298\n",
            "[74,    80] loss: 0.292\n",
            "[74,   120] loss: 0.287\n",
            "[75,    40] loss: 0.291\n",
            "[75,    80] loss: 0.304\n",
            "[75,   120] loss: 0.304\n",
            "[76,    40] loss: 0.293\n",
            "[76,    80] loss: 0.274\n",
            "[76,   120] loss: 0.295\n",
            "[77,    40] loss: 0.253\n",
            "[77,    80] loss: 0.279\n",
            "[77,   120] loss: 0.275\n",
            "[78,    40] loss: 0.260\n",
            "[78,    80] loss: 0.278\n",
            "[78,   120] loss: 0.273\n",
            "[79,    40] loss: 0.238\n",
            "[79,    80] loss: 0.270\n",
            "[79,   120] loss: 0.279\n",
            "[80,    40] loss: 0.266\n",
            "[80,    80] loss: 0.284\n",
            "[80,   120] loss: 0.264\n",
            "[81,    40] loss: 0.231\n",
            "[81,    80] loss: 0.234\n",
            "[81,   120] loss: 0.265\n",
            "[82,    40] loss: 0.229\n",
            "[82,    80] loss: 0.247\n",
            "[82,   120] loss: 0.256\n",
            "[83,    40] loss: 0.233\n",
            "[83,    80] loss: 0.232\n",
            "[83,   120] loss: 0.249\n",
            "[84,    40] loss: 0.202\n",
            "[84,    80] loss: 0.237\n",
            "[84,   120] loss: 0.229\n",
            "[85,    40] loss: 0.197\n",
            "[85,    80] loss: 0.207\n",
            "[85,   120] loss: 0.229\n",
            "[86,    40] loss: 0.231\n",
            "[86,    80] loss: 0.260\n",
            "[86,   120] loss: 0.207\n",
            "[87,    40] loss: 0.202\n",
            "[87,    80] loss: 0.216\n",
            "[87,   120] loss: 0.250\n",
            "[88,    40] loss: 0.198\n",
            "[88,    80] loss: 0.192\n",
            "[88,   120] loss: 0.214\n",
            "[89,    40] loss: 0.199\n",
            "[89,    80] loss: 0.191\n",
            "[89,   120] loss: 0.202\n",
            "[90,    40] loss: 0.165\n",
            "[90,    80] loss: 0.179\n",
            "[90,   120] loss: 0.190\n",
            "[91,    40] loss: 0.168\n",
            "[91,    80] loss: 0.192\n",
            "[91,   120] loss: 0.234\n",
            "[92,    40] loss: 0.173\n",
            "[92,    80] loss: 0.211\n",
            "[92,   120] loss: 0.211\n",
            "[93,    40] loss: 0.183\n",
            "[93,    80] loss: 0.163\n",
            "[93,   120] loss: 0.236\n",
            "[94,    40] loss: 0.178\n",
            "[94,    80] loss: 0.165\n",
            "[94,   120] loss: 0.194\n",
            "[95,    40] loss: 0.175\n",
            "[95,    80] loss: 0.176\n",
            "[95,   120] loss: 0.166\n",
            "[96,    40] loss: 0.168\n",
            "[96,    80] loss: 0.156\n",
            "[96,   120] loss: 0.169\n",
            "[97,    40] loss: 0.139\n",
            "[97,    80] loss: 0.152\n",
            "[97,   120] loss: 0.160\n",
            "[98,    40] loss: 0.139\n",
            "[98,    80] loss: 0.163\n",
            "[98,   120] loss: 0.171\n",
            "[99,    40] loss: 0.163\n",
            "[99,    80] loss: 0.147\n",
            "[99,   120] loss: 0.145\n",
            "[100,    40] loss: 0.128\n",
            "[100,    80] loss: 0.136\n",
            "[100,   120] loss: 0.150\n",
            "[101,    40] loss: 0.127\n",
            "[101,    80] loss: 0.135\n",
            "[101,   120] loss: 0.129\n",
            "[102,    40] loss: 0.114\n",
            "[102,    80] loss: 0.136\n",
            "[102,   120] loss: 0.155\n",
            "[103,    40] loss: 0.137\n",
            "[103,    80] loss: 0.133\n",
            "[103,   120] loss: 0.147\n",
            "[104,    40] loss: 0.121\n",
            "[104,    80] loss: 0.125\n",
            "[104,   120] loss: 0.158\n",
            "[105,    40] loss: 0.118\n",
            "[105,    80] loss: 0.120\n",
            "[105,   120] loss: 0.173\n",
            "[106,    40] loss: 0.165\n",
            "[106,    80] loss: 0.137\n",
            "[106,   120] loss: 0.119\n",
            "[107,    40] loss: 0.097\n",
            "[107,    80] loss: 0.112\n",
            "[107,   120] loss: 0.127\n",
            "[108,    40] loss: 0.105\n",
            "[108,    80] loss: 0.124\n",
            "[108,   120] loss: 0.124\n",
            "[109,    40] loss: 0.117\n",
            "[109,    80] loss: 0.105\n",
            "[109,   120] loss: 0.110\n",
            "[110,    40] loss: 0.113\n",
            "[110,    80] loss: 0.128\n",
            "[110,   120] loss: 0.110\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lB7KlwGVpmd",
        "colab_type": "code",
        "outputId": "d1b83d4c-b9ce-4954-8dcc-bcd61efc5c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "  train_acc = 0\n",
        "for i, data in enumerate(mosaic_loader):\n",
        "    inputs,labels,_ = data\n",
        "    inputs,labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    avg_data,alphas = focus_net(inputs)\n",
        "    outputs = classification_net(avg_data)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    # print(predicted.detach().cpu().numpy())\n",
        "    train_acc += sum(predicted.cpu().numpy() == labels.cpu().numpy())\n",
        "print(\"percentage train accuracy: \",train_acc/300) \n",
        "\n",
        "torch.save(focus_net.state_dict(),\"focus_net_at_zero.pt\")\n",
        "torch.save(classification_net.state_dict(),\"classification_net_at_zero.pt\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "percentage train accuracy:  96.68333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEdCv9Lfd6Pf",
        "colab_type": "code",
        "outputId": "b58dc209-fff6-45b9-c5f7-1f7a810884a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_acc = 0\n",
        "for i, data in enumerate(test_loader):\n",
        "    inputs,labels,_ = data\n",
        "    inputs,labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    avg_data,alphas = focus_net(inputs)\n",
        "    outputs = classification_net(avg_data)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "\n",
        "    val_acc +=sum(predicted.cpu().numpy() == labels.cpu().numpy())\n",
        "print(\"percentage validation accuracy: \",val_acc/100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "percentage validation accuracy:  85.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5MIz98beE2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "db8acd4a-464c-45ad-ae09-cee01f91b120"
      },
      "source": [
        "plt.figure(figsize = (5,4))\n",
        "plt.plot(tr_loss,label= \"training loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"cross entropy loss\")\n",
        "plt.savefig(\"training_loss_at_zero.png\")\n",
        "plt.savefig(\"training_loss_at_zero.pdf\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDF5iDVwYCZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}