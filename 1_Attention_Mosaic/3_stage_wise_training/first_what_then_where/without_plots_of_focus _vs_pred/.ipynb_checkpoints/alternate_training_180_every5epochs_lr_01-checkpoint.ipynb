{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSjG64ra4aFu"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8-7SARDZErK"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "acRFqJNrZErV",
    "outputId": "7f7512ed-455c-4d61-8737-71e7b3dbde5f"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_JUhwCeZErk"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "foreground_classes = {'horse','ship', 'truck'}\n",
    "\n",
    "background_classes = {'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog'}\n",
    "\n",
    "# print(type(foreground_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYuA7_81ZEro"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "background_data=[]\n",
    "background_label=[]\n",
    "foreground_data=[]\n",
    "foreground_label=[]\n",
    "batch_size=10\n",
    "\n",
    "for i in range(5000):\n",
    "  images, labels = dataiter.next()\n",
    "  for j in range(batch_size):\n",
    "    if(classes[labels[j]] in background_classes):\n",
    "      img = images[j].tolist()\n",
    "      background_data.append(img)\n",
    "      background_label.append(labels[j])\n",
    "    else:\n",
    "      img = images[j].tolist()\n",
    "      foreground_data.append(img)\n",
    "      foreground_label.append(labels[j])\n",
    "            \n",
    "foreground_data = torch.tensor(foreground_data)\n",
    "foreground_label = torch.tensor(foreground_label)\n",
    "background_data = torch.tensor(background_data)\n",
    "background_label = torch.tensor(background_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shc63RaLZEr5"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "  img = img / 2 + 0.5     # unnormalize\n",
    "  npimg = img#.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 787
    },
    "colab_type": "code",
    "id": "2IoXe-nrZEr8",
    "outputId": "d3dc61fe-4503-4999-856d-7231da744449",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img1 = torch.cat((background_data[0],background_data[1],background_data[2]),1)\n",
    "imshow(img1)\n",
    "img2 = torch.cat((background_data[27],background_data[3],background_data[43]),1)\n",
    "imshow(img2)\n",
    "img3 = torch.cat((img1,img2),2)\n",
    "imshow(img3)\n",
    "print(img2.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6nKOvp8ZEsF"
   },
   "outputs": [],
   "source": [
    "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
    "  \"\"\"\n",
    "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
    "  fg_idx : index of image to be used as foreground image from foreground data\n",
    "  fg : at what position/index foreground image has to be stored out of 0-8\n",
    "  \"\"\"\n",
    "  image_list=[]\n",
    "  j=0\n",
    "  for i in range(9):\n",
    "    if i != fg:\n",
    "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
    "      j+=1\n",
    "    else: \n",
    "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
    "      label = foreground_label[fg_idx]-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
    "  #image_list = np.concatenate(image_list ,axis=0)\n",
    "  image_list = torch.stack(image_list) \n",
    "  return image_list,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hS0soEiqZEsK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desired_num = 30000\n",
    "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
    "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
    "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
    "for i in range(desired_num):\n",
    "  bg_idx = np.random.randint(0,35000,8)\n",
    "  fg_idx = np.random.randint(0,15000)\n",
    "  fg = np.random.randint(0,9)\n",
    "  fore_idx.append(fg)\n",
    "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
    "  mosaic_list_of_images.append(image_list)\n",
    "  mosaic_label.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "aXs-q623ZEsN",
    "outputId": "01890d8e-d87e-4089-93ac-c1e41262b661"
   },
   "outputs": [],
   "source": [
    "qw=45\n",
    "\n",
    "print(fore_idx[qw])\n",
    "imshow(mosaic_list_of_images[qw][fore_idx[qw]])\n",
    "# print(mosaic_list_of_images[0])\n",
    "print(classes[mosaic_label[qw]+7]) # add 7 as we had subtracted 7 while saving\n",
    "\n",
    "# imshow(mosaic_list_of_images[13][2])\n",
    "# print(type(mosaic_list_of_images[1][0]))\n",
    "# print(mosaic_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSO9SFE25Lrk"
   },
   "outputs": [],
   "source": [
    "class MosaicDataset(Dataset):\n",
    "  \"\"\"MosaicDataset dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        csv_file (string): Path to the csv file with annotations.\n",
    "        root_dir (string): Directory with all the images.\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "    \"\"\"\n",
    "    self.mosaic = mosaic_list_of_images\n",
    "    self.label = mosaic_label\n",
    "    self.fore_idx = fore_idx\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.label)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
    "\n",
    "batch = 250\n",
    "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
    "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SadRzWBBZEsP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Module1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Module1, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 10)\n",
    "    self.fc4 = nn.Linear(10,1)\n",
    "\n",
    "  def forward(self, z):\n",
    "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
    "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
    "    x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
    "    for i in range(9):\n",
    "      x[:,i] = self.helper(z[:,i])[:,0]\n",
    "    x = F.softmax(x,dim=1)   # alphas\n",
    "    \n",
    "    x1 = x[:,0]\n",
    "    torch.mul(x1[:,None,None,None],z[:,0])\n",
    "\n",
    "    for i in range(9):            \n",
    "      x1 = x[:,i]          \n",
    "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
    "    return y , x \n",
    "  \n",
    "  def helper(self,x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = x.view(-1, 16 * 5 * 5)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = self.fc4(x)\n",
    "    return x\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IgGYMG_ZZEsT"
   },
   "outputs": [],
   "source": [
    " class Module2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Module2, self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, 10)\n",
    "    self.fc4 = nn.Linear(10,3)\n",
    "\n",
    "  def forward(self,y):  #z batch of list of 9 images\n",
    "    y1 = self.pool(F.relu(self.conv1(y)))\n",
    "    y1 = self.pool(F.relu(self.conv2(y1)))\n",
    "    y1 = y1.view(-1, 16 * 5 * 5)\n",
    "\n",
    "    y1 = F.relu(self.fc1(y1))\n",
    "    y1 = F.relu(self.fc2(y1))\n",
    "    y1 = F.relu(self.fc3(y1))\n",
    "    y1 = self.fc4(y1)\n",
    "    return y1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6axOYCmGZoI"
   },
   "outputs": [],
   "source": [
    "where_net = Module1().double()\n",
    "where_net = where_net.to(\"cuda\")\n",
    "# print(net.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IGao9FdE4Gf"
   },
   "outputs": [],
   "source": [
    "# idx = np.random.randint(0,250,10)\n",
    "# train_iter = iter(train_loader)\n",
    "# images,labels,_=train_iter.next()\n",
    "\n",
    "# for i in idx:\n",
    "#   imshow(where_net1(images)[i].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thkdqW91Hpju"
   },
   "outputs": [],
   "source": [
    "what_net = Module2().double()\n",
    "what_net = what_net.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jW2j1VYGXcF"
   },
   "outputs": [],
   "source": [
    "# where_net.load_state_dict(torch.load(\"model_epoch90.pt\"))\n",
    "# what_net.load_state_dict(torch.load(\"model_epoch90.pt\"))\n",
    "# print(fore_net.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1yVWgR4vFhe"
   },
   "outputs": [],
   "source": [
    "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
    "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
    "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
    "for i in range(10000):\n",
    "  bg_idx = np.random.randint(0,35000,8)\n",
    "  fg_idx = np.random.randint(0,15000)\n",
    "  fg = np.random.randint(0,9)\n",
    "  fore_idx_test.append(fg)\n",
    "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
    "  test_images.append(image_list)\n",
    "  test_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRq1cUvgvLeH"
   },
   "outputs": [],
   "source": [
    "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
    "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "tFfAJZkcZEsY",
    "outputId": "f86e76e8-12a3-4f06-d5ce-5f822d40fa43"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_where = optim.SGD(where_net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_what = optim.SGD(what_net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "nos_epochs = 180\n",
    "every_what_epoch = 5\n",
    "\n",
    "train_loss=[]\n",
    "test_loss =[]\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    batch_correct = 0.0\n",
    "    cnt=0\n",
    "    total=0\n",
    "    iteration = desired_num // batch\n",
    "    #training data set\n",
    "  \n",
    "    if (epoch % (every_what_epoch*2) ) < every_what_epoch :\n",
    "        print(epoch,\"updating what_net, where_net is freezed\")\n",
    "    elif (epoch % (every_what_epoch*2)) > every_what_epoch :\n",
    "        print(epoch,\"updating where_net, what_net is freezed\")\n",
    "      \n",
    "    for i, data in  enumerate(train_loader):\n",
    "        inputs , labels , fore_idx = data\n",
    "        inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\") \n",
    "        # zero the parameter gradients\n",
    "        \n",
    "        optimizer_what.zero_grad()\n",
    "        optimizer_where.zero_grad()\n",
    "        \n",
    "        avg_images , alphas = where_net(inputs)\n",
    "        outputs = what_net(avg_images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward() \n",
    "    \n",
    "        if (epoch % (every_what_epoch*2) ) < every_what_epoch :\n",
    "            optimizer_what.step()\n",
    "        elif (epoch % (every_what_epoch*2)) > every_what_epoch :\n",
    "            optimizer_where.step()\n",
    "        batch_correct += sum(predicted == labels)\n",
    "        total += len(predicted)\n",
    "        running_loss += loss.item()\n",
    "        if cnt % 120 == 119:    # print every 40 mini-batches\n",
    "            print(\"--\"*40)\n",
    "            print(\"Epoch: \",epoch)\n",
    "#             print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / 120))\n",
    "            train_loss.append(running_loss/120)\n",
    "            train_acc.append(batch_correct.item()/desired_num)\n",
    "            print(\"total_Correct:\",batch_correct.item(),\"Total:\",total,\"train_loss\",running_loss/120,\"train_acc: \", batch_correct.item()/total)\n",
    "            #running_loss = 0.0\n",
    "        cnt=cnt+1\n",
    "   \n",
    "    with torch.no_grad():\n",
    "      loss = 0.0\n",
    "      correct = 0.0\n",
    "      tot =0\n",
    "      for data in test_loader:\n",
    "        inputs, labels , fore_idx = data\n",
    "        inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\") \n",
    "        avg_images , alphas = where_net(inputs)\n",
    "        outputs = what_net(avg_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        loss += criterion(outputs, labels).item() \n",
    "        correct += sum(predicted == labels)\n",
    "        tot += len(predicted)\n",
    "\n",
    "      test_loss.append(loss/40) # 10000/250 = 40\n",
    "      test_acc.append(correct.item()/tot)\n",
    "      print(\"total_Correct:\",correct.item(),\"Total:\",tot,\"test loss: \", loss/40, \"test accuracy\", correct.item()/tot)\n",
    "    \n",
    "    if (epoch % (every_what_epoch*2) == every_what_epoch*2 - 1):\n",
    "        torch.save(where_net.state_dict(),\"weights1/where_model_epoch\"+str(epoch)+\".pt\")\n",
    "        torch.save(what_net.state_dict(),\"weights1/what_model_epoch\"+str(epoch)+\".pt\")\n",
    "    \n",
    "print('Finished Training')\n",
    "torch.save(where_net.state_dict(),\"weights1/where_model_epoch\"+str(nos_epochs)+\".pt\")\n",
    "torch.save(what_net.state_dict(),\"weights1/what_model_epoch\"+str(nos_epochs)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "SGPiqPeXzwfc",
    "outputId": "08e50c79-6de7-4046-afe6-4fc7cbb5c24a"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,8) )\n",
    "vline_list = np.arange(every_what_epoch, nos_epochs + every_what_epoch, every_what_epoch )\n",
    "# train_loss = np.random.randn(340)\n",
    "# test_loss = np.random.randn(340)\n",
    "epoch_list = np.arange(1, nos_epochs+1)\n",
    "plt.plot(epoch_list,train_loss, label='train_loss')\n",
    "plt.plot(epoch_list,test_loss, label='test_loss')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"CE Loss\")\n",
    "plt.vlines(vline_list,min(min(train_loss),min(test_loss)), max(max(test_loss),max(train_loss)),linestyles='dotted')\n",
    "plt.title(\"train loss vs test loss\")\n",
    "plt.show()\n",
    "fig.savefig(\"train_test_loss_plot.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "SAVFCzqQ4HtI",
    "outputId": "a82faf2c-5265-4ba0-b91e-126d145912fa"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,8) )\n",
    "vline_list = np.arange(every_what_epoch, nos_epochs + every_what_epoch, every_what_epoch )\n",
    "# train_acc = np.random.randn(340)\n",
    "# test_acc = np.random.randn(340)\n",
    "epoch_list = np.arange(1, nos_epochs+1)\n",
    "plt.plot(epoch_list,train_acc, label='train_accuracy')\n",
    "plt.plot(epoch_list,test_acc, label='test_accuracy')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.vlines(vline_list,min(min(train_acc),min(test_acc)), max(max(test_acc),max(train_acc)),linestyles='dotted')\n",
    "plt.title(\"train accuracy vs test accuracy\")\n",
    "plt.show()\n",
    "fig.savefig(\"train_test_acc_plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0t54AJl-85nr"
   },
   "outputs": [],
   "source": [
    "def display(img):\n",
    "  img = img / 2 + 0.5     # unnormalize\n",
    "  npimg = img\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxLIMJ-L831N",
    "outputId": "30741281-9f21-4a33-db4f-846132fa70b8"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "count = 0\n",
    "flag = 1\n",
    "focus_true_pred_true =0\n",
    "focus_false_pred_true =0\n",
    "focus_true_pred_false =0\n",
    "focus_false_pred_false =0\n",
    "\n",
    "argmax_more_than_half = 0\n",
    "argmax_less_than_half =0\n",
    "\n",
    "train_loader1 = DataLoader( msd,batch_size= batch ,shuffle=False)\n",
    "with torch.no_grad():\n",
    "  for data in train_loader1:\n",
    "    inputs, labels , fore_idx = data\n",
    "    inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\") \n",
    "    avg_images , alphas = where_net(inputs)\n",
    "    outputs = what_net(avg_images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    if flag==1 :\n",
    "      for j in range (50):\n",
    "        print(\"*\"*100)\n",
    "        img1 = torch.cat((inputs[j][0], inputs[j][1], inputs[j][2], inputs[j][3], inputs[j][4], inputs[j][5], inputs[j][6], inputs[j][7], inputs[j][8]) , 2)\n",
    "        display(img1.cpu())\n",
    "\n",
    "        print(alphas[j])\n",
    "\n",
    "        img2 = avg_images[j]\n",
    "        display(img2.cpu())\n",
    "\n",
    "        img3 = inputs[j][fore_idx[j]]\n",
    "        display(img3.cpu())\n",
    "\n",
    "        print(\"predicted\", classes[predicted[j]+7])\n",
    "        print(\"true\", classes[labels[j]+7])\n",
    "        \n",
    "        focus = torch.argmax(alphas[j])\n",
    "      \n",
    "        if(alphas[j][focus] >= 0.5):\n",
    "          argmax_more_than_half +=1\n",
    "        else:\n",
    "          argmax_less_than_half +=1\n",
    "\n",
    "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
    "          focus_true_pred_true += 1\n",
    "\n",
    "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
    "          focus_false_pred_true +=1\n",
    "\n",
    "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
    "          focus_true_pred_false +=1\n",
    "\n",
    "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
    "          focus_false_pred_false +=1\n",
    "\n",
    "      flag =0\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(\"total correct\", correct)\n",
    "print(\"total train set images\", total)\n",
    "\n",
    "print(\"focus_true_pred_true\",focus_true_pred_true)\n",
    "print(\"focus_false_pred_true\",focus_false_pred_true )\n",
    "print(\"focus_true_pred_false\",focus_true_pred_false )\n",
    "print(\"focus_false_pred_false\",focus_false_pred_false)\n",
    "\n",
    "print(\"argmax_more_than_half\",argmax_more_than_half)\n",
    "print(\"argmax_less_than_half\",argmax_less_than_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcAFVMNo82yL"
   },
   "outputs": [],
   "source": [
    "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
    "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
    "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
    "for i in range(10000):\n",
    "    bg_idx = np.random.randint(0,35000,8)\n",
    "    fg_idx = np.random.randint(0,15000)\n",
    "    fg = np.random.randint(0,9)\n",
    "    fore_idx_test.append(fg)\n",
    "    image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
    "    test_images.append(image_list)\n",
    "    test_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvcoishw818R"
   },
   "outputs": [],
   "source": [
    "# test_data = MosaicDataset(test_images,test_label,)\n",
    "# test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWVT7ZENLFN2",
    "outputId": "84b853a3-e0ea-48a4-d612-32622a038092"
   },
   "outputs": [],
   "source": [
    "print(fore_idx_test[0])\n",
    "imshow(test_images[0][fore_idx_test[0]])\n",
    "print(classes[test_label[0]+7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXtO0pGXPilB",
    "outputId": "194c1a5b-3b84-42d7-fb5e-fcc0d2105069"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "flag =1\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    inputs, labels , fore_idx = data\n",
    "    inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\") \n",
    "    avg_images , alphas = where_net(inputs)\n",
    "    outputs = what_net(avg_images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "\n",
    "    if flag==1 :\n",
    "      for j in range (50):\n",
    "        print(\"*\"*100)\n",
    "        img1 = torch.cat((inputs[j][0], inputs[j][1], inputs[j][2], inputs[j][3], inputs[j][4], inputs[j][5], inputs[j][6], inputs[j][7], inputs[j][8]) , 2)\n",
    "        display(img1.cpu())\n",
    "\n",
    "        print(alphas[j])\n",
    "\n",
    "        img2 = avg_images[j]\n",
    "        display(img2.cpu())\n",
    "\n",
    "        img3 = inputs[j][fore_idx_test[j]]\n",
    "        display(img3.cpu())\n",
    "\n",
    "        print(\"predicted\", classes[predicted[j]+7])\n",
    "        print(\"true\", classes[labels[j]+7])\n",
    "\n",
    "      flag =0\n",
    "\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "print(\"total correct\", correct)\n",
    "print(\"total test set images\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qabm7caSTfee"
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([0.0071, 0.0466, 0.0025, 0.0282, 0.0140, 0.0067, 0.0145, 0.8750, 0.0055])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVt7_8kiUSX3",
    "outputId": "fd9feaf2-4680-457a-9a10-8f629f099667"
   },
   "outputs": [],
   "source": [
    "print(torch.argmax(a) == 7)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7g_sJcuUV3g",
    "outputId": "790938d3-a344-4517-9bcd-f81306d2ff9d"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "count = 0\n",
    "flag = 1\n",
    "focus_true_pred_true =0\n",
    "focus_false_pred_true =0\n",
    "focus_true_pred_false =0\n",
    "focus_false_pred_false =0\n",
    "\n",
    "argmax_more_than_half = 0\n",
    "argmax_less_than_half =0\n",
    "\n",
    "train_loader1 = DataLoader( msd,batch_size= batch ,shuffle=False)\n",
    "with torch.no_grad():\n",
    "  for data in train_loader1:\n",
    "    inputs, labels , fore_idx = data\n",
    "    inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\") \n",
    "    avg_images , alphas = where_net(inputs)\n",
    "    outputs = what_net(avg_images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for j in range (batch):\n",
    "      focus = torch.argmax(alphas[j])\n",
    "      \n",
    "      if(alphas[j][focus] >= 0.5):\n",
    "        argmax_more_than_half +=1\n",
    "      else:\n",
    "        argmax_less_than_half +=1\n",
    "        \n",
    "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
    "        focus_true_pred_true += 1\n",
    "        \n",
    "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
    "        focus_false_pred_true +=1\n",
    "        \n",
    "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
    "        focus_true_pred_false +=1\n",
    "        \n",
    "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
    "        focus_false_pred_false +=1\n",
    "      \n",
    "#       print(\"*\"*100)\n",
    "#       img1 = torch.cat((inputs[j][0], inputs[j][1], inputs[j][2], inputs[j][3], inputs[j][4], inputs[j][5], inputs[j][6], inputs[j][7], inputs[j][8]) , 2)\n",
    "#       display(img1)\n",
    "\n",
    "#       print(alphas[j])\n",
    "\n",
    "#       img2 = avg_images[j]\n",
    "#       display(img2)\n",
    "\n",
    "#       img3 = inputs[j][fore_idx[j]]\n",
    "#       display(img3)\n",
    "\n",
    "#       print(\"predicted\", classes[predicted[j]+7])\n",
    "#       print(\"true\", classes[labels[j]+7])\n",
    "\n",
    "     \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(\"total correct\", correct)\n",
    "print(\"total train set images\", total)\n",
    "\n",
    "print(\"focus_true_pred_true\",focus_true_pred_true)\n",
    "print(\"focus_false_pred_true\",focus_false_pred_true )\n",
    "print(\"focus_true_pred_false\",focus_true_pred_false )\n",
    "print(\"focus_false_pred_false\",focus_false_pred_false)\n",
    "\n",
    "print(\"argmax_more_than_half\",argmax_more_than_half)\n",
    "print(\"argmax_less_than_half\",argmax_less_than_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NMj8wXnVrze",
    "outputId": "fe720f9b-902a-48e9-c0bf-4b4a28400c29"
   },
   "outputs": [],
   "source": [
    "bg_idx = np.random.randint(0,35000,8)\n",
    "fg_idx = np.random.randint(0,15000)\n",
    "fg = np.random.randint(0,9)\n",
    "fore_idx_test.append(fg)\n",
    "image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
    "test_images.append(image_list)\n",
    "test_label.append(label)\n",
    "correct = 0\n",
    "total = 0\n",
    "count = 0\n",
    "flag = 1\n",
    "focus_true_pred_true =0\n",
    "focus_false_pred_true =0\n",
    "focus_true_pred_false =0\n",
    "focus_false_pred_false =0\n",
    "\n",
    "argmax_more_than_half = 0\n",
    "argmax_less_than_half =0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    inputs, labels , fore_idx = data\n",
    "    inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\") \n",
    "    avg_images , alphas = where_net(inputs)\n",
    "    outputs = what_net(avg_images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for j in range (batch):\n",
    "      focus = torch.argmax(alphas[j])\n",
    "      \n",
    "      if(alphas[j][focus] >= 0.5):\n",
    "        argmax_more_than_half +=1\n",
    "      else:\n",
    "        argmax_less_than_half +=1\n",
    "        \n",
    "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
    "        focus_true_pred_true += 1\n",
    "        \n",
    "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
    "        focus_false_pred_true +=1\n",
    "        \n",
    "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
    "        focus_true_pred_false +=1\n",
    "        \n",
    "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
    "        focus_false_pred_false +=1\n",
    "      \n",
    "#       print(\"*\"*100)\n",
    "#       img1 = torch.cat((inputs[j][0], inputs[j][1], inputs[j][2], inputs[j][3], inputs[j][4], inputs[j][5], inputs[j][6], inputs[j][7], inputs[j][8]) , 2)\n",
    "#       display(img1)\n",
    "\n",
    "#       print(alphas[j])\n",
    "\n",
    "#       img2 = avg_images[j]\n",
    "#       display(img2)\n",
    "\n",
    "#       img3 = inputs[j][fore_idx[j]]\n",
    "#       display(img3)\n",
    "\n",
    "#       print(\"predicted\", classes[predicted[j]+7])\n",
    "#       print(\"true\", classes[labels[j]+7])\n",
    "\n",
    "     \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(\"total correct\", correct)\n",
    "print(\"total train set images\", total)\n",
    "\n",
    "print(\"focus_true_pred_true\",focus_true_pred_true)\n",
    "print(\"focus_false_pred_true\",focus_false_pred_true )\n",
    "print(\"focus_true_pred_false\",focus_true_pred_false )\n",
    "print(\"focus_false_pred_false\",focus_false_pred_false)\n",
    "\n",
    "print(\"argmax_more_than_half\",argmax_more_than_half)\n",
    "print(\"argmax_less_than_half\",argmax_less_than_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxwOAPq35dKK"
   },
   "outputs": [],
   "source": [
    "# epoch = 100\n",
    "# for i in range(epoch):\n",
    "#   if (i %40) <20:\n",
    "#     print(\"What\",i)\n",
    "#   elif (i%40)>20:\n",
    "#     print(\"Where\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9B4nGLQ0JBf2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CIFAR_Mosaic_alternate_what_where_training (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
