{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar_learn_only_atttention_weights_lr_10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgw1f4rVkGr9",
        "outputId": "2ffb4066-41af-4c13-c6d8-fa7759622391"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-xlWYTKkQEn"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "#foreground_classes = {'bird', 'cat', 'deer'}\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
        "#background_classes = {'plane', 'car', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrX68qhikUbz"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD-QJkvnkgyk"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])#.type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])#.type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]-fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs10rfXHkli2"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7km9Swb1kq4O"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=False,num_workers=0,)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "data,labels,fg_index = iter(train_loader).next()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "ag = []\n",
        "for i in range(120):\n",
        "  alphag = torch.ones((250,9))/9\n",
        "  ag.append( alphag.requires_grad_() )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "    self.fc4 = nn.Linear(10,3)\n",
        "\n",
        "  def forward(self,y):  #z batch of list of 9 images\n",
        "    y1 = self.pool(F.relu(self.conv1(y)))\n",
        "    y1 = self.pool(F.relu(self.conv2(y1)))\n",
        "    y1 = y1.view(-1, 16 * 5 * 5)\n",
        "\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "    return y1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "what_net.load_state_dict(torch.load(\"simultaneous_what.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8Wch99l4yB"
      },
      "source": [
        "def attn_avg(x,alpha):\n",
        "  y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "  y = y.to(\"cuda\")\n",
        "  alpha = F.softmax(alpha,dim=1)   # alphas\n",
        "  for i in range(9):            \n",
        "    alpha1 = alpha[:,i]          \n",
        "    y = y + torch.mul(alpha1[:,None,None,None],x[:,i])\n",
        "    return y,alpha\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz1Kpw12loV6"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,criter):\n",
        "  what.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  correct = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx= data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      alpha = ag[i]  # alpha for ith batch\n",
        "      inputs, labels,alpha = inputs.to(\"cuda\"),labels.to(\"cuda\"),alpha.to(\"cuda\")\n",
        "      avg,alpha = attn_avg(inputs,alpha)\n",
        "      alpha = alpha.to(\"cuda\")\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += sum(predicted == labels)\n",
        "      tot += len(predicted)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis,correct.item(),tot,correct.item()/tot"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAY-x6UAwrwE"
      },
      "source": [
        "for param in what_net.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toCktPanH0S"
      },
      "source": [
        "\n",
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "optim1 = []\n",
        "for i in range(120):\n",
        "  optim1.append(optim.RMSprop([ag[i]], lr=10))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPaYaojinMTA",
        "outputId": "84942ae5-2035-4760-821f-c5c27c5b88c0"
      },
      "source": [
        "# instantiate optimizer\n",
        "#optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.001)#, momentum=0.9)#,nesterov=True)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    grads = [] \n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    alpha = ag[i] # alpha for ith batch\n",
        "    inputs, labels,alpha = inputs.to(\"cuda\"),labels.to(\"cuda\"),alpha.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    #optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,alpha)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    #optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 4.434 correct: 9998.000, total: 30000.000, accuracy: 0.333\n",
            "training epoch: [1 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [2 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [3 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [4 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [5 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [6 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [7 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [8 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [9 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [10 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [11 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [12 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [13 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [14 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [15 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [16 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [17 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [18 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [19 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [20 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [21 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [22 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [23 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [24 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [25 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [26 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [27 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [28 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [29 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [30 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [31 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [32 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [33 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [34 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [35 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [36 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [37 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [38 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [39 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [40 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [41 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [42 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [43 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [44 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [45 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [46 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [47 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [48 ] loss: 4.358 correct: 14129.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [49 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [50 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [51 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [52 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [53 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [54 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [55 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [56 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [57 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [58 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [59 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [60 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [61 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [62 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [63 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [64 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [65 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [66 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [67 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [68 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [69 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [70 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [71 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [72 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [73 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [74 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [75 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [76 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [77 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [78 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [79 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [80 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [81 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [82 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [83 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [84 ] loss: 4.358 correct: 14130.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [85 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [86 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [87 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [88 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [89 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [90 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [91 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [92 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [93 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [94 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [95 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [96 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [97 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [98 ] loss: 4.357 correct: 14131.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [99 ] loss: 4.357 correct: 14132.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [100 ] loss: 4.357 correct: 14132.000, total: 30000.000, accuracy: 0.471\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "NoQpS_6scRsC",
        "outputId": "2cbbe6e4-31ca-4c73-9445-1ed276903f0c"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>1158</td>\n",
              "      <td>8840</td>\n",
              "      <td>2226</td>\n",
              "      <td>17776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17102</td>\n",
              "      <td>12898</td>\n",
              "      <td>2886</td>\n",
              "      <td>11244</td>\n",
              "      <td>1008</td>\n",
              "      <td>14862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17102</td>\n",
              "      <td>12898</td>\n",
              "      <td>2886</td>\n",
              "      <td>11244</td>\n",
              "      <td>1008</td>\n",
              "      <td>14862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17102</td>\n",
              "      <td>12898</td>\n",
              "      <td>2886</td>\n",
              "      <td>11244</td>\n",
              "      <td>1008</td>\n",
              "      <td>14862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>17101</td>\n",
              "      <td>12899</td>\n",
              "      <td>2887</td>\n",
              "      <td>11244</td>\n",
              "      <td>1009</td>\n",
              "      <td>14860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>17101</td>\n",
              "      <td>12899</td>\n",
              "      <td>2887</td>\n",
              "      <td>11244</td>\n",
              "      <td>1009</td>\n",
              "      <td>14860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>17101</td>\n",
              "      <td>12899</td>\n",
              "      <td>2887</td>\n",
              "      <td>11244</td>\n",
              "      <td>1009</td>\n",
              "      <td>14860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>17100</td>\n",
              "      <td>12900</td>\n",
              "      <td>2888</td>\n",
              "      <td>11244</td>\n",
              "      <td>1009</td>\n",
              "      <td>14859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>100</td>\n",
              "      <td>17100</td>\n",
              "      <td>12900</td>\n",
              "      <td>2888</td>\n",
              "      <td>11244</td>\n",
              "      <td>1009</td>\n",
              "      <td>14859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0         0             0  ...                   2226                   17776\n",
              "1         1         17106  ...                   1008                   14866\n",
              "2         2         17102  ...                   1008                   14862\n",
              "3         3         17102  ...                   1008                   14862\n",
              "4         4         17102  ...                   1008                   14862\n",
              "..      ...           ...  ...                    ...                     ...\n",
              "96       96         17101  ...                   1009                   14860\n",
              "97       97         17101  ...                   1009                   14860\n",
              "98       98         17101  ...                   1009                   14860\n",
              "99       99         17100  ...                   1009                   14859\n",
              "100     100         17100  ...                   1009                   14859\n",
              "\n",
              "[101 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "IMAhRdxOcVf6",
        "outputId": "3c7ae286-aee8-4a55-acb5-f89cb795f138"
      },
      "source": [
        "fig= plt.figure(figsize=(12,12))\n",
        "plt.plot(df_train[columns[0]],df_train[columns[3]]/300, label =\"focus_true_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[4]]/300, label =\"focus_false_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[5]]/300, label =\"focus_true_pred_false \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[6]]/300, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Train set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"percentage of data\")\n",
        "#plt.vlines(vline_list,min(min(df_train[columns[3]]/300),min(df_train[columns[4]]/300),min(df_train[columns[5]]/300),min(df_train[columns[6]]/300)), max(max(df_train[columns[3]]/300),max(df_train[columns[4]]/300),max(df_train[columns[5]]/300),max(df_train[columns[6]]/300)),linestyles='dotted')\n",
        "plt.show()\n",
        "fig.savefig(\"train_analysis_every_20.pdf\")\n",
        "fig.savefig(\"train_analysis_every_20.png\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in ag:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "torch.save({\n",
        "            'epoch': 500,\n",
        "            'model_state_dict': what_net.state_dict(),\n",
        "            #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "            \"optimizer_alpha\":optim1,\n",
        "            \"FTPT_analysis\":analysis_data_tr,\n",
        "            \"alpha\":aph\n",
        "\n",
        "            }, \"cifar_what_net_500.pt\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVzrDOGS4UxU",
        "outputId": "5e8481bb-a508-48d0-f1d3-f9060f55404a"
      },
      "source": [
        "aph"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 0.125, 0.125, ..., 0.125, 0.125, 0.125],\n",
              "       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
              "       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
              "       ...,\n",
              "       [0.   , 0.125, 0.125, ..., 0.125, 0.125, 0.125],\n",
              "       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
              "       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6heHND15EMz"
      },
      "source": [
        "running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeKhsdpYWQvB",
        "outputId": "4ccb0778-9864-4a15-e2fa-29c339e70cbe"
      },
      "source": [
        "print(\"argmax>0.5\",anls_data[-2])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "argmax>0.5 17100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF2bvWdIWUTa"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}