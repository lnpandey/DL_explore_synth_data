{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "blob_only_atttention_weights_lr_0_01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "train_data = np.load(\"train_blob_data.npy\",allow_pickle=True)\n",
        "\n",
        "test_data = np.load(\"test_blob_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL771xuGZC5Q"
      },
      "source": [
        "mosaic_list_of_images = train_data[0][\"mosaic_list\"]\n",
        "mosaic_label = train_data[0][\"mosaic_label\"]\n",
        "fore_idx = train_data[0][\"fore_idx\"]\n",
        "\n",
        "\n",
        "test_mosaic_list_of_images = test_data[0][\"mosaic_list\"]\n",
        "test_mosaic_label = test_data[0][\"mosaic_label\"]\n",
        "test_fore_idx = test_data[0][\"fore_idx\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qfRXfNZCao"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf76JwkxZCT0"
      },
      "source": [
        "batch = 250\n",
        "train_dataset = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=False)\n",
        "test_dataset = MosaicDataset1(test_mosaic_list_of_images, test_mosaic_label, test_fore_idx)\n",
        "test_loader = DataLoader(test_dataset,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "bg = []\n",
        "for i in range(12):\n",
        "  torch.manual_seed(i)\n",
        "  betag = torch.randn(250,9)#torch.ones((250,9))/9\n",
        "  bg.append( betag.requires_grad_() )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzb3ii4drXpu",
        "outputId": "70cb335e-5ae8-4d25-e1e1-7f0a5af536c7"
      },
      "source": [
        "bg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-1.1258, -1.1524, -0.2506,  ..., -0.3160, -2.1152,  0.3223],\n",
              "         [-1.2633,  0.3500,  0.3081,  ..., -0.2473, -1.3527, -1.6959],\n",
              "         [ 0.5667,  0.7935,  0.5988,  ...,  0.7502, -0.5855, -0.1734],\n",
              "         ...,\n",
              "         [ 0.8374, -0.7942, -0.3622,  ...,  0.0121,  0.8032, -0.6962],\n",
              "         [-1.0645,  0.2384, -0.3385,  ...,  0.9635, -1.0340,  0.1894],\n",
              "         [ 0.8253,  1.1038, -1.2491,  ..., -0.5940, -1.7125,  0.3617]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.5256, -0.7502, -0.6540,  ..., -0.9798, -1.6091, -0.7121],\n",
              "         [ 0.3037, -0.7773, -0.2515,  ...,  0.4676, -0.6970, -1.1608],\n",
              "         [ 0.6995,  0.1991,  0.8657,  ...,  1.1017, -0.1759, -2.2456],\n",
              "         ...,\n",
              "         [-0.4302,  0.1508,  0.6937,  ...,  0.0314,  2.6645,  0.1189],\n",
              "         [ 1.4484, -0.0213, -1.3367,  ...,  0.6279, -1.4719, -1.0291],\n",
              "         [ 0.9081, -1.2433,  1.6062,  ..., -0.1177, -0.5548, -0.0595]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0408,  0.9166, -1.3042,  ..., -1.0574, -0.1188, -0.9078],\n",
              "         [ 0.3452, -0.5713, -0.2351,  ..., -0.4327, -1.5071, -0.4586],\n",
              "         [-0.8480,  0.5266,  0.0299,  ...,  0.4640, -0.4986,  0.1289],\n",
              "         ...,\n",
              "         [ 1.5719,  1.0154, -2.1620,  ..., -1.0790,  1.5801, -1.6557],\n",
              "         [-1.1613,  0.3672, -0.3078,  ..., -1.2456, -0.1125,  0.6222],\n",
              "         [ 0.4521, -0.2505,  2.3728,  ..., -0.1377, -0.8815, -0.1671]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.0766,  0.3599, -0.7820,  ...,  1.6206, -1.5967, -0.0517],\n",
              "         [-0.3060,  0.2485, -0.2226,  ...,  0.4163,  0.2615,  0.9311],\n",
              "         [-0.5145, -1.6517,  1.0460,  ...,  0.5638,  2.2566,  1.8693],\n",
              "         ...,\n",
              "         [ 2.1181,  0.1464, -0.0447,  ...,  1.3816,  0.4975,  0.2814],\n",
              "         [-0.7639, -1.4938, -1.1430,  ...,  0.6355,  0.6700,  1.5335],\n",
              "         [-0.0191, -0.3568,  0.4536,  ..., -0.9493,  2.0439, -0.3827]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.9414,  1.2632, -0.1838,  ..., -2.6021,  0.6245, -0.8684],\n",
              "         [-0.2051,  0.3976,  0.6699,  ..., -2.1205,  1.5191, -0.6682],\n",
              "         [ 0.0031, -0.1535,  1.1396,  ..., -0.7588, -0.1853, -0.8558],\n",
              "         ...,\n",
              "         [ 1.6794, -0.5509,  0.4118,  ...,  0.9084, -0.8626, -0.6553],\n",
              "         [ 0.6058, -0.5888,  0.9448,  ...,  0.0072, -0.2579,  1.7659],\n",
              "         [-1.2965,  0.2970, -0.5833,  ...,  1.7838, -0.4794,  0.5579]],\n",
              "        requires_grad=True),\n",
              " tensor([[ 1.8423,  0.5189, -1.7119,  ..., -0.1307, -1.4374,  0.3908],\n",
              "         [-0.0190, -1.3527, -0.7308,  ..., -0.7823,  2.7799,  1.2220],\n",
              "         [-0.3364, -0.9651, -0.1297,  ..., -0.4374,  0.7792, -0.0583],\n",
              "         ...,\n",
              "         [ 0.6700, -0.5400,  0.2353,  ..., -1.0840, -0.6141, -0.0155],\n",
              "         [ 0.4779, -0.4648, -0.1366,  ...,  0.1162,  3.0351, -0.2885],\n",
              "         [-0.6777, -0.1373, -0.7330,  ...,  0.6185, -0.3036, -1.0850]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.2113,  0.6304, -1.4713,  ...,  0.3295,  0.3264, -0.4806],\n",
              "         [ 1.1032,  2.5485,  0.3006,  ..., -1.6279, -1.4801, -1.0631],\n",
              "         [ 0.3630,  0.3995,  0.1457,  ..., -1.3437,  0.8535,  0.8811],\n",
              "         ...,\n",
              "         [-0.5519,  0.2253,  0.4891,  ..., -0.0110, -0.6023, -0.7230],\n",
              "         [-1.1593, -0.6551,  1.6578,  ...,  0.4795, -1.3562,  0.2920],\n",
              "         [ 0.3474, -0.9874, -0.0130,  ...,  0.6061,  0.8639, -0.9552]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8201,  0.3956,  0.8989,  ..., -0.6411, -0.8937,  0.9265],\n",
              "         [-0.5355, -1.1597, -0.4602,  ...,  1.0902, -1.5827, -0.3246],\n",
              "         [ 1.9264, -0.3300,  0.1984,  ..., -0.2093, -0.2153, -1.8157],\n",
              "         ...,\n",
              "         [-0.6910,  0.3328,  2.2102,  ..., -0.0383,  0.4400, -0.8350],\n",
              "         [-0.2194, -0.7611, -0.0921,  ..., -0.3143, -0.4196,  1.1570],\n",
              "         [-0.8934, -1.7705,  0.3805,  ...,  0.1963, -0.7307,  1.3581]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.1892,  1.3932,  2.1059,  ...,  2.1414,  0.1317, -0.6388],\n",
              "         [ 1.3384, -1.1908, -0.7601,  ..., -0.1051,  0.4414,  0.6590],\n",
              "         [-0.7585, -0.6001, -0.3948,  ..., -1.7526,  0.3920,  0.8295],\n",
              "         ...,\n",
              "         [-0.0557, -0.1032, -0.4624,  ..., -0.1339, -1.6662, -0.4955],\n",
              "         [ 1.0884, -0.4479, -0.0847,  ...,  1.7487, -1.6152, -1.8258],\n",
              "         [ 1.7062,  1.1041, -1.3736,  ..., -1.5244,  0.4869, -1.7420]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0674, -0.7172,  1.0897,  ..., -0.7737, -2.4656,  0.9968],\n",
              "         [ 0.4524, -0.3464, -0.7245,  ...,  0.2331, -1.1433,  0.8289],\n",
              "         [ 0.9534,  0.2948,  1.5159,  ...,  0.3971,  0.4058, -0.5274],\n",
              "         ...,\n",
              "         [-0.3297, -0.3700,  1.9490,  ..., -0.0443,  1.8073, -0.6388],\n",
              "         [ 0.0977,  0.1862,  1.4303,  ..., -1.9735, -1.1663,  1.7066],\n",
              "         [-0.8396, -2.5271, -1.0791,  ...,  0.1053,  1.2463, -0.7709]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8173, -0.5556, -0.8267,  ..., -0.5133,  2.6278, -0.7465],\n",
              "         [ 1.0051, -0.2568,  0.4765,  ..., -0.2496,  0.8298,  1.1209],\n",
              "         [ 0.9999,  1.1167,  1.0763,  ...,  0.0562,  0.2456,  0.9535],\n",
              "         ...,\n",
              "         [-1.0042, -0.7732,  0.9129,  ..., -0.4342,  1.3256, -0.6357],\n",
              "         [-0.5979,  1.2285,  1.0288,  ..., -1.4067,  0.2403,  0.5257],\n",
              "         [-1.7332, -0.2443,  0.1425,  ..., -0.9291,  1.4324, -0.2338]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.5108,  1.0283, -0.3532,  ...,  0.1421, -0.5243, -0.2487],\n",
              "         [-0.5252,  2.8922, -0.5947,  ..., -0.0080,  0.2479,  1.5727],\n",
              "         [-1.6395, -1.5925, -0.1546,  ..., -0.3935,  0.6171,  0.7528],\n",
              "         ...,\n",
              "         [-0.3538,  0.1294,  1.1873,  ..., -0.2866, -0.3111,  0.2674],\n",
              "         [ 1.7757, -0.1730,  0.6679,  ..., -0.2519,  0.8360, -0.4348],\n",
              "         [ 0.4242,  0.7649, -0.5807,  ..., -0.7654, -0.1086,  0.4636]],\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    self.linear1 = nn.Linear(5,100)\n",
        "    self.linear2 = nn.Linear(100,3)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "what_net.load_state_dict(torch.load(\"blob_what_net.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8Wch99l4yB"
      },
      "source": [
        "def attn_avg(x,beta):\n",
        "  y = torch.zeros([batch,5], dtype=torch.float64)\n",
        "  y = y.to(\"cuda\")\n",
        "  alpha = F.softmax(beta,dim=1)   # alphas\n",
        "  #print(alpha[0],x[0,:])\n",
        "  for i in range(9):            \n",
        "    alpha1 = alpha[:,i]      \n",
        "    y = y + torch.mul(alpha1[:,None],x[:,i])\n",
        "  return y,alpha\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz1Kpw12loV6"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,criter):\n",
        "  what.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  correct = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx= data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      beta = bg[i]  # beta for ith batch\n",
        "      inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "      avg,alpha = attn_avg(inputs,beta)\n",
        "      alpha = alpha.to(\"cuda\")\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += sum(predicted == labels)\n",
        "      tot += len(predicted)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis,correct.item(),tot,correct.item()/tot"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAY-x6UAwrwE"
      },
      "source": [
        "for param in what_net.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toCktPanH0S"
      },
      "source": [
        "\n",
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "optim1 = []\n",
        "for i in range(12):\n",
        "  optim1.append(optim.RMSprop([bg[i]], lr=0.01))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPaYaojinMTA",
        "outputId": "c43b4096-424a-4d5f-f9d9-02414993ba29"
      },
      "source": [
        "# instantiate optimizer\n",
        "#optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.001)#, momentum=0.9)#,nesterov=True)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  #what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    beta = bg[i] # alpha for ith batch\n",
        "    #print(labels)\n",
        "    inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    #optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,beta)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    #optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 12.050 correct: 1071.000, total: 3000.000, accuracy: 0.357\n",
            "training epoch: [1 ] loss: 9.999 correct: 1251.000, total: 3000.000, accuracy: 0.417\n",
            "training epoch: [2 ] loss: 8.679 correct: 1375.000, total: 3000.000, accuracy: 0.458\n",
            "training epoch: [3 ] loss: 7.710 correct: 1492.000, total: 3000.000, accuracy: 0.497\n",
            "training epoch: [4 ] loss: 6.943 correct: 1576.000, total: 3000.000, accuracy: 0.525\n",
            "training epoch: [5 ] loss: 6.315 correct: 1654.000, total: 3000.000, accuracy: 0.551\n",
            "training epoch: [6 ] loss: 5.794 correct: 1720.000, total: 3000.000, accuracy: 0.573\n",
            "training epoch: [7 ] loss: 5.334 correct: 1774.000, total: 3000.000, accuracy: 0.591\n",
            "training epoch: [8 ] loss: 4.936 correct: 1831.000, total: 3000.000, accuracy: 0.610\n",
            "training epoch: [9 ] loss: 4.585 correct: 1871.000, total: 3000.000, accuracy: 0.624\n",
            "training epoch: [10 ] loss: 4.273 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [11 ] loss: 3.992 correct: 1975.000, total: 3000.000, accuracy: 0.658\n",
            "training epoch: [12 ] loss: 3.740 correct: 2019.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [13 ] loss: 3.505 correct: 2059.000, total: 3000.000, accuracy: 0.686\n",
            "training epoch: [14 ] loss: 3.290 correct: 2088.000, total: 3000.000, accuracy: 0.696\n",
            "training epoch: [15 ] loss: 3.091 correct: 2121.000, total: 3000.000, accuracy: 0.707\n",
            "training epoch: [16 ] loss: 2.909 correct: 2152.000, total: 3000.000, accuracy: 0.717\n",
            "training epoch: [17 ] loss: 2.741 correct: 2190.000, total: 3000.000, accuracy: 0.730\n",
            "training epoch: [18 ] loss: 2.592 correct: 2227.000, total: 3000.000, accuracy: 0.742\n",
            "training epoch: [19 ] loss: 2.452 correct: 2256.000, total: 3000.000, accuracy: 0.752\n",
            "training epoch: [20 ] loss: 2.324 correct: 2286.000, total: 3000.000, accuracy: 0.762\n",
            "training epoch: [21 ] loss: 2.206 correct: 2313.000, total: 3000.000, accuracy: 0.771\n",
            "training epoch: [22 ] loss: 2.095 correct: 2338.000, total: 3000.000, accuracy: 0.779\n",
            "training epoch: [23 ] loss: 1.994 correct: 2356.000, total: 3000.000, accuracy: 0.785\n",
            "training epoch: [24 ] loss: 1.903 correct: 2378.000, total: 3000.000, accuracy: 0.793\n",
            "training epoch: [25 ] loss: 1.819 correct: 2396.000, total: 3000.000, accuracy: 0.799\n",
            "training epoch: [26 ] loss: 1.741 correct: 2412.000, total: 3000.000, accuracy: 0.804\n",
            "training epoch: [27 ] loss: 1.668 correct: 2429.000, total: 3000.000, accuracy: 0.810\n",
            "training epoch: [28 ] loss: 1.598 correct: 2449.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [29 ] loss: 1.530 correct: 2458.000, total: 3000.000, accuracy: 0.819\n",
            "training epoch: [30 ] loss: 1.467 correct: 2479.000, total: 3000.000, accuracy: 0.826\n",
            "training epoch: [31 ] loss: 1.408 correct: 2490.000, total: 3000.000, accuracy: 0.830\n",
            "training epoch: [32 ] loss: 1.349 correct: 2503.000, total: 3000.000, accuracy: 0.834\n",
            "training epoch: [33 ] loss: 1.297 correct: 2521.000, total: 3000.000, accuracy: 0.840\n",
            "training epoch: [34 ] loss: 1.246 correct: 2537.000, total: 3000.000, accuracy: 0.846\n",
            "training epoch: [35 ] loss: 1.201 correct: 2549.000, total: 3000.000, accuracy: 0.850\n",
            "training epoch: [36 ] loss: 1.159 correct: 2566.000, total: 3000.000, accuracy: 0.855\n",
            "training epoch: [37 ] loss: 1.120 correct: 2576.000, total: 3000.000, accuracy: 0.859\n",
            "training epoch: [38 ] loss: 1.083 correct: 2586.000, total: 3000.000, accuracy: 0.862\n",
            "training epoch: [39 ] loss: 1.047 correct: 2602.000, total: 3000.000, accuracy: 0.867\n",
            "training epoch: [40 ] loss: 1.012 correct: 2610.000, total: 3000.000, accuracy: 0.870\n",
            "training epoch: [41 ] loss: 0.979 correct: 2614.000, total: 3000.000, accuracy: 0.871\n",
            "training epoch: [42 ] loss: 0.948 correct: 2621.000, total: 3000.000, accuracy: 0.874\n",
            "training epoch: [43 ] loss: 0.919 correct: 2628.000, total: 3000.000, accuracy: 0.876\n",
            "training epoch: [44 ] loss: 0.892 correct: 2640.000, total: 3000.000, accuracy: 0.880\n",
            "training epoch: [45 ] loss: 0.867 correct: 2654.000, total: 3000.000, accuracy: 0.885\n",
            "training epoch: [46 ] loss: 0.843 correct: 2664.000, total: 3000.000, accuracy: 0.888\n",
            "training epoch: [47 ] loss: 0.820 correct: 2667.000, total: 3000.000, accuracy: 0.889\n",
            "training epoch: [48 ] loss: 0.798 correct: 2672.000, total: 3000.000, accuracy: 0.891\n",
            "training epoch: [49 ] loss: 0.778 correct: 2679.000, total: 3000.000, accuracy: 0.893\n",
            "training epoch: [50 ] loss: 0.758 correct: 2682.000, total: 3000.000, accuracy: 0.894\n",
            "training epoch: [51 ] loss: 0.738 correct: 2692.000, total: 3000.000, accuracy: 0.897\n",
            "training epoch: [52 ] loss: 0.719 correct: 2697.000, total: 3000.000, accuracy: 0.899\n",
            "training epoch: [53 ] loss: 0.703 correct: 2706.000, total: 3000.000, accuracy: 0.902\n",
            "training epoch: [54 ] loss: 0.688 correct: 2710.000, total: 3000.000, accuracy: 0.903\n",
            "training epoch: [55 ] loss: 0.672 correct: 2714.000, total: 3000.000, accuracy: 0.905\n",
            "training epoch: [56 ] loss: 0.658 correct: 2719.000, total: 3000.000, accuracy: 0.906\n",
            "training epoch: [57 ] loss: 0.645 correct: 2723.000, total: 3000.000, accuracy: 0.908\n",
            "training epoch: [58 ] loss: 0.632 correct: 2725.000, total: 3000.000, accuracy: 0.908\n",
            "training epoch: [59 ] loss: 0.619 correct: 2731.000, total: 3000.000, accuracy: 0.910\n",
            "training epoch: [60 ] loss: 0.607 correct: 2732.000, total: 3000.000, accuracy: 0.911\n",
            "training epoch: [61 ] loss: 0.594 correct: 2738.000, total: 3000.000, accuracy: 0.913\n",
            "training epoch: [62 ] loss: 0.581 correct: 2746.000, total: 3000.000, accuracy: 0.915\n",
            "training epoch: [63 ] loss: 0.569 correct: 2748.000, total: 3000.000, accuracy: 0.916\n",
            "training epoch: [64 ] loss: 0.558 correct: 2752.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [65 ] loss: 0.546 correct: 2759.000, total: 3000.000, accuracy: 0.920\n",
            "training epoch: [66 ] loss: 0.535 correct: 2766.000, total: 3000.000, accuracy: 0.922\n",
            "training epoch: [67 ] loss: 0.524 correct: 2771.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [68 ] loss: 0.514 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [69 ] loss: 0.504 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [70 ] loss: 0.494 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [71 ] loss: 0.485 correct: 2790.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [72 ] loss: 0.476 correct: 2796.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [73 ] loss: 0.468 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [74 ] loss: 0.460 correct: 2802.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [75 ] loss: 0.452 correct: 2804.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [76 ] loss: 0.444 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [77 ] loss: 0.436 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [78 ] loss: 0.428 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [79 ] loss: 0.422 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [80 ] loss: 0.415 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [81 ] loss: 0.409 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [82 ] loss: 0.403 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [83 ] loss: 0.397 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [84 ] loss: 0.391 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [85 ] loss: 0.386 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [86 ] loss: 0.380 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [87 ] loss: 0.375 correct: 2831.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [88 ] loss: 0.370 correct: 2833.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [89 ] loss: 0.364 correct: 2833.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [90 ] loss: 0.359 correct: 2834.000, total: 3000.000, accuracy: 0.945\n",
            "training epoch: [91 ] loss: 0.354 correct: 2834.000, total: 3000.000, accuracy: 0.945\n",
            "training epoch: [92 ] loss: 0.349 correct: 2837.000, total: 3000.000, accuracy: 0.946\n",
            "training epoch: [93 ] loss: 0.344 correct: 2841.000, total: 3000.000, accuracy: 0.947\n",
            "training epoch: [94 ] loss: 0.339 correct: 2841.000, total: 3000.000, accuracy: 0.947\n",
            "training epoch: [95 ] loss: 0.334 correct: 2842.000, total: 3000.000, accuracy: 0.947\n",
            "training epoch: [96 ] loss: 0.330 correct: 2842.000, total: 3000.000, accuracy: 0.947\n",
            "training epoch: [97 ] loss: 0.325 correct: 2843.000, total: 3000.000, accuracy: 0.948\n",
            "training epoch: [98 ] loss: 0.321 correct: 2844.000, total: 3000.000, accuracy: 0.948\n",
            "training epoch: [99 ] loss: 0.317 correct: 2848.000, total: 3000.000, accuracy: 0.949\n",
            "training epoch: [100 ] loss: 0.313 correct: 2851.000, total: 3000.000, accuracy: 0.950\n",
            "training epoch: [101 ] loss: 0.309 correct: 2855.000, total: 3000.000, accuracy: 0.952\n",
            "training epoch: [102 ] loss: 0.306 correct: 2856.000, total: 3000.000, accuracy: 0.952\n",
            "training epoch: [103 ] loss: 0.302 correct: 2857.000, total: 3000.000, accuracy: 0.952\n",
            "training epoch: [104 ] loss: 0.298 correct: 2859.000, total: 3000.000, accuracy: 0.953\n",
            "training epoch: [105 ] loss: 0.294 correct: 2860.000, total: 3000.000, accuracy: 0.953\n",
            "training epoch: [106 ] loss: 0.291 correct: 2860.000, total: 3000.000, accuracy: 0.953\n",
            "training epoch: [107 ] loss: 0.287 correct: 2861.000, total: 3000.000, accuracy: 0.954\n",
            "training epoch: [108 ] loss: 0.284 correct: 2863.000, total: 3000.000, accuracy: 0.954\n",
            "training epoch: [109 ] loss: 0.282 correct: 2863.000, total: 3000.000, accuracy: 0.954\n",
            "training epoch: [110 ] loss: 0.279 correct: 2863.000, total: 3000.000, accuracy: 0.954\n",
            "training epoch: [111 ] loss: 0.276 correct: 2865.000, total: 3000.000, accuracy: 0.955\n",
            "training epoch: [112 ] loss: 0.273 correct: 2865.000, total: 3000.000, accuracy: 0.955\n",
            "training epoch: [113 ] loss: 0.270 correct: 2866.000, total: 3000.000, accuracy: 0.955\n",
            "training epoch: [114 ] loss: 0.268 correct: 2867.000, total: 3000.000, accuracy: 0.956\n",
            "training epoch: [115 ] loss: 0.265 correct: 2869.000, total: 3000.000, accuracy: 0.956\n",
            "training epoch: [116 ] loss: 0.263 correct: 2870.000, total: 3000.000, accuracy: 0.957\n",
            "training epoch: [117 ] loss: 0.261 correct: 2870.000, total: 3000.000, accuracy: 0.957\n",
            "training epoch: [118 ] loss: 0.258 correct: 2871.000, total: 3000.000, accuracy: 0.957\n",
            "training epoch: [119 ] loss: 0.256 correct: 2871.000, total: 3000.000, accuracy: 0.957\n",
            "training epoch: [120 ] loss: 0.254 correct: 2873.000, total: 3000.000, accuracy: 0.958\n",
            "training epoch: [121 ] loss: 0.252 correct: 2874.000, total: 3000.000, accuracy: 0.958\n",
            "training epoch: [122 ] loss: 0.250 correct: 2874.000, total: 3000.000, accuracy: 0.958\n",
            "training epoch: [123 ] loss: 0.248 correct: 2875.000, total: 3000.000, accuracy: 0.958\n",
            "training epoch: [124 ] loss: 0.246 correct: 2876.000, total: 3000.000, accuracy: 0.959\n",
            "training epoch: [125 ] loss: 0.244 correct: 2877.000, total: 3000.000, accuracy: 0.959\n",
            "training epoch: [126 ] loss: 0.242 correct: 2877.000, total: 3000.000, accuracy: 0.959\n",
            "training epoch: [127 ] loss: 0.240 correct: 2878.000, total: 3000.000, accuracy: 0.959\n",
            "training epoch: [128 ] loss: 0.239 correct: 2879.000, total: 3000.000, accuracy: 0.960\n",
            "training epoch: [129 ] loss: 0.237 correct: 2879.000, total: 3000.000, accuracy: 0.960\n",
            "training epoch: [130 ] loss: 0.235 correct: 2880.000, total: 3000.000, accuracy: 0.960\n",
            "training epoch: [131 ] loss: 0.234 correct: 2880.000, total: 3000.000, accuracy: 0.960\n",
            "training epoch: [132 ] loss: 0.232 correct: 2882.000, total: 3000.000, accuracy: 0.961\n",
            "training epoch: [133 ] loss: 0.230 correct: 2882.000, total: 3000.000, accuracy: 0.961\n",
            "training epoch: [134 ] loss: 0.229 correct: 2882.000, total: 3000.000, accuracy: 0.961\n",
            "training epoch: [135 ] loss: 0.227 correct: 2883.000, total: 3000.000, accuracy: 0.961\n",
            "training epoch: [136 ] loss: 0.226 correct: 2885.000, total: 3000.000, accuracy: 0.962\n",
            "training epoch: [137 ] loss: 0.225 correct: 2885.000, total: 3000.000, accuracy: 0.962\n",
            "training epoch: [138 ] loss: 0.223 correct: 2885.000, total: 3000.000, accuracy: 0.962\n",
            "training epoch: [139 ] loss: 0.222 correct: 2888.000, total: 3000.000, accuracy: 0.963\n",
            "training epoch: [140 ] loss: 0.221 correct: 2889.000, total: 3000.000, accuracy: 0.963\n",
            "training epoch: [141 ] loss: 0.218 correct: 2891.000, total: 3000.000, accuracy: 0.964\n",
            "training epoch: [142 ] loss: 0.215 correct: 2892.000, total: 3000.000, accuracy: 0.964\n",
            "training epoch: [143 ] loss: 0.214 correct: 2892.000, total: 3000.000, accuracy: 0.964\n",
            "training epoch: [144 ] loss: 0.213 correct: 2893.000, total: 3000.000, accuracy: 0.964\n",
            "training epoch: [145 ] loss: 0.211 correct: 2894.000, total: 3000.000, accuracy: 0.965\n",
            "training epoch: [146 ] loss: 0.209 correct: 2894.000, total: 3000.000, accuracy: 0.965\n",
            "training epoch: [147 ] loss: 0.208 correct: 2896.000, total: 3000.000, accuracy: 0.965\n",
            "training epoch: [148 ] loss: 0.206 correct: 2897.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [149 ] loss: 0.205 correct: 2897.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [150 ] loss: 0.204 correct: 2897.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [151 ] loss: 0.203 correct: 2897.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [152 ] loss: 0.202 correct: 2897.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [153 ] loss: 0.201 correct: 2897.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [154 ] loss: 0.200 correct: 2897.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [155 ] loss: 0.199 correct: 2898.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [156 ] loss: 0.198 correct: 2898.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [157 ] loss: 0.196 correct: 2898.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [158 ] loss: 0.195 correct: 2899.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [159 ] loss: 0.194 correct: 2899.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [160 ] loss: 0.193 correct: 2899.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [161 ] loss: 0.192 correct: 2899.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [162 ] loss: 0.191 correct: 2899.000, total: 3000.000, accuracy: 0.966\n",
            "training epoch: [163 ] loss: 0.190 correct: 2900.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [164 ] loss: 0.189 correct: 2900.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [165 ] loss: 0.188 correct: 2900.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [166 ] loss: 0.187 correct: 2900.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [167 ] loss: 0.186 correct: 2901.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [168 ] loss: 0.185 correct: 2901.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [169 ] loss: 0.184 correct: 2901.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [170 ] loss: 0.184 correct: 2901.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [171 ] loss: 0.183 correct: 2901.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [172 ] loss: 0.182 correct: 2901.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [173 ] loss: 0.181 correct: 2901.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [174 ] loss: 0.180 correct: 2901.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [175 ] loss: 0.179 correct: 2902.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [176 ] loss: 0.178 correct: 2902.000, total: 3000.000, accuracy: 0.967\n",
            "training epoch: [177 ] loss: 0.178 correct: 2903.000, total: 3000.000, accuracy: 0.968\n",
            "training epoch: [178 ] loss: 0.177 correct: 2904.000, total: 3000.000, accuracy: 0.968\n",
            "training epoch: [179 ] loss: 0.176 correct: 2904.000, total: 3000.000, accuracy: 0.968\n",
            "training epoch: [180 ] loss: 0.175 correct: 2904.000, total: 3000.000, accuracy: 0.968\n",
            "training epoch: [181 ] loss: 0.174 correct: 2905.000, total: 3000.000, accuracy: 0.968\n",
            "training epoch: [182 ] loss: 0.173 correct: 2905.000, total: 3000.000, accuracy: 0.968\n",
            "training epoch: [183 ] loss: 0.171 correct: 2906.000, total: 3000.000, accuracy: 0.969\n",
            "training epoch: [184 ] loss: 0.170 correct: 2907.000, total: 3000.000, accuracy: 0.969\n",
            "training epoch: [185 ] loss: 0.169 correct: 2907.000, total: 3000.000, accuracy: 0.969\n",
            "training epoch: [186 ] loss: 0.168 correct: 2908.000, total: 3000.000, accuracy: 0.969\n",
            "training epoch: [187 ] loss: 0.167 correct: 2908.000, total: 3000.000, accuracy: 0.969\n",
            "training epoch: [188 ] loss: 0.166 correct: 2908.000, total: 3000.000, accuracy: 0.969\n",
            "training epoch: [189 ] loss: 0.166 correct: 2908.000, total: 3000.000, accuracy: 0.969\n",
            "training epoch: [190 ] loss: 0.165 correct: 2909.000, total: 3000.000, accuracy: 0.970\n",
            "training epoch: [191 ] loss: 0.164 correct: 2910.000, total: 3000.000, accuracy: 0.970\n",
            "training epoch: [192 ] loss: 0.164 correct: 2911.000, total: 3000.000, accuracy: 0.970\n",
            "training epoch: [193 ] loss: 0.163 correct: 2911.000, total: 3000.000, accuracy: 0.970\n",
            "training epoch: [194 ] loss: 0.162 correct: 2912.000, total: 3000.000, accuracy: 0.971\n",
            "training epoch: [195 ] loss: 0.162 correct: 2912.000, total: 3000.000, accuracy: 0.971\n",
            "training epoch: [196 ] loss: 0.161 correct: 2912.000, total: 3000.000, accuracy: 0.971\n",
            "training epoch: [197 ] loss: 0.160 correct: 2913.000, total: 3000.000, accuracy: 0.971\n",
            "training epoch: [198 ] loss: 0.158 correct: 2913.000, total: 3000.000, accuracy: 0.971\n",
            "training epoch: [199 ] loss: 0.157 correct: 2916.000, total: 3000.000, accuracy: 0.972\n",
            "training epoch: [200 ] loss: 0.157 correct: 2917.000, total: 3000.000, accuracy: 0.972\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "NoQpS_6scRsC",
        "outputId": "916c3db1-0648-4fde-fe3f-ab34a110a12c"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>302</td>\n",
              "      <td>2698</td>\n",
              "      <td>135</td>\n",
              "      <td>936</td>\n",
              "      <td>179</td>\n",
              "      <td>1750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>276</td>\n",
              "      <td>2724</td>\n",
              "      <td>163</td>\n",
              "      <td>1088</td>\n",
              "      <td>192</td>\n",
              "      <td>1557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>261</td>\n",
              "      <td>2739</td>\n",
              "      <td>183</td>\n",
              "      <td>1192</td>\n",
              "      <td>193</td>\n",
              "      <td>1432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>265</td>\n",
              "      <td>2735</td>\n",
              "      <td>210</td>\n",
              "      <td>1282</td>\n",
              "      <td>191</td>\n",
              "      <td>1317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>265</td>\n",
              "      <td>2735</td>\n",
              "      <td>234</td>\n",
              "      <td>1342</td>\n",
              "      <td>193</td>\n",
              "      <td>1231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>460</td>\n",
              "      <td>2540</td>\n",
              "      <td>626</td>\n",
              "      <td>2286</td>\n",
              "      <td>15</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>197</td>\n",
              "      <td>461</td>\n",
              "      <td>2539</td>\n",
              "      <td>627</td>\n",
              "      <td>2286</td>\n",
              "      <td>14</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>461</td>\n",
              "      <td>2539</td>\n",
              "      <td>626</td>\n",
              "      <td>2287</td>\n",
              "      <td>14</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>199</td>\n",
              "      <td>461</td>\n",
              "      <td>2539</td>\n",
              "      <td>630</td>\n",
              "      <td>2286</td>\n",
              "      <td>11</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>200</td>\n",
              "      <td>462</td>\n",
              "      <td>2538</td>\n",
              "      <td>630</td>\n",
              "      <td>2287</td>\n",
              "      <td>11</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>201 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0         0           302  ...                    179                    1750\n",
              "1         1           276  ...                    192                    1557\n",
              "2         2           261  ...                    193                    1432\n",
              "3         3           265  ...                    191                    1317\n",
              "4         4           265  ...                    193                    1231\n",
              "..      ...           ...  ...                    ...                     ...\n",
              "196     196           460  ...                     15                      73\n",
              "197     197           461  ...                     14                      73\n",
              "198     198           461  ...                     14                      73\n",
              "199     199           461  ...                     11                      73\n",
              "200     200           462  ...                     11                      72\n",
              "\n",
              "[201 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "IMAhRdxOcVf6",
        "outputId": "7ea1602c-3725-4c89-d94c-cef3a6ff19af"
      },
      "source": [
        "fig= plt.figure(figsize=(6,6))\n",
        "plt.plot(df_train[columns[0]],df_train[columns[3]]/30, label =\"focus_true_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[4]]/30, label =\"focus_false_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[5]]/30, label =\"focus_true_pred_false \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[6]]/30, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Train set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"percentage of data\")\n",
        "plt.xticks([0,50,100,150,200])\n",
        "#plt.vlines(vline_list,min(min(df_train[columns[3]]/300),min(df_train[columns[4]]/300),min(df_train[columns[5]]/300),min(df_train[columns[6]]/300)), max(max(df_train[columns[3]]/300),max(df_train[columns[4]]/300),max(df_train[columns[5]]/300),max(df_train[columns[6]]/300)),linestyles='dotted')\n",
        "plt.show()\n",
        "fig.savefig(\"train_analysis.pdf\")\n",
        "fig.savefig(\"train_analysis.png\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in bg:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "torch.save({\n",
        "            'epoch': 500,\n",
        "            'model_state_dict': what_net.state_dict(),\n",
        "            #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "            \"optimizer_alpha\":optim1,\n",
        "            \"FTPT_analysis\":analysis_data_tr,\n",
        "            \"alpha\":aph\n",
        "\n",
        "            }, \"type4_what_net_500.pt\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVzrDOGS4UxU",
        "outputId": "466d9c02-3fd3-41d5-8665-bec81a2d6cbe"
      },
      "source": [
        "aph[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08846691, 0.04294628, 0.11967705, 0.02797441, 0.13886474,\n",
              "       0.28934133, 0.1560873 , 0.00712901, 0.12951294], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwTDpx6STIPh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}