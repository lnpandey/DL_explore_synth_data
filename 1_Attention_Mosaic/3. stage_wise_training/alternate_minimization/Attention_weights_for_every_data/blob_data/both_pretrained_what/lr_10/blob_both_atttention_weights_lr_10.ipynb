{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "blob_both_atttention_weights_lr_10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "train_data = np.load(\"train_blob_data.npy\",allow_pickle=True)\n",
        "\n",
        "test_data = np.load(\"test_blob_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL771xuGZC5Q"
      },
      "source": [
        "mosaic_list_of_images = train_data[0][\"mosaic_list\"]\n",
        "mosaic_label = train_data[0][\"mosaic_label\"]\n",
        "fore_idx = train_data[0][\"fore_idx\"]\n",
        "\n",
        "\n",
        "test_mosaic_list_of_images = test_data[0][\"mosaic_list\"]\n",
        "test_mosaic_label = test_data[0][\"mosaic_label\"]\n",
        "test_fore_idx = test_data[0][\"fore_idx\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qfRXfNZCao"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf76JwkxZCT0"
      },
      "source": [
        "batch = 250\n",
        "train_dataset = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=False)\n",
        "test_dataset = MosaicDataset1(test_mosaic_list_of_images, test_mosaic_label, test_fore_idx)\n",
        "test_loader = DataLoader(test_dataset,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "bg = []\n",
        "for i in range(12):\n",
        "  torch.manual_seed(i)\n",
        "  betag = torch.randn(250,9)#torch.ones((250,9))/9\n",
        "  bg.append( betag.requires_grad_() )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzb3ii4drXpu",
        "outputId": "7c00736e-7922-4ec2-ba66-126f493675a9"
      },
      "source": [
        "bg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-1.1258, -1.1524, -0.2506,  ..., -0.3160, -2.1152,  0.3223],\n",
              "         [-1.2633,  0.3500,  0.3081,  ..., -0.2473, -1.3527, -1.6959],\n",
              "         [ 0.5667,  0.7935,  0.5988,  ...,  0.7502, -0.5855, -0.1734],\n",
              "         ...,\n",
              "         [ 0.8374, -0.7942, -0.3622,  ...,  0.0121,  0.8032, -0.6962],\n",
              "         [-1.0645,  0.2384, -0.3385,  ...,  0.9635, -1.0340,  0.1894],\n",
              "         [ 0.8253,  1.1038, -1.2491,  ..., -0.5940, -1.7125,  0.3617]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.5256, -0.7502, -0.6540,  ..., -0.9798, -1.6091, -0.7121],\n",
              "         [ 0.3037, -0.7773, -0.2515,  ...,  0.4676, -0.6970, -1.1608],\n",
              "         [ 0.6995,  0.1991,  0.8657,  ...,  1.1017, -0.1759, -2.2456],\n",
              "         ...,\n",
              "         [-0.4302,  0.1508,  0.6937,  ...,  0.0314,  2.6645,  0.1189],\n",
              "         [ 1.4484, -0.0213, -1.3367,  ...,  0.6279, -1.4719, -1.0291],\n",
              "         [ 0.9081, -1.2433,  1.6062,  ..., -0.1177, -0.5548, -0.0595]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0408,  0.9166, -1.3042,  ..., -1.0574, -0.1188, -0.9078],\n",
              "         [ 0.3452, -0.5713, -0.2351,  ..., -0.4327, -1.5071, -0.4586],\n",
              "         [-0.8480,  0.5266,  0.0299,  ...,  0.4640, -0.4986,  0.1289],\n",
              "         ...,\n",
              "         [ 1.5719,  1.0154, -2.1620,  ..., -1.0790,  1.5801, -1.6557],\n",
              "         [-1.1613,  0.3672, -0.3078,  ..., -1.2456, -0.1125,  0.6222],\n",
              "         [ 0.4521, -0.2505,  2.3728,  ..., -0.1377, -0.8815, -0.1671]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.0766,  0.3599, -0.7820,  ...,  1.6206, -1.5967, -0.0517],\n",
              "         [-0.3060,  0.2485, -0.2226,  ...,  0.4163,  0.2615,  0.9311],\n",
              "         [-0.5145, -1.6517,  1.0460,  ...,  0.5638,  2.2566,  1.8693],\n",
              "         ...,\n",
              "         [ 2.1181,  0.1464, -0.0447,  ...,  1.3816,  0.4975,  0.2814],\n",
              "         [-0.7639, -1.4938, -1.1430,  ...,  0.6355,  0.6700,  1.5335],\n",
              "         [-0.0191, -0.3568,  0.4536,  ..., -0.9493,  2.0439, -0.3827]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.9414,  1.2632, -0.1838,  ..., -2.6021,  0.6245, -0.8684],\n",
              "         [-0.2051,  0.3976,  0.6699,  ..., -2.1205,  1.5191, -0.6682],\n",
              "         [ 0.0031, -0.1535,  1.1396,  ..., -0.7588, -0.1853, -0.8558],\n",
              "         ...,\n",
              "         [ 1.6794, -0.5509,  0.4118,  ...,  0.9084, -0.8626, -0.6553],\n",
              "         [ 0.6058, -0.5888,  0.9448,  ...,  0.0072, -0.2579,  1.7659],\n",
              "         [-1.2965,  0.2970, -0.5833,  ...,  1.7838, -0.4794,  0.5579]],\n",
              "        requires_grad=True),\n",
              " tensor([[ 1.8423,  0.5189, -1.7119,  ..., -0.1307, -1.4374,  0.3908],\n",
              "         [-0.0190, -1.3527, -0.7308,  ..., -0.7823,  2.7799,  1.2220],\n",
              "         [-0.3364, -0.9651, -0.1297,  ..., -0.4374,  0.7792, -0.0583],\n",
              "         ...,\n",
              "         [ 0.6700, -0.5400,  0.2353,  ..., -1.0840, -0.6141, -0.0155],\n",
              "         [ 0.4779, -0.4648, -0.1366,  ...,  0.1162,  3.0351, -0.2885],\n",
              "         [-0.6777, -0.1373, -0.7330,  ...,  0.6185, -0.3036, -1.0850]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.2113,  0.6304, -1.4713,  ...,  0.3295,  0.3264, -0.4806],\n",
              "         [ 1.1032,  2.5485,  0.3006,  ..., -1.6279, -1.4801, -1.0631],\n",
              "         [ 0.3630,  0.3995,  0.1457,  ..., -1.3437,  0.8535,  0.8811],\n",
              "         ...,\n",
              "         [-0.5519,  0.2253,  0.4891,  ..., -0.0110, -0.6023, -0.7230],\n",
              "         [-1.1593, -0.6551,  1.6578,  ...,  0.4795, -1.3562,  0.2920],\n",
              "         [ 0.3474, -0.9874, -0.0130,  ...,  0.6061,  0.8639, -0.9552]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8201,  0.3956,  0.8989,  ..., -0.6411, -0.8937,  0.9265],\n",
              "         [-0.5355, -1.1597, -0.4602,  ...,  1.0902, -1.5827, -0.3246],\n",
              "         [ 1.9264, -0.3300,  0.1984,  ..., -0.2093, -0.2153, -1.8157],\n",
              "         ...,\n",
              "         [-0.6910,  0.3328,  2.2102,  ..., -0.0383,  0.4400, -0.8350],\n",
              "         [-0.2194, -0.7611, -0.0921,  ..., -0.3143, -0.4196,  1.1570],\n",
              "         [-0.8934, -1.7705,  0.3805,  ...,  0.1963, -0.7307,  1.3581]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.1892,  1.3932,  2.1059,  ...,  2.1414,  0.1317, -0.6388],\n",
              "         [ 1.3384, -1.1908, -0.7601,  ..., -0.1051,  0.4414,  0.6590],\n",
              "         [-0.7585, -0.6001, -0.3948,  ..., -1.7526,  0.3920,  0.8295],\n",
              "         ...,\n",
              "         [-0.0557, -0.1032, -0.4624,  ..., -0.1339, -1.6662, -0.4955],\n",
              "         [ 1.0884, -0.4479, -0.0847,  ...,  1.7487, -1.6152, -1.8258],\n",
              "         [ 1.7062,  1.1041, -1.3736,  ..., -1.5244,  0.4869, -1.7420]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0674, -0.7172,  1.0897,  ..., -0.7737, -2.4656,  0.9968],\n",
              "         [ 0.4524, -0.3464, -0.7245,  ...,  0.2331, -1.1433,  0.8289],\n",
              "         [ 0.9534,  0.2948,  1.5159,  ...,  0.3971,  0.4058, -0.5274],\n",
              "         ...,\n",
              "         [-0.3297, -0.3700,  1.9490,  ..., -0.0443,  1.8073, -0.6388],\n",
              "         [ 0.0977,  0.1862,  1.4303,  ..., -1.9735, -1.1663,  1.7066],\n",
              "         [-0.8396, -2.5271, -1.0791,  ...,  0.1053,  1.2463, -0.7709]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8173, -0.5556, -0.8267,  ..., -0.5133,  2.6278, -0.7465],\n",
              "         [ 1.0051, -0.2568,  0.4765,  ..., -0.2496,  0.8298,  1.1209],\n",
              "         [ 0.9999,  1.1167,  1.0763,  ...,  0.0562,  0.2456,  0.9535],\n",
              "         ...,\n",
              "         [-1.0042, -0.7732,  0.9129,  ..., -0.4342,  1.3256, -0.6357],\n",
              "         [-0.5979,  1.2285,  1.0288,  ..., -1.4067,  0.2403,  0.5257],\n",
              "         [-1.7332, -0.2443,  0.1425,  ..., -0.9291,  1.4324, -0.2338]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.5108,  1.0283, -0.3532,  ...,  0.1421, -0.5243, -0.2487],\n",
              "         [-0.5252,  2.8922, -0.5947,  ..., -0.0080,  0.2479,  1.5727],\n",
              "         [-1.6395, -1.5925, -0.1546,  ..., -0.3935,  0.6171,  0.7528],\n",
              "         ...,\n",
              "         [-0.3538,  0.1294,  1.1873,  ..., -0.2866, -0.3111,  0.2674],\n",
              "         [ 1.7757, -0.1730,  0.6679,  ..., -0.2519,  0.8360, -0.4348],\n",
              "         [ 0.4242,  0.7649, -0.5807,  ..., -0.7654, -0.1086,  0.4636]],\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    self.linear1 = nn.Linear(5,100)\n",
        "    self.linear2 = nn.Linear(100,3)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "what_net.load_state_dict(torch.load(\"blob_what_net.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8Wch99l4yB"
      },
      "source": [
        "def attn_avg(x,beta):\n",
        "  y = torch.zeros([batch,5], dtype=torch.float64)\n",
        "  y = y.to(\"cuda\")\n",
        "  alpha = F.softmax(beta,dim=1)   # alphas\n",
        "  #print(alpha[0],x[0,:])\n",
        "  for i in range(9):            \n",
        "    alpha1 = alpha[:,i]      \n",
        "    y = y + torch.mul(alpha1[:,None],x[:,i])\n",
        "  return y,alpha\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz1Kpw12loV6"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,criter):\n",
        "  what.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  correct = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx= data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      beta = bg[i]  # beta for ith batch\n",
        "      inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "      avg,alpha = attn_avg(inputs,beta)\n",
        "      alpha = alpha.to(\"cuda\")\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += sum(predicted == labels)\n",
        "      tot += len(predicted)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis,correct.item(),tot,correct.item()/tot"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAY-x6UAwrwE"
      },
      "source": [
        "# for param in what_net.parameters():\n",
        "#     param.requires_grad = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toCktPanH0S"
      },
      "source": [
        "\n",
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "optim1 = []\n",
        "for i in range(12):\n",
        "  optim1.append(optim.RMSprop([bg[i]], lr=10))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPaYaojinMTA",
        "outputId": "e2a6fd86-ac5c-408b-cf82-29df384b1aeb"
      },
      "source": [
        "# instantiate optimizer\n",
        "optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.001)#, momentum=0.9)#,nesterov=True)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    beta = bg[i] # alpha for ith batch\n",
        "    #print(labels)\n",
        "    inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,beta)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 12.050 correct: 1071.000, total: 3000.000, accuracy: 0.357\n",
            "training epoch: [1 ] loss: 2.449 correct: 1852.000, total: 3000.000, accuracy: 0.617\n",
            "training epoch: [2 ] loss: 1.529 correct: 2308.000, total: 3000.000, accuracy: 0.769\n",
            "training epoch: [3 ] loss: 1.253 correct: 2355.000, total: 3000.000, accuracy: 0.785\n",
            "training epoch: [4 ] loss: 1.047 correct: 2373.000, total: 3000.000, accuracy: 0.791\n",
            "training epoch: [5 ] loss: 0.942 correct: 2389.000, total: 3000.000, accuracy: 0.796\n",
            "training epoch: [6 ] loss: 0.899 correct: 2386.000, total: 3000.000, accuracy: 0.795\n",
            "training epoch: [7 ] loss: 0.865 correct: 2385.000, total: 3000.000, accuracy: 0.795\n",
            "training epoch: [8 ] loss: 0.852 correct: 2386.000, total: 3000.000, accuracy: 0.795\n",
            "training epoch: [9 ] loss: 0.827 correct: 2388.000, total: 3000.000, accuracy: 0.796\n",
            "training epoch: [10 ] loss: 0.793 correct: 2397.000, total: 3000.000, accuracy: 0.799\n",
            "training epoch: [11 ] loss: 0.778 correct: 2394.000, total: 3000.000, accuracy: 0.798\n",
            "training epoch: [12 ] loss: 0.767 correct: 2400.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [13 ] loss: 0.752 correct: 2392.000, total: 3000.000, accuracy: 0.797\n",
            "training epoch: [14 ] loss: 0.733 correct: 2399.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [15 ] loss: 0.724 correct: 2401.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [16 ] loss: 0.708 correct: 2401.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [17 ] loss: 0.702 correct: 2393.000, total: 3000.000, accuracy: 0.798\n",
            "training epoch: [18 ] loss: 0.680 correct: 2394.000, total: 3000.000, accuracy: 0.798\n",
            "training epoch: [19 ] loss: 0.670 correct: 2408.000, total: 3000.000, accuracy: 0.803\n",
            "training epoch: [20 ] loss: 0.660 correct: 2405.000, total: 3000.000, accuracy: 0.802\n",
            "training epoch: [21 ] loss: 0.654 correct: 2400.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [22 ] loss: 0.650 correct: 2404.000, total: 3000.000, accuracy: 0.801\n",
            "training epoch: [23 ] loss: 0.650 correct: 2399.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [24 ] loss: 0.630 correct: 2403.000, total: 3000.000, accuracy: 0.801\n",
            "training epoch: [25 ] loss: 0.621 correct: 2400.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [26 ] loss: 0.637 correct: 2396.000, total: 3000.000, accuracy: 0.799\n",
            "training epoch: [27 ] loss: 0.637 correct: 2400.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [28 ] loss: 0.601 correct: 2400.000, total: 3000.000, accuracy: 0.800\n",
            "training epoch: [29 ] loss: 0.591 correct: 2398.000, total: 3000.000, accuracy: 0.799\n",
            "training epoch: [30 ] loss: 0.586 correct: 2408.000, total: 3000.000, accuracy: 0.803\n",
            "training epoch: [31 ] loss: 0.575 correct: 2412.000, total: 3000.000, accuracy: 0.804\n",
            "training epoch: [32 ] loss: 0.569 correct: 2417.000, total: 3000.000, accuracy: 0.806\n",
            "training epoch: [33 ] loss: 0.565 correct: 2419.000, total: 3000.000, accuracy: 0.806\n",
            "training epoch: [34 ] loss: 0.562 correct: 2419.000, total: 3000.000, accuracy: 0.806\n",
            "training epoch: [35 ] loss: 0.559 correct: 2423.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [36 ] loss: 0.556 correct: 2422.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [37 ] loss: 0.555 correct: 2425.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [38 ] loss: 0.552 correct: 2427.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [39 ] loss: 0.550 correct: 2433.000, total: 3000.000, accuracy: 0.811\n",
            "training epoch: [40 ] loss: 0.547 correct: 2429.000, total: 3000.000, accuracy: 0.810\n",
            "training epoch: [41 ] loss: 0.551 correct: 2419.000, total: 3000.000, accuracy: 0.806\n",
            "training epoch: [42 ] loss: 0.633 correct: 2385.000, total: 3000.000, accuracy: 0.795\n",
            "training epoch: [43 ] loss: 0.556 correct: 2424.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [44 ] loss: 0.658 correct: 2388.000, total: 3000.000, accuracy: 0.796\n",
            "training epoch: [45 ] loss: 0.538 correct: 2435.000, total: 3000.000, accuracy: 0.812\n",
            "training epoch: [46 ] loss: 0.542 correct: 2427.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [47 ] loss: 0.554 correct: 2427.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [48 ] loss: 0.542 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [49 ] loss: 0.538 correct: 2414.000, total: 3000.000, accuracy: 0.805\n",
            "training epoch: [50 ] loss: 0.534 correct: 2420.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [51 ] loss: 0.530 correct: 2434.000, total: 3000.000, accuracy: 0.811\n",
            "training epoch: [52 ] loss: 0.529 correct: 2430.000, total: 3000.000, accuracy: 0.810\n",
            "training epoch: [53 ] loss: 0.527 correct: 2434.000, total: 3000.000, accuracy: 0.811\n",
            "training epoch: [54 ] loss: 0.529 correct: 2420.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [55 ] loss: 0.528 correct: 2418.000, total: 3000.000, accuracy: 0.806\n",
            "training epoch: [56 ] loss: 0.526 correct: 2416.000, total: 3000.000, accuracy: 0.805\n",
            "training epoch: [57 ] loss: 0.525 correct: 2415.000, total: 3000.000, accuracy: 0.805\n",
            "training epoch: [58 ] loss: 0.521 correct: 2432.000, total: 3000.000, accuracy: 0.811\n",
            "training epoch: [59 ] loss: 0.523 correct: 2422.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [60 ] loss: 0.523 correct: 2420.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [61 ] loss: 0.522 correct: 2422.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [62 ] loss: 0.523 correct: 2416.000, total: 3000.000, accuracy: 0.805\n",
            "training epoch: [63 ] loss: 0.523 correct: 2415.000, total: 3000.000, accuracy: 0.805\n",
            "training epoch: [64 ] loss: 0.521 correct: 2411.000, total: 3000.000, accuracy: 0.804\n",
            "training epoch: [65 ] loss: 0.517 correct: 2428.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [66 ] loss: 0.517 correct: 2420.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [67 ] loss: 0.516 correct: 2419.000, total: 3000.000, accuracy: 0.806\n",
            "training epoch: [68 ] loss: 0.515 correct: 2424.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [69 ] loss: 0.514 correct: 2423.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [70 ] loss: 0.514 correct: 2421.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [71 ] loss: 0.513 correct: 2421.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [72 ] loss: 0.512 correct: 2422.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [73 ] loss: 0.512 correct: 2429.000, total: 3000.000, accuracy: 0.810\n",
            "training epoch: [74 ] loss: 0.512 correct: 2423.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [75 ] loss: 0.512 correct: 2422.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [76 ] loss: 0.511 correct: 2422.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [77 ] loss: 0.511 correct: 2423.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [78 ] loss: 0.511 correct: 2419.000, total: 3000.000, accuracy: 0.806\n",
            "training epoch: [79 ] loss: 0.511 correct: 2421.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [80 ] loss: 0.511 correct: 2421.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [81 ] loss: 0.511 correct: 2420.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [82 ] loss: 0.510 correct: 2423.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [83 ] loss: 0.510 correct: 2424.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [84 ] loss: 0.509 correct: 2424.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [85 ] loss: 0.509 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [86 ] loss: 0.507 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [87 ] loss: 0.507 correct: 2424.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [88 ] loss: 0.506 correct: 2427.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [89 ] loss: 0.506 correct: 2423.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [90 ] loss: 0.506 correct: 2427.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [91 ] loss: 0.506 correct: 2422.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [92 ] loss: 0.506 correct: 2421.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [93 ] loss: 0.505 correct: 2421.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [94 ] loss: 0.505 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [95 ] loss: 0.505 correct: 2422.000, total: 3000.000, accuracy: 0.807\n",
            "training epoch: [96 ] loss: 0.504 correct: 2428.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [97 ] loss: 0.504 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [98 ] loss: 0.503 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [99 ] loss: 0.504 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [100 ] loss: 0.503 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [101 ] loss: 0.503 correct: 2428.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [102 ] loss: 0.504 correct: 2427.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [103 ] loss: 0.503 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [104 ] loss: 0.503 correct: 2425.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [105 ] loss: 0.503 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [106 ] loss: 0.503 correct: 2425.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [107 ] loss: 0.502 correct: 2426.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [108 ] loss: 0.502 correct: 2427.000, total: 3000.000, accuracy: 0.809\n",
            "training epoch: [109 ] loss: 0.501 correct: 2425.000, total: 3000.000, accuracy: 0.808\n",
            "training epoch: [110 ] loss: 0.501 correct: 2430.000, total: 3000.000, accuracy: 0.810\n",
            "training epoch: [111 ] loss: 0.501 correct: 2441.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [112 ] loss: 0.500 correct: 2438.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [113 ] loss: 0.500 correct: 2439.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [114 ] loss: 0.500 correct: 2437.000, total: 3000.000, accuracy: 0.812\n",
            "training epoch: [115 ] loss: 0.499 correct: 2437.000, total: 3000.000, accuracy: 0.812\n",
            "training epoch: [116 ] loss: 0.499 correct: 2438.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [117 ] loss: 0.499 correct: 2438.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [118 ] loss: 0.499 correct: 2438.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [119 ] loss: 0.499 correct: 2438.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [120 ] loss: 0.499 correct: 2438.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [121 ] loss: 0.498 correct: 2441.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [122 ] loss: 0.498 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [123 ] loss: 0.498 correct: 2437.000, total: 3000.000, accuracy: 0.812\n",
            "training epoch: [124 ] loss: 0.498 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [125 ] loss: 0.499 correct: 2431.000, total: 3000.000, accuracy: 0.810\n",
            "training epoch: [126 ] loss: 0.498 correct: 2434.000, total: 3000.000, accuracy: 0.811\n",
            "training epoch: [127 ] loss: 0.498 correct: 2436.000, total: 3000.000, accuracy: 0.812\n",
            "training epoch: [128 ] loss: 0.498 correct: 2439.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [129 ] loss: 0.498 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [130 ] loss: 0.498 correct: 2438.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [131 ] loss: 0.498 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [132 ] loss: 0.498 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [133 ] loss: 0.497 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [134 ] loss: 0.497 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [135 ] loss: 0.497 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [136 ] loss: 0.497 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [137 ] loss: 0.497 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [138 ] loss: 0.497 correct: 2442.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [139 ] loss: 0.496 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [140 ] loss: 0.497 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [141 ] loss: 0.496 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [142 ] loss: 0.496 correct: 2439.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [143 ] loss: 0.496 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [144 ] loss: 0.495 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [145 ] loss: 0.495 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [146 ] loss: 0.495 correct: 2442.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [147 ] loss: 0.495 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [148 ] loss: 0.495 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [149 ] loss: 0.496 correct: 2442.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [150 ] loss: 0.495 correct: 2449.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [151 ] loss: 0.495 correct: 2444.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [152 ] loss: 0.495 correct: 2447.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [153 ] loss: 0.495 correct: 2444.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [154 ] loss: 0.496 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [155 ] loss: 0.496 correct: 2441.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [156 ] loss: 0.496 correct: 2442.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [157 ] loss: 0.496 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [158 ] loss: 0.496 correct: 2442.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [159 ] loss: 0.495 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [160 ] loss: 0.495 correct: 2442.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [161 ] loss: 0.496 correct: 2440.000, total: 3000.000, accuracy: 0.813\n",
            "training epoch: [162 ] loss: 0.494 correct: 2447.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [163 ] loss: 0.495 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [164 ] loss: 0.495 correct: 2442.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [165 ] loss: 0.495 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [166 ] loss: 0.495 correct: 2444.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [167 ] loss: 0.495 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [168 ] loss: 0.495 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [169 ] loss: 0.495 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [170 ] loss: 0.495 correct: 2443.000, total: 3000.000, accuracy: 0.814\n",
            "training epoch: [171 ] loss: 0.495 correct: 2446.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [172 ] loss: 0.494 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [173 ] loss: 0.494 correct: 2446.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [174 ] loss: 0.493 correct: 2446.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [175 ] loss: 0.494 correct: 2446.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [176 ] loss: 0.494 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [177 ] loss: 0.493 correct: 2446.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [178 ] loss: 0.493 correct: 2449.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [179 ] loss: 0.493 correct: 2447.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [180 ] loss: 0.495 correct: 2444.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [181 ] loss: 0.494 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [182 ] loss: 0.494 correct: 2446.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [183 ] loss: 0.494 correct: 2447.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [184 ] loss: 0.494 correct: 2447.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [185 ] loss: 0.493 correct: 2448.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [186 ] loss: 0.493 correct: 2450.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [187 ] loss: 0.493 correct: 2449.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [188 ] loss: 0.493 correct: 2450.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [189 ] loss: 0.493 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [190 ] loss: 0.493 correct: 2448.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [191 ] loss: 0.493 correct: 2449.000, total: 3000.000, accuracy: 0.816\n",
            "training epoch: [192 ] loss: 0.494 correct: 2450.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [193 ] loss: 0.493 correct: 2451.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [194 ] loss: 0.493 correct: 2451.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [195 ] loss: 0.493 correct: 2452.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [196 ] loss: 0.493 correct: 2451.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [197 ] loss: 0.493 correct: 2452.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [198 ] loss: 0.493 correct: 2451.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [199 ] loss: 0.493 correct: 2451.000, total: 3000.000, accuracy: 0.817\n",
            "training epoch: [200 ] loss: 0.494 correct: 2450.000, total: 3000.000, accuracy: 0.817\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "NoQpS_6scRsC",
        "outputId": "6462d8bd-5104-41b0-94fd-a269826d4b9b"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>302</td>\n",
              "      <td>2698</td>\n",
              "      <td>135</td>\n",
              "      <td>936</td>\n",
              "      <td>179</td>\n",
              "      <td>1750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1379</td>\n",
              "      <td>1621</td>\n",
              "      <td>274</td>\n",
              "      <td>1578</td>\n",
              "      <td>167</td>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2567</td>\n",
              "      <td>433</td>\n",
              "      <td>529</td>\n",
              "      <td>1779</td>\n",
              "      <td>46</td>\n",
              "      <td>646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2707</td>\n",
              "      <td>293</td>\n",
              "      <td>588</td>\n",
              "      <td>1767</td>\n",
              "      <td>38</td>\n",
              "      <td>607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2730</td>\n",
              "      <td>270</td>\n",
              "      <td>602</td>\n",
              "      <td>1771</td>\n",
              "      <td>38</td>\n",
              "      <td>589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>2973</td>\n",
              "      <td>27</td>\n",
              "      <td>746</td>\n",
              "      <td>1705</td>\n",
              "      <td>15</td>\n",
              "      <td>534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>197</td>\n",
              "      <td>2973</td>\n",
              "      <td>27</td>\n",
              "      <td>745</td>\n",
              "      <td>1707</td>\n",
              "      <td>15</td>\n",
              "      <td>533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>2974</td>\n",
              "      <td>26</td>\n",
              "      <td>745</td>\n",
              "      <td>1706</td>\n",
              "      <td>15</td>\n",
              "      <td>534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>199</td>\n",
              "      <td>2974</td>\n",
              "      <td>26</td>\n",
              "      <td>745</td>\n",
              "      <td>1706</td>\n",
              "      <td>15</td>\n",
              "      <td>534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>200</td>\n",
              "      <td>2975</td>\n",
              "      <td>25</td>\n",
              "      <td>745</td>\n",
              "      <td>1705</td>\n",
              "      <td>15</td>\n",
              "      <td>535</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>201 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0         0           302  ...                    179                    1750\n",
              "1         1          1379  ...                    167                     981\n",
              "2         2          2567  ...                     46                     646\n",
              "3         3          2707  ...                     38                     607\n",
              "4         4          2730  ...                     38                     589\n",
              "..      ...           ...  ...                    ...                     ...\n",
              "196     196          2973  ...                     15                     534\n",
              "197     197          2973  ...                     15                     533\n",
              "198     198          2974  ...                     15                     534\n",
              "199     199          2974  ...                     15                     534\n",
              "200     200          2975  ...                     15                     535\n",
              "\n",
              "[201 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "IMAhRdxOcVf6",
        "outputId": "99420696-33c6-45f4-cf64-b75f9042f8d7"
      },
      "source": [
        "fig= plt.figure(figsize=(6,6))\n",
        "plt.plot(df_train[columns[0]],df_train[columns[3]]/30, label =\"focus_true_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[4]]/30, label =\"focus_false_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[5]]/30, label =\"focus_true_pred_false \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[6]]/30, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Train set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"percentage of data\")\n",
        "plt.xticks([0,50,100,150,200])\n",
        "#plt.vlines(vline_list,min(min(df_train[columns[3]]/300),min(df_train[columns[4]]/300),min(df_train[columns[5]]/300),min(df_train[columns[6]]/300)), max(max(df_train[columns[3]]/300),max(df_train[columns[4]]/300),max(df_train[columns[5]]/300),max(df_train[columns[6]]/300)),linestyles='dotted')\n",
        "plt.show()\n",
        "fig.savefig(\"train_analysis.pdf\")\n",
        "fig.savefig(\"train_analysis.png\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in bg:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "torch.save({\n",
        "            'epoch': 500,\n",
        "            'model_state_dict': what_net.state_dict(),\n",
        "            #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "            \"optimizer_alpha\":optim1,\n",
        "            \"FTPT_analysis\":analysis_data_tr,\n",
        "            \"alpha\":aph\n",
        "\n",
        "            }, \"type4_what_net_500.pt\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVzrDOGS4UxU",
        "outputId": "39934a51-16e7-4126-ba19-57fc151f7890"
      },
      "source": [
        "aph[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.0000000e+00, 7.5123044e-19, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       1.0199681e-08], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwTDpx6STIPh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}