{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "type4_attn_ewts_NTK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pI7PJ8XATdT",
        "outputId": "41af1e72-9887-4609-9799-e20a7eeb57ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9qVDQd_BBqS",
        "outputId": "be0043c0-5539-471f-ec92-195d6acd2a20"
      },
      "source": [
        "%cd /content/drive/MyDrive/Neural_Tangent_Kernel/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Neural_Tangent_Kernel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "from myrmsprop import MyRmsprop\n",
        "from utils import plot_decision_boundary,attn_avg,plot_analysis\n",
        "from synthetic_dataset import MosaicDataset1\n",
        "from eval_model import calculate_attn_loss,analyse_data\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "train_data = np.load(\"train_type4_data.npy\",allow_pickle=True)\n",
        "\n",
        "test_data = np.load(\"test_type4_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL771xuGZC5Q"
      },
      "source": [
        "mosaic_list_of_images = train_data[0][\"mosaic_list\"]\n",
        "mosaic_label = train_data[0][\"mosaic_label\"]\n",
        "fore_idx = train_data[0][\"fore_idx\"]\n",
        "\n",
        "\n",
        "test_mosaic_list_of_images = test_data[0][\"mosaic_list\"]\n",
        "test_mosaic_label = test_data[0][\"mosaic_label\"]\n",
        "test_fore_idx = test_data[0][\"fore_idx\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf76JwkxZCT0"
      },
      "source": [
        "batch = 3000\n",
        "train_dataset = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=False)\n",
        "#batch = 2000\n",
        "#test_dataset = MosaicDataset1(test_mosaic_list_of_images, test_mosaic_label, test_fore_idx)\n",
        "#test_loader = DataLoader(test_dataset,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Lv8nHoB8z-"
      },
      "source": [
        "# NTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmGjlMfTBp3F"
      },
      "source": [
        "data = np.load(\"NTK_1.npy\",allow_pickle=True)\n",
        "# H = data[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beyk_-qYB_Ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c7e6c1-4661-4c05-d80c-b0184184f972"
      },
      "source": [
        "print(data[0].keys())\n",
        "H = torch.tensor(data[0][\"NTK\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['NTK'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ULTAsyF6G6a"
      },
      "source": [
        "lr_1 = 1/1470559.2\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnqbuxdO2U4j"
      },
      "source": [
        "# p_vec = nn.utils.parameters_to_vector(where_func.parameters())\n",
        "# p, = p_vec.shape\n",
        "# n_m, n_obj,_ = inputs.shape  # number of mosaic images x number of objects in each mosaic  x d\n",
        "# # this is the transpose jacobian (grad y(w))^T)\n",
        "# features = torch.zeros(n_m*n_obj, p, requires_grad=False)\n",
        " \n",
        "# k = 0 \n",
        "\n",
        "\n",
        "# for i in range(27000):\n",
        "#     out = where_func(inpp[i])\n",
        "#     where_func.zero_grad()\n",
        "#     out.backward(retain_graph=False)\n",
        "#     p_grad = torch.tensor([], requires_grad=False)\n",
        "#     for p in where_func.parameters():\n",
        "#       p_grad = torch.cat((p_grad, p.grad.reshape(-1)))\n",
        "#     features[k,:] = p_grad\n",
        "#     k = k+1\n",
        "# tangent_kernel =  features@features.T"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SInPc5gk9XDH"
      },
      "source": [
        "# class Module1(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(Module1, self).__init__()\n",
        "#     self.linear1 = nn.Linear(2,100)\n",
        "#     self.linear2 = nn.Linear(100,1)\n",
        "\n",
        "#   def forward(self,x):\n",
        "#     x = F.relu(self.linear1(x))\n",
        "#     x = self.linear2(x)\n",
        "#     return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW0lzy6i9wk0"
      },
      "source": [
        "# from tqdm import tqdm as tqdm"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cti_LAbE8-dn"
      },
      "source": [
        "# inputs,_,_ = iter(train_loader).next()\n",
        "# inputs = torch.reshape(inputs,(27000,2))\n",
        "# inputs = (inputs - torch.mean(inputs,dim=0,keepdims=True) )/torch.std(inputs,dim=0,keepdims=True)\n",
        "# where_net = Module1()\n",
        "# outputs = where_net(inputs)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-03FnsNP5bk"
      },
      "source": [
        "# feature1 = torch.zeros((27000,200))\n",
        "# feature2  = torch.zeros((27000,100))\n",
        "# for i in tqdm(range(27000)):\n",
        "#   where_net.zero_grad()\n",
        "#   outputs[i].backward(retain_graph=True)\n",
        "#   par = []\n",
        "#   j = 0\n",
        "#   for p in where_net.parameters():\n",
        "#     if j%2 == 0:\n",
        "#       vec = torch.nn.utils.parameters_to_vector(p)\n",
        "#       p_grad = p.grad.reshape(-1)\n",
        "#       par.append(p_grad)\n",
        "#     j = j+1\n",
        "#   feature1[i,:] = par[0]\n",
        "#   feature2[i,:] = par[1]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI20WxiR-zCi"
      },
      "source": [
        "# H = feature1@feature1.T + feature2@feature2.T"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWIBQfQly25h"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    self.linear1 = nn.Linear(2,100)\n",
        "    self.linear2 = nn.Linear(100,3)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXpnLkMoCocj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04280bd6-da83-49ea-9793-8b4e6e17e43a"
      },
      "source": [
        "print(H)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[75.1031, 35.6146, 79.1224,  ..., 63.2880, 38.2985, 72.4251],\n",
            "        [35.6146, 21.1840, 42.9770,  ..., 33.6579, 25.0675, 44.2191],\n",
            "        [79.1224, 42.9770, 92.8314,  ..., 73.0225, 48.9726, 88.7758],\n",
            "        ...,\n",
            "        [63.2880, 33.6579, 73.0225,  ..., 58.0862, 38.0167, 69.3583],\n",
            "        [38.2985, 25.0675, 48.9726,  ..., 38.0167, 34.9229, 54.7437],\n",
            "        [72.4251, 44.2191, 88.7758,  ..., 69.3583, 54.7437, 95.1200]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRDhoG3rEp_w"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "#what_net.load_state_dict(torch.load(\"type4_what_net.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "n_batches = 3000//batch\n",
        "bg = []\n",
        "for i in range(n_batches):\n",
        "  torch.manual_seed(i)\n",
        "  betag = torch.randn(3000,9)#torch.ones((250,9))/9\n",
        "  bg.append( betag.requires_grad_() )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76PwzSMACDDj"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lrDkUUaDFCR"
      },
      "source": [
        "optim1 = []\n",
        "H= H.to(\"cpu\")\n",
        "for i in range(n_batches):\n",
        "  optim1.append(MyRmsprop([bg[i]],H=H,lr=1))\n",
        "# instantiate what net optimizer\n",
        "optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.0001)#, momentum=0.9)#,nesterov=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPaYaojinMTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c74f356-e9e9-4363-87e6-780e7cbddff1"
      },
      "source": [
        "\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 2500\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,bg,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    beta = bg[i] # alpha for ith batch\n",
        "    #print(labels)\n",
        "    inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,beta)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,bg,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 1.478 correct: 971.000, total: 3000.000, accuracy: 0.324\n",
            "training epoch: [1 ] loss: 1.403 correct: 969.000, total: 3000.000, accuracy: 0.323\n",
            "training epoch: [2 ] loss: 1.354 correct: 972.000, total: 3000.000, accuracy: 0.324\n",
            "training epoch: [3 ] loss: 1.316 correct: 972.000, total: 3000.000, accuracy: 0.324\n",
            "training epoch: [4 ] loss: 1.286 correct: 970.000, total: 3000.000, accuracy: 0.323\n",
            "training epoch: [5 ] loss: 1.261 correct: 972.000, total: 3000.000, accuracy: 0.324\n",
            "training epoch: [6 ] loss: 1.239 correct: 970.000, total: 3000.000, accuracy: 0.323\n",
            "training epoch: [7 ] loss: 1.221 correct: 969.000, total: 3000.000, accuracy: 0.323\n",
            "training epoch: [8 ] loss: 1.205 correct: 971.000, total: 3000.000, accuracy: 0.324\n",
            "training epoch: [9 ] loss: 1.191 correct: 979.000, total: 3000.000, accuracy: 0.326\n",
            "training epoch: [10 ] loss: 1.179 correct: 985.000, total: 3000.000, accuracy: 0.328\n",
            "training epoch: [11 ] loss: 1.169 correct: 998.000, total: 3000.000, accuracy: 0.333\n",
            "training epoch: [12 ] loss: 1.160 correct: 997.000, total: 3000.000, accuracy: 0.332\n",
            "training epoch: [13 ] loss: 1.152 correct: 987.000, total: 3000.000, accuracy: 0.329\n",
            "training epoch: [14 ] loss: 1.145 correct: 988.000, total: 3000.000, accuracy: 0.329\n",
            "training epoch: [15 ] loss: 1.139 correct: 994.000, total: 3000.000, accuracy: 0.331\n",
            "training epoch: [16 ] loss: 1.133 correct: 1003.000, total: 3000.000, accuracy: 0.334\n",
            "training epoch: [17 ] loss: 1.129 correct: 1011.000, total: 3000.000, accuracy: 0.337\n",
            "training epoch: [18 ] loss: 1.125 correct: 1027.000, total: 3000.000, accuracy: 0.342\n",
            "training epoch: [19 ] loss: 1.121 correct: 1033.000, total: 3000.000, accuracy: 0.344\n",
            "training epoch: [20 ] loss: 1.118 correct: 1038.000, total: 3000.000, accuracy: 0.346\n",
            "training epoch: [21 ] loss: 1.115 correct: 1037.000, total: 3000.000, accuracy: 0.346\n",
            "training epoch: [22 ] loss: 1.113 correct: 1045.000, total: 3000.000, accuracy: 0.348\n",
            "training epoch: [23 ] loss: 1.111 correct: 1067.000, total: 3000.000, accuracy: 0.356\n",
            "training epoch: [24 ] loss: 1.109 correct: 1073.000, total: 3000.000, accuracy: 0.358\n",
            "training epoch: [25 ] loss: 1.107 correct: 1080.000, total: 3000.000, accuracy: 0.360\n",
            "training epoch: [26 ] loss: 1.106 correct: 1077.000, total: 3000.000, accuracy: 0.359\n",
            "training epoch: [27 ] loss: 1.105 correct: 1083.000, total: 3000.000, accuracy: 0.361\n",
            "training epoch: [28 ] loss: 1.104 correct: 1090.000, total: 3000.000, accuracy: 0.363\n",
            "training epoch: [29 ] loss: 1.103 correct: 1091.000, total: 3000.000, accuracy: 0.364\n",
            "training epoch: [30 ] loss: 1.102 correct: 1096.000, total: 3000.000, accuracy: 0.365\n",
            "training epoch: [31 ] loss: 1.101 correct: 1098.000, total: 3000.000, accuracy: 0.366\n",
            "training epoch: [32 ] loss: 1.101 correct: 1103.000, total: 3000.000, accuracy: 0.368\n",
            "training epoch: [33 ] loss: 1.100 correct: 1105.000, total: 3000.000, accuracy: 0.368\n",
            "training epoch: [34 ] loss: 1.099 correct: 1107.000, total: 3000.000, accuracy: 0.369\n",
            "training epoch: [35 ] loss: 1.099 correct: 1101.000, total: 3000.000, accuracy: 0.367\n",
            "training epoch: [36 ] loss: 1.099 correct: 1095.000, total: 3000.000, accuracy: 0.365\n",
            "training epoch: [37 ] loss: 1.098 correct: 1092.000, total: 3000.000, accuracy: 0.364\n",
            "training epoch: [38 ] loss: 1.098 correct: 1083.000, total: 3000.000, accuracy: 0.361\n",
            "training epoch: [39 ] loss: 1.097 correct: 1080.000, total: 3000.000, accuracy: 0.360\n",
            "training epoch: [40 ] loss: 1.097 correct: 1075.000, total: 3000.000, accuracy: 0.358\n",
            "training epoch: [41 ] loss: 1.097 correct: 1074.000, total: 3000.000, accuracy: 0.358\n",
            "training epoch: [42 ] loss: 1.097 correct: 1079.000, total: 3000.000, accuracy: 0.360\n",
            "training epoch: [43 ] loss: 1.096 correct: 1086.000, total: 3000.000, accuracy: 0.362\n",
            "training epoch: [44 ] loss: 1.096 correct: 1086.000, total: 3000.000, accuracy: 0.362\n",
            "training epoch: [45 ] loss: 1.096 correct: 1080.000, total: 3000.000, accuracy: 0.360\n",
            "training epoch: [46 ] loss: 1.096 correct: 1071.000, total: 3000.000, accuracy: 0.357\n",
            "training epoch: [47 ] loss: 1.095 correct: 1074.000, total: 3000.000, accuracy: 0.358\n",
            "training epoch: [48 ] loss: 1.095 correct: 1073.000, total: 3000.000, accuracy: 0.358\n",
            "training epoch: [49 ] loss: 1.095 correct: 1076.000, total: 3000.000, accuracy: 0.359\n",
            "training epoch: [50 ] loss: 1.095 correct: 1077.000, total: 3000.000, accuracy: 0.359\n",
            "training epoch: [51 ] loss: 1.095 correct: 1077.000, total: 3000.000, accuracy: 0.359\n",
            "training epoch: [52 ] loss: 1.094 correct: 1079.000, total: 3000.000, accuracy: 0.360\n",
            "training epoch: [53 ] loss: 1.094 correct: 1085.000, total: 3000.000, accuracy: 0.362\n",
            "training epoch: [54 ] loss: 1.094 correct: 1087.000, total: 3000.000, accuracy: 0.362\n",
            "training epoch: [55 ] loss: 1.094 correct: 1083.000, total: 3000.000, accuracy: 0.361\n",
            "training epoch: [56 ] loss: 1.094 correct: 1081.000, total: 3000.000, accuracy: 0.360\n",
            "training epoch: [57 ] loss: 1.094 correct: 1087.000, total: 3000.000, accuracy: 0.362\n",
            "training epoch: [58 ] loss: 1.093 correct: 1095.000, total: 3000.000, accuracy: 0.365\n",
            "training epoch: [59 ] loss: 1.093 correct: 1103.000, total: 3000.000, accuracy: 0.368\n",
            "training epoch: [60 ] loss: 1.093 correct: 1097.000, total: 3000.000, accuracy: 0.366\n",
            "training epoch: [61 ] loss: 1.093 correct: 1094.000, total: 3000.000, accuracy: 0.365\n",
            "training epoch: [62 ] loss: 1.093 correct: 1092.000, total: 3000.000, accuracy: 0.364\n",
            "training epoch: [63 ] loss: 1.092 correct: 1101.000, total: 3000.000, accuracy: 0.367\n",
            "training epoch: [64 ] loss: 1.092 correct: 1101.000, total: 3000.000, accuracy: 0.367\n",
            "training epoch: [65 ] loss: 1.092 correct: 1098.000, total: 3000.000, accuracy: 0.366\n",
            "training epoch: [66 ] loss: 1.092 correct: 1100.000, total: 3000.000, accuracy: 0.367\n",
            "training epoch: [67 ] loss: 1.092 correct: 1098.000, total: 3000.000, accuracy: 0.366\n",
            "training epoch: [68 ] loss: 1.091 correct: 1100.000, total: 3000.000, accuracy: 0.367\n",
            "training epoch: [69 ] loss: 1.091 correct: 1097.000, total: 3000.000, accuracy: 0.366\n",
            "training epoch: [70 ] loss: 1.091 correct: 1099.000, total: 3000.000, accuracy: 0.366\n",
            "training epoch: [71 ] loss: 1.091 correct: 1098.000, total: 3000.000, accuracy: 0.366\n",
            "training epoch: [72 ] loss: 1.091 correct: 1101.000, total: 3000.000, accuracy: 0.367\n",
            "training epoch: [73 ] loss: 1.090 correct: 1104.000, total: 3000.000, accuracy: 0.368\n",
            "training epoch: [74 ] loss: 1.090 correct: 1105.000, total: 3000.000, accuracy: 0.368\n",
            "training epoch: [75 ] loss: 1.090 correct: 1104.000, total: 3000.000, accuracy: 0.368\n",
            "training epoch: [76 ] loss: 1.090 correct: 1111.000, total: 3000.000, accuracy: 0.370\n",
            "training epoch: [77 ] loss: 1.090 correct: 1106.000, total: 3000.000, accuracy: 0.369\n",
            "training epoch: [78 ] loss: 1.089 correct: 1104.000, total: 3000.000, accuracy: 0.368\n",
            "training epoch: [79 ] loss: 1.089 correct: 1110.000, total: 3000.000, accuracy: 0.370\n",
            "training epoch: [80 ] loss: 1.089 correct: 1112.000, total: 3000.000, accuracy: 0.371\n",
            "training epoch: [81 ] loss: 1.089 correct: 1108.000, total: 3000.000, accuracy: 0.369\n",
            "training epoch: [82 ] loss: 1.088 correct: 1113.000, total: 3000.000, accuracy: 0.371\n",
            "training epoch: [83 ] loss: 1.088 correct: 1116.000, total: 3000.000, accuracy: 0.372\n",
            "training epoch: [84 ] loss: 1.088 correct: 1120.000, total: 3000.000, accuracy: 0.373\n",
            "training epoch: [85 ] loss: 1.088 correct: 1120.000, total: 3000.000, accuracy: 0.373\n",
            "training epoch: [86 ] loss: 1.087 correct: 1123.000, total: 3000.000, accuracy: 0.374\n",
            "training epoch: [87 ] loss: 1.087 correct: 1123.000, total: 3000.000, accuracy: 0.374\n",
            "training epoch: [88 ] loss: 1.087 correct: 1131.000, total: 3000.000, accuracy: 0.377\n",
            "training epoch: [89 ] loss: 1.087 correct: 1128.000, total: 3000.000, accuracy: 0.376\n",
            "training epoch: [90 ] loss: 1.086 correct: 1133.000, total: 3000.000, accuracy: 0.378\n",
            "training epoch: [91 ] loss: 1.086 correct: 1135.000, total: 3000.000, accuracy: 0.378\n",
            "training epoch: [92 ] loss: 1.086 correct: 1130.000, total: 3000.000, accuracy: 0.377\n",
            "training epoch: [93 ] loss: 1.085 correct: 1123.000, total: 3000.000, accuracy: 0.374\n",
            "training epoch: [94 ] loss: 1.085 correct: 1120.000, total: 3000.000, accuracy: 0.373\n",
            "training epoch: [95 ] loss: 1.085 correct: 1128.000, total: 3000.000, accuracy: 0.376\n",
            "training epoch: [96 ] loss: 1.084 correct: 1126.000, total: 3000.000, accuracy: 0.375\n",
            "training epoch: [97 ] loss: 1.084 correct: 1127.000, total: 3000.000, accuracy: 0.376\n",
            "training epoch: [98 ] loss: 1.084 correct: 1132.000, total: 3000.000, accuracy: 0.377\n",
            "training epoch: [99 ] loss: 1.083 correct: 1136.000, total: 3000.000, accuracy: 0.379\n",
            "training epoch: [100 ] loss: 1.083 correct: 1143.000, total: 3000.000, accuracy: 0.381\n",
            "training epoch: [101 ] loss: 1.083 correct: 1150.000, total: 3000.000, accuracy: 0.383\n",
            "training epoch: [102 ] loss: 1.082 correct: 1149.000, total: 3000.000, accuracy: 0.383\n",
            "training epoch: [103 ] loss: 1.082 correct: 1150.000, total: 3000.000, accuracy: 0.383\n",
            "training epoch: [104 ] loss: 1.082 correct: 1154.000, total: 3000.000, accuracy: 0.385\n",
            "training epoch: [105 ] loss: 1.081 correct: 1154.000, total: 3000.000, accuracy: 0.385\n",
            "training epoch: [106 ] loss: 1.081 correct: 1156.000, total: 3000.000, accuracy: 0.385\n",
            "training epoch: [107 ] loss: 1.081 correct: 1157.000, total: 3000.000, accuracy: 0.386\n",
            "training epoch: [108 ] loss: 1.080 correct: 1165.000, total: 3000.000, accuracy: 0.388\n",
            "training epoch: [109 ] loss: 1.080 correct: 1164.000, total: 3000.000, accuracy: 0.388\n",
            "training epoch: [110 ] loss: 1.079 correct: 1163.000, total: 3000.000, accuracy: 0.388\n",
            "training epoch: [111 ] loss: 1.079 correct: 1167.000, total: 3000.000, accuracy: 0.389\n",
            "training epoch: [112 ] loss: 1.079 correct: 1167.000, total: 3000.000, accuracy: 0.389\n",
            "training epoch: [113 ] loss: 1.078 correct: 1169.000, total: 3000.000, accuracy: 0.390\n",
            "training epoch: [114 ] loss: 1.078 correct: 1172.000, total: 3000.000, accuracy: 0.391\n",
            "training epoch: [115 ] loss: 1.077 correct: 1177.000, total: 3000.000, accuracy: 0.392\n",
            "training epoch: [116 ] loss: 1.077 correct: 1179.000, total: 3000.000, accuracy: 0.393\n",
            "training epoch: [117 ] loss: 1.076 correct: 1185.000, total: 3000.000, accuracy: 0.395\n",
            "training epoch: [118 ] loss: 1.076 correct: 1185.000, total: 3000.000, accuracy: 0.395\n",
            "training epoch: [119 ] loss: 1.076 correct: 1185.000, total: 3000.000, accuracy: 0.395\n",
            "training epoch: [120 ] loss: 1.075 correct: 1187.000, total: 3000.000, accuracy: 0.396\n",
            "training epoch: [121 ] loss: 1.075 correct: 1190.000, total: 3000.000, accuracy: 0.397\n",
            "training epoch: [122 ] loss: 1.074 correct: 1193.000, total: 3000.000, accuracy: 0.398\n",
            "training epoch: [123 ] loss: 1.074 correct: 1203.000, total: 3000.000, accuracy: 0.401\n",
            "training epoch: [124 ] loss: 1.073 correct: 1205.000, total: 3000.000, accuracy: 0.402\n",
            "training epoch: [125 ] loss: 1.073 correct: 1209.000, total: 3000.000, accuracy: 0.403\n",
            "training epoch: [126 ] loss: 1.072 correct: 1212.000, total: 3000.000, accuracy: 0.404\n",
            "training epoch: [127 ] loss: 1.071 correct: 1205.000, total: 3000.000, accuracy: 0.402\n",
            "training epoch: [128 ] loss: 1.071 correct: 1209.000, total: 3000.000, accuracy: 0.403\n",
            "training epoch: [129 ] loss: 1.070 correct: 1206.000, total: 3000.000, accuracy: 0.402\n",
            "training epoch: [130 ] loss: 1.070 correct: 1207.000, total: 3000.000, accuracy: 0.402\n",
            "training epoch: [131 ] loss: 1.069 correct: 1207.000, total: 3000.000, accuracy: 0.402\n",
            "training epoch: [132 ] loss: 1.069 correct: 1210.000, total: 3000.000, accuracy: 0.403\n",
            "training epoch: [133 ] loss: 1.068 correct: 1217.000, total: 3000.000, accuracy: 0.406\n",
            "training epoch: [134 ] loss: 1.067 correct: 1221.000, total: 3000.000, accuracy: 0.407\n",
            "training epoch: [135 ] loss: 1.067 correct: 1218.000, total: 3000.000, accuracy: 0.406\n",
            "training epoch: [136 ] loss: 1.066 correct: 1219.000, total: 3000.000, accuracy: 0.406\n",
            "training epoch: [137 ] loss: 1.065 correct: 1217.000, total: 3000.000, accuracy: 0.406\n",
            "training epoch: [138 ] loss: 1.065 correct: 1219.000, total: 3000.000, accuracy: 0.406\n",
            "training epoch: [139 ] loss: 1.064 correct: 1216.000, total: 3000.000, accuracy: 0.405\n",
            "training epoch: [140 ] loss: 1.063 correct: 1215.000, total: 3000.000, accuracy: 0.405\n",
            "training epoch: [141 ] loss: 1.063 correct: 1214.000, total: 3000.000, accuracy: 0.405\n",
            "training epoch: [142 ] loss: 1.062 correct: 1216.000, total: 3000.000, accuracy: 0.405\n",
            "training epoch: [143 ] loss: 1.061 correct: 1226.000, total: 3000.000, accuracy: 0.409\n",
            "training epoch: [144 ] loss: 1.060 correct: 1228.000, total: 3000.000, accuracy: 0.409\n",
            "training epoch: [145 ] loss: 1.059 correct: 1225.000, total: 3000.000, accuracy: 0.408\n",
            "training epoch: [146 ] loss: 1.059 correct: 1222.000, total: 3000.000, accuracy: 0.407\n",
            "training epoch: [147 ] loss: 1.058 correct: 1235.000, total: 3000.000, accuracy: 0.412\n",
            "training epoch: [148 ] loss: 1.057 correct: 1243.000, total: 3000.000, accuracy: 0.414\n",
            "training epoch: [149 ] loss: 1.056 correct: 1241.000, total: 3000.000, accuracy: 0.414\n",
            "training epoch: [150 ] loss: 1.055 correct: 1248.000, total: 3000.000, accuracy: 0.416\n",
            "training epoch: [151 ] loss: 1.054 correct: 1253.000, total: 3000.000, accuracy: 0.418\n",
            "training epoch: [152 ] loss: 1.053 correct: 1249.000, total: 3000.000, accuracy: 0.416\n",
            "training epoch: [153 ] loss: 1.052 correct: 1259.000, total: 3000.000, accuracy: 0.420\n",
            "training epoch: [154 ] loss: 1.051 correct: 1264.000, total: 3000.000, accuracy: 0.421\n",
            "training epoch: [155 ] loss: 1.050 correct: 1270.000, total: 3000.000, accuracy: 0.423\n",
            "training epoch: [156 ] loss: 1.048 correct: 1279.000, total: 3000.000, accuracy: 0.426\n",
            "training epoch: [157 ] loss: 1.047 correct: 1286.000, total: 3000.000, accuracy: 0.429\n",
            "training epoch: [158 ] loss: 1.046 correct: 1289.000, total: 3000.000, accuracy: 0.430\n",
            "training epoch: [159 ] loss: 1.045 correct: 1298.000, total: 3000.000, accuracy: 0.433\n",
            "training epoch: [160 ] loss: 1.043 correct: 1306.000, total: 3000.000, accuracy: 0.435\n",
            "training epoch: [161 ] loss: 1.042 correct: 1317.000, total: 3000.000, accuracy: 0.439\n",
            "training epoch: [162 ] loss: 1.040 correct: 1323.000, total: 3000.000, accuracy: 0.441\n",
            "training epoch: [163 ] loss: 1.039 correct: 1332.000, total: 3000.000, accuracy: 0.444\n",
            "training epoch: [164 ] loss: 1.037 correct: 1331.000, total: 3000.000, accuracy: 0.444\n",
            "training epoch: [165 ] loss: 1.036 correct: 1334.000, total: 3000.000, accuracy: 0.445\n",
            "training epoch: [166 ] loss: 1.034 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [167 ] loss: 1.033 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [168 ] loss: 1.031 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [169 ] loss: 1.029 correct: 1358.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [170 ] loss: 1.027 correct: 1366.000, total: 3000.000, accuracy: 0.455\n",
            "training epoch: [171 ] loss: 1.025 correct: 1380.000, total: 3000.000, accuracy: 0.460\n",
            "training epoch: [172 ] loss: 1.024 correct: 1382.000, total: 3000.000, accuracy: 0.461\n",
            "training epoch: [173 ] loss: 1.022 correct: 1401.000, total: 3000.000, accuracy: 0.467\n",
            "training epoch: [174 ] loss: 1.020 correct: 1413.000, total: 3000.000, accuracy: 0.471\n",
            "training epoch: [175 ] loss: 1.018 correct: 1432.000, total: 3000.000, accuracy: 0.477\n",
            "training epoch: [176 ] loss: 1.015 correct: 1438.000, total: 3000.000, accuracy: 0.479\n",
            "training epoch: [177 ] loss: 1.013 correct: 1446.000, total: 3000.000, accuracy: 0.482\n",
            "training epoch: [178 ] loss: 1.011 correct: 1457.000, total: 3000.000, accuracy: 0.486\n",
            "training epoch: [179 ] loss: 1.009 correct: 1466.000, total: 3000.000, accuracy: 0.489\n",
            "training epoch: [180 ] loss: 1.007 correct: 1488.000, total: 3000.000, accuracy: 0.496\n",
            "training epoch: [181 ] loss: 1.004 correct: 1494.000, total: 3000.000, accuracy: 0.498\n",
            "training epoch: [182 ] loss: 1.002 correct: 1514.000, total: 3000.000, accuracy: 0.505\n",
            "training epoch: [183 ] loss: 1.000 correct: 1527.000, total: 3000.000, accuracy: 0.509\n",
            "training epoch: [184 ] loss: 0.997 correct: 1543.000, total: 3000.000, accuracy: 0.514\n",
            "training epoch: [185 ] loss: 0.995 correct: 1553.000, total: 3000.000, accuracy: 0.518\n",
            "training epoch: [186 ] loss: 0.992 correct: 1565.000, total: 3000.000, accuracy: 0.522\n",
            "training epoch: [187 ] loss: 0.990 correct: 1575.000, total: 3000.000, accuracy: 0.525\n",
            "training epoch: [188 ] loss: 0.987 correct: 1588.000, total: 3000.000, accuracy: 0.529\n",
            "training epoch: [189 ] loss: 0.985 correct: 1602.000, total: 3000.000, accuracy: 0.534\n",
            "training epoch: [190 ] loss: 0.982 correct: 1610.000, total: 3000.000, accuracy: 0.537\n",
            "training epoch: [191 ] loss: 0.980 correct: 1626.000, total: 3000.000, accuracy: 0.542\n",
            "training epoch: [192 ] loss: 0.977 correct: 1632.000, total: 3000.000, accuracy: 0.544\n",
            "training epoch: [193 ] loss: 0.975 correct: 1646.000, total: 3000.000, accuracy: 0.549\n",
            "training epoch: [194 ] loss: 0.972 correct: 1653.000, total: 3000.000, accuracy: 0.551\n",
            "training epoch: [195 ] loss: 0.970 correct: 1659.000, total: 3000.000, accuracy: 0.553\n",
            "training epoch: [196 ] loss: 0.967 correct: 1674.000, total: 3000.000, accuracy: 0.558\n",
            "training epoch: [197 ] loss: 0.965 correct: 1689.000, total: 3000.000, accuracy: 0.563\n",
            "training epoch: [198 ] loss: 0.962 correct: 1698.000, total: 3000.000, accuracy: 0.566\n",
            "training epoch: [199 ] loss: 0.960 correct: 1708.000, total: 3000.000, accuracy: 0.569\n",
            "training epoch: [200 ] loss: 0.957 correct: 1714.000, total: 3000.000, accuracy: 0.571\n",
            "training epoch: [201 ] loss: 0.955 correct: 1722.000, total: 3000.000, accuracy: 0.574\n",
            "training epoch: [202 ] loss: 0.953 correct: 1731.000, total: 3000.000, accuracy: 0.577\n",
            "training epoch: [203 ] loss: 0.950 correct: 1741.000, total: 3000.000, accuracy: 0.580\n",
            "training epoch: [204 ] loss: 0.948 correct: 1753.000, total: 3000.000, accuracy: 0.584\n",
            "training epoch: [205 ] loss: 0.945 correct: 1760.000, total: 3000.000, accuracy: 0.587\n",
            "training epoch: [206 ] loss: 0.943 correct: 1772.000, total: 3000.000, accuracy: 0.591\n",
            "training epoch: [207 ] loss: 0.941 correct: 1784.000, total: 3000.000, accuracy: 0.595\n",
            "training epoch: [208 ] loss: 0.939 correct: 1789.000, total: 3000.000, accuracy: 0.596\n",
            "training epoch: [209 ] loss: 0.936 correct: 1796.000, total: 3000.000, accuracy: 0.599\n",
            "training epoch: [210 ] loss: 0.934 correct: 1805.000, total: 3000.000, accuracy: 0.602\n",
            "training epoch: [211 ] loss: 0.932 correct: 1813.000, total: 3000.000, accuracy: 0.604\n",
            "training epoch: [212 ] loss: 0.930 correct: 1821.000, total: 3000.000, accuracy: 0.607\n",
            "training epoch: [213 ] loss: 0.928 correct: 1828.000, total: 3000.000, accuracy: 0.609\n",
            "training epoch: [214 ] loss: 0.926 correct: 1838.000, total: 3000.000, accuracy: 0.613\n",
            "training epoch: [215 ] loss: 0.923 correct: 1844.000, total: 3000.000, accuracy: 0.615\n",
            "training epoch: [216 ] loss: 0.921 correct: 1848.000, total: 3000.000, accuracy: 0.616\n",
            "training epoch: [217 ] loss: 0.919 correct: 1860.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [218 ] loss: 0.917 correct: 1870.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [219 ] loss: 0.915 correct: 1874.000, total: 3000.000, accuracy: 0.625\n",
            "training epoch: [220 ] loss: 0.913 correct: 1874.000, total: 3000.000, accuracy: 0.625\n",
            "training epoch: [221 ] loss: 0.911 correct: 1881.000, total: 3000.000, accuracy: 0.627\n",
            "training epoch: [222 ] loss: 0.909 correct: 1884.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [223 ] loss: 0.908 correct: 1889.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [224 ] loss: 0.906 correct: 1886.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [225 ] loss: 0.904 correct: 1889.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [226 ] loss: 0.902 correct: 1897.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [227 ] loss: 0.900 correct: 1901.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [228 ] loss: 0.898 correct: 1904.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [229 ] loss: 0.896 correct: 1910.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [230 ] loss: 0.895 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [231 ] loss: 0.893 correct: 1919.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [232 ] loss: 0.891 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [233 ] loss: 0.889 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [234 ] loss: 0.888 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [235 ] loss: 0.886 correct: 1934.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [236 ] loss: 0.884 correct: 1939.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [237 ] loss: 0.882 correct: 1941.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [238 ] loss: 0.881 correct: 1939.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [239 ] loss: 0.879 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [240 ] loss: 0.877 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [241 ] loss: 0.876 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [242 ] loss: 0.874 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [243 ] loss: 0.872 correct: 1945.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [244 ] loss: 0.871 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [245 ] loss: 0.869 correct: 1949.000, total: 3000.000, accuracy: 0.650\n",
            "training epoch: [246 ] loss: 0.867 correct: 1948.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [247 ] loss: 0.866 correct: 1947.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [248 ] loss: 0.864 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [249 ] loss: 0.863 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [250 ] loss: 0.861 correct: 1947.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [251 ] loss: 0.859 correct: 1953.000, total: 3000.000, accuracy: 0.651\n",
            "training epoch: [252 ] loss: 0.858 correct: 1955.000, total: 3000.000, accuracy: 0.652\n",
            "training epoch: [253 ] loss: 0.856 correct: 1954.000, total: 3000.000, accuracy: 0.651\n",
            "training epoch: [254 ] loss: 0.855 correct: 1948.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [255 ] loss: 0.853 correct: 1948.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [256 ] loss: 0.851 correct: 1951.000, total: 3000.000, accuracy: 0.650\n",
            "training epoch: [257 ] loss: 0.850 correct: 1956.000, total: 3000.000, accuracy: 0.652\n",
            "training epoch: [258 ] loss: 0.848 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [259 ] loss: 0.847 correct: 1948.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [260 ] loss: 0.845 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [261 ] loss: 0.843 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [262 ] loss: 0.842 correct: 1941.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [263 ] loss: 0.840 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [264 ] loss: 0.839 correct: 1939.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [265 ] loss: 0.837 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [266 ] loss: 0.835 correct: 1942.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [267 ] loss: 0.834 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [268 ] loss: 0.832 correct: 1939.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [269 ] loss: 0.831 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [270 ] loss: 0.829 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [271 ] loss: 0.828 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [272 ] loss: 0.826 correct: 1923.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [273 ] loss: 0.825 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [274 ] loss: 0.823 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [275 ] loss: 0.822 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [276 ] loss: 0.821 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [277 ] loss: 0.820 correct: 1961.000, total: 3000.000, accuracy: 0.654\n",
            "training epoch: [278 ] loss: 0.820 correct: 1911.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [279 ] loss: 0.821 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [280 ] loss: 0.829 correct: 1895.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [281 ] loss: 0.835 correct: 1870.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [282 ] loss: 0.866 correct: 1755.000, total: 3000.000, accuracy: 0.585\n",
            "training epoch: [283 ] loss: 0.859 correct: 1770.000, total: 3000.000, accuracy: 0.590\n",
            "training epoch: [284 ] loss: 0.890 correct: 1669.000, total: 3000.000, accuracy: 0.556\n",
            "training epoch: [285 ] loss: 0.823 correct: 1898.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [286 ] loss: 0.831 correct: 1872.000, total: 3000.000, accuracy: 0.624\n",
            "training epoch: [287 ] loss: 0.806 correct: 1934.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [288 ] loss: 0.810 correct: 1899.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [289 ] loss: 0.800 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [290 ] loss: 0.802 correct: 1897.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [291 ] loss: 0.797 correct: 1913.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [292 ] loss: 0.800 correct: 1878.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [293 ] loss: 0.796 correct: 1894.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [294 ] loss: 0.802 correct: 1851.000, total: 3000.000, accuracy: 0.617\n",
            "training epoch: [295 ] loss: 0.801 correct: 1864.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [296 ] loss: 0.813 correct: 1830.000, total: 3000.000, accuracy: 0.610\n",
            "training epoch: [297 ] loss: 0.812 correct: 1815.000, total: 3000.000, accuracy: 0.605\n",
            "training epoch: [298 ] loss: 0.825 correct: 1799.000, total: 3000.000, accuracy: 0.600\n",
            "training epoch: [299 ] loss: 0.806 correct: 1823.000, total: 3000.000, accuracy: 0.608\n",
            "training epoch: [300 ] loss: 0.809 correct: 1829.000, total: 3000.000, accuracy: 0.610\n",
            "training epoch: [301 ] loss: 0.788 correct: 1870.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [302 ] loss: 0.788 correct: 1845.000, total: 3000.000, accuracy: 0.615\n",
            "training epoch: [303 ] loss: 0.777 correct: 1885.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [304 ] loss: 0.776 correct: 1857.000, total: 3000.000, accuracy: 0.619\n",
            "training epoch: [305 ] loss: 0.772 correct: 1893.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [306 ] loss: 0.770 correct: 1873.000, total: 3000.000, accuracy: 0.624\n",
            "training epoch: [307 ] loss: 0.768 correct: 1886.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [308 ] loss: 0.766 correct: 1864.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [309 ] loss: 0.764 correct: 1879.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [310 ] loss: 0.762 correct: 1870.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [311 ] loss: 0.761 correct: 1869.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [312 ] loss: 0.759 correct: 1858.000, total: 3000.000, accuracy: 0.619\n",
            "training epoch: [313 ] loss: 0.758 correct: 1873.000, total: 3000.000, accuracy: 0.624\n",
            "training epoch: [314 ] loss: 0.756 correct: 1865.000, total: 3000.000, accuracy: 0.622\n",
            "training epoch: [315 ] loss: 0.755 correct: 1874.000, total: 3000.000, accuracy: 0.625\n",
            "training epoch: [316 ] loss: 0.752 correct: 1863.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [317 ] loss: 0.751 correct: 1880.000, total: 3000.000, accuracy: 0.627\n",
            "training epoch: [318 ] loss: 0.749 correct: 1863.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [319 ] loss: 0.749 correct: 1883.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [320 ] loss: 0.746 correct: 1861.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [321 ] loss: 0.746 correct: 1884.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [322 ] loss: 0.744 correct: 1867.000, total: 3000.000, accuracy: 0.622\n",
            "training epoch: [323 ] loss: 0.743 correct: 1882.000, total: 3000.000, accuracy: 0.627\n",
            "training epoch: [324 ] loss: 0.741 correct: 1869.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [325 ] loss: 0.740 correct: 1885.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [326 ] loss: 0.738 correct: 1865.000, total: 3000.000, accuracy: 0.622\n",
            "training epoch: [327 ] loss: 0.737 correct: 1879.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [328 ] loss: 0.735 correct: 1869.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [329 ] loss: 0.735 correct: 1878.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [330 ] loss: 0.733 correct: 1869.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [331 ] loss: 0.732 correct: 1879.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [332 ] loss: 0.730 correct: 1867.000, total: 3000.000, accuracy: 0.622\n",
            "training epoch: [333 ] loss: 0.729 correct: 1881.000, total: 3000.000, accuracy: 0.627\n",
            "training epoch: [334 ] loss: 0.727 correct: 1874.000, total: 3000.000, accuracy: 0.625\n",
            "training epoch: [335 ] loss: 0.727 correct: 1886.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [336 ] loss: 0.725 correct: 1879.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [337 ] loss: 0.724 correct: 1887.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [338 ] loss: 0.722 correct: 1877.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [339 ] loss: 0.721 correct: 1888.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [340 ] loss: 0.719 correct: 1884.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [341 ] loss: 0.719 correct: 1888.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [342 ] loss: 0.717 correct: 1885.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [343 ] loss: 0.716 correct: 1890.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [344 ] loss: 0.715 correct: 1890.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [345 ] loss: 0.714 correct: 1889.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [346 ] loss: 0.712 correct: 1893.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [347 ] loss: 0.711 correct: 1890.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [348 ] loss: 0.710 correct: 1892.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [349 ] loss: 0.709 correct: 1889.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [350 ] loss: 0.708 correct: 1895.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [351 ] loss: 0.707 correct: 1890.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [352 ] loss: 0.706 correct: 1892.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [353 ] loss: 0.705 correct: 1891.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [354 ] loss: 0.703 correct: 1895.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [355 ] loss: 0.702 correct: 1894.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [356 ] loss: 0.701 correct: 1898.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [357 ] loss: 0.700 correct: 1892.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [358 ] loss: 0.699 correct: 1897.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [359 ] loss: 0.698 correct: 1892.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [360 ] loss: 0.697 correct: 1896.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [361 ] loss: 0.696 correct: 1895.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [362 ] loss: 0.695 correct: 1895.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [363 ] loss: 0.694 correct: 1895.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [364 ] loss: 0.693 correct: 1895.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [365 ] loss: 0.692 correct: 1901.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [366 ] loss: 0.691 correct: 1900.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [367 ] loss: 0.690 correct: 1901.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [368 ] loss: 0.689 correct: 1902.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [369 ] loss: 0.688 correct: 1900.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [370 ] loss: 0.687 correct: 1900.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [371 ] loss: 0.686 correct: 1904.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [372 ] loss: 0.685 correct: 1903.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [373 ] loss: 0.685 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [374 ] loss: 0.684 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [375 ] loss: 0.683 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [376 ] loss: 0.682 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [377 ] loss: 0.681 correct: 1904.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [378 ] loss: 0.680 correct: 1906.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [379 ] loss: 0.679 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [380 ] loss: 0.678 correct: 1904.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [381 ] loss: 0.677 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [382 ] loss: 0.677 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [383 ] loss: 0.676 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [384 ] loss: 0.675 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [385 ] loss: 0.674 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [386 ] loss: 0.673 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [387 ] loss: 0.672 correct: 1910.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [388 ] loss: 0.672 correct: 1911.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [389 ] loss: 0.671 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [390 ] loss: 0.670 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [391 ] loss: 0.669 correct: 1913.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [392 ] loss: 0.668 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [393 ] loss: 0.668 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [394 ] loss: 0.667 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [395 ] loss: 0.666 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [396 ] loss: 0.665 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [397 ] loss: 0.665 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [398 ] loss: 0.664 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [399 ] loss: 0.663 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [400 ] loss: 0.662 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [401 ] loss: 0.662 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [402 ] loss: 0.661 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [403 ] loss: 0.660 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [404 ] loss: 0.660 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [405 ] loss: 0.659 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [406 ] loss: 0.658 correct: 1913.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [407 ] loss: 0.657 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [408 ] loss: 0.657 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [409 ] loss: 0.656 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [410 ] loss: 0.655 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [411 ] loss: 0.655 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [412 ] loss: 0.654 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [413 ] loss: 0.653 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [414 ] loss: 0.653 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [415 ] loss: 0.652 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [416 ] loss: 0.651 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [417 ] loss: 0.651 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [418 ] loss: 0.650 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [419 ] loss: 0.650 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [420 ] loss: 0.649 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [421 ] loss: 0.648 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [422 ] loss: 0.648 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [423 ] loss: 0.647 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [424 ] loss: 0.646 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [425 ] loss: 0.646 correct: 1919.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [426 ] loss: 0.645 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [427 ] loss: 0.645 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [428 ] loss: 0.644 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [429 ] loss: 0.644 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [430 ] loss: 0.643 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [431 ] loss: 0.642 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [432 ] loss: 0.642 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [433 ] loss: 0.641 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [434 ] loss: 0.641 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [435 ] loss: 0.640 correct: 1919.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [436 ] loss: 0.640 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [437 ] loss: 0.639 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [438 ] loss: 0.639 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [439 ] loss: 0.638 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [440 ] loss: 0.638 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [441 ] loss: 0.637 correct: 1919.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [442 ] loss: 0.637 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [443 ] loss: 0.636 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [444 ] loss: 0.636 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [445 ] loss: 0.635 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [446 ] loss: 0.635 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [447 ] loss: 0.634 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [448 ] loss: 0.634 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [449 ] loss: 0.633 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [450 ] loss: 0.633 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [451 ] loss: 0.632 correct: 1916.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [452 ] loss: 0.632 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [453 ] loss: 0.631 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [454 ] loss: 0.631 correct: 1919.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [455 ] loss: 0.630 correct: 1919.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [456 ] loss: 0.630 correct: 1919.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [457 ] loss: 0.629 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [458 ] loss: 0.629 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [459 ] loss: 0.629 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [460 ] loss: 0.628 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [461 ] loss: 0.628 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [462 ] loss: 0.627 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [463 ] loss: 0.627 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [464 ] loss: 0.626 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [465 ] loss: 0.626 correct: 1923.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [466 ] loss: 0.626 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [467 ] loss: 0.625 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [468 ] loss: 0.625 correct: 1920.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [469 ] loss: 0.624 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [470 ] loss: 0.624 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [471 ] loss: 0.624 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [472 ] loss: 0.623 correct: 1923.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [473 ] loss: 0.623 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [474 ] loss: 0.622 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [475 ] loss: 0.622 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [476 ] loss: 0.622 correct: 1923.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [477 ] loss: 0.621 correct: 1923.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [478 ] loss: 0.621 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [479 ] loss: 0.620 correct: 1923.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [480 ] loss: 0.620 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [481 ] loss: 0.620 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [482 ] loss: 0.620 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [483 ] loss: 0.619 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [484 ] loss: 0.619 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [485 ] loss: 0.618 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [486 ] loss: 0.618 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [487 ] loss: 0.618 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [488 ] loss: 0.618 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [489 ] loss: 0.617 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [490 ] loss: 0.617 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [491 ] loss: 0.616 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [492 ] loss: 0.616 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [493 ] loss: 0.616 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [494 ] loss: 0.616 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [495 ] loss: 0.615 correct: 1929.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [496 ] loss: 0.615 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [497 ] loss: 0.614 correct: 1929.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [498 ] loss: 0.614 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [499 ] loss: 0.614 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [500 ] loss: 0.614 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [501 ] loss: 0.613 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [502 ] loss: 0.613 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [503 ] loss: 0.613 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [504 ] loss: 0.613 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [505 ] loss: 0.612 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [506 ] loss: 0.612 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [507 ] loss: 0.611 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [508 ] loss: 0.612 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [509 ] loss: 0.611 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [510 ] loss: 0.611 correct: 1929.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [511 ] loss: 0.610 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [512 ] loss: 0.610 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [513 ] loss: 0.610 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [514 ] loss: 0.610 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [515 ] loss: 0.609 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [516 ] loss: 0.609 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [517 ] loss: 0.609 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [518 ] loss: 0.609 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [519 ] loss: 0.608 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [520 ] loss: 0.608 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [521 ] loss: 0.608 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [522 ] loss: 0.608 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [523 ] loss: 0.607 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [524 ] loss: 0.608 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [525 ] loss: 0.607 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [526 ] loss: 0.607 correct: 1923.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [527 ] loss: 0.606 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [528 ] loss: 0.607 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [529 ] loss: 0.606 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [530 ] loss: 0.606 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [531 ] loss: 0.605 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [532 ] loss: 0.606 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [533 ] loss: 0.605 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [534 ] loss: 0.606 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [535 ] loss: 0.604 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [536 ] loss: 0.605 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [537 ] loss: 0.604 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [538 ] loss: 0.605 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [539 ] loss: 0.603 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [540 ] loss: 0.604 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [541 ] loss: 0.603 correct: 1923.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [542 ] loss: 0.604 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [543 ] loss: 0.603 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [544 ] loss: 0.603 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [545 ] loss: 0.602 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [546 ] loss: 0.603 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [547 ] loss: 0.602 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [548 ] loss: 0.603 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [549 ] loss: 0.601 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [550 ] loss: 0.602 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [551 ] loss: 0.601 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [552 ] loss: 0.602 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [553 ] loss: 0.600 correct: 1929.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [554 ] loss: 0.601 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [555 ] loss: 0.600 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [556 ] loss: 0.601 correct: 1927.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [557 ] loss: 0.600 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [558 ] loss: 0.600 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [559 ] loss: 0.599 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [560 ] loss: 0.600 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [561 ] loss: 0.599 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [562 ] loss: 0.599 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [563 ] loss: 0.599 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [564 ] loss: 0.599 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [565 ] loss: 0.598 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [566 ] loss: 0.598 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [567 ] loss: 0.598 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [568 ] loss: 0.598 correct: 1929.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [569 ] loss: 0.597 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [570 ] loss: 0.598 correct: 1929.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [571 ] loss: 0.597 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [572 ] loss: 0.597 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [573 ] loss: 0.597 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [574 ] loss: 0.597 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [575 ] loss: 0.596 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [576 ] loss: 0.597 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [577 ] loss: 0.596 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [578 ] loss: 0.596 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [579 ] loss: 0.596 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [580 ] loss: 0.596 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [581 ] loss: 0.596 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [582 ] loss: 0.596 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [583 ] loss: 0.595 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [584 ] loss: 0.595 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [585 ] loss: 0.595 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [586 ] loss: 0.595 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [587 ] loss: 0.595 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [588 ] loss: 0.595 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [589 ] loss: 0.594 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [590 ] loss: 0.594 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [591 ] loss: 0.594 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [592 ] loss: 0.594 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [593 ] loss: 0.594 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [594 ] loss: 0.594 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [595 ] loss: 0.593 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [596 ] loss: 0.593 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [597 ] loss: 0.593 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [598 ] loss: 0.593 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [599 ] loss: 0.593 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [600 ] loss: 0.593 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [601 ] loss: 0.593 correct: 1934.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [602 ] loss: 0.592 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [603 ] loss: 0.592 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [604 ] loss: 0.592 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [605 ] loss: 0.592 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [606 ] loss: 0.592 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [607 ] loss: 0.592 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [608 ] loss: 0.592 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [609 ] loss: 0.591 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [610 ] loss: 0.591 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [611 ] loss: 0.591 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [612 ] loss: 0.591 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [613 ] loss: 0.591 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [614 ] loss: 0.591 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [615 ] loss: 0.591 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [616 ] loss: 0.591 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [617 ] loss: 0.590 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [618 ] loss: 0.590 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [619 ] loss: 0.590 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [620 ] loss: 0.590 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [621 ] loss: 0.590 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [622 ] loss: 0.590 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [623 ] loss: 0.590 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [624 ] loss: 0.590 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [625 ] loss: 0.589 correct: 1934.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [626 ] loss: 0.589 correct: 1934.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [627 ] loss: 0.589 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [628 ] loss: 0.589 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [629 ] loss: 0.589 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [630 ] loss: 0.589 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [631 ] loss: 0.589 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [632 ] loss: 0.589 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [633 ] loss: 0.588 correct: 1939.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [634 ] loss: 0.588 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [635 ] loss: 0.588 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [636 ] loss: 0.588 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [637 ] loss: 0.588 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [638 ] loss: 0.588 correct: 1941.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [639 ] loss: 0.588 correct: 1941.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [640 ] loss: 0.588 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [641 ] loss: 0.588 correct: 1942.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [642 ] loss: 0.587 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [643 ] loss: 0.587 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [644 ] loss: 0.587 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [645 ] loss: 0.587 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [646 ] loss: 0.587 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [647 ] loss: 0.587 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [648 ] loss: 0.587 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [649 ] loss: 0.587 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [650 ] loss: 0.587 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [651 ] loss: 0.587 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [652 ] loss: 0.586 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [653 ] loss: 0.586 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [654 ] loss: 0.586 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [655 ] loss: 0.586 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [656 ] loss: 0.586 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [657 ] loss: 0.586 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [658 ] loss: 0.586 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [659 ] loss: 0.586 correct: 1942.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [660 ] loss: 0.585 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [661 ] loss: 0.586 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [662 ] loss: 0.585 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [663 ] loss: 0.585 correct: 1939.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [664 ] loss: 0.585 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [665 ] loss: 0.585 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [666 ] loss: 0.585 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [667 ] loss: 0.586 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [668 ] loss: 0.585 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [669 ] loss: 0.586 correct: 1942.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [670 ] loss: 0.585 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [671 ] loss: 0.587 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [672 ] loss: 0.585 correct: 1939.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [673 ] loss: 0.591 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [674 ] loss: 0.589 correct: 1942.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [675 ] loss: 0.603 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [676 ] loss: 0.601 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [677 ] loss: 0.629 correct: 1892.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [678 ] loss: 0.609 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [679 ] loss: 0.594 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [680 ] loss: 0.585 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [681 ] loss: 0.581 correct: 1949.000, total: 3000.000, accuracy: 0.650\n",
            "training epoch: [682 ] loss: 0.584 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [683 ] loss: 0.585 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [684 ] loss: 0.585 correct: 1942.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [685 ] loss: 0.585 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [686 ] loss: 0.585 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [687 ] loss: 0.585 correct: 1945.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [688 ] loss: 0.585 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [689 ] loss: 0.585 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [690 ] loss: 0.585 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [691 ] loss: 0.585 correct: 1947.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [692 ] loss: 0.585 correct: 1945.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [693 ] loss: 0.585 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [694 ] loss: 0.585 correct: 1945.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [695 ] loss: 0.585 correct: 1947.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [696 ] loss: 0.585 correct: 1947.000, total: 3000.000, accuracy: 0.649\n",
            "training epoch: [697 ] loss: 0.585 correct: 1950.000, total: 3000.000, accuracy: 0.650\n",
            "training epoch: [698 ] loss: 0.585 correct: 1952.000, total: 3000.000, accuracy: 0.651\n",
            "training epoch: [699 ] loss: 0.585 correct: 1953.000, total: 3000.000, accuracy: 0.651\n",
            "training epoch: [700 ] loss: 0.585 correct: 1955.000, total: 3000.000, accuracy: 0.652\n",
            "training epoch: [701 ] loss: 0.585 correct: 1957.000, total: 3000.000, accuracy: 0.652\n",
            "training epoch: [702 ] loss: 0.585 correct: 1957.000, total: 3000.000, accuracy: 0.652\n",
            "training epoch: [703 ] loss: 0.585 correct: 1958.000, total: 3000.000, accuracy: 0.653\n",
            "training epoch: [704 ] loss: 0.585 correct: 1955.000, total: 3000.000, accuracy: 0.652\n",
            "training epoch: [705 ] loss: 0.585 correct: 1959.000, total: 3000.000, accuracy: 0.653\n",
            "training epoch: [706 ] loss: 0.585 correct: 1957.000, total: 3000.000, accuracy: 0.652\n",
            "training epoch: [707 ] loss: 0.585 correct: 1961.000, total: 3000.000, accuracy: 0.654\n",
            "training epoch: [708 ] loss: 0.585 correct: 1964.000, total: 3000.000, accuracy: 0.655\n",
            "training epoch: [709 ] loss: 0.585 correct: 1965.000, total: 3000.000, accuracy: 0.655\n",
            "training epoch: [710 ] loss: 0.585 correct: 1967.000, total: 3000.000, accuracy: 0.656\n",
            "training epoch: [711 ] loss: 0.585 correct: 1969.000, total: 3000.000, accuracy: 0.656\n",
            "training epoch: [712 ] loss: 0.585 correct: 1967.000, total: 3000.000, accuracy: 0.656\n",
            "training epoch: [713 ] loss: 0.585 correct: 1974.000, total: 3000.000, accuracy: 0.658\n",
            "training epoch: [714 ] loss: 0.585 correct: 1971.000, total: 3000.000, accuracy: 0.657\n",
            "training epoch: [715 ] loss: 0.585 correct: 1970.000, total: 3000.000, accuracy: 0.657\n",
            "training epoch: [716 ] loss: 0.585 correct: 1970.000, total: 3000.000, accuracy: 0.657\n",
            "training epoch: [717 ] loss: 0.584 correct: 1972.000, total: 3000.000, accuracy: 0.657\n",
            "training epoch: [718 ] loss: 0.584 correct: 1973.000, total: 3000.000, accuracy: 0.658\n",
            "training epoch: [719 ] loss: 0.584 correct: 1979.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [720 ] loss: 0.584 correct: 1985.000, total: 3000.000, accuracy: 0.662\n",
            "training epoch: [721 ] loss: 0.584 correct: 1986.000, total: 3000.000, accuracy: 0.662\n",
            "training epoch: [722 ] loss: 0.584 correct: 1989.000, total: 3000.000, accuracy: 0.663\n",
            "training epoch: [723 ] loss: 0.584 correct: 1991.000, total: 3000.000, accuracy: 0.664\n",
            "training epoch: [724 ] loss: 0.584 correct: 1990.000, total: 3000.000, accuracy: 0.663\n",
            "training epoch: [725 ] loss: 0.584 correct: 1986.000, total: 3000.000, accuracy: 0.662\n",
            "training epoch: [726 ] loss: 0.584 correct: 1986.000, total: 3000.000, accuracy: 0.662\n",
            "training epoch: [727 ] loss: 0.584 correct: 1985.000, total: 3000.000, accuracy: 0.662\n",
            "training epoch: [728 ] loss: 0.584 correct: 1984.000, total: 3000.000, accuracy: 0.661\n",
            "training epoch: [729 ] loss: 0.584 correct: 1982.000, total: 3000.000, accuracy: 0.661\n",
            "training epoch: [730 ] loss: 0.584 correct: 1979.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [731 ] loss: 0.584 correct: 1981.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [732 ] loss: 0.584 correct: 1981.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [733 ] loss: 0.584 correct: 1983.000, total: 3000.000, accuracy: 0.661\n",
            "training epoch: [734 ] loss: 0.584 correct: 1984.000, total: 3000.000, accuracy: 0.661\n",
            "training epoch: [735 ] loss: 0.583 correct: 1981.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [736 ] loss: 0.583 correct: 1980.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [737 ] loss: 0.583 correct: 1981.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [738 ] loss: 0.583 correct: 1982.000, total: 3000.000, accuracy: 0.661\n",
            "training epoch: [739 ] loss: 0.583 correct: 1981.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [740 ] loss: 0.583 correct: 1980.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [741 ] loss: 0.583 correct: 1977.000, total: 3000.000, accuracy: 0.659\n",
            "training epoch: [742 ] loss: 0.583 correct: 1976.000, total: 3000.000, accuracy: 0.659\n",
            "training epoch: [743 ] loss: 0.583 correct: 1973.000, total: 3000.000, accuracy: 0.658\n",
            "training epoch: [744 ] loss: 0.583 correct: 1972.000, total: 3000.000, accuracy: 0.657\n",
            "training epoch: [745 ] loss: 0.583 correct: 1974.000, total: 3000.000, accuracy: 0.658\n",
            "training epoch: [746 ] loss: 0.583 correct: 1975.000, total: 3000.000, accuracy: 0.658\n",
            "training epoch: [747 ] loss: 0.583 correct: 1977.000, total: 3000.000, accuracy: 0.659\n",
            "training epoch: [748 ] loss: 0.583 correct: 1978.000, total: 3000.000, accuracy: 0.659\n",
            "training epoch: [749 ] loss: 0.583 correct: 1977.000, total: 3000.000, accuracy: 0.659\n",
            "training epoch: [750 ] loss: 0.583 correct: 1977.000, total: 3000.000, accuracy: 0.659\n",
            "training epoch: [751 ] loss: 0.583 correct: 1980.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [752 ] loss: 0.583 correct: 1980.000, total: 3000.000, accuracy: 0.660\n",
            "training epoch: [753 ] loss: 0.583 correct: 1984.000, total: 3000.000, accuracy: 0.661\n",
            "training epoch: [754 ] loss: 0.583 correct: 1983.000, total: 3000.000, accuracy: 0.661\n",
            "training epoch: [755 ] loss: 0.583 correct: 1986.000, total: 3000.000, accuracy: 0.662\n",
            "training epoch: [756 ] loss: 0.583 correct: 1985.000, total: 3000.000, accuracy: 0.662\n",
            "training epoch: [757 ] loss: 0.583 correct: 1992.000, total: 3000.000, accuracy: 0.664\n",
            "training epoch: [758 ] loss: 0.582 correct: 1993.000, total: 3000.000, accuracy: 0.664\n",
            "training epoch: [759 ] loss: 0.582 correct: 1998.000, total: 3000.000, accuracy: 0.666\n",
            "training epoch: [760 ] loss: 0.582 correct: 1995.000, total: 3000.000, accuracy: 0.665\n",
            "training epoch: [761 ] loss: 0.582 correct: 1995.000, total: 3000.000, accuracy: 0.665\n",
            "training epoch: [762 ] loss: 0.582 correct: 1996.000, total: 3000.000, accuracy: 0.665\n",
            "training epoch: [763 ] loss: 0.582 correct: 2002.000, total: 3000.000, accuracy: 0.667\n",
            "training epoch: [764 ] loss: 0.582 correct: 2001.000, total: 3000.000, accuracy: 0.667\n",
            "training epoch: [765 ] loss: 0.582 correct: 2003.000, total: 3000.000, accuracy: 0.668\n",
            "training epoch: [766 ] loss: 0.582 correct: 2007.000, total: 3000.000, accuracy: 0.669\n",
            "training epoch: [767 ] loss: 0.582 correct: 2010.000, total: 3000.000, accuracy: 0.670\n",
            "training epoch: [768 ] loss: 0.582 correct: 2013.000, total: 3000.000, accuracy: 0.671\n",
            "training epoch: [769 ] loss: 0.582 correct: 2011.000, total: 3000.000, accuracy: 0.670\n",
            "training epoch: [770 ] loss: 0.582 correct: 2018.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [771 ] loss: 0.582 correct: 2014.000, total: 3000.000, accuracy: 0.671\n",
            "training epoch: [772 ] loss: 0.582 correct: 2019.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [773 ] loss: 0.582 correct: 2018.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [774 ] loss: 0.581 correct: 2021.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [775 ] loss: 0.581 correct: 2020.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [776 ] loss: 0.581 correct: 2020.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [777 ] loss: 0.581 correct: 2020.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [778 ] loss: 0.581 correct: 2022.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [779 ] loss: 0.581 correct: 2023.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [780 ] loss: 0.581 correct: 2024.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [781 ] loss: 0.581 correct: 2023.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [782 ] loss: 0.581 correct: 2021.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [783 ] loss: 0.581 correct: 2021.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [784 ] loss: 0.581 correct: 2023.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [785 ] loss: 0.581 correct: 2023.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [786 ] loss: 0.581 correct: 2024.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [787 ] loss: 0.581 correct: 2023.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [788 ] loss: 0.581 correct: 2025.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [789 ] loss: 0.581 correct: 2026.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [790 ] loss: 0.580 correct: 2025.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [791 ] loss: 0.580 correct: 2026.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [792 ] loss: 0.580 correct: 2028.000, total: 3000.000, accuracy: 0.676\n",
            "training epoch: [793 ] loss: 0.580 correct: 2024.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [794 ] loss: 0.580 correct: 2026.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [795 ] loss: 0.580 correct: 2023.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [796 ] loss: 0.580 correct: 2025.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [797 ] loss: 0.580 correct: 2025.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [798 ] loss: 0.580 correct: 2027.000, total: 3000.000, accuracy: 0.676\n",
            "training epoch: [799 ] loss: 0.580 correct: 2026.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [800 ] loss: 0.580 correct: 2026.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [801 ] loss: 0.580 correct: 2022.000, total: 3000.000, accuracy: 0.674\n",
            "training epoch: [802 ] loss: 0.580 correct: 2024.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [803 ] loss: 0.580 correct: 2026.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [804 ] loss: 0.580 correct: 2025.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [805 ] loss: 0.580 correct: 2024.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [806 ] loss: 0.580 correct: 2025.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [807 ] loss: 0.579 correct: 2024.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [808 ] loss: 0.580 correct: 2033.000, total: 3000.000, accuracy: 0.678\n",
            "training epoch: [809 ] loss: 0.579 correct: 2032.000, total: 3000.000, accuracy: 0.677\n",
            "training epoch: [810 ] loss: 0.580 correct: 2028.000, total: 3000.000, accuracy: 0.676\n",
            "training epoch: [811 ] loss: 0.579 correct: 2030.000, total: 3000.000, accuracy: 0.677\n",
            "training epoch: [812 ] loss: 0.580 correct: 2029.000, total: 3000.000, accuracy: 0.676\n",
            "training epoch: [813 ] loss: 0.578 correct: 2026.000, total: 3000.000, accuracy: 0.675\n",
            "training epoch: [814 ] loss: 0.580 correct: 2048.000, total: 3000.000, accuracy: 0.683\n",
            "training epoch: [815 ] loss: 0.578 correct: 2036.000, total: 3000.000, accuracy: 0.679\n",
            "training epoch: [816 ] loss: 0.580 correct: 2053.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [817 ] loss: 0.578 correct: 2030.000, total: 3000.000, accuracy: 0.677\n",
            "training epoch: [818 ] loss: 0.581 correct: 2051.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [819 ] loss: 0.578 correct: 2027.000, total: 3000.000, accuracy: 0.676\n",
            "training epoch: [820 ] loss: 0.581 correct: 2052.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [821 ] loss: 0.578 correct: 2018.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [822 ] loss: 0.580 correct: 2053.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [823 ] loss: 0.578 correct: 2020.000, total: 3000.000, accuracy: 0.673\n",
            "training epoch: [824 ] loss: 0.580 correct: 2054.000, total: 3000.000, accuracy: 0.685\n",
            "training epoch: [825 ] loss: 0.578 correct: 2027.000, total: 3000.000, accuracy: 0.676\n",
            "training epoch: [826 ] loss: 0.580 correct: 2055.000, total: 3000.000, accuracy: 0.685\n",
            "training epoch: [827 ] loss: 0.578 correct: 2034.000, total: 3000.000, accuracy: 0.678\n",
            "training epoch: [828 ] loss: 0.580 correct: 2055.000, total: 3000.000, accuracy: 0.685\n",
            "training epoch: [829 ] loss: 0.578 correct: 2045.000, total: 3000.000, accuracy: 0.682\n",
            "training epoch: [830 ] loss: 0.580 correct: 2055.000, total: 3000.000, accuracy: 0.685\n",
            "training epoch: [831 ] loss: 0.577 correct: 2053.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [832 ] loss: 0.580 correct: 2061.000, total: 3000.000, accuracy: 0.687\n",
            "training epoch: [833 ] loss: 0.577 correct: 2049.000, total: 3000.000, accuracy: 0.683\n",
            "training epoch: [834 ] loss: 0.580 correct: 2066.000, total: 3000.000, accuracy: 0.689\n",
            "training epoch: [835 ] loss: 0.577 correct: 2049.000, total: 3000.000, accuracy: 0.683\n",
            "training epoch: [836 ] loss: 0.580 correct: 2064.000, total: 3000.000, accuracy: 0.688\n",
            "training epoch: [837 ] loss: 0.578 correct: 2048.000, total: 3000.000, accuracy: 0.683\n",
            "training epoch: [838 ] loss: 0.580 correct: 2062.000, total: 3000.000, accuracy: 0.687\n",
            "training epoch: [839 ] loss: 0.577 correct: 2051.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [840 ] loss: 0.580 correct: 2059.000, total: 3000.000, accuracy: 0.686\n",
            "training epoch: [841 ] loss: 0.578 correct: 2047.000, total: 3000.000, accuracy: 0.682\n",
            "training epoch: [842 ] loss: 0.580 correct: 2064.000, total: 3000.000, accuracy: 0.688\n",
            "training epoch: [843 ] loss: 0.578 correct: 2047.000, total: 3000.000, accuracy: 0.682\n",
            "training epoch: [844 ] loss: 0.580 correct: 2065.000, total: 3000.000, accuracy: 0.688\n",
            "training epoch: [845 ] loss: 0.578 correct: 2047.000, total: 3000.000, accuracy: 0.682\n",
            "training epoch: [846 ] loss: 0.580 correct: 2071.000, total: 3000.000, accuracy: 0.690\n",
            "training epoch: [847 ] loss: 0.578 correct: 2045.000, total: 3000.000, accuracy: 0.682\n",
            "training epoch: [848 ] loss: 0.580 correct: 2072.000, total: 3000.000, accuracy: 0.691\n",
            "training epoch: [849 ] loss: 0.578 correct: 2044.000, total: 3000.000, accuracy: 0.681\n",
            "training epoch: [850 ] loss: 0.580 correct: 2069.000, total: 3000.000, accuracy: 0.690\n",
            "training epoch: [851 ] loss: 0.578 correct: 2043.000, total: 3000.000, accuracy: 0.681\n",
            "training epoch: [852 ] loss: 0.580 correct: 2074.000, total: 3000.000, accuracy: 0.691\n",
            "training epoch: [853 ] loss: 0.578 correct: 2052.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [854 ] loss: 0.580 correct: 2074.000, total: 3000.000, accuracy: 0.691\n",
            "training epoch: [855 ] loss: 0.578 correct: 2046.000, total: 3000.000, accuracy: 0.682\n",
            "training epoch: [856 ] loss: 0.580 correct: 2071.000, total: 3000.000, accuracy: 0.690\n",
            "training epoch: [857 ] loss: 0.578 correct: 2041.000, total: 3000.000, accuracy: 0.680\n",
            "training epoch: [858 ] loss: 0.580 correct: 2070.000, total: 3000.000, accuracy: 0.690\n",
            "training epoch: [859 ] loss: 0.579 correct: 2051.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [860 ] loss: 0.580 correct: 2069.000, total: 3000.000, accuracy: 0.690\n",
            "training epoch: [861 ] loss: 0.579 correct: 2054.000, total: 3000.000, accuracy: 0.685\n",
            "training epoch: [862 ] loss: 0.580 correct: 2066.000, total: 3000.000, accuracy: 0.689\n",
            "training epoch: [863 ] loss: 0.579 correct: 2053.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [864 ] loss: 0.580 correct: 2069.000, total: 3000.000, accuracy: 0.690\n",
            "training epoch: [865 ] loss: 0.579 correct: 2053.000, total: 3000.000, accuracy: 0.684\n",
            "training epoch: [866 ] loss: 0.580 correct: 2066.000, total: 3000.000, accuracy: 0.689\n",
            "training epoch: [867 ] loss: 0.579 correct: 2063.000, total: 3000.000, accuracy: 0.688\n",
            "training epoch: [868 ] loss: 0.580 correct: 2065.000, total: 3000.000, accuracy: 0.688\n",
            "training epoch: [869 ] loss: 0.579 correct: 2064.000, total: 3000.000, accuracy: 0.688\n",
            "training epoch: [870 ] loss: 0.580 correct: 2065.000, total: 3000.000, accuracy: 0.688\n",
            "training epoch: [871 ] loss: 0.579 correct: 2068.000, total: 3000.000, accuracy: 0.689\n",
            "training epoch: [872 ] loss: 0.580 correct: 2067.000, total: 3000.000, accuracy: 0.689\n",
            "training epoch: [873 ] loss: 0.579 correct: 2069.000, total: 3000.000, accuracy: 0.690\n",
            "training epoch: [874 ] loss: 0.580 correct: 2072.000, total: 3000.000, accuracy: 0.691\n",
            "training epoch: [875 ] loss: 0.579 correct: 2074.000, total: 3000.000, accuracy: 0.691\n",
            "training epoch: [876 ] loss: 0.580 correct: 2072.000, total: 3000.000, accuracy: 0.691\n",
            "training epoch: [877 ] loss: 0.580 correct: 2071.000, total: 3000.000, accuracy: 0.690\n",
            "training epoch: [878 ] loss: 0.580 correct: 2076.000, total: 3000.000, accuracy: 0.692\n",
            "training epoch: [879 ] loss: 0.580 correct: 2072.000, total: 3000.000, accuracy: 0.691\n",
            "training epoch: [880 ] loss: 0.580 correct: 2079.000, total: 3000.000, accuracy: 0.693\n",
            "training epoch: [881 ] loss: 0.580 correct: 2078.000, total: 3000.000, accuracy: 0.693\n",
            "training epoch: [882 ] loss: 0.580 correct: 2081.000, total: 3000.000, accuracy: 0.694\n",
            "training epoch: [883 ] loss: 0.580 correct: 2082.000, total: 3000.000, accuracy: 0.694\n",
            "training epoch: [884 ] loss: 0.580 correct: 2083.000, total: 3000.000, accuracy: 0.694\n",
            "training epoch: [885 ] loss: 0.580 correct: 2082.000, total: 3000.000, accuracy: 0.694\n",
            "training epoch: [886 ] loss: 0.580 correct: 2086.000, total: 3000.000, accuracy: 0.695\n",
            "training epoch: [887 ] loss: 0.580 correct: 2091.000, total: 3000.000, accuracy: 0.697\n",
            "training epoch: [888 ] loss: 0.580 correct: 2096.000, total: 3000.000, accuracy: 0.699\n",
            "training epoch: [889 ] loss: 0.580 correct: 2095.000, total: 3000.000, accuracy: 0.698\n",
            "training epoch: [890 ] loss: 0.580 correct: 2097.000, total: 3000.000, accuracy: 0.699\n",
            "training epoch: [891 ] loss: 0.580 correct: 2099.000, total: 3000.000, accuracy: 0.700\n",
            "training epoch: [892 ] loss: 0.580 correct: 2107.000, total: 3000.000, accuracy: 0.702\n",
            "training epoch: [893 ] loss: 0.580 correct: 2119.000, total: 3000.000, accuracy: 0.706\n",
            "training epoch: [894 ] loss: 0.580 correct: 2128.000, total: 3000.000, accuracy: 0.709\n",
            "training epoch: [895 ] loss: 0.580 correct: 2130.000, total: 3000.000, accuracy: 0.710\n",
            "training epoch: [896 ] loss: 0.580 correct: 2137.000, total: 3000.000, accuracy: 0.712\n",
            "training epoch: [897 ] loss: 0.580 correct: 2135.000, total: 3000.000, accuracy: 0.712\n",
            "training epoch: [898 ] loss: 0.580 correct: 2142.000, total: 3000.000, accuracy: 0.714\n",
            "training epoch: [899 ] loss: 0.580 correct: 2146.000, total: 3000.000, accuracy: 0.715\n",
            "training epoch: [900 ] loss: 0.580 correct: 2152.000, total: 3000.000, accuracy: 0.717\n",
            "training epoch: [901 ] loss: 0.580 correct: 2158.000, total: 3000.000, accuracy: 0.719\n",
            "training epoch: [902 ] loss: 0.580 correct: 2165.000, total: 3000.000, accuracy: 0.722\n",
            "training epoch: [903 ] loss: 0.580 correct: 2169.000, total: 3000.000, accuracy: 0.723\n",
            "training epoch: [904 ] loss: 0.580 correct: 2174.000, total: 3000.000, accuracy: 0.725\n",
            "training epoch: [905 ] loss: 0.580 correct: 2177.000, total: 3000.000, accuracy: 0.726\n",
            "training epoch: [906 ] loss: 0.580 correct: 2180.000, total: 3000.000, accuracy: 0.727\n",
            "training epoch: [907 ] loss: 0.580 correct: 2179.000, total: 3000.000, accuracy: 0.726\n",
            "training epoch: [908 ] loss: 0.580 correct: 2183.000, total: 3000.000, accuracy: 0.728\n",
            "training epoch: [909 ] loss: 0.580 correct: 2184.000, total: 3000.000, accuracy: 0.728\n",
            "training epoch: [910 ] loss: 0.580 correct: 2181.000, total: 3000.000, accuracy: 0.727\n",
            "training epoch: [911 ] loss: 0.580 correct: 2176.000, total: 3000.000, accuracy: 0.725\n",
            "training epoch: [912 ] loss: 0.580 correct: 2179.000, total: 3000.000, accuracy: 0.726\n",
            "training epoch: [913 ] loss: 0.580 correct: 2177.000, total: 3000.000, accuracy: 0.726\n",
            "training epoch: [914 ] loss: 0.580 correct: 2175.000, total: 3000.000, accuracy: 0.725\n",
            "training epoch: [915 ] loss: 0.580 correct: 2180.000, total: 3000.000, accuracy: 0.727\n",
            "training epoch: [916 ] loss: 0.580 correct: 2182.000, total: 3000.000, accuracy: 0.727\n",
            "training epoch: [917 ] loss: 0.580 correct: 2188.000, total: 3000.000, accuracy: 0.729\n",
            "training epoch: [918 ] loss: 0.580 correct: 2188.000, total: 3000.000, accuracy: 0.729\n",
            "training epoch: [919 ] loss: 0.580 correct: 2186.000, total: 3000.000, accuracy: 0.729\n",
            "training epoch: [920 ] loss: 0.580 correct: 2189.000, total: 3000.000, accuracy: 0.730\n",
            "training epoch: [921 ] loss: 0.580 correct: 2190.000, total: 3000.000, accuracy: 0.730\n",
            "training epoch: [922 ] loss: 0.580 correct: 2188.000, total: 3000.000, accuracy: 0.729\n",
            "training epoch: [923 ] loss: 0.580 correct: 2189.000, total: 3000.000, accuracy: 0.730\n",
            "training epoch: [924 ] loss: 0.580 correct: 2186.000, total: 3000.000, accuracy: 0.729\n",
            "training epoch: [925 ] loss: 0.580 correct: 2188.000, total: 3000.000, accuracy: 0.729\n",
            "training epoch: [926 ] loss: 0.580 correct: 2192.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [927 ] loss: 0.580 correct: 2192.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [928 ] loss: 0.580 correct: 2194.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [929 ] loss: 0.580 correct: 2192.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [930 ] loss: 0.580 correct: 2193.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [931 ] loss: 0.580 correct: 2196.000, total: 3000.000, accuracy: 0.732\n",
            "training epoch: [932 ] loss: 0.580 correct: 2193.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [933 ] loss: 0.580 correct: 2199.000, total: 3000.000, accuracy: 0.733\n",
            "training epoch: [934 ] loss: 0.580 correct: 2193.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [935 ] loss: 0.580 correct: 2202.000, total: 3000.000, accuracy: 0.734\n",
            "training epoch: [936 ] loss: 0.580 correct: 2195.000, total: 3000.000, accuracy: 0.732\n",
            "training epoch: [937 ] loss: 0.580 correct: 2200.000, total: 3000.000, accuracy: 0.733\n",
            "training epoch: [938 ] loss: 0.580 correct: 2196.000, total: 3000.000, accuracy: 0.732\n",
            "training epoch: [939 ] loss: 0.580 correct: 2201.000, total: 3000.000, accuracy: 0.734\n",
            "training epoch: [940 ] loss: 0.580 correct: 2193.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [941 ] loss: 0.580 correct: 2204.000, total: 3000.000, accuracy: 0.735\n",
            "training epoch: [942 ] loss: 0.580 correct: 2200.000, total: 3000.000, accuracy: 0.733\n",
            "training epoch: [943 ] loss: 0.580 correct: 2210.000, total: 3000.000, accuracy: 0.737\n",
            "training epoch: [944 ] loss: 0.580 correct: 2191.000, total: 3000.000, accuracy: 0.730\n",
            "training epoch: [945 ] loss: 0.580 correct: 2209.000, total: 3000.000, accuracy: 0.736\n",
            "training epoch: [946 ] loss: 0.580 correct: 2180.000, total: 3000.000, accuracy: 0.727\n",
            "training epoch: [947 ] loss: 0.580 correct: 2210.000, total: 3000.000, accuracy: 0.737\n",
            "training epoch: [948 ] loss: 0.581 correct: 2178.000, total: 3000.000, accuracy: 0.726\n",
            "training epoch: [949 ] loss: 0.580 correct: 2212.000, total: 3000.000, accuracy: 0.737\n",
            "training epoch: [950 ] loss: 0.581 correct: 2163.000, total: 3000.000, accuracy: 0.721\n",
            "training epoch: [951 ] loss: 0.580 correct: 2218.000, total: 3000.000, accuracy: 0.739\n",
            "training epoch: [952 ] loss: 0.581 correct: 2148.000, total: 3000.000, accuracy: 0.716\n",
            "training epoch: [953 ] loss: 0.580 correct: 2199.000, total: 3000.000, accuracy: 0.733\n",
            "training epoch: [954 ] loss: 0.581 correct: 2150.000, total: 3000.000, accuracy: 0.717\n",
            "training epoch: [955 ] loss: 0.580 correct: 2215.000, total: 3000.000, accuracy: 0.738\n",
            "training epoch: [956 ] loss: 0.581 correct: 2166.000, total: 3000.000, accuracy: 0.722\n",
            "training epoch: [957 ] loss: 0.580 correct: 2217.000, total: 3000.000, accuracy: 0.739\n",
            "training epoch: [958 ] loss: 0.581 correct: 2176.000, total: 3000.000, accuracy: 0.725\n",
            "training epoch: [959 ] loss: 0.580 correct: 2215.000, total: 3000.000, accuracy: 0.738\n",
            "training epoch: [960 ] loss: 0.581 correct: 2179.000, total: 3000.000, accuracy: 0.726\n",
            "training epoch: [961 ] loss: 0.580 correct: 2214.000, total: 3000.000, accuracy: 0.738\n",
            "training epoch: [962 ] loss: 0.581 correct: 2187.000, total: 3000.000, accuracy: 0.729\n",
            "training epoch: [963 ] loss: 0.581 correct: 2212.000, total: 3000.000, accuracy: 0.737\n",
            "training epoch: [964 ] loss: 0.581 correct: 2188.000, total: 3000.000, accuracy: 0.729\n",
            "training epoch: [965 ] loss: 0.581 correct: 2213.000, total: 3000.000, accuracy: 0.738\n",
            "training epoch: [966 ] loss: 0.581 correct: 2196.000, total: 3000.000, accuracy: 0.732\n",
            "training epoch: [967 ] loss: 0.581 correct: 2212.000, total: 3000.000, accuracy: 0.737\n",
            "training epoch: [968 ] loss: 0.582 correct: 2195.000, total: 3000.000, accuracy: 0.732\n",
            "training epoch: [969 ] loss: 0.581 correct: 2212.000, total: 3000.000, accuracy: 0.737\n",
            "training epoch: [970 ] loss: 0.582 correct: 2192.000, total: 3000.000, accuracy: 0.731\n",
            "training epoch: [971 ] loss: 0.582 correct: 2213.000, total: 3000.000, accuracy: 0.738\n",
            "training epoch: [972 ] loss: 0.582 correct: 2197.000, total: 3000.000, accuracy: 0.732\n",
            "training epoch: [973 ] loss: 0.582 correct: 2211.000, total: 3000.000, accuracy: 0.737\n",
            "training epoch: [974 ] loss: 0.582 correct: 2196.000, total: 3000.000, accuracy: 0.732\n",
            "training epoch: [975 ] loss: 0.582 correct: 2212.000, total: 3000.000, accuracy: 0.737\n",
            "training epoch: [976 ] loss: 0.582 correct: 2200.000, total: 3000.000, accuracy: 0.733\n",
            "training epoch: [977 ] loss: 0.582 correct: 2214.000, total: 3000.000, accuracy: 0.738\n",
            "training epoch: [978 ] loss: 0.583 correct: 2205.000, total: 3000.000, accuracy: 0.735\n",
            "training epoch: [979 ] loss: 0.583 correct: 2213.000, total: 3000.000, accuracy: 0.738\n",
            "training epoch: [980 ] loss: 0.583 correct: 2203.000, total: 3000.000, accuracy: 0.734\n",
            "training epoch: [981 ] loss: 0.583 correct: 2216.000, total: 3000.000, accuracy: 0.739\n",
            "training epoch: [982 ] loss: 0.583 correct: 2205.000, total: 3000.000, accuracy: 0.735\n",
            "training epoch: [983 ] loss: 0.583 correct: 2218.000, total: 3000.000, accuracy: 0.739\n",
            "training epoch: [984 ] loss: 0.584 correct: 2206.000, total: 3000.000, accuracy: 0.735\n",
            "training epoch: [985 ] loss: 0.584 correct: 2219.000, total: 3000.000, accuracy: 0.740\n",
            "training epoch: [986 ] loss: 0.584 correct: 2209.000, total: 3000.000, accuracy: 0.736\n",
            "training epoch: [987 ] loss: 0.584 correct: 2222.000, total: 3000.000, accuracy: 0.741\n",
            "training epoch: [988 ] loss: 0.585 correct: 2209.000, total: 3000.000, accuracy: 0.736\n",
            "training epoch: [989 ] loss: 0.584 correct: 2224.000, total: 3000.000, accuracy: 0.741\n",
            "training epoch: [990 ] loss: 0.585 correct: 2213.000, total: 3000.000, accuracy: 0.738\n",
            "training epoch: [991 ] loss: 0.585 correct: 2217.000, total: 3000.000, accuracy: 0.739\n",
            "training epoch: [992 ] loss: 0.585 correct: 2209.000, total: 3000.000, accuracy: 0.736\n",
            "training epoch: [993 ] loss: 0.585 correct: 2223.000, total: 3000.000, accuracy: 0.741\n",
            "training epoch: [994 ] loss: 0.586 correct: 2222.000, total: 3000.000, accuracy: 0.741\n",
            "training epoch: [995 ] loss: 0.586 correct: 2235.000, total: 3000.000, accuracy: 0.745\n",
            "training epoch: [996 ] loss: 0.586 correct: 2229.000, total: 3000.000, accuracy: 0.743\n",
            "training epoch: [997 ] loss: 0.586 correct: 2243.000, total: 3000.000, accuracy: 0.748\n",
            "training epoch: [998 ] loss: 0.586 correct: 2240.000, total: 3000.000, accuracy: 0.747\n",
            "training epoch: [999 ] loss: 0.586 correct: 2257.000, total: 3000.000, accuracy: 0.752\n",
            "training epoch: [1000 ] loss: 0.586 correct: 2250.000, total: 3000.000, accuracy: 0.750\n",
            "training epoch: [1001 ] loss: 0.586 correct: 2266.000, total: 3000.000, accuracy: 0.755\n",
            "training epoch: [1002 ] loss: 0.586 correct: 2263.000, total: 3000.000, accuracy: 0.754\n",
            "training epoch: [1003 ] loss: 0.586 correct: 2287.000, total: 3000.000, accuracy: 0.762\n",
            "training epoch: [1004 ] loss: 0.586 correct: 2280.000, total: 3000.000, accuracy: 0.760\n",
            "training epoch: [1005 ] loss: 0.585 correct: 2310.000, total: 3000.000, accuracy: 0.770\n",
            "training epoch: [1006 ] loss: 0.584 correct: 2305.000, total: 3000.000, accuracy: 0.768\n",
            "training epoch: [1007 ] loss: 0.583 correct: 2328.000, total: 3000.000, accuracy: 0.776\n",
            "training epoch: [1008 ] loss: 0.582 correct: 2327.000, total: 3000.000, accuracy: 0.776\n",
            "training epoch: [1009 ] loss: 0.581 correct: 2331.000, total: 3000.000, accuracy: 0.777\n",
            "training epoch: [1010 ] loss: 0.580 correct: 2344.000, total: 3000.000, accuracy: 0.781\n",
            "training epoch: [1011 ] loss: 0.578 correct: 2362.000, total: 3000.000, accuracy: 0.787\n",
            "training epoch: [1012 ] loss: 0.577 correct: 2359.000, total: 3000.000, accuracy: 0.786\n",
            "training epoch: [1013 ] loss: 0.576 correct: 2376.000, total: 3000.000, accuracy: 0.792\n",
            "training epoch: [1014 ] loss: 0.575 correct: 2373.000, total: 3000.000, accuracy: 0.791\n",
            "training epoch: [1015 ] loss: 0.573 correct: 2393.000, total: 3000.000, accuracy: 0.798\n",
            "training epoch: [1016 ] loss: 0.572 correct: 2388.000, total: 3000.000, accuracy: 0.796\n",
            "training epoch: [1017 ] loss: 0.571 correct: 2407.000, total: 3000.000, accuracy: 0.802\n",
            "training epoch: [1018 ] loss: 0.570 correct: 2404.000, total: 3000.000, accuracy: 0.801\n",
            "training epoch: [1019 ] loss: 0.569 correct: 2429.000, total: 3000.000, accuracy: 0.810\n",
            "training epoch: [1020 ] loss: 0.567 correct: 2419.000, total: 3000.000, accuracy: 0.806\n",
            "training epoch: [1021 ] loss: 0.566 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [1022 ] loss: 0.565 correct: 2444.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [1023 ] loss: 0.563 correct: 2457.000, total: 3000.000, accuracy: 0.819\n",
            "training epoch: [1024 ] loss: 0.562 correct: 2453.000, total: 3000.000, accuracy: 0.818\n",
            "training epoch: [1025 ] loss: 0.560 correct: 2469.000, total: 3000.000, accuracy: 0.823\n",
            "training epoch: [1026 ] loss: 0.559 correct: 2467.000, total: 3000.000, accuracy: 0.822\n",
            "training epoch: [1027 ] loss: 0.558 correct: 2476.000, total: 3000.000, accuracy: 0.825\n",
            "training epoch: [1028 ] loss: 0.556 correct: 2480.000, total: 3000.000, accuracy: 0.827\n",
            "training epoch: [1029 ] loss: 0.555 correct: 2494.000, total: 3000.000, accuracy: 0.831\n",
            "training epoch: [1030 ] loss: 0.554 correct: 2497.000, total: 3000.000, accuracy: 0.832\n",
            "training epoch: [1031 ] loss: 0.553 correct: 2501.000, total: 3000.000, accuracy: 0.834\n",
            "training epoch: [1032 ] loss: 0.551 correct: 2510.000, total: 3000.000, accuracy: 0.837\n",
            "training epoch: [1033 ] loss: 0.550 correct: 2516.000, total: 3000.000, accuracy: 0.839\n",
            "training epoch: [1034 ] loss: 0.548 correct: 2521.000, total: 3000.000, accuracy: 0.840\n",
            "training epoch: [1035 ] loss: 0.547 correct: 2528.000, total: 3000.000, accuracy: 0.843\n",
            "training epoch: [1036 ] loss: 0.545 correct: 2535.000, total: 3000.000, accuracy: 0.845\n",
            "training epoch: [1037 ] loss: 0.543 correct: 2540.000, total: 3000.000, accuracy: 0.847\n",
            "training epoch: [1038 ] loss: 0.542 correct: 2545.000, total: 3000.000, accuracy: 0.848\n",
            "training epoch: [1039 ] loss: 0.540 correct: 2557.000, total: 3000.000, accuracy: 0.852\n",
            "training epoch: [1040 ] loss: 0.538 correct: 2567.000, total: 3000.000, accuracy: 0.856\n",
            "training epoch: [1041 ] loss: 0.537 correct: 2575.000, total: 3000.000, accuracy: 0.858\n",
            "training epoch: [1042 ] loss: 0.536 correct: 2579.000, total: 3000.000, accuracy: 0.860\n",
            "training epoch: [1043 ] loss: 0.535 correct: 2582.000, total: 3000.000, accuracy: 0.861\n",
            "training epoch: [1044 ] loss: 0.534 correct: 2588.000, total: 3000.000, accuracy: 0.863\n",
            "training epoch: [1045 ] loss: 0.533 correct: 2593.000, total: 3000.000, accuracy: 0.864\n",
            "training epoch: [1046 ] loss: 0.533 correct: 2595.000, total: 3000.000, accuracy: 0.865\n",
            "training epoch: [1047 ] loss: 0.532 correct: 2606.000, total: 3000.000, accuracy: 0.869\n",
            "training epoch: [1048 ] loss: 0.531 correct: 2614.000, total: 3000.000, accuracy: 0.871\n",
            "training epoch: [1049 ] loss: 0.531 correct: 2616.000, total: 3000.000, accuracy: 0.872\n",
            "training epoch: [1050 ] loss: 0.530 correct: 2620.000, total: 3000.000, accuracy: 0.873\n",
            "training epoch: [1051 ] loss: 0.529 correct: 2630.000, total: 3000.000, accuracy: 0.877\n",
            "training epoch: [1052 ] loss: 0.529 correct: 2636.000, total: 3000.000, accuracy: 0.879\n",
            "training epoch: [1053 ] loss: 0.528 correct: 2639.000, total: 3000.000, accuracy: 0.880\n",
            "training epoch: [1054 ] loss: 0.527 correct: 2646.000, total: 3000.000, accuracy: 0.882\n",
            "training epoch: [1055 ] loss: 0.527 correct: 2649.000, total: 3000.000, accuracy: 0.883\n",
            "training epoch: [1056 ] loss: 0.526 correct: 2657.000, total: 3000.000, accuracy: 0.886\n",
            "training epoch: [1057 ] loss: 0.526 correct: 2660.000, total: 3000.000, accuracy: 0.887\n",
            "training epoch: [1058 ] loss: 0.525 correct: 2662.000, total: 3000.000, accuracy: 0.887\n",
            "training epoch: [1059 ] loss: 0.524 correct: 2668.000, total: 3000.000, accuracy: 0.889\n",
            "training epoch: [1060 ] loss: 0.524 correct: 2674.000, total: 3000.000, accuracy: 0.891\n",
            "training epoch: [1061 ] loss: 0.523 correct: 2673.000, total: 3000.000, accuracy: 0.891\n",
            "training epoch: [1062 ] loss: 0.523 correct: 2682.000, total: 3000.000, accuracy: 0.894\n",
            "training epoch: [1063 ] loss: 0.522 correct: 2682.000, total: 3000.000, accuracy: 0.894\n",
            "training epoch: [1064 ] loss: 0.522 correct: 2686.000, total: 3000.000, accuracy: 0.895\n",
            "training epoch: [1065 ] loss: 0.521 correct: 2689.000, total: 3000.000, accuracy: 0.896\n",
            "training epoch: [1066 ] loss: 0.521 correct: 2694.000, total: 3000.000, accuracy: 0.898\n",
            "training epoch: [1067 ] loss: 0.520 correct: 2697.000, total: 3000.000, accuracy: 0.899\n",
            "training epoch: [1068 ] loss: 0.520 correct: 2700.000, total: 3000.000, accuracy: 0.900\n",
            "training epoch: [1069 ] loss: 0.519 correct: 2701.000, total: 3000.000, accuracy: 0.900\n",
            "training epoch: [1070 ] loss: 0.519 correct: 2703.000, total: 3000.000, accuracy: 0.901\n",
            "training epoch: [1071 ] loss: 0.519 correct: 2709.000, total: 3000.000, accuracy: 0.903\n",
            "training epoch: [1072 ] loss: 0.518 correct: 2712.000, total: 3000.000, accuracy: 0.904\n",
            "training epoch: [1073 ] loss: 0.518 correct: 2712.000, total: 3000.000, accuracy: 0.904\n",
            "training epoch: [1074 ] loss: 0.517 correct: 2715.000, total: 3000.000, accuracy: 0.905\n",
            "training epoch: [1075 ] loss: 0.517 correct: 2718.000, total: 3000.000, accuracy: 0.906\n",
            "training epoch: [1076 ] loss: 0.517 correct: 2724.000, total: 3000.000, accuracy: 0.908\n",
            "training epoch: [1077 ] loss: 0.516 correct: 2725.000, total: 3000.000, accuracy: 0.908\n",
            "training epoch: [1078 ] loss: 0.516 correct: 2728.000, total: 3000.000, accuracy: 0.909\n",
            "training epoch: [1079 ] loss: 0.515 correct: 2729.000, total: 3000.000, accuracy: 0.910\n",
            "training epoch: [1080 ] loss: 0.515 correct: 2730.000, total: 3000.000, accuracy: 0.910\n",
            "training epoch: [1081 ] loss: 0.515 correct: 2734.000, total: 3000.000, accuracy: 0.911\n",
            "training epoch: [1082 ] loss: 0.514 correct: 2738.000, total: 3000.000, accuracy: 0.913\n",
            "training epoch: [1083 ] loss: 0.514 correct: 2742.000, total: 3000.000, accuracy: 0.914\n",
            "training epoch: [1084 ] loss: 0.514 correct: 2743.000, total: 3000.000, accuracy: 0.914\n",
            "training epoch: [1085 ] loss: 0.513 correct: 2744.000, total: 3000.000, accuracy: 0.915\n",
            "training epoch: [1086 ] loss: 0.513 correct: 2749.000, total: 3000.000, accuracy: 0.916\n",
            "training epoch: [1087 ] loss: 0.513 correct: 2750.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [1088 ] loss: 0.512 correct: 2753.000, total: 3000.000, accuracy: 0.918\n",
            "training epoch: [1089 ] loss: 0.512 correct: 2755.000, total: 3000.000, accuracy: 0.918\n",
            "training epoch: [1090 ] loss: 0.512 correct: 2756.000, total: 3000.000, accuracy: 0.919\n",
            "training epoch: [1091 ] loss: 0.511 correct: 2756.000, total: 3000.000, accuracy: 0.919\n",
            "training epoch: [1092 ] loss: 0.511 correct: 2759.000, total: 3000.000, accuracy: 0.920\n",
            "training epoch: [1093 ] loss: 0.510 correct: 2760.000, total: 3000.000, accuracy: 0.920\n",
            "training epoch: [1094 ] loss: 0.509 correct: 2762.000, total: 3000.000, accuracy: 0.921\n",
            "training epoch: [1095 ] loss: 0.508 correct: 2767.000, total: 3000.000, accuracy: 0.922\n",
            "training epoch: [1096 ] loss: 0.508 correct: 2767.000, total: 3000.000, accuracy: 0.922\n",
            "training epoch: [1097 ] loss: 0.507 correct: 2770.000, total: 3000.000, accuracy: 0.923\n",
            "training epoch: [1098 ] loss: 0.507 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [1099 ] loss: 0.506 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [1100 ] loss: 0.506 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [1101 ] loss: 0.506 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [1102 ] loss: 0.505 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1103 ] loss: 0.505 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1104 ] loss: 0.505 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [1105 ] loss: 0.505 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1106 ] loss: 0.504 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1107 ] loss: 0.504 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1108 ] loss: 0.504 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1109 ] loss: 0.504 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1110 ] loss: 0.503 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1111 ] loss: 0.503 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [1112 ] loss: 0.503 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [1113 ] loss: 0.503 correct: 2783.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [1114 ] loss: 0.503 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1115 ] loss: 0.502 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1116 ] loss: 0.502 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1117 ] loss: 0.502 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1118 ] loss: 0.502 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1119 ] loss: 0.502 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1120 ] loss: 0.501 correct: 2788.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1121 ] loss: 0.501 correct: 2788.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1122 ] loss: 0.501 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1123 ] loss: 0.501 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1124 ] loss: 0.501 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1125 ] loss: 0.500 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [1126 ] loss: 0.500 correct: 2789.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [1127 ] loss: 0.500 correct: 2789.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [1128 ] loss: 0.500 correct: 2791.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [1129 ] loss: 0.500 correct: 2792.000, total: 3000.000, accuracy: 0.931\n",
            "training epoch: [1130 ] loss: 0.499 correct: 2794.000, total: 3000.000, accuracy: 0.931\n",
            "training epoch: [1131 ] loss: 0.499 correct: 2795.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1132 ] loss: 0.499 correct: 2796.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1133 ] loss: 0.499 correct: 2796.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1134 ] loss: 0.498 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1135 ] loss: 0.498 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1136 ] loss: 0.498 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1137 ] loss: 0.498 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1138 ] loss: 0.498 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1139 ] loss: 0.497 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1140 ] loss: 0.497 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1141 ] loss: 0.497 correct: 2798.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1142 ] loss: 0.497 correct: 2798.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1143 ] loss: 0.496 correct: 2798.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1144 ] loss: 0.496 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1145 ] loss: 0.496 correct: 2797.000, total: 3000.000, accuracy: 0.932\n",
            "training epoch: [1146 ] loss: 0.496 correct: 2798.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1147 ] loss: 0.495 correct: 2800.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1148 ] loss: 0.495 correct: 2800.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1149 ] loss: 0.495 correct: 2800.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1150 ] loss: 0.495 correct: 2800.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1151 ] loss: 0.495 correct: 2799.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1152 ] loss: 0.494 correct: 2799.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1153 ] loss: 0.494 correct: 2800.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1154 ] loss: 0.494 correct: 2800.000, total: 3000.000, accuracy: 0.933\n",
            "training epoch: [1155 ] loss: 0.494 correct: 2801.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [1156 ] loss: 0.493 correct: 2802.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [1157 ] loss: 0.493 correct: 2802.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [1158 ] loss: 0.493 correct: 2802.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [1159 ] loss: 0.493 correct: 2803.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [1160 ] loss: 0.492 correct: 2803.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [1161 ] loss: 0.492 correct: 2803.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [1162 ] loss: 0.492 correct: 2803.000, total: 3000.000, accuracy: 0.934\n",
            "training epoch: [1163 ] loss: 0.492 correct: 2805.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [1164 ] loss: 0.492 correct: 2805.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [1165 ] loss: 0.491 correct: 2805.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [1166 ] loss: 0.491 correct: 2805.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [1167 ] loss: 0.491 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [1168 ] loss: 0.491 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1169 ] loss: 0.490 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1170 ] loss: 0.490 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1171 ] loss: 0.490 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1172 ] loss: 0.490 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1173 ] loss: 0.490 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1174 ] loss: 0.489 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1175 ] loss: 0.489 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1176 ] loss: 0.489 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1177 ] loss: 0.489 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1178 ] loss: 0.488 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1179 ] loss: 0.488 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1180 ] loss: 0.488 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1181 ] loss: 0.488 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1182 ] loss: 0.487 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1183 ] loss: 0.487 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1184 ] loss: 0.487 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1185 ] loss: 0.487 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1186 ] loss: 0.487 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1187 ] loss: 0.486 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1188 ] loss: 0.486 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1189 ] loss: 0.486 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1190 ] loss: 0.486 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1191 ] loss: 0.485 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1192 ] loss: 0.485 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1193 ] loss: 0.485 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1194 ] loss: 0.485 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1195 ] loss: 0.485 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1196 ] loss: 0.484 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1197 ] loss: 0.484 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1198 ] loss: 0.484 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1199 ] loss: 0.484 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1200 ] loss: 0.484 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1201 ] loss: 0.483 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1202 ] loss: 0.483 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1203 ] loss: 0.483 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1204 ] loss: 0.483 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1205 ] loss: 0.482 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1206 ] loss: 0.482 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1207 ] loss: 0.482 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1208 ] loss: 0.482 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1209 ] loss: 0.482 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1210 ] loss: 0.481 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1211 ] loss: 0.481 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1212 ] loss: 0.481 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1213 ] loss: 0.481 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1214 ] loss: 0.481 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1215 ] loss: 0.480 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1216 ] loss: 0.480 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1217 ] loss: 0.480 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1218 ] loss: 0.480 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1219 ] loss: 0.479 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1220 ] loss: 0.479 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1221 ] loss: 0.479 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1222 ] loss: 0.479 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1223 ] loss: 0.479 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1224 ] loss: 0.478 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1225 ] loss: 0.478 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1226 ] loss: 0.478 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1227 ] loss: 0.478 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1228 ] loss: 0.478 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1229 ] loss: 0.477 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1230 ] loss: 0.477 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1231 ] loss: 0.477 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1232 ] loss: 0.477 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1233 ] loss: 0.477 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1234 ] loss: 0.476 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1235 ] loss: 0.476 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1236 ] loss: 0.476 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1237 ] loss: 0.476 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1238 ] loss: 0.476 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1239 ] loss: 0.475 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1240 ] loss: 0.475 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1241 ] loss: 0.475 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1242 ] loss: 0.475 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1243 ] loss: 0.474 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1244 ] loss: 0.474 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1245 ] loss: 0.474 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1246 ] loss: 0.474 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1247 ] loss: 0.474 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1248 ] loss: 0.473 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1249 ] loss: 0.473 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1250 ] loss: 0.473 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1251 ] loss: 0.473 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1252 ] loss: 0.473 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1253 ] loss: 0.472 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1254 ] loss: 0.472 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1255 ] loss: 0.472 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1256 ] loss: 0.472 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1257 ] loss: 0.472 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1258 ] loss: 0.471 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1259 ] loss: 0.471 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1260 ] loss: 0.471 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1261 ] loss: 0.471 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1262 ] loss: 0.471 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1263 ] loss: 0.470 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1264 ] loss: 0.470 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1265 ] loss: 0.470 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1266 ] loss: 0.470 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1267 ] loss: 0.470 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1268 ] loss: 0.469 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1269 ] loss: 0.469 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1270 ] loss: 0.469 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1271 ] loss: 0.469 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1272 ] loss: 0.469 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1273 ] loss: 0.468 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1274 ] loss: 0.468 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1275 ] loss: 0.468 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1276 ] loss: 0.468 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1277 ] loss: 0.468 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1278 ] loss: 0.467 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1279 ] loss: 0.467 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1280 ] loss: 0.467 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1281 ] loss: 0.467 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1282 ] loss: 0.467 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1283 ] loss: 0.466 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1284 ] loss: 0.466 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1285 ] loss: 0.466 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1286 ] loss: 0.466 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1287 ] loss: 0.466 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1288 ] loss: 0.465 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1289 ] loss: 0.465 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1290 ] loss: 0.465 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1291 ] loss: 0.465 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1292 ] loss: 0.465 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1293 ] loss: 0.464 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1294 ] loss: 0.464 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1295 ] loss: 0.464 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1296 ] loss: 0.464 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1297 ] loss: 0.464 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1298 ] loss: 0.464 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1299 ] loss: 0.463 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1300 ] loss: 0.463 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1301 ] loss: 0.463 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1302 ] loss: 0.463 correct: 2820.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1303 ] loss: 0.463 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1304 ] loss: 0.463 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1305 ] loss: 0.462 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1306 ] loss: 0.462 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1307 ] loss: 0.462 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1308 ] loss: 0.462 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1309 ] loss: 0.461 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1310 ] loss: 0.461 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1311 ] loss: 0.461 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1312 ] loss: 0.461 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1313 ] loss: 0.461 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1314 ] loss: 0.461 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1315 ] loss: 0.460 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1316 ] loss: 0.460 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1317 ] loss: 0.460 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1318 ] loss: 0.460 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1319 ] loss: 0.460 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1320 ] loss: 0.459 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1321 ] loss: 0.459 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1322 ] loss: 0.459 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1323 ] loss: 0.459 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1324 ] loss: 0.459 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1325 ] loss: 0.458 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1326 ] loss: 0.458 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1327 ] loss: 0.458 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1328 ] loss: 0.458 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1329 ] loss: 0.458 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1330 ] loss: 0.457 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1331 ] loss: 0.457 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1332 ] loss: 0.457 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1333 ] loss: 0.457 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1334 ] loss: 0.457 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1335 ] loss: 0.456 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1336 ] loss: 0.456 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1337 ] loss: 0.456 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1338 ] loss: 0.456 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1339 ] loss: 0.456 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1340 ] loss: 0.455 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1341 ] loss: 0.455 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1342 ] loss: 0.455 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1343 ] loss: 0.455 correct: 2831.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1344 ] loss: 0.455 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1345 ] loss: 0.454 correct: 2831.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1346 ] loss: 0.454 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1347 ] loss: 0.454 correct: 2831.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1348 ] loss: 0.454 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1349 ] loss: 0.454 correct: 2833.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1350 ] loss: 0.454 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1351 ] loss: 0.453 correct: 2832.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1352 ] loss: 0.453 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1353 ] loss: 0.453 correct: 2832.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1354 ] loss: 0.453 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1355 ] loss: 0.452 correct: 2833.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1356 ] loss: 0.452 correct: 2831.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1357 ] loss: 0.452 correct: 2833.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1358 ] loss: 0.452 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1359 ] loss: 0.452 correct: 2834.000, total: 3000.000, accuracy: 0.945\n",
            "training epoch: [1360 ] loss: 0.452 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1361 ] loss: 0.451 correct: 2834.000, total: 3000.000, accuracy: 0.945\n",
            "training epoch: [1362 ] loss: 0.451 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1363 ] loss: 0.451 correct: 2833.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1364 ] loss: 0.451 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1365 ] loss: 0.451 correct: 2831.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1366 ] loss: 0.451 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1367 ] loss: 0.450 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1368 ] loss: 0.450 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1369 ] loss: 0.450 correct: 2831.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1370 ] loss: 0.450 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1371 ] loss: 0.449 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1372 ] loss: 0.449 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1373 ] loss: 0.449 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1374 ] loss: 0.449 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1375 ] loss: 0.449 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1376 ] loss: 0.449 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1377 ] loss: 0.448 correct: 2831.000, total: 3000.000, accuracy: 0.944\n",
            "training epoch: [1378 ] loss: 0.448 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1379 ] loss: 0.448 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1380 ] loss: 0.448 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1381 ] loss: 0.448 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1382 ] loss: 0.447 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1383 ] loss: 0.447 correct: 2830.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1384 ] loss: 0.447 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1385 ] loss: 0.447 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1386 ] loss: 0.447 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1387 ] loss: 0.446 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1388 ] loss: 0.446 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1389 ] loss: 0.446 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1390 ] loss: 0.446 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1391 ] loss: 0.446 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1392 ] loss: 0.445 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1393 ] loss: 0.445 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1394 ] loss: 0.445 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1395 ] loss: 0.445 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1396 ] loss: 0.445 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1397 ] loss: 0.444 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1398 ] loss: 0.444 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1399 ] loss: 0.444 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1400 ] loss: 0.444 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1401 ] loss: 0.444 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1402 ] loss: 0.444 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1403 ] loss: 0.443 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1404 ] loss: 0.443 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1405 ] loss: 0.443 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1406 ] loss: 0.443 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1407 ] loss: 0.443 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1408 ] loss: 0.442 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1409 ] loss: 0.442 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1410 ] loss: 0.442 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1411 ] loss: 0.442 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1412 ] loss: 0.442 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1413 ] loss: 0.441 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1414 ] loss: 0.441 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1415 ] loss: 0.441 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1416 ] loss: 0.441 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1417 ] loss: 0.441 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1418 ] loss: 0.441 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1419 ] loss: 0.440 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1420 ] loss: 0.440 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1421 ] loss: 0.440 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1422 ] loss: 0.440 correct: 2829.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1423 ] loss: 0.440 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1424 ] loss: 0.439 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1425 ] loss: 0.439 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1426 ] loss: 0.439 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1427 ] loss: 0.439 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1428 ] loss: 0.439 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1429 ] loss: 0.438 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1430 ] loss: 0.438 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1431 ] loss: 0.438 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1432 ] loss: 0.438 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1433 ] loss: 0.438 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1434 ] loss: 0.438 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1435 ] loss: 0.437 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1436 ] loss: 0.437 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1437 ] loss: 0.437 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1438 ] loss: 0.437 correct: 2828.000, total: 3000.000, accuracy: 0.943\n",
            "training epoch: [1439 ] loss: 0.437 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1440 ] loss: 0.437 correct: 2827.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1441 ] loss: 0.436 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1442 ] loss: 0.436 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1443 ] loss: 0.436 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1444 ] loss: 0.436 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1445 ] loss: 0.436 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1446 ] loss: 0.435 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1447 ] loss: 0.435 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1448 ] loss: 0.435 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1449 ] loss: 0.435 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1450 ] loss: 0.435 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1451 ] loss: 0.434 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1452 ] loss: 0.434 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1453 ] loss: 0.434 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1454 ] loss: 0.434 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1455 ] loss: 0.434 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1456 ] loss: 0.434 correct: 2826.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1457 ] loss: 0.433 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1458 ] loss: 0.433 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1459 ] loss: 0.433 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1460 ] loss: 0.433 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1461 ] loss: 0.433 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1462 ] loss: 0.432 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1463 ] loss: 0.432 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1464 ] loss: 0.432 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1465 ] loss: 0.432 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1466 ] loss: 0.432 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1467 ] loss: 0.432 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1468 ] loss: 0.431 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1469 ] loss: 0.431 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1470 ] loss: 0.431 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1471 ] loss: 0.431 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1472 ] loss: 0.431 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1473 ] loss: 0.430 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1474 ] loss: 0.430 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1475 ] loss: 0.430 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1476 ] loss: 0.430 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1477 ] loss: 0.430 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1478 ] loss: 0.430 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1479 ] loss: 0.429 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1480 ] loss: 0.429 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1481 ] loss: 0.429 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1482 ] loss: 0.429 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1483 ] loss: 0.429 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1484 ] loss: 0.429 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1485 ] loss: 0.428 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1486 ] loss: 0.428 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1487 ] loss: 0.428 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1488 ] loss: 0.428 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1489 ] loss: 0.427 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1490 ] loss: 0.427 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1491 ] loss: 0.427 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1492 ] loss: 0.427 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1493 ] loss: 0.427 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1494 ] loss: 0.427 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1495 ] loss: 0.426 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1496 ] loss: 0.426 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1497 ] loss: 0.426 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1498 ] loss: 0.426 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1499 ] loss: 0.426 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1500 ] loss: 0.426 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1501 ] loss: 0.425 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1502 ] loss: 0.425 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1503 ] loss: 0.425 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1504 ] loss: 0.425 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1505 ] loss: 0.425 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1506 ] loss: 0.425 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1507 ] loss: 0.424 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1508 ] loss: 0.424 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1509 ] loss: 0.424 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1510 ] loss: 0.424 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1511 ] loss: 0.423 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1512 ] loss: 0.423 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1513 ] loss: 0.423 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1514 ] loss: 0.423 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1515 ] loss: 0.423 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1516 ] loss: 0.423 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1517 ] loss: 0.422 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1518 ] loss: 0.422 correct: 2825.000, total: 3000.000, accuracy: 0.942\n",
            "training epoch: [1519 ] loss: 0.422 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1520 ] loss: 0.422 correct: 2824.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1521 ] loss: 0.422 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1522 ] loss: 0.422 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1523 ] loss: 0.421 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1524 ] loss: 0.421 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1525 ] loss: 0.421 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1526 ] loss: 0.421 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1527 ] loss: 0.421 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1528 ] loss: 0.421 correct: 2823.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1529 ] loss: 0.420 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1530 ] loss: 0.420 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1531 ] loss: 0.420 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1532 ] loss: 0.420 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1533 ] loss: 0.419 correct: 2820.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1534 ] loss: 0.419 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1535 ] loss: 0.419 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1536 ] loss: 0.419 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1537 ] loss: 0.419 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1538 ] loss: 0.419 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1539 ] loss: 0.418 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1540 ] loss: 0.418 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1541 ] loss: 0.418 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1542 ] loss: 0.418 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1543 ] loss: 0.418 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1544 ] loss: 0.418 correct: 2822.000, total: 3000.000, accuracy: 0.941\n",
            "training epoch: [1545 ] loss: 0.417 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1546 ] loss: 0.417 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1547 ] loss: 0.417 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1548 ] loss: 0.417 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1549 ] loss: 0.417 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1550 ] loss: 0.417 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1551 ] loss: 0.416 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1552 ] loss: 0.416 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1553 ] loss: 0.416 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1554 ] loss: 0.416 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1555 ] loss: 0.415 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1556 ] loss: 0.415 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1557 ] loss: 0.415 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1558 ] loss: 0.415 correct: 2821.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1559 ] loss: 0.415 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1560 ] loss: 0.415 correct: 2820.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1561 ] loss: 0.414 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1562 ] loss: 0.414 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1563 ] loss: 0.414 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1564 ] loss: 0.414 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1565 ] loss: 0.414 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1566 ] loss: 0.414 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1567 ] loss: 0.413 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1568 ] loss: 0.413 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1569 ] loss: 0.413 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1570 ] loss: 0.413 correct: 2819.000, total: 3000.000, accuracy: 0.940\n",
            "training epoch: [1571 ] loss: 0.413 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1572 ] loss: 0.413 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1573 ] loss: 0.412 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1574 ] loss: 0.412 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1575 ] loss: 0.412 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1576 ] loss: 0.412 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1577 ] loss: 0.412 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1578 ] loss: 0.411 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1579 ] loss: 0.411 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1580 ] loss: 0.411 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1581 ] loss: 0.411 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1582 ] loss: 0.411 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1583 ] loss: 0.410 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1584 ] loss: 0.410 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1585 ] loss: 0.410 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1586 ] loss: 0.410 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1587 ] loss: 0.410 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1588 ] loss: 0.410 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1589 ] loss: 0.409 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1590 ] loss: 0.409 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1591 ] loss: 0.409 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1592 ] loss: 0.409 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1593 ] loss: 0.409 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1594 ] loss: 0.409 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1595 ] loss: 0.408 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1596 ] loss: 0.408 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1597 ] loss: 0.408 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1598 ] loss: 0.408 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1599 ] loss: 0.408 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1600 ] loss: 0.408 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1601 ] loss: 0.407 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1602 ] loss: 0.407 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1603 ] loss: 0.407 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1604 ] loss: 0.407 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1605 ] loss: 0.406 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1606 ] loss: 0.406 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1607 ] loss: 0.406 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1608 ] loss: 0.406 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1609 ] loss: 0.406 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1610 ] loss: 0.406 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1611 ] loss: 0.405 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1612 ] loss: 0.405 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1613 ] loss: 0.405 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1614 ] loss: 0.405 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1615 ] loss: 0.405 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1616 ] loss: 0.405 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1617 ] loss: 0.404 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1618 ] loss: 0.404 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1619 ] loss: 0.404 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1620 ] loss: 0.404 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1621 ] loss: 0.404 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1622 ] loss: 0.404 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1623 ] loss: 0.403 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1624 ] loss: 0.403 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1625 ] loss: 0.403 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1626 ] loss: 0.403 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1627 ] loss: 0.403 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1628 ] loss: 0.403 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1629 ] loss: 0.402 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1630 ] loss: 0.402 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1631 ] loss: 0.402 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1632 ] loss: 0.402 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1633 ] loss: 0.402 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1634 ] loss: 0.402 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1635 ] loss: 0.401 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1636 ] loss: 0.401 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1637 ] loss: 0.401 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1638 ] loss: 0.401 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1639 ] loss: 0.400 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1640 ] loss: 0.400 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1641 ] loss: 0.400 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1642 ] loss: 0.400 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1643 ] loss: 0.400 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1644 ] loss: 0.400 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1645 ] loss: 0.399 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1646 ] loss: 0.399 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1647 ] loss: 0.399 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1648 ] loss: 0.399 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1649 ] loss: 0.399 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1650 ] loss: 0.399 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1651 ] loss: 0.398 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1652 ] loss: 0.398 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1653 ] loss: 0.398 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1654 ] loss: 0.398 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1655 ] loss: 0.398 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1656 ] loss: 0.398 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1657 ] loss: 0.397 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1658 ] loss: 0.397 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1659 ] loss: 0.397 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1660 ] loss: 0.397 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1661 ] loss: 0.397 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1662 ] loss: 0.397 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1663 ] loss: 0.396 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1664 ] loss: 0.396 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1665 ] loss: 0.396 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1666 ] loss: 0.396 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1667 ] loss: 0.396 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1668 ] loss: 0.396 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1669 ] loss: 0.395 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1670 ] loss: 0.395 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1671 ] loss: 0.395 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1672 ] loss: 0.395 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1673 ] loss: 0.395 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1674 ] loss: 0.395 correct: 2818.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1675 ] loss: 0.394 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1676 ] loss: 0.394 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1677 ] loss: 0.394 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1678 ] loss: 0.394 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1679 ] loss: 0.393 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1680 ] loss: 0.393 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1681 ] loss: 0.393 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1682 ] loss: 0.393 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1683 ] loss: 0.393 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1684 ] loss: 0.393 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1685 ] loss: 0.392 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1686 ] loss: 0.392 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1687 ] loss: 0.392 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1688 ] loss: 0.392 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1689 ] loss: 0.392 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1690 ] loss: 0.392 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1691 ] loss: 0.391 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1692 ] loss: 0.391 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1693 ] loss: 0.391 correct: 2817.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1694 ] loss: 0.391 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1695 ] loss: 0.391 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1696 ] loss: 0.391 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1697 ] loss: 0.390 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1698 ] loss: 0.390 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1699 ] loss: 0.390 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1700 ] loss: 0.390 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1701 ] loss: 0.390 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1702 ] loss: 0.390 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1703 ] loss: 0.389 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1704 ] loss: 0.389 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1705 ] loss: 0.389 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1706 ] loss: 0.389 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1707 ] loss: 0.389 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1708 ] loss: 0.389 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1709 ] loss: 0.388 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1710 ] loss: 0.388 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1711 ] loss: 0.388 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1712 ] loss: 0.388 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1713 ] loss: 0.388 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1714 ] loss: 0.388 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1715 ] loss: 0.387 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1716 ] loss: 0.387 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1717 ] loss: 0.387 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1718 ] loss: 0.387 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1719 ] loss: 0.387 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1720 ] loss: 0.387 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1721 ] loss: 0.386 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1722 ] loss: 0.386 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1723 ] loss: 0.386 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1724 ] loss: 0.386 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1725 ] loss: 0.386 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1726 ] loss: 0.386 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1727 ] loss: 0.385 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1728 ] loss: 0.385 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1729 ] loss: 0.385 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1730 ] loss: 0.385 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1731 ] loss: 0.385 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1732 ] loss: 0.385 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1733 ] loss: 0.384 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1734 ] loss: 0.384 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1735 ] loss: 0.384 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1736 ] loss: 0.384 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1737 ] loss: 0.384 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1738 ] loss: 0.384 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1739 ] loss: 0.383 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1740 ] loss: 0.383 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1741 ] loss: 0.383 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1742 ] loss: 0.383 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1743 ] loss: 0.383 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1744 ] loss: 0.383 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1745 ] loss: 0.382 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1746 ] loss: 0.382 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1747 ] loss: 0.382 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1748 ] loss: 0.382 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1749 ] loss: 0.382 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1750 ] loss: 0.382 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1751 ] loss: 0.381 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1752 ] loss: 0.381 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1753 ] loss: 0.381 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1754 ] loss: 0.381 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1755 ] loss: 0.381 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1756 ] loss: 0.381 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1757 ] loss: 0.380 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1758 ] loss: 0.380 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1759 ] loss: 0.380 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1760 ] loss: 0.380 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1761 ] loss: 0.380 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1762 ] loss: 0.380 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1763 ] loss: 0.379 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1764 ] loss: 0.379 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1765 ] loss: 0.379 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1766 ] loss: 0.379 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1767 ] loss: 0.379 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1768 ] loss: 0.379 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1769 ] loss: 0.378 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1770 ] loss: 0.378 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1771 ] loss: 0.378 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1772 ] loss: 0.378 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1773 ] loss: 0.378 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1774 ] loss: 0.378 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1775 ] loss: 0.377 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1776 ] loss: 0.377 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1777 ] loss: 0.377 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1778 ] loss: 0.377 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1779 ] loss: 0.377 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1780 ] loss: 0.377 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1781 ] loss: 0.376 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1782 ] loss: 0.376 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1783 ] loss: 0.376 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1784 ] loss: 0.376 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1785 ] loss: 0.376 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1786 ] loss: 0.376 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1787 ] loss: 0.375 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1788 ] loss: 0.375 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1789 ] loss: 0.375 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1790 ] loss: 0.375 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1791 ] loss: 0.375 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1792 ] loss: 0.375 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1793 ] loss: 0.374 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1794 ] loss: 0.374 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1795 ] loss: 0.374 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1796 ] loss: 0.374 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1797 ] loss: 0.374 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1798 ] loss: 0.374 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1799 ] loss: 0.373 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1800 ] loss: 0.373 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1801 ] loss: 0.373 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1802 ] loss: 0.373 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1803 ] loss: 0.373 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1804 ] loss: 0.373 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1805 ] loss: 0.372 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1806 ] loss: 0.372 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1807 ] loss: 0.372 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1808 ] loss: 0.372 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1809 ] loss: 0.372 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1810 ] loss: 0.372 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1811 ] loss: 0.371 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1812 ] loss: 0.371 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1813 ] loss: 0.371 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1814 ] loss: 0.371 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1815 ] loss: 0.371 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1816 ] loss: 0.371 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1817 ] loss: 0.370 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1818 ] loss: 0.370 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1819 ] loss: 0.370 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1820 ] loss: 0.370 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1821 ] loss: 0.370 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1822 ] loss: 0.370 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1823 ] loss: 0.369 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1824 ] loss: 0.369 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1825 ] loss: 0.369 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1826 ] loss: 0.369 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1827 ] loss: 0.369 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1828 ] loss: 0.369 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1829 ] loss: 0.368 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1830 ] loss: 0.368 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1831 ] loss: 0.368 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1832 ] loss: 0.368 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1833 ] loss: 0.368 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1834 ] loss: 0.368 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1835 ] loss: 0.367 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1836 ] loss: 0.368 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1837 ] loss: 0.367 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1838 ] loss: 0.367 correct: 2816.000, total: 3000.000, accuracy: 0.939\n",
            "training epoch: [1839 ] loss: 0.367 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1840 ] loss: 0.367 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1841 ] loss: 0.367 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1842 ] loss: 0.367 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1843 ] loss: 0.366 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1844 ] loss: 0.366 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1845 ] loss: 0.366 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1846 ] loss: 0.366 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1847 ] loss: 0.366 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1848 ] loss: 0.366 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1849 ] loss: 0.365 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1850 ] loss: 0.365 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1851 ] loss: 0.365 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1852 ] loss: 0.365 correct: 2815.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1853 ] loss: 0.365 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1854 ] loss: 0.365 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1855 ] loss: 0.364 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1856 ] loss: 0.364 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1857 ] loss: 0.364 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1858 ] loss: 0.364 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1859 ] loss: 0.364 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1860 ] loss: 0.364 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1861 ] loss: 0.363 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1862 ] loss: 0.363 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1863 ] loss: 0.363 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1864 ] loss: 0.363 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1865 ] loss: 0.363 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1866 ] loss: 0.363 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1867 ] loss: 0.362 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1868 ] loss: 0.363 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1869 ] loss: 0.362 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1870 ] loss: 0.362 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1871 ] loss: 0.362 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1872 ] loss: 0.362 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1873 ] loss: 0.362 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1874 ] loss: 0.362 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1875 ] loss: 0.361 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1876 ] loss: 0.361 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1877 ] loss: 0.361 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1878 ] loss: 0.361 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1879 ] loss: 0.361 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1880 ] loss: 0.361 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1881 ] loss: 0.360 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1882 ] loss: 0.360 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1883 ] loss: 0.360 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1884 ] loss: 0.360 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1885 ] loss: 0.360 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1886 ] loss: 0.360 correct: 2814.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1887 ] loss: 0.359 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1888 ] loss: 0.359 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1889 ] loss: 0.359 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1890 ] loss: 0.359 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1891 ] loss: 0.359 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1892 ] loss: 0.359 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1893 ] loss: 0.358 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1894 ] loss: 0.359 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1895 ] loss: 0.358 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1896 ] loss: 0.358 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1897 ] loss: 0.358 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1898 ] loss: 0.358 correct: 2813.000, total: 3000.000, accuracy: 0.938\n",
            "training epoch: [1899 ] loss: 0.358 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1900 ] loss: 0.358 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1901 ] loss: 0.357 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1902 ] loss: 0.357 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1903 ] loss: 0.357 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1904 ] loss: 0.357 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1905 ] loss: 0.357 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1906 ] loss: 0.357 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1907 ] loss: 0.356 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1908 ] loss: 0.356 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1909 ] loss: 0.356 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1910 ] loss: 0.356 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1911 ] loss: 0.356 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1912 ] loss: 0.356 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1913 ] loss: 0.355 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1914 ] loss: 0.355 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1915 ] loss: 0.355 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1916 ] loss: 0.355 correct: 2812.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1917 ] loss: 0.355 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1918 ] loss: 0.355 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [1919 ] loss: 0.355 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1920 ] loss: 0.355 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1921 ] loss: 0.354 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1922 ] loss: 0.354 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1923 ] loss: 0.354 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1924 ] loss: 0.354 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1925 ] loss: 0.354 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1926 ] loss: 0.354 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1927 ] loss: 0.354 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1928 ] loss: 0.354 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1929 ] loss: 0.353 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1930 ] loss: 0.353 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1931 ] loss: 0.353 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1932 ] loss: 0.353 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1933 ] loss: 0.353 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1934 ] loss: 0.353 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1935 ] loss: 0.352 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1936 ] loss: 0.352 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1937 ] loss: 0.352 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1938 ] loss: 0.352 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1939 ] loss: 0.352 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1940 ] loss: 0.352 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1941 ] loss: 0.352 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1942 ] loss: 0.352 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1943 ] loss: 0.351 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1944 ] loss: 0.351 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1945 ] loss: 0.351 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1946 ] loss: 0.351 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1947 ] loss: 0.351 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1948 ] loss: 0.351 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1949 ] loss: 0.350 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1950 ] loss: 0.350 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1951 ] loss: 0.350 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1952 ] loss: 0.350 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1953 ] loss: 0.350 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1954 ] loss: 0.350 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1955 ] loss: 0.350 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1956 ] loss: 0.350 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1957 ] loss: 0.349 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1958 ] loss: 0.349 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1959 ] loss: 0.349 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1960 ] loss: 0.349 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1961 ] loss: 0.349 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1962 ] loss: 0.349 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1963 ] loss: 0.348 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1964 ] loss: 0.348 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1965 ] loss: 0.348 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1966 ] loss: 0.348 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1967 ] loss: 0.348 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1968 ] loss: 0.348 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1969 ] loss: 0.348 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1970 ] loss: 0.348 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1971 ] loss: 0.347 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1972 ] loss: 0.347 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1973 ] loss: 0.347 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1974 ] loss: 0.347 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1975 ] loss: 0.347 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1976 ] loss: 0.347 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1977 ] loss: 0.346 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1978 ] loss: 0.346 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1979 ] loss: 0.346 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1980 ] loss: 0.346 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1981 ] loss: 0.346 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1982 ] loss: 0.346 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1983 ] loss: 0.345 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1984 ] loss: 0.346 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1985 ] loss: 0.345 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1986 ] loss: 0.345 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1987 ] loss: 0.345 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1988 ] loss: 0.345 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1989 ] loss: 0.345 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1990 ] loss: 0.345 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1991 ] loss: 0.344 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1992 ] loss: 0.344 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1993 ] loss: 0.344 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1994 ] loss: 0.344 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1995 ] loss: 0.344 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1996 ] loss: 0.344 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1997 ] loss: 0.344 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1998 ] loss: 0.344 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [1999 ] loss: 0.343 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2000 ] loss: 0.343 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2001 ] loss: 0.343 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2002 ] loss: 0.343 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2003 ] loss: 0.343 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2004 ] loss: 0.343 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2005 ] loss: 0.342 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2006 ] loss: 0.342 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2007 ] loss: 0.342 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2008 ] loss: 0.342 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2009 ] loss: 0.342 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2010 ] loss: 0.342 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2011 ] loss: 0.342 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2012 ] loss: 0.342 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2013 ] loss: 0.341 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2014 ] loss: 0.341 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2015 ] loss: 0.341 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2016 ] loss: 0.341 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2017 ] loss: 0.341 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2018 ] loss: 0.341 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2019 ] loss: 0.340 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2020 ] loss: 0.341 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2021 ] loss: 0.340 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2022 ] loss: 0.340 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2023 ] loss: 0.340 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2024 ] loss: 0.340 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2025 ] loss: 0.340 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2026 ] loss: 0.340 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2027 ] loss: 0.339 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2028 ] loss: 0.339 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2029 ] loss: 0.339 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2030 ] loss: 0.339 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2031 ] loss: 0.339 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2032 ] loss: 0.339 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2033 ] loss: 0.339 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2034 ] loss: 0.339 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2035 ] loss: 0.338 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2036 ] loss: 0.338 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2037 ] loss: 0.338 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2038 ] loss: 0.338 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2039 ] loss: 0.338 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2040 ] loss: 0.338 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2041 ] loss: 0.337 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2042 ] loss: 0.338 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2043 ] loss: 0.337 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2044 ] loss: 0.337 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2045 ] loss: 0.337 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2046 ] loss: 0.337 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2047 ] loss: 0.337 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2048 ] loss: 0.337 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2049 ] loss: 0.336 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2050 ] loss: 0.336 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2051 ] loss: 0.336 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2052 ] loss: 0.336 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2053 ] loss: 0.336 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2054 ] loss: 0.336 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2055 ] loss: 0.336 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2056 ] loss: 0.336 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2057 ] loss: 0.335 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2058 ] loss: 0.335 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2059 ] loss: 0.335 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2060 ] loss: 0.335 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2061 ] loss: 0.335 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2062 ] loss: 0.335 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2063 ] loss: 0.334 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2064 ] loss: 0.335 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2065 ] loss: 0.334 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2066 ] loss: 0.334 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2067 ] loss: 0.334 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2068 ] loss: 0.334 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2069 ] loss: 0.334 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2070 ] loss: 0.334 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2071 ] loss: 0.333 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2072 ] loss: 0.333 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2073 ] loss: 0.333 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2074 ] loss: 0.333 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2075 ] loss: 0.333 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2076 ] loss: 0.333 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2077 ] loss: 0.333 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2078 ] loss: 0.333 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2079 ] loss: 0.332 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2080 ] loss: 0.332 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2081 ] loss: 0.332 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2082 ] loss: 0.332 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2083 ] loss: 0.332 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2084 ] loss: 0.332 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2085 ] loss: 0.332 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2086 ] loss: 0.332 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2087 ] loss: 0.331 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2088 ] loss: 0.331 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2089 ] loss: 0.331 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2090 ] loss: 0.331 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2091 ] loss: 0.331 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2092 ] loss: 0.331 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2093 ] loss: 0.331 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2094 ] loss: 0.331 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2095 ] loss: 0.330 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2096 ] loss: 0.330 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2097 ] loss: 0.330 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2098 ] loss: 0.330 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2099 ] loss: 0.330 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2100 ] loss: 0.330 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2101 ] loss: 0.330 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2102 ] loss: 0.330 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2103 ] loss: 0.329 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2104 ] loss: 0.329 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2105 ] loss: 0.329 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2106 ] loss: 0.329 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2107 ] loss: 0.329 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2108 ] loss: 0.329 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2109 ] loss: 0.328 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2110 ] loss: 0.329 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2111 ] loss: 0.328 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2112 ] loss: 0.328 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2113 ] loss: 0.328 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2114 ] loss: 0.328 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2115 ] loss: 0.328 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2116 ] loss: 0.328 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2117 ] loss: 0.327 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2118 ] loss: 0.328 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2119 ] loss: 0.327 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2120 ] loss: 0.327 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2121 ] loss: 0.327 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2122 ] loss: 0.327 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2123 ] loss: 0.327 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2124 ] loss: 0.327 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2125 ] loss: 0.326 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2126 ] loss: 0.327 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2127 ] loss: 0.326 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2128 ] loss: 0.326 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2129 ] loss: 0.326 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2130 ] loss: 0.326 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2131 ] loss: 0.326 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2132 ] loss: 0.326 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2133 ] loss: 0.325 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2134 ] loss: 0.326 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2135 ] loss: 0.325 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2136 ] loss: 0.325 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2137 ] loss: 0.325 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2138 ] loss: 0.325 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2139 ] loss: 0.325 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2140 ] loss: 0.325 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2141 ] loss: 0.324 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2142 ] loss: 0.325 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2143 ] loss: 0.324 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2144 ] loss: 0.324 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2145 ] loss: 0.324 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2146 ] loss: 0.324 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2147 ] loss: 0.324 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2148 ] loss: 0.324 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2149 ] loss: 0.323 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2150 ] loss: 0.324 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2151 ] loss: 0.323 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2152 ] loss: 0.323 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2153 ] loss: 0.323 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2154 ] loss: 0.323 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2155 ] loss: 0.323 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2156 ] loss: 0.323 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2157 ] loss: 0.322 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2158 ] loss: 0.323 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2159 ] loss: 0.322 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2160 ] loss: 0.322 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2161 ] loss: 0.322 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2162 ] loss: 0.322 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2163 ] loss: 0.322 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2164 ] loss: 0.322 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2165 ] loss: 0.321 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2166 ] loss: 0.322 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2167 ] loss: 0.321 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2168 ] loss: 0.321 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2169 ] loss: 0.321 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2170 ] loss: 0.321 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2171 ] loss: 0.321 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2172 ] loss: 0.321 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2173 ] loss: 0.321 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2174 ] loss: 0.321 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2175 ] loss: 0.320 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2176 ] loss: 0.320 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2177 ] loss: 0.320 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2178 ] loss: 0.320 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2179 ] loss: 0.320 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2180 ] loss: 0.320 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2181 ] loss: 0.320 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2182 ] loss: 0.320 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2183 ] loss: 0.319 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2184 ] loss: 0.319 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2185 ] loss: 0.319 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2186 ] loss: 0.319 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2187 ] loss: 0.319 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2188 ] loss: 0.319 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2189 ] loss: 0.319 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2190 ] loss: 0.319 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2191 ] loss: 0.318 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2192 ] loss: 0.318 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2193 ] loss: 0.318 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2194 ] loss: 0.318 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2195 ] loss: 0.318 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2196 ] loss: 0.318 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2197 ] loss: 0.318 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2198 ] loss: 0.318 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2199 ] loss: 0.317 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2200 ] loss: 0.318 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2201 ] loss: 0.317 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2202 ] loss: 0.317 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2203 ] loss: 0.317 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2204 ] loss: 0.317 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2205 ] loss: 0.317 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2206 ] loss: 0.317 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2207 ] loss: 0.316 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2208 ] loss: 0.317 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2209 ] loss: 0.316 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2210 ] loss: 0.316 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2211 ] loss: 0.316 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2212 ] loss: 0.316 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2213 ] loss: 0.316 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2214 ] loss: 0.316 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2215 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2216 ] loss: 0.316 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2217 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2218 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2219 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2220 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2221 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2222 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2223 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2224 ] loss: 0.315 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2225 ] loss: 0.314 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2226 ] loss: 0.314 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2227 ] loss: 0.314 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2228 ] loss: 0.314 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2229 ] loss: 0.314 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2230 ] loss: 0.314 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2231 ] loss: 0.314 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2232 ] loss: 0.314 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2233 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2234 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2235 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2236 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2237 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2238 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2239 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2240 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2241 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2242 ] loss: 0.313 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2243 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2244 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2245 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2246 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2247 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2248 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2249 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2250 ] loss: 0.312 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2251 ] loss: 0.311 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2252 ] loss: 0.311 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2253 ] loss: 0.311 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2254 ] loss: 0.311 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2255 ] loss: 0.311 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2256 ] loss: 0.311 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2257 ] loss: 0.311 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2258 ] loss: 0.311 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2259 ] loss: 0.310 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2260 ] loss: 0.311 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2261 ] loss: 0.310 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2262 ] loss: 0.310 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2263 ] loss: 0.310 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2264 ] loss: 0.310 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2265 ] loss: 0.310 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2266 ] loss: 0.310 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2267 ] loss: 0.310 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2268 ] loss: 0.310 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2269 ] loss: 0.309 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2270 ] loss: 0.310 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2271 ] loss: 0.309 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2272 ] loss: 0.309 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2273 ] loss: 0.309 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2274 ] loss: 0.309 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2275 ] loss: 0.309 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2276 ] loss: 0.309 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2277 ] loss: 0.309 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2278 ] loss: 0.309 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2279 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2280 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2281 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2282 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2283 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2284 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2285 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2286 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2287 ] loss: 0.307 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2288 ] loss: 0.308 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2289 ] loss: 0.307 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2290 ] loss: 0.307 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2291 ] loss: 0.307 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2292 ] loss: 0.307 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2293 ] loss: 0.307 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2294 ] loss: 0.307 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2295 ] loss: 0.307 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2296 ] loss: 0.307 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2297 ] loss: 0.306 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2298 ] loss: 0.307 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2299 ] loss: 0.306 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2300 ] loss: 0.306 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2301 ] loss: 0.306 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2302 ] loss: 0.306 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2303 ] loss: 0.306 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2304 ] loss: 0.306 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2305 ] loss: 0.306 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2306 ] loss: 0.306 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2307 ] loss: 0.305 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2308 ] loss: 0.305 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2309 ] loss: 0.305 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2310 ] loss: 0.305 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2311 ] loss: 0.305 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2312 ] loss: 0.305 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2313 ] loss: 0.305 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2314 ] loss: 0.305 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2315 ] loss: 0.305 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2316 ] loss: 0.305 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2317 ] loss: 0.304 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2318 ] loss: 0.304 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2319 ] loss: 0.304 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2320 ] loss: 0.304 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2321 ] loss: 0.304 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2322 ] loss: 0.304 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2323 ] loss: 0.304 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2324 ] loss: 0.304 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2325 ] loss: 0.303 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2326 ] loss: 0.304 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2327 ] loss: 0.303 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2328 ] loss: 0.303 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2329 ] loss: 0.303 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2330 ] loss: 0.303 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2331 ] loss: 0.303 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2332 ] loss: 0.303 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2333 ] loss: 0.303 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2334 ] loss: 0.303 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2335 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2336 ] loss: 0.303 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2337 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2338 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2339 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2340 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2341 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2342 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2343 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2344 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2345 ] loss: 0.301 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2346 ] loss: 0.302 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2347 ] loss: 0.301 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2348 ] loss: 0.301 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2349 ] loss: 0.301 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2350 ] loss: 0.301 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2351 ] loss: 0.301 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2352 ] loss: 0.301 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2353 ] loss: 0.301 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2354 ] loss: 0.301 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2355 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2356 ] loss: 0.301 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2357 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2358 ] loss: 0.300 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2359 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2360 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2361 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2362 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2363 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2364 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2365 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2366 ] loss: 0.300 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2367 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2368 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2369 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2370 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2371 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2372 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2373 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2374 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2375 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2376 ] loss: 0.299 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2377 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2378 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2379 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2380 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2381 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2382 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2383 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2384 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2385 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2386 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2387 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2388 ] loss: 0.298 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2389 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2390 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2391 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2392 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2393 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2394 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2395 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2396 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2397 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2398 ] loss: 0.297 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2399 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2400 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2401 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2402 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2403 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2404 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2405 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2406 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2407 ] loss: 0.295 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2408 ] loss: 0.296 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2409 ] loss: 0.295 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2410 ] loss: 0.295 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2411 ] loss: 0.295 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2412 ] loss: 0.295 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2413 ] loss: 0.295 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2414 ] loss: 0.295 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2415 ] loss: 0.295 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2416 ] loss: 0.295 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2417 ] loss: 0.294 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2418 ] loss: 0.295 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2419 ] loss: 0.294 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2420 ] loss: 0.294 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2421 ] loss: 0.294 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2422 ] loss: 0.294 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2423 ] loss: 0.294 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2424 ] loss: 0.294 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2425 ] loss: 0.294 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2426 ] loss: 0.294 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2427 ] loss: 0.293 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2428 ] loss: 0.294 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2429 ] loss: 0.293 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2430 ] loss: 0.293 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2431 ] loss: 0.293 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2432 ] loss: 0.293 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2433 ] loss: 0.293 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2434 ] loss: 0.293 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2435 ] loss: 0.293 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2436 ] loss: 0.293 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2437 ] loss: 0.293 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2438 ] loss: 0.293 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2439 ] loss: 0.292 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2440 ] loss: 0.293 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2441 ] loss: 0.292 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2442 ] loss: 0.292 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2443 ] loss: 0.292 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2444 ] loss: 0.292 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2445 ] loss: 0.292 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2446 ] loss: 0.292 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2447 ] loss: 0.292 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2448 ] loss: 0.292 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2449 ] loss: 0.292 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2450 ] loss: 0.292 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2451 ] loss: 0.291 correct: 2811.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2452 ] loss: 0.291 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2453 ] loss: 0.291 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2454 ] loss: 0.291 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2455 ] loss: 0.291 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2456 ] loss: 0.291 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2457 ] loss: 0.291 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2458 ] loss: 0.291 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2459 ] loss: 0.291 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2460 ] loss: 0.291 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2461 ] loss: 0.290 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2462 ] loss: 0.291 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2463 ] loss: 0.290 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2464 ] loss: 0.290 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2465 ] loss: 0.290 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2466 ] loss: 0.290 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2467 ] loss: 0.290 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2468 ] loss: 0.290 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2469 ] loss: 0.290 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2470 ] loss: 0.290 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2471 ] loss: 0.290 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2472 ] loss: 0.290 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2473 ] loss: 0.289 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2474 ] loss: 0.290 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2475 ] loss: 0.289 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2476 ] loss: 0.289 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2477 ] loss: 0.289 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2478 ] loss: 0.289 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2479 ] loss: 0.289 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2480 ] loss: 0.289 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2481 ] loss: 0.289 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2482 ] loss: 0.289 correct: 2808.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2483 ] loss: 0.289 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2484 ] loss: 0.289 correct: 2807.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2485 ] loss: 0.288 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2486 ] loss: 0.289 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2487 ] loss: 0.288 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2488 ] loss: 0.288 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2489 ] loss: 0.288 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2490 ] loss: 0.288 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2491 ] loss: 0.288 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2492 ] loss: 0.288 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2493 ] loss: 0.288 correct: 2810.000, total: 3000.000, accuracy: 0.937\n",
            "training epoch: [2494 ] loss: 0.288 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2495 ] loss: 0.287 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2496 ] loss: 0.288 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2497 ] loss: 0.287 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2498 ] loss: 0.287 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "training epoch: [2499 ] loss: 0.287 correct: 2809.000, total: 3000.000, accuracy: 0.936\n",
            "training epoch: [2500 ] loss: 0.287 correct: 2806.000, total: 3000.000, accuracy: 0.935\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]/30+\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]/30\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]/30\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]/30\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]/30\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]/30"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoQpS_6scRsC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "71a753dc-dca4-4549-b96c-df533435d52c"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>90.200000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>28.566667</td>\n",
              "      <td>7.966667</td>\n",
              "      <td>59.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>90.200000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>28.500000</td>\n",
              "      <td>7.966667</td>\n",
              "      <td>59.733333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>90.200000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>28.800000</td>\n",
              "      <td>8.066667</td>\n",
              "      <td>59.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>9.666667</td>\n",
              "      <td>90.333333</td>\n",
              "      <td>3.566667</td>\n",
              "      <td>28.833333</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>59.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9.633333</td>\n",
              "      <td>90.366667</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>28.833333</td>\n",
              "      <td>8.066667</td>\n",
              "      <td>59.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>2496</td>\n",
              "      <td>98.066667</td>\n",
              "      <td>1.933333</td>\n",
              "      <td>84.833333</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>5.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>2497</td>\n",
              "      <td>98.033333</td>\n",
              "      <td>1.966667</td>\n",
              "      <td>84.933333</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>2498</td>\n",
              "      <td>98.066667</td>\n",
              "      <td>1.933333</td>\n",
              "      <td>84.833333</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>5.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>2499</td>\n",
              "      <td>98.033333</td>\n",
              "      <td>1.966667</td>\n",
              "      <td>84.933333</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>2500</td>\n",
              "      <td>98.066667</td>\n",
              "      <td>1.933333</td>\n",
              "      <td>84.833333</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>5.533333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2501 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0          0      9.800000  ...               7.966667               59.666667\n",
              "1          1      9.800000  ...               7.966667               59.733333\n",
              "2          2      9.800000  ...               8.066667               59.533333\n",
              "3          3      9.666667  ...               8.100000               59.500000\n",
              "4          4      9.633333  ...               8.066667               59.600000\n",
              "...      ...           ...  ...                    ...                     ...\n",
              "2496    2496     98.066667  ...               0.933333                5.533333\n",
              "2497    2497     98.033333  ...               0.866667                5.500000\n",
              "2498    2498     98.066667  ...               0.933333                5.533333\n",
              "2499    2499     98.033333  ...               0.866667                5.500000\n",
              "2500    2500     98.066667  ...               0.933333                5.533333\n",
              "\n",
              "[2501 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY_j8B274vuH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "dbd2604f-c05e-49ea-fb50-2e531d9f8f8a"
      },
      "source": [
        "%cd /content/\n",
        "plot_analysis(df_train,columns,[0,500,1000,1500,2000,2500])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in bg:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "# torch.save({\n",
        "#             'epoch': 500,\n",
        "#             'model_state_dict': what_net.state_dict(),\n",
        "#             #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "#             \"optimizer_alpha\":optim1,\n",
        "#             \"FTPT_analysis\":analysis_data_tr,\n",
        "#             \"alpha\":aph\n",
        "\n",
        "#             }, \"type4_what_net_500.pt\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVzrDOGS4UxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d887fc27-26e3-4443-b9e7-b40315ab8459"
      },
      "source": [
        "aph[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.3262834e-10, 7.1417326e-01, 2.2131849e-06, 2.7756560e-01,\n",
              "       5.3772784e-04, 2.9445667e-08, 7.7211624e-03, 8.5318919e-10,\n",
              "       1.6911276e-17], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ut6ZTAXbvqx"
      },
      "source": [
        "avrg = []\n",
        "avrg_lbls = []\n",
        "with torch.no_grad():\n",
        "  for i, data1 in  enumerate(train_loader):\n",
        "          inputs , labels , fore_idx = data1\n",
        "          inputs = inputs.double()\n",
        "          inputs = inputs.to(\"cuda\")\n",
        "          beta  = bg[i]\n",
        "          beta = beta.to(\"cuda\")\n",
        "          avg,alpha = attn_avg(inputs,beta)\n",
        "          \n",
        "          avrg.append(avg.detach().cpu().numpy())\n",
        "          avrg_lbls.append(labels.numpy())\n",
        "avrg= np.concatenate(avrg,axis=0)\n",
        "avrg_lbls = np.concatenate(avrg_lbls,axis=0)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KQFYlmTLG0N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "05658481-922d-4522-d009-93b8adc16fd2"
      },
      "source": [
        "%cd /content/drive/MyDrive/Neural_Tangent_Kernel/\n",
        "data = np.load(\"type_4_data.npy\",allow_pickle=True)\n",
        "%cd /content/\n",
        "plot_decision_boundary(what_net,[1,8,2,9],data,bg,avrg,avrg_lbls)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Neural_Tangent_Kernel\n",
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqS70WNvOcIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a8487ac1-13f7-4665-8173-2c9c3297dd38"
      },
      "source": [
        "plt.plot(loss_curi_tr)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5cbe7d4950>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GmyEWKD92_T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZQMzXXJa8lB"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6WUeyvNO3iP"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQRNesx7O3Xr"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLPSDVK_QWId"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw2rtHfzFyFA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3lfGywVHL6S"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}