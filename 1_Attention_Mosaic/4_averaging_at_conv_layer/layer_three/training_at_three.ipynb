{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R2j0wT2NxUG",
        "colab_type": "code",
        "outputId": "f65db0cb-0d54-4aed-8282-0e73775aed75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Models import Classification_Module2 as Classification_Module\n",
        "from Models import Focus_Module2 as Focus_Module\n",
        "from Mosaic import mosaic_data, MosaicDataset,split_foreground_background\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SblUamycPE7O",
        "colab_type": "code",
        "outputId": "2cf9d53f-d5e6-4029-eb50-8f317c1417e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsd9DNgUPMBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = split_foreground_background(trainloader,total = 50000)\n",
        "mosaic_list_of_images,mosaic_label,fore_idx = mosaic_data(data,desired_num=30000,total=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC1dUctdPgmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "train_dataset  = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "mosaic_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCm_yFatRxib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mimages_val,mlabel_val,fidx_val = mosaic_data(data,desired_num=10000,total=50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RccSHk3DU3jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 250\n",
        "test_dataset  = MosaicDataset(mimages_val,mlabel_val,fidx_val)\n",
        "test_loader = DataLoader( test_dataset,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di1vx00TVFgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net =  Focus_Module(3,1).double()\n",
        "focus_net = focus_net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0wsFjYFVPfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classification_net  = Classification_Module(20,3).double()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz6llbjujOm8",
        "colab_type": "code",
        "outputId": "6baec76c-832c-4846-8bad-521410182b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\n",
        "classification_net = classification_net.to(device)\n",
        "classification_net"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification_Module2(\n",
              "  (fc1): Linear(in_features=720, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=10, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emZvvTp0VbIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_focus = optim.SGD(focus_net.parameters(),lr = 0.01,momentum=0.9)\n",
        "optimizer_classification = optim.SGD(classification_net.parameters(),lr =0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cClaMnSRVfS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8iOl6JEVjJJ",
        "colab_type": "code",
        "outputId": "26aed1da-a89a-48e9-fc57-3bf0ea6f0403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tr_loss = []\n",
        "for epoch in range(110):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    cnt=0\n",
        "    iteration = 30000 // batch\n",
        "    ep_loss = []\n",
        "    for i, data in  enumerate(mosaic_loader):\n",
        "        inputs , labels , fgrnd_idx = data\n",
        "        inputs,labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "        optimizer_focus.zero_grad()\n",
        "        optimizer_classification.zero_grad()\n",
        "        avg_data , alphas = focus_net(inputs)\n",
        "        outputs = classification_net(avg_data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_focus.step()\n",
        "        optimizer_classification.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        mini = 40\n",
        "        if cnt % mini == mini-1:    # print every mini mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "            ep_loss.append(running_loss/mini)\n",
        "            running_loss = 0.0  \n",
        "        cnt=cnt+1\n",
        "    tr_loss.append(np.mean(ep_loss))      \n",
        "print('Finished Training')    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,    40] loss: 1.106\n",
            "[1,    80] loss: 1.099\n",
            "[1,   120] loss: 1.099\n",
            "[2,    40] loss: 1.099\n",
            "[2,    80] loss: 1.099\n",
            "[2,   120] loss: 1.099\n",
            "[3,    40] loss: 1.099\n",
            "[3,    80] loss: 1.099\n",
            "[3,   120] loss: 1.099\n",
            "[4,    40] loss: 1.099\n",
            "[4,    80] loss: 1.099\n",
            "[4,   120] loss: 1.099\n",
            "[5,    40] loss: 1.099\n",
            "[5,    80] loss: 1.099\n",
            "[5,   120] loss: 1.099\n",
            "[6,    40] loss: 1.099\n",
            "[6,    80] loss: 1.098\n",
            "[6,   120] loss: 1.099\n",
            "[7,    40] loss: 1.099\n",
            "[7,    80] loss: 1.099\n",
            "[7,   120] loss: 1.099\n",
            "[8,    40] loss: 1.099\n",
            "[8,    80] loss: 1.099\n",
            "[8,   120] loss: 1.098\n",
            "[9,    40] loss: 1.098\n",
            "[9,    80] loss: 1.098\n",
            "[9,   120] loss: 1.098\n",
            "[10,    40] loss: 1.098\n",
            "[10,    80] loss: 1.098\n",
            "[10,   120] loss: 1.098\n",
            "[11,    40] loss: 1.098\n",
            "[11,    80] loss: 1.098\n",
            "[11,   120] loss: 1.097\n",
            "[12,    40] loss: 1.097\n",
            "[12,    80] loss: 1.097\n",
            "[12,   120] loss: 1.096\n",
            "[13,    40] loss: 1.094\n",
            "[13,    80] loss: 1.092\n",
            "[13,   120] loss: 1.088\n",
            "[14,    40] loss: 1.085\n",
            "[14,    80] loss: 1.081\n",
            "[14,   120] loss: 1.077\n",
            "[15,    40] loss: 1.073\n",
            "[15,    80] loss: 1.072\n",
            "[15,   120] loss: 1.075\n",
            "[16,    40] loss: 1.066\n",
            "[16,    80] loss: 1.065\n",
            "[16,   120] loss: 1.066\n",
            "[17,    40] loss: 1.060\n",
            "[17,    80] loss: 1.058\n",
            "[17,   120] loss: 1.057\n",
            "[18,    40] loss: 1.049\n",
            "[18,    80] loss: 1.054\n",
            "[18,   120] loss: 1.052\n",
            "[19,    40] loss: 1.040\n",
            "[19,    80] loss: 1.047\n",
            "[19,   120] loss: 1.039\n",
            "[20,    40] loss: 1.038\n",
            "[20,    80] loss: 1.031\n",
            "[20,   120] loss: 1.038\n",
            "[21,    40] loss: 1.033\n",
            "[21,    80] loss: 1.024\n",
            "[21,   120] loss: 1.012\n",
            "[22,    40] loss: 1.006\n",
            "[22,    80] loss: 0.999\n",
            "[22,   120] loss: 0.979\n",
            "[23,    40] loss: 0.977\n",
            "[23,    80] loss: 0.974\n",
            "[23,   120] loss: 0.946\n",
            "[24,    40] loss: 0.941\n",
            "[24,    80] loss: 0.933\n",
            "[24,   120] loss: 0.921\n",
            "[25,    40] loss: 0.887\n",
            "[25,    80] loss: 0.880\n",
            "[25,   120] loss: 0.879\n",
            "[26,    40] loss: 0.864\n",
            "[26,    80] loss: 0.835\n",
            "[26,   120] loss: 0.822\n",
            "[27,    40] loss: 0.794\n",
            "[27,    80] loss: 0.798\n",
            "[27,   120] loss: 0.788\n",
            "[28,    40] loss: 0.790\n",
            "[28,    80] loss: 0.762\n",
            "[28,   120] loss: 0.733\n",
            "[29,    40] loss: 0.746\n",
            "[29,    80] loss: 0.720\n",
            "[29,   120] loss: 0.716\n",
            "[30,    40] loss: 0.700\n",
            "[30,    80] loss: 0.689\n",
            "[30,   120] loss: 0.689\n",
            "[31,    40] loss: 0.651\n",
            "[31,    80] loss: 0.658\n",
            "[31,   120] loss: 0.630\n",
            "[32,    40] loss: 0.639\n",
            "[32,    80] loss: 0.642\n",
            "[32,   120] loss: 0.635\n",
            "[33,    40] loss: 0.595\n",
            "[33,    80] loss: 0.607\n",
            "[33,   120] loss: 0.615\n",
            "[34,    40] loss: 0.568\n",
            "[34,    80] loss: 0.592\n",
            "[34,   120] loss: 0.575\n",
            "[35,    40] loss: 0.537\n",
            "[35,    80] loss: 0.531\n",
            "[35,   120] loss: 0.560\n",
            "[36,    40] loss: 0.529\n",
            "[36,    80] loss: 0.502\n",
            "[36,   120] loss: 0.520\n",
            "[37,    40] loss: 0.512\n",
            "[37,    80] loss: 0.500\n",
            "[37,   120] loss: 0.484\n",
            "[38,    40] loss: 0.466\n",
            "[38,    80] loss: 0.482\n",
            "[38,   120] loss: 0.451\n",
            "[39,    40] loss: 0.442\n",
            "[39,    80] loss: 0.453\n",
            "[39,   120] loss: 0.456\n",
            "[40,    40] loss: 0.412\n",
            "[40,    80] loss: 0.446\n",
            "[40,   120] loss: 0.399\n",
            "[41,    40] loss: 0.383\n",
            "[41,    80] loss: 0.412\n",
            "[41,   120] loss: 0.401\n",
            "[42,    40] loss: 0.385\n",
            "[42,    80] loss: 0.359\n",
            "[42,   120] loss: 0.380\n",
            "[43,    40] loss: 0.365\n",
            "[43,    80] loss: 0.342\n",
            "[43,   120] loss: 0.386\n",
            "[44,    40] loss: 0.335\n",
            "[44,    80] loss: 0.363\n",
            "[44,   120] loss: 0.332\n",
            "[45,    40] loss: 0.298\n",
            "[45,    80] loss: 0.322\n",
            "[45,   120] loss: 0.336\n",
            "[46,    40] loss: 0.301\n",
            "[46,    80] loss: 0.304\n",
            "[46,   120] loss: 0.291\n",
            "[47,    40] loss: 0.289\n",
            "[47,    80] loss: 0.279\n",
            "[47,   120] loss: 0.320\n",
            "[48,    40] loss: 0.283\n",
            "[48,    80] loss: 0.247\n",
            "[48,   120] loss: 0.268\n",
            "[49,    40] loss: 0.231\n",
            "[49,    80] loss: 0.246\n",
            "[49,   120] loss: 0.296\n",
            "[50,    40] loss: 0.228\n",
            "[50,    80] loss: 0.273\n",
            "[50,   120] loss: 0.261\n",
            "[51,    40] loss: 0.227\n",
            "[51,    80] loss: 0.231\n",
            "[51,   120] loss: 0.265\n",
            "[52,    40] loss: 0.201\n",
            "[52,    80] loss: 0.210\n",
            "[52,   120] loss: 0.247\n",
            "[53,    40] loss: 0.187\n",
            "[53,    80] loss: 0.201\n",
            "[53,   120] loss: 0.197\n",
            "[54,    40] loss: 0.221\n",
            "[54,    80] loss: 0.228\n",
            "[54,   120] loss: 0.224\n",
            "[55,    40] loss: 0.166\n",
            "[55,    80] loss: 0.179\n",
            "[55,   120] loss: 0.175\n",
            "[56,    40] loss: 0.165\n",
            "[56,    80] loss: 0.201\n",
            "[56,   120] loss: 0.234\n",
            "[57,    40] loss: 0.159\n",
            "[57,    80] loss: 0.138\n",
            "[57,   120] loss: 0.155\n",
            "[58,    40] loss: 0.137\n",
            "[58,    80] loss: 0.141\n",
            "[58,   120] loss: 0.170\n",
            "[59,    40] loss: 0.139\n",
            "[59,    80] loss: 0.156\n",
            "[59,   120] loss: 0.146\n",
            "[60,    40] loss: 0.109\n",
            "[60,    80] loss: 0.119\n",
            "[60,   120] loss: 0.110\n",
            "[61,    40] loss: 0.109\n",
            "[61,    80] loss: 0.129\n",
            "[61,   120] loss: 0.191\n",
            "[62,    40] loss: 0.142\n",
            "[62,    80] loss: 0.118\n",
            "[62,   120] loss: 0.153\n",
            "[63,    40] loss: 0.119\n",
            "[63,    80] loss: 0.135\n",
            "[63,   120] loss: 0.124\n",
            "[64,    40] loss: 0.117\n",
            "[64,    80] loss: 0.116\n",
            "[64,   120] loss: 0.130\n",
            "[65,    40] loss: 0.092\n",
            "[65,    80] loss: 0.120\n",
            "[65,   120] loss: 0.130\n",
            "[66,    40] loss: 0.113\n",
            "[66,    80] loss: 0.115\n",
            "[66,   120] loss: 0.123\n",
            "[67,    40] loss: 0.114\n",
            "[67,    80] loss: 0.128\n",
            "[67,   120] loss: 0.104\n",
            "[68,    40] loss: 0.087\n",
            "[68,    80] loss: 0.104\n",
            "[68,   120] loss: 0.090\n",
            "[69,    40] loss: 0.095\n",
            "[69,    80] loss: 0.093\n",
            "[69,   120] loss: 0.097\n",
            "[70,    40] loss: 0.083\n",
            "[70,    80] loss: 0.079\n",
            "[70,   120] loss: 0.094\n",
            "[71,    40] loss: 0.061\n",
            "[71,    80] loss: 0.071\n",
            "[71,   120] loss: 0.081\n",
            "[72,    40] loss: 0.083\n",
            "[72,    80] loss: 0.107\n",
            "[72,   120] loss: 0.082\n",
            "[73,    40] loss: 0.075\n",
            "[73,    80] loss: 0.082\n",
            "[73,   120] loss: 0.055\n",
            "[74,    40] loss: 0.054\n",
            "[74,    80] loss: 0.061\n",
            "[74,   120] loss: 0.127\n",
            "[75,    40] loss: 0.110\n",
            "[75,    80] loss: 0.115\n",
            "[75,   120] loss: 0.072\n",
            "[76,    40] loss: 0.038\n",
            "[76,    80] loss: 0.046\n",
            "[76,   120] loss: 0.043\n",
            "[77,    40] loss: 0.041\n",
            "[77,    80] loss: 0.061\n",
            "[77,   120] loss: 0.081\n",
            "[78,    40] loss: 0.048\n",
            "[78,    80] loss: 0.074\n",
            "[78,   120] loss: 0.077\n",
            "[79,    40] loss: 0.060\n",
            "[79,    80] loss: 0.095\n",
            "[79,   120] loss: 0.062\n",
            "[80,    40] loss: 0.071\n",
            "[80,    80] loss: 0.065\n",
            "[80,   120] loss: 0.059\n",
            "[81,    40] loss: 0.060\n",
            "[81,    80] loss: 0.090\n",
            "[81,   120] loss: 0.056\n",
            "[82,    40] loss: 0.050\n",
            "[82,    80] loss: 0.059\n",
            "[82,   120] loss: 0.064\n",
            "[83,    40] loss: 0.043\n",
            "[83,    80] loss: 0.037\n",
            "[83,   120] loss: 0.039\n",
            "[84,    40] loss: 0.027\n",
            "[84,    80] loss: 0.049\n",
            "[84,   120] loss: 0.053\n",
            "[85,    40] loss: 0.032\n",
            "[85,    80] loss: 0.035\n",
            "[85,   120] loss: 0.041\n",
            "[86,    40] loss: 0.032\n",
            "[86,    80] loss: 0.024\n",
            "[86,   120] loss: 0.047\n",
            "[87,    40] loss: 0.047\n",
            "[87,    80] loss: 0.036\n",
            "[87,   120] loss: 0.027\n",
            "[88,    40] loss: 0.032\n",
            "[88,    80] loss: 0.059\n",
            "[88,   120] loss: 0.060\n",
            "[89,    40] loss: 0.058\n",
            "[89,    80] loss: 0.074\n",
            "[89,   120] loss: 0.058\n",
            "[90,    40] loss: 0.038\n",
            "[90,    80] loss: 0.032\n",
            "[90,   120] loss: 0.038\n",
            "[91,    40] loss: 0.029\n",
            "[91,    80] loss: 0.033\n",
            "[91,   120] loss: 0.038\n",
            "[92,    40] loss: 0.029\n",
            "[92,    80] loss: 0.027\n",
            "[92,   120] loss: 0.044\n",
            "[93,    40] loss: 0.025\n",
            "[93,    80] loss: 0.031\n",
            "[93,   120] loss: 0.035\n",
            "[94,    40] loss: 0.085\n",
            "[94,    80] loss: 0.050\n",
            "[94,   120] loss: 0.035\n",
            "[95,    40] loss: 0.033\n",
            "[95,    80] loss: 0.025\n",
            "[95,   120] loss: 0.022\n",
            "[96,    40] loss: 0.008\n",
            "[96,    80] loss: 0.008\n",
            "[96,   120] loss: 0.022\n",
            "[97,    40] loss: 0.017\n",
            "[97,    80] loss: 0.012\n",
            "[97,   120] loss: 0.013\n",
            "[98,    40] loss: 0.006\n",
            "[98,    80] loss: 0.004\n",
            "[98,   120] loss: 0.004\n",
            "[99,    40] loss: 0.004\n",
            "[99,    80] loss: 0.003\n",
            "[99,   120] loss: 0.002\n",
            "[100,    40] loss: 0.001\n",
            "[100,    80] loss: 0.001\n",
            "[100,   120] loss: 0.002\n",
            "[101,    40] loss: 0.001\n",
            "[101,    80] loss: 0.002\n",
            "[101,   120] loss: 0.009\n",
            "[102,    40] loss: 0.087\n",
            "[102,    80] loss: 0.114\n",
            "[102,   120] loss: 0.057\n",
            "[103,    40] loss: 0.037\n",
            "[103,    80] loss: 0.025\n",
            "[103,   120] loss: 0.021\n",
            "[104,    40] loss: 0.017\n",
            "[104,    80] loss: 0.029\n",
            "[104,   120] loss: 0.044\n",
            "[105,    40] loss: 0.058\n",
            "[105,    80] loss: 0.041\n",
            "[105,   120] loss: 0.029\n",
            "[106,    40] loss: 0.017\n",
            "[106,    80] loss: 0.024\n",
            "[106,   120] loss: 0.030\n",
            "[107,    40] loss: 0.032\n",
            "[107,    80] loss: 0.037\n",
            "[107,   120] loss: 0.039\n",
            "[108,    40] loss: 0.019\n",
            "[108,    80] loss: 0.014\n",
            "[108,   120] loss: 0.017\n",
            "[109,    40] loss: 0.019\n",
            "[109,    80] loss: 0.013\n",
            "[109,   120] loss: 0.016\n",
            "[110,    40] loss: 0.012\n",
            "[110,    80] loss: 0.015\n",
            "[110,   120] loss: 0.012\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lB7KlwGVpmd",
        "colab_type": "code",
        "outputId": "606e6449-4d5a-4290-8524-7c15475d96a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "  train_acc = 0\n",
        "for i, data in enumerate(mosaic_loader):\n",
        "    inputs,labels,_ = data\n",
        "    inputs,labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    avg_data,alphas = focus_net(inputs)\n",
        "    outputs = classification_net(avg_data)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    # print(predicted.detach().cpu().numpy())\n",
        "    train_acc += sum(predicted.cpu().numpy() == labels.cpu().numpy())\n",
        "print(\"percentage train accuracy: \",train_acc/300) \n",
        "\n",
        "torch.save(focus_net.state_dict(),\"focus_netat3.pt\")\n",
        "torch.save(classification_net.state_dict(),\"classification_netat3.pt\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "percentage train accuracy:  99.83333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEdCv9Lfd6Pf",
        "colab_type": "code",
        "outputId": "2554b515-1558-4c05-cc8f-416b56a69412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "val_acc = 0\n",
        "for i, data in enumerate(test_loader):\n",
        "    inputs,labels,_ = data\n",
        "    inputs,labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    avg_data,alphas = focus_net(inputs)\n",
        "    outputs = classification_net(avg_data)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "\n",
        "    val_acc +=sum(predicted.cpu().numpy() == labels.cpu().numpy())\n",
        "print(\"percentage validation accuracy: \",val_acc/100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "percentage validation accuracy:  90.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5MIz98beE2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "6d8dcee5-3e37-43b2-ac85-bd5468a4316d"
      },
      "source": [
        "plt.figure(figsize = (5,4))\n",
        "plt.plot(tr_loss,label= \"training loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"cross entropy loss\")\n",
        "plt.savefig(\"traininglossat3.png\")\n",
        "plt.savefig(\"traininglossat3.pdf\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDF5iDVwYCZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}