{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_size,corruption_percentage):\n",
    "    dims =50\n",
    "    #np.random.seed(1234)\n",
    "    y = np.ones(data_size,dtype=\"long\")\n",
    "    idx = np.random.uniform(size =data_size)>0.5\n",
    "    y[idx] = 0 \n",
    "    print(\"positive_class\",sum(y==1),\"negative_class\",sum(y==0))\n",
    "    idx1 = ~idx #positive class indices\n",
    "    idx2 = idx #negative class indices \n",
    "\n",
    "    x = np.zeros((data_size,dims))\n",
    "    x[idx1,0] = np.random.randn(sum(idx1)) # standard normal\n",
    "    x[idx2,0] = np.random.randn(sum(idx2)) +2 # normal with mean 10 and standard deviation 1\n",
    "\n",
    "    x[:,1:] = np.random.uniform(-1,1,size=(data_size,dims-1))\n",
    "    \n",
    "    # plt.figure(figsize=(8,5))\n",
    "    # plt.hist(x[idx1,0],density=True,label = str(data_size)+\"_1 class\")  #positive class histogram \n",
    "\n",
    "    # plt.hist(x[idx2,0],density = True, label = str(data_size)+\"_0 class\")  #negative class histogram\n",
    "    # plt.xlabel(\"x1\")\n",
    "    # plt.ylabel(\"probability density\")\n",
    "    # plt.legend()\n",
    "    # plt.title(\"corruption_percentage: \"+str(corruption_percentage)+\"_Data size: \"+str(data_size)+\"_histogram\")\n",
    "    \n",
    "    #corruption_percentage = 0.5\n",
    "    mask = np.random.uniform(0,1,data_size) < corruption_percentage\n",
    "    a = np.array(y)\n",
    "    #print(\"true\",a[mask])\n",
    "    a[mask] = np.random.randint(0,2,sum(mask))\n",
    "    #print(\"randomized\",a[mask])\n",
    "    y = list(a)\n",
    "    \n",
    "    return x,y,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_class 57 negative_class 43\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(1234)\n",
    "y = np.ones(100,dtype=\"long\")\n",
    "idx = np.random.uniform(size =100)>0.5\n",
    "y[idx] = 0 \n",
    "\n",
    "print(\"positive_class\",sum(y==1),\"negative_class\",sum(y==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = ~idx #positive class indices\n",
    "idx2 = idx #negative class indices \n",
    "\n",
    "x = np.zeros((100,50))\n",
    "x[idx1,0] = np.random.randn(sum(idx1)) # standard normal\n",
    "x[idx2,0] = np.random.randn(sum(idx2)) +2 # normal with mean 10 and standard deviation 1\n",
    "\n",
    "x[:,1:] = np.random.uniform(-1,1,size=(100,49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa5e19e6b10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(x[idx1,0],density=True,label = \"+1 class\")  #positive class histogram \n",
    "\n",
    "# plt.hist(x[idx2,0],density = True, label = \"0 class\")  #negative class histogram\n",
    "sns.distplot(x[idx1,0], hist=True, label=\"+1 class\")\n",
    "sns.distplot(x[idx2,0], hist= True, label=\"0 class\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"probability density\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true [0 1 0 1 1 1 1 0 1 1]\n",
      "randomized [1 0 0 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "corruption_percentage = 0.1\n",
    "mask = np.random.uniform(0,1,100) < corruption_percentage\n",
    "a = np.array(y)\n",
    "print(\"true\",a[mask])\n",
    "a[mask] = np.random.randint(0,2,sum(mask))\n",
    "print(\"randomized\",a[mask])\n",
    "y = list(a)\n",
    "# # cifar_trainset_random.targets[:50000] = np.random.randint(low=0,high=9,size=50000)\n",
    "# #trainloader_random = torch.utils.data.DataLoader(cifar_trainset_random,batch_size=256,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y),sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy( a, b):\n",
    "    length = a.shape\n",
    "    #print(a,\"dfgfg\",length)\n",
    "    correct = a==b\n",
    "    return sum(correct)/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthetic_data(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        super(Synthetic_data,self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.y))\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx,:],self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1 = nn.Linear(50,16)\n",
    "        self.linear2 = nn.Linear(16,2)\n",
    "#         self.linear3 = nn.Linear(128,64)\n",
    "#         self.linear4 = nn.Linear(64,2)\n",
    "    def forward(self,x):\n",
    "        x =  F.relu(self.linear1(x))\n",
    "        x =  self.linear2(x)\n",
    "#         x = F.relu(self.linear3(x))\n",
    "#         x = self.linear4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,data_loader,epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(),lr =0.01)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        cnt = 0 \n",
    "        for i,data in enumerate(data_loader):\n",
    "            x_input ,targets = data\n",
    "            #true.append(targets.cpu().numpy())\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(x_input)\n",
    "            #out.append(outputs.cpu())\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            #pred.append(predicted.cpu().numpy())\n",
    "            loss = criterion(outputs,targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if cnt % 4 == 3:    # print every 50 mini-batches\n",
    "                #print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / 50))\n",
    "                running_loss = 0.0\n",
    "            cnt=cnt+1\n",
    "    return net,criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_train(net,dataloader,criterion,mask):\n",
    "    out = []\n",
    "    pred = []\n",
    "    true = []\n",
    "    for i,data in enumerate(trainloader):\n",
    "        x_input ,targets = data\n",
    "        true.append(targets.cpu().numpy())\n",
    "        \n",
    "        outputs = net(x_input)\n",
    "        out.append(outputs.cpu())\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        pred.append(predicted.cpu().numpy())\n",
    "        \n",
    "    \n",
    "    true_targets = np.concatenate(true,axis=0)\n",
    "    predicted_targets = np.concatenate(pred,axis =0)\n",
    "\n",
    "    acc_corrupt = accuracy(true_targets[mask],predicted_targets[mask])\n",
    "    acc_uncorrupt = accuracy(true_targets[~mask],predicted_targets[~mask])\n",
    "    acc_full = accuracy(true_targets, predicted_targets)\n",
    "    print(\"Train accuracy on corrupt data\",acc_corrupt)\n",
    "    print(\"Train accuracy on un-corrupt data\",acc_uncorrupt)\n",
    "    print(\"Train accuracy on full data\", accuracy(true_targets, predicted_targets))\n",
    "    \n",
    "    l= np.where(mask ==True)\n",
    "    p = np.where(mask == False)\n",
    "\n",
    "    out = torch.cat(out, dim =0)\n",
    "    \n",
    "    print(\"Train cross entropy loss on corrupt data\", criterion(out[l], torch.Tensor(true_targets[l]).type(torch.LongTensor)).item())\n",
    "    print(\"Train cross entropy loss on un-corrupt data\",criterion(out[p], torch.Tensor(true_targets[p]).type(torch.LongTensor)).item())\n",
    "    print(\"Train cross entropy loss on full data\",criterion(out, torch.Tensor(true_targets).type(torch.LongTensor)).item())\n",
    "    print(\"---\"*20)\n",
    "    loss_full = criterion(out, torch.Tensor(true_targets).type(torch.LongTensor)).item()\n",
    "    return  acc_full, loss_full\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(net,dataloader,criterion):\n",
    "    out = []\n",
    "    pred = []\n",
    "    true = []\n",
    "    for i,data in enumerate(trainloader):\n",
    "        x_input ,targets = data\n",
    "        true.append(targets.cpu().numpy())\n",
    "        \n",
    "        outputs = net(x_input)\n",
    "        out.append(outputs.cpu())\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        pred.append(predicted.cpu().numpy())\n",
    "        \n",
    "    \n",
    "    true_targets = np.concatenate(true,axis=0)\n",
    "    predicted_targets = np.concatenate(pred,axis =0)\n",
    "\n",
    "    \n",
    "    acc_full = accuracy(true_targets, predicted_targets)\n",
    "    print(\"Test accuracy on full data\", accuracy(true_targets, predicted_targets))\n",
    "\n",
    "    out = torch.cat(out, dim =0)\n",
    "    print(\"Test cross entropy loss on full data\",criterion(out, torch.Tensor(true_targets).type(torch.LongTensor)).item())\n",
    "    print(\"---\"*20)\n",
    "    loss_full = criterion(out, torch.Tensor(true_targets).type(torch.LongTensor)).item()\n",
    "    return  acc_full, loss_full\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_class 47 negative_class 53\n",
      "positive_class 44 negative_class 56\n",
      "Train accuracy on corrupt data [1.]\n",
      "Train accuracy on un-corrupt data [0.98979592]\n",
      "Train accuracy on full data [0.99]\n",
      "Train cross entropy loss on corrupt data 0.09528393706710077\n",
      "Train cross entropy loss on un-corrupt data 0.1202116309383874\n",
      "Train cross entropy loss on full data 0.1197130770609617\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.99]\n",
      "Test cross entropy loss on full data 0.1197130770609617\n",
      "------------------------------------------------------------\n",
      "positive_class 54 negative_class 46\n",
      "positive_class 54 negative_class 46\n",
      "Train accuracy on corrupt data [1.]\n",
      "Train accuracy on un-corrupt data [0.97727273]\n",
      "Train accuracy on full data [0.98]\n",
      "Train cross entropy loss on corrupt data 0.23443186687901704\n",
      "Train cross entropy loss on un-corrupt data 0.17675920006370288\n",
      "Train cross entropy loss on full data 0.18367992008154052\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.98]\n",
      "Test cross entropy loss on full data 0.18367992008154052\n",
      "------------------------------------------------------------\n",
      "positive_class 52 negative_class 48\n",
      "positive_class 43 negative_class 57\n",
      "Train accuracy on corrupt data [0.95833333]\n",
      "Train accuracy on un-corrupt data [1.]\n",
      "Train accuracy on full data [0.99]\n",
      "Train cross entropy loss on corrupt data 0.2322358673368304\n",
      "Train cross entropy loss on un-corrupt data 0.0956361584267994\n",
      "Train cross entropy loss on full data 0.12842008856520684\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.99]\n",
      "Test cross entropy loss on full data 0.12842008856520684\n",
      "------------------------------------------------------------\n",
      "positive_class 43 negative_class 57\n",
      "positive_class 52 negative_class 48\n",
      "Train accuracy on corrupt data [0.94736842]\n",
      "Train accuracy on un-corrupt data [0.97674419]\n",
      "Train accuracy on full data [0.96]\n",
      "Train cross entropy loss on corrupt data 0.2323858073047039\n",
      "Train cross entropy loss on un-corrupt data 0.18549491607702265\n",
      "Train cross entropy loss on full data 0.21222272407680112\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.96]\n",
      "Test cross entropy loss on full data 0.21222272407680112\n",
      "------------------------------------------------------------\n",
      "positive_class 236 negative_class 264\n",
      "positive_class 266 negative_class 234\n",
      "Train accuracy on corrupt data [1.]\n",
      "Train accuracy on un-corrupt data [0.96363636]\n",
      "Train accuracy on full data [0.964]\n",
      "Train cross entropy loss on corrupt data 0.19948341685853266\n",
      "Train cross entropy loss on un-corrupt data 0.11791660799008817\n",
      "Train cross entropy loss on full data 0.11873227607877264\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.964]\n",
      "Test cross entropy loss on full data 0.11873227607877264\n",
      "------------------------------------------------------------\n",
      "positive_class 238 negative_class 262\n",
      "positive_class 263 negative_class 237\n",
      "Train accuracy on corrupt data [0.77777778]\n",
      "Train accuracy on un-corrupt data [0.96923077]\n",
      "Train accuracy on full data [0.952]\n",
      "Train cross entropy loss on corrupt data 0.4911877907423219\n",
      "Train cross entropy loss on un-corrupt data 0.16492764729989712\n",
      "Train cross entropy loss on full data 0.1942910602097155\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.952]\n",
      "Test cross entropy loss on full data 0.1942910602097155\n",
      "------------------------------------------------------------\n",
      "positive_class 260 negative_class 240\n",
      "positive_class 241 negative_class 259\n",
      "Train accuracy on corrupt data [0.86315789]\n",
      "Train accuracy on un-corrupt data [0.96790123]\n",
      "Train accuracy on full data [0.948]\n",
      "Train cross entropy loss on corrupt data 0.34060212562269365\n",
      "Train cross entropy loss on un-corrupt data 0.1818758527240585\n",
      "Train cross entropy loss on full data 0.21203384457479893\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.948]\n",
      "Test cross entropy loss on full data 0.21203384457479893\n",
      "------------------------------------------------------------\n",
      "positive_class 261 negative_class 239\n",
      "positive_class 260 negative_class 240\n",
      "Train accuracy on corrupt data [0.9581749]\n",
      "Train accuracy on un-corrupt data [0.96624473]\n",
      "Train accuracy on full data [0.962]\n",
      "Train cross entropy loss on corrupt data 0.2341938023376575\n",
      "Train cross entropy loss on un-corrupt data 0.18898746579387993\n",
      "Train cross entropy loss on full data 0.21276599881590677\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.962]\n",
      "Test cross entropy loss on full data 0.21276599881590677\n",
      "------------------------------------------------------------\n",
      "positive_class 524 negative_class 476\n",
      "positive_class 505 negative_class 495\n",
      "Train accuracy on corrupt data [0.91666667]\n",
      "Train accuracy on un-corrupt data [0.97469636]\n",
      "Train accuracy on full data [0.974]\n",
      "Train cross entropy loss on corrupt data 0.21063710907632407\n",
      "Train cross entropy loss on un-corrupt data 0.11835155161958777\n",
      "Train cross entropy loss on full data 0.11945897830906863\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.974]\n",
      "Test cross entropy loss on full data 0.11945897830906863\n",
      "------------------------------------------------------------\n",
      "positive_class 521 negative_class 479\n",
      "positive_class 500 negative_class 500\n",
      "Train accuracy on corrupt data [0.7979798]\n",
      "Train accuracy on un-corrupt data [0.97669256]\n",
      "Train accuracy on full data [0.959]\n",
      "Train cross entropy loss on corrupt data 0.4540062603226922\n",
      "Train cross entropy loss on un-corrupt data 0.13731015386678608\n",
      "Train cross entropy loss on full data 0.16866306840592077\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.959]\n",
      "Test cross entropy loss on full data 0.16866306840592077\n",
      "------------------------------------------------------------\n",
      "positive_class 482 negative_class 518\n",
      "positive_class 516 negative_class 484\n",
      "Train accuracy on corrupt data [0.86021505]\n",
      "Train accuracy on un-corrupt data [0.96683047]\n",
      "Train accuracy on full data [0.947]\n",
      "Train cross entropy loss on corrupt data 0.34610765984305636\n",
      "Train cross entropy loss on un-corrupt data 0.15888724086213377\n",
      "Train cross entropy loss on full data 0.19371023879258523\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.947]\n",
      "Test cross entropy loss on full data 0.19371023879258523\n",
      "------------------------------------------------------------\n",
      "positive_class 508 negative_class 492\n",
      "positive_class 522 negative_class 478\n",
      "Train accuracy on corrupt data [0.88663968]\n",
      "Train accuracy on un-corrupt data [0.95256917]\n",
      "Train accuracy on full data [0.92]\n",
      "Train cross entropy loss on corrupt data 0.31975950960165755\n",
      "Train cross entropy loss on un-corrupt data 0.21484080789822957\n",
      "Train cross entropy loss on full data 0.2666706465397231\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.92]\n",
      "Test cross entropy loss on full data 0.2666706465397231\n",
      "------------------------------------------------------------\n",
      "positive_class 980 negative_class 1020\n",
      "positive_class 1003 negative_class 997\n",
      "Train accuracy on corrupt data [0.77272727]\n",
      "Train accuracy on un-corrupt data [0.9570273]\n",
      "Train accuracy on full data [0.955]\n",
      "Train cross entropy loss on corrupt data 0.6633121844683797\n",
      "Train cross entropy loss on un-corrupt data 0.13956737217082066\n",
      "Train cross entropy loss on full data 0.14532856510609382\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.955]\n",
      "Test cross entropy loss on full data 0.14532856510609382\n",
      "------------------------------------------------------------\n",
      "positive_class 983 negative_class 1017\n",
      "positive_class 1021 negative_class 979\n",
      "Train accuracy on corrupt data [0.79679144]\n",
      "Train accuracy on un-corrupt data [0.95035852]\n",
      "Train accuracy on full data [0.936]\n",
      "Train cross entropy loss on corrupt data 0.40467158387179575\n",
      "Train cross entropy loss on un-corrupt data 0.15843221499907373\n",
      "Train cross entropy loss on full data 0.1814555959886735\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.936]\n",
      "Test cross entropy loss on full data 0.1814555959886735\n",
      "------------------------------------------------------------\n",
      "positive_class 996 negative_class 1004\n",
      "positive_class 1020 negative_class 980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy on corrupt data [0.76334107]\n",
      "Train accuracy on un-corrupt data [0.94136393]\n",
      "Train accuracy on full data [0.903]\n",
      "Train cross entropy loss on corrupt data 0.5126944923101646\n",
      "Train cross entropy loss on un-corrupt data 0.2029517396395123\n",
      "Train cross entropy loss on full data 0.26970130284003774\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.903]\n",
      "Test cross entropy loss on full data 0.26970130284003774\n",
      "------------------------------------------------------------\n",
      "positive_class 988 negative_class 1012\n",
      "positive_class 983 negative_class 1017\n",
      "Train accuracy on corrupt data [0.82125604]\n",
      "Train accuracy on un-corrupt data [0.89430052]\n",
      "Train accuracy on full data [0.8565]\n",
      "Train cross entropy loss on corrupt data 0.42743058794222294\n",
      "Train cross entropy loss on un-corrupt data 0.28426927083080894\n",
      "Train cross entropy loss on full data 0.3583552524359655\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.8565]\n",
      "Test cross entropy loss on full data 0.3583552524359655\n",
      "------------------------------------------------------------\n",
      "positive_class 2483 negative_class 2517\n",
      "positive_class 2534 negative_class 2466\n",
      "Train accuracy on corrupt data [0.57377049]\n",
      "Train accuracy on un-corrupt data [0.89451306]\n",
      "Train accuracy on full data [0.8906]\n",
      "Train cross entropy loss on corrupt data 1.1532633916815416\n",
      "Train cross entropy loss on un-corrupt data 0.25608789557907446\n",
      "Train cross entropy loss on full data 0.2670334366315245\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.8906]\n",
      "Test cross entropy loss on full data 0.2670334366315245\n",
      "------------------------------------------------------------\n",
      "positive_class 2579 negative_class 2421\n",
      "positive_class 2525 negative_class 2475\n",
      "Train accuracy on corrupt data [0.62548263]\n",
      "Train accuracy on un-corrupt data [0.89045069]\n",
      "Train accuracy on full data [0.863]\n",
      "Train cross entropy loss on corrupt data 0.8082230610513184\n",
      "Train cross entropy loss on un-corrupt data 0.27148206680374454\n",
      "Train cross entropy loss on full data 0.327088433807793\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.863]\n",
      "Test cross entropy loss on full data 0.327088433807793\n",
      "------------------------------------------------------------\n",
      "positive_class 2510 negative_class 2490\n",
      "positive_class 2598 negative_class 2402\n",
      "Train accuracy on corrupt data [0.64105263]\n",
      "Train accuracy on un-corrupt data [0.87604938]\n",
      "Train accuracy on full data [0.8314]\n",
      "Train cross entropy loss on corrupt data 0.7116970388371164\n",
      "Train cross entropy loss on un-corrupt data 0.3059667505770841\n",
      "Train cross entropy loss on full data 0.3830555053464902\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.8314]\n",
      "Test cross entropy loss on full data 0.3830555053464902\n",
      "------------------------------------------------------------\n",
      "positive_class 2525 negative_class 2475\n",
      "positive_class 2500 negative_class 2500\n",
      "Train accuracy on corrupt data [0.67539683]\n",
      "Train accuracy on un-corrupt data [0.83790323]\n",
      "Train accuracy on full data [0.756]\n",
      "Train cross entropy loss on corrupt data 0.6008483208421204\n",
      "Train cross entropy loss on un-corrupt data 0.391451129845888\n",
      "Train cross entropy loss on full data 0.49698731410798763\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.756]\n",
      "Test cross entropy loss on full data 0.49698731410798763\n",
      "------------------------------------------------------------\n",
      "positive_class 4906 negative_class 5094\n",
      "positive_class 4943 negative_class 5057\n",
      "Train accuracy on corrupt data [0.47321429]\n",
      "Train accuracy on un-corrupt data [0.87621359]\n",
      "Train accuracy on full data [0.8717]\n",
      "Train cross entropy loss on corrupt data 1.408827978313436\n",
      "Train cross entropy loss on un-corrupt data 0.29461288079108683\n",
      "Train cross entropy loss on full data 0.3070920898833372\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.8717]\n",
      "Test cross entropy loss on full data 0.3070920898833372\n",
      "------------------------------------------------------------\n",
      "positive_class 5122 negative_class 4878\n",
      "positive_class 5083 negative_class 4917\n",
      "Train accuracy on corrupt data [0.58449304]\n",
      "Train accuracy on un-corrupt data [0.86424283]\n",
      "Train accuracy on full data [0.8361]\n",
      "Train cross entropy loss on corrupt data 0.8854462749494916\n",
      "Train cross entropy loss on un-corrupt data 0.3191285956662503\n",
      "Train cross entropy loss on full data 0.3761001542021445\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.8361]\n",
      "Test cross entropy loss on full data 0.3761001542021445\n",
      "------------------------------------------------------------\n",
      "positive_class 5012 negative_class 4988\n",
      "positive_class 4944 negative_class 5056\n",
      "Train accuracy on corrupt data [0.58183684]\n",
      "Train accuracy on un-corrupt data [0.87181717]\n",
      "Train accuracy on full data [0.8153]\n",
      "Train cross entropy loss on corrupt data 0.8425814951233964\n",
      "Train cross entropy loss on un-corrupt data 0.3268947100605535\n",
      "Train cross entropy loss on full data 0.4274020644692999\n",
      "------------------------------------------------------------\n",
      "Test accuracy on full data [0.8153]\n",
      "Test cross entropy loss on full data 0.4274020644692999\n",
      "------------------------------------------------------------\n",
      "positive_class 4958 negative_class 5042\n",
      "positive_class 4990 negative_class 5010\n"
     ]
    }
   ],
   "source": [
    "datasizes = [100,500,1000,2000,5000,10000]\n",
    "corrupt_percent = [0.01,0.1,0.2,0.5]\n",
    "train_acc=[]\n",
    "train_ce_loss=[]\n",
    "test_acc=[]\n",
    "test_ce_loss=[]\n",
    "for i in datasizes:\n",
    "    for j in corrupt_percent:\n",
    "        \n",
    "        x,y,mask = generate_data(data_size= i , corruption_percentage= j)\n",
    "        \n",
    "        x_test,y_test,mask_test = generate_data(data_size= i , corruption_percentage= 0)\n",
    "        \n",
    "        #print(sum(mask))\n",
    "        \n",
    "        \n",
    "        data_set = Synthetic_data(x,y)\n",
    "        test_set = Synthetic_data(x_test,y_test)\n",
    "        \n",
    "        trainloader = DataLoader(data_set,batch_size=20,shuffle=False)\n",
    "        testloader = DataLoader(test_set,batch_size=20,shuffle=False)\n",
    "        net = Net().double()\n",
    "        \n",
    "        net,criterion = train(net,trainloader,300)\n",
    "        \n",
    "        a,b = evaluate_train(net,trainloader,criterion,mask)\n",
    "        \n",
    "        c,d = evaluate_test(net , testloader, criterion)\n",
    "        \n",
    "        train_acc.append(a)\n",
    "        train_ce_loss.append(b)\n",
    "        test_acc.append(c)\n",
    "        test_ce_loss.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(datasizes,[train_acc[0],train_acc[4],train_acc[8],train_acc[12],train_acc[16],train_acc[20]],\"o--\",label=\"noise 1 %\")\n",
    "plt.plot(datasizes,[train_acc[1],train_acc[5],train_acc[9],train_acc[13],train_acc[17],train_acc[21]],\"o--\",label=\"noise 10 %\")\n",
    "plt.plot(datasizes,[train_acc[2],train_acc[6],train_acc[10],train_acc[14],train_acc[18],train_acc[22]],\"o--\",label=\"noise 20 %\")\n",
    "plt.plot(datasizes,[train_acc[3],train_acc[7],train_acc[11],train_acc[15],train_acc[19],train_acc[23]],\"o--\",label=\"noise 50 %\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Data_set_size\")\n",
    "plt.ylabel(\"Percentage_Accuracy\")\n",
    "plt.title(\"Train_Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(datasizes,[train_ce_loss[0],train_ce_loss[4],train_ce_loss[8],train_ce_loss[12],train_ce_loss[16],train_ce_loss[20]],\"o--\",label=\"noise 1 %\")\n",
    "plt.plot(datasizes,[train_ce_loss[1],train_ce_loss[5],train_ce_loss[9],train_ce_loss[13],train_ce_loss[17],train_ce_loss[21]],\"o--\",label=\"noise 10 %\")\n",
    "plt.plot(datasizes,[train_ce_loss[2],train_ce_loss[6],train_ce_loss[10],train_ce_loss[14],train_ce_loss[18],train_ce_loss[22]],\"o--\",label=\"noise 20 %\")\n",
    "plt.plot(datasizes,[train_ce_loss[3],train_ce_loss[7],train_ce_loss[11],train_ce_loss[15],train_ce_loss[19],train_ce_loss[23]],\"o--\",label=\"noise 50 %\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Data_set_size\")\n",
    "plt.ylabel(\"CE_Loss\")\n",
    "plt.title(\"Train_CE_Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(datasizes,[test_acc[0],test_acc[4],test_acc[8],test_acc[12],test_acc[16],test_acc[20]],\"o--\",label=\"noise 1 %\")\n",
    "plt.plot(datasizes,[test_acc[1],test_acc[5],test_acc[9],test_acc[13],test_acc[17],test_acc[21]],\"o--\",label=\"noise 10 %\")\n",
    "plt.plot(datasizes,[test_acc[2],test_acc[6],test_acc[10],test_acc[14],test_acc[18],test_acc[22]],\"o--\",label=\"noise 20 %\")\n",
    "plt.plot(datasizes,[test_acc[3],test_acc[7],test_acc[11],test_acc[15],test_acc[19],test_acc[23]],\"o--\",label=\"noise 50 %\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Data_set_size\")\n",
    "plt.ylabel(\"Percentage_Accuracy\")\n",
    "plt.title(\"Test_Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(datasizes,[test_ce_loss[0],test_ce_loss[4],test_ce_loss[8],test_ce_loss[12],test_ce_loss[16],test_ce_loss[20]],\"o--\",label=\"noise 1 %\")\n",
    "plt.plot(datasizes,[test_ce_loss[1],test_ce_loss[5],test_ce_loss[9],test_ce_loss[13],test_ce_loss[17],test_ce_loss[21]],\"o--\",label=\"noise 10 %\")\n",
    "plt.plot(datasizes,[test_ce_loss[2],test_ce_loss[6],test_ce_loss[10],test_ce_loss[14],test_ce_loss[18],test_ce_loss[22]],\"o--\",label=\"noise 20 %\")\n",
    "plt.plot(datasizes,[test_ce_loss[3],test_ce_loss[7],test_ce_loss[11],test_ce_loss[15],test_ce_loss[19],test_ce_loss[23]],\"o--\",label=\"noise 50 %\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Data_set_size\")\n",
    "plt.ylabel(\"CE_Loss\")\n",
    "plt.title(\"Test_CE_Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
