{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST_class_classification_cnn_10layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjG64ra4aFu",
        "outputId": "c2ad0dc6-f234-4e43-be64-78cf404f36e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-7SARDZErK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acRFqJNrZErV"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize([0.5],[0.5])])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQeenFDL6SA9",
        "outputId": "ce22592d-821f-472a-fc96-62ee091a72e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "dataset = trainset.train_data\n",
        "x = dataset[7777]\n",
        "print(x.shape)\n",
        "\n",
        "plt.imshow(x, cmap='gray')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe47dabd668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQOH55xR6INA"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256,shuffle=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SadRzWBBZEsP"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=28, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=28, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.conv7 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.conv8 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.conv9 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.conv10 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(28, track_running_stats = False)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128, track_running_stats = False)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv7(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = self.conv8(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = self.conv9(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = self.conv10(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w"
      },
      "source": [
        "cnn_net = CNN()#.double()\n",
        "cnn_net = cnn_net.to(\"cuda\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO37uxDTXDBV",
        "outputId": "84b31fa4-d9ce-4ab3-8203-6940f9631e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "print(cnn_net)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 28, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(28, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (batch_norm1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "  (dropout1): Dropout2d(p=0.05, inplace=False)\n",
            "  (dropout2): Dropout2d(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_cnn = nn.CrossEntropyLoss()\n",
        "optimizer_cnn = optim.SGD(cnn_net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFfAJZkcZEsY",
        "outputId": "8eb8c6c8-98ea-4f69-c8fb-7036d9402617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "acti = []\n",
        "loss_curi = []\n",
        "epochs = 300\n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "    ep_lossi = []\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer_cnn.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = cnn_net(inputs)\n",
        "        loss = criterion_cnn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_cnn.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        mini_batch = 50\n",
        "        if i % mini_batch == mini_batch-1:    # print every 50 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / mini_batch))\n",
        "            ep_lossi.append(running_loss/mini_batch) # loss per minibatch\n",
        "            running_loss = 0.0\n",
        "            \n",
        "    if(np.mean(ep_lossi) <= 0.01):\n",
        "      break;\n",
        "    loss_curi.append(np.mean(ep_lossi))   #loss per epoch            \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    50] loss: 1.815\n",
            "[1,   100] loss: 0.321\n",
            "[1,   150] loss: 0.131\n",
            "[1,   200] loss: 0.112\n",
            "[2,    50] loss: 0.069\n",
            "[2,   100] loss: 0.053\n",
            "[2,   150] loss: 0.058\n",
            "[2,   200] loss: 0.054\n",
            "[3,    50] loss: 0.041\n",
            "[3,   100] loss: 0.041\n",
            "[3,   150] loss: 0.040\n",
            "[3,   200] loss: 0.034\n",
            "[4,    50] loss: 0.029\n",
            "[4,   100] loss: 0.030\n",
            "[4,   150] loss: 0.036\n",
            "[4,   200] loss: 0.028\n",
            "[5,    50] loss: 0.023\n",
            "[5,   100] loss: 0.019\n",
            "[5,   150] loss: 0.021\n",
            "[5,   200] loss: 0.022\n",
            "[6,    50] loss: 0.018\n",
            "[6,   100] loss: 0.019\n",
            "[6,   150] loss: 0.021\n",
            "[6,   200] loss: 0.018\n",
            "[7,    50] loss: 0.013\n",
            "[7,   100] loss: 0.013\n",
            "[7,   150] loss: 0.016\n",
            "[7,   200] loss: 0.014\n",
            "[8,    50] loss: 0.009\n",
            "[8,   100] loss: 0.014\n",
            "[8,   150] loss: 0.015\n",
            "[8,   200] loss: 0.020\n",
            "[9,    50] loss: 0.012\n",
            "[9,   100] loss: 0.013\n",
            "[9,   150] loss: 0.011\n",
            "[9,   200] loss: 0.012\n",
            "[10,    50] loss: 0.007\n",
            "[10,   100] loss: 0.008\n",
            "[10,   150] loss: 0.009\n",
            "[10,   200] loss: 0.012\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE"
      },
      "source": [
        "torch.save(cnn_net.state_dict(),\"/content/drive/My Drive/Research/train_begining_layers_vs_last_layers/cnn_net_10layer.pt\")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "outputId": "12d5d8fd-57ad-44c9-8995-0f87412be634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        outputs = cnn_net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the %d train images: %d %%' % (total,  100 * correct / total))\n",
        "print(total,correct)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 60000 train images: 99 %\n",
            "60000 59861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WqTm-aW-TGU",
        "outputId": "09c8298b-a4b5-47aa-fa19-eaa7b4517491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "out = []\n",
        "pred = []\n",
        "cnn_net.eval()\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(\"cuda\"),labels.to(\"cuda\")\n",
        "        out.append(labels.cpu().numpy())\n",
        "        outputs= cnn_net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        pred.append(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(total,correct)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n",
            "10000 9933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUvZSREgEct3"
      },
      "source": [
        "classes = ['0','1','2','3','4','5','6','7','8','9']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ1yPyXRBNT4",
        "outputId": "20921bd7-c8ee-48ac-eae2-2d0f9c885def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(\"cuda\"),labels.to(\"cuda\")\n",
        "        outputs = cnn_net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of     0 : 100 %\n",
            "Accuracy of     1 : 100 %\n",
            "Accuracy of     2 : 100 %\n",
            "Accuracy of     3 : 100 %\n",
            "Accuracy of     4 : 100 %\n",
            "Accuracy of     5 : 90 %\n",
            "Accuracy of     6 : 100 %\n",
            "Accuracy of     7 : 100 %\n",
            "Accuracy of     8 : 100 %\n",
            "Accuracy of     9 : 100 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzU_HuQnEB29"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}