{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 170008576/170498071 [00:17<00:00, 11916937.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "foreground_classes = {'plane', 'car', 'bird'}\n",
    "\n",
    "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
    "\n",
    "# print(type(foreground_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "170500096it [00:30, 11916937.06it/s]                               "
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "background_data=[]\n",
    "background_label=[]\n",
    "foreground_data=[]\n",
    "foreground_label=[]\n",
    "batch_size=10\n",
    "\n",
    "for i in range(5000):   #5000*batch_size = 50000 data points\n",
    "    images, labels = dataiter.next()\n",
    "    for j in range(batch_size):\n",
    "        if(classes[labels[j]] in background_classes):\n",
    "            img = images[j].tolist()\n",
    "            background_data.append(img)\n",
    "            background_label.append(labels[j])\n",
    "        else:\n",
    "            img = images[j].tolist()\n",
    "            foreground_data.append(img)\n",
    "            foreground_label.append(labels[j])\n",
    "            \n",
    "foreground_data = torch.tensor(foreground_data)\n",
    "foreground_label = torch.tensor(foreground_label)\n",
    "background_data = torch.tensor(background_data)\n",
    "background_label = torch.tensor(background_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img#.numpy()\n",
    "    plt.imshow(np.transpose(npimg, axes = (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = torch.cat((background_data[0],background_data[1],background_data[2]),1)\n",
    "# imshow(img1)\n",
    "# img2 = torch.cat((background_data[27],background_data[3],background_data[43]),1)\n",
    "# imshow(img2)\n",
    "# img3 = torch.cat((img1,img2),2)\n",
    "# imshow(img3)\n",
    "# print(img2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
    "    \"\"\"\n",
    "      bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
    "      fg_idx : index of image to be used as foreground image from foreground data\n",
    "      fg : at what position/index foreground image has to be stored out of 0-8\n",
    "    \"\"\"\n",
    "    image_list=[]\n",
    "    j=0\n",
    "    for i in range(9):\n",
    "        if i != fg:\n",
    "            image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
    "            j+=1\n",
    "        else: \n",
    "            image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
    "            label = foreground_label[fg_idx]  #-7  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
    "    #image_list = np.concatenate(image_list ,axis=0)\n",
    "    image_list = torch.stack(image_list) \n",
    "    return image_list,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_num = 30000\n",
    "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
    "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
    "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
    "for i in range(desired_num):\n",
    "    bg_idx = np.random.randint(0,35000,8)\n",
    "    fg_idx = np.random.randint(0,15000)\n",
    "    fg = np.random.randint(0,9)\n",
    "    fore_idx.append(fg)\n",
    "    image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
    "    mosaic_list_of_images.append(image_list)\n",
    "    mosaic_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qw=10010\n",
    "\n",
    "print(fore_idx[qw])\n",
    "imshow(mosaic_list_of_images[qw][fore_idx[qw]])\n",
    "# print(mosaic_list_of_images[0])\n",
    "print(classes[mosaic_label[qw]]) # add 7 as we had subtracted 7 while saving\n",
    "\n",
    "# imshow(mosaic_list_of_images[13][2])\n",
    "# print(type(mosaic_list_of_images[1][0]))\n",
    "# print(mosaic_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MosaicDataset(Dataset):\n",
    "    \"\"\"MosaicDataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
    "        \"\"\"\n",
    "          Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mosaic = mosaic_list_of_images\n",
    "        self.label = mosaic_label\n",
    "        self.fore_idx = fore_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
    "\n",
    "batch = 250\n",
    "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
    "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wherenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Wherenet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc4 = nn.Linear(10,1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = torch.zeros([batch,9],dtype=torch.float64)\n",
    "        y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
    "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
    "        for i in range(9):\n",
    "            x[:,i] = self.helper(z[:,i])[:,0]\n",
    "        x = F.softmax(x,dim=1)   # alphas\n",
    "    \n",
    "        x1 = x[:,0]\n",
    "        torch.mul(x1[:,None,None,None],z[:,0])\n",
    "\n",
    "        for i in range(9):            \n",
    "            x1 = x[:,i]          \n",
    "            y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
    "        return y , x \n",
    "  \n",
    "    def helper(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Whatnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Whatnet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc4 = nn.Linear(10,3)\n",
    "\n",
    "    def forward(self,y):  #z batch of list of 9 images\n",
    "        y1 = self.pool(F.relu(self.conv1(y)))\n",
    "        y1 = self.pool(F.relu(self.conv2(y1)))\n",
    "        y1 = y1.view(-1, 16 * 5 * 5)\n",
    "\n",
    "        y1 = F.relu(self.fc1(y1))\n",
    "        y1 = F.relu(self.fc2(y1))\n",
    "        y1 = F.relu(self.fc3(y1))\n",
    "        y1 = self.fc4(y1)\n",
    "        return y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
    "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
    "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
    "for i in range(10000):\n",
    "    bg_idx = np.random.randint(0,35000,8)\n",
    "    fg_idx = np.random.randint(0,15000)\n",
    "    fg = np.random.randint(0,9)\n",
    "    fore_idx_test.append(fg)\n",
    "    image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
    "    test_images.append(image_list)\n",
    "    test_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
    "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = Wherenet().double()\n",
    "where = where.to(device)\n",
    "# out_where,alphas = where(input1)\n",
    "# out_where.shape,alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = Whatnet().double()\n",
    "what =what.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "focus_true_pred_true =0\n",
    "focus_false_pred_true =0\n",
    "focus_true_pred_false =0\n",
    "focus_false_pred_false =0\n",
    "\n",
    "argmax_more_than_half = 0\n",
    "argmax_less_than_half =0\n",
    "\n",
    "cifar_acc = []\n",
    "\n",
    "col1=[]\n",
    "col2=[]\n",
    "col3=[]\n",
    "col4=[]\n",
    "col5=[]\n",
    "col6=[]\n",
    "col7=[]\n",
    "col8=[]\n",
    "col9=[]\n",
    "col10=[]\n",
    "col11=[]\n",
    "col12=[]\n",
    "col13=[]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_where = optim.SGD(where.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_what = optim.SGD(what.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "nos_epochs = 150\n",
    "\n",
    "train_loss=[]\n",
    "test_loss =[]\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "ig = np.random.randint(0,250)\n",
    "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    focus_true_pred_true =0\n",
    "    focus_false_pred_true =0\n",
    "    focus_true_pred_false =0\n",
    "    focus_false_pred_false =0\n",
    "\n",
    "    argmax_more_than_half = 0\n",
    "    argmax_less_than_half =0\n",
    "\n",
    "    running_loss = 0.0\n",
    "    cnt=0\n",
    "    c = 0\n",
    "    iteration = desired_num // batch\n",
    "\n",
    "    #training data set\n",
    "\n",
    "    for i, data in  enumerate(train_loader):\n",
    "        inputs , labels , fore_idx = data\n",
    "        inputs,labels,fore_idx = inputs.to(device),labels.to(device),fore_idx.to(device)\n",
    "        # zero the parameter gradients\n",
    "        \n",
    "        optimizer_what.zero_grad()\n",
    "        optimizer_where.zero_grad()\n",
    "        \n",
    "        \n",
    "        avg_inp,alphas = where(inputs)\n",
    "        \n",
    "        outputs = what(avg_inp)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        \n",
    "        # display plots \n",
    "#         if(c==0): \n",
    "#             disp_plot(inputs[ig,:],avg_inp[ig,:],ig,labels[ig].item(),predicted[ig].item(), alphas[ig,:], fore_idx[ig].item())\n",
    "#             c+=1\n",
    "        \n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward() \n",
    "        \n",
    "        optimizer_what.step()\n",
    "        optimizer_where.step() \n",
    "        \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if cnt % 40 == 39:    # print every 6 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / 40))\n",
    "            running_loss = 0.0\n",
    "        cnt=cnt+1\n",
    "    \n",
    "        if epoch % 5 == 4:\n",
    "            for j in range (batch):\n",
    "                focus = torch.argmax(alphas[j])\n",
    "\n",
    "                if(alphas[j][focus] >= 0.5):\n",
    "                    argmax_more_than_half +=1\n",
    "                else:\n",
    "                    argmax_less_than_half +=1\n",
    "\n",
    "                if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
    "                    focus_true_pred_true += 1\n",
    "\n",
    "                elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
    "                    focus_false_pred_true +=1\n",
    "\n",
    "                elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
    "                    focus_true_pred_false +=1\n",
    "\n",
    "                elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
    "                    focus_false_pred_false +=1\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        col1.append(epoch)\n",
    "        col2.append(argmax_more_than_half)\n",
    "        col3.append(argmax_less_than_half)\n",
    "        col4.append(focus_true_pred_true)\n",
    "        col5.append(focus_false_pred_true)\n",
    "        col6.append(focus_true_pred_false)\n",
    "        col7.append(focus_false_pred_false)\n",
    "\n",
    "    #************************************************************************\n",
    "        #testing data set  \n",
    "        with torch.no_grad():\n",
    "            full_batch_true = 0\n",
    "            \n",
    "            focus_true_pred_true =0\n",
    "            focus_false_pred_true =0\n",
    "            focus_true_pred_false =0\n",
    "            focus_false_pred_false =0\n",
    "            argmax_more_than_half = 0\n",
    "            argmax_less_than_half =0\n",
    "            for data in trainloader:\n",
    "                inputs,labels = data\n",
    "                \n",
    "                inputs,labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = what(inputs.double())\n",
    "                \n",
    "                _,predicted = torch.max(outputs.data,1)\n",
    "                #print(predicted.cpu().numpy(),\"labels\",labels.cpu().numpy())\n",
    "                full_batch_true+=sum(predicted.cpu().numpy()== labels.cpu().numpy())\n",
    "            \n",
    "            cifar_acc.append(full_batch_true)\n",
    "            print(\"focibly_true_accuracy: \",full_batch_true)\n",
    "            \n",
    "            \n",
    "            for data in test_loader:\n",
    "                inputs, labels , fore_idx = data\n",
    "                inputs,labels,fore_idx = inputs.to(device),labels.to(device),fore_idx.to(device) \n",
    "#                 print(inputs.shtorch.save(where.state_dict(),\"model_epoch\"+str(epoch)+\".pt\")ape,labels.shape)\n",
    "                avg_inp,alphas = where(inputs)\n",
    "                outputs = what(avg_inp)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                for j in range (batch):\n",
    "                    focus = torch.argmax(alphas[j])\n",
    "\n",
    "                    if(alphas[j][focus] >= 0.5):\n",
    "                        argmax_more_than_half +=1\n",
    "                    else:\n",
    "                        argmax_less_than_half +=1\n",
    "\n",
    "                    if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
    "                        focus_true_pred_true += 1\n",
    "\n",
    "                    elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
    "                        focus_false_pred_true +=1\n",
    "\n",
    "                    elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
    "                        focus_true_pred_false +=1\n",
    "\n",
    "                    elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
    "                        focus_false_pred_false +=1\n",
    "\n",
    "        col8.append(argmax_more_than_half)\n",
    "        col9.append(argmax_less_than_half)\n",
    "        col10.append(focus_true_pred_true)\n",
    "        col11.append(focus_false_pred_true)\n",
    "        col12.append(focus_true_pred_false)\n",
    "        col13.append(focus_false_pred_false)\n",
    "        torch.save(where.state_dict(),\"weights_forcibly_true/where_model_epoch\"+str(epoch)+\".pt\")\n",
    "        torch.save(what.state_dict(),\"weights_forcibly_true/what_model_epoch\"+str(epoch)+\".pt\")\n",
    "    \n",
    "print('Finished Training')\n",
    "torch.save(where.state_dict(),\"weights_forcibly_true/where_model_epoch\"+str(nos_epochs)+\".pt\")\n",
    "torch.save(what.state_dict(),\"weights_forcibly_true/what_model_epoch\"+str(epoch)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_acc = 0 \n",
    "for data in train_loader:\n",
    "    inputs,labels,fore_idx = data\n",
    "    inputs,labels,fore_idx = inputs.to(device), labels.to(device),fore_idx.to(device)\n",
    "    avg_inp,alphas = where(inputs)\n",
    "    outputs = what(avg_inp)\n",
    "    _,predicted = torch.max(outputs.data,1)\n",
    "    #print(predicted.cpu().numpy(),\"labels\",labels.cpu().numpy())\n",
    "    full_train_acc+=sum(predicted.cpu().numpy()== labels.cpu().numpy())\n",
    "print(\"mosaic_data_training_accuracy :\",full_train_acc/30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_acc = 0 \n",
    "for data in test_loader:\n",
    "    inputs,labels,fore_idx = data\n",
    "    inputs,labels,fore_idx = inputs.to(device), labels.to(device),fore_idx.to(device)\n",
    "    avg_inp,alphas = where(inputs)\n",
    "    outputs = what(avg_inp)\n",
    "    _,predicted = torch.max(outputs.data,1)\n",
    "    #print(predicted.cpu().numpy(),\"labels\",labels.cpu().numpy())\n",
    "    full_test_acc+=sum(predicted.cpu().numpy()== labels.cpu().numpy())\n",
    "print(\"mosaic_data_test_accuracy :\",full_test_acc/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_train[columns[0]] = col1\n",
    "df_train[columns[1]] = col2\n",
    "df_train[columns[2]] = col3\n",
    "df_train[columns[3]] = col4\n",
    "df_train[columns[4]] = col5\n",
    "df_train[columns[5]] = col6\n",
    "df_train[columns[6]] = col7\n",
    "df_test[columns[0]] = col1\n",
    "df_test[columns[1]] = col8\n",
    "df_test[columns[2]] = col9\n",
    "df_test[columns[3]] = col10\n",
    "df_test[columns[4]] = col11\n",
    "df_test[columns[5]] = col12\n",
    "df_test[columns[6]] = col13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(col1,col2, label='argmax > 0.5')\n",
    "plt.plot(col1,col3, label='argmax < 0.5')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"training data\")\n",
    "plt.title(\"On Training set\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
    "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
    "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
    "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
    "plt.title(\"On Training set\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"training data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(col1,col8, label='argmax > 0.5')\n",
    "plt.plot(col1,col9, label='argmax < 0.5')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Testing data\")\n",
    "plt.title(\"On Testing set\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
    "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
    "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
    "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
    "plt.title(\"On Testing set\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Testing data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cifar_acc,\"forcibly true accuracy\")\n",
    "plt.xlabel(\"every 5th epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"forcibly true accuracy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
