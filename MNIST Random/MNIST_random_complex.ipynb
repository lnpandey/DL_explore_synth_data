{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lR-eQfx0acq8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "HxCE5TSmap0T",
    "outputId": "7ff8a57b-b510-46c7-b7b0-02dbd3142dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yh4EScpqacrC"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.CenterCrop((28,28)),transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "YoAqFwqpacrH",
    "outputId": "c9610402-ac0b-468a-fa2f-85f802ec93dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:03, 2828973.15it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 334226.51it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 1128761.80it/s]                             \n",
      "8192it [00:00, 132596.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56x0FjYZacrM"
   },
   "outputs": [],
   "source": [
    "# index = [np.where(mnist_trainset.targets==0)[0] , np.where(mnist_trainset.targets==1)[0] ]\n",
    "# index = np.concatenate(index,axis=0)\n",
    "# len(index) #12665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_8snSm1acrR"
   },
   "outputs": [],
   "source": [
    "index = np.where(np.logical_and(mnist_trainset.targets!=0,mnist_trainset.targets!=1))[0]  #47335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vYhiSaAnacrW",
    "outputId": "69f27c85-a282-469a-86ec-1c7ee05c057e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23684 23651\n"
     ]
    }
   ],
   "source": [
    "values = np.random.choice([0,1],size= 47335) \n",
    "print(sum(values ==0),sum(values==1))\n",
    "mnist_trainset.targets[index] = torch.Tensor(values).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8WPVHnPacrd"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=256,shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7L7ocAcracri"
   },
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=256,shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdhAr2p6acrm"
   },
   "outputs": [],
   "source": [
    "classes = ('zero', 'one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhUOj6Tnacrr"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vVgW5hBkacrv",
    "outputId": "976e4a32-6d20-4a22-943d-04aa6b41ca55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUtA80KCacr1"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "Xv34FfAdacr5",
    "outputId": "972614b1-7e5b-4937-bf25-226008aa2788"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB4CAYAAADi1gmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    one  zero  zero   one   one  zero   one   one   one  zero\n"
     ]
    }
   ],
   "source": [
    "imshow(torchvision.utils.make_grid(images[:10]))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ss-jhHRIacr-"
   },
   "outputs": [],
   "source": [
    "class Conv_module(nn.Module):\n",
    "    def __init__(self,inp_ch,f,s,k,pad):\n",
    "        super(Conv_module,self).__init__()\n",
    "        self.inp_ch = inp_ch\n",
    "        self.f = f\n",
    "        self.s = s \n",
    "        self.k = k \n",
    "        self.pad = pad\n",
    "        \n",
    "        \n",
    "        self.conv = nn.Conv2d(self.inp_ch,self.f,k,stride=s,padding=self.pad)\n",
    "        self.bn = nn.BatchNorm2d(self.f)\n",
    "        self.act = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51c92MhjacsC"
   },
   "outputs": [],
   "source": [
    "class inception_module(nn.Module):\n",
    "    def __init__(self,inp_ch,f0,f1):\n",
    "        super(inception_module, self).__init__()\n",
    "        self.inp_ch = inp_ch\n",
    "        self.f0 = f0\n",
    "        self.f1 = f1\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv1 = Conv_module(self.inp_ch,self.f0,1,1,pad=0)\n",
    "        self.conv3 = Conv_module(self.inp_ch,self.f1,1,3,pad=1)\n",
    "        #self.conv1 = nn.Conv2d(3,self.f0,1)\n",
    "        #self.conv3 = nn.Conv2d(3,self.f1,3,padding=1)\n",
    "    def forward(self,x):\n",
    "        x1 = self.conv1.forward(x)\n",
    "        x3 = self.conv3.forward(x)\n",
    "        #print(x1.shape,x3.shape)\n",
    "        \n",
    "        x = torch.cat((x1,x3),dim=1)\n",
    "        \n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Tl67apKacsG"
   },
   "outputs": [],
   "source": [
    "class downsample_module(nn.Module):\n",
    "    def __init__(self,inp_ch,f):\n",
    "        super(downsample_module,self).__init__()\n",
    "        self.inp_ch = inp_ch\n",
    "        self.f = f\n",
    "        self.conv = Conv_module(self.inp_ch,self.f,2,3,pad=0)\n",
    "        self.pool = nn.MaxPool2d(3,stride=2,padding=0)\n",
    "    def forward(self,x):\n",
    "        x1 = self.conv(x)\n",
    "        #print(x1.shape)\n",
    "        x2 = self.pool(x)\n",
    "        #print(x2.shape)\n",
    "        x = torch.cat((x1,x2),dim=1)\n",
    "        \n",
    "        return x,x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RKEYiG7acsJ"
   },
   "outputs": [],
   "source": [
    "class inception_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(inception_net,self).__init__()\n",
    "        self.conv1 = Conv_module(1,96,1,3,0)\n",
    "        \n",
    "        self.incept1 = inception_module(96,32,32)\n",
    "        self.incept2 = inception_module(64,32,48)\n",
    "        \n",
    "        self.downsample1 = downsample_module(80,80)\n",
    "        \n",
    "        self.incept3 = inception_module(160,112,48)\n",
    "        self.incept4 = inception_module(160,96,64)\n",
    "        self.incept5 = inception_module(160,80,80)\n",
    "        self.incept6 = inception_module(160,48,96)\n",
    "        \n",
    "        self.downsample2 = downsample_module(144,96)\n",
    "        \n",
    "        self.incept7 = inception_module(240,176,60)\n",
    "        self.incept8 = inception_module(236,176,60)\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.linear = nn.Linear(236,10)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1.forward(x)\n",
    "        #act1 = x\n",
    "        \n",
    "        x = self.incept1.forward(x)\n",
    "        #act2 = x\n",
    "        \n",
    "        x = self.incept2.forward(x)\n",
    "        #act3 = x\n",
    "        \n",
    "        x,act4 = self.downsample1.forward(x)\n",
    "        \n",
    "        x = self.incept3.forward(x)\n",
    "        #act5 = x\n",
    "        \n",
    "        x = self.incept4.forward(x)\n",
    "        #act6 = x\n",
    "        \n",
    "        x = self.incept5.forward(x)\n",
    "        #act7 = x\n",
    "        \n",
    "        x = self.incept6.forward(x)\n",
    "        #act8 = x\n",
    "        \n",
    "        x,act9 = self.downsample2.forward(x)\n",
    "        \n",
    "        x = self.incept7.forward(x)\n",
    "        #act10 = x\n",
    "        x = self.incept8.forward(x)\n",
    "        #act11 = x\n",
    "        #print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,1*1*236)\n",
    "        x = self.linear(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rByxqKdOacsM"
   },
   "outputs": [],
   "source": [
    "inc = inception_net()\n",
    "inc = inc.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imWjagA2acsO"
   },
   "outputs": [],
   "source": [
    "criterion_inception = nn.CrossEntropyLoss()\n",
    "optimizer_inception = optim.SGD(inc.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "r5mCNr38acsR",
    "outputId": "5dd5611c-c82b-467c-fd88-e128fda57dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 0.766\n",
      "[1,   100] loss: 0.584\n",
      "[1,   150] loss: 0.576\n",
      "[1,   200] loss: 0.568\n",
      "[2,    50] loss: 0.561\n",
      "[2,   100] loss: 0.563\n",
      "[2,   150] loss: 0.562\n",
      "[2,   200] loss: 0.555\n",
      "[3,    50] loss: 0.552\n",
      "[3,   100] loss: 0.555\n",
      "[3,   150] loss: 0.556\n",
      "[3,   200] loss: 0.549\n",
      "[4,    50] loss: 0.545\n",
      "[4,   100] loss: 0.549\n",
      "[4,   150] loss: 0.551\n",
      "[4,   200] loss: 0.545\n",
      "[5,    50] loss: 0.540\n",
      "[5,   100] loss: 0.542\n",
      "[5,   150] loss: 0.547\n",
      "[5,   200] loss: 0.540\n",
      "[6,    50] loss: 0.531\n",
      "[6,   100] loss: 0.537\n",
      "[6,   150] loss: 0.544\n",
      "[6,   200] loss: 0.539\n",
      "[7,    50] loss: 0.520\n",
      "[7,   100] loss: 0.536\n",
      "[7,   150] loss: 0.539\n",
      "[7,   200] loss: 0.537\n",
      "[8,    50] loss: 0.510\n",
      "[8,   100] loss: 0.531\n",
      "[8,   150] loss: 0.538\n",
      "[8,   200] loss: 0.530\n",
      "[9,    50] loss: 0.500\n",
      "[9,   100] loss: 0.522\n",
      "[9,   150] loss: 0.544\n",
      "[9,   200] loss: 0.526\n",
      "[10,    50] loss: 0.491\n",
      "[10,   100] loss: 0.509\n",
      "[10,   150] loss: 0.543\n",
      "[10,   200] loss: 0.520\n",
      "[11,    50] loss: 0.472\n",
      "[11,   100] loss: 0.496\n",
      "[11,   150] loss: 0.539\n",
      "[11,   200] loss: 0.516\n",
      "[12,    50] loss: 0.451\n",
      "[12,   100] loss: 0.472\n",
      "[12,   150] loss: 0.542\n",
      "[12,   200] loss: 0.517\n",
      "[13,    50] loss: 0.432\n",
      "[13,   100] loss: 0.465\n",
      "[13,   150] loss: 0.541\n",
      "[13,   200] loss: 0.521\n",
      "[14,    50] loss: 0.422\n",
      "[14,   100] loss: 0.462\n",
      "[14,   150] loss: 0.528\n",
      "[14,   200] loss: 0.513\n",
      "[15,    50] loss: 0.385\n",
      "[15,   100] loss: 0.433\n",
      "[15,   150] loss: 0.514\n",
      "[15,   200] loss: 0.493\n",
      "[16,    50] loss: 0.378\n",
      "[16,   100] loss: 0.445\n",
      "[16,   150] loss: 0.511\n",
      "[16,   200] loss: 0.480\n",
      "[17,    50] loss: 0.346\n",
      "[17,   100] loss: 0.424\n",
      "[17,   150] loss: 0.504\n",
      "[17,   200] loss: 0.461\n",
      "[18,    50] loss: 0.336\n",
      "[18,   100] loss: 0.411\n",
      "[18,   150] loss: 0.485\n",
      "[18,   200] loss: 0.444\n",
      "[19,    50] loss: 0.302\n",
      "[19,   100] loss: 0.403\n",
      "[19,   150] loss: 0.460\n",
      "[19,   200] loss: 0.414\n",
      "[20,    50] loss: 0.306\n",
      "[20,   100] loss: 0.379\n",
      "[20,   150] loss: 0.444\n",
      "[20,   200] loss: 0.368\n",
      "[21,    50] loss: 0.297\n",
      "[21,   100] loss: 0.349\n",
      "[21,   150] loss: 0.414\n",
      "[21,   200] loss: 0.352\n",
      "[22,    50] loss: 0.309\n",
      "[22,   100] loss: 0.341\n",
      "[22,   150] loss: 0.394\n",
      "[22,   200] loss: 0.321\n",
      "[23,    50] loss: 0.296\n",
      "[23,   100] loss: 0.337\n",
      "[23,   150] loss: 0.368\n",
      "[23,   200] loss: 0.299\n",
      "[24,    50] loss: 0.276\n",
      "[24,   100] loss: 0.319\n",
      "[24,   150] loss: 0.350\n",
      "[24,   200] loss: 0.286\n",
      "[25,    50] loss: 0.267\n",
      "[25,   100] loss: 0.294\n",
      "[25,   150] loss: 0.322\n",
      "[25,   200] loss: 0.266\n",
      "[26,    50] loss: 0.257\n",
      "[26,   100] loss: 0.262\n",
      "[26,   150] loss: 0.306\n",
      "[26,   200] loss: 0.251\n",
      "[27,    50] loss: 0.260\n",
      "[27,   100] loss: 0.261\n",
      "[27,   150] loss: 0.254\n",
      "[27,   200] loss: 0.240\n",
      "[28,    50] loss: 0.213\n",
      "[28,   100] loss: 0.233\n",
      "[28,   150] loss: 0.242\n",
      "[28,   200] loss: 0.230\n",
      "[29,    50] loss: 0.192\n",
      "[29,   100] loss: 0.209\n",
      "[29,   150] loss: 0.234\n",
      "[29,   200] loss: 0.220\n",
      "[30,    50] loss: 0.196\n",
      "[30,   100] loss: 0.214\n",
      "[30,   150] loss: 0.218\n",
      "[30,   200] loss: 0.205\n",
      "[31,    50] loss: 0.173\n",
      "[31,   100] loss: 0.178\n",
      "[31,   150] loss: 0.200\n",
      "[31,   200] loss: 0.181\n",
      "[32,    50] loss: 0.161\n",
      "[32,   100] loss: 0.162\n",
      "[32,   150] loss: 0.181\n",
      "[32,   200] loss: 0.166\n",
      "[33,    50] loss: 0.164\n",
      "[33,   100] loss: 0.165\n",
      "[33,   150] loss: 0.179\n",
      "[33,   200] loss: 0.156\n",
      "[34,    50] loss: 0.148\n",
      "[34,   100] loss: 0.146\n",
      "[34,   150] loss: 0.159\n",
      "[34,   200] loss: 0.145\n",
      "[35,    50] loss: 0.138\n",
      "[35,   100] loss: 0.140\n",
      "[35,   150] loss: 0.141\n",
      "[35,   200] loss: 0.143\n",
      "[36,    50] loss: 0.134\n",
      "[36,   100] loss: 0.123\n",
      "[36,   150] loss: 0.134\n",
      "[36,   200] loss: 0.135\n",
      "[37,    50] loss: 0.119\n",
      "[37,   100] loss: 0.116\n",
      "[37,   150] loss: 0.125\n",
      "[37,   200] loss: 0.119\n",
      "[38,    50] loss: 0.117\n",
      "[38,   100] loss: 0.106\n",
      "[38,   150] loss: 0.120\n",
      "[38,   200] loss: 0.119\n",
      "[39,    50] loss: 0.102\n",
      "[39,   100] loss: 0.091\n",
      "[39,   150] loss: 0.103\n",
      "[39,   200] loss: 0.103\n",
      "[40,    50] loss: 0.097\n",
      "[40,   100] loss: 0.086\n",
      "[40,   150] loss: 0.100\n",
      "[40,   200] loss: 0.101\n",
      "[41,    50] loss: 0.089\n",
      "[41,   100] loss: 0.087\n",
      "[41,   150] loss: 0.086\n",
      "[41,   200] loss: 0.099\n",
      "[42,    50] loss: 0.083\n",
      "[42,   100] loss: 0.083\n",
      "[42,   150] loss: 0.084\n",
      "[42,   200] loss: 0.079\n",
      "[43,    50] loss: 0.082\n",
      "[43,   100] loss: 0.079\n",
      "[43,   150] loss: 0.077\n",
      "[43,   200] loss: 0.077\n",
      "[44,    50] loss: 0.066\n",
      "[44,   100] loss: 0.071\n",
      "[44,   150] loss: 0.077\n",
      "[44,   200] loss: 0.066\n",
      "[45,    50] loss: 0.067\n",
      "[45,   100] loss: 0.073\n",
      "[45,   150] loss: 0.074\n",
      "[45,   200] loss: 0.057\n",
      "[46,    50] loss: 0.069\n",
      "[46,   100] loss: 0.058\n",
      "[46,   150] loss: 0.059\n",
      "[46,   200] loss: 0.047\n",
      "[47,    50] loss: 0.057\n",
      "[47,   100] loss: 0.052\n",
      "[47,   150] loss: 0.057\n",
      "[47,   200] loss: 0.054\n",
      "[48,    50] loss: 0.050\n",
      "[48,   100] loss: 0.053\n",
      "[48,   150] loss: 0.053\n",
      "[48,   200] loss: 0.047\n",
      "[49,    50] loss: 0.041\n",
      "[49,   100] loss: 0.050\n",
      "[49,   150] loss: 0.066\n",
      "[49,   200] loss: 0.053\n",
      "[50,    50] loss: 0.051\n",
      "[50,   100] loss: 0.051\n",
      "[50,   150] loss: 0.062\n",
      "[50,   200] loss: 0.058\n",
      "[51,    50] loss: 0.049\n",
      "[51,   100] loss: 0.053\n",
      "[51,   150] loss: 0.062\n",
      "[51,   200] loss: 0.051\n",
      "[52,    50] loss: 0.040\n",
      "[52,   100] loss: 0.048\n",
      "[52,   150] loss: 0.057\n",
      "[52,   200] loss: 0.057\n",
      "[53,    50] loss: 0.035\n",
      "[53,   100] loss: 0.051\n",
      "[53,   150] loss: 0.046\n",
      "[53,   200] loss: 0.054\n",
      "[54,    50] loss: 0.034\n",
      "[54,   100] loss: 0.045\n",
      "[54,   150] loss: 0.047\n",
      "[54,   200] loss: 0.043\n",
      "[55,    50] loss: 0.035\n",
      "[55,   100] loss: 0.043\n",
      "[55,   150] loss: 0.051\n",
      "[55,   200] loss: 0.047\n",
      "[56,    50] loss: 0.035\n",
      "[56,   100] loss: 0.045\n",
      "[56,   150] loss: 0.054\n",
      "[56,   200] loss: 0.040\n",
      "[57,    50] loss: 0.037\n",
      "[57,   100] loss: 0.042\n",
      "[57,   150] loss: 0.046\n",
      "[57,   200] loss: 0.042\n",
      "[58,    50] loss: 0.035\n",
      "[58,   100] loss: 0.041\n",
      "[58,   150] loss: 0.038\n",
      "[58,   200] loss: 0.045\n",
      "[59,    50] loss: 0.033\n",
      "[59,   100] loss: 0.044\n",
      "[59,   150] loss: 0.042\n",
      "[59,   200] loss: 0.033\n",
      "[60,    50] loss: 0.043\n",
      "[60,   100] loss: 0.039\n",
      "[60,   150] loss: 0.046\n",
      "[60,   200] loss: 0.040\n",
      "[61,    50] loss: 0.035\n",
      "[61,   100] loss: 0.038\n",
      "[61,   150] loss: 0.034\n",
      "[61,   200] loss: 0.036\n",
      "[62,    50] loss: 0.032\n",
      "[62,   100] loss: 0.036\n",
      "[62,   150] loss: 0.036\n",
      "[62,   200] loss: 0.025\n",
      "[63,    50] loss: 0.040\n",
      "[63,   100] loss: 0.035\n",
      "[63,   150] loss: 0.039\n",
      "[63,   200] loss: 0.044\n",
      "[64,    50] loss: 0.033\n",
      "[64,   100] loss: 0.041\n",
      "[64,   150] loss: 0.037\n",
      "[64,   200] loss: 0.041\n",
      "[65,    50] loss: 0.029\n",
      "[65,   100] loss: 0.036\n",
      "[65,   150] loss: 0.046\n",
      "[65,   200] loss: 0.030\n",
      "[66,    50] loss: 0.044\n",
      "[66,   100] loss: 0.043\n",
      "[66,   150] loss: 0.043\n",
      "[66,   200] loss: 0.031\n",
      "[67,    50] loss: 0.034\n",
      "[67,   100] loss: 0.038\n",
      "[67,   150] loss: 0.037\n",
      "[67,   200] loss: 0.032\n",
      "[68,    50] loss: 0.034\n",
      "[68,   100] loss: 0.039\n",
      "[68,   150] loss: 0.044\n",
      "[68,   200] loss: 0.033\n",
      "[69,    50] loss: 0.032\n",
      "[69,   100] loss: 0.040\n",
      "[69,   150] loss: 0.037\n",
      "[69,   200] loss: 0.037\n",
      "[70,    50] loss: 0.027\n",
      "[70,   100] loss: 0.041\n",
      "[70,   150] loss: 0.028\n",
      "[70,   200] loss: 0.040\n",
      "[71,    50] loss: 0.026\n",
      "[71,   100] loss: 0.044\n",
      "[71,   150] loss: 0.031\n",
      "[71,   200] loss: 0.035\n",
      "[72,    50] loss: 0.024\n",
      "[72,   100] loss: 0.035\n",
      "[72,   150] loss: 0.039\n",
      "[72,   200] loss: 0.028\n",
      "[73,    50] loss: 0.031\n",
      "[73,   100] loss: 0.034\n",
      "[73,   150] loss: 0.042\n",
      "[73,   200] loss: 0.026\n",
      "[74,    50] loss: 0.023\n",
      "[74,   100] loss: 0.027\n",
      "[74,   150] loss: 0.031\n",
      "[74,   200] loss: 0.020\n",
      "[75,    50] loss: 0.021\n",
      "[75,   100] loss: 0.027\n",
      "[75,   150] loss: 0.035\n",
      "[75,   200] loss: 0.023\n",
      "[76,    50] loss: 0.027\n",
      "[76,   100] loss: 0.023\n",
      "[76,   150] loss: 0.043\n",
      "[76,   200] loss: 0.030\n",
      "[77,    50] loss: 0.023\n",
      "[77,   100] loss: 0.028\n",
      "[77,   150] loss: 0.027\n",
      "[77,   200] loss: 0.028\n",
      "[78,    50] loss: 0.025\n",
      "[78,   100] loss: 0.029\n",
      "[78,   150] loss: 0.028\n",
      "[78,   200] loss: 0.023\n",
      "[79,    50] loss: 0.025\n",
      "[79,   100] loss: 0.024\n",
      "[79,   150] loss: 0.043\n",
      "[79,   200] loss: 0.026\n",
      "[80,    50] loss: 0.024\n",
      "[80,   100] loss: 0.024\n",
      "[80,   150] loss: 0.039\n",
      "[80,   200] loss: 0.029\n",
      "[81,    50] loss: 0.026\n",
      "[81,   100] loss: 0.033\n",
      "[81,   150] loss: 0.033\n",
      "[81,   200] loss: 0.036\n",
      "[82,    50] loss: 0.026\n",
      "[82,   100] loss: 0.033\n",
      "[82,   150] loss: 0.030\n",
      "[82,   200] loss: 0.034\n",
      "[83,    50] loss: 0.024\n",
      "[83,   100] loss: 0.022\n",
      "[83,   150] loss: 0.026\n",
      "[83,   200] loss: 0.026\n",
      "[84,    50] loss: 0.019\n",
      "[84,   100] loss: 0.022\n",
      "[84,   150] loss: 0.023\n",
      "[84,   200] loss: 0.028\n",
      "[85,    50] loss: 0.015\n",
      "[85,   100] loss: 0.027\n",
      "[85,   150] loss: 0.020\n",
      "[85,   200] loss: 0.028\n",
      "[86,    50] loss: 0.018\n",
      "[86,   100] loss: 0.027\n",
      "[86,   150] loss: 0.024\n",
      "[86,   200] loss: 0.025\n",
      "[87,    50] loss: 0.018\n",
      "[87,   100] loss: 0.025\n",
      "[87,   150] loss: 0.021\n",
      "[87,   200] loss: 0.019\n",
      "[88,    50] loss: 0.018\n",
      "[88,   100] loss: 0.020\n",
      "[88,   150] loss: 0.019\n",
      "[88,   200] loss: 0.019\n",
      "[89,    50] loss: 0.019\n",
      "[89,   100] loss: 0.019\n",
      "[89,   150] loss: 0.022\n",
      "[89,   200] loss: 0.015\n",
      "[90,    50] loss: 0.020\n",
      "[90,   100] loss: 0.019\n",
      "[90,   150] loss: 0.025\n",
      "[90,   200] loss: 0.016\n",
      "[91,    50] loss: 0.019\n",
      "[91,   100] loss: 0.017\n",
      "[91,   150] loss: 0.024\n",
      "[91,   200] loss: 0.014\n",
      "[92,    50] loss: 0.021\n",
      "[92,   100] loss: 0.022\n",
      "[92,   150] loss: 0.017\n",
      "[92,   200] loss: 0.017\n",
      "[93,    50] loss: 0.019\n",
      "[93,   100] loss: 0.021\n",
      "[93,   150] loss: 0.018\n",
      "[93,   200] loss: 0.015\n",
      "[94,    50] loss: 0.015\n",
      "[94,   100] loss: 0.018\n",
      "[94,   150] loss: 0.016\n",
      "[94,   200] loss: 0.019\n",
      "[95,    50] loss: 0.014\n",
      "[95,   100] loss: 0.017\n",
      "[95,   150] loss: 0.019\n",
      "[95,   200] loss: 0.018\n",
      "[96,    50] loss: 0.015\n",
      "[96,   100] loss: 0.018\n",
      "[96,   150] loss: 0.017\n",
      "[96,   200] loss: 0.019\n",
      "[97,    50] loss: 0.013\n",
      "[97,   100] loss: 0.023\n",
      "[97,   150] loss: 0.015\n",
      "[97,   200] loss: 0.019\n",
      "[98,    50] loss: 0.015\n",
      "[98,   100] loss: 0.018\n",
      "[98,   150] loss: 0.018\n",
      "[98,   200] loss: 0.016\n",
      "[99,    50] loss: 0.015\n",
      "[99,   100] loss: 0.019\n",
      "[99,   150] loss: 0.023\n",
      "[99,   200] loss: 0.018\n",
      "[100,    50] loss: 0.019\n",
      "[100,   100] loss: 0.020\n",
      "[100,   150] loss: 0.024\n",
      "[100,   200] loss: 0.014\n",
      "[101,    50] loss: 0.020\n",
      "[101,   100] loss: 0.018\n",
      "[101,   150] loss: 0.027\n",
      "[101,   200] loss: 0.018\n",
      "[102,    50] loss: 0.023\n",
      "[102,   100] loss: 0.017\n",
      "[102,   150] loss: 0.026\n",
      "[102,   200] loss: 0.021\n",
      "[103,    50] loss: 0.024\n",
      "[103,   100] loss: 0.022\n",
      "[103,   150] loss: 0.027\n",
      "[103,   200] loss: 0.022\n",
      "[104,    50] loss: 0.020\n",
      "[104,   100] loss: 0.024\n",
      "[104,   150] loss: 0.020\n",
      "[104,   200] loss: 0.024\n",
      "[105,    50] loss: 0.014\n",
      "[105,   100] loss: 0.021\n",
      "[105,   150] loss: 0.016\n",
      "[105,   200] loss: 0.022\n",
      "[106,    50] loss: 0.013\n",
      "[106,   100] loss: 0.021\n",
      "[106,   150] loss: 0.017\n",
      "[106,   200] loss: 0.019\n",
      "[107,    50] loss: 0.012\n",
      "[107,   100] loss: 0.020\n",
      "[107,   150] loss: 0.018\n",
      "[107,   200] loss: 0.013\n",
      "[108,    50] loss: 0.010\n",
      "[108,   100] loss: 0.013\n",
      "[108,   150] loss: 0.015\n",
      "[108,   200] loss: 0.012\n",
      "[109,    50] loss: 0.010\n",
      "[109,   100] loss: 0.014\n",
      "[109,   150] loss: 0.013\n",
      "[109,   200] loss: 0.012\n",
      "[110,    50] loss: 0.009\n",
      "[110,   100] loss: 0.012\n",
      "[110,   150] loss: 0.012\n",
      "[110,   200] loss: 0.011\n",
      "[111,    50] loss: 0.011\n",
      "[111,   100] loss: 0.013\n",
      "[111,   150] loss: 0.010\n",
      "[111,   200] loss: 0.010\n",
      "[112,    50] loss: 0.010\n",
      "[112,   100] loss: 0.014\n",
      "[112,   150] loss: 0.012\n",
      "[112,   200] loss: 0.012\n",
      "[113,    50] loss: 0.011\n",
      "[113,   100] loss: 0.012\n",
      "[113,   150] loss: 0.015\n",
      "[113,   200] loss: 0.013\n",
      "[114,    50] loss: 0.012\n",
      "[114,   100] loss: 0.017\n",
      "[114,   150] loss: 0.019\n",
      "[114,   200] loss: 0.013\n",
      "[115,    50] loss: 0.015\n",
      "[115,   100] loss: 0.015\n",
      "[115,   150] loss: 0.017\n",
      "[115,   200] loss: 0.012\n",
      "[116,    50] loss: 0.016\n",
      "[116,   100] loss: 0.013\n",
      "[116,   150] loss: 0.023\n",
      "[116,   200] loss: 0.015\n",
      "[117,    50] loss: 0.015\n",
      "[117,   100] loss: 0.018\n",
      "[117,   150] loss: 0.022\n",
      "[117,   200] loss: 0.017\n",
      "[118,    50] loss: 0.016\n",
      "[118,   100] loss: 0.019\n",
      "[118,   150] loss: 0.024\n",
      "[118,   200] loss: 0.021\n",
      "[119,    50] loss: 0.022\n",
      "[119,   100] loss: 0.016\n",
      "[119,   150] loss: 0.023\n",
      "[119,   200] loss: 0.015\n",
      "[120,    50] loss: 0.015\n",
      "[120,   100] loss: 0.014\n",
      "[120,   150] loss: 0.018\n",
      "[120,   200] loss: 0.014\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "acti = []\n",
    "loss_curi = []\n",
    "for epoch in range(140): # loop over the dataset multiple times\n",
    "    ep_lossi = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_inception.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = inc(inputs)\n",
    "        loss = criterion_inception(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_inception.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\n",
    "            ep_lossi.append(running_loss/50) # loss per minibatch\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    loss_curi.append(np.mean(ep_lossi))   #loss per epoch\n",
    "#     if (epoch%5 == 0):\n",
    "#         _,actis= inc(inputs)\n",
    "#         acti.append(actis)\n",
    "    \n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IxXbhlbEacsW",
    "outputId": "c8b3ecbf-0835-4393-aa0e-80d9afb0f031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 60000 train images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "        outputs = inc(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 60000 train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U2kQXLzgacsa",
    "outputId": "2e6c1bce-1189-4b1f-e4b8-14567cbceb6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 58597)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5IcmEl2lacsd",
    "outputId": "b57a2378-e285-4030-9f88-05d22138a1af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 21 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "out = []\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(\"cuda\"),labels.to(\"cuda\")\n",
    "        out.append(labels.cpu().numpy())\n",
    "        outputs= inc(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred.append(predicted.cpu().numpy())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrlBRcSQacsg"
   },
   "outputs": [],
   "source": [
    "out = np.concatenate(out,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWyBhOPlacsi"
   },
   "outputs": [],
   "source": [
    "pred = np.concatenate(pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IJ1F7Lfdacsl",
    "outputId": "6b2aa392-c702-4bd5-baf9-b85fcbc03be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "index = np.logical_or(out ==1,out==0)\n",
    "print(index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h7PmLPkGacsn",
    "outputId": "54013986-c2c9-445c-970d-dbf055ef6266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99 %\n"
     ]
    }
   ],
   "source": [
    "acc = sum(out[index] == pred[index])/sum(index)\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "fvCi8x41acsq",
    "outputId": "229f63ac-ecf2-4c70-9437-55f24cbb51b6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f9b83d6e04fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdGNgi62acss"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_rand.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
