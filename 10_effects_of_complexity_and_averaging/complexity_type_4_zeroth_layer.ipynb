{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "complexity_type_4_ Zeroth_Layer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "guDi_gtH7IFF"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYu3ISwwGks"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guDi_gtH7IFF"
      },
      "source": [
        "# type 4 mosaic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IBs5VXs7HfZ"
      },
      "source": [
        "# y = np.random.randint(0,10,5000)\r\n",
        "# idx= []\r\n",
        "# for i in range(10):\r\n",
        "#     print(i,sum(y==i))\r\n",
        "#     idx.append(y==i)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MzwprbA57AS"
      },
      "source": [
        "# x = np.zeros((5000,2))\r\n",
        "\r\n",
        "# x[idx[0],:] = np.random.multivariate_normal(mean = [4,6.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[0]))\r\n",
        "\r\n",
        "# x[idx[1],:] = np.random.multivariate_normal(mean = [5.5,6],cov=[[0.01,0],[0,0.01]],size=sum(idx[1]))\r\n",
        "\r\n",
        "# x[idx[2],:] = np.random.multivariate_normal(mean = [4.5,4.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[2]))\r\n",
        "\r\n",
        "# x[idx[3],:] = np.random.multivariate_normal(mean = [3,3.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[3]))\r\n",
        "\r\n",
        "# x[idx[4],:] = np.random.multivariate_normal(mean = [2.5,5.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[4]))\r\n",
        "\r\n",
        "# x[idx[5],:] = np.random.multivariate_normal(mean = [3.5,8],cov=[[0.01,0],[0,0.01]],size=sum(idx[5]))\r\n",
        "\r\n",
        "# x[idx[6],:] = np.random.multivariate_normal(mean = [5.5,8],cov=[[0.01,0],[0,0.01]],size=sum(idx[6]))\r\n",
        "\r\n",
        "# x[idx[7],:] = np.random.multivariate_normal(mean = [7,6.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[7]))\r\n",
        "\r\n",
        "# x[idx[8],:] = np.random.multivariate_normal(mean = [6.5,4.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[8]))\r\n",
        "\r\n",
        "# x[idx[9],:] = np.random.multivariate_normal(mean = [5,3],cov=[[0.01,0],[0,0.01]],size=sum(idx[9]))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCtGoFVB5623"
      },
      "source": [
        "# plt.figure(figsize=(6,6))\r\n",
        "# for i in range(10):\r\n",
        "#     plt.scatter(x[idx[i],0],x[idx[i],1],label=\"class_\"+str(i))\r\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCOaX6Q356S1"
      },
      "source": [
        "# class SyntheticDataset(Dataset):\r\n",
        "#   \"\"\"MosaicDataset dataset.\"\"\"\r\n",
        "\r\n",
        "#   def __init__(self, x, y):\r\n",
        "#     \"\"\"\r\n",
        "#       Args:\r\n",
        "#         csv_file (string): Path to the csv file with annotations.\r\n",
        "#         root_dir (string): Directory with all the images.\r\n",
        "#         transform (callable, optional): Optional transform to be applied\r\n",
        "#             on a sample.\r\n",
        "#     \"\"\"\r\n",
        "#     self.x = x\r\n",
        "#     self.y = y\r\n",
        "#     #self.fore_idx = fore_idx\r\n",
        "    \r\n",
        "#   def __len__(self):\r\n",
        "#     return len(self.y)\r\n",
        "\r\n",
        "#   def __getitem__(self, idx):\r\n",
        "#     return self.x[idx] , self.y[idx] #, self.fore_idx[idx]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnF886Dc9R6-"
      },
      "source": [
        "# trainset = SyntheticDataset(x,y)\r\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\r\n",
        "# classes = ('zero','one','two','three','four','five','six','seven','eight','nine')\r\n",
        "\r\n",
        "# foreground_classes = {'zero','one','two'}\r\n",
        "# fg_used = '012'\r\n",
        "# fg1, fg2, fg3 = 0,1,2\r\n",
        "\r\n",
        "\r\n",
        "# all_classes = {'zero','one','two','three','four','five','six','seven','eight','nine'}\r\n",
        "# background_classes = all_classes - foreground_classes\r\n",
        "# background_classes"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTR_tYs19RlC"
      },
      "source": [
        "# dataiter = iter(trainloader)\r\n",
        "# background_data=[]\r\n",
        "# background_label=[]\r\n",
        "# foreground_data=[]\r\n",
        "# foreground_label=[]\r\n",
        "# batch_size=100\r\n",
        "\r\n",
        "# for i in range(50):\r\n",
        "#   images, labels = dataiter.next()\r\n",
        "#   for j in range(batch_size):\r\n",
        "#     if(classes[labels[j]] in background_classes):\r\n",
        "#       img = images[j].tolist()\r\n",
        "#       background_data.append(img)\r\n",
        "#       background_label.append(labels[j])\r\n",
        "#     else:\r\n",
        "#       img = images[j].tolist()\r\n",
        "#       foreground_data.append(img)\r\n",
        "#       foreground_label.append(labels[j])\r\n",
        "            \r\n",
        "# foreground_data = torch.tensor(foreground_data)\r\n",
        "# foreground_label = torch.tensor(foreground_label)\r\n",
        "# background_data = torch.tensor(background_data)\r\n",
        "# background_label = torch.tensor(background_label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dIQxt5b-HXy"
      },
      "source": [
        "# def create_mosaic_img(bg_idx,fg_idx,fg): \r\n",
        "#   \"\"\"\r\n",
        "#   bg_idx : list of indexes of background_data[] to be used as background images in mosaic\r\n",
        "#   fg_idx : index of image to be used as foreground image from foreground data\r\n",
        "#   fg : at what position/index foreground image has to be stored out of 0-8\r\n",
        "#   \"\"\"\r\n",
        "#   image_list=[]\r\n",
        "#   j=0\r\n",
        "#   for i in range(9):\r\n",
        "#     if i != fg:\r\n",
        "#       image_list.append(background_data[bg_idx[j]])\r\n",
        "#       j+=1\r\n",
        "#     else: \r\n",
        "#       image_list.append(foreground_data[fg_idx])\r\n",
        "#       label = foreground_label[fg_idx] - fg1  # minus fg1 because our fore ground classes are fg1,fg2,fg3 but we have to store it as 0,1,2\r\n",
        "#   #image_list = np.concatenate(image_list ,axis=0)\r\n",
        "#   image_list = torch.stack(image_list) \r\n",
        "#   return image_list,label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa7CFvfu-hE_"
      },
      "source": [
        "# # number of data points in bg class and fg class\r\n",
        "# nbg = sum(idx[3]) + sum(idx[4]) + sum(idx[5]) + sum(idx[6]) + sum(idx[7]) + sum(idx[8]) + sum(idx[9])\r\n",
        "# nfg   = sum(idx[0]) + sum(idx[1]) + sum(idx[2])\r\n",
        "\r\n",
        "# print(nbg, nfg, nbg+nfg)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLVolDGh9RY_"
      },
      "source": [
        "# desired_num = 3000\r\n",
        "# mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\r\n",
        "# fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \r\n",
        "# mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\r\n",
        "# list_set_labels = [] \r\n",
        "# for i in range(desired_num):\r\n",
        "#   set_idx = set()\r\n",
        "#   np.random.seed(i)\r\n",
        "#   bg_idx = np.random.randint(0,nbg,8)\r\n",
        "#   set_idx = set(background_label[bg_idx].tolist())\r\n",
        "#   fg_idx = np.random.randint(0,nfg)\r\n",
        "#   set_idx.add(foreground_label[fg_idx].item())\r\n",
        "#   fg = np.random.randint(0,9)\r\n",
        "#   fore_idx.append(fg)\r\n",
        "#   image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\r\n",
        "#   mosaic_list_of_images.append(image_list)\r\n",
        "#   mosaic_label.append(label)\r\n",
        "#   list_set_labels.append(set_idx)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm4jv30eD_hl"
      },
      "source": [
        "# data =  [{\"mosaic_list\":mosaic_list_of_images, \"mosaic_label\": mosaic_label, \"fore_idx\":fore_idx}]\r\n",
        "# np.save(\"type4_data_1.npy\",data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4ZKaqzq_vcD"
      },
      "source": [
        "# load mosaic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN7ItmyIEdnB"
      },
      "source": [
        "data = np.load(\"type4_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iifTn7hNEmCU"
      },
      "source": [
        "mosaic_list_of_images = data[0][\"mosaic_list\"]\r\n",
        "mosaic_label = data[0][\"mosaic_label\"]\r\n",
        "fore_idx = data[0][\"fore_idx\"]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syESDetXAPK2"
      },
      "source": [
        "class MosaicDataset1(Dataset):\r\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\r\n",
        "\r\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\r\n",
        "    \"\"\"\r\n",
        "      Args:\r\n",
        "        csv_file (string): Path to the csv file with annotations.\r\n",
        "        root_dir (string): Directory with all the images.\r\n",
        "        transform (callable, optional): Optional transform to be applied\r\n",
        "            on a sample.\r\n",
        "    \"\"\"\r\n",
        "    self.mosaic = mosaic_list\r\n",
        "    self.label = mosaic_label\r\n",
        "    self.fore_idx = fore_idx\r\n",
        "    \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.label)\r\n",
        "\r\n",
        "  def __getitem__(self, idx):\r\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5NPRPmb904"
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARLPPASQ_2gB"
      },
      "source": [
        "# models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN3Bbs8c0fA"
      },
      "source": [
        "class Focus_deep(nn.Module):\n",
        "    '''\n",
        "       deep focus network averaged at zeroth layer\n",
        "       input : elemental data\n",
        "    '''\n",
        "    def __init__(self,inputs,output,K,d):\n",
        "        super(Focus_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.K = K\n",
        "        self.d  = d\n",
        "        self.linear1 = nn.Linear(self.inputs,10)  #,self.output)\n",
        "        #self.linear2 = nn.Linear(50,50)\n",
        "        self.linear2 = nn.Linear(10,self.output) \n",
        "    def forward(self,z):\n",
        "        batch = z.shape[0]\n",
        "        x = torch.zeros([batch,self.K],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,self.d], dtype=torch.float64)\n",
        "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        #print(z[:,0].shape,z[:,self.d*0:self.d*0+self.d].shape)\n",
        "        for i in range(self.K):\n",
        "            x[:,i] = self.helper(z[:,i] )[:,0]  # self.d*i:self.d*i+self.d\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(self.K):\n",
        "            x1 = x[:,i]          \n",
        "            y = y+torch.mul(x1[:,None],z[:,i])  # self.d*i:self.d*i+self.d\n",
        "        return y , x \n",
        "    def helper(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      #x = F.relu(self.linear2(x))\n",
        "      x = self.linear2(x)\n",
        "      return x\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W0oKcClFZY"
      },
      "source": [
        "class Classification_deep(nn.Module):\n",
        "    '''\n",
        "       input : elemental data\n",
        "       deep classification module data averaged at zeroth layer\n",
        "    '''\n",
        "    def __init__(self,inputs,output):\n",
        "        super(Classification_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.linear1 = nn.Linear(self.inputs,10)\n",
        "        #self.linear2 = nn.Linear(50,50)\n",
        "        self.linear2 = nn.Linear(10,self.output)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      #x = F.relu(self.linear2(x))\n",
        "      x = self.linear2(x)\n",
        "      return x    "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAfQnNwgFYX"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,where,criter):\n",
        "  what.eval()\n",
        "  where.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx = data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      avg,alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9HQJMzxBhp"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2AlGgRa_6_H"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOfxUJZ_eFKw"
      },
      "source": [
        "number_runs = 20\n",
        "FTPT_analysis = pd.DataFrame(columns = [\"FTPT\",\"FFPT\", \"FTPF\",\"FFPF\"])\n",
        "for n in range(number_runs):\n",
        "  print(\"--\"*40)\n",
        "  \n",
        "  # instantiate focus and classification Model\n",
        "  torch.manual_seed(n)\n",
        "  where = Focus_deep(2,1,9,2).double()\n",
        "  torch.manual_seed(n)\n",
        "  what = Classification_deep(2,3).double()\n",
        "  where = where.to(\"cuda\")\n",
        "  what = what.to(\"cuda\")\n",
        "\n",
        "\n",
        "\n",
        "  # instantiate optimizer\n",
        "  optimizer_where = optim.Adam(where.parameters(),lr =0.01)#,momentum=0.9)\n",
        "  optimizer_what = optim.Adam(what.parameters(), lr=0.01)#,momentum=0.9)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  acti = []\n",
        "  analysis_data = []\n",
        "  loss_curi = []\n",
        "  epochs = 2000\n",
        "\n",
        "\n",
        "  # calculate zeroth epoch loss and FTPT values\n",
        "  running_loss,anlys_data = calculate_attn_loss(train_loader,what,where,criterion)\n",
        "  loss_curi.append(running_loss)\n",
        "  analysis_data.append(anlys_data)\n",
        "\n",
        "  print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "\n",
        "  # training starts \n",
        "  for epoch in range(epochs): # loop over the dataset multiple times\n",
        "    ep_lossi = []\n",
        "    running_loss = 0.0\n",
        "    what.train()\n",
        "    where.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      # get the inputs\n",
        "      inputs, labels,_ = data\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer_where.zero_grad()\n",
        "      optimizer_what.zero_grad()\n",
        "      \n",
        "      # forward + backward + optimize\n",
        "      avg, alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      loss.backward()\n",
        "      optimizer_where.step()\n",
        "      optimizer_what.step()\n",
        "\n",
        "    running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion)\n",
        "    analysis_data.append(anls_data)\n",
        "    print('epoch: [%d] loss: %.3f' %(epoch + 1,running_loss)) \n",
        "    loss_curi.append(running_loss)   #loss per epoch\n",
        "    if running_loss<=0.01:\n",
        "      break\n",
        "  print('Finished Training run ' +str(n))\n",
        "  analysis_data = np.array(analysis_data)\n",
        "  FTPT_analysis.loc[n] = analysis_data[-1,:4]/30\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "      images, labels,_ = data\n",
        "      images = images.double()\n",
        "      images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "      avg, alpha = where(images)\n",
        "      outputs  = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31RVViMkYM-"
      },
      "source": [
        "# plt.figure(figsize=(6,6))\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,0],label=\"ftpt\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,1],label=\"ffpt\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,2],label=\"ftpf\")\n",
        "# plt.plot(np.arange(0,epoch+2,1),analysis_data[:,3],label=\"ffpf\")\n",
        "\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvRPe6kn_-9b"
      },
      "source": [
        "# performance\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yEabNK9Q1bTE",
        "outputId": "1801e8a2-e609-4966-c414-b248335e87d6"
      },
      "source": [
        "plt.plot(loss_curi)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6fd9b75250>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBbboK0mtLTL",
        "outputId": "714b18be-3db6-480e-b82e-102e4c206f71"
      },
      "source": [
        "np.mean(np.array(FTPT_analysis),axis=0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([57.36166667, 28.27666667,  0.93666667, 13.425     ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYS7jRsCz30j"
      },
      "source": [
        "FTPT_analysis.to_csv(\"synthetic_zeroth_10_10.csv\",index=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwzQFzul37sQ"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "PzR8ISPlOSbP",
        "outputId": "2e484cc7-735b-482d-af8d-dde06f714759"
      },
      "source": [
        "FTPT_analysis"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FTPT</th>\n",
              "      <th>FFPT</th>\n",
              "      <th>FTPF</th>\n",
              "      <th>FFPF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68.833333</td>\n",
              "      <td>30.800000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>40.866667</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>56.966667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36.166667</td>\n",
              "      <td>34.666667</td>\n",
              "      <td>4.566667</td>\n",
              "      <td>24.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.466667</td>\n",
              "      <td>36.533333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71.033333</td>\n",
              "      <td>28.833333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>71.033333</td>\n",
              "      <td>28.833333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>82.266667</td>\n",
              "      <td>17.700000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>71.033333</td>\n",
              "      <td>28.833333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>93.066667</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.900000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>58.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>71.000000</td>\n",
              "      <td>28.866667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>81.133333</td>\n",
              "      <td>18.766667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>71.066667</td>\n",
              "      <td>28.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>34.266667</td>\n",
              "      <td>37.100000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>27.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>71.000000</td>\n",
              "      <td>28.900000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>76.200000</td>\n",
              "      <td>23.666667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6.733333</td>\n",
              "      <td>44.733333</td>\n",
              "      <td>9.133333</td>\n",
              "      <td>39.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>68.900000</td>\n",
              "      <td>30.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>70.966667</td>\n",
              "      <td>28.833333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          FTPT       FFPT      FTPF       FFPF\n",
              "0    68.833333  30.800000  0.066667   0.300000\n",
              "1     0.066667  40.866667  2.100000  56.966667\n",
              "2    36.166667  34.666667  4.566667  24.600000\n",
              "3     2.466667  36.533333  0.000000  61.000000\n",
              "4    71.033333  28.833333  0.066667   0.066667\n",
              "5    71.033333  28.833333  0.066667   0.066667\n",
              "6    82.266667  17.700000  0.033333   0.000000\n",
              "7    71.033333  28.833333  0.066667   0.066667\n",
              "8    93.066667   6.900000  0.033333   0.000000\n",
              "9     0.000000  40.900000  0.700000  58.400000\n",
              "10   71.000000  28.866667  0.100000   0.033333\n",
              "11   81.133333  18.766667  0.100000   0.000000\n",
              "12  100.000000   0.000000  0.000000   0.000000\n",
              "13   71.066667  28.900000  0.000000   0.033333\n",
              "14   34.266667  37.100000  1.333333  27.300000\n",
              "15   71.000000  28.900000  0.100000   0.000000\n",
              "16   76.200000  23.666667  0.133333   0.000000\n",
              "17    6.733333  44.733333  9.133333  39.400000\n",
              "18   68.900000  30.900000  0.000000   0.200000\n",
              "19   70.966667  28.833333  0.133333   0.066667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ch0nnjvUf4O"
      },
      "source": [
        "\r\n",
        "\r\n",
        "1.   7.55150000e+01, 2.43783333e+01, 6.00000000e-02, 4.66666667e-02\r\n",
        "2. \r\n",
        "3.  \r\n",
        "4.  \r\n",
        "5.  \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JUoGWONAXEk"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}