{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Synthetic elliptical blobs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYu3ISwwGks"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEp-LtqiWAf"
      },
      "source": [
        "mu1 = np.array([3,3,3,3,0])\n",
        "sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu2 = np.array([4,4,4,4,0])\n",
        "sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu3 = np.array([10,5,5,10,0])\n",
        "sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu4 = np.array([-10,-10,-10,-10,0])\n",
        "sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu5 = np.array([-21,4,4,-21,0])\n",
        "sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu6 = np.array([-10,18,18,-10,0])\n",
        "sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu7 = np.array([4,20,4,20,0])\n",
        "sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu8 = np.array([4,-20,-20,4,0])\n",
        "sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu9 = np.array([20,20,20,20,0])\n",
        "sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "mu10 = np.array([20,-10,-10,20,0])\n",
        "sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NshDNGjY2T3w"
      },
      "source": [
        "# mu1 = np.array([3,3,0,0,0])\n",
        "# sigma1 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu2 = np.array([4,4,0,0,0])\n",
        "# sigma2 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu3 = np.array([10,5,0,0,0])\n",
        "# sigma3 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu4 = np.array([-10,-10,0,0,0])\n",
        "# sigma4 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu5 = np.array([-21,4,0,0,0])\n",
        "# sigma5 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu6 = np.array([-10,18,0,0,0])\n",
        "# sigma6 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu7 = np.array([4,20,0,0,0])\n",
        "# sigma7 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu8 = np.array([4,-20,0,0,0])\n",
        "# sigma8 = np.array([[16,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu9 = np.array([20,20,0,0,0])\n",
        "# sigma9 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "# mu10 = np.array([20,-10,0,0,0])\n",
        "# sigma10 = np.array([[1,1,1,1,1],[1,16,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])\n",
        "\n",
        "\n",
        "\n",
        "# sample1 = np.random.multivariate_normal(mean=mu1,cov= sigma1,size=500)\n",
        "# sample2 = np.random.multivariate_normal(mean=mu2,cov= sigma2,size=500)\n",
        "# sample3 = np.random.multivariate_normal(mean=mu3,cov= sigma3,size=500)\n",
        "# sample4 = np.random.multivariate_normal(mean=mu4,cov= sigma4,size=500)\n",
        "# sample5 = np.random.multivariate_normal(mean=mu5,cov= sigma5,size=500)\n",
        "# sample6 = np.random.multivariate_normal(mean=mu6,cov= sigma6,size=500)\n",
        "# sample7 = np.random.multivariate_normal(mean=mu7,cov= sigma7,size=500)\n",
        "# sample8 = np.random.multivariate_normal(mean=mu8,cov= sigma8,size=500)\n",
        "# sample9 = np.random.multivariate_normal(mean=mu9,cov= sigma9,size=500)\n",
        "# sample10 = np.random.multivariate_normal(mean=mu10,cov= sigma10,size=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YDnxeP-2_1V",
        "outputId": "eea6755b-2f42-4cb7-b903-3f510e96ad83"
      },
      "source": [
        "X = np.concatenate((sample1,sample2,sample3,sample4,sample5,sample6,sample7,sample8,sample9,sample10),axis=0)\n",
        "Y = np.concatenate((np.zeros((500,1)),np.ones((500,1)),2*np.ones((500,1)),3*np.ones((500,1)),4*np.ones((500,1)),\n",
        "                    5*np.ones((500,1)),6*np.ones((500,1)),7*np.ones((500,1)),8*np.ones((500,1)),9*np.ones((500,1))),axis=0).astype(int)\n",
        "print(X.shape,Y.shape)\n",
        "# plt.scatter(sample1[:,0],sample1[:,1],label=\"class_0\")\n",
        "# plt.scatter(sample2[:,0],sample2[:,1],label=\"class_1\")\n",
        "# plt.scatter(sample3[:,0],sample3[:,1],label=\"class_2\")\n",
        "# plt.scatter(sample4[:,0],sample4[:,1],label=\"class_3\")\n",
        "# plt.scatter(sample5[:,0],sample5[:,1],label=\"class_4\")\n",
        "# plt.scatter(sample6[:,0],sample6[:,1],label=\"class_5\")\n",
        "# plt.scatter(sample7[:,0],sample7[:,1],label=\"class_6\")\n",
        "# plt.scatter(sample8[:,0],sample8[:,1],label=\"class_7\")\n",
        "# plt.scatter(sample9[:,0],sample9[:,1],label=\"class_8\")\n",
        "# plt.scatter(sample10[:,0],sample10[:,1],label=\"class_9\")\n",
        "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 5) (5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YzqPUf3CHa"
      },
      "source": [
        "class SyntheticDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    #self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx] , self.y[idx] #, self.fore_idx[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mi3nL5-4D7_"
      },
      "source": [
        "trainset = SyntheticDataset(X,Y)\n",
        "\n",
        "\n",
        "# testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKzc7IgwqoU2",
        "outputId": "b4ba4e4c-1c98-45cb-d0f9-3ed0dd3cce8b"
      },
      "source": [
        "classes = ('zero','one','two','three','four','five','six','seven','eight','nine')\n",
        "\n",
        "foreground_classes = {'zero','one','two'}\n",
        "fg_used = '012'\n",
        "fg1, fg2, fg3 = 0,1,2\n",
        "\n",
        "\n",
        "all_classes = {'zero','one','two','three','four','five','six','seven','eight','nine'}\n",
        "background_classes = all_classes - foreground_classes\n",
        "background_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eight', 'five', 'four', 'nine', 'seven', 'six', 'three'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT6iKHutquR8"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKzXkPSq5KU"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=100\n",
        "\n",
        "for i in range(50):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChdziOP3rF1G"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])\n",
        "      label = foreground_label[fg_idx] - fg1  # minus fg1 because our fore ground classes are fg1,fg2,fg3 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASrmPqErIDM"
      },
      "source": [
        "desired_num = 3000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "list_set_labels = [] \n",
        "for i in range(desired_num):\n",
        "  set_idx = set()\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,3500,8)\n",
        "  set_idx = set(background_label[bg_idx].tolist())\n",
        "  fg_idx = np.random.randint(0,1500)\n",
        "  set_idx.add(foreground_label[fg_idx].item())\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)\n",
        "  list_set_labels.append(set_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDFN7dCarmmR"
      },
      "source": [
        "def create_avg_image_from_mosaic_dataset(mosaic_dataset,labels,foreground_index,dataset_number):\n",
        "  \"\"\"\n",
        "  mosaic_dataset : mosaic_dataset contains 9 images 32 x 32 each as 1 data point\n",
        "  labels : mosaic_dataset labels\n",
        "  foreground_index : contains list of indexes where foreground image is present so that using this we can take weighted average\n",
        "  dataset_number : will help us to tell what ratio of foreground image to be taken. for eg: if it is \"j\" then fg_image_ratio = j/9 , bg_image_ratio = (9-j)/8*9\n",
        "  \"\"\"\n",
        "  avg_image_dataset = []\n",
        "  for i in range(len(mosaic_dataset)):\n",
        "    img = torch.zeros([5], dtype=torch.float64)\n",
        "    for j in range(9):\n",
        "      if j == foreground_index[i]:\n",
        "        img = img + mosaic_dataset[i][j]*dataset_number/9\n",
        "      else :\n",
        "        img = img + mosaic_dataset[i][j]*(9-dataset_number)/(8*9)\n",
        "    \n",
        "    avg_image_dataset.append(img)\n",
        "    \n",
        "  return torch.stack(avg_image_dataset) , torch.stack(labels) , foreground_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmi8RoaDrxLy"
      },
      "source": [
        "avg_image_dataset_1 , labels_1,  fg_index_1 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 1)\n",
        "avg_image_dataset_2 , labels_2,  fg_index_2 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 2)\n",
        "avg_image_dataset_3 , labels_3,  fg_index_3 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 3)\n",
        "avg_image_dataset_4 , labels_4,  fg_index_4 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 4)\n",
        "avg_image_dataset_5 , labels_5,  fg_index_5 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 5)\n",
        "avg_image_dataset_6 , labels_6,  fg_index_6 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 6)\n",
        "avg_image_dataset_7 , labels_7,  fg_index_7 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 7)\n",
        "avg_image_dataset_8 , labels_8,  fg_index_8 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 8)\n",
        "avg_image_dataset_9 , labels_9,  fg_index_9 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images, mosaic_label, fore_idx, 9)\n",
        "\n",
        "# avg_test_1 , labels_test_1,  fg_index_test_1 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 1)\n",
        "# avg_test_2 , labels_test_2,  fg_index_test_2 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 2)\n",
        "# avg_test_3 , labels_test_3,  fg_index_test_3 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 3)\n",
        "# avg_test_4 , labels_test_4,  fg_index_test_4 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 4)\n",
        "# avg_test_5 , labels_test_5,  fg_index_test_5 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 5)\n",
        "# avg_test_6 , labels_test_6,  fg_index_test_6 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 6)\n",
        "# avg_test_7 , labels_test_7,  fg_index_test_7 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 7)\n",
        "# avg_test_8 , labels_test_8,  fg_index_test_8 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 8)\n",
        "# avg_test_9 , labels_test_9,  fg_index_test_9 = create_avg_image_from_mosaic_dataset(test_images, test_label, fore_idx_test , 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qep4og1r08h"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    #self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] #, self.fore_idx[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0UMB9aJr477"
      },
      "source": [
        "batch = 256\n",
        "epochs = 65\n",
        "\n",
        "# training_data = avg_image_dataset_5    #just change this and training_label to desired dataset for training\n",
        "# training_label = labels_5\n",
        "\n",
        "traindata_1 = MosaicDataset(avg_image_dataset_1, labels_1 )\n",
        "trainloader_1 = DataLoader( traindata_1 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_2 = MosaicDataset(avg_image_dataset_2, labels_2 )\n",
        "trainloader_2 = DataLoader( traindata_2 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_3 = MosaicDataset(avg_image_dataset_3, labels_3 )\n",
        "trainloader_3 = DataLoader( traindata_3 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_4 = MosaicDataset(avg_image_dataset_4, labels_4 )\n",
        "trainloader_4 = DataLoader( traindata_4 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_5 = MosaicDataset(avg_image_dataset_5, labels_5 )\n",
        "trainloader_5 = DataLoader( traindata_5 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_6 = MosaicDataset(avg_image_dataset_6, labels_6 )\n",
        "trainloader_6 = DataLoader( traindata_6 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_7 = MosaicDataset(avg_image_dataset_7, labels_7 )\n",
        "trainloader_7 = DataLoader( traindata_7 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_8 = MosaicDataset(avg_image_dataset_8, labels_8 )\n",
        "trainloader_8 = DataLoader( traindata_8 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "traindata_9 = MosaicDataset(avg_image_dataset_9, labels_9 )\n",
        "trainloader_9 = DataLoader( traindata_9 , batch_size= batch ,shuffle=True)\n",
        "\n",
        "# testdata_1 = MosaicDataset(avg_test_1, labels_test_1 )\n",
        "# testloader_1 = DataLoader( testdata_1 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "# testdata_2 = MosaicDataset(avg_test_2, labels_test_2 )\n",
        "# testloader_2 = DataLoader( testdata_2 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "# testdata_3 = MosaicDataset(avg_test_3, labels_test_3 )\n",
        "# testloader_3 = DataLoader( testdata_3 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "# testdata_4 = MosaicDataset(avg_test_4, labels_test_4 )\n",
        "# testloader_4 = DataLoader( testdata_4 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "# testdata_5 = MosaicDataset(avg_test_5, labels_test_5 )\n",
        "# testloader_5 = DataLoader( testdata_5 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "# testdata_6 = MosaicDataset(avg_test_6, labels_test_6 )\n",
        "# testloader_6 = DataLoader( testdata_6 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "# testdata_7 = MosaicDataset(avg_test_7, labels_test_7 )\n",
        "# testloader_7 = DataLoader( testdata_7 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "# testdata_8 = MosaicDataset(avg_test_8, labels_test_8 )\n",
        "# testloader_8 = DataLoader( testdata_8 , batch_size= batch ,shuffle=False)\n",
        "\n",
        "# testdata_9 = MosaicDataset(avg_test_9, labels_test_9 )\n",
        "# testloader_9 = DataLoader( testdata_9 , batch_size= batch ,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odyXoQcOtf26"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.linear1 = nn.Linear(5,100)\n",
        "        self.linear2 = nn.Linear(100,3)\n",
        "#         self.linear3 = nn.Linear(8,3)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        #x = F.relu(self.linear2(x))\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgF90qBIt8yN"
      },
      "source": [
        "def calculate_loss(dataloader,model,criter):\n",
        "  model.eval()\n",
        "  r_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      outputs = model(inputs)\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  return r_loss/i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkgW8pq7uIeJ"
      },
      "source": [
        "def test_all(number, testloader,inc):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    out = []\n",
        "    pred = []\n",
        "    inc.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(\"cuda\"),labels.to(\"cuda\")\n",
        "            out.append(labels.cpu().numpy())\n",
        "            outputs= inc(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            pred.append(predicted.cpu().numpy())\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 3000 test dataset %d: %d %%' % (number , 100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEYwpxTMuLiF"
      },
      "source": [
        "def train_all(trainloader, ds_number, testloader_list):\n",
        "    \n",
        "    print(\"--\"*40)\n",
        "    print(\"training on data set  \", ds_number)\n",
        "    \n",
        "    net = Net().double()\n",
        "    net = net.to(\"cuda\")\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "    \n",
        "    acti = []\n",
        "    loss_curi = []\n",
        "    epochs = 500\n",
        "    running_loss = calculate_loss(trainloader,net,criterion)\n",
        "    loss_curi.append(running_loss)\n",
        "    print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "    for epoch in range(epochs): # loop over the dataset multiple times\n",
        "        ep_lossi = []\n",
        "\n",
        "        running_loss = 0.0\n",
        "        net.train()\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss = calculate_loss(trainloader,net,criterion)\n",
        "        print('epoch: [%d] loss: %.3f' %(epoch + 1,running_loss)) \n",
        "        loss_curi.append(running_loss)   #loss per epoch\n",
        "        if running_loss<=0.01:\n",
        "          break\n",
        "    #     if (epoch%5 == 0):\n",
        "    #         _,actis= inc(inputs)\n",
        "    #         acti.append(actis)\n",
        "\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    #torch.save(net.state_dict(),\"train_dataset_\"+str(ds_number)+\"_\"+str(epochs)+\".pt\")\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in trainloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    \n",
        "    for i, j in enumerate(testloader_list):\n",
        "        test_all(i+1, j,net)\n",
        "    \n",
        "    print(\"--\"*40)\n",
        "    \n",
        "    return loss_curi\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcAeQRpXuxFs",
        "outputId": "50496547-fa2a-47f0-ea65-45d95fa0b1c7"
      },
      "source": [
        "train_loss_all=[]\n",
        "\n",
        "testloader_list= [ trainloader_1, trainloader_2, trainloader_3, trainloader_4, trainloader_5, trainloader_6,\n",
        "                  trainloader_7, trainloader_8, trainloader_9]\n",
        "\n",
        "train_loss_all.append(train_all(trainloader_1, 1, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_2, 2, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_3, 3, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_4, 4, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_5, 5, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_6, 6, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_7, 7, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_8, 8, testloader_list))\n",
        "train_loss_all.append(train_all(trainloader_9, 9, testloader_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "training on data set   1\n",
            "epoch: [0 ] loss: 1.462\n",
            "epoch: [1] loss: 1.212\n",
            "epoch: [2] loss: 1.209\n",
            "epoch: [3] loss: 1.196\n",
            "epoch: [4] loss: 1.193\n",
            "epoch: [5] loss: 1.192\n",
            "epoch: [6] loss: 1.192\n",
            "epoch: [7] loss: 1.192\n",
            "epoch: [8] loss: 1.190\n",
            "epoch: [9] loss: 1.189\n",
            "epoch: [10] loss: 1.188\n",
            "epoch: [11] loss: 1.189\n",
            "epoch: [12] loss: 1.188\n",
            "epoch: [13] loss: 1.188\n",
            "epoch: [14] loss: 1.187\n",
            "epoch: [15] loss: 1.186\n",
            "epoch: [16] loss: 1.186\n",
            "epoch: [17] loss: 1.186\n",
            "epoch: [18] loss: 1.188\n",
            "epoch: [19] loss: 1.189\n",
            "epoch: [20] loss: 1.186\n",
            "epoch: [21] loss: 1.187\n",
            "epoch: [22] loss: 1.188\n",
            "epoch: [23] loss: 1.186\n",
            "epoch: [24] loss: 1.185\n",
            "epoch: [25] loss: 1.184\n",
            "epoch: [26] loss: 1.186\n",
            "epoch: [27] loss: 1.187\n",
            "epoch: [28] loss: 1.184\n",
            "epoch: [29] loss: 1.183\n",
            "epoch: [30] loss: 1.185\n",
            "epoch: [31] loss: 1.184\n",
            "epoch: [32] loss: 1.184\n",
            "epoch: [33] loss: 1.183\n",
            "epoch: [34] loss: 1.183\n",
            "epoch: [35] loss: 1.183\n",
            "epoch: [36] loss: 1.186\n",
            "epoch: [37] loss: 1.184\n",
            "epoch: [38] loss: 1.183\n",
            "epoch: [39] loss: 1.183\n",
            "epoch: [40] loss: 1.181\n",
            "epoch: [41] loss: 1.182\n",
            "epoch: [42] loss: 1.183\n",
            "epoch: [43] loss: 1.181\n",
            "epoch: [44] loss: 1.182\n",
            "epoch: [45] loss: 1.183\n",
            "epoch: [46] loss: 1.184\n",
            "epoch: [47] loss: 1.186\n",
            "epoch: [48] loss: 1.184\n",
            "epoch: [49] loss: 1.180\n",
            "epoch: [50] loss: 1.181\n",
            "epoch: [51] loss: 1.180\n",
            "epoch: [52] loss: 1.181\n",
            "epoch: [53] loss: 1.182\n",
            "epoch: [54] loss: 1.180\n",
            "epoch: [55] loss: 1.180\n",
            "epoch: [56] loss: 1.180\n",
            "epoch: [57] loss: 1.179\n",
            "epoch: [58] loss: 1.182\n",
            "epoch: [59] loss: 1.181\n",
            "epoch: [60] loss: 1.180\n",
            "epoch: [61] loss: 1.180\n",
            "epoch: [62] loss: 1.181\n",
            "epoch: [63] loss: 1.179\n",
            "epoch: [64] loss: 1.181\n",
            "epoch: [65] loss: 1.180\n",
            "epoch: [66] loss: 1.180\n",
            "epoch: [67] loss: 1.178\n",
            "epoch: [68] loss: 1.178\n",
            "epoch: [69] loss: 1.179\n",
            "epoch: [70] loss: 1.179\n",
            "epoch: [71] loss: 1.178\n",
            "epoch: [72] loss: 1.178\n",
            "epoch: [73] loss: 1.177\n",
            "epoch: [74] loss: 1.177\n",
            "epoch: [75] loss: 1.177\n",
            "epoch: [76] loss: 1.179\n",
            "epoch: [77] loss: 1.177\n",
            "epoch: [78] loss: 1.180\n",
            "epoch: [79] loss: 1.181\n",
            "epoch: [80] loss: 1.179\n",
            "epoch: [81] loss: 1.177\n",
            "epoch: [82] loss: 1.178\n",
            "epoch: [83] loss: 1.178\n",
            "epoch: [84] loss: 1.177\n",
            "epoch: [85] loss: 1.176\n",
            "epoch: [86] loss: 1.176\n",
            "epoch: [87] loss: 1.176\n",
            "epoch: [88] loss: 1.175\n",
            "epoch: [89] loss: 1.176\n",
            "epoch: [90] loss: 1.176\n",
            "epoch: [91] loss: 1.177\n",
            "epoch: [92] loss: 1.178\n",
            "epoch: [93] loss: 1.176\n",
            "epoch: [94] loss: 1.176\n",
            "epoch: [95] loss: 1.176\n",
            "epoch: [96] loss: 1.176\n",
            "epoch: [97] loss: 1.175\n",
            "epoch: [98] loss: 1.175\n",
            "epoch: [99] loss: 1.175\n",
            "epoch: [100] loss: 1.175\n",
            "epoch: [101] loss: 1.176\n",
            "epoch: [102] loss: 1.175\n",
            "epoch: [103] loss: 1.174\n",
            "epoch: [104] loss: 1.174\n",
            "epoch: [105] loss: 1.175\n",
            "epoch: [106] loss: 1.175\n",
            "epoch: [107] loss: 1.174\n",
            "epoch: [108] loss: 1.174\n",
            "epoch: [109] loss: 1.175\n",
            "epoch: [110] loss: 1.175\n",
            "epoch: [111] loss: 1.176\n",
            "epoch: [112] loss: 1.175\n",
            "epoch: [113] loss: 1.174\n",
            "epoch: [114] loss: 1.174\n",
            "epoch: [115] loss: 1.174\n",
            "epoch: [116] loss: 1.174\n",
            "epoch: [117] loss: 1.174\n",
            "epoch: [118] loss: 1.175\n",
            "epoch: [119] loss: 1.174\n",
            "epoch: [120] loss: 1.172\n",
            "epoch: [121] loss: 1.174\n",
            "epoch: [122] loss: 1.173\n",
            "epoch: [123] loss: 1.172\n",
            "epoch: [124] loss: 1.176\n",
            "epoch: [125] loss: 1.174\n",
            "epoch: [126] loss: 1.172\n",
            "epoch: [127] loss: 1.172\n",
            "epoch: [128] loss: 1.174\n",
            "epoch: [129] loss: 1.172\n",
            "epoch: [130] loss: 1.173\n",
            "epoch: [131] loss: 1.175\n",
            "epoch: [132] loss: 1.174\n",
            "epoch: [133] loss: 1.172\n",
            "epoch: [134] loss: 1.172\n",
            "epoch: [135] loss: 1.174\n",
            "epoch: [136] loss: 1.173\n",
            "epoch: [137] loss: 1.171\n",
            "epoch: [138] loss: 1.173\n",
            "epoch: [139] loss: 1.173\n",
            "epoch: [140] loss: 1.174\n",
            "epoch: [141] loss: 1.172\n",
            "epoch: [142] loss: 1.174\n",
            "epoch: [143] loss: 1.172\n",
            "epoch: [144] loss: 1.171\n",
            "epoch: [145] loss: 1.171\n",
            "epoch: [146] loss: 1.172\n",
            "epoch: [147] loss: 1.173\n",
            "epoch: [148] loss: 1.173\n",
            "epoch: [149] loss: 1.172\n",
            "epoch: [150] loss: 1.171\n",
            "epoch: [151] loss: 1.170\n",
            "epoch: [152] loss: 1.170\n",
            "epoch: [153] loss: 1.171\n",
            "epoch: [154] loss: 1.174\n",
            "epoch: [155] loss: 1.173\n",
            "epoch: [156] loss: 1.172\n",
            "epoch: [157] loss: 1.172\n",
            "epoch: [158] loss: 1.171\n",
            "epoch: [159] loss: 1.170\n",
            "epoch: [160] loss: 1.170\n",
            "epoch: [161] loss: 1.170\n",
            "epoch: [162] loss: 1.170\n",
            "epoch: [163] loss: 1.173\n",
            "epoch: [164] loss: 1.172\n",
            "epoch: [165] loss: 1.171\n",
            "epoch: [166] loss: 1.170\n",
            "epoch: [167] loss: 1.170\n",
            "epoch: [168] loss: 1.170\n",
            "epoch: [169] loss: 1.171\n",
            "epoch: [170] loss: 1.172\n",
            "epoch: [171] loss: 1.170\n",
            "epoch: [172] loss: 1.169\n",
            "epoch: [173] loss: 1.170\n",
            "epoch: [174] loss: 1.170\n",
            "epoch: [175] loss: 1.171\n",
            "epoch: [176] loss: 1.171\n",
            "epoch: [177] loss: 1.170\n",
            "epoch: [178] loss: 1.169\n",
            "epoch: [179] loss: 1.170\n",
            "epoch: [180] loss: 1.168\n",
            "epoch: [181] loss: 1.169\n",
            "epoch: [182] loss: 1.170\n",
            "epoch: [183] loss: 1.172\n",
            "epoch: [184] loss: 1.168\n",
            "epoch: [185] loss: 1.168\n",
            "epoch: [186] loss: 1.170\n",
            "epoch: [187] loss: 1.169\n",
            "epoch: [188] loss: 1.168\n",
            "epoch: [189] loss: 1.167\n",
            "epoch: [190] loss: 1.168\n",
            "epoch: [191] loss: 1.167\n",
            "epoch: [192] loss: 1.168\n",
            "epoch: [193] loss: 1.169\n",
            "epoch: [194] loss: 1.168\n",
            "epoch: [195] loss: 1.167\n",
            "epoch: [196] loss: 1.167\n",
            "epoch: [197] loss: 1.169\n",
            "epoch: [198] loss: 1.175\n",
            "epoch: [199] loss: 1.174\n",
            "epoch: [200] loss: 1.167\n",
            "epoch: [201] loss: 1.168\n",
            "epoch: [202] loss: 1.175\n",
            "epoch: [203] loss: 1.167\n",
            "epoch: [204] loss: 1.171\n",
            "epoch: [205] loss: 1.167\n",
            "epoch: [206] loss: 1.167\n",
            "epoch: [207] loss: 1.170\n",
            "epoch: [208] loss: 1.169\n",
            "epoch: [209] loss: 1.170\n",
            "epoch: [210] loss: 1.166\n",
            "epoch: [211] loss: 1.169\n",
            "epoch: [212] loss: 1.167\n",
            "epoch: [213] loss: 1.169\n",
            "epoch: [214] loss: 1.168\n",
            "epoch: [215] loss: 1.167\n",
            "epoch: [216] loss: 1.166\n",
            "epoch: [217] loss: 1.168\n",
            "epoch: [218] loss: 1.169\n",
            "epoch: [219] loss: 1.167\n",
            "epoch: [220] loss: 1.166\n",
            "epoch: [221] loss: 1.166\n",
            "epoch: [222] loss: 1.167\n",
            "epoch: [223] loss: 1.167\n",
            "epoch: [224] loss: 1.167\n",
            "epoch: [225] loss: 1.167\n",
            "epoch: [226] loss: 1.167\n",
            "epoch: [227] loss: 1.168\n",
            "epoch: [228] loss: 1.165\n",
            "epoch: [229] loss: 1.170\n",
            "epoch: [230] loss: 1.166\n",
            "epoch: [231] loss: 1.168\n",
            "epoch: [232] loss: 1.167\n",
            "epoch: [233] loss: 1.165\n",
            "epoch: [234] loss: 1.165\n",
            "epoch: [235] loss: 1.167\n",
            "epoch: [236] loss: 1.167\n",
            "epoch: [237] loss: 1.166\n",
            "epoch: [238] loss: 1.168\n",
            "epoch: [239] loss: 1.165\n",
            "epoch: [240] loss: 1.164\n",
            "epoch: [241] loss: 1.164\n",
            "epoch: [242] loss: 1.166\n",
            "epoch: [243] loss: 1.168\n",
            "epoch: [244] loss: 1.174\n",
            "epoch: [245] loss: 1.167\n",
            "epoch: [246] loss: 1.166\n",
            "epoch: [247] loss: 1.166\n",
            "epoch: [248] loss: 1.166\n",
            "epoch: [249] loss: 1.166\n",
            "epoch: [250] loss: 1.164\n",
            "epoch: [251] loss: 1.164\n",
            "epoch: [252] loss: 1.165\n",
            "epoch: [253] loss: 1.166\n",
            "epoch: [254] loss: 1.164\n",
            "epoch: [255] loss: 1.166\n",
            "epoch: [256] loss: 1.164\n",
            "epoch: [257] loss: 1.164\n",
            "epoch: [258] loss: 1.164\n",
            "epoch: [259] loss: 1.166\n",
            "epoch: [260] loss: 1.164\n",
            "epoch: [261] loss: 1.165\n",
            "epoch: [262] loss: 1.166\n",
            "epoch: [263] loss: 1.164\n",
            "epoch: [264] loss: 1.166\n",
            "epoch: [265] loss: 1.162\n",
            "epoch: [266] loss: 1.163\n",
            "epoch: [267] loss: 1.165\n",
            "epoch: [268] loss: 1.166\n",
            "epoch: [269] loss: 1.164\n",
            "epoch: [270] loss: 1.166\n",
            "epoch: [271] loss: 1.163\n",
            "epoch: [272] loss: 1.163\n",
            "epoch: [273] loss: 1.163\n",
            "epoch: [274] loss: 1.164\n",
            "epoch: [275] loss: 1.165\n",
            "epoch: [276] loss: 1.162\n",
            "epoch: [277] loss: 1.163\n",
            "epoch: [278] loss: 1.164\n",
            "epoch: [279] loss: 1.165\n",
            "epoch: [280] loss: 1.164\n",
            "epoch: [281] loss: 1.163\n",
            "epoch: [282] loss: 1.163\n",
            "epoch: [283] loss: 1.164\n",
            "epoch: [284] loss: 1.165\n",
            "epoch: [285] loss: 1.164\n",
            "epoch: [286] loss: 1.161\n",
            "epoch: [287] loss: 1.164\n",
            "epoch: [288] loss: 1.162\n",
            "epoch: [289] loss: 1.165\n",
            "epoch: [290] loss: 1.162\n",
            "epoch: [291] loss: 1.163\n",
            "epoch: [292] loss: 1.162\n",
            "epoch: [293] loss: 1.164\n",
            "epoch: [294] loss: 1.163\n",
            "epoch: [295] loss: 1.162\n",
            "epoch: [296] loss: 1.164\n",
            "epoch: [297] loss: 1.162\n",
            "epoch: [298] loss: 1.161\n",
            "epoch: [299] loss: 1.162\n",
            "epoch: [300] loss: 1.161\n",
            "epoch: [301] loss: 1.161\n",
            "epoch: [302] loss: 1.161\n",
            "epoch: [303] loss: 1.164\n",
            "epoch: [304] loss: 1.162\n",
            "epoch: [305] loss: 1.164\n",
            "epoch: [306] loss: 1.167\n",
            "epoch: [307] loss: 1.162\n",
            "epoch: [308] loss: 1.164\n",
            "epoch: [309] loss: 1.161\n",
            "epoch: [310] loss: 1.163\n",
            "epoch: [311] loss: 1.161\n",
            "epoch: [312] loss: 1.161\n",
            "epoch: [313] loss: 1.162\n",
            "epoch: [314] loss: 1.165\n",
            "epoch: [315] loss: 1.161\n",
            "epoch: [316] loss: 1.161\n",
            "epoch: [317] loss: 1.160\n",
            "epoch: [318] loss: 1.160\n",
            "epoch: [319] loss: 1.161\n",
            "epoch: [320] loss: 1.163\n",
            "epoch: [321] loss: 1.160\n",
            "epoch: [322] loss: 1.168\n",
            "epoch: [323] loss: 1.163\n",
            "epoch: [324] loss: 1.159\n",
            "epoch: [325] loss: 1.161\n",
            "epoch: [326] loss: 1.161\n",
            "epoch: [327] loss: 1.163\n",
            "epoch: [328] loss: 1.163\n",
            "epoch: [329] loss: 1.165\n",
            "epoch: [330] loss: 1.162\n",
            "epoch: [331] loss: 1.160\n",
            "epoch: [332] loss: 1.161\n",
            "epoch: [333] loss: 1.160\n",
            "epoch: [334] loss: 1.160\n",
            "epoch: [335] loss: 1.159\n",
            "epoch: [336] loss: 1.159\n",
            "epoch: [337] loss: 1.160\n",
            "epoch: [338] loss: 1.160\n",
            "epoch: [339] loss: 1.161\n",
            "epoch: [340] loss: 1.160\n",
            "epoch: [341] loss: 1.161\n",
            "epoch: [342] loss: 1.159\n",
            "epoch: [343] loss: 1.159\n",
            "epoch: [344] loss: 1.159\n",
            "epoch: [345] loss: 1.159\n",
            "epoch: [346] loss: 1.160\n",
            "epoch: [347] loss: 1.158\n",
            "epoch: [348] loss: 1.159\n",
            "epoch: [349] loss: 1.159\n",
            "epoch: [350] loss: 1.161\n",
            "epoch: [351] loss: 1.161\n",
            "epoch: [352] loss: 1.161\n",
            "epoch: [353] loss: 1.159\n",
            "epoch: [354] loss: 1.159\n",
            "epoch: [355] loss: 1.160\n",
            "epoch: [356] loss: 1.159\n",
            "epoch: [357] loss: 1.158\n",
            "epoch: [358] loss: 1.162\n",
            "epoch: [359] loss: 1.158\n",
            "epoch: [360] loss: 1.158\n",
            "epoch: [361] loss: 1.161\n",
            "epoch: [362] loss: 1.159\n",
            "epoch: [363] loss: 1.158\n",
            "epoch: [364] loss: 1.157\n",
            "epoch: [365] loss: 1.160\n",
            "epoch: [366] loss: 1.157\n",
            "epoch: [367] loss: 1.157\n",
            "epoch: [368] loss: 1.158\n",
            "epoch: [369] loss: 1.157\n",
            "epoch: [370] loss: 1.159\n",
            "epoch: [371] loss: 1.161\n",
            "epoch: [372] loss: 1.159\n",
            "epoch: [373] loss: 1.158\n",
            "epoch: [374] loss: 1.160\n",
            "epoch: [375] loss: 1.160\n",
            "epoch: [376] loss: 1.161\n",
            "epoch: [377] loss: 1.158\n",
            "epoch: [378] loss: 1.157\n",
            "epoch: [379] loss: 1.157\n",
            "epoch: [380] loss: 1.157\n",
            "epoch: [381] loss: 1.158\n",
            "epoch: [382] loss: 1.157\n",
            "epoch: [383] loss: 1.157\n",
            "epoch: [384] loss: 1.156\n",
            "epoch: [385] loss: 1.157\n",
            "epoch: [386] loss: 1.157\n",
            "epoch: [387] loss: 1.157\n",
            "epoch: [388] loss: 1.158\n",
            "epoch: [389] loss: 1.159\n",
            "epoch: [390] loss: 1.160\n",
            "epoch: [391] loss: 1.156\n",
            "epoch: [392] loss: 1.158\n",
            "epoch: [393] loss: 1.156\n",
            "epoch: [394] loss: 1.157\n",
            "epoch: [395] loss: 1.160\n",
            "epoch: [396] loss: 1.156\n",
            "epoch: [397] loss: 1.156\n",
            "epoch: [398] loss: 1.156\n",
            "epoch: [399] loss: 1.158\n",
            "epoch: [400] loss: 1.157\n",
            "epoch: [401] loss: 1.156\n",
            "epoch: [402] loss: 1.157\n",
            "epoch: [403] loss: 1.156\n",
            "epoch: [404] loss: 1.156\n",
            "epoch: [405] loss: 1.157\n",
            "epoch: [406] loss: 1.159\n",
            "epoch: [407] loss: 1.156\n",
            "epoch: [408] loss: 1.155\n",
            "epoch: [409] loss: 1.158\n",
            "epoch: [410] loss: 1.157\n",
            "epoch: [411] loss: 1.155\n",
            "epoch: [412] loss: 1.156\n",
            "epoch: [413] loss: 1.155\n",
            "epoch: [414] loss: 1.160\n",
            "epoch: [415] loss: 1.159\n",
            "epoch: [416] loss: 1.157\n",
            "epoch: [417] loss: 1.156\n",
            "epoch: [418] loss: 1.157\n",
            "epoch: [419] loss: 1.155\n",
            "epoch: [420] loss: 1.156\n",
            "epoch: [421] loss: 1.155\n",
            "epoch: [422] loss: 1.155\n",
            "epoch: [423] loss: 1.156\n",
            "epoch: [424] loss: 1.156\n",
            "epoch: [425] loss: 1.155\n",
            "epoch: [426] loss: 1.157\n",
            "epoch: [427] loss: 1.157\n",
            "epoch: [428] loss: 1.158\n",
            "epoch: [429] loss: 1.159\n",
            "epoch: [430] loss: 1.155\n",
            "epoch: [431] loss: 1.157\n",
            "epoch: [432] loss: 1.160\n",
            "epoch: [433] loss: 1.155\n",
            "epoch: [434] loss: 1.156\n",
            "epoch: [435] loss: 1.157\n",
            "epoch: [436] loss: 1.158\n",
            "epoch: [437] loss: 1.155\n",
            "epoch: [438] loss: 1.157\n",
            "epoch: [439] loss: 1.155\n",
            "epoch: [440] loss: 1.159\n",
            "epoch: [441] loss: 1.159\n",
            "epoch: [442] loss: 1.160\n",
            "epoch: [443] loss: 1.155\n",
            "epoch: [444] loss: 1.155\n",
            "epoch: [445] loss: 1.159\n",
            "epoch: [446] loss: 1.159\n",
            "epoch: [447] loss: 1.153\n",
            "epoch: [448] loss: 1.154\n",
            "epoch: [449] loss: 1.156\n",
            "epoch: [450] loss: 1.153\n",
            "epoch: [451] loss: 1.154\n",
            "epoch: [452] loss: 1.155\n",
            "epoch: [453] loss: 1.154\n",
            "epoch: [454] loss: 1.153\n",
            "epoch: [455] loss: 1.154\n",
            "epoch: [456] loss: 1.153\n",
            "epoch: [457] loss: 1.154\n",
            "epoch: [458] loss: 1.154\n",
            "epoch: [459] loss: 1.154\n",
            "epoch: [460] loss: 1.154\n",
            "epoch: [461] loss: 1.153\n",
            "epoch: [462] loss: 1.153\n",
            "epoch: [463] loss: 1.154\n",
            "epoch: [464] loss: 1.154\n",
            "epoch: [465] loss: 1.153\n",
            "epoch: [466] loss: 1.156\n",
            "epoch: [467] loss: 1.155\n",
            "epoch: [468] loss: 1.154\n",
            "epoch: [469] loss: 1.154\n",
            "epoch: [470] loss: 1.153\n",
            "epoch: [471] loss: 1.153\n",
            "epoch: [472] loss: 1.156\n",
            "epoch: [473] loss: 1.154\n",
            "epoch: [474] loss: 1.161\n",
            "epoch: [475] loss: 1.154\n",
            "epoch: [476] loss: 1.153\n",
            "epoch: [477] loss: 1.155\n",
            "epoch: [478] loss: 1.153\n",
            "epoch: [479] loss: 1.152\n",
            "epoch: [480] loss: 1.152\n",
            "epoch: [481] loss: 1.154\n",
            "epoch: [482] loss: 1.153\n",
            "epoch: [483] loss: 1.155\n",
            "epoch: [484] loss: 1.152\n",
            "epoch: [485] loss: 1.153\n",
            "epoch: [486] loss: 1.152\n",
            "epoch: [487] loss: 1.152\n",
            "epoch: [488] loss: 1.152\n",
            "epoch: [489] loss: 1.154\n",
            "epoch: [490] loss: 1.152\n",
            "epoch: [491] loss: 1.155\n",
            "epoch: [492] loss: 1.151\n",
            "epoch: [493] loss: 1.153\n",
            "epoch: [494] loss: 1.151\n",
            "epoch: [495] loss: 1.151\n",
            "epoch: [496] loss: 1.151\n",
            "epoch: [497] loss: 1.151\n",
            "epoch: [498] loss: 1.154\n",
            "epoch: [499] loss: 1.153\n",
            "epoch: [500] loss: 1.153\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 45 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 45 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 43 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 43 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 43 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 43 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 42 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 42 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 38 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 35 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   2\n",
            "epoch: [0 ] loss: 1.441\n",
            "epoch: [1] loss: 1.220\n",
            "epoch: [2] loss: 1.192\n",
            "epoch: [3] loss: 1.181\n",
            "epoch: [4] loss: 1.178\n",
            "epoch: [5] loss: 1.177\n",
            "epoch: [6] loss: 1.175\n",
            "epoch: [7] loss: 1.174\n",
            "epoch: [8] loss: 1.173\n",
            "epoch: [9] loss: 1.173\n",
            "epoch: [10] loss: 1.170\n",
            "epoch: [11] loss: 1.169\n",
            "epoch: [12] loss: 1.169\n",
            "epoch: [13] loss: 1.170\n",
            "epoch: [14] loss: 1.168\n",
            "epoch: [15] loss: 1.167\n",
            "epoch: [16] loss: 1.165\n",
            "epoch: [17] loss: 1.165\n",
            "epoch: [18] loss: 1.164\n",
            "epoch: [19] loss: 1.164\n",
            "epoch: [20] loss: 1.164\n",
            "epoch: [21] loss: 1.164\n",
            "epoch: [22] loss: 1.163\n",
            "epoch: [23] loss: 1.162\n",
            "epoch: [24] loss: 1.166\n",
            "epoch: [25] loss: 1.162\n",
            "epoch: [26] loss: 1.161\n",
            "epoch: [27] loss: 1.160\n",
            "epoch: [28] loss: 1.160\n",
            "epoch: [29] loss: 1.160\n",
            "epoch: [30] loss: 1.161\n",
            "epoch: [31] loss: 1.161\n",
            "epoch: [32] loss: 1.161\n",
            "epoch: [33] loss: 1.161\n",
            "epoch: [34] loss: 1.157\n",
            "epoch: [35] loss: 1.157\n",
            "epoch: [36] loss: 1.160\n",
            "epoch: [37] loss: 1.159\n",
            "epoch: [38] loss: 1.156\n",
            "epoch: [39] loss: 1.157\n",
            "epoch: [40] loss: 1.155\n",
            "epoch: [41] loss: 1.154\n",
            "epoch: [42] loss: 1.154\n",
            "epoch: [43] loss: 1.155\n",
            "epoch: [44] loss: 1.155\n",
            "epoch: [45] loss: 1.153\n",
            "epoch: [46] loss: 1.156\n",
            "epoch: [47] loss: 1.153\n",
            "epoch: [48] loss: 1.154\n",
            "epoch: [49] loss: 1.153\n",
            "epoch: [50] loss: 1.153\n",
            "epoch: [51] loss: 1.154\n",
            "epoch: [52] loss: 1.157\n",
            "epoch: [53] loss: 1.154\n",
            "epoch: [54] loss: 1.152\n",
            "epoch: [55] loss: 1.153\n",
            "epoch: [56] loss: 1.152\n",
            "epoch: [57] loss: 1.156\n",
            "epoch: [58] loss: 1.150\n",
            "epoch: [59] loss: 1.153\n",
            "epoch: [60] loss: 1.153\n",
            "epoch: [61] loss: 1.153\n",
            "epoch: [62] loss: 1.150\n",
            "epoch: [63] loss: 1.153\n",
            "epoch: [64] loss: 1.155\n",
            "epoch: [65] loss: 1.151\n",
            "epoch: [66] loss: 1.152\n",
            "epoch: [67] loss: 1.151\n",
            "epoch: [68] loss: 1.148\n",
            "epoch: [69] loss: 1.148\n",
            "epoch: [70] loss: 1.149\n",
            "epoch: [71] loss: 1.148\n",
            "epoch: [72] loss: 1.148\n",
            "epoch: [73] loss: 1.147\n",
            "epoch: [74] loss: 1.147\n",
            "epoch: [75] loss: 1.147\n",
            "epoch: [76] loss: 1.147\n",
            "epoch: [77] loss: 1.150\n",
            "epoch: [78] loss: 1.147\n",
            "epoch: [79] loss: 1.148\n",
            "epoch: [80] loss: 1.147\n",
            "epoch: [81] loss: 1.146\n",
            "epoch: [82] loss: 1.148\n",
            "epoch: [83] loss: 1.147\n",
            "epoch: [84] loss: 1.148\n",
            "epoch: [85] loss: 1.147\n",
            "epoch: [86] loss: 1.146\n",
            "epoch: [87] loss: 1.146\n",
            "epoch: [88] loss: 1.147\n",
            "epoch: [89] loss: 1.145\n",
            "epoch: [90] loss: 1.147\n",
            "epoch: [91] loss: 1.145\n",
            "epoch: [92] loss: 1.144\n",
            "epoch: [93] loss: 1.146\n",
            "epoch: [94] loss: 1.144\n",
            "epoch: [95] loss: 1.144\n",
            "epoch: [96] loss: 1.146\n",
            "epoch: [97] loss: 1.142\n",
            "epoch: [98] loss: 1.143\n",
            "epoch: [99] loss: 1.143\n",
            "epoch: [100] loss: 1.142\n",
            "epoch: [101] loss: 1.146\n",
            "epoch: [102] loss: 1.148\n",
            "epoch: [103] loss: 1.145\n",
            "epoch: [104] loss: 1.143\n",
            "epoch: [105] loss: 1.142\n",
            "epoch: [106] loss: 1.144\n",
            "epoch: [107] loss: 1.146\n",
            "epoch: [108] loss: 1.145\n",
            "epoch: [109] loss: 1.143\n",
            "epoch: [110] loss: 1.142\n",
            "epoch: [111] loss: 1.143\n",
            "epoch: [112] loss: 1.143\n",
            "epoch: [113] loss: 1.142\n",
            "epoch: [114] loss: 1.141\n",
            "epoch: [115] loss: 1.144\n",
            "epoch: [116] loss: 1.143\n",
            "epoch: [117] loss: 1.141\n",
            "epoch: [118] loss: 1.143\n",
            "epoch: [119] loss: 1.141\n",
            "epoch: [120] loss: 1.140\n",
            "epoch: [121] loss: 1.142\n",
            "epoch: [122] loss: 1.141\n",
            "epoch: [123] loss: 1.141\n",
            "epoch: [124] loss: 1.141\n",
            "epoch: [125] loss: 1.141\n",
            "epoch: [126] loss: 1.140\n",
            "epoch: [127] loss: 1.139\n",
            "epoch: [128] loss: 1.140\n",
            "epoch: [129] loss: 1.140\n",
            "epoch: [130] loss: 1.142\n",
            "epoch: [131] loss: 1.140\n",
            "epoch: [132] loss: 1.139\n",
            "epoch: [133] loss: 1.140\n",
            "epoch: [134] loss: 1.140\n",
            "epoch: [135] loss: 1.139\n",
            "epoch: [136] loss: 1.139\n",
            "epoch: [137] loss: 1.139\n",
            "epoch: [138] loss: 1.139\n",
            "epoch: [139] loss: 1.142\n",
            "epoch: [140] loss: 1.141\n",
            "epoch: [141] loss: 1.140\n",
            "epoch: [142] loss: 1.140\n",
            "epoch: [143] loss: 1.138\n",
            "epoch: [144] loss: 1.138\n",
            "epoch: [145] loss: 1.138\n",
            "epoch: [146] loss: 1.138\n",
            "epoch: [147] loss: 1.139\n",
            "epoch: [148] loss: 1.138\n",
            "epoch: [149] loss: 1.140\n",
            "epoch: [150] loss: 1.139\n",
            "epoch: [151] loss: 1.138\n",
            "epoch: [152] loss: 1.139\n",
            "epoch: [153] loss: 1.140\n",
            "epoch: [154] loss: 1.137\n",
            "epoch: [155] loss: 1.138\n",
            "epoch: [156] loss: 1.139\n",
            "epoch: [157] loss: 1.140\n",
            "epoch: [158] loss: 1.139\n",
            "epoch: [159] loss: 1.138\n",
            "epoch: [160] loss: 1.139\n",
            "epoch: [161] loss: 1.138\n",
            "epoch: [162] loss: 1.139\n",
            "epoch: [163] loss: 1.143\n",
            "epoch: [164] loss: 1.137\n",
            "epoch: [165] loss: 1.137\n",
            "epoch: [166] loss: 1.139\n",
            "epoch: [167] loss: 1.138\n",
            "epoch: [168] loss: 1.137\n",
            "epoch: [169] loss: 1.136\n",
            "epoch: [170] loss: 1.137\n",
            "epoch: [171] loss: 1.137\n",
            "epoch: [172] loss: 1.138\n",
            "epoch: [173] loss: 1.144\n",
            "epoch: [174] loss: 1.138\n",
            "epoch: [175] loss: 1.138\n",
            "epoch: [176] loss: 1.136\n",
            "epoch: [177] loss: 1.135\n",
            "epoch: [178] loss: 1.135\n",
            "epoch: [179] loss: 1.138\n",
            "epoch: [180] loss: 1.141\n",
            "epoch: [181] loss: 1.144\n",
            "epoch: [182] loss: 1.140\n",
            "epoch: [183] loss: 1.137\n",
            "epoch: [184] loss: 1.136\n",
            "epoch: [185] loss: 1.137\n",
            "epoch: [186] loss: 1.137\n",
            "epoch: [187] loss: 1.137\n",
            "epoch: [188] loss: 1.136\n",
            "epoch: [189] loss: 1.133\n",
            "epoch: [190] loss: 1.136\n",
            "epoch: [191] loss: 1.137\n",
            "epoch: [192] loss: 1.134\n",
            "epoch: [193] loss: 1.135\n",
            "epoch: [194] loss: 1.135\n",
            "epoch: [195] loss: 1.135\n",
            "epoch: [196] loss: 1.137\n",
            "epoch: [197] loss: 1.135\n",
            "epoch: [198] loss: 1.136\n",
            "epoch: [199] loss: 1.138\n",
            "epoch: [200] loss: 1.135\n",
            "epoch: [201] loss: 1.134\n",
            "epoch: [202] loss: 1.135\n",
            "epoch: [203] loss: 1.134\n",
            "epoch: [204] loss: 1.135\n",
            "epoch: [205] loss: 1.140\n",
            "epoch: [206] loss: 1.136\n",
            "epoch: [207] loss: 1.135\n",
            "epoch: [208] loss: 1.136\n",
            "epoch: [209] loss: 1.136\n",
            "epoch: [210] loss: 1.135\n",
            "epoch: [211] loss: 1.133\n",
            "epoch: [212] loss: 1.134\n",
            "epoch: [213] loss: 1.135\n",
            "epoch: [214] loss: 1.133\n",
            "epoch: [215] loss: 1.133\n",
            "epoch: [216] loss: 1.132\n",
            "epoch: [217] loss: 1.133\n",
            "epoch: [218] loss: 1.133\n",
            "epoch: [219] loss: 1.134\n",
            "epoch: [220] loss: 1.134\n",
            "epoch: [221] loss: 1.133\n",
            "epoch: [222] loss: 1.133\n",
            "epoch: [223] loss: 1.133\n",
            "epoch: [224] loss: 1.132\n",
            "epoch: [225] loss: 1.133\n",
            "epoch: [226] loss: 1.133\n",
            "epoch: [227] loss: 1.138\n",
            "epoch: [228] loss: 1.132\n",
            "epoch: [229] loss: 1.133\n",
            "epoch: [230] loss: 1.136\n",
            "epoch: [231] loss: 1.132\n",
            "epoch: [232] loss: 1.132\n",
            "epoch: [233] loss: 1.133\n",
            "epoch: [234] loss: 1.132\n",
            "epoch: [235] loss: 1.131\n",
            "epoch: [236] loss: 1.132\n",
            "epoch: [237] loss: 1.132\n",
            "epoch: [238] loss: 1.131\n",
            "epoch: [239] loss: 1.131\n",
            "epoch: [240] loss: 1.134\n",
            "epoch: [241] loss: 1.133\n",
            "epoch: [242] loss: 1.132\n",
            "epoch: [243] loss: 1.132\n",
            "epoch: [244] loss: 1.133\n",
            "epoch: [245] loss: 1.132\n",
            "epoch: [246] loss: 1.131\n",
            "epoch: [247] loss: 1.132\n",
            "epoch: [248] loss: 1.132\n",
            "epoch: [249] loss: 1.131\n",
            "epoch: [250] loss: 1.131\n",
            "epoch: [251] loss: 1.130\n",
            "epoch: [252] loss: 1.131\n",
            "epoch: [253] loss: 1.131\n",
            "epoch: [254] loss: 1.130\n",
            "epoch: [255] loss: 1.131\n",
            "epoch: [256] loss: 1.131\n",
            "epoch: [257] loss: 1.131\n",
            "epoch: [258] loss: 1.131\n",
            "epoch: [259] loss: 1.130\n",
            "epoch: [260] loss: 1.130\n",
            "epoch: [261] loss: 1.130\n",
            "epoch: [262] loss: 1.131\n",
            "epoch: [263] loss: 1.130\n",
            "epoch: [264] loss: 1.130\n",
            "epoch: [265] loss: 1.132\n",
            "epoch: [266] loss: 1.132\n",
            "epoch: [267] loss: 1.131\n",
            "epoch: [268] loss: 1.130\n",
            "epoch: [269] loss: 1.129\n",
            "epoch: [270] loss: 1.130\n",
            "epoch: [271] loss: 1.129\n",
            "epoch: [272] loss: 1.136\n",
            "epoch: [273] loss: 1.130\n",
            "epoch: [274] loss: 1.130\n",
            "epoch: [275] loss: 1.128\n",
            "epoch: [276] loss: 1.129\n",
            "epoch: [277] loss: 1.130\n",
            "epoch: [278] loss: 1.129\n",
            "epoch: [279] loss: 1.129\n",
            "epoch: [280] loss: 1.130\n",
            "epoch: [281] loss: 1.128\n",
            "epoch: [282] loss: 1.129\n",
            "epoch: [283] loss: 1.129\n",
            "epoch: [284] loss: 1.135\n",
            "epoch: [285] loss: 1.132\n",
            "epoch: [286] loss: 1.131\n",
            "epoch: [287] loss: 1.131\n",
            "epoch: [288] loss: 1.128\n",
            "epoch: [289] loss: 1.131\n",
            "epoch: [290] loss: 1.130\n",
            "epoch: [291] loss: 1.128\n",
            "epoch: [292] loss: 1.129\n",
            "epoch: [293] loss: 1.127\n",
            "epoch: [294] loss: 1.128\n",
            "epoch: [295] loss: 1.133\n",
            "epoch: [296] loss: 1.131\n",
            "epoch: [297] loss: 1.130\n",
            "epoch: [298] loss: 1.129\n",
            "epoch: [299] loss: 1.127\n",
            "epoch: [300] loss: 1.129\n",
            "epoch: [301] loss: 1.127\n",
            "epoch: [302] loss: 1.129\n",
            "epoch: [303] loss: 1.128\n",
            "epoch: [304] loss: 1.130\n",
            "epoch: [305] loss: 1.130\n",
            "epoch: [306] loss: 1.132\n",
            "epoch: [307] loss: 1.130\n",
            "epoch: [308] loss: 1.127\n",
            "epoch: [309] loss: 1.128\n",
            "epoch: [310] loss: 1.127\n",
            "epoch: [311] loss: 1.128\n",
            "epoch: [312] loss: 1.127\n",
            "epoch: [313] loss: 1.126\n",
            "epoch: [314] loss: 1.127\n",
            "epoch: [315] loss: 1.128\n",
            "epoch: [316] loss: 1.127\n",
            "epoch: [317] loss: 1.126\n",
            "epoch: [318] loss: 1.127\n",
            "epoch: [319] loss: 1.127\n",
            "epoch: [320] loss: 1.127\n",
            "epoch: [321] loss: 1.130\n",
            "epoch: [322] loss: 1.127\n",
            "epoch: [323] loss: 1.127\n",
            "epoch: [324] loss: 1.128\n",
            "epoch: [325] loss: 1.126\n",
            "epoch: [326] loss: 1.127\n",
            "epoch: [327] loss: 1.126\n",
            "epoch: [328] loss: 1.125\n",
            "epoch: [329] loss: 1.130\n",
            "epoch: [330] loss: 1.131\n",
            "epoch: [331] loss: 1.127\n",
            "epoch: [332] loss: 1.128\n",
            "epoch: [333] loss: 1.125\n",
            "epoch: [334] loss: 1.125\n",
            "epoch: [335] loss: 1.127\n",
            "epoch: [336] loss: 1.127\n",
            "epoch: [337] loss: 1.124\n",
            "epoch: [338] loss: 1.131\n",
            "epoch: [339] loss: 1.126\n",
            "epoch: [340] loss: 1.125\n",
            "epoch: [341] loss: 1.124\n",
            "epoch: [342] loss: 1.128\n",
            "epoch: [343] loss: 1.126\n",
            "epoch: [344] loss: 1.127\n",
            "epoch: [345] loss: 1.127\n",
            "epoch: [346] loss: 1.124\n",
            "epoch: [347] loss: 1.124\n",
            "epoch: [348] loss: 1.126\n",
            "epoch: [349] loss: 1.126\n",
            "epoch: [350] loss: 1.124\n",
            "epoch: [351] loss: 1.125\n",
            "epoch: [352] loss: 1.125\n",
            "epoch: [353] loss: 1.124\n",
            "epoch: [354] loss: 1.126\n",
            "epoch: [355] loss: 1.124\n",
            "epoch: [356] loss: 1.124\n",
            "epoch: [357] loss: 1.124\n",
            "epoch: [358] loss: 1.125\n",
            "epoch: [359] loss: 1.125\n",
            "epoch: [360] loss: 1.125\n",
            "epoch: [361] loss: 1.125\n",
            "epoch: [362] loss: 1.124\n",
            "epoch: [363] loss: 1.123\n",
            "epoch: [364] loss: 1.125\n",
            "epoch: [365] loss: 1.123\n",
            "epoch: [366] loss: 1.123\n",
            "epoch: [367] loss: 1.124\n",
            "epoch: [368] loss: 1.124\n",
            "epoch: [369] loss: 1.124\n",
            "epoch: [370] loss: 1.124\n",
            "epoch: [371] loss: 1.126\n",
            "epoch: [372] loss: 1.123\n",
            "epoch: [373] loss: 1.128\n",
            "epoch: [374] loss: 1.124\n",
            "epoch: [375] loss: 1.125\n",
            "epoch: [376] loss: 1.123\n",
            "epoch: [377] loss: 1.122\n",
            "epoch: [378] loss: 1.124\n",
            "epoch: [379] loss: 1.124\n",
            "epoch: [380] loss: 1.123\n",
            "epoch: [381] loss: 1.123\n",
            "epoch: [382] loss: 1.123\n",
            "epoch: [383] loss: 1.123\n",
            "epoch: [384] loss: 1.123\n",
            "epoch: [385] loss: 1.122\n",
            "epoch: [386] loss: 1.122\n",
            "epoch: [387] loss: 1.122\n",
            "epoch: [388] loss: 1.123\n",
            "epoch: [389] loss: 1.122\n",
            "epoch: [390] loss: 1.122\n",
            "epoch: [391] loss: 1.124\n",
            "epoch: [392] loss: 1.122\n",
            "epoch: [393] loss: 1.121\n",
            "epoch: [394] loss: 1.122\n",
            "epoch: [395] loss: 1.125\n",
            "epoch: [396] loss: 1.127\n",
            "epoch: [397] loss: 1.125\n",
            "epoch: [398] loss: 1.123\n",
            "epoch: [399] loss: 1.128\n",
            "epoch: [400] loss: 1.122\n",
            "epoch: [401] loss: 1.122\n",
            "epoch: [402] loss: 1.121\n",
            "epoch: [403] loss: 1.121\n",
            "epoch: [404] loss: 1.122\n",
            "epoch: [405] loss: 1.123\n",
            "epoch: [406] loss: 1.122\n",
            "epoch: [407] loss: 1.127\n",
            "epoch: [408] loss: 1.127\n",
            "epoch: [409] loss: 1.122\n",
            "epoch: [410] loss: 1.121\n",
            "epoch: [411] loss: 1.121\n",
            "epoch: [412] loss: 1.121\n",
            "epoch: [413] loss: 1.122\n",
            "epoch: [414] loss: 1.120\n",
            "epoch: [415] loss: 1.124\n",
            "epoch: [416] loss: 1.123\n",
            "epoch: [417] loss: 1.121\n",
            "epoch: [418] loss: 1.122\n",
            "epoch: [419] loss: 1.120\n",
            "epoch: [420] loss: 1.121\n",
            "epoch: [421] loss: 1.120\n",
            "epoch: [422] loss: 1.122\n",
            "epoch: [423] loss: 1.120\n",
            "epoch: [424] loss: 1.119\n",
            "epoch: [425] loss: 1.120\n",
            "epoch: [426] loss: 1.121\n",
            "epoch: [427] loss: 1.123\n",
            "epoch: [428] loss: 1.120\n",
            "epoch: [429] loss: 1.122\n",
            "epoch: [430] loss: 1.120\n",
            "epoch: [431] loss: 1.120\n",
            "epoch: [432] loss: 1.119\n",
            "epoch: [433] loss: 1.121\n",
            "epoch: [434] loss: 1.118\n",
            "epoch: [435] loss: 1.120\n",
            "epoch: [436] loss: 1.119\n",
            "epoch: [437] loss: 1.119\n",
            "epoch: [438] loss: 1.119\n",
            "epoch: [439] loss: 1.118\n",
            "epoch: [440] loss: 1.121\n",
            "epoch: [441] loss: 1.121\n",
            "epoch: [442] loss: 1.122\n",
            "epoch: [443] loss: 1.120\n",
            "epoch: [444] loss: 1.122\n",
            "epoch: [445] loss: 1.120\n",
            "epoch: [446] loss: 1.121\n",
            "epoch: [447] loss: 1.119\n",
            "epoch: [448] loss: 1.117\n",
            "epoch: [449] loss: 1.117\n",
            "epoch: [450] loss: 1.119\n",
            "epoch: [451] loss: 1.120\n",
            "epoch: [452] loss: 1.120\n",
            "epoch: [453] loss: 1.122\n",
            "epoch: [454] loss: 1.120\n",
            "epoch: [455] loss: 1.118\n",
            "epoch: [456] loss: 1.119\n",
            "epoch: [457] loss: 1.125\n",
            "epoch: [458] loss: 1.124\n",
            "epoch: [459] loss: 1.120\n",
            "epoch: [460] loss: 1.121\n",
            "epoch: [461] loss: 1.118\n",
            "epoch: [462] loss: 1.119\n",
            "epoch: [463] loss: 1.117\n",
            "epoch: [464] loss: 1.118\n",
            "epoch: [465] loss: 1.117\n",
            "epoch: [466] loss: 1.117\n",
            "epoch: [467] loss: 1.118\n",
            "epoch: [468] loss: 1.118\n",
            "epoch: [469] loss: 1.117\n",
            "epoch: [470] loss: 1.119\n",
            "epoch: [471] loss: 1.118\n",
            "epoch: [472] loss: 1.118\n",
            "epoch: [473] loss: 1.117\n",
            "epoch: [474] loss: 1.117\n",
            "epoch: [475] loss: 1.117\n",
            "epoch: [476] loss: 1.121\n",
            "epoch: [477] loss: 1.116\n",
            "epoch: [478] loss: 1.117\n",
            "epoch: [479] loss: 1.116\n",
            "epoch: [480] loss: 1.117\n",
            "epoch: [481] loss: 1.118\n",
            "epoch: [482] loss: 1.116\n",
            "epoch: [483] loss: 1.118\n",
            "epoch: [484] loss: 1.117\n",
            "epoch: [485] loss: 1.115\n",
            "epoch: [486] loss: 1.120\n",
            "epoch: [487] loss: 1.117\n",
            "epoch: [488] loss: 1.120\n",
            "epoch: [489] loss: 1.118\n",
            "epoch: [490] loss: 1.116\n",
            "epoch: [491] loss: 1.116\n",
            "epoch: [492] loss: 1.117\n",
            "epoch: [493] loss: 1.118\n",
            "epoch: [494] loss: 1.116\n",
            "epoch: [495] loss: 1.118\n",
            "epoch: [496] loss: 1.117\n",
            "epoch: [497] loss: 1.116\n",
            "epoch: [498] loss: 1.117\n",
            "epoch: [499] loss: 1.118\n",
            "epoch: [500] loss: 1.115\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 47 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 41 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 47 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 50 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 53 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 56 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 57 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 57 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 58 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 60 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   3\n",
            "epoch: [0 ] loss: 1.313\n",
            "epoch: [1] loss: 1.185\n",
            "epoch: [2] loss: 1.159\n",
            "epoch: [3] loss: 1.151\n",
            "epoch: [4] loss: 1.145\n",
            "epoch: [5] loss: 1.140\n",
            "epoch: [6] loss: 1.138\n",
            "epoch: [7] loss: 1.136\n",
            "epoch: [8] loss: 1.135\n",
            "epoch: [9] loss: 1.133\n",
            "epoch: [10] loss: 1.130\n",
            "epoch: [11] loss: 1.129\n",
            "epoch: [12] loss: 1.127\n",
            "epoch: [13] loss: 1.126\n",
            "epoch: [14] loss: 1.123\n",
            "epoch: [15] loss: 1.122\n",
            "epoch: [16] loss: 1.120\n",
            "epoch: [17] loss: 1.119\n",
            "epoch: [18] loss: 1.117\n",
            "epoch: [19] loss: 1.116\n",
            "epoch: [20] loss: 1.115\n",
            "epoch: [21] loss: 1.115\n",
            "epoch: [22] loss: 1.113\n",
            "epoch: [23] loss: 1.110\n",
            "epoch: [24] loss: 1.108\n",
            "epoch: [25] loss: 1.108\n",
            "epoch: [26] loss: 1.106\n",
            "epoch: [27] loss: 1.106\n",
            "epoch: [28] loss: 1.101\n",
            "epoch: [29] loss: 1.101\n",
            "epoch: [30] loss: 1.100\n",
            "epoch: [31] loss: 1.099\n",
            "epoch: [32] loss: 1.095\n",
            "epoch: [33] loss: 1.095\n",
            "epoch: [34] loss: 1.094\n",
            "epoch: [35] loss: 1.092\n",
            "epoch: [36] loss: 1.093\n",
            "epoch: [37] loss: 1.090\n",
            "epoch: [38] loss: 1.088\n",
            "epoch: [39] loss: 1.086\n",
            "epoch: [40] loss: 1.084\n",
            "epoch: [41] loss: 1.084\n",
            "epoch: [42] loss: 1.082\n",
            "epoch: [43] loss: 1.082\n",
            "epoch: [44] loss: 1.079\n",
            "epoch: [45] loss: 1.079\n",
            "epoch: [46] loss: 1.079\n",
            "epoch: [47] loss: 1.078\n",
            "epoch: [48] loss: 1.077\n",
            "epoch: [49] loss: 1.076\n",
            "epoch: [50] loss: 1.076\n",
            "epoch: [51] loss: 1.073\n",
            "epoch: [52] loss: 1.072\n",
            "epoch: [53] loss: 1.072\n",
            "epoch: [54] loss: 1.072\n",
            "epoch: [55] loss: 1.073\n",
            "epoch: [56] loss: 1.071\n",
            "epoch: [57] loss: 1.069\n",
            "epoch: [58] loss: 1.071\n",
            "epoch: [59] loss: 1.069\n",
            "epoch: [60] loss: 1.068\n",
            "epoch: [61] loss: 1.066\n",
            "epoch: [62] loss: 1.067\n",
            "epoch: [63] loss: 1.066\n",
            "epoch: [64] loss: 1.064\n",
            "epoch: [65] loss: 1.066\n",
            "epoch: [66] loss: 1.065\n",
            "epoch: [67] loss: 1.064\n",
            "epoch: [68] loss: 1.063\n",
            "epoch: [69] loss: 1.063\n",
            "epoch: [70] loss: 1.062\n",
            "epoch: [71] loss: 1.063\n",
            "epoch: [72] loss: 1.062\n",
            "epoch: [73] loss: 1.063\n",
            "epoch: [74] loss: 1.062\n",
            "epoch: [75] loss: 1.062\n",
            "epoch: [76] loss: 1.060\n",
            "epoch: [77] loss: 1.062\n",
            "epoch: [78] loss: 1.064\n",
            "epoch: [79] loss: 1.067\n",
            "epoch: [80] loss: 1.059\n",
            "epoch: [81] loss: 1.060\n",
            "epoch: [82] loss: 1.060\n",
            "epoch: [83] loss: 1.060\n",
            "epoch: [84] loss: 1.059\n",
            "epoch: [85] loss: 1.058\n",
            "epoch: [86] loss: 1.058\n",
            "epoch: [87] loss: 1.059\n",
            "epoch: [88] loss: 1.058\n",
            "epoch: [89] loss: 1.059\n",
            "epoch: [90] loss: 1.057\n",
            "epoch: [91] loss: 1.058\n",
            "epoch: [92] loss: 1.057\n",
            "epoch: [93] loss: 1.056\n",
            "epoch: [94] loss: 1.057\n",
            "epoch: [95] loss: 1.059\n",
            "epoch: [96] loss: 1.061\n",
            "epoch: [97] loss: 1.064\n",
            "epoch: [98] loss: 1.058\n",
            "epoch: [99] loss: 1.059\n",
            "epoch: [100] loss: 1.059\n",
            "epoch: [101] loss: 1.059\n",
            "epoch: [102] loss: 1.057\n",
            "epoch: [103] loss: 1.057\n",
            "epoch: [104] loss: 1.054\n",
            "epoch: [105] loss: 1.056\n",
            "epoch: [106] loss: 1.056\n",
            "epoch: [107] loss: 1.054\n",
            "epoch: [108] loss: 1.054\n",
            "epoch: [109] loss: 1.053\n",
            "epoch: [110] loss: 1.055\n",
            "epoch: [111] loss: 1.056\n",
            "epoch: [112] loss: 1.054\n",
            "epoch: [113] loss: 1.054\n",
            "epoch: [114] loss: 1.054\n",
            "epoch: [115] loss: 1.055\n",
            "epoch: [116] loss: 1.053\n",
            "epoch: [117] loss: 1.054\n",
            "epoch: [118] loss: 1.053\n",
            "epoch: [119] loss: 1.053\n",
            "epoch: [120] loss: 1.055\n",
            "epoch: [121] loss: 1.052\n",
            "epoch: [122] loss: 1.053\n",
            "epoch: [123] loss: 1.051\n",
            "epoch: [124] loss: 1.053\n",
            "epoch: [125] loss: 1.055\n",
            "epoch: [126] loss: 1.056\n",
            "epoch: [127] loss: 1.054\n",
            "epoch: [128] loss: 1.052\n",
            "epoch: [129] loss: 1.050\n",
            "epoch: [130] loss: 1.050\n",
            "epoch: [131] loss: 1.052\n",
            "epoch: [132] loss: 1.055\n",
            "epoch: [133] loss: 1.054\n",
            "epoch: [134] loss: 1.055\n",
            "epoch: [135] loss: 1.055\n",
            "epoch: [136] loss: 1.051\n",
            "epoch: [137] loss: 1.057\n",
            "epoch: [138] loss: 1.056\n",
            "epoch: [139] loss: 1.054\n",
            "epoch: [140] loss: 1.051\n",
            "epoch: [141] loss: 1.050\n",
            "epoch: [142] loss: 1.050\n",
            "epoch: [143] loss: 1.049\n",
            "epoch: [144] loss: 1.051\n",
            "epoch: [145] loss: 1.049\n",
            "epoch: [146] loss: 1.051\n",
            "epoch: [147] loss: 1.051\n",
            "epoch: [148] loss: 1.050\n",
            "epoch: [149] loss: 1.051\n",
            "epoch: [150] loss: 1.049\n",
            "epoch: [151] loss: 1.049\n",
            "epoch: [152] loss: 1.050\n",
            "epoch: [153] loss: 1.051\n",
            "epoch: [154] loss: 1.050\n",
            "epoch: [155] loss: 1.049\n",
            "epoch: [156] loss: 1.049\n",
            "epoch: [157] loss: 1.048\n",
            "epoch: [158] loss: 1.048\n",
            "epoch: [159] loss: 1.050\n",
            "epoch: [160] loss: 1.047\n",
            "epoch: [161] loss: 1.048\n",
            "epoch: [162] loss: 1.049\n",
            "epoch: [163] loss: 1.049\n",
            "epoch: [164] loss: 1.048\n",
            "epoch: [165] loss: 1.047\n",
            "epoch: [166] loss: 1.048\n",
            "epoch: [167] loss: 1.047\n",
            "epoch: [168] loss: 1.046\n",
            "epoch: [169] loss: 1.046\n",
            "epoch: [170] loss: 1.048\n",
            "epoch: [171] loss: 1.046\n",
            "epoch: [172] loss: 1.047\n",
            "epoch: [173] loss: 1.047\n",
            "epoch: [174] loss: 1.046\n",
            "epoch: [175] loss: 1.047\n",
            "epoch: [176] loss: 1.047\n",
            "epoch: [177] loss: 1.046\n",
            "epoch: [178] loss: 1.045\n",
            "epoch: [179] loss: 1.045\n",
            "epoch: [180] loss: 1.046\n",
            "epoch: [181] loss: 1.045\n",
            "epoch: [182] loss: 1.048\n",
            "epoch: [183] loss: 1.045\n",
            "epoch: [184] loss: 1.047\n",
            "epoch: [185] loss: 1.046\n",
            "epoch: [186] loss: 1.047\n",
            "epoch: [187] loss: 1.046\n",
            "epoch: [188] loss: 1.045\n",
            "epoch: [189] loss: 1.044\n",
            "epoch: [190] loss: 1.045\n",
            "epoch: [191] loss: 1.046\n",
            "epoch: [192] loss: 1.044\n",
            "epoch: [193] loss: 1.044\n",
            "epoch: [194] loss: 1.045\n",
            "epoch: [195] loss: 1.045\n",
            "epoch: [196] loss: 1.044\n",
            "epoch: [197] loss: 1.044\n",
            "epoch: [198] loss: 1.046\n",
            "epoch: [199] loss: 1.049\n",
            "epoch: [200] loss: 1.043\n",
            "epoch: [201] loss: 1.046\n",
            "epoch: [202] loss: 1.044\n",
            "epoch: [203] loss: 1.045\n",
            "epoch: [204] loss: 1.043\n",
            "epoch: [205] loss: 1.047\n",
            "epoch: [206] loss: 1.044\n",
            "epoch: [207] loss: 1.042\n",
            "epoch: [208] loss: 1.043\n",
            "epoch: [209] loss: 1.043\n",
            "epoch: [210] loss: 1.042\n",
            "epoch: [211] loss: 1.044\n",
            "epoch: [212] loss: 1.042\n",
            "epoch: [213] loss: 1.045\n",
            "epoch: [214] loss: 1.043\n",
            "epoch: [215] loss: 1.043\n",
            "epoch: [216] loss: 1.042\n",
            "epoch: [217] loss: 1.044\n",
            "epoch: [218] loss: 1.048\n",
            "epoch: [219] loss: 1.046\n",
            "epoch: [220] loss: 1.045\n",
            "epoch: [221] loss: 1.042\n",
            "epoch: [222] loss: 1.042\n",
            "epoch: [223] loss: 1.042\n",
            "epoch: [224] loss: 1.043\n",
            "epoch: [225] loss: 1.042\n",
            "epoch: [226] loss: 1.042\n",
            "epoch: [227] loss: 1.042\n",
            "epoch: [228] loss: 1.041\n",
            "epoch: [229] loss: 1.043\n",
            "epoch: [230] loss: 1.045\n",
            "epoch: [231] loss: 1.044\n",
            "epoch: [232] loss: 1.047\n",
            "epoch: [233] loss: 1.041\n",
            "epoch: [234] loss: 1.043\n",
            "epoch: [235] loss: 1.047\n",
            "epoch: [236] loss: 1.042\n",
            "epoch: [237] loss: 1.041\n",
            "epoch: [238] loss: 1.043\n",
            "epoch: [239] loss: 1.042\n",
            "epoch: [240] loss: 1.041\n",
            "epoch: [241] loss: 1.040\n",
            "epoch: [242] loss: 1.041\n",
            "epoch: [243] loss: 1.041\n",
            "epoch: [244] loss: 1.040\n",
            "epoch: [245] loss: 1.039\n",
            "epoch: [246] loss: 1.041\n",
            "epoch: [247] loss: 1.042\n",
            "epoch: [248] loss: 1.040\n",
            "epoch: [249] loss: 1.044\n",
            "epoch: [250] loss: 1.042\n",
            "epoch: [251] loss: 1.040\n",
            "epoch: [252] loss: 1.040\n",
            "epoch: [253] loss: 1.041\n",
            "epoch: [254] loss: 1.039\n",
            "epoch: [255] loss: 1.040\n",
            "epoch: [256] loss: 1.042\n",
            "epoch: [257] loss: 1.043\n",
            "epoch: [258] loss: 1.040\n",
            "epoch: [259] loss: 1.039\n",
            "epoch: [260] loss: 1.044\n",
            "epoch: [261] loss: 1.039\n",
            "epoch: [262] loss: 1.042\n",
            "epoch: [263] loss: 1.040\n",
            "epoch: [264] loss: 1.040\n",
            "epoch: [265] loss: 1.041\n",
            "epoch: [266] loss: 1.043\n",
            "epoch: [267] loss: 1.043\n",
            "epoch: [268] loss: 1.041\n",
            "epoch: [269] loss: 1.038\n",
            "epoch: [270] loss: 1.039\n",
            "epoch: [271] loss: 1.038\n",
            "epoch: [272] loss: 1.039\n",
            "epoch: [273] loss: 1.040\n",
            "epoch: [274] loss: 1.039\n",
            "epoch: [275] loss: 1.038\n",
            "epoch: [276] loss: 1.039\n",
            "epoch: [277] loss: 1.039\n",
            "epoch: [278] loss: 1.039\n",
            "epoch: [279] loss: 1.041\n",
            "epoch: [280] loss: 1.041\n",
            "epoch: [281] loss: 1.041\n",
            "epoch: [282] loss: 1.038\n",
            "epoch: [283] loss: 1.041\n",
            "epoch: [284] loss: 1.043\n",
            "epoch: [285] loss: 1.039\n",
            "epoch: [286] loss: 1.041\n",
            "epoch: [287] loss: 1.036\n",
            "epoch: [288] loss: 1.039\n",
            "epoch: [289] loss: 1.040\n",
            "epoch: [290] loss: 1.038\n",
            "epoch: [291] loss: 1.038\n",
            "epoch: [292] loss: 1.038\n",
            "epoch: [293] loss: 1.039\n",
            "epoch: [294] loss: 1.037\n",
            "epoch: [295] loss: 1.039\n",
            "epoch: [296] loss: 1.042\n",
            "epoch: [297] loss: 1.037\n",
            "epoch: [298] loss: 1.037\n",
            "epoch: [299] loss: 1.039\n",
            "epoch: [300] loss: 1.038\n",
            "epoch: [301] loss: 1.036\n",
            "epoch: [302] loss: 1.037\n",
            "epoch: [303] loss: 1.041\n",
            "epoch: [304] loss: 1.041\n",
            "epoch: [305] loss: 1.038\n",
            "epoch: [306] loss: 1.037\n",
            "epoch: [307] loss: 1.038\n",
            "epoch: [308] loss: 1.042\n",
            "epoch: [309] loss: 1.037\n",
            "epoch: [310] loss: 1.038\n",
            "epoch: [311] loss: 1.037\n",
            "epoch: [312] loss: 1.035\n",
            "epoch: [313] loss: 1.035\n",
            "epoch: [314] loss: 1.037\n",
            "epoch: [315] loss: 1.038\n",
            "epoch: [316] loss: 1.036\n",
            "epoch: [317] loss: 1.036\n",
            "epoch: [318] loss: 1.036\n",
            "epoch: [319] loss: 1.035\n",
            "epoch: [320] loss: 1.035\n",
            "epoch: [321] loss: 1.035\n",
            "epoch: [322] loss: 1.036\n",
            "epoch: [323] loss: 1.034\n",
            "epoch: [324] loss: 1.035\n",
            "epoch: [325] loss: 1.037\n",
            "epoch: [326] loss: 1.037\n",
            "epoch: [327] loss: 1.045\n",
            "epoch: [328] loss: 1.035\n",
            "epoch: [329] loss: 1.033\n",
            "epoch: [330] loss: 1.033\n",
            "epoch: [331] loss: 1.037\n",
            "epoch: [332] loss: 1.036\n",
            "epoch: [333] loss: 1.037\n",
            "epoch: [334] loss: 1.034\n",
            "epoch: [335] loss: 1.035\n",
            "epoch: [336] loss: 1.035\n",
            "epoch: [337] loss: 1.034\n",
            "epoch: [338] loss: 1.033\n",
            "epoch: [339] loss: 1.034\n",
            "epoch: [340] loss: 1.040\n",
            "epoch: [341] loss: 1.036\n",
            "epoch: [342] loss: 1.034\n",
            "epoch: [343] loss: 1.033\n",
            "epoch: [344] loss: 1.033\n",
            "epoch: [345] loss: 1.034\n",
            "epoch: [346] loss: 1.035\n",
            "epoch: [347] loss: 1.035\n",
            "epoch: [348] loss: 1.032\n",
            "epoch: [349] loss: 1.034\n",
            "epoch: [350] loss: 1.034\n",
            "epoch: [351] loss: 1.035\n",
            "epoch: [352] loss: 1.034\n",
            "epoch: [353] loss: 1.034\n",
            "epoch: [354] loss: 1.034\n",
            "epoch: [355] loss: 1.034\n",
            "epoch: [356] loss: 1.032\n",
            "epoch: [357] loss: 1.038\n",
            "epoch: [358] loss: 1.039\n",
            "epoch: [359] loss: 1.035\n",
            "epoch: [360] loss: 1.034\n",
            "epoch: [361] loss: 1.033\n",
            "epoch: [362] loss: 1.032\n",
            "epoch: [363] loss: 1.032\n",
            "epoch: [364] loss: 1.033\n",
            "epoch: [365] loss: 1.034\n",
            "epoch: [366] loss: 1.033\n",
            "epoch: [367] loss: 1.035\n",
            "epoch: [368] loss: 1.033\n",
            "epoch: [369] loss: 1.031\n",
            "epoch: [370] loss: 1.033\n",
            "epoch: [371] loss: 1.033\n",
            "epoch: [372] loss: 1.032\n",
            "epoch: [373] loss: 1.033\n",
            "epoch: [374] loss: 1.034\n",
            "epoch: [375] loss: 1.031\n",
            "epoch: [376] loss: 1.032\n",
            "epoch: [377] loss: 1.032\n",
            "epoch: [378] loss: 1.032\n",
            "epoch: [379] loss: 1.034\n",
            "epoch: [380] loss: 1.030\n",
            "epoch: [381] loss: 1.032\n",
            "epoch: [382] loss: 1.034\n",
            "epoch: [383] loss: 1.035\n",
            "epoch: [384] loss: 1.033\n",
            "epoch: [385] loss: 1.030\n",
            "epoch: [386] loss: 1.034\n",
            "epoch: [387] loss: 1.035\n",
            "epoch: [388] loss: 1.036\n",
            "epoch: [389] loss: 1.032\n",
            "epoch: [390] loss: 1.034\n",
            "epoch: [391] loss: 1.031\n",
            "epoch: [392] loss: 1.031\n",
            "epoch: [393] loss: 1.030\n",
            "epoch: [394] loss: 1.030\n",
            "epoch: [395] loss: 1.034\n",
            "epoch: [396] loss: 1.031\n",
            "epoch: [397] loss: 1.031\n",
            "epoch: [398] loss: 1.030\n",
            "epoch: [399] loss: 1.032\n",
            "epoch: [400] loss: 1.038\n",
            "epoch: [401] loss: 1.033\n",
            "epoch: [402] loss: 1.033\n",
            "epoch: [403] loss: 1.029\n",
            "epoch: [404] loss: 1.032\n",
            "epoch: [405] loss: 1.032\n",
            "epoch: [406] loss: 1.029\n",
            "epoch: [407] loss: 1.034\n",
            "epoch: [408] loss: 1.030\n",
            "epoch: [409] loss: 1.030\n",
            "epoch: [410] loss: 1.030\n",
            "epoch: [411] loss: 1.030\n",
            "epoch: [412] loss: 1.030\n",
            "epoch: [413] loss: 1.032\n",
            "epoch: [414] loss: 1.031\n",
            "epoch: [415] loss: 1.036\n",
            "epoch: [416] loss: 1.030\n",
            "epoch: [417] loss: 1.030\n",
            "epoch: [418] loss: 1.029\n",
            "epoch: [419] loss: 1.029\n",
            "epoch: [420] loss: 1.029\n",
            "epoch: [421] loss: 1.029\n",
            "epoch: [422] loss: 1.029\n",
            "epoch: [423] loss: 1.032\n",
            "epoch: [424] loss: 1.030\n",
            "epoch: [425] loss: 1.030\n",
            "epoch: [426] loss: 1.029\n",
            "epoch: [427] loss: 1.030\n",
            "epoch: [428] loss: 1.032\n",
            "epoch: [429] loss: 1.028\n",
            "epoch: [430] loss: 1.028\n",
            "epoch: [431] loss: 1.028\n",
            "epoch: [432] loss: 1.029\n",
            "epoch: [433] loss: 1.030\n",
            "epoch: [434] loss: 1.029\n",
            "epoch: [435] loss: 1.030\n",
            "epoch: [436] loss: 1.029\n",
            "epoch: [437] loss: 1.030\n",
            "epoch: [438] loss: 1.029\n",
            "epoch: [439] loss: 1.028\n",
            "epoch: [440] loss: 1.029\n",
            "epoch: [441] loss: 1.028\n",
            "epoch: [442] loss: 1.028\n",
            "epoch: [443] loss: 1.032\n",
            "epoch: [444] loss: 1.028\n",
            "epoch: [445] loss: 1.026\n",
            "epoch: [446] loss: 1.028\n",
            "epoch: [447] loss: 1.031\n",
            "epoch: [448] loss: 1.033\n",
            "epoch: [449] loss: 1.030\n",
            "epoch: [450] loss: 1.029\n",
            "epoch: [451] loss: 1.033\n",
            "epoch: [452] loss: 1.028\n",
            "epoch: [453] loss: 1.027\n",
            "epoch: [454] loss: 1.030\n",
            "epoch: [455] loss: 1.028\n",
            "epoch: [456] loss: 1.029\n",
            "epoch: [457] loss: 1.027\n",
            "epoch: [458] loss: 1.026\n",
            "epoch: [459] loss: 1.027\n",
            "epoch: [460] loss: 1.027\n",
            "epoch: [461] loss: 1.031\n",
            "epoch: [462] loss: 1.027\n",
            "epoch: [463] loss: 1.030\n",
            "epoch: [464] loss: 1.029\n",
            "epoch: [465] loss: 1.026\n",
            "epoch: [466] loss: 1.029\n",
            "epoch: [467] loss: 1.029\n",
            "epoch: [468] loss: 1.028\n",
            "epoch: [469] loss: 1.034\n",
            "epoch: [470] loss: 1.029\n",
            "epoch: [471] loss: 1.026\n",
            "epoch: [472] loss: 1.029\n",
            "epoch: [473] loss: 1.027\n",
            "epoch: [474] loss: 1.028\n",
            "epoch: [475] loss: 1.028\n",
            "epoch: [476] loss: 1.029\n",
            "epoch: [477] loss: 1.028\n",
            "epoch: [478] loss: 1.030\n",
            "epoch: [479] loss: 1.025\n",
            "epoch: [480] loss: 1.026\n",
            "epoch: [481] loss: 1.028\n",
            "epoch: [482] loss: 1.025\n",
            "epoch: [483] loss: 1.028\n",
            "epoch: [484] loss: 1.026\n",
            "epoch: [485] loss: 1.028\n",
            "epoch: [486] loss: 1.025\n",
            "epoch: [487] loss: 1.028\n",
            "epoch: [488] loss: 1.028\n",
            "epoch: [489] loss: 1.025\n",
            "epoch: [490] loss: 1.024\n",
            "epoch: [491] loss: 1.027\n",
            "epoch: [492] loss: 1.027\n",
            "epoch: [493] loss: 1.031\n",
            "epoch: [494] loss: 1.026\n",
            "epoch: [495] loss: 1.025\n",
            "epoch: [496] loss: 1.025\n",
            "epoch: [497] loss: 1.027\n",
            "epoch: [498] loss: 1.026\n",
            "epoch: [499] loss: 1.026\n",
            "epoch: [500] loss: 1.025\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 52 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 37 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 43 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 52 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 59 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 63 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 67 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 66 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 65 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 65 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   4\n",
            "epoch: [0 ] loss: 1.729\n",
            "epoch: [1] loss: 1.206\n",
            "epoch: [2] loss: 1.136\n",
            "epoch: [3] loss: 1.119\n",
            "epoch: [4] loss: 1.105\n",
            "epoch: [5] loss: 1.095\n",
            "epoch: [6] loss: 1.083\n",
            "epoch: [7] loss: 1.075\n",
            "epoch: [8] loss: 1.068\n",
            "epoch: [9] loss: 1.061\n",
            "epoch: [10] loss: 1.052\n",
            "epoch: [11] loss: 1.044\n",
            "epoch: [12] loss: 1.036\n",
            "epoch: [13] loss: 1.029\n",
            "epoch: [14] loss: 1.024\n",
            "epoch: [15] loss: 1.017\n",
            "epoch: [16] loss: 1.009\n",
            "epoch: [17] loss: 1.004\n",
            "epoch: [18] loss: 0.999\n",
            "epoch: [19] loss: 0.993\n",
            "epoch: [20] loss: 0.987\n",
            "epoch: [21] loss: 0.982\n",
            "epoch: [22] loss: 0.977\n",
            "epoch: [23] loss: 0.973\n",
            "epoch: [24] loss: 0.970\n",
            "epoch: [25] loss: 0.967\n",
            "epoch: [26] loss: 0.962\n",
            "epoch: [27] loss: 0.958\n",
            "epoch: [28] loss: 0.957\n",
            "epoch: [29] loss: 0.954\n",
            "epoch: [30] loss: 0.949\n",
            "epoch: [31] loss: 0.946\n",
            "epoch: [32] loss: 0.943\n",
            "epoch: [33] loss: 0.945\n",
            "epoch: [34] loss: 0.941\n",
            "epoch: [35] loss: 0.936\n",
            "epoch: [36] loss: 0.933\n",
            "epoch: [37] loss: 0.934\n",
            "epoch: [38] loss: 0.931\n",
            "epoch: [39] loss: 0.929\n",
            "epoch: [40] loss: 0.929\n",
            "epoch: [41] loss: 0.927\n",
            "epoch: [42] loss: 0.924\n",
            "epoch: [43] loss: 0.924\n",
            "epoch: [44] loss: 0.921\n",
            "epoch: [45] loss: 0.924\n",
            "epoch: [46] loss: 0.922\n",
            "epoch: [47] loss: 0.921\n",
            "epoch: [48] loss: 0.916\n",
            "epoch: [49] loss: 0.914\n",
            "epoch: [50] loss: 0.915\n",
            "epoch: [51] loss: 0.915\n",
            "epoch: [52] loss: 0.914\n",
            "epoch: [53] loss: 0.914\n",
            "epoch: [54] loss: 0.910\n",
            "epoch: [55] loss: 0.912\n",
            "epoch: [56] loss: 0.911\n",
            "epoch: [57] loss: 0.909\n",
            "epoch: [58] loss: 0.909\n",
            "epoch: [59] loss: 0.908\n",
            "epoch: [60] loss: 0.907\n",
            "epoch: [61] loss: 0.921\n",
            "epoch: [62] loss: 0.923\n",
            "epoch: [63] loss: 0.908\n",
            "epoch: [64] loss: 0.906\n",
            "epoch: [65] loss: 0.907\n",
            "epoch: [66] loss: 0.906\n",
            "epoch: [67] loss: 0.907\n",
            "epoch: [68] loss: 0.907\n",
            "epoch: [69] loss: 0.904\n",
            "epoch: [70] loss: 0.904\n",
            "epoch: [71] loss: 0.901\n",
            "epoch: [72] loss: 0.902\n",
            "epoch: [73] loss: 0.903\n",
            "epoch: [74] loss: 0.906\n",
            "epoch: [75] loss: 0.911\n",
            "epoch: [76] loss: 0.905\n",
            "epoch: [77] loss: 0.901\n",
            "epoch: [78] loss: 0.903\n",
            "epoch: [79] loss: 0.899\n",
            "epoch: [80] loss: 0.900\n",
            "epoch: [81] loss: 0.899\n",
            "epoch: [82] loss: 0.896\n",
            "epoch: [83] loss: 0.897\n",
            "epoch: [84] loss: 0.903\n",
            "epoch: [85] loss: 0.900\n",
            "epoch: [86] loss: 0.902\n",
            "epoch: [87] loss: 0.898\n",
            "epoch: [88] loss: 0.898\n",
            "epoch: [89] loss: 0.897\n",
            "epoch: [90] loss: 0.896\n",
            "epoch: [91] loss: 0.897\n",
            "epoch: [92] loss: 0.900\n",
            "epoch: [93] loss: 0.904\n",
            "epoch: [94] loss: 0.896\n",
            "epoch: [95] loss: 0.894\n",
            "epoch: [96] loss: 0.894\n",
            "epoch: [97] loss: 0.895\n",
            "epoch: [98] loss: 0.894\n",
            "epoch: [99] loss: 0.895\n",
            "epoch: [100] loss: 0.894\n",
            "epoch: [101] loss: 0.899\n",
            "epoch: [102] loss: 0.900\n",
            "epoch: [103] loss: 0.894\n",
            "epoch: [104] loss: 0.895\n",
            "epoch: [105] loss: 0.893\n",
            "epoch: [106] loss: 0.893\n",
            "epoch: [107] loss: 0.893\n",
            "epoch: [108] loss: 0.894\n",
            "epoch: [109] loss: 0.892\n",
            "epoch: [110] loss: 0.893\n",
            "epoch: [111] loss: 0.895\n",
            "epoch: [112] loss: 0.894\n",
            "epoch: [113] loss: 0.899\n",
            "epoch: [114] loss: 0.893\n",
            "epoch: [115] loss: 0.892\n",
            "epoch: [116] loss: 0.888\n",
            "epoch: [117] loss: 0.894\n",
            "epoch: [118] loss: 0.892\n",
            "epoch: [119] loss: 0.893\n",
            "epoch: [120] loss: 0.892\n",
            "epoch: [121] loss: 0.892\n",
            "epoch: [122] loss: 0.892\n",
            "epoch: [123] loss: 0.890\n",
            "epoch: [124] loss: 0.890\n",
            "epoch: [125] loss: 0.888\n",
            "epoch: [126] loss: 0.889\n",
            "epoch: [127] loss: 0.891\n",
            "epoch: [128] loss: 0.888\n",
            "epoch: [129] loss: 0.890\n",
            "epoch: [130] loss: 0.889\n",
            "epoch: [131] loss: 0.890\n",
            "epoch: [132] loss: 0.891\n",
            "epoch: [133] loss: 0.889\n",
            "epoch: [134] loss: 0.888\n",
            "epoch: [135] loss: 0.889\n",
            "epoch: [136] loss: 0.886\n",
            "epoch: [137] loss: 0.888\n",
            "epoch: [138] loss: 0.888\n",
            "epoch: [139] loss: 0.888\n",
            "epoch: [140] loss: 0.889\n",
            "epoch: [141] loss: 0.889\n",
            "epoch: [142] loss: 0.887\n",
            "epoch: [143] loss: 0.888\n",
            "epoch: [144] loss: 0.891\n",
            "epoch: [145] loss: 0.892\n",
            "epoch: [146] loss: 0.889\n",
            "epoch: [147] loss: 0.888\n",
            "epoch: [148] loss: 0.887\n",
            "epoch: [149] loss: 0.887\n",
            "epoch: [150] loss: 0.885\n",
            "epoch: [151] loss: 0.885\n",
            "epoch: [152] loss: 0.888\n",
            "epoch: [153] loss: 0.888\n",
            "epoch: [154] loss: 0.887\n",
            "epoch: [155] loss: 0.887\n",
            "epoch: [156] loss: 0.886\n",
            "epoch: [157] loss: 0.885\n",
            "epoch: [158] loss: 0.885\n",
            "epoch: [159] loss: 0.884\n",
            "epoch: [160] loss: 0.884\n",
            "epoch: [161] loss: 0.886\n",
            "epoch: [162] loss: 0.884\n",
            "epoch: [163] loss: 0.885\n",
            "epoch: [164] loss: 0.888\n",
            "epoch: [165] loss: 0.884\n",
            "epoch: [166] loss: 0.885\n",
            "epoch: [167] loss: 0.884\n",
            "epoch: [168] loss: 0.884\n",
            "epoch: [169] loss: 0.886\n",
            "epoch: [170] loss: 0.885\n",
            "epoch: [171] loss: 0.883\n",
            "epoch: [172] loss: 0.882\n",
            "epoch: [173] loss: 0.886\n",
            "epoch: [174] loss: 0.884\n",
            "epoch: [175] loss: 0.882\n",
            "epoch: [176] loss: 0.883\n",
            "epoch: [177] loss: 0.881\n",
            "epoch: [178] loss: 0.882\n",
            "epoch: [179] loss: 0.885\n",
            "epoch: [180] loss: 0.889\n",
            "epoch: [181] loss: 0.882\n",
            "epoch: [182] loss: 0.891\n",
            "epoch: [183] loss: 0.889\n",
            "epoch: [184] loss: 0.883\n",
            "epoch: [185] loss: 0.885\n",
            "epoch: [186] loss: 0.883\n",
            "epoch: [187] loss: 0.882\n",
            "epoch: [188] loss: 0.881\n",
            "epoch: [189] loss: 0.881\n",
            "epoch: [190] loss: 0.880\n",
            "epoch: [191] loss: 0.881\n",
            "epoch: [192] loss: 0.879\n",
            "epoch: [193] loss: 0.882\n",
            "epoch: [194] loss: 0.879\n",
            "epoch: [195] loss: 0.883\n",
            "epoch: [196] loss: 0.881\n",
            "epoch: [197] loss: 0.881\n",
            "epoch: [198] loss: 0.882\n",
            "epoch: [199] loss: 0.883\n",
            "epoch: [200] loss: 0.880\n",
            "epoch: [201] loss: 0.880\n",
            "epoch: [202] loss: 0.880\n",
            "epoch: [203] loss: 0.880\n",
            "epoch: [204] loss: 0.884\n",
            "epoch: [205] loss: 0.879\n",
            "epoch: [206] loss: 0.881\n",
            "epoch: [207] loss: 0.880\n",
            "epoch: [208] loss: 0.881\n",
            "epoch: [209] loss: 0.883\n",
            "epoch: [210] loss: 0.878\n",
            "epoch: [211] loss: 0.879\n",
            "epoch: [212] loss: 0.879\n",
            "epoch: [213] loss: 0.885\n",
            "epoch: [214] loss: 0.878\n",
            "epoch: [215] loss: 0.880\n",
            "epoch: [216] loss: 0.883\n",
            "epoch: [217] loss: 0.880\n",
            "epoch: [218] loss: 0.881\n",
            "epoch: [219] loss: 0.881\n",
            "epoch: [220] loss: 0.878\n",
            "epoch: [221] loss: 0.880\n",
            "epoch: [222] loss: 0.878\n",
            "epoch: [223] loss: 0.877\n",
            "epoch: [224] loss: 0.879\n",
            "epoch: [225] loss: 0.879\n",
            "epoch: [226] loss: 0.876\n",
            "epoch: [227] loss: 0.877\n",
            "epoch: [228] loss: 0.877\n",
            "epoch: [229] loss: 0.878\n",
            "epoch: [230] loss: 0.877\n",
            "epoch: [231] loss: 0.876\n",
            "epoch: [232] loss: 0.876\n",
            "epoch: [233] loss: 0.880\n",
            "epoch: [234] loss: 0.877\n",
            "epoch: [235] loss: 0.878\n",
            "epoch: [236] loss: 0.878\n",
            "epoch: [237] loss: 0.878\n",
            "epoch: [238] loss: 0.879\n",
            "epoch: [239] loss: 0.874\n",
            "epoch: [240] loss: 0.879\n",
            "epoch: [241] loss: 0.883\n",
            "epoch: [242] loss: 0.878\n",
            "epoch: [243] loss: 0.878\n",
            "epoch: [244] loss: 0.876\n",
            "epoch: [245] loss: 0.876\n",
            "epoch: [246] loss: 0.877\n",
            "epoch: [247] loss: 0.876\n",
            "epoch: [248] loss: 0.874\n",
            "epoch: [249] loss: 0.876\n",
            "epoch: [250] loss: 0.875\n",
            "epoch: [251] loss: 0.874\n",
            "epoch: [252] loss: 0.880\n",
            "epoch: [253] loss: 0.875\n",
            "epoch: [254] loss: 0.877\n",
            "epoch: [255] loss: 0.876\n",
            "epoch: [256] loss: 0.874\n",
            "epoch: [257] loss: 0.873\n",
            "epoch: [258] loss: 0.878\n",
            "epoch: [259] loss: 0.876\n",
            "epoch: [260] loss: 0.877\n",
            "epoch: [261] loss: 0.875\n",
            "epoch: [262] loss: 0.879\n",
            "epoch: [263] loss: 0.883\n",
            "epoch: [264] loss: 0.878\n",
            "epoch: [265] loss: 0.877\n",
            "epoch: [266] loss: 0.873\n",
            "epoch: [267] loss: 0.877\n",
            "epoch: [268] loss: 0.876\n",
            "epoch: [269] loss: 0.874\n",
            "epoch: [270] loss: 0.875\n",
            "epoch: [271] loss: 0.874\n",
            "epoch: [272] loss: 0.874\n",
            "epoch: [273] loss: 0.875\n",
            "epoch: [274] loss: 0.876\n",
            "epoch: [275] loss: 0.875\n",
            "epoch: [276] loss: 0.875\n",
            "epoch: [277] loss: 0.874\n",
            "epoch: [278] loss: 0.874\n",
            "epoch: [279] loss: 0.875\n",
            "epoch: [280] loss: 0.875\n",
            "epoch: [281] loss: 0.873\n",
            "epoch: [282] loss: 0.874\n",
            "epoch: [283] loss: 0.873\n",
            "epoch: [284] loss: 0.873\n",
            "epoch: [285] loss: 0.872\n",
            "epoch: [286] loss: 0.877\n",
            "epoch: [287] loss: 0.872\n",
            "epoch: [288] loss: 0.876\n",
            "epoch: [289] loss: 0.872\n",
            "epoch: [290] loss: 0.874\n",
            "epoch: [291] loss: 0.873\n",
            "epoch: [292] loss: 0.872\n",
            "epoch: [293] loss: 0.871\n",
            "epoch: [294] loss: 0.871\n",
            "epoch: [295] loss: 0.881\n",
            "epoch: [296] loss: 0.873\n",
            "epoch: [297] loss: 0.873\n",
            "epoch: [298] loss: 0.871\n",
            "epoch: [299] loss: 0.874\n",
            "epoch: [300] loss: 0.871\n",
            "epoch: [301] loss: 0.871\n",
            "epoch: [302] loss: 0.875\n",
            "epoch: [303] loss: 0.878\n",
            "epoch: [304] loss: 0.872\n",
            "epoch: [305] loss: 0.879\n",
            "epoch: [306] loss: 0.875\n",
            "epoch: [307] loss: 0.881\n",
            "epoch: [308] loss: 0.876\n",
            "epoch: [309] loss: 0.869\n",
            "epoch: [310] loss: 0.873\n",
            "epoch: [311] loss: 0.874\n",
            "epoch: [312] loss: 0.871\n",
            "epoch: [313] loss: 0.872\n",
            "epoch: [314] loss: 0.871\n",
            "epoch: [315] loss: 0.870\n",
            "epoch: [316] loss: 0.872\n",
            "epoch: [317] loss: 0.870\n",
            "epoch: [318] loss: 0.873\n",
            "epoch: [319] loss: 0.873\n",
            "epoch: [320] loss: 0.872\n",
            "epoch: [321] loss: 0.872\n",
            "epoch: [322] loss: 0.870\n",
            "epoch: [323] loss: 0.873\n",
            "epoch: [324] loss: 0.874\n",
            "epoch: [325] loss: 0.872\n",
            "epoch: [326] loss: 0.870\n",
            "epoch: [327] loss: 0.872\n",
            "epoch: [328] loss: 0.872\n",
            "epoch: [329] loss: 0.870\n",
            "epoch: [330] loss: 0.873\n",
            "epoch: [331] loss: 0.869\n",
            "epoch: [332] loss: 0.870\n",
            "epoch: [333] loss: 0.870\n",
            "epoch: [334] loss: 0.869\n",
            "epoch: [335] loss: 0.870\n",
            "epoch: [336] loss: 0.874\n",
            "epoch: [337] loss: 0.871\n",
            "epoch: [338] loss: 0.868\n",
            "epoch: [339] loss: 0.868\n",
            "epoch: [340] loss: 0.872\n",
            "epoch: [341] loss: 0.868\n",
            "epoch: [342] loss: 0.873\n",
            "epoch: [343] loss: 0.876\n",
            "epoch: [344] loss: 0.868\n",
            "epoch: [345] loss: 0.871\n",
            "epoch: [346] loss: 0.873\n",
            "epoch: [347] loss: 0.868\n",
            "epoch: [348] loss: 0.872\n",
            "epoch: [349] loss: 0.867\n",
            "epoch: [350] loss: 0.868\n",
            "epoch: [351] loss: 0.871\n",
            "epoch: [352] loss: 0.874\n",
            "epoch: [353] loss: 0.872\n",
            "epoch: [354] loss: 0.869\n",
            "epoch: [355] loss: 0.868\n",
            "epoch: [356] loss: 0.870\n",
            "epoch: [357] loss: 0.870\n",
            "epoch: [358] loss: 0.869\n",
            "epoch: [359] loss: 0.868\n",
            "epoch: [360] loss: 0.868\n",
            "epoch: [361] loss: 0.871\n",
            "epoch: [362] loss: 0.868\n",
            "epoch: [363] loss: 0.866\n",
            "epoch: [364] loss: 0.869\n",
            "epoch: [365] loss: 0.868\n",
            "epoch: [366] loss: 0.866\n",
            "epoch: [367] loss: 0.867\n",
            "epoch: [368] loss: 0.867\n",
            "epoch: [369] loss: 0.869\n",
            "epoch: [370] loss: 0.870\n",
            "epoch: [371] loss: 0.869\n",
            "epoch: [372] loss: 0.872\n",
            "epoch: [373] loss: 0.865\n",
            "epoch: [374] loss: 0.866\n",
            "epoch: [375] loss: 0.866\n",
            "epoch: [376] loss: 0.872\n",
            "epoch: [377] loss: 0.867\n",
            "epoch: [378] loss: 0.868\n",
            "epoch: [379] loss: 0.870\n",
            "epoch: [380] loss: 0.865\n",
            "epoch: [381] loss: 0.865\n",
            "epoch: [382] loss: 0.872\n",
            "epoch: [383] loss: 0.868\n",
            "epoch: [384] loss: 0.866\n",
            "epoch: [385] loss: 0.866\n",
            "epoch: [386] loss: 0.869\n",
            "epoch: [387] loss: 0.870\n",
            "epoch: [388] loss: 0.864\n",
            "epoch: [389] loss: 0.868\n",
            "epoch: [390] loss: 0.867\n",
            "epoch: [391] loss: 0.868\n",
            "epoch: [392] loss: 0.868\n",
            "epoch: [393] loss: 0.866\n",
            "epoch: [394] loss: 0.872\n",
            "epoch: [395] loss: 0.867\n",
            "epoch: [396] loss: 0.864\n",
            "epoch: [397] loss: 0.865\n",
            "epoch: [398] loss: 0.869\n",
            "epoch: [399] loss: 0.869\n",
            "epoch: [400] loss: 0.866\n",
            "epoch: [401] loss: 0.867\n",
            "epoch: [402] loss: 0.867\n",
            "epoch: [403] loss: 0.866\n",
            "epoch: [404] loss: 0.866\n",
            "epoch: [405] loss: 0.867\n",
            "epoch: [406] loss: 0.867\n",
            "epoch: [407] loss: 0.866\n",
            "epoch: [408] loss: 0.864\n",
            "epoch: [409] loss: 0.865\n",
            "epoch: [410] loss: 0.865\n",
            "epoch: [411] loss: 0.869\n",
            "epoch: [412] loss: 0.865\n",
            "epoch: [413] loss: 0.868\n",
            "epoch: [414] loss: 0.869\n",
            "epoch: [415] loss: 0.865\n",
            "epoch: [416] loss: 0.864\n",
            "epoch: [417] loss: 0.866\n",
            "epoch: [418] loss: 0.863\n",
            "epoch: [419] loss: 0.863\n",
            "epoch: [420] loss: 0.864\n",
            "epoch: [421] loss: 0.866\n",
            "epoch: [422] loss: 0.868\n",
            "epoch: [423] loss: 0.867\n",
            "epoch: [424] loss: 0.866\n",
            "epoch: [425] loss: 0.866\n",
            "epoch: [426] loss: 0.864\n",
            "epoch: [427] loss: 0.863\n",
            "epoch: [428] loss: 0.865\n",
            "epoch: [429] loss: 0.864\n",
            "epoch: [430] loss: 0.866\n",
            "epoch: [431] loss: 0.865\n",
            "epoch: [432] loss: 0.865\n",
            "epoch: [433] loss: 0.865\n",
            "epoch: [434] loss: 0.862\n",
            "epoch: [435] loss: 0.864\n",
            "epoch: [436] loss: 0.866\n",
            "epoch: [437] loss: 0.861\n",
            "epoch: [438] loss: 0.862\n",
            "epoch: [439] loss: 0.861\n",
            "epoch: [440] loss: 0.863\n",
            "epoch: [441] loss: 0.867\n",
            "epoch: [442] loss: 0.867\n",
            "epoch: [443] loss: 0.865\n",
            "epoch: [444] loss: 0.868\n",
            "epoch: [445] loss: 0.862\n",
            "epoch: [446] loss: 0.862\n",
            "epoch: [447] loss: 0.865\n",
            "epoch: [448] loss: 0.862\n",
            "epoch: [449] loss: 0.862\n",
            "epoch: [450] loss: 0.863\n",
            "epoch: [451] loss: 0.865\n",
            "epoch: [452] loss: 0.867\n",
            "epoch: [453] loss: 0.866\n",
            "epoch: [454] loss: 0.864\n",
            "epoch: [455] loss: 0.866\n",
            "epoch: [456] loss: 0.863\n",
            "epoch: [457] loss: 0.863\n",
            "epoch: [458] loss: 0.862\n",
            "epoch: [459] loss: 0.862\n",
            "epoch: [460] loss: 0.864\n",
            "epoch: [461] loss: 0.861\n",
            "epoch: [462] loss: 0.862\n",
            "epoch: [463] loss: 0.863\n",
            "epoch: [464] loss: 0.867\n",
            "epoch: [465] loss: 0.871\n",
            "epoch: [466] loss: 0.861\n",
            "epoch: [467] loss: 0.862\n",
            "epoch: [468] loss: 0.860\n",
            "epoch: [469] loss: 0.864\n",
            "epoch: [470] loss: 0.861\n",
            "epoch: [471] loss: 0.861\n",
            "epoch: [472] loss: 0.864\n",
            "epoch: [473] loss: 0.870\n",
            "epoch: [474] loss: 0.864\n",
            "epoch: [475] loss: 0.863\n",
            "epoch: [476] loss: 0.862\n",
            "epoch: [477] loss: 0.866\n",
            "epoch: [478] loss: 0.864\n",
            "epoch: [479] loss: 0.860\n",
            "epoch: [480] loss: 0.863\n",
            "epoch: [481] loss: 0.860\n",
            "epoch: [482] loss: 0.870\n",
            "epoch: [483] loss: 0.865\n",
            "epoch: [484] loss: 0.860\n",
            "epoch: [485] loss: 0.867\n",
            "epoch: [486] loss: 0.862\n",
            "epoch: [487] loss: 0.861\n",
            "epoch: [488] loss: 0.862\n",
            "epoch: [489] loss: 0.862\n",
            "epoch: [490] loss: 0.861\n",
            "epoch: [491] loss: 0.861\n",
            "epoch: [492] loss: 0.861\n",
            "epoch: [493] loss: 0.858\n",
            "epoch: [494] loss: 0.861\n",
            "epoch: [495] loss: 0.864\n",
            "epoch: [496] loss: 0.862\n",
            "epoch: [497] loss: 0.860\n",
            "epoch: [498] loss: 0.859\n",
            "epoch: [499] loss: 0.861\n",
            "epoch: [500] loss: 0.860\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 61 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 41 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 51 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 61 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 70 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 77 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 79 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 76 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 73 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   5\n",
            "epoch: [0 ] loss: 1.378\n",
            "epoch: [1] loss: 1.132\n",
            "epoch: [2] loss: 1.069\n",
            "epoch: [3] loss: 1.032\n",
            "epoch: [4] loss: 1.004\n",
            "epoch: [5] loss: 0.985\n",
            "epoch: [6] loss: 0.966\n",
            "epoch: [7] loss: 0.945\n",
            "epoch: [8] loss: 0.928\n",
            "epoch: [9] loss: 0.910\n",
            "epoch: [10] loss: 0.892\n",
            "epoch: [11] loss: 0.876\n",
            "epoch: [12] loss: 0.861\n",
            "epoch: [13] loss: 0.849\n",
            "epoch: [14] loss: 0.834\n",
            "epoch: [15] loss: 0.821\n",
            "epoch: [16] loss: 0.811\n",
            "epoch: [17] loss: 0.803\n",
            "epoch: [18] loss: 0.793\n",
            "epoch: [19] loss: 0.784\n",
            "epoch: [20] loss: 0.775\n",
            "epoch: [21] loss: 0.768\n",
            "epoch: [22] loss: 0.762\n",
            "epoch: [23] loss: 0.755\n",
            "epoch: [24] loss: 0.749\n",
            "epoch: [25] loss: 0.743\n",
            "epoch: [26] loss: 0.738\n",
            "epoch: [27] loss: 0.736\n",
            "epoch: [28] loss: 0.732\n",
            "epoch: [29] loss: 0.725\n",
            "epoch: [30] loss: 0.723\n",
            "epoch: [31] loss: 0.717\n",
            "epoch: [32] loss: 0.715\n",
            "epoch: [33] loss: 0.716\n",
            "epoch: [34] loss: 0.708\n",
            "epoch: [35] loss: 0.705\n",
            "epoch: [36] loss: 0.701\n",
            "epoch: [37] loss: 0.699\n",
            "epoch: [38] loss: 0.699\n",
            "epoch: [39] loss: 0.697\n",
            "epoch: [40] loss: 0.694\n",
            "epoch: [41] loss: 0.692\n",
            "epoch: [42] loss: 0.690\n",
            "epoch: [43] loss: 0.692\n",
            "epoch: [44] loss: 0.689\n",
            "epoch: [45] loss: 0.693\n",
            "epoch: [46] loss: 0.688\n",
            "epoch: [47] loss: 0.688\n",
            "epoch: [48] loss: 0.690\n",
            "epoch: [49] loss: 0.685\n",
            "epoch: [50] loss: 0.685\n",
            "epoch: [51] loss: 0.682\n",
            "epoch: [52] loss: 0.683\n",
            "epoch: [53] loss: 0.678\n",
            "epoch: [54] loss: 0.679\n",
            "epoch: [55] loss: 0.678\n",
            "epoch: [56] loss: 0.679\n",
            "epoch: [57] loss: 0.677\n",
            "epoch: [58] loss: 0.678\n",
            "epoch: [59] loss: 0.675\n",
            "epoch: [60] loss: 0.674\n",
            "epoch: [61] loss: 0.673\n",
            "epoch: [62] loss: 0.675\n",
            "epoch: [63] loss: 0.675\n",
            "epoch: [64] loss: 0.673\n",
            "epoch: [65] loss: 0.678\n",
            "epoch: [66] loss: 0.677\n",
            "epoch: [67] loss: 0.677\n",
            "epoch: [68] loss: 0.673\n",
            "epoch: [69] loss: 0.670\n",
            "epoch: [70] loss: 0.671\n",
            "epoch: [71] loss: 0.672\n",
            "epoch: [72] loss: 0.671\n",
            "epoch: [73] loss: 0.670\n",
            "epoch: [74] loss: 0.670\n",
            "epoch: [75] loss: 0.669\n",
            "epoch: [76] loss: 0.669\n",
            "epoch: [77] loss: 0.667\n",
            "epoch: [78] loss: 0.670\n",
            "epoch: [79] loss: 0.670\n",
            "epoch: [80] loss: 0.670\n",
            "epoch: [81] loss: 0.668\n",
            "epoch: [82] loss: 0.665\n",
            "epoch: [83] loss: 0.665\n",
            "epoch: [84] loss: 0.664\n",
            "epoch: [85] loss: 0.665\n",
            "epoch: [86] loss: 0.669\n",
            "epoch: [87] loss: 0.665\n",
            "epoch: [88] loss: 0.664\n",
            "epoch: [89] loss: 0.666\n",
            "epoch: [90] loss: 0.664\n",
            "epoch: [91] loss: 0.664\n",
            "epoch: [92] loss: 0.665\n",
            "epoch: [93] loss: 0.666\n",
            "epoch: [94] loss: 0.662\n",
            "epoch: [95] loss: 0.663\n",
            "epoch: [96] loss: 0.662\n",
            "epoch: [97] loss: 0.663\n",
            "epoch: [98] loss: 0.661\n",
            "epoch: [99] loss: 0.661\n",
            "epoch: [100] loss: 0.662\n",
            "epoch: [101] loss: 0.662\n",
            "epoch: [102] loss: 0.662\n",
            "epoch: [103] loss: 0.661\n",
            "epoch: [104] loss: 0.660\n",
            "epoch: [105] loss: 0.663\n",
            "epoch: [106] loss: 0.663\n",
            "epoch: [107] loss: 0.662\n",
            "epoch: [108] loss: 0.658\n",
            "epoch: [109] loss: 0.659\n",
            "epoch: [110] loss: 0.659\n",
            "epoch: [111] loss: 0.660\n",
            "epoch: [112] loss: 0.659\n",
            "epoch: [113] loss: 0.658\n",
            "epoch: [114] loss: 0.660\n",
            "epoch: [115] loss: 0.659\n",
            "epoch: [116] loss: 0.660\n",
            "epoch: [117] loss: 0.661\n",
            "epoch: [118] loss: 0.658\n",
            "epoch: [119] loss: 0.656\n",
            "epoch: [120] loss: 0.659\n",
            "epoch: [121] loss: 0.658\n",
            "epoch: [122] loss: 0.660\n",
            "epoch: [123] loss: 0.659\n",
            "epoch: [124] loss: 0.657\n",
            "epoch: [125] loss: 0.656\n",
            "epoch: [126] loss: 0.656\n",
            "epoch: [127] loss: 0.655\n",
            "epoch: [128] loss: 0.656\n",
            "epoch: [129] loss: 0.652\n",
            "epoch: [130] loss: 0.658\n",
            "epoch: [131] loss: 0.655\n",
            "epoch: [132] loss: 0.655\n",
            "epoch: [133] loss: 0.657\n",
            "epoch: [134] loss: 0.655\n",
            "epoch: [135] loss: 0.655\n",
            "epoch: [136] loss: 0.656\n",
            "epoch: [137] loss: 0.655\n",
            "epoch: [138] loss: 0.655\n",
            "epoch: [139] loss: 0.653\n",
            "epoch: [140] loss: 0.655\n",
            "epoch: [141] loss: 0.654\n",
            "epoch: [142] loss: 0.655\n",
            "epoch: [143] loss: 0.657\n",
            "epoch: [144] loss: 0.652\n",
            "epoch: [145] loss: 0.655\n",
            "epoch: [146] loss: 0.656\n",
            "epoch: [147] loss: 0.654\n",
            "epoch: [148] loss: 0.654\n",
            "epoch: [149] loss: 0.658\n",
            "epoch: [150] loss: 0.658\n",
            "epoch: [151] loss: 0.654\n",
            "epoch: [152] loss: 0.655\n",
            "epoch: [153] loss: 0.655\n",
            "epoch: [154] loss: 0.656\n",
            "epoch: [155] loss: 0.652\n",
            "epoch: [156] loss: 0.653\n",
            "epoch: [157] loss: 0.652\n",
            "epoch: [158] loss: 0.657\n",
            "epoch: [159] loss: 0.655\n",
            "epoch: [160] loss: 0.650\n",
            "epoch: [161] loss: 0.660\n",
            "epoch: [162] loss: 0.654\n",
            "epoch: [163] loss: 0.651\n",
            "epoch: [164] loss: 0.651\n",
            "epoch: [165] loss: 0.652\n",
            "epoch: [166] loss: 0.651\n",
            "epoch: [167] loss: 0.653\n",
            "epoch: [168] loss: 0.654\n",
            "epoch: [169] loss: 0.650\n",
            "epoch: [170] loss: 0.652\n",
            "epoch: [171] loss: 0.652\n",
            "epoch: [172] loss: 0.649\n",
            "epoch: [173] loss: 0.652\n",
            "epoch: [174] loss: 0.650\n",
            "epoch: [175] loss: 0.650\n",
            "epoch: [176] loss: 0.650\n",
            "epoch: [177] loss: 0.656\n",
            "epoch: [178] loss: 0.653\n",
            "epoch: [179] loss: 0.651\n",
            "epoch: [180] loss: 0.650\n",
            "epoch: [181] loss: 0.649\n",
            "epoch: [182] loss: 0.649\n",
            "epoch: [183] loss: 0.650\n",
            "epoch: [184] loss: 0.649\n",
            "epoch: [185] loss: 0.649\n",
            "epoch: [186] loss: 0.649\n",
            "epoch: [187] loss: 0.651\n",
            "epoch: [188] loss: 0.649\n",
            "epoch: [189] loss: 0.650\n",
            "epoch: [190] loss: 0.650\n",
            "epoch: [191] loss: 0.653\n",
            "epoch: [192] loss: 0.648\n",
            "epoch: [193] loss: 0.650\n",
            "epoch: [194] loss: 0.650\n",
            "epoch: [195] loss: 0.650\n",
            "epoch: [196] loss: 0.648\n",
            "epoch: [197] loss: 0.650\n",
            "epoch: [198] loss: 0.647\n",
            "epoch: [199] loss: 0.648\n",
            "epoch: [200] loss: 0.647\n",
            "epoch: [201] loss: 0.651\n",
            "epoch: [202] loss: 0.647\n",
            "epoch: [203] loss: 0.647\n",
            "epoch: [204] loss: 0.647\n",
            "epoch: [205] loss: 0.649\n",
            "epoch: [206] loss: 0.650\n",
            "epoch: [207] loss: 0.647\n",
            "epoch: [208] loss: 0.650\n",
            "epoch: [209] loss: 0.649\n",
            "epoch: [210] loss: 0.647\n",
            "epoch: [211] loss: 0.648\n",
            "epoch: [212] loss: 0.648\n",
            "epoch: [213] loss: 0.647\n",
            "epoch: [214] loss: 0.645\n",
            "epoch: [215] loss: 0.647\n",
            "epoch: [216] loss: 0.647\n",
            "epoch: [217] loss: 0.647\n",
            "epoch: [218] loss: 0.647\n",
            "epoch: [219] loss: 0.653\n",
            "epoch: [220] loss: 0.647\n",
            "epoch: [221] loss: 0.643\n",
            "epoch: [222] loss: 0.645\n",
            "epoch: [223] loss: 0.645\n",
            "epoch: [224] loss: 0.647\n",
            "epoch: [225] loss: 0.646\n",
            "epoch: [226] loss: 0.643\n",
            "epoch: [227] loss: 0.647\n",
            "epoch: [228] loss: 0.644\n",
            "epoch: [229] loss: 0.646\n",
            "epoch: [230] loss: 0.646\n",
            "epoch: [231] loss: 0.646\n",
            "epoch: [232] loss: 0.647\n",
            "epoch: [233] loss: 0.645\n",
            "epoch: [234] loss: 0.646\n",
            "epoch: [235] loss: 0.645\n",
            "epoch: [236] loss: 0.644\n",
            "epoch: [237] loss: 0.644\n",
            "epoch: [238] loss: 0.644\n",
            "epoch: [239] loss: 0.644\n",
            "epoch: [240] loss: 0.648\n",
            "epoch: [241] loss: 0.646\n",
            "epoch: [242] loss: 0.649\n",
            "epoch: [243] loss: 0.648\n",
            "epoch: [244] loss: 0.643\n",
            "epoch: [245] loss: 0.644\n",
            "epoch: [246] loss: 0.645\n",
            "epoch: [247] loss: 0.644\n",
            "epoch: [248] loss: 0.643\n",
            "epoch: [249] loss: 0.644\n",
            "epoch: [250] loss: 0.643\n",
            "epoch: [251] loss: 0.648\n",
            "epoch: [252] loss: 0.642\n",
            "epoch: [253] loss: 0.643\n",
            "epoch: [254] loss: 0.646\n",
            "epoch: [255] loss: 0.644\n",
            "epoch: [256] loss: 0.645\n",
            "epoch: [257] loss: 0.642\n",
            "epoch: [258] loss: 0.642\n",
            "epoch: [259] loss: 0.647\n",
            "epoch: [260] loss: 0.643\n",
            "epoch: [261] loss: 0.643\n",
            "epoch: [262] loss: 0.644\n",
            "epoch: [263] loss: 0.641\n",
            "epoch: [264] loss: 0.642\n",
            "epoch: [265] loss: 0.644\n",
            "epoch: [266] loss: 0.643\n",
            "epoch: [267] loss: 0.643\n",
            "epoch: [268] loss: 0.643\n",
            "epoch: [269] loss: 0.641\n",
            "epoch: [270] loss: 0.642\n",
            "epoch: [271] loss: 0.641\n",
            "epoch: [272] loss: 0.645\n",
            "epoch: [273] loss: 0.641\n",
            "epoch: [274] loss: 0.641\n",
            "epoch: [275] loss: 0.640\n",
            "epoch: [276] loss: 0.639\n",
            "epoch: [277] loss: 0.642\n",
            "epoch: [278] loss: 0.646\n",
            "epoch: [279] loss: 0.643\n",
            "epoch: [280] loss: 0.642\n",
            "epoch: [281] loss: 0.642\n",
            "epoch: [282] loss: 0.642\n",
            "epoch: [283] loss: 0.643\n",
            "epoch: [284] loss: 0.643\n",
            "epoch: [285] loss: 0.643\n",
            "epoch: [286] loss: 0.641\n",
            "epoch: [287] loss: 0.641\n",
            "epoch: [288] loss: 0.641\n",
            "epoch: [289] loss: 0.641\n",
            "epoch: [290] loss: 0.640\n",
            "epoch: [291] loss: 0.639\n",
            "epoch: [292] loss: 0.642\n",
            "epoch: [293] loss: 0.640\n",
            "epoch: [294] loss: 0.642\n",
            "epoch: [295] loss: 0.638\n",
            "epoch: [296] loss: 0.637\n",
            "epoch: [297] loss: 0.640\n",
            "epoch: [298] loss: 0.640\n",
            "epoch: [299] loss: 0.641\n",
            "epoch: [300] loss: 0.640\n",
            "epoch: [301] loss: 0.639\n",
            "epoch: [302] loss: 0.641\n",
            "epoch: [303] loss: 0.641\n",
            "epoch: [304] loss: 0.641\n",
            "epoch: [305] loss: 0.643\n",
            "epoch: [306] loss: 0.640\n",
            "epoch: [307] loss: 0.640\n",
            "epoch: [308] loss: 0.642\n",
            "epoch: [309] loss: 0.638\n",
            "epoch: [310] loss: 0.642\n",
            "epoch: [311] loss: 0.642\n",
            "epoch: [312] loss: 0.641\n",
            "epoch: [313] loss: 0.642\n",
            "epoch: [314] loss: 0.639\n",
            "epoch: [315] loss: 0.639\n",
            "epoch: [316] loss: 0.641\n",
            "epoch: [317] loss: 0.640\n",
            "epoch: [318] loss: 0.637\n",
            "epoch: [319] loss: 0.639\n",
            "epoch: [320] loss: 0.638\n",
            "epoch: [321] loss: 0.640\n",
            "epoch: [322] loss: 0.636\n",
            "epoch: [323] loss: 0.639\n",
            "epoch: [324] loss: 0.635\n",
            "epoch: [325] loss: 0.637\n",
            "epoch: [326] loss: 0.638\n",
            "epoch: [327] loss: 0.641\n",
            "epoch: [328] loss: 0.639\n",
            "epoch: [329] loss: 0.639\n",
            "epoch: [330] loss: 0.637\n",
            "epoch: [331] loss: 0.639\n",
            "epoch: [332] loss: 0.638\n",
            "epoch: [333] loss: 0.636\n",
            "epoch: [334] loss: 0.637\n",
            "epoch: [335] loss: 0.639\n",
            "epoch: [336] loss: 0.646\n",
            "epoch: [337] loss: 0.637\n",
            "epoch: [338] loss: 0.640\n",
            "epoch: [339] loss: 0.642\n",
            "epoch: [340] loss: 0.639\n",
            "epoch: [341] loss: 0.644\n",
            "epoch: [342] loss: 0.639\n",
            "epoch: [343] loss: 0.636\n",
            "epoch: [344] loss: 0.636\n",
            "epoch: [345] loss: 0.640\n",
            "epoch: [346] loss: 0.639\n",
            "epoch: [347] loss: 0.635\n",
            "epoch: [348] loss: 0.634\n",
            "epoch: [349] loss: 0.635\n",
            "epoch: [350] loss: 0.637\n",
            "epoch: [351] loss: 0.636\n",
            "epoch: [352] loss: 0.635\n",
            "epoch: [353] loss: 0.635\n",
            "epoch: [354] loss: 0.639\n",
            "epoch: [355] loss: 0.636\n",
            "epoch: [356] loss: 0.638\n",
            "epoch: [357] loss: 0.641\n",
            "epoch: [358] loss: 0.636\n",
            "epoch: [359] loss: 0.639\n",
            "epoch: [360] loss: 0.640\n",
            "epoch: [361] loss: 0.637\n",
            "epoch: [362] loss: 0.636\n",
            "epoch: [363] loss: 0.635\n",
            "epoch: [364] loss: 0.635\n",
            "epoch: [365] loss: 0.635\n",
            "epoch: [366] loss: 0.636\n",
            "epoch: [367] loss: 0.636\n",
            "epoch: [368] loss: 0.637\n",
            "epoch: [369] loss: 0.640\n",
            "epoch: [370] loss: 0.635\n",
            "epoch: [371] loss: 0.635\n",
            "epoch: [372] loss: 0.642\n",
            "epoch: [373] loss: 0.639\n",
            "epoch: [374] loss: 0.635\n",
            "epoch: [375] loss: 0.634\n",
            "epoch: [376] loss: 0.634\n",
            "epoch: [377] loss: 0.633\n",
            "epoch: [378] loss: 0.635\n",
            "epoch: [379] loss: 0.631\n",
            "epoch: [380] loss: 0.637\n",
            "epoch: [381] loss: 0.636\n",
            "epoch: [382] loss: 0.637\n",
            "epoch: [383] loss: 0.639\n",
            "epoch: [384] loss: 0.635\n",
            "epoch: [385] loss: 0.634\n",
            "epoch: [386] loss: 0.635\n",
            "epoch: [387] loss: 0.635\n",
            "epoch: [388] loss: 0.635\n",
            "epoch: [389] loss: 0.637\n",
            "epoch: [390] loss: 0.635\n",
            "epoch: [391] loss: 0.634\n",
            "epoch: [392] loss: 0.639\n",
            "epoch: [393] loss: 0.635\n",
            "epoch: [394] loss: 0.632\n",
            "epoch: [395] loss: 0.633\n",
            "epoch: [396] loss: 0.633\n",
            "epoch: [397] loss: 0.635\n",
            "epoch: [398] loss: 0.639\n",
            "epoch: [399] loss: 0.633\n",
            "epoch: [400] loss: 0.635\n",
            "epoch: [401] loss: 0.640\n",
            "epoch: [402] loss: 0.634\n",
            "epoch: [403] loss: 0.635\n",
            "epoch: [404] loss: 0.632\n",
            "epoch: [405] loss: 0.634\n",
            "epoch: [406] loss: 0.630\n",
            "epoch: [407] loss: 0.633\n",
            "epoch: [408] loss: 0.635\n",
            "epoch: [409] loss: 0.635\n",
            "epoch: [410] loss: 0.632\n",
            "epoch: [411] loss: 0.634\n",
            "epoch: [412] loss: 0.634\n",
            "epoch: [413] loss: 0.633\n",
            "epoch: [414] loss: 0.631\n",
            "epoch: [415] loss: 0.634\n",
            "epoch: [416] loss: 0.630\n",
            "epoch: [417] loss: 0.631\n",
            "epoch: [418] loss: 0.634\n",
            "epoch: [419] loss: 0.631\n",
            "epoch: [420] loss: 0.631\n",
            "epoch: [421] loss: 0.631\n",
            "epoch: [422] loss: 0.633\n",
            "epoch: [423] loss: 0.635\n",
            "epoch: [424] loss: 0.631\n",
            "epoch: [425] loss: 0.630\n",
            "epoch: [426] loss: 0.630\n",
            "epoch: [427] loss: 0.633\n",
            "epoch: [428] loss: 0.631\n",
            "epoch: [429] loss: 0.629\n",
            "epoch: [430] loss: 0.634\n",
            "epoch: [431] loss: 0.631\n",
            "epoch: [432] loss: 0.632\n",
            "epoch: [433] loss: 0.632\n",
            "epoch: [434] loss: 0.633\n",
            "epoch: [435] loss: 0.632\n",
            "epoch: [436] loss: 0.630\n",
            "epoch: [437] loss: 0.631\n",
            "epoch: [438] loss: 0.636\n",
            "epoch: [439] loss: 0.631\n",
            "epoch: [440] loss: 0.629\n",
            "epoch: [441] loss: 0.631\n",
            "epoch: [442] loss: 0.628\n",
            "epoch: [443] loss: 0.630\n",
            "epoch: [444] loss: 0.631\n",
            "epoch: [445] loss: 0.629\n",
            "epoch: [446] loss: 0.634\n",
            "epoch: [447] loss: 0.632\n",
            "epoch: [448] loss: 0.629\n",
            "epoch: [449] loss: 0.628\n",
            "epoch: [450] loss: 0.633\n",
            "epoch: [451] loss: 0.633\n",
            "epoch: [452] loss: 0.629\n",
            "epoch: [453] loss: 0.632\n",
            "epoch: [454] loss: 0.630\n",
            "epoch: [455] loss: 0.638\n",
            "epoch: [456] loss: 0.629\n",
            "epoch: [457] loss: 0.630\n",
            "epoch: [458] loss: 0.629\n",
            "epoch: [459] loss: 0.633\n",
            "epoch: [460] loss: 0.635\n",
            "epoch: [461] loss: 0.630\n",
            "epoch: [462] loss: 0.630\n",
            "epoch: [463] loss: 0.632\n",
            "epoch: [464] loss: 0.627\n",
            "epoch: [465] loss: 0.631\n",
            "epoch: [466] loss: 0.637\n",
            "epoch: [467] loss: 0.631\n",
            "epoch: [468] loss: 0.628\n",
            "epoch: [469] loss: 0.629\n",
            "epoch: [470] loss: 0.628\n",
            "epoch: [471] loss: 0.628\n",
            "epoch: [472] loss: 0.629\n",
            "epoch: [473] loss: 0.630\n",
            "epoch: [474] loss: 0.629\n",
            "epoch: [475] loss: 0.631\n",
            "epoch: [476] loss: 0.628\n",
            "epoch: [477] loss: 0.628\n",
            "epoch: [478] loss: 0.630\n",
            "epoch: [479] loss: 0.627\n",
            "epoch: [480] loss: 0.628\n",
            "epoch: [481] loss: 0.628\n",
            "epoch: [482] loss: 0.630\n",
            "epoch: [483] loss: 0.630\n",
            "epoch: [484] loss: 0.627\n",
            "epoch: [485] loss: 0.626\n",
            "epoch: [486] loss: 0.628\n",
            "epoch: [487] loss: 0.629\n",
            "epoch: [488] loss: 0.629\n",
            "epoch: [489] loss: 0.629\n",
            "epoch: [490] loss: 0.628\n",
            "epoch: [491] loss: 0.628\n",
            "epoch: [492] loss: 0.631\n",
            "epoch: [493] loss: 0.627\n",
            "epoch: [494] loss: 0.629\n",
            "epoch: [495] loss: 0.628\n",
            "epoch: [496] loss: 0.626\n",
            "epoch: [497] loss: 0.627\n",
            "epoch: [498] loss: 0.627\n",
            "epoch: [499] loss: 0.628\n",
            "epoch: [500] loss: 0.627\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 73 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 40 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 48 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 59 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 73 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 82 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 86 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 88 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 83 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   6\n",
            "epoch: [0 ] loss: 1.345\n",
            "epoch: [1] loss: 1.081\n",
            "epoch: [2] loss: 1.002\n",
            "epoch: [3] loss: 0.962\n",
            "epoch: [4] loss: 0.929\n",
            "epoch: [5] loss: 0.895\n",
            "epoch: [6] loss: 0.866\n",
            "epoch: [7] loss: 0.837\n",
            "epoch: [8] loss: 0.806\n",
            "epoch: [9] loss: 0.777\n",
            "epoch: [10] loss: 0.747\n",
            "epoch: [11] loss: 0.717\n",
            "epoch: [12] loss: 0.690\n",
            "epoch: [13] loss: 0.664\n",
            "epoch: [14] loss: 0.638\n",
            "epoch: [15] loss: 0.615\n",
            "epoch: [16] loss: 0.598\n",
            "epoch: [17] loss: 0.580\n",
            "epoch: [18] loss: 0.562\n",
            "epoch: [19] loss: 0.552\n",
            "epoch: [20] loss: 0.541\n",
            "epoch: [21] loss: 0.527\n",
            "epoch: [22] loss: 0.524\n",
            "epoch: [23] loss: 0.509\n",
            "epoch: [24] loss: 0.500\n",
            "epoch: [25] loss: 0.494\n",
            "epoch: [26] loss: 0.487\n",
            "epoch: [27] loss: 0.481\n",
            "epoch: [28] loss: 0.478\n",
            "epoch: [29] loss: 0.470\n",
            "epoch: [30] loss: 0.465\n",
            "epoch: [31] loss: 0.460\n",
            "epoch: [32] loss: 0.460\n",
            "epoch: [33] loss: 0.461\n",
            "epoch: [34] loss: 0.451\n",
            "epoch: [35] loss: 0.464\n",
            "epoch: [36] loss: 0.450\n",
            "epoch: [37] loss: 0.443\n",
            "epoch: [38] loss: 0.442\n",
            "epoch: [39] loss: 0.436\n",
            "epoch: [40] loss: 0.435\n",
            "epoch: [41] loss: 0.436\n",
            "epoch: [42] loss: 0.435\n",
            "epoch: [43] loss: 0.427\n",
            "epoch: [44] loss: 0.429\n",
            "epoch: [45] loss: 0.424\n",
            "epoch: [46] loss: 0.425\n",
            "epoch: [47] loss: 0.421\n",
            "epoch: [48] loss: 0.420\n",
            "epoch: [49] loss: 0.419\n",
            "epoch: [50] loss: 0.416\n",
            "epoch: [51] loss: 0.416\n",
            "epoch: [52] loss: 0.413\n",
            "epoch: [53] loss: 0.415\n",
            "epoch: [54] loss: 0.412\n",
            "epoch: [55] loss: 0.413\n",
            "epoch: [56] loss: 0.413\n",
            "epoch: [57] loss: 0.411\n",
            "epoch: [58] loss: 0.410\n",
            "epoch: [59] loss: 0.411\n",
            "epoch: [60] loss: 0.408\n",
            "epoch: [61] loss: 0.406\n",
            "epoch: [62] loss: 0.409\n",
            "epoch: [63] loss: 0.407\n",
            "epoch: [64] loss: 0.407\n",
            "epoch: [65] loss: 0.403\n",
            "epoch: [66] loss: 0.402\n",
            "epoch: [67] loss: 0.402\n",
            "epoch: [68] loss: 0.401\n",
            "epoch: [69] loss: 0.407\n",
            "epoch: [70] loss: 0.400\n",
            "epoch: [71] loss: 0.400\n",
            "epoch: [72] loss: 0.401\n",
            "epoch: [73] loss: 0.397\n",
            "epoch: [74] loss: 0.398\n",
            "epoch: [75] loss: 0.396\n",
            "epoch: [76] loss: 0.401\n",
            "epoch: [77] loss: 0.396\n",
            "epoch: [78] loss: 0.395\n",
            "epoch: [79] loss: 0.397\n",
            "epoch: [80] loss: 0.396\n",
            "epoch: [81] loss: 0.395\n",
            "epoch: [82] loss: 0.395\n",
            "epoch: [83] loss: 0.393\n",
            "epoch: [84] loss: 0.392\n",
            "epoch: [85] loss: 0.394\n",
            "epoch: [86] loss: 0.393\n",
            "epoch: [87] loss: 0.395\n",
            "epoch: [88] loss: 0.392\n",
            "epoch: [89] loss: 0.395\n",
            "epoch: [90] loss: 0.391\n",
            "epoch: [91] loss: 0.390\n",
            "epoch: [92] loss: 0.395\n",
            "epoch: [93] loss: 0.392\n",
            "epoch: [94] loss: 0.392\n",
            "epoch: [95] loss: 0.393\n",
            "epoch: [96] loss: 0.392\n",
            "epoch: [97] loss: 0.392\n",
            "epoch: [98] loss: 0.393\n",
            "epoch: [99] loss: 0.391\n",
            "epoch: [100] loss: 0.390\n",
            "epoch: [101] loss: 0.386\n",
            "epoch: [102] loss: 0.386\n",
            "epoch: [103] loss: 0.387\n",
            "epoch: [104] loss: 0.394\n",
            "epoch: [105] loss: 0.395\n",
            "epoch: [106] loss: 0.388\n",
            "epoch: [107] loss: 0.388\n",
            "epoch: [108] loss: 0.386\n",
            "epoch: [109] loss: 0.389\n",
            "epoch: [110] loss: 0.393\n",
            "epoch: [111] loss: 0.385\n",
            "epoch: [112] loss: 0.388\n",
            "epoch: [113] loss: 0.392\n",
            "epoch: [114] loss: 0.392\n",
            "epoch: [115] loss: 0.390\n",
            "epoch: [116] loss: 0.385\n",
            "epoch: [117] loss: 0.385\n",
            "epoch: [118] loss: 0.386\n",
            "epoch: [119] loss: 0.387\n",
            "epoch: [120] loss: 0.386\n",
            "epoch: [121] loss: 0.392\n",
            "epoch: [122] loss: 0.385\n",
            "epoch: [123] loss: 0.382\n",
            "epoch: [124] loss: 0.388\n",
            "epoch: [125] loss: 0.390\n",
            "epoch: [126] loss: 0.388\n",
            "epoch: [127] loss: 0.385\n",
            "epoch: [128] loss: 0.386\n",
            "epoch: [129] loss: 0.384\n",
            "epoch: [130] loss: 0.384\n",
            "epoch: [131] loss: 0.386\n",
            "epoch: [132] loss: 0.385\n",
            "epoch: [133] loss: 0.383\n",
            "epoch: [134] loss: 0.383\n",
            "epoch: [135] loss: 0.383\n",
            "epoch: [136] loss: 0.384\n",
            "epoch: [137] loss: 0.384\n",
            "epoch: [138] loss: 0.383\n",
            "epoch: [139] loss: 0.385\n",
            "epoch: [140] loss: 0.381\n",
            "epoch: [141] loss: 0.383\n",
            "epoch: [142] loss: 0.382\n",
            "epoch: [143] loss: 0.382\n",
            "epoch: [144] loss: 0.382\n",
            "epoch: [145] loss: 0.387\n",
            "epoch: [146] loss: 0.385\n",
            "epoch: [147] loss: 0.384\n",
            "epoch: [148] loss: 0.381\n",
            "epoch: [149] loss: 0.382\n",
            "epoch: [150] loss: 0.381\n",
            "epoch: [151] loss: 0.382\n",
            "epoch: [152] loss: 0.383\n",
            "epoch: [153] loss: 0.381\n",
            "epoch: [154] loss: 0.381\n",
            "epoch: [155] loss: 0.380\n",
            "epoch: [156] loss: 0.381\n",
            "epoch: [157] loss: 0.379\n",
            "epoch: [158] loss: 0.384\n",
            "epoch: [159] loss: 0.383\n",
            "epoch: [160] loss: 0.382\n",
            "epoch: [161] loss: 0.384\n",
            "epoch: [162] loss: 0.382\n",
            "epoch: [163] loss: 0.382\n",
            "epoch: [164] loss: 0.383\n",
            "epoch: [165] loss: 0.379\n",
            "epoch: [166] loss: 0.377\n",
            "epoch: [167] loss: 0.378\n",
            "epoch: [168] loss: 0.380\n",
            "epoch: [169] loss: 0.381\n",
            "epoch: [170] loss: 0.381\n",
            "epoch: [171] loss: 0.379\n",
            "epoch: [172] loss: 0.379\n",
            "epoch: [173] loss: 0.377\n",
            "epoch: [174] loss: 0.379\n",
            "epoch: [175] loss: 0.378\n",
            "epoch: [176] loss: 0.381\n",
            "epoch: [177] loss: 0.380\n",
            "epoch: [178] loss: 0.379\n",
            "epoch: [179] loss: 0.380\n",
            "epoch: [180] loss: 0.381\n",
            "epoch: [181] loss: 0.380\n",
            "epoch: [182] loss: 0.379\n",
            "epoch: [183] loss: 0.380\n",
            "epoch: [184] loss: 0.378\n",
            "epoch: [185] loss: 0.379\n",
            "epoch: [186] loss: 0.378\n",
            "epoch: [187] loss: 0.379\n",
            "epoch: [188] loss: 0.380\n",
            "epoch: [189] loss: 0.378\n",
            "epoch: [190] loss: 0.379\n",
            "epoch: [191] loss: 0.380\n",
            "epoch: [192] loss: 0.381\n",
            "epoch: [193] loss: 0.378\n",
            "epoch: [194] loss: 0.379\n",
            "epoch: [195] loss: 0.376\n",
            "epoch: [196] loss: 0.377\n",
            "epoch: [197] loss: 0.384\n",
            "epoch: [198] loss: 0.376\n",
            "epoch: [199] loss: 0.376\n",
            "epoch: [200] loss: 0.377\n",
            "epoch: [201] loss: 0.377\n",
            "epoch: [202] loss: 0.375\n",
            "epoch: [203] loss: 0.376\n",
            "epoch: [204] loss: 0.380\n",
            "epoch: [205] loss: 0.375\n",
            "epoch: [206] loss: 0.376\n",
            "epoch: [207] loss: 0.375\n",
            "epoch: [208] loss: 0.378\n",
            "epoch: [209] loss: 0.376\n",
            "epoch: [210] loss: 0.376\n",
            "epoch: [211] loss: 0.375\n",
            "epoch: [212] loss: 0.375\n",
            "epoch: [213] loss: 0.377\n",
            "epoch: [214] loss: 0.375\n",
            "epoch: [215] loss: 0.375\n",
            "epoch: [216] loss: 0.376\n",
            "epoch: [217] loss: 0.376\n",
            "epoch: [218] loss: 0.377\n",
            "epoch: [219] loss: 0.374\n",
            "epoch: [220] loss: 0.379\n",
            "epoch: [221] loss: 0.376\n",
            "epoch: [222] loss: 0.378\n",
            "epoch: [223] loss: 0.378\n",
            "epoch: [224] loss: 0.378\n",
            "epoch: [225] loss: 0.376\n",
            "epoch: [226] loss: 0.375\n",
            "epoch: [227] loss: 0.376\n",
            "epoch: [228] loss: 0.373\n",
            "epoch: [229] loss: 0.375\n",
            "epoch: [230] loss: 0.374\n",
            "epoch: [231] loss: 0.376\n",
            "epoch: [232] loss: 0.377\n",
            "epoch: [233] loss: 0.374\n",
            "epoch: [234] loss: 0.376\n",
            "epoch: [235] loss: 0.373\n",
            "epoch: [236] loss: 0.377\n",
            "epoch: [237] loss: 0.373\n",
            "epoch: [238] loss: 0.374\n",
            "epoch: [239] loss: 0.373\n",
            "epoch: [240] loss: 0.373\n",
            "epoch: [241] loss: 0.372\n",
            "epoch: [242] loss: 0.372\n",
            "epoch: [243] loss: 0.376\n",
            "epoch: [244] loss: 0.375\n",
            "epoch: [245] loss: 0.380\n",
            "epoch: [246] loss: 0.374\n",
            "epoch: [247] loss: 0.374\n",
            "epoch: [248] loss: 0.373\n",
            "epoch: [249] loss: 0.374\n",
            "epoch: [250] loss: 0.375\n",
            "epoch: [251] loss: 0.374\n",
            "epoch: [252] loss: 0.378\n",
            "epoch: [253] loss: 0.373\n",
            "epoch: [254] loss: 0.375\n",
            "epoch: [255] loss: 0.371\n",
            "epoch: [256] loss: 0.375\n",
            "epoch: [257] loss: 0.374\n",
            "epoch: [258] loss: 0.371\n",
            "epoch: [259] loss: 0.375\n",
            "epoch: [260] loss: 0.373\n",
            "epoch: [261] loss: 0.371\n",
            "epoch: [262] loss: 0.373\n",
            "epoch: [263] loss: 0.370\n",
            "epoch: [264] loss: 0.372\n",
            "epoch: [265] loss: 0.372\n",
            "epoch: [266] loss: 0.373\n",
            "epoch: [267] loss: 0.371\n",
            "epoch: [268] loss: 0.377\n",
            "epoch: [269] loss: 0.378\n",
            "epoch: [270] loss: 0.372\n",
            "epoch: [271] loss: 0.371\n",
            "epoch: [272] loss: 0.376\n",
            "epoch: [273] loss: 0.373\n",
            "epoch: [274] loss: 0.378\n",
            "epoch: [275] loss: 0.369\n",
            "epoch: [276] loss: 0.370\n",
            "epoch: [277] loss: 0.375\n",
            "epoch: [278] loss: 0.371\n",
            "epoch: [279] loss: 0.371\n",
            "epoch: [280] loss: 0.373\n",
            "epoch: [281] loss: 0.369\n",
            "epoch: [282] loss: 0.371\n",
            "epoch: [283] loss: 0.374\n",
            "epoch: [284] loss: 0.372\n",
            "epoch: [285] loss: 0.370\n",
            "epoch: [286] loss: 0.372\n",
            "epoch: [287] loss: 0.372\n",
            "epoch: [288] loss: 0.372\n",
            "epoch: [289] loss: 0.377\n",
            "epoch: [290] loss: 0.371\n",
            "epoch: [291] loss: 0.372\n",
            "epoch: [292] loss: 0.370\n",
            "epoch: [293] loss: 0.375\n",
            "epoch: [294] loss: 0.372\n",
            "epoch: [295] loss: 0.377\n",
            "epoch: [296] loss: 0.371\n",
            "epoch: [297] loss: 0.370\n",
            "epoch: [298] loss: 0.369\n",
            "epoch: [299] loss: 0.372\n",
            "epoch: [300] loss: 0.369\n",
            "epoch: [301] loss: 0.374\n",
            "epoch: [302] loss: 0.372\n",
            "epoch: [303] loss: 0.370\n",
            "epoch: [304] loss: 0.369\n",
            "epoch: [305] loss: 0.368\n",
            "epoch: [306] loss: 0.370\n",
            "epoch: [307] loss: 0.370\n",
            "epoch: [308] loss: 0.367\n",
            "epoch: [309] loss: 0.368\n",
            "epoch: [310] loss: 0.369\n",
            "epoch: [311] loss: 0.373\n",
            "epoch: [312] loss: 0.369\n",
            "epoch: [313] loss: 0.369\n",
            "epoch: [314] loss: 0.370\n",
            "epoch: [315] loss: 0.368\n",
            "epoch: [316] loss: 0.370\n",
            "epoch: [317] loss: 0.370\n",
            "epoch: [318] loss: 0.367\n",
            "epoch: [319] loss: 0.367\n",
            "epoch: [320] loss: 0.371\n",
            "epoch: [321] loss: 0.369\n",
            "epoch: [322] loss: 0.369\n",
            "epoch: [323] loss: 0.369\n",
            "epoch: [324] loss: 0.368\n",
            "epoch: [325] loss: 0.369\n",
            "epoch: [326] loss: 0.368\n",
            "epoch: [327] loss: 0.368\n",
            "epoch: [328] loss: 0.370\n",
            "epoch: [329] loss: 0.367\n",
            "epoch: [330] loss: 0.368\n",
            "epoch: [331] loss: 0.368\n",
            "epoch: [332] loss: 0.371\n",
            "epoch: [333] loss: 0.371\n",
            "epoch: [334] loss: 0.370\n",
            "epoch: [335] loss: 0.370\n",
            "epoch: [336] loss: 0.369\n",
            "epoch: [337] loss: 0.367\n",
            "epoch: [338] loss: 0.368\n",
            "epoch: [339] loss: 0.370\n",
            "epoch: [340] loss: 0.371\n",
            "epoch: [341] loss: 0.372\n",
            "epoch: [342] loss: 0.367\n",
            "epoch: [343] loss: 0.367\n",
            "epoch: [344] loss: 0.367\n",
            "epoch: [345] loss: 0.368\n",
            "epoch: [346] loss: 0.370\n",
            "epoch: [347] loss: 0.368\n",
            "epoch: [348] loss: 0.368\n",
            "epoch: [349] loss: 0.375\n",
            "epoch: [350] loss: 0.369\n",
            "epoch: [351] loss: 0.368\n",
            "epoch: [352] loss: 0.370\n",
            "epoch: [353] loss: 0.366\n",
            "epoch: [354] loss: 0.368\n",
            "epoch: [355] loss: 0.369\n",
            "epoch: [356] loss: 0.366\n",
            "epoch: [357] loss: 0.366\n",
            "epoch: [358] loss: 0.366\n",
            "epoch: [359] loss: 0.370\n",
            "epoch: [360] loss: 0.367\n",
            "epoch: [361] loss: 0.369\n",
            "epoch: [362] loss: 0.374\n",
            "epoch: [363] loss: 0.364\n",
            "epoch: [364] loss: 0.367\n",
            "epoch: [365] loss: 0.366\n",
            "epoch: [366] loss: 0.366\n",
            "epoch: [367] loss: 0.367\n",
            "epoch: [368] loss: 0.366\n",
            "epoch: [369] loss: 0.368\n",
            "epoch: [370] loss: 0.365\n",
            "epoch: [371] loss: 0.367\n",
            "epoch: [372] loss: 0.371\n",
            "epoch: [373] loss: 0.364\n",
            "epoch: [374] loss: 0.364\n",
            "epoch: [375] loss: 0.369\n",
            "epoch: [376] loss: 0.368\n",
            "epoch: [377] loss: 0.367\n",
            "epoch: [378] loss: 0.366\n",
            "epoch: [379] loss: 0.374\n",
            "epoch: [380] loss: 0.371\n",
            "epoch: [381] loss: 0.366\n",
            "epoch: [382] loss: 0.364\n",
            "epoch: [383] loss: 0.365\n",
            "epoch: [384] loss: 0.368\n",
            "epoch: [385] loss: 0.369\n",
            "epoch: [386] loss: 0.367\n",
            "epoch: [387] loss: 0.371\n",
            "epoch: [388] loss: 0.365\n",
            "epoch: [389] loss: 0.364\n",
            "epoch: [390] loss: 0.367\n",
            "epoch: [391] loss: 0.372\n",
            "epoch: [392] loss: 0.365\n",
            "epoch: [393] loss: 0.366\n",
            "epoch: [394] loss: 0.366\n",
            "epoch: [395] loss: 0.366\n",
            "epoch: [396] loss: 0.368\n",
            "epoch: [397] loss: 0.366\n",
            "epoch: [398] loss: 0.363\n",
            "epoch: [399] loss: 0.364\n",
            "epoch: [400] loss: 0.370\n",
            "epoch: [401] loss: 0.366\n",
            "epoch: [402] loss: 0.364\n",
            "epoch: [403] loss: 0.364\n",
            "epoch: [404] loss: 0.367\n",
            "epoch: [405] loss: 0.367\n",
            "epoch: [406] loss: 0.364\n",
            "epoch: [407] loss: 0.363\n",
            "epoch: [408] loss: 0.368\n",
            "epoch: [409] loss: 0.365\n",
            "epoch: [410] loss: 0.361\n",
            "epoch: [411] loss: 0.362\n",
            "epoch: [412] loss: 0.364\n",
            "epoch: [413] loss: 0.363\n",
            "epoch: [414] loss: 0.365\n",
            "epoch: [415] loss: 0.366\n",
            "epoch: [416] loss: 0.364\n",
            "epoch: [417] loss: 0.370\n",
            "epoch: [418] loss: 0.372\n",
            "epoch: [419] loss: 0.364\n",
            "epoch: [420] loss: 0.362\n",
            "epoch: [421] loss: 0.362\n",
            "epoch: [422] loss: 0.369\n",
            "epoch: [423] loss: 0.375\n",
            "epoch: [424] loss: 0.363\n",
            "epoch: [425] loss: 0.369\n",
            "epoch: [426] loss: 0.364\n",
            "epoch: [427] loss: 0.364\n",
            "epoch: [428] loss: 0.368\n",
            "epoch: [429] loss: 0.367\n",
            "epoch: [430] loss: 0.363\n",
            "epoch: [431] loss: 0.364\n",
            "epoch: [432] loss: 0.363\n",
            "epoch: [433] loss: 0.368\n",
            "epoch: [434] loss: 0.367\n",
            "epoch: [435] loss: 0.363\n",
            "epoch: [436] loss: 0.362\n",
            "epoch: [437] loss: 0.362\n",
            "epoch: [438] loss: 0.365\n",
            "epoch: [439] loss: 0.364\n",
            "epoch: [440] loss: 0.365\n",
            "epoch: [441] loss: 0.364\n",
            "epoch: [442] loss: 0.371\n",
            "epoch: [443] loss: 0.362\n",
            "epoch: [444] loss: 0.362\n",
            "epoch: [445] loss: 0.361\n",
            "epoch: [446] loss: 0.364\n",
            "epoch: [447] loss: 0.363\n",
            "epoch: [448] loss: 0.360\n",
            "epoch: [449] loss: 0.364\n",
            "epoch: [450] loss: 0.366\n",
            "epoch: [451] loss: 0.364\n",
            "epoch: [452] loss: 0.364\n",
            "epoch: [453] loss: 0.363\n",
            "epoch: [454] loss: 0.364\n",
            "epoch: [455] loss: 0.362\n",
            "epoch: [456] loss: 0.364\n",
            "epoch: [457] loss: 0.362\n",
            "epoch: [458] loss: 0.365\n",
            "epoch: [459] loss: 0.365\n",
            "epoch: [460] loss: 0.362\n",
            "epoch: [461] loss: 0.363\n",
            "epoch: [462] loss: 0.362\n",
            "epoch: [463] loss: 0.364\n",
            "epoch: [464] loss: 0.363\n",
            "epoch: [465] loss: 0.368\n",
            "epoch: [466] loss: 0.363\n",
            "epoch: [467] loss: 0.362\n",
            "epoch: [468] loss: 0.362\n",
            "epoch: [469] loss: 0.363\n",
            "epoch: [470] loss: 0.359\n",
            "epoch: [471] loss: 0.360\n",
            "epoch: [472] loss: 0.361\n",
            "epoch: [473] loss: 0.369\n",
            "epoch: [474] loss: 0.363\n",
            "epoch: [475] loss: 0.365\n",
            "epoch: [476] loss: 0.362\n",
            "epoch: [477] loss: 0.360\n",
            "epoch: [478] loss: 0.360\n",
            "epoch: [479] loss: 0.364\n",
            "epoch: [480] loss: 0.367\n",
            "epoch: [481] loss: 0.363\n",
            "epoch: [482] loss: 0.361\n",
            "epoch: [483] loss: 0.360\n",
            "epoch: [484] loss: 0.362\n",
            "epoch: [485] loss: 0.369\n",
            "epoch: [486] loss: 0.362\n",
            "epoch: [487] loss: 0.362\n",
            "epoch: [488] loss: 0.368\n",
            "epoch: [489] loss: 0.361\n",
            "epoch: [490] loss: 0.361\n",
            "epoch: [491] loss: 0.363\n",
            "epoch: [492] loss: 0.362\n",
            "epoch: [493] loss: 0.362\n",
            "epoch: [494] loss: 0.364\n",
            "epoch: [495] loss: 0.360\n",
            "epoch: [496] loss: 0.359\n",
            "epoch: [497] loss: 0.361\n",
            "epoch: [498] loss: 0.362\n",
            "epoch: [499] loss: 0.362\n",
            "epoch: [500] loss: 0.363\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 85 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 34 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 39 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 45 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 55 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 70 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 85 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 92 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 94 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 93 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   7\n",
            "epoch: [0 ] loss: 1.369\n",
            "epoch: [1] loss: 1.124\n",
            "epoch: [2] loss: 0.994\n",
            "epoch: [3] loss: 0.911\n",
            "epoch: [4] loss: 0.847\n",
            "epoch: [5] loss: 0.790\n",
            "epoch: [6] loss: 0.741\n",
            "epoch: [7] loss: 0.695\n",
            "epoch: [8] loss: 0.651\n",
            "epoch: [9] loss: 0.614\n",
            "epoch: [10] loss: 0.577\n",
            "epoch: [11] loss: 0.542\n",
            "epoch: [12] loss: 0.506\n",
            "epoch: [13] loss: 0.479\n",
            "epoch: [14] loss: 0.455\n",
            "epoch: [15] loss: 0.434\n",
            "epoch: [16] loss: 0.414\n",
            "epoch: [17] loss: 0.395\n",
            "epoch: [18] loss: 0.384\n",
            "epoch: [19] loss: 0.368\n",
            "epoch: [20] loss: 0.353\n",
            "epoch: [21] loss: 0.345\n",
            "epoch: [22] loss: 0.330\n",
            "epoch: [23] loss: 0.321\n",
            "epoch: [24] loss: 0.313\n",
            "epoch: [25] loss: 0.302\n",
            "epoch: [26] loss: 0.294\n",
            "epoch: [27] loss: 0.285\n",
            "epoch: [28] loss: 0.282\n",
            "epoch: [29] loss: 0.273\n",
            "epoch: [30] loss: 0.269\n",
            "epoch: [31] loss: 0.265\n",
            "epoch: [32] loss: 0.259\n",
            "epoch: [33] loss: 0.253\n",
            "epoch: [34] loss: 0.250\n",
            "epoch: [35] loss: 0.246\n",
            "epoch: [36] loss: 0.240\n",
            "epoch: [37] loss: 0.239\n",
            "epoch: [38] loss: 0.236\n",
            "epoch: [39] loss: 0.231\n",
            "epoch: [40] loss: 0.228\n",
            "epoch: [41] loss: 0.226\n",
            "epoch: [42] loss: 0.223\n",
            "epoch: [43] loss: 0.221\n",
            "epoch: [44] loss: 0.217\n",
            "epoch: [45] loss: 0.214\n",
            "epoch: [46] loss: 0.212\n",
            "epoch: [47] loss: 0.211\n",
            "epoch: [48] loss: 0.208\n",
            "epoch: [49] loss: 0.206\n",
            "epoch: [50] loss: 0.208\n",
            "epoch: [51] loss: 0.203\n",
            "epoch: [52] loss: 0.200\n",
            "epoch: [53] loss: 0.198\n",
            "epoch: [54] loss: 0.196\n",
            "epoch: [55] loss: 0.195\n",
            "epoch: [56] loss: 0.198\n",
            "epoch: [57] loss: 0.192\n",
            "epoch: [58] loss: 0.192\n",
            "epoch: [59] loss: 0.190\n",
            "epoch: [60] loss: 0.187\n",
            "epoch: [61] loss: 0.188\n",
            "epoch: [62] loss: 0.186\n",
            "epoch: [63] loss: 0.185\n",
            "epoch: [64] loss: 0.184\n",
            "epoch: [65] loss: 0.183\n",
            "epoch: [66] loss: 0.181\n",
            "epoch: [67] loss: 0.181\n",
            "epoch: [68] loss: 0.180\n",
            "epoch: [69] loss: 0.180\n",
            "epoch: [70] loss: 0.178\n",
            "epoch: [71] loss: 0.177\n",
            "epoch: [72] loss: 0.175\n",
            "epoch: [73] loss: 0.175\n",
            "epoch: [74] loss: 0.173\n",
            "epoch: [75] loss: 0.174\n",
            "epoch: [76] loss: 0.173\n",
            "epoch: [77] loss: 0.173\n",
            "epoch: [78] loss: 0.174\n",
            "epoch: [79] loss: 0.171\n",
            "epoch: [80] loss: 0.170\n",
            "epoch: [81] loss: 0.170\n",
            "epoch: [82] loss: 0.168\n",
            "epoch: [83] loss: 0.167\n",
            "epoch: [84] loss: 0.169\n",
            "epoch: [85] loss: 0.169\n",
            "epoch: [86] loss: 0.166\n",
            "epoch: [87] loss: 0.167\n",
            "epoch: [88] loss: 0.165\n",
            "epoch: [89] loss: 0.165\n",
            "epoch: [90] loss: 0.165\n",
            "epoch: [91] loss: 0.165\n",
            "epoch: [92] loss: 0.165\n",
            "epoch: [93] loss: 0.165\n",
            "epoch: [94] loss: 0.162\n",
            "epoch: [95] loss: 0.164\n",
            "epoch: [96] loss: 0.164\n",
            "epoch: [97] loss: 0.162\n",
            "epoch: [98] loss: 0.160\n",
            "epoch: [99] loss: 0.163\n",
            "epoch: [100] loss: 0.164\n",
            "epoch: [101] loss: 0.160\n",
            "epoch: [102] loss: 0.159\n",
            "epoch: [103] loss: 0.159\n",
            "epoch: [104] loss: 0.157\n",
            "epoch: [105] loss: 0.157\n",
            "epoch: [106] loss: 0.157\n",
            "epoch: [107] loss: 0.158\n",
            "epoch: [108] loss: 0.158\n",
            "epoch: [109] loss: 0.156\n",
            "epoch: [110] loss: 0.156\n",
            "epoch: [111] loss: 0.156\n",
            "epoch: [112] loss: 0.156\n",
            "epoch: [113] loss: 0.155\n",
            "epoch: [114] loss: 0.155\n",
            "epoch: [115] loss: 0.155\n",
            "epoch: [116] loss: 0.156\n",
            "epoch: [117] loss: 0.154\n",
            "epoch: [118] loss: 0.155\n",
            "epoch: [119] loss: 0.156\n",
            "epoch: [120] loss: 0.154\n",
            "epoch: [121] loss: 0.153\n",
            "epoch: [122] loss: 0.153\n",
            "epoch: [123] loss: 0.153\n",
            "epoch: [124] loss: 0.153\n",
            "epoch: [125] loss: 0.153\n",
            "epoch: [126] loss: 0.152\n",
            "epoch: [127] loss: 0.151\n",
            "epoch: [128] loss: 0.151\n",
            "epoch: [129] loss: 0.154\n",
            "epoch: [130] loss: 0.152\n",
            "epoch: [131] loss: 0.151\n",
            "epoch: [132] loss: 0.153\n",
            "epoch: [133] loss: 0.149\n",
            "epoch: [134] loss: 0.151\n",
            "epoch: [135] loss: 0.150\n",
            "epoch: [136] loss: 0.150\n",
            "epoch: [137] loss: 0.148\n",
            "epoch: [138] loss: 0.149\n",
            "epoch: [139] loss: 0.149\n",
            "epoch: [140] loss: 0.148\n",
            "epoch: [141] loss: 0.148\n",
            "epoch: [142] loss: 0.148\n",
            "epoch: [143] loss: 0.147\n",
            "epoch: [144] loss: 0.148\n",
            "epoch: [145] loss: 0.149\n",
            "epoch: [146] loss: 0.148\n",
            "epoch: [147] loss: 0.147\n",
            "epoch: [148] loss: 0.147\n",
            "epoch: [149] loss: 0.148\n",
            "epoch: [150] loss: 0.146\n",
            "epoch: [151] loss: 0.147\n",
            "epoch: [152] loss: 0.148\n",
            "epoch: [153] loss: 0.146\n",
            "epoch: [154] loss: 0.148\n",
            "epoch: [155] loss: 0.146\n",
            "epoch: [156] loss: 0.147\n",
            "epoch: [157] loss: 0.146\n",
            "epoch: [158] loss: 0.147\n",
            "epoch: [159] loss: 0.148\n",
            "epoch: [160] loss: 0.145\n",
            "epoch: [161] loss: 0.151\n",
            "epoch: [162] loss: 0.147\n",
            "epoch: [163] loss: 0.146\n",
            "epoch: [164] loss: 0.149\n",
            "epoch: [165] loss: 0.144\n",
            "epoch: [166] loss: 0.144\n",
            "epoch: [167] loss: 0.145\n",
            "epoch: [168] loss: 0.144\n",
            "epoch: [169] loss: 0.146\n",
            "epoch: [170] loss: 0.146\n",
            "epoch: [171] loss: 0.145\n",
            "epoch: [172] loss: 0.144\n",
            "epoch: [173] loss: 0.145\n",
            "epoch: [174] loss: 0.145\n",
            "epoch: [175] loss: 0.144\n",
            "epoch: [176] loss: 0.144\n",
            "epoch: [177] loss: 0.143\n",
            "epoch: [178] loss: 0.143\n",
            "epoch: [179] loss: 0.144\n",
            "epoch: [180] loss: 0.149\n",
            "epoch: [181] loss: 0.143\n",
            "epoch: [182] loss: 0.144\n",
            "epoch: [183] loss: 0.143\n",
            "epoch: [184] loss: 0.143\n",
            "epoch: [185] loss: 0.144\n",
            "epoch: [186] loss: 0.143\n",
            "epoch: [187] loss: 0.142\n",
            "epoch: [188] loss: 0.144\n",
            "epoch: [189] loss: 0.144\n",
            "epoch: [190] loss: 0.142\n",
            "epoch: [191] loss: 0.143\n",
            "epoch: [192] loss: 0.142\n",
            "epoch: [193] loss: 0.142\n",
            "epoch: [194] loss: 0.142\n",
            "epoch: [195] loss: 0.141\n",
            "epoch: [196] loss: 0.141\n",
            "epoch: [197] loss: 0.144\n",
            "epoch: [198] loss: 0.142\n",
            "epoch: [199] loss: 0.140\n",
            "epoch: [200] loss: 0.142\n",
            "epoch: [201] loss: 0.142\n",
            "epoch: [202] loss: 0.143\n",
            "epoch: [203] loss: 0.141\n",
            "epoch: [204] loss: 0.141\n",
            "epoch: [205] loss: 0.142\n",
            "epoch: [206] loss: 0.141\n",
            "epoch: [207] loss: 0.141\n",
            "epoch: [208] loss: 0.141\n",
            "epoch: [209] loss: 0.140\n",
            "epoch: [210] loss: 0.139\n",
            "epoch: [211] loss: 0.141\n",
            "epoch: [212] loss: 0.140\n",
            "epoch: [213] loss: 0.140\n",
            "epoch: [214] loss: 0.141\n",
            "epoch: [215] loss: 0.139\n",
            "epoch: [216] loss: 0.141\n",
            "epoch: [217] loss: 0.140\n",
            "epoch: [218] loss: 0.139\n",
            "epoch: [219] loss: 0.141\n",
            "epoch: [220] loss: 0.144\n",
            "epoch: [221] loss: 0.140\n",
            "epoch: [222] loss: 0.139\n",
            "epoch: [223] loss: 0.139\n",
            "epoch: [224] loss: 0.140\n",
            "epoch: [225] loss: 0.140\n",
            "epoch: [226] loss: 0.139\n",
            "epoch: [227] loss: 0.138\n",
            "epoch: [228] loss: 0.141\n",
            "epoch: [229] loss: 0.140\n",
            "epoch: [230] loss: 0.138\n",
            "epoch: [231] loss: 0.138\n",
            "epoch: [232] loss: 0.138\n",
            "epoch: [233] loss: 0.138\n",
            "epoch: [234] loss: 0.139\n",
            "epoch: [235] loss: 0.138\n",
            "epoch: [236] loss: 0.137\n",
            "epoch: [237] loss: 0.140\n",
            "epoch: [238] loss: 0.140\n",
            "epoch: [239] loss: 0.138\n",
            "epoch: [240] loss: 0.138\n",
            "epoch: [241] loss: 0.139\n",
            "epoch: [242] loss: 0.137\n",
            "epoch: [243] loss: 0.138\n",
            "epoch: [244] loss: 0.139\n",
            "epoch: [245] loss: 0.138\n",
            "epoch: [246] loss: 0.140\n",
            "epoch: [247] loss: 0.139\n",
            "epoch: [248] loss: 0.138\n",
            "epoch: [249] loss: 0.136\n",
            "epoch: [250] loss: 0.137\n",
            "epoch: [251] loss: 0.138\n",
            "epoch: [252] loss: 0.136\n",
            "epoch: [253] loss: 0.138\n",
            "epoch: [254] loss: 0.137\n",
            "epoch: [255] loss: 0.137\n",
            "epoch: [256] loss: 0.139\n",
            "epoch: [257] loss: 0.137\n",
            "epoch: [258] loss: 0.136\n",
            "epoch: [259] loss: 0.136\n",
            "epoch: [260] loss: 0.137\n",
            "epoch: [261] loss: 0.136\n",
            "epoch: [262] loss: 0.137\n",
            "epoch: [263] loss: 0.140\n",
            "epoch: [264] loss: 0.137\n",
            "epoch: [265] loss: 0.137\n",
            "epoch: [266] loss: 0.136\n",
            "epoch: [267] loss: 0.136\n",
            "epoch: [268] loss: 0.140\n",
            "epoch: [269] loss: 0.137\n",
            "epoch: [270] loss: 0.136\n",
            "epoch: [271] loss: 0.139\n",
            "epoch: [272] loss: 0.135\n",
            "epoch: [273] loss: 0.135\n",
            "epoch: [274] loss: 0.137\n",
            "epoch: [275] loss: 0.138\n",
            "epoch: [276] loss: 0.139\n",
            "epoch: [277] loss: 0.136\n",
            "epoch: [278] loss: 0.136\n",
            "epoch: [279] loss: 0.139\n",
            "epoch: [280] loss: 0.135\n",
            "epoch: [281] loss: 0.143\n",
            "epoch: [282] loss: 0.137\n",
            "epoch: [283] loss: 0.136\n",
            "epoch: [284] loss: 0.136\n",
            "epoch: [285] loss: 0.136\n",
            "epoch: [286] loss: 0.135\n",
            "epoch: [287] loss: 0.136\n",
            "epoch: [288] loss: 0.135\n",
            "epoch: [289] loss: 0.137\n",
            "epoch: [290] loss: 0.135\n",
            "epoch: [291] loss: 0.135\n",
            "epoch: [292] loss: 0.135\n",
            "epoch: [293] loss: 0.134\n",
            "epoch: [294] loss: 0.139\n",
            "epoch: [295] loss: 0.134\n",
            "epoch: [296] loss: 0.135\n",
            "epoch: [297] loss: 0.134\n",
            "epoch: [298] loss: 0.134\n",
            "epoch: [299] loss: 0.134\n",
            "epoch: [300] loss: 0.134\n",
            "epoch: [301] loss: 0.135\n",
            "epoch: [302] loss: 0.134\n",
            "epoch: [303] loss: 0.133\n",
            "epoch: [304] loss: 0.135\n",
            "epoch: [305] loss: 0.134\n",
            "epoch: [306] loss: 0.135\n",
            "epoch: [307] loss: 0.135\n",
            "epoch: [308] loss: 0.135\n",
            "epoch: [309] loss: 0.134\n",
            "epoch: [310] loss: 0.135\n",
            "epoch: [311] loss: 0.135\n",
            "epoch: [312] loss: 0.135\n",
            "epoch: [313] loss: 0.138\n",
            "epoch: [314] loss: 0.135\n",
            "epoch: [315] loss: 0.132\n",
            "epoch: [316] loss: 0.135\n",
            "epoch: [317] loss: 0.136\n",
            "epoch: [318] loss: 0.133\n",
            "epoch: [319] loss: 0.135\n",
            "epoch: [320] loss: 0.134\n",
            "epoch: [321] loss: 0.132\n",
            "epoch: [322] loss: 0.133\n",
            "epoch: [323] loss: 0.135\n",
            "epoch: [324] loss: 0.133\n",
            "epoch: [325] loss: 0.137\n",
            "epoch: [326] loss: 0.137\n",
            "epoch: [327] loss: 0.134\n",
            "epoch: [328] loss: 0.134\n",
            "epoch: [329] loss: 0.133\n",
            "epoch: [330] loss: 0.134\n",
            "epoch: [331] loss: 0.134\n",
            "epoch: [332] loss: 0.133\n",
            "epoch: [333] loss: 0.135\n",
            "epoch: [334] loss: 0.133\n",
            "epoch: [335] loss: 0.132\n",
            "epoch: [336] loss: 0.133\n",
            "epoch: [337] loss: 0.133\n",
            "epoch: [338] loss: 0.134\n",
            "epoch: [339] loss: 0.133\n",
            "epoch: [340] loss: 0.135\n",
            "epoch: [341] loss: 0.132\n",
            "epoch: [342] loss: 0.134\n",
            "epoch: [343] loss: 0.133\n",
            "epoch: [344] loss: 0.136\n",
            "epoch: [345] loss: 0.133\n",
            "epoch: [346] loss: 0.138\n",
            "epoch: [347] loss: 0.134\n",
            "epoch: [348] loss: 0.132\n",
            "epoch: [349] loss: 0.132\n",
            "epoch: [350] loss: 0.136\n",
            "epoch: [351] loss: 0.137\n",
            "epoch: [352] loss: 0.132\n",
            "epoch: [353] loss: 0.134\n",
            "epoch: [354] loss: 0.133\n",
            "epoch: [355] loss: 0.134\n",
            "epoch: [356] loss: 0.138\n",
            "epoch: [357] loss: 0.132\n",
            "epoch: [358] loss: 0.134\n",
            "epoch: [359] loss: 0.133\n",
            "epoch: [360] loss: 0.134\n",
            "epoch: [361] loss: 0.138\n",
            "epoch: [362] loss: 0.131\n",
            "epoch: [363] loss: 0.132\n",
            "epoch: [364] loss: 0.131\n",
            "epoch: [365] loss: 0.132\n",
            "epoch: [366] loss: 0.134\n",
            "epoch: [367] loss: 0.135\n",
            "epoch: [368] loss: 0.133\n",
            "epoch: [369] loss: 0.134\n",
            "epoch: [370] loss: 0.132\n",
            "epoch: [371] loss: 0.132\n",
            "epoch: [372] loss: 0.136\n",
            "epoch: [373] loss: 0.131\n",
            "epoch: [374] loss: 0.139\n",
            "epoch: [375] loss: 0.134\n",
            "epoch: [376] loss: 0.131\n",
            "epoch: [377] loss: 0.131\n",
            "epoch: [378] loss: 0.130\n",
            "epoch: [379] loss: 0.132\n",
            "epoch: [380] loss: 0.133\n",
            "epoch: [381] loss: 0.132\n",
            "epoch: [382] loss: 0.133\n",
            "epoch: [383] loss: 0.133\n",
            "epoch: [384] loss: 0.130\n",
            "epoch: [385] loss: 0.131\n",
            "epoch: [386] loss: 0.131\n",
            "epoch: [387] loss: 0.132\n",
            "epoch: [388] loss: 0.132\n",
            "epoch: [389] loss: 0.131\n",
            "epoch: [390] loss: 0.131\n",
            "epoch: [391] loss: 0.131\n",
            "epoch: [392] loss: 0.131\n",
            "epoch: [393] loss: 0.133\n",
            "epoch: [394] loss: 0.132\n",
            "epoch: [395] loss: 0.134\n",
            "epoch: [396] loss: 0.138\n",
            "epoch: [397] loss: 0.130\n",
            "epoch: [398] loss: 0.132\n",
            "epoch: [399] loss: 0.132\n",
            "epoch: [400] loss: 0.130\n",
            "epoch: [401] loss: 0.131\n",
            "epoch: [402] loss: 0.131\n",
            "epoch: [403] loss: 0.131\n",
            "epoch: [404] loss: 0.131\n",
            "epoch: [405] loss: 0.131\n",
            "epoch: [406] loss: 0.129\n",
            "epoch: [407] loss: 0.130\n",
            "epoch: [408] loss: 0.130\n",
            "epoch: [409] loss: 0.134\n",
            "epoch: [410] loss: 0.137\n",
            "epoch: [411] loss: 0.131\n",
            "epoch: [412] loss: 0.132\n",
            "epoch: [413] loss: 0.130\n",
            "epoch: [414] loss: 0.130\n",
            "epoch: [415] loss: 0.130\n",
            "epoch: [416] loss: 0.130\n",
            "epoch: [417] loss: 0.130\n",
            "epoch: [418] loss: 0.130\n",
            "epoch: [419] loss: 0.131\n",
            "epoch: [420] loss: 0.133\n",
            "epoch: [421] loss: 0.131\n",
            "epoch: [422] loss: 0.130\n",
            "epoch: [423] loss: 0.130\n",
            "epoch: [424] loss: 0.130\n",
            "epoch: [425] loss: 0.131\n",
            "epoch: [426] loss: 0.131\n",
            "epoch: [427] loss: 0.133\n",
            "epoch: [428] loss: 0.130\n",
            "epoch: [429] loss: 0.130\n",
            "epoch: [430] loss: 0.130\n",
            "epoch: [431] loss: 0.131\n",
            "epoch: [432] loss: 0.129\n",
            "epoch: [433] loss: 0.130\n",
            "epoch: [434] loss: 0.130\n",
            "epoch: [435] loss: 0.131\n",
            "epoch: [436] loss: 0.130\n",
            "epoch: [437] loss: 0.130\n",
            "epoch: [438] loss: 0.132\n",
            "epoch: [439] loss: 0.130\n",
            "epoch: [440] loss: 0.133\n",
            "epoch: [441] loss: 0.131\n",
            "epoch: [442] loss: 0.132\n",
            "epoch: [443] loss: 0.129\n",
            "epoch: [444] loss: 0.129\n",
            "epoch: [445] loss: 0.131\n",
            "epoch: [446] loss: 0.133\n",
            "epoch: [447] loss: 0.129\n",
            "epoch: [448] loss: 0.128\n",
            "epoch: [449] loss: 0.130\n",
            "epoch: [450] loss: 0.130\n",
            "epoch: [451] loss: 0.129\n",
            "epoch: [452] loss: 0.129\n",
            "epoch: [453] loss: 0.128\n",
            "epoch: [454] loss: 0.130\n",
            "epoch: [455] loss: 0.129\n",
            "epoch: [456] loss: 0.128\n",
            "epoch: [457] loss: 0.129\n",
            "epoch: [458] loss: 0.128\n",
            "epoch: [459] loss: 0.130\n",
            "epoch: [460] loss: 0.128\n",
            "epoch: [461] loss: 0.130\n",
            "epoch: [462] loss: 0.130\n",
            "epoch: [463] loss: 0.129\n",
            "epoch: [464] loss: 0.131\n",
            "epoch: [465] loss: 0.128\n",
            "epoch: [466] loss: 0.129\n",
            "epoch: [467] loss: 0.127\n",
            "epoch: [468] loss: 0.129\n",
            "epoch: [469] loss: 0.128\n",
            "epoch: [470] loss: 0.128\n",
            "epoch: [471] loss: 0.133\n",
            "epoch: [472] loss: 0.130\n",
            "epoch: [473] loss: 0.129\n",
            "epoch: [474] loss: 0.127\n",
            "epoch: [475] loss: 0.129\n",
            "epoch: [476] loss: 0.129\n",
            "epoch: [477] loss: 0.128\n",
            "epoch: [478] loss: 0.128\n",
            "epoch: [479] loss: 0.128\n",
            "epoch: [480] loss: 0.129\n",
            "epoch: [481] loss: 0.127\n",
            "epoch: [482] loss: 0.130\n",
            "epoch: [483] loss: 0.127\n",
            "epoch: [484] loss: 0.129\n",
            "epoch: [485] loss: 0.130\n",
            "epoch: [486] loss: 0.131\n",
            "epoch: [487] loss: 0.126\n",
            "epoch: [488] loss: 0.128\n",
            "epoch: [489] loss: 0.130\n",
            "epoch: [490] loss: 0.128\n",
            "epoch: [491] loss: 0.130\n",
            "epoch: [492] loss: 0.129\n",
            "epoch: [493] loss: 0.128\n",
            "epoch: [494] loss: 0.131\n",
            "epoch: [495] loss: 0.134\n",
            "epoch: [496] loss: 0.127\n",
            "epoch: [497] loss: 0.127\n",
            "epoch: [498] loss: 0.129\n",
            "epoch: [499] loss: 0.129\n",
            "epoch: [500] loss: 0.129\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 94 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 34 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 37 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 42 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 51 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 65 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 80 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 94 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 97 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 98 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   8\n",
            "epoch: [0 ] loss: 1.770\n",
            "epoch: [1] loss: 1.041\n",
            "epoch: [2] loss: 0.945\n",
            "epoch: [3] loss: 0.838\n",
            "epoch: [4] loss: 0.760\n",
            "epoch: [5] loss: 0.695\n",
            "epoch: [6] loss: 0.634\n",
            "epoch: [7] loss: 0.580\n",
            "epoch: [8] loss: 0.529\n",
            "epoch: [9] loss: 0.483\n",
            "epoch: [10] loss: 0.443\n",
            "epoch: [11] loss: 0.409\n",
            "epoch: [12] loss: 0.378\n",
            "epoch: [13] loss: 0.352\n",
            "epoch: [14] loss: 0.330\n",
            "epoch: [15] loss: 0.310\n",
            "epoch: [16] loss: 0.293\n",
            "epoch: [17] loss: 0.278\n",
            "epoch: [18] loss: 0.265\n",
            "epoch: [19] loss: 0.251\n",
            "epoch: [20] loss: 0.240\n",
            "epoch: [21] loss: 0.231\n",
            "epoch: [22] loss: 0.221\n",
            "epoch: [23] loss: 0.212\n",
            "epoch: [24] loss: 0.205\n",
            "epoch: [25] loss: 0.198\n",
            "epoch: [26] loss: 0.191\n",
            "epoch: [27] loss: 0.183\n",
            "epoch: [28] loss: 0.177\n",
            "epoch: [29] loss: 0.172\n",
            "epoch: [30] loss: 0.167\n",
            "epoch: [31] loss: 0.162\n",
            "epoch: [32] loss: 0.158\n",
            "epoch: [33] loss: 0.153\n",
            "epoch: [34] loss: 0.150\n",
            "epoch: [35] loss: 0.145\n",
            "epoch: [36] loss: 0.140\n",
            "epoch: [37] loss: 0.137\n",
            "epoch: [38] loss: 0.133\n",
            "epoch: [39] loss: 0.130\n",
            "epoch: [40] loss: 0.126\n",
            "epoch: [41] loss: 0.123\n",
            "epoch: [42] loss: 0.121\n",
            "epoch: [43] loss: 0.119\n",
            "epoch: [44] loss: 0.115\n",
            "epoch: [45] loss: 0.115\n",
            "epoch: [46] loss: 0.111\n",
            "epoch: [47] loss: 0.109\n",
            "epoch: [48] loss: 0.107\n",
            "epoch: [49] loss: 0.105\n",
            "epoch: [50] loss: 0.104\n",
            "epoch: [51] loss: 0.102\n",
            "epoch: [52] loss: 0.099\n",
            "epoch: [53] loss: 0.098\n",
            "epoch: [54] loss: 0.096\n",
            "epoch: [55] loss: 0.094\n",
            "epoch: [56] loss: 0.093\n",
            "epoch: [57] loss: 0.091\n",
            "epoch: [58] loss: 0.090\n",
            "epoch: [59] loss: 0.088\n",
            "epoch: [60] loss: 0.088\n",
            "epoch: [61] loss: 0.086\n",
            "epoch: [62] loss: 0.084\n",
            "epoch: [63] loss: 0.083\n",
            "epoch: [64] loss: 0.082\n",
            "epoch: [65] loss: 0.081\n",
            "epoch: [66] loss: 0.081\n",
            "epoch: [67] loss: 0.079\n",
            "epoch: [68] loss: 0.078\n",
            "epoch: [69] loss: 0.077\n",
            "epoch: [70] loss: 0.077\n",
            "epoch: [71] loss: 0.076\n",
            "epoch: [72] loss: 0.077\n",
            "epoch: [73] loss: 0.074\n",
            "epoch: [74] loss: 0.074\n",
            "epoch: [75] loss: 0.072\n",
            "epoch: [76] loss: 0.071\n",
            "epoch: [77] loss: 0.071\n",
            "epoch: [78] loss: 0.071\n",
            "epoch: [79] loss: 0.069\n",
            "epoch: [80] loss: 0.068\n",
            "epoch: [81] loss: 0.068\n",
            "epoch: [82] loss: 0.067\n",
            "epoch: [83] loss: 0.067\n",
            "epoch: [84] loss: 0.066\n",
            "epoch: [85] loss: 0.065\n",
            "epoch: [86] loss: 0.064\n",
            "epoch: [87] loss: 0.064\n",
            "epoch: [88] loss: 0.064\n",
            "epoch: [89] loss: 0.063\n",
            "epoch: [90] loss: 0.062\n",
            "epoch: [91] loss: 0.062\n",
            "epoch: [92] loss: 0.062\n",
            "epoch: [93] loss: 0.061\n",
            "epoch: [94] loss: 0.061\n",
            "epoch: [95] loss: 0.060\n",
            "epoch: [96] loss: 0.060\n",
            "epoch: [97] loss: 0.060\n",
            "epoch: [98] loss: 0.059\n",
            "epoch: [99] loss: 0.060\n",
            "epoch: [100] loss: 0.059\n",
            "epoch: [101] loss: 0.057\n",
            "epoch: [102] loss: 0.057\n",
            "epoch: [103] loss: 0.057\n",
            "epoch: [104] loss: 0.057\n",
            "epoch: [105] loss: 0.058\n",
            "epoch: [106] loss: 0.057\n",
            "epoch: [107] loss: 0.056\n",
            "epoch: [108] loss: 0.055\n",
            "epoch: [109] loss: 0.055\n",
            "epoch: [110] loss: 0.054\n",
            "epoch: [111] loss: 0.054\n",
            "epoch: [112] loss: 0.054\n",
            "epoch: [113] loss: 0.054\n",
            "epoch: [114] loss: 0.053\n",
            "epoch: [115] loss: 0.053\n",
            "epoch: [116] loss: 0.053\n",
            "epoch: [117] loss: 0.053\n",
            "epoch: [118] loss: 0.052\n",
            "epoch: [119] loss: 0.052\n",
            "epoch: [120] loss: 0.052\n",
            "epoch: [121] loss: 0.052\n",
            "epoch: [122] loss: 0.051\n",
            "epoch: [123] loss: 0.051\n",
            "epoch: [124] loss: 0.051\n",
            "epoch: [125] loss: 0.051\n",
            "epoch: [126] loss: 0.051\n",
            "epoch: [127] loss: 0.050\n",
            "epoch: [128] loss: 0.051\n",
            "epoch: [129] loss: 0.050\n",
            "epoch: [130] loss: 0.049\n",
            "epoch: [131] loss: 0.049\n",
            "epoch: [132] loss: 0.049\n",
            "epoch: [133] loss: 0.049\n",
            "epoch: [134] loss: 0.048\n",
            "epoch: [135] loss: 0.048\n",
            "epoch: [136] loss: 0.048\n",
            "epoch: [137] loss: 0.048\n",
            "epoch: [138] loss: 0.047\n",
            "epoch: [139] loss: 0.048\n",
            "epoch: [140] loss: 0.047\n",
            "epoch: [141] loss: 0.047\n",
            "epoch: [142] loss: 0.047\n",
            "epoch: [143] loss: 0.047\n",
            "epoch: [144] loss: 0.046\n",
            "epoch: [145] loss: 0.046\n",
            "epoch: [146] loss: 0.046\n",
            "epoch: [147] loss: 0.046\n",
            "epoch: [148] loss: 0.046\n",
            "epoch: [149] loss: 0.046\n",
            "epoch: [150] loss: 0.046\n",
            "epoch: [151] loss: 0.046\n",
            "epoch: [152] loss: 0.047\n",
            "epoch: [153] loss: 0.045\n",
            "epoch: [154] loss: 0.045\n",
            "epoch: [155] loss: 0.045\n",
            "epoch: [156] loss: 0.044\n",
            "epoch: [157] loss: 0.046\n",
            "epoch: [158] loss: 0.045\n",
            "epoch: [159] loss: 0.045\n",
            "epoch: [160] loss: 0.044\n",
            "epoch: [161] loss: 0.044\n",
            "epoch: [162] loss: 0.044\n",
            "epoch: [163] loss: 0.044\n",
            "epoch: [164] loss: 0.044\n",
            "epoch: [165] loss: 0.043\n",
            "epoch: [166] loss: 0.044\n",
            "epoch: [167] loss: 0.043\n",
            "epoch: [168] loss: 0.043\n",
            "epoch: [169] loss: 0.043\n",
            "epoch: [170] loss: 0.043\n",
            "epoch: [171] loss: 0.042\n",
            "epoch: [172] loss: 0.043\n",
            "epoch: [173] loss: 0.042\n",
            "epoch: [174] loss: 0.043\n",
            "epoch: [175] loss: 0.042\n",
            "epoch: [176] loss: 0.042\n",
            "epoch: [177] loss: 0.042\n",
            "epoch: [178] loss: 0.042\n",
            "epoch: [179] loss: 0.041\n",
            "epoch: [180] loss: 0.041\n",
            "epoch: [181] loss: 0.042\n",
            "epoch: [182] loss: 0.043\n",
            "epoch: [183] loss: 0.042\n",
            "epoch: [184] loss: 0.042\n",
            "epoch: [185] loss: 0.041\n",
            "epoch: [186] loss: 0.041\n",
            "epoch: [187] loss: 0.041\n",
            "epoch: [188] loss: 0.041\n",
            "epoch: [189] loss: 0.041\n",
            "epoch: [190] loss: 0.040\n",
            "epoch: [191] loss: 0.041\n",
            "epoch: [192] loss: 0.041\n",
            "epoch: [193] loss: 0.040\n",
            "epoch: [194] loss: 0.040\n",
            "epoch: [195] loss: 0.040\n",
            "epoch: [196] loss: 0.039\n",
            "epoch: [197] loss: 0.040\n",
            "epoch: [198] loss: 0.040\n",
            "epoch: [199] loss: 0.040\n",
            "epoch: [200] loss: 0.040\n",
            "epoch: [201] loss: 0.040\n",
            "epoch: [202] loss: 0.040\n",
            "epoch: [203] loss: 0.040\n",
            "epoch: [204] loss: 0.039\n",
            "epoch: [205] loss: 0.039\n",
            "epoch: [206] loss: 0.039\n",
            "epoch: [207] loss: 0.039\n",
            "epoch: [208] loss: 0.040\n",
            "epoch: [209] loss: 0.040\n",
            "epoch: [210] loss: 0.039\n",
            "epoch: [211] loss: 0.039\n",
            "epoch: [212] loss: 0.040\n",
            "epoch: [213] loss: 0.038\n",
            "epoch: [214] loss: 0.039\n",
            "epoch: [215] loss: 0.038\n",
            "epoch: [216] loss: 0.038\n",
            "epoch: [217] loss: 0.038\n",
            "epoch: [218] loss: 0.038\n",
            "epoch: [219] loss: 0.039\n",
            "epoch: [220] loss: 0.038\n",
            "epoch: [221] loss: 0.038\n",
            "epoch: [222] loss: 0.040\n",
            "epoch: [223] loss: 0.039\n",
            "epoch: [224] loss: 0.042\n",
            "epoch: [225] loss: 0.041\n",
            "epoch: [226] loss: 0.039\n",
            "epoch: [227] loss: 0.037\n",
            "epoch: [228] loss: 0.038\n",
            "epoch: [229] loss: 0.037\n",
            "epoch: [230] loss: 0.037\n",
            "epoch: [231] loss: 0.037\n",
            "epoch: [232] loss: 0.037\n",
            "epoch: [233] loss: 0.038\n",
            "epoch: [234] loss: 0.037\n",
            "epoch: [235] loss: 0.037\n",
            "epoch: [236] loss: 0.037\n",
            "epoch: [237] loss: 0.037\n",
            "epoch: [238] loss: 0.036\n",
            "epoch: [239] loss: 0.037\n",
            "epoch: [240] loss: 0.037\n",
            "epoch: [241] loss: 0.036\n",
            "epoch: [242] loss: 0.037\n",
            "epoch: [243] loss: 0.037\n",
            "epoch: [244] loss: 0.036\n",
            "epoch: [245] loss: 0.036\n",
            "epoch: [246] loss: 0.037\n",
            "epoch: [247] loss: 0.037\n",
            "epoch: [248] loss: 0.036\n",
            "epoch: [249] loss: 0.038\n",
            "epoch: [250] loss: 0.037\n",
            "epoch: [251] loss: 0.037\n",
            "epoch: [252] loss: 0.036\n",
            "epoch: [253] loss: 0.036\n",
            "epoch: [254] loss: 0.036\n",
            "epoch: [255] loss: 0.036\n",
            "epoch: [256] loss: 0.036\n",
            "epoch: [257] loss: 0.036\n",
            "epoch: [258] loss: 0.036\n",
            "epoch: [259] loss: 0.036\n",
            "epoch: [260] loss: 0.036\n",
            "epoch: [261] loss: 0.036\n",
            "epoch: [262] loss: 0.036\n",
            "epoch: [263] loss: 0.037\n",
            "epoch: [264] loss: 0.036\n",
            "epoch: [265] loss: 0.036\n",
            "epoch: [266] loss: 0.036\n",
            "epoch: [267] loss: 0.036\n",
            "epoch: [268] loss: 0.035\n",
            "epoch: [269] loss: 0.037\n",
            "epoch: [270] loss: 0.036\n",
            "epoch: [271] loss: 0.036\n",
            "epoch: [272] loss: 0.036\n",
            "epoch: [273] loss: 0.035\n",
            "epoch: [274] loss: 0.035\n",
            "epoch: [275] loss: 0.035\n",
            "epoch: [276] loss: 0.035\n",
            "epoch: [277] loss: 0.035\n",
            "epoch: [278] loss: 0.036\n",
            "epoch: [279] loss: 0.035\n",
            "epoch: [280] loss: 0.035\n",
            "epoch: [281] loss: 0.036\n",
            "epoch: [282] loss: 0.035\n",
            "epoch: [283] loss: 0.035\n",
            "epoch: [284] loss: 0.037\n",
            "epoch: [285] loss: 0.035\n",
            "epoch: [286] loss: 0.035\n",
            "epoch: [287] loss: 0.035\n",
            "epoch: [288] loss: 0.036\n",
            "epoch: [289] loss: 0.035\n",
            "epoch: [290] loss: 0.034\n",
            "epoch: [291] loss: 0.035\n",
            "epoch: [292] loss: 0.035\n",
            "epoch: [293] loss: 0.035\n",
            "epoch: [294] loss: 0.035\n",
            "epoch: [295] loss: 0.035\n",
            "epoch: [296] loss: 0.035\n",
            "epoch: [297] loss: 0.034\n",
            "epoch: [298] loss: 0.034\n",
            "epoch: [299] loss: 0.034\n",
            "epoch: [300] loss: 0.034\n",
            "epoch: [301] loss: 0.034\n",
            "epoch: [302] loss: 0.035\n",
            "epoch: [303] loss: 0.034\n",
            "epoch: [304] loss: 0.034\n",
            "epoch: [305] loss: 0.034\n",
            "epoch: [306] loss: 0.034\n",
            "epoch: [307] loss: 0.035\n",
            "epoch: [308] loss: 0.035\n",
            "epoch: [309] loss: 0.033\n",
            "epoch: [310] loss: 0.034\n",
            "epoch: [311] loss: 0.034\n",
            "epoch: [312] loss: 0.034\n",
            "epoch: [313] loss: 0.034\n",
            "epoch: [314] loss: 0.034\n",
            "epoch: [315] loss: 0.034\n",
            "epoch: [316] loss: 0.035\n",
            "epoch: [317] loss: 0.034\n",
            "epoch: [318] loss: 0.035\n",
            "epoch: [319] loss: 0.034\n",
            "epoch: [320] loss: 0.034\n",
            "epoch: [321] loss: 0.033\n",
            "epoch: [322] loss: 0.034\n",
            "epoch: [323] loss: 0.033\n",
            "epoch: [324] loss: 0.033\n",
            "epoch: [325] loss: 0.033\n",
            "epoch: [326] loss: 0.035\n",
            "epoch: [327] loss: 0.034\n",
            "epoch: [328] loss: 0.034\n",
            "epoch: [329] loss: 0.033\n",
            "epoch: [330] loss: 0.034\n",
            "epoch: [331] loss: 0.033\n",
            "epoch: [332] loss: 0.033\n",
            "epoch: [333] loss: 0.033\n",
            "epoch: [334] loss: 0.034\n",
            "epoch: [335] loss: 0.033\n",
            "epoch: [336] loss: 0.033\n",
            "epoch: [337] loss: 0.032\n",
            "epoch: [338] loss: 0.033\n",
            "epoch: [339] loss: 0.033\n",
            "epoch: [340] loss: 0.033\n",
            "epoch: [341] loss: 0.033\n",
            "epoch: [342] loss: 0.033\n",
            "epoch: [343] loss: 0.033\n",
            "epoch: [344] loss: 0.033\n",
            "epoch: [345] loss: 0.032\n",
            "epoch: [346] loss: 0.033\n",
            "epoch: [347] loss: 0.034\n",
            "epoch: [348] loss: 0.033\n",
            "epoch: [349] loss: 0.033\n",
            "epoch: [350] loss: 0.033\n",
            "epoch: [351] loss: 0.033\n",
            "epoch: [352] loss: 0.034\n",
            "epoch: [353] loss: 0.033\n",
            "epoch: [354] loss: 0.032\n",
            "epoch: [355] loss: 0.033\n",
            "epoch: [356] loss: 0.033\n",
            "epoch: [357] loss: 0.036\n",
            "epoch: [358] loss: 0.035\n",
            "epoch: [359] loss: 0.032\n",
            "epoch: [360] loss: 0.032\n",
            "epoch: [361] loss: 0.033\n",
            "epoch: [362] loss: 0.032\n",
            "epoch: [363] loss: 0.032\n",
            "epoch: [364] loss: 0.032\n",
            "epoch: [365] loss: 0.032\n",
            "epoch: [366] loss: 0.032\n",
            "epoch: [367] loss: 0.032\n",
            "epoch: [368] loss: 0.033\n",
            "epoch: [369] loss: 0.032\n",
            "epoch: [370] loss: 0.033\n",
            "epoch: [371] loss: 0.036\n",
            "epoch: [372] loss: 0.034\n",
            "epoch: [373] loss: 0.032\n",
            "epoch: [374] loss: 0.033\n",
            "epoch: [375] loss: 0.032\n",
            "epoch: [376] loss: 0.031\n",
            "epoch: [377] loss: 0.032\n",
            "epoch: [378] loss: 0.032\n",
            "epoch: [379] loss: 0.033\n",
            "epoch: [380] loss: 0.032\n",
            "epoch: [381] loss: 0.033\n",
            "epoch: [382] loss: 0.032\n",
            "epoch: [383] loss: 0.031\n",
            "epoch: [384] loss: 0.032\n",
            "epoch: [385] loss: 0.032\n",
            "epoch: [386] loss: 0.031\n",
            "epoch: [387] loss: 0.032\n",
            "epoch: [388] loss: 0.032\n",
            "epoch: [389] loss: 0.032\n",
            "epoch: [390] loss: 0.032\n",
            "epoch: [391] loss: 0.031\n",
            "epoch: [392] loss: 0.031\n",
            "epoch: [393] loss: 0.031\n",
            "epoch: [394] loss: 0.032\n",
            "epoch: [395] loss: 0.031\n",
            "epoch: [396] loss: 0.031\n",
            "epoch: [397] loss: 0.031\n",
            "epoch: [398] loss: 0.032\n",
            "epoch: [399] loss: 0.031\n",
            "epoch: [400] loss: 0.031\n",
            "epoch: [401] loss: 0.032\n",
            "epoch: [402] loss: 0.032\n",
            "epoch: [403] loss: 0.033\n",
            "epoch: [404] loss: 0.034\n",
            "epoch: [405] loss: 0.032\n",
            "epoch: [406] loss: 0.032\n",
            "epoch: [407] loss: 0.032\n",
            "epoch: [408] loss: 0.031\n",
            "epoch: [409] loss: 0.031\n",
            "epoch: [410] loss: 0.031\n",
            "epoch: [411] loss: 0.031\n",
            "epoch: [412] loss: 0.031\n",
            "epoch: [413] loss: 0.032\n",
            "epoch: [414] loss: 0.032\n",
            "epoch: [415] loss: 0.032\n",
            "epoch: [416] loss: 0.033\n",
            "epoch: [417] loss: 0.031\n",
            "epoch: [418] loss: 0.031\n",
            "epoch: [419] loss: 0.031\n",
            "epoch: [420] loss: 0.033\n",
            "epoch: [421] loss: 0.031\n",
            "epoch: [422] loss: 0.031\n",
            "epoch: [423] loss: 0.031\n",
            "epoch: [424] loss: 0.031\n",
            "epoch: [425] loss: 0.032\n",
            "epoch: [426] loss: 0.033\n",
            "epoch: [427] loss: 0.030\n",
            "epoch: [428] loss: 0.033\n",
            "epoch: [429] loss: 0.033\n",
            "epoch: [430] loss: 0.032\n",
            "epoch: [431] loss: 0.031\n",
            "epoch: [432] loss: 0.031\n",
            "epoch: [433] loss: 0.031\n",
            "epoch: [434] loss: 0.031\n",
            "epoch: [435] loss: 0.030\n",
            "epoch: [436] loss: 0.031\n",
            "epoch: [437] loss: 0.030\n",
            "epoch: [438] loss: 0.030\n",
            "epoch: [439] loss: 0.031\n",
            "epoch: [440] loss: 0.030\n",
            "epoch: [441] loss: 0.033\n",
            "epoch: [442] loss: 0.033\n",
            "epoch: [443] loss: 0.031\n",
            "epoch: [444] loss: 0.030\n",
            "epoch: [445] loss: 0.030\n",
            "epoch: [446] loss: 0.030\n",
            "epoch: [447] loss: 0.030\n",
            "epoch: [448] loss: 0.031\n",
            "epoch: [449] loss: 0.031\n",
            "epoch: [450] loss: 0.030\n",
            "epoch: [451] loss: 0.030\n",
            "epoch: [452] loss: 0.030\n",
            "epoch: [453] loss: 0.031\n",
            "epoch: [454] loss: 0.030\n",
            "epoch: [455] loss: 0.030\n",
            "epoch: [456] loss: 0.031\n",
            "epoch: [457] loss: 0.030\n",
            "epoch: [458] loss: 0.030\n",
            "epoch: [459] loss: 0.030\n",
            "epoch: [460] loss: 0.030\n",
            "epoch: [461] loss: 0.030\n",
            "epoch: [462] loss: 0.030\n",
            "epoch: [463] loss: 0.033\n",
            "epoch: [464] loss: 0.031\n",
            "epoch: [465] loss: 0.030\n",
            "epoch: [466] loss: 0.030\n",
            "epoch: [467] loss: 0.031\n",
            "epoch: [468] loss: 0.030\n",
            "epoch: [469] loss: 0.030\n",
            "epoch: [470] loss: 0.030\n",
            "epoch: [471] loss: 0.031\n",
            "epoch: [472] loss: 0.031\n",
            "epoch: [473] loss: 0.031\n",
            "epoch: [474] loss: 0.030\n",
            "epoch: [475] loss: 0.030\n",
            "epoch: [476] loss: 0.029\n",
            "epoch: [477] loss: 0.030\n",
            "epoch: [478] loss: 0.030\n",
            "epoch: [479] loss: 0.030\n",
            "epoch: [480] loss: 0.029\n",
            "epoch: [481] loss: 0.030\n",
            "epoch: [482] loss: 0.030\n",
            "epoch: [483] loss: 0.029\n",
            "epoch: [484] loss: 0.029\n",
            "epoch: [485] loss: 0.030\n",
            "epoch: [486] loss: 0.032\n",
            "epoch: [487] loss: 0.030\n",
            "epoch: [488] loss: 0.030\n",
            "epoch: [489] loss: 0.032\n",
            "epoch: [490] loss: 0.030\n",
            "epoch: [491] loss: 0.029\n",
            "epoch: [492] loss: 0.031\n",
            "epoch: [493] loss: 0.030\n",
            "epoch: [494] loss: 0.029\n",
            "epoch: [495] loss: 0.029\n",
            "epoch: [496] loss: 0.030\n",
            "epoch: [497] loss: 0.030\n",
            "epoch: [498] loss: 0.030\n",
            "epoch: [499] loss: 0.030\n",
            "epoch: [500] loss: 0.030\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 99 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 35 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 38 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 43 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 50 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 61 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 75 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 89 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 99 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 100 %\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "training on data set   9\n",
            "epoch: [0 ] loss: 1.656\n",
            "epoch: [1] loss: 1.006\n",
            "epoch: [2] loss: 0.827\n",
            "epoch: [3] loss: 0.722\n",
            "epoch: [4] loss: 0.636\n",
            "epoch: [5] loss: 0.564\n",
            "epoch: [6] loss: 0.504\n",
            "epoch: [7] loss: 0.452\n",
            "epoch: [8] loss: 0.409\n",
            "epoch: [9] loss: 0.369\n",
            "epoch: [10] loss: 0.335\n",
            "epoch: [11] loss: 0.305\n",
            "epoch: [12] loss: 0.276\n",
            "epoch: [13] loss: 0.251\n",
            "epoch: [14] loss: 0.230\n",
            "epoch: [15] loss: 0.212\n",
            "epoch: [16] loss: 0.195\n",
            "epoch: [17] loss: 0.181\n",
            "epoch: [18] loss: 0.168\n",
            "epoch: [19] loss: 0.156\n",
            "epoch: [20] loss: 0.146\n",
            "epoch: [21] loss: 0.137\n",
            "epoch: [22] loss: 0.128\n",
            "epoch: [23] loss: 0.119\n",
            "epoch: [24] loss: 0.113\n",
            "epoch: [25] loss: 0.107\n",
            "epoch: [26] loss: 0.101\n",
            "epoch: [27] loss: 0.096\n",
            "epoch: [28] loss: 0.091\n",
            "epoch: [29] loss: 0.086\n",
            "epoch: [30] loss: 0.082\n",
            "epoch: [31] loss: 0.078\n",
            "epoch: [32] loss: 0.074\n",
            "epoch: [33] loss: 0.071\n",
            "epoch: [34] loss: 0.068\n",
            "epoch: [35] loss: 0.065\n",
            "epoch: [36] loss: 0.063\n",
            "epoch: [37] loss: 0.060\n",
            "epoch: [38] loss: 0.057\n",
            "epoch: [39] loss: 0.055\n",
            "epoch: [40] loss: 0.052\n",
            "epoch: [41] loss: 0.050\n",
            "epoch: [42] loss: 0.048\n",
            "epoch: [43] loss: 0.046\n",
            "epoch: [44] loss: 0.045\n",
            "epoch: [45] loss: 0.043\n",
            "epoch: [46] loss: 0.042\n",
            "epoch: [47] loss: 0.041\n",
            "epoch: [48] loss: 0.039\n",
            "epoch: [49] loss: 0.038\n",
            "epoch: [50] loss: 0.036\n",
            "epoch: [51] loss: 0.035\n",
            "epoch: [52] loss: 0.034\n",
            "epoch: [53] loss: 0.033\n",
            "epoch: [54] loss: 0.032\n",
            "epoch: [55] loss: 0.031\n",
            "epoch: [56] loss: 0.030\n",
            "epoch: [57] loss: 0.029\n",
            "epoch: [58] loss: 0.028\n",
            "epoch: [59] loss: 0.027\n",
            "epoch: [60] loss: 0.026\n",
            "epoch: [61] loss: 0.026\n",
            "epoch: [62] loss: 0.026\n",
            "epoch: [63] loss: 0.024\n",
            "epoch: [64] loss: 0.024\n",
            "epoch: [65] loss: 0.023\n",
            "epoch: [66] loss: 0.023\n",
            "epoch: [67] loss: 0.022\n",
            "epoch: [68] loss: 0.021\n",
            "epoch: [69] loss: 0.021\n",
            "epoch: [70] loss: 0.020\n",
            "epoch: [71] loss: 0.019\n",
            "epoch: [72] loss: 0.019\n",
            "epoch: [73] loss: 0.019\n",
            "epoch: [74] loss: 0.018\n",
            "epoch: [75] loss: 0.018\n",
            "epoch: [76] loss: 0.017\n",
            "epoch: [77] loss: 0.017\n",
            "epoch: [78] loss: 0.016\n",
            "epoch: [79] loss: 0.016\n",
            "epoch: [80] loss: 0.016\n",
            "epoch: [81] loss: 0.016\n",
            "epoch: [82] loss: 0.015\n",
            "epoch: [83] loss: 0.014\n",
            "epoch: [84] loss: 0.014\n",
            "epoch: [85] loss: 0.014\n",
            "epoch: [86] loss: 0.014\n",
            "epoch: [87] loss: 0.013\n",
            "epoch: [88] loss: 0.013\n",
            "epoch: [89] loss: 0.013\n",
            "epoch: [90] loss: 0.012\n",
            "epoch: [91] loss: 0.012\n",
            "epoch: [92] loss: 0.012\n",
            "epoch: [93] loss: 0.012\n",
            "epoch: [94] loss: 0.011\n",
            "epoch: [95] loss: 0.011\n",
            "epoch: [96] loss: 0.011\n",
            "epoch: [97] loss: 0.011\n",
            "epoch: [98] loss: 0.010\n",
            "epoch: [99] loss: 0.010\n",
            "epoch: [100] loss: 0.010\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 100 %\n",
            "Accuracy of the network on the 3000 test dataset 1: 34 %\n",
            "Accuracy of the network on the 3000 test dataset 2: 36 %\n",
            "Accuracy of the network on the 3000 test dataset 3: 39 %\n",
            "Accuracy of the network on the 3000 test dataset 4: 44 %\n",
            "Accuracy of the network on the 3000 test dataset 5: 51 %\n",
            "Accuracy of the network on the 3000 test dataset 6: 62 %\n",
            "Accuracy of the network on the 3000 test dataset 7: 78 %\n",
            "Accuracy of the network on the 3000 test dataset 8: 95 %\n",
            "Accuracy of the network on the 3000 test dataset 9: 100 %\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "QTahDg_Su-Uz",
        "outputId": "1d1959ad-77fa-415b-deb8-2dbf054587ca"
      },
      "source": [
        "for i,j in enumerate(train_loss_all):\n",
        "    plt.plot(j,label =\"dataset \"+str(i+1))\n",
        "    \n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training_loss\")\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7770445668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whGsdvMSzIUK"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5NPRPmb904"
      },
      "source": [
        "batch = 250\n",
        "msd = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzN3Bbs8c0fA"
      },
      "source": [
        "class Focus_deep(nn.Module):\n",
        "    '''\n",
        "       deep focus network averaged at zeroth layer\n",
        "       input : elemental data\n",
        "    '''\n",
        "    def __init__(self,inputs,output,K,d):\n",
        "        super(Focus_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.K = K\n",
        "        self.d  = d\n",
        "        self.linear1 = nn.Linear(self.inputs,300)  #,self.output)\n",
        "        self.linear2 = nn.Linear(300,self.output) \n",
        "    def forward(self,z):\n",
        "        batch = z.shape[0]\n",
        "        x = torch.zeros([batch,self.K],dtype=torch.float64)\n",
        "        y = torch.zeros([batch,self.d], dtype=torch.float64)\n",
        "        x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "        for i in range(self.K):\n",
        "            x[:,i] = self.helper(z[:,i] )[:,0]  # self.d*i:self.d*i+self.d\n",
        "        x = F.softmax(x,dim=1)   # alphas\n",
        "        x1 = x[:,0]\n",
        "        for i in range(self.K):\n",
        "            x1 = x[:,i]          \n",
        "            y = y+torch.mul(x1[:,None],z[:,i])  # self.d*i:self.d*i+self.d\n",
        "        return y , x \n",
        "    def helper(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W0oKcClFZY"
      },
      "source": [
        "class Classification_deep(nn.Module):\n",
        "    '''\n",
        "       input : elemental data\n",
        "       deep classification module data averaged at zeroth layer\n",
        "    '''\n",
        "    def __init__(self,inputs,output):\n",
        "        super(Classification_deep,self).__init__()\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "        self.linear1 = nn.Linear(self.inputs,300)\n",
        "        self.linear2 = nn.Linear(300,self.output)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = self.linear2(x)\n",
        "      return x    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAPjSKkrd0ru"
      },
      "source": [
        "where = Focus_deep(5,1,9,5).double()\n",
        "what = Classification_deep(5,3).double()\n",
        "where = where.to(\"cuda\")\n",
        "what = what.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAfQnNwgFYX"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,where,criter):\n",
        "  what.eval()\n",
        "  where.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx = data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "      avg,alpha = where(inputs)\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9HQJMzxBhp"
      },
      "source": [
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOfxUJZ_eFKw",
        "outputId": "7d88d85a-db81-4aa1-e034-ea67ab7b95af"
      },
      "source": [
        "\n",
        "print(\"--\"*40)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_where = optim.Adam(where.parameters(),lr =0.001)\n",
        "optimizer_what = optim.Adam(what.parameters(), lr=0.001)\n",
        "acti = []\n",
        "loss_curi = []\n",
        "analysis_data = []\n",
        "epochs = 1000\n",
        "running_loss,anlys_data = calculate_attn_loss(train_loader,what,where,criterion)\n",
        "loss_curi.append(running_loss)\n",
        "analysis_data.append(anlys_data)\n",
        "print('epoch: [%d ] loss: %.3f' %(0,running_loss)) \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what.train()\n",
        "  where.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_ = data\n",
        "    inputs = inputs.double()\n",
        "    inputs, labels = inputs.to(\"cuda\"),labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    optimizer_where.zero_grad()\n",
        "    optimizer_what.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    avg, alpha = where(inputs)\n",
        "    outputs = what(avg)\n",
        "    loss = criterion(outputs, labels)\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer_where.step()\n",
        "    optimizer_what.step()\n",
        "\n",
        "  running_loss,anls_data = calculate_attn_loss(train_loader,what,where,criterion)\n",
        "  analysis_data.append(anls_data)\n",
        "  print('epoch: [%d] loss: %.3f' %(epoch + 1,running_loss)) \n",
        "  loss_curi.append(running_loss)   #loss per epoch\n",
        "  if running_loss<=0.01:\n",
        "    break\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels,_ = data\n",
        "    images = images.double()\n",
        "    images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    avg, alpha = where(images)\n",
        "    outputs  = what(avg)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 3000 train images: %d %%' % (  100 * correct / total))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "epoch: [0 ] loss: 1.949\n",
            "epoch: [1] loss: 1.309\n",
            "epoch: [2] loss: 1.227\n",
            "epoch: [3] loss: 1.219\n",
            "epoch: [4] loss: 1.204\n",
            "epoch: [5] loss: 1.203\n",
            "epoch: [6] loss: 1.195\n",
            "epoch: [7] loss: 1.198\n",
            "epoch: [8] loss: 1.204\n",
            "epoch: [9] loss: 1.195\n",
            "epoch: [10] loss: 1.193\n",
            "epoch: [11] loss: 1.200\n",
            "epoch: [12] loss: 1.204\n",
            "epoch: [13] loss: 1.205\n",
            "epoch: [14] loss: 1.207\n",
            "epoch: [15] loss: 1.199\n",
            "epoch: [16] loss: 1.147\n",
            "epoch: [17] loss: 0.738\n",
            "epoch: [18] loss: 0.500\n",
            "epoch: [19] loss: 0.378\n",
            "epoch: [20] loss: 0.314\n",
            "epoch: [21] loss: 0.270\n",
            "epoch: [22] loss: 0.233\n",
            "epoch: [23] loss: 0.207\n",
            "epoch: [24] loss: 0.184\n",
            "epoch: [25] loss: 0.166\n",
            "epoch: [26] loss: 0.153\n",
            "epoch: [27] loss: 0.139\n",
            "epoch: [28] loss: 0.128\n",
            "epoch: [29] loss: 0.118\n",
            "epoch: [30] loss: 0.111\n",
            "epoch: [31] loss: 0.104\n",
            "epoch: [32] loss: 0.097\n",
            "epoch: [33] loss: 0.090\n",
            "epoch: [34] loss: 0.085\n",
            "epoch: [35] loss: 0.080\n",
            "epoch: [36] loss: 0.076\n",
            "epoch: [37] loss: 0.072\n",
            "epoch: [38] loss: 0.068\n",
            "epoch: [39] loss: 0.065\n",
            "epoch: [40] loss: 0.061\n",
            "epoch: [41] loss: 0.059\n",
            "epoch: [42] loss: 0.056\n",
            "epoch: [43] loss: 0.053\n",
            "epoch: [44] loss: 0.051\n",
            "epoch: [45] loss: 0.049\n",
            "epoch: [46] loss: 0.047\n",
            "epoch: [47] loss: 0.045\n",
            "epoch: [48] loss: 0.043\n",
            "epoch: [49] loss: 0.041\n",
            "epoch: [50] loss: 0.039\n",
            "epoch: [51] loss: 0.038\n",
            "epoch: [52] loss: 0.036\n",
            "epoch: [53] loss: 0.035\n",
            "epoch: [54] loss: 0.034\n",
            "epoch: [55] loss: 0.033\n",
            "epoch: [56] loss: 0.031\n",
            "epoch: [57] loss: 0.030\n",
            "epoch: [58] loss: 0.030\n",
            "epoch: [59] loss: 0.028\n",
            "epoch: [60] loss: 0.027\n",
            "epoch: [61] loss: 0.026\n",
            "epoch: [62] loss: 0.026\n",
            "epoch: [63] loss: 0.025\n",
            "epoch: [64] loss: 0.024\n",
            "epoch: [65] loss: 0.023\n",
            "epoch: [66] loss: 0.022\n",
            "epoch: [67] loss: 0.022\n",
            "epoch: [68] loss: 0.021\n",
            "epoch: [69] loss: 0.021\n",
            "epoch: [70] loss: 0.020\n",
            "epoch: [71] loss: 0.019\n",
            "epoch: [72] loss: 0.019\n",
            "epoch: [73] loss: 0.018\n",
            "epoch: [74] loss: 0.017\n",
            "epoch: [75] loss: 0.017\n",
            "epoch: [76] loss: 0.017\n",
            "epoch: [77] loss: 0.016\n",
            "epoch: [78] loss: 0.016\n",
            "epoch: [79] loss: 0.015\n",
            "epoch: [80] loss: 0.015\n",
            "epoch: [81] loss: 0.014\n",
            "epoch: [82] loss: 0.014\n",
            "epoch: [83] loss: 0.014\n",
            "epoch: [84] loss: 0.013\n",
            "epoch: [85] loss: 0.013\n",
            "epoch: [86] loss: 0.013\n",
            "epoch: [87] loss: 0.012\n",
            "epoch: [88] loss: 0.012\n",
            "epoch: [89] loss: 0.012\n",
            "epoch: [90] loss: 0.011\n",
            "epoch: [91] loss: 0.011\n",
            "epoch: [92] loss: 0.011\n",
            "epoch: [93] loss: 0.011\n",
            "epoch: [94] loss: 0.010\n",
            "epoch: [95] loss: 0.010\n",
            "epoch: [96] loss: 0.010\n",
            "Finished Training\n",
            "Accuracy of the network on the 3000 train images: 100 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "L31RVViMkYM-",
        "outputId": "793dfeb5-cc91-49c7-9deb-a3ce8494c424"
      },
      "source": [
        "analysis_data = np.array(analysis_data)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,0],label=\"ftpt\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,1],label=\"ffpt\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,2],label=\"ftpf\")\n",
        "plt.plot(np.arange(0,epoch+2,1),analysis_data[:,3],label=\"ffpf\")\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.savefig(\"trends_synthetic_300_300.png\",bbox_inches=\"tight\")\n",
        "plt.savefig(\"trends_synthetic_300_300.pdf\",bbox_inches=\"tight\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5mag3jZ-LMe",
        "outputId": "9c8ead5b-e80c-4c9d-cf22-3f8732d149fa"
      },
      "source": [
        "analysis_data[-1,:2]/3000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99666667, 0.00333333])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGfR1m_0-SBq",
        "outputId": "f6bf936b-d12e-4354-c39c-ae4ed90ef10f"
      },
      "source": [
        "1972/3000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6573333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyAAqplWAkvH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}